<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Paper Sorted</title>
    <url>/posts/46623364.html</url>
    <content><![CDATA[<h1 id="Natural-Language-Processing"><a href="#Natural-Language-Processing" class="headerlink" title="Natural Language Processing"></a>Natural Language Processing</h1><ul>
<li><a href="https://github.com/maidis/awesome-machine-translation" target="_blank" rel="noopener">Machine Translation</a> <br> <img src="https://img.shields.io/badge/author-maidis-be8abf" alt> <img src="https://img.shields.io/github/stars/maidis/awesome-machine-translation" alt></li>
<li><a href="https://github.com/fendouai/Awesome-Text-Classification" target="_blank" rel="noopener">Text Classification</a> <br> <img src="https://img.shields.io/badge/author-fendouai-be8abf" alt> <img src="https://img.shields.io/github/stars/fendouai/Awesome-Text-Classification" alt></li>
<li><a href="https://github.com/xiamx/awesome-sentiment-analysis" target="_blank" rel="noopener">Sentiment Analysis</a> <br> <img src="https://img.shields.io/badge/author-xiamx-be8abf" alt> <img src="https://img.shields.io/github/stars/xiamx/awesome-sentiment-analysis" alt></li>
<li><a href="https://github.com/laugustyniak/awesome-sentiment-analysis" target="_blank" rel="noopener">Sentiment Analysis</a> <br> <img src="https://img.shields.io/badge/author-laugustyniak-be8abf" alt> <img src="https://img.shields.io/github/stars/laugustyniak/awesome-sentiment-analysis" alt></li>
<li><a href="https://github.com/haiker2011/awesome-nlp-sentiment-analysis" target="_blank" rel="noopener">Sentiment Analysis</a> <br> <img src="https://img.shields.io/badge/author-haiker2011-be8abf" alt> <img src="https://img.shields.io/github/stars/haiker2011/awesome-nlp-sentiment-analysis" alt></li>
<li><a href="https://github.com/ZhengZixiang/ABSAPapers" target="_blank" rel="noopener">Aspect-Based Sentiment Analysis</a> <br> <img src="https://img.shields.io/badge/author-ZhengZixiang-be8abf" alt> <img src="https://img.shields.io/github/stars/ZhengZixiang/ABSAPapers" alt></li>
<li><a href="https://github.com/jiangqn/Aspect-Based-Sentiment-Analysis" target="_blank" rel="noopener">Aspect-Based Sentiment Analysis</a> <br> <img src="https://img.shields.io/badge/author-jiangqn-be8abf" alt> <img src="https://img.shields.io/github/stars/jiangqn/Aspect-Based-Sentiment-Analysis" alt></li>
<li><a href="https://github.com/thunlp/RCPapers" target="_blank" rel="noopener">Machine Reading Comprehension</a> <br> <img src="https://img.shields.io/badge/author-thunlp-be8abf" alt> <img src="https://img.shields.io/github/stars/thunlp/RCPapers" alt></li>
<li><a href="https://github.com/xanhho/Reading-Comprehension-Question-Answering-Papers" target="_blank" rel="noopener">Machine Reading Comprehension</a> <br> <img src="https://img.shields.io/badge/author-xanhho-be8abf" alt> <img src="https://img.shields.io/github/stars/xanhho/Reading-Comprehension-Question-Answering-Papers" alt></li>
<li><a href="https://github.com/thunlp/NREPapers" target="_blank" rel="noopener">Relation Extraction</a> <br> <img src="https://img.shields.io/badge/author-thunlp-be8abf" alt> <img src="https://img.shields.io/github/stars/thunlp/NREPapers" alt></li>
<li><a href="https://github.com/roomylee/awesome-relation-extraction" target="_blank" rel="noopener">Relation Extraction</a> <br> <img src="https://img.shields.io/badge/author-roomylee-be8abf" alt> <img src="https://img.shields.io/github/stars/roomylee/awesome-relation-extraction" alt></li>
<li><a href="https://github.com/cedrickchee/awesome-bert-nlp" target="_blank" rel="noopener">BERT-based Research</a> <br> <img src="https://img.shields.io/badge/author-cedrickchee-be8abf" alt> <img src="https://img.shields.io/github/stars/cedrickchee/awesome-bert-nlp" alt></li>
<li><a href="https://github.com/thunlp/PLMpapers" target="_blank" rel="noopener">Pre-trained Language Model</a> <br> <img src="https://img.shields.io/badge/author-thunlp-be8abf" alt> <img src="https://img.shields.io/github/stars/thunlp/PLMpapers" alt></li>
<li><a href="https://github.com/thunlp/SCPapers" target="_blank" rel="noopener">Sememe Computation</a> <br> <img src="https://img.shields.io/badge/author-thunlp-be8abf" alt> <img src="https://img.shields.io/github/stars/thunlp/SCPapers" alt></li>
<li><a href="https://github.com/THUNLP-MT/TG-Reading-List" target="_blank" rel="noopener">Text Generation</a><br> <img src="https://img.shields.io/badge/author-THUNLP_MT-be8abf" alt> <img src="https://img.shields.io/github/stars/THUNLP-MT/TG-Reading-List" alt></li>
<li><a href="https://github.com/ChenChengKuan/awesome-text-generation" target="_blank" rel="noopener">Text Generation</a> <br> <img src="https://img.shields.io/badge/author-ChenChengKuan-be8abf" alt> <img src="https://img.shields.io/github/stars/ChenChengKuan/awesome-text-generation" alt></li>
<li><a href="https://github.com/tokenmill/awesome-nlg" target="_blank" rel="noopener">Text Generation</a><br> <img src="https://img.shields.io/badge/author-tokenmill-be8abf" alt> <img src="https://img.shields.io/github/stars/tokenmill/awesome-nlg" alt></li>
<li><a href="https://github.com/franxyao/Deep-Generative-Models-for-Natural-Language-Processing" target="_blank" rel="noopener">Text Generation</a><br> <img src="https://img.shields.io/badge/author-franxyao-be8abf" alt> <img src="https://img.shields.io/github/stars/franxyao/Deep-Generative-Models-for-Natural-Language-Processing" alt></li>
<li><a href="https://github.com/FranxYao/Language-Model-Pretraining-for-Text-Generation" target="_blank" rel="noopener">Pre-trained LM for Text Generation</a><br> <img src="https://img.shields.io/badge/author-franxyao-be8abf" alt> <img src="https://img.shields.io/github/stars/FranxYao/Language-Model-Pretraining-for-Text-Generation" alt></li>
<li><a href="https://github.com/thunlp/TAADpapers" target="_blank" rel="noopener">Textual Adversarial Attack and Defense</a> <br> <img src="https://img.shields.io/badge/author-thunlp-be8abf" alt> <img src="https://img.shields.io/github/stars/thunlp/TAADpapers" alt></li>
<li><a href="https://github.com/jaromirsalamon/Awesome-Dialogue-System-Papers" target="_blank" rel="noopener">Dialogue System</a> <br> <img src="https://img.shields.io/badge/author-jaromirsalamon-be8abf" alt> <img src="https://img.shields.io/github/stars/jaromirsalamon/Awesome-Dialogue-System-Papers" alt></li>
<li><a href="https://github.com/ZhengZixiang/DSPapers" target="_blank" rel="noopener">Dialogue System</a> <br> <img src="https://img.shields.io/badge/author-ZhengZixiang-be8abf" alt> <img src="https://img.shields.io/github/stars/ZhengZixiang/DSPapers" alt></li>
<li><a href="https://github.com/tsenghungchen/dialog-generation-paper" target="_blank" rel="noopener">Dialogue Generation</a> <br> <img src="https://img.shields.io/badge/author-tsenghungchen-be8abf" alt> <img src="https://img.shields.io/github/stars/tsenghungchen/dialog-generation-paper" alt></li>
<li><a href="https://github.com/yajingsunno/dialogue-system-reading-paper-list" target="_blank" rel="noopener">Dialogue System</a> <br> <img src="https://img.shields.io/badge/author-yajingsunno-be8abf" alt> <img src="https://img.shields.io/github/stars/yajingsunno/dialogue-system-reading-paper-list" alt></li>
<li><a href="https://github.com/google-research-datasets/dstc8-schema-guided-dialogue" target="_blank" rel="noopener">Dialogue State Tracking</a> <br> <img src="https://img.shields.io/badge/author-google-be8abf" alt> <img src="https://img.shields.io/github/stars/google-research-datasets/dstc8-schema-guided-dialogue" alt></li>
<li><a href="https://github.com/AtmaHou/Task-Oriented-Dialogue-Dataset-Survey" target="_blank" rel="noopener">Task-Oriented Dialogue</a> <br> <img src="https://img.shields.io/badge/author-AtmaHou-be8abf" alt> <img src="https://img.shields.io/github/stars/AtmaHou/Task-Oriented-Dialogue-Dataset-Survey" alt></li>
<li><a href="https://github.com/jianguoz/Conversational-AI" target="_blank" rel="noopener">Conversational AI</a> <br> <img src="https://img.shields.io/badge/author-jianguoz-be8abf" alt> <img src="https://img.shields.io/github/stars/jianguoz/Conversational-AI" alt></li>
<li><a href="https://github.com/Separius/awesome-sentence-embedding" target="_blank" rel="noopener">Sentence Embeddings</a> <br> <img src="https://img.shields.io/badge/author-Separius-be8abf" alt> <img src="https://img.shields.io/github/stars/Separius/awesome-sentence-embedding" alt></li>
<li><a href="https://github.com/dapurv5/awesome-question-answering" target="_blank" rel="noopener">Question Answering</a> <br> <img src="https://img.shields.io/badge/author-dapurv5-be8abf" alt> <img src="https://img.shields.io/github/stars/dapurv5/awesome-question-answering" alt></li>
<li><a href="https://github.com/BshoterJ/awesome-knowledge-graph-question-answering" target="_blank" rel="noopener">Knowledge Base Question Answering</a> <br> <img src="https://img.shields.io/badge/author-Bshoter-be8abf" alt> <img src="https://img.shields.io/github/stars/BshoterJ/awesome-knowledge-graph-question-answering" alt></li>
<li><a href="https://github.com/fuzhenxin/Style-Transfer-in-Text" target="_blank" rel="noopener">Text Style Transfer</a> <br> <img src="https://img.shields.io/badge/author-fuzhenxin-be8abf" alt> <img src="https://img.shields.io/github/stars/fuzhenxin/Style-Transfer-in-Text" alt></li>
<li><a href="https://github.com/yd1996/awesome-text-style-transfer" target="_blank" rel="noopener">Text Style Transfer</a> <br> <img src="https://img.shields.io/badge/author-yd1996-be8abf" alt> <img src="https://img.shields.io/github/stars/yd1996/awesome-text-style-transfer" alt></li>
<li><a href="https://github.com/NTMC-Community/awesome-neural-models-for-semantic-match" target="_blank" rel="noopener">Text Matching</a> <br> <img src="https://img.shields.io/badge/author-NTMC_Community-be8abf" alt> <img src="https://img.shields.io/github/stars/NTMC-Community/awesome-neural-models-for-semantic-match" alt></li>
<li><a href="https://github.com/luopeixiang/awesome-text-summarization" target="_blank" rel="noopener">Text Summarization</a> <br> <img src="https://img.shields.io/badge/author-NTMC_Community-be8abf" alt> <img src="https://img.shields.io/github/stars/NTMC-Community/awesome-neural-models-for-semantic-match" alt></li>
<li><a href="https://github.com/fuzhenxin/Personal-Emotional-Stylized-Dialog" target="_blank" rel="noopener">Personal Emotional Stylized Dialog</a> <br> <img src="https://img.shields.io/badge/author-fuzhenxin-be8abf" alt> <img src="https://img.shields.io/github/stars/fuzhenxin/Personal-Emotional-Stylized-Dialog" alt></li>
<li><a href="https://github.com/pfliu-nlp/Named-Entity-Recognition-NER-Papers" target="_blank" rel="noopener">Named Entity Recognition</a> <br> <img src="https://img.shields.io/badge/author-pfliu-be8abf" alt> <img src="https://img.shields.io/github/stars/pfliu-nlp/Named-Entity-Recognition-NER-Papers" alt></li>
<li><a href="https://github.com/lingluodlut/BioNER-Progress" target="_blank" rel="noopener">Biomedical NER</a> <br> <img src="https://img.shields.io/badge/author-lingluodlut-be8abf" alt> <img src="https://img.shields.io/github/stars/lingluodlut/BioNER-Progress" alt></li>
<li><a href="https://github.com/ZhengZixiang/NERPapers" target="_blank" rel="noopener">Named Entity Recognition</a> <br> <img src="https://img.shields.io/badge/author-ZhengZixiang-be8abf" alt> <img src="https://img.shields.io/github/stars/ZhengZixiang/NERPapers" alt></li>
<li><a href="https://github.com/ryanzhumich/awesome-clir" target="_blank" rel="noopener">Cross-lingual Information Retrieval</a> <br> <img src="https://img.shields.io/badge/author-ryanzhumich-be8abf" alt> <img src="https://img.shields.io/github/stars/ryanzhumich/awesome-clir" alt></li>
<li><a href="https://github.com/harpribot/awesome-information-retrieval" target="_blank" rel="noopener">Information Retrieval</a> <br> <img src="https://img.shields.io/badge/author-harpribot-be8abf" alt> <img src="https://img.shields.io/github/stars/harpribot/awesome-information-retrieval" alt></li>
<li><a href="https://github.com/umbrellabeach/awesome-Biomedical-EntityLinking-papers" target="_blank" rel="noopener">Biomedical Entity Linking</a> <br><br><img src="https://img.shields.io/badge/author-umbrellabeach-be8abf" alt><br><img src="https://img.shields.io/github/stars/umbrellabeach/awesome-Biomedical-EntityLinking-papers" alt></li>
<li><a href="https://github.com/NPCai/Open-IE-Papers" target="_blank" rel="noopener">Open Information Extraction</a> <br><br><img src="https://img.shields.io/badge/author-NPCai-be8abf" alt><br><img src="https://img.shields.io/github/stars/NPCai/Open-IE-Papers" alt></li>
<li><a href="https://github.com/caufieldjh/awesome-bioie" target="_blank" rel="noopener">Biomedical Information Extraction</a> <br><br><img src="https://img.shields.io/badge/author-caufieldjh-be8abf" alt><br><img src="https://img.shields.io/github/stars/caufieldjh/awesome-bioie" alt></li>
</ul>
<h1 id="Computer-Vision"><a href="#Computer-Vision" class="headerlink" title="Computer Vision"></a>Computer Vision</h1><ul>
<li><a href="https://github.com/mrgloom/awesome-semantic-segmentation" target="_blank" rel="noopener">Semantic Segmentation</a> <br><br><img src="https://img.shields.io/badge/author-mrgloom-be8abf" alt><br><img src="https://img.shields.io/github/stars/mrgloom/awesome-semantic-segmentation" alt></li>
<li><a href="https://github.com/jinwchoi/awesome-action-recognition" target="_blank" rel="noopener">Action Recognition</a> <br><br><img src="https://img.shields.io/badge/author-jinwchoi-be8abf" alt><br><img src="https://img.shields.io/github/stars/jinwchoi/awesome-action-recognition" alt></li>
<li><a href="https://github.com/weiaicunzai/awesome-image-classification" target="_blank" rel="noopener">Image Classification</a> <br><br><img src="https://img.shields.io/badge/author-weiaicunzai-be8abf" alt><br><img src="https://img.shields.io/github/stars/weiaicunzai/awesome-image-classification" alt></li>
<li><a href="https://github.com/willard-yuan/awesome-cbir-papers" target="_blank" rel="noopener">Image Retrieval</a> <br><br><img src="https://img.shields.io/badge/author-willard_yuan-be8abf" alt><br><img src="https://img.shields.io/github/stars/willard-yuan/awesome-cbir-papers" alt></li>
<li><a href="https://github.com/amusi/awesome-object-detection" target="_blank" rel="noopener">Object Detection</a> <br><br><img src="https://img.shields.io/badge/author-amusi-be8abf" alt><br><img src="https://img.shields.io/github/stars/amusi/awesome-object-detection" alt></li>
<li><a href="https://github.com/hoya012/deep_learning_object_detection" target="_blank" rel="noopener">Object Detection</a> <br><br><img src="https://img.shields.io/badge/author-hoya012-be8abf" alt><br><img src="https://img.shields.io/github/stars/hoya012/deep_learning_object_detection" alt></li>
<li><a href="https://github.com/xiaweihao/awesome-image-translation" target="_blank" rel="noopener">Image-to-image Translation</a> <br><br><img src="https://img.shields.io/badge/author-xiaweihao-be8abf" alt><br><img src="https://img.shields.io/github/stars/xiaweihao/awesome-image-translation" alt></li>
<li><a href="https://github.com/zhaoxin94/awesome-domain-adaptation" target="_blank" rel="noopener">Domain Adaptation</a> <br><br><img src="https://img.shields.io/badge/author-zhaoxin94-be8abf" alt><br><img src="https://img.shields.io/github/stars/zhaoxin94/awesome-domain-adaptation" alt></li>
<li><a href="https://github.com/tzutalin/awesome-visual-slam" target="_blank" rel="noopener">vision-based SLAM / Visual Odometry</a> <br><br><img src="https://img.shields.io/badge/author-tzutalin-be8abf" alt><br><img src="https://img.shields.io/github/stars/tzutalin/awesome-visual-slam" alt></li>
<li><a href="https://github.com/ChanChiChoi/awesome-Face_Recognition" target="_blank" rel="noopener">Face-related</a> <br><br><img src="https://img.shields.io/badge/author-ChanChiChoi-be8abf" alt><br><img src="https://img.shields.io/github/stars/ChanChiChoi/awesome-Face_Recognition" alt></li>
<li><a href="https://github.com/chongyangtao/Awesome-Scene-Text-Recognition" target="_blank" rel="noopener">Scene Text Recognition</a> <br><br><img src="https://img.shields.io/badge/author-chongyangtao-be8abf" alt><br><img src="https://img.shields.io/github/stars/chongyangtao/Awesome-Scene-Text-Recognition" alt></li>
<li><a href="https://github.com/hwalsuklee/awesome-deep-text-detection-recognition" target="_blank" rel="noopener">Text Detection &amp; Recognition</a> <br><br><img src="https://img.shields.io/badge/author-hwalsuklee-be8abf" alt><br><img src="https://img.shields.io/github/stars/hwalsuklee/awesome-deep-text-detection-recognition" alt></li>
</ul>
<h1 id="Graphs"><a href="#Graphs" class="headerlink" title="Graphs"></a>Graphs</h1><ul>
<li><a href="https://github.com/nnzhan/Awesome-Graph-Neural-Networks" target="_blank" rel="noopener">Graph Neural Networks</a> <br><br><img src="https://img.shields.io/badge/author-nnzhan-be8abf" alt><br><img src="https://img.shields.io/github/stars/nnzhan/Awesome-Graph-Neural-Networks" alt></li>
<li><a href="https://github.com/thunlp/GNNPapers" target="_blank" rel="noopener">Graph Neural Networks</a> <br><br><img src="https://img.shields.io/badge/author-thunlp-be8abf" alt><br><img src="https://img.shields.io/github/stars/thunlp/GNNPapers" alt></li>
<li><a href="https://github.com/Jiakui/awesome-gcn" target="_blank" rel="noopener">Graph Convolutional Networks</a> <br><br><img src="https://img.shields.io/badge/author-Jiakui-be8abf" alt><br><img src="https://img.shields.io/github/stars/Jiakui/awesome-gcn" alt></li>
<li><a href="https://github.com/benedekrozemberczki/awesome-graph-classification" target="_blank" rel="noopener">Graph Classification</a> <br><br><img src="https://img.shields.io/badge/author-benedekrozemberczki-be8abf" alt><br><img src="https://img.shields.io/github/stars/benedekrozemberczki/awesome-graph-classification" alt></li>
<li><a href="https://github.com/ky-zhang/awesome-graph-representation-learning" target="_blank" rel="noopener">Graph Representation Learning</a> <br><br><img src="https://img.shields.io/badge/author-ky_zhang-be8abf" alt><br><img src="https://img.shields.io/github/stars/ky-zhang/awesome-graph-representation-learning" alt></li>
<li><a href="https://github.com/thunlp/NRLPapers" target="_blank" rel="noopener">Graph Representation Learning</a> <br><br><img src="https://img.shields.io/badge/author-thunlp-be8abf" alt><br><img src="https://img.shields.io/github/stars/thunlp/NRLPapers" alt></li>
<li><a href="https://github.com/chihming/awesome-network-embedding" target="_blank" rel="noopener">Network Embeddings</a> <br><br><img src="https://img.shields.io/badge/author-chihming-be8abf" alt><br><img src="https://img.shields.io/github/stars/chihming/awesome-network-embedding" alt></li>
<li><a href="https://github.com/thunlp/KB2E" target="_blank" rel="noopener">Knowledge Graph Embeddings</a> <br><br><img src="https://img.shields.io/badge/author-thun-be8abf" alt><br><img src="https://img.shields.io/github/stars/thunlp/KB2E" alt></li>
<li><a href="https://github.com/benedekrozemberczki/awesome-community-detection" target="_blank" rel="noopener">Community Detection</a> <br><br><img src="https://img.shields.io/badge/author-benedekrozemberczki-be8abf" alt><br><img src="https://img.shields.io/github/stars/benedekrozemberczki/awesome-community-detection" alt></li>
<li><a href="https://github.com/FatemehTarashi/awesome-TDA" target="_blank" rel="noopener">Topological Data Analysis</a> <br><br><img src="https://img.shields.io/badge/author-FatemehTarashi-be8abf" alt><br><img src="https://img.shields.io/github/stars/FatemehTarashi/awesome-TDA" alt></li>
<li><a href="https://github.com/safe-graph/graph-adversarial-learning-literature" target="_blank" rel="noopener">Graph Adversarial Learning</a> <br><br><img src="https://img.shields.io/badge/author-SafeGraph-be8abf" alt><br><img src="https://img.shields.io/github/stars/safe-graph/graph-adversarial-learning-literature" alt></li>
<li><a href="https://github.com/jbmusso/awesome-graph" target="_blank" rel="noopener">Graph Computing</a> <br><br><img src="https://img.shields.io/badge/author-jbmusso-be8abf" alt><br><img src="https://img.shields.io/github/stars/jbmusso/awesome-graph" alt></li>
</ul>
<h1 id="Knowledge-Graph"><a href="#Knowledge-Graph" class="headerlink" title="Knowledge Graph"></a>Knowledge Graph</h1><ul>
<li><a href="https://github.com/songjiang0909/awesome-knowledge-graph-construction" target="_blank" rel="noopener">Knowledge Graph Construction</a> <br><br><img src="https://img.shields.io/badge/author-songjiang0909-be8abf" alt><br><img src="https://img.shields.io/github/stars/songjiang0909/awesome-knowledge-graph-construction" alt></li>
<li><a href="https://github.com/thunlp/KRLPapers" target="_blank" rel="noopener">Knowledge Embeddings</a> <br><br><img src="https://img.shields.io/badge/author-thunlp-be8abf" alt><br><img src="https://img.shields.io/github/stars/thunlp/KRLPapers" alt></li>
<li><a href="https://github.com/husthuke/awesome-knowledge-graph" target="_blank" rel="noopener">Knowledge Graph</a> <br><br><img src="https://img.shields.io/badge/author-husthuke-be8abf" alt><br><img src="https://img.shields.io/github/stars/husthuke/awesome-knowledge-graph" alt></li>
<li><a href="https://github.com/shaoxiongji/awesome-knowledge-graph" target="_blank" rel="noopener">Knowledge Graph</a> <br><br><img src="https://img.shields.io/badge/author-shaoxiongji-be8abf" alt><br><img src="https://img.shields.io/github/stars/shaoxiongji/awesome-knowledge-graph" alt></li>
<li><a href="https://github.com/BrambleXu/knowledge-graph-learning" target="_blank" rel="noopener">Knowledge Graph</a> <br><br><img src="https://img.shields.io/badge/author-BrambleXu-be8abf" alt><br><img src="https://img.shields.io/github/stars/BrambleXu/knowledge-graph-learning" alt></li>
<li><a href="https://github.com/totogo/awesome-knowledge-graph" target="_blank" rel="noopener">Knowledge Graph</a> <br><br><img src="https://img.shields.io/badge/author-totogo-be8abf" alt><br><img src="https://img.shields.io/github/stars/totogo/awesome-knowledge-graph" alt></li>
</ul>
<h1 id="MultiModality"><a href="#MultiModality" class="headerlink" title="MultiModality"></a>MultiModality</h1><ul>
<li><a href="https://github.com/zhjohnchan/awesome-image-captioning" target="_blank" rel="noopener">Image Captioning</a>  <br><br><img src="https://img.shields.io/badge/author-zhjohnchan-be8abf" alt><br><img src="https://img.shields.io/github/stars/zhjohnchan/awesome-image-captioning" alt></li>
<li><a href="https://github.com/forence/Awesome-Visual-Captioning" target="_blank" rel="noopener">Image Captioning</a>  <br><br><img src="https://img.shields.io/badge/author-forence-be8abf" alt><br><img src="https://img.shields.io/github/stars/forence/Awesome-Visual-Captioning" alt></li>
<li><a href="https://github.com/chingyaoc/awesome-vqa" target="_blank" rel="noopener">Visual Question Answering</a>  <br><br><img src="https://img.shields.io/badge/author-chingyaoc-be8abf" alt><br><img src="https://img.shields.io/github/stars/chingyaoc/awesome-vqa" alt></li>
<li><a href="https://github.com/jokieleung/awesome-visual-question-answering" target="_blank" rel="noopener">Visual Question Answering</a>  <br><br><img src="https://img.shields.io/badge/author-jokieleung-be8abf" alt><br><img src="https://img.shields.io/github/stars/jokieleung/awesome-visual-question-answering" alt></li>
<li><a href="https://github.com/DerekDLP/VQA-papers" target="_blank" rel="noopener">Visual Question Answering</a>  <br><br><img src="https://img.shields.io/badge/author-DerekDLP-be8abf" alt><br><img src="https://img.shields.io/github/stars/DerekDLP/VQA-papers" alt></li>
<li><a href="https://github.com/ZihengZZH/awesome-multimodal-machine-translation" target="_blank" rel="noopener">Multimodal Machine Translation</a>  <br><br><img src="https://img.shields.io/badge/author-ZihengZZH-be8abf" alt><br><img src="https://img.shields.io/github/stars/ZihengZZH/awesome-multimodal-machine-translation" alt></li>
<li><a href="https://github.com/TheShadow29/awesome-grounding" target="_blank" rel="noopener">Visual Grounding</a>  <br><br><img src="https://img.shields.io/badge/author-TheShadow29-be8abf" alt><br><img src="https://img.shields.io/github/stars/TheShadow29/awesome-grounding" alt></li>
</ul>
<h1 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h1><ul>
<li><a href="https://github.com/matthewvowels1/Awesome-VAEs" target="_blank" rel="noopener">Awesome-VAEs</a> <br><br><img src="https://img.shields.io/badge/author-matthewvowels1-be8abf" alt><br><img src="https://img.shields.io/github/stars/matthewvowels1/Awesome-VAEs" alt></li>
<li><a href="https://github.com/LongLong-Jing/awesome-unsupervised-learning" target="_blank" rel="noopener">Unsupervised Learning</a> <br><br><img src="https://img.shields.io/badge/author-LongLong_Jing-be8abf" alt><br><img src="https://img.shields.io/github/stars/LongLong-Jing/awesome-unsupervised-learning" alt></li>
<li><a href="https://github.com/floodsung/Meta-Learning-Papers" target="_blank" rel="noopener">Meta Learning</a> <br><br><img src="https://img.shields.io/badge/author-floodsung-be8abf" alt><br><img src="https://img.shields.io/github/stars/floodsung/Meta-Learning-Papers" alt></li>
<li><a href="https://github.com/e-271/awesome-few-shot-learning" target="_blank" rel="noopener">Few Shot Learning</a> <br><br><img src="https://img.shields.io/badge/author-e_271-be8abf" alt><br><img src="https://img.shields.io/github/stars/e-271/awesome-few-shot-learning" alt></li>
<li><a href="https://github.com/Duan-JM/awesome-papers-fewshot" target="_blank" rel="noopener">Few Shot Learning</a> <br><br><img src="https://img.shields.io/badge/author-Duan_JM-be8abf" alt><br><img src="https://img.shields.io/github/stars/Duan-JM/awesome-papers-fewshot" alt></li>
<li><a href="https://github.com/sekwiatkowski/awesome-capsule-networks" target="_blank" rel="noopener">Capsule Networks</a> <br><br><img src="https://img.shields.io/badge/author-sekwiatkowski-be8abf" alt><br><img src="https://img.shields.io/github/stars/sekwiatkowski/awesome-capsule-networks" alt></li>
<li><a href="https://github.com/benedekrozemberczki/awesome-decision-tree-papers" target="_blank" rel="noopener">Decision Tree</a> <br><br><img src="https://img.shields.io/badge/author-benedekrozemberczki-be8abf" alt><br><img src="https://img.shields.io/github/stars/benedekrozemberczki/awesome-decision-tree-papers" alt></li>
<li><a href="https://github.com/blakeliu/awesome-cell-detection-segmentation" target="_blank" rel="noopener">Cell Detection &amp; Segmentation</a> <br><br><img src="https://img.shields.io/badge/author-blakeliu-be8abf" alt><br><img src="https://img.shields.io/github/stars/blakeliu/awesome-cell-detection-segmentation" alt></li>
<li><a href="https://github.com/benedekrozemberczki/awesome-fraud-detection-papers" target="_blank" rel="noopener">Fraud Detection</a> <br><br><img src="https://img.shields.io/badge/author-benedekrozemberczki-be8abf" alt><br><img src="https://img.shields.io/github/stars/benedekrozemberczki/awesome-fraud-detection-papers" alt></li>
<li><a href="https://github.com/safe-graph/graph-fraud-detection-papers" target="_blank" rel="noopener">Graph-based Fraud Detection</a> <br><br><img src="https://img.shields.io/badge/author-SafeGraph-be8abf" alt><br><img src="https://img.shields.io/github/stars/safe-graph/graph-fraud-detection-papers" alt></li>
<li><a href="https://github.com/thunlp/LegalPapers" target="_blank" rel="noopener">Legal Intelligence</a> <br><br><img src="https://img.shields.io/badge/author-thunlp-be8abf" alt><br><img src="https://img.shields.io/github/stars/thunlp/LegalPapers" alt></li>
<li><a href="https://github.com/CrazyVertigo/awesome-data-augmentation" target="_blank" rel="noopener">Data Augmentation</a> <br><br><img src="https://img.shields.io/badge/author-CrazyVertigo-be8abf" alt><br><img src="https://img.shields.io/github/stars/CrazyVertigo/awesome-data-augmentation" alt></li>
<li><a href="https://github.com/jiachenli94/Awesome-Decision-Making-Reinforcement-Learning" target="_blank" rel="noopener">Decision Making</a> <br><br><img src="https://img.shields.io/badge/author-jiachenli94-be8abf" alt><br><img src="https://img.shields.io/github/stars/jiachenli94/Awesome-Decision-Making-Reinforcement-Learning" alt></li>
</ul>
<h1 id="Commensense"><a href="#Commensense" class="headerlink" title="Commensense"></a>Commensense</h1><ul>
<li><a href="https://github.com/yhy1117/Commonsense_Reasoning_Papers" target="_blank" rel="noopener">Commonsense Reasoning</a> <br><br><img src="https://img.shields.io/badge/author-yhy1117-be8abf" alt><br><img src="https://img.shields.io/github/stars/yhy1117/Commonsense_Reasoning_Papers" alt></li>
<li><a href="https://github.com/wonderseen/Commonsense-Modeling" target="_blank" rel="noopener">Commonsense Modeling</a> <br><br><img src="https://img.shields.io/badge/author-wonderseen-be8abf" alt><br><img src="https://img.shields.io/github/stars/wonderseen/Commonsense-Modeling" alt></li>
</ul>
<h1 id="Time-Series"><a href="#Time-Series" class="headerlink" title="Time Series"></a>Time Series</h1><ul>
<li><a href="https://github.com/xephonhq/awesome-time-series-database" target="_blank" rel="noopener">Time Series</a> <br><br><img src="https://img.shields.io/badge/author-xephonhq-be8abf" alt><br><img src="https://img.shields.io/github/stars/xephonhq/awesome-time-series-database" alt></li>
<li><a href="https://github.com/bighuang624/Time-Series-Papers" target="_blank" rel="noopener">Time Series</a> <br><br><img src="https://img.shields.io/badge/author-bighuang624-be8abf" alt><br><img src="https://img.shields.io/github/stars/bighuang624/Time-Series-Papers" alt></li>
<li><a href="https://github.com/MaxBenChrist/awesome_time_series_in_python" target="_blank" rel="noopener">Time Series in Python</a> <br><br><img src="https://img.shields.io/badge/author-MaxBenChrist-be8abf" alt><br><img src="https://img.shields.io/github/stars/MaxBenChrist/awesome_time_series_in_python" alt></li>
<li><a href="https://github.com/youngdou/awesome-time-series-analysis" target="_blank" rel="noopener">Time Series Analysis</a> <br><br><img src="https://img.shields.io/badge/author-youngdou-be8abf" alt><br><img src="https://img.shields.io/github/stars/youngdou/awesome-time-series-analysis" alt></li>
</ul>
<h1 id="Speech"><a href="#Speech" class="headerlink" title="Speech"></a>Speech</h1><ul>
<li><p><a href="https://github.com/zzw922cn/awesome-speech-recognition-speech-synthesis-papers" target="_blank" rel="noopener">Speech Recognition &amp; Synthesis</a> <br><br><img src="https://img.shields.io/badge/author-zzw922cn-be8abf" alt><br><img src="https://img.shields.io/github/stars/zzw922cn/awesome-speech-recognition-speech-synthesis-papers" alt></p>
</li>
<li><p><a href="https://github.com/charlesliucn/awesome-end2end-speech-recognition" target="_blank" rel="noopener">End2End Speech Recognition</a> <br><br><img src="https://img.shields.io/badge/author-charlesliucn-be8abf" alt><br><img src="https://img.shields.io/github/stars/charlesliucn/awesome-end2end-speech-recognition" alt></p>
</li>
<li><a href="https://github.com/cyrta/awesome-speech-enhancement" target="_blank" rel="noopener">Speech Enhancement</a> <br><br><img src="https://img.shields.io/badge/author-cyrta-be8abf" alt><br><img src="https://img.shields.io/github/stars/cyrta/awesome-speech-enhancement" alt></li>
</ul>
<h1 id="Causality"><a href="#Causality" class="headerlink" title="Causality"></a>Causality</h1><ul>
<li><a href="https://github.com/dragen1860/awesome-causal-reasoning" target="_blank" rel="noopener">Causal Reasoning</a> <br><br><img src="https://img.shields.io/badge/author-dragen1860-be8abf" alt><br><img src="https://img.shields.io/github/stars/dragen1860/awesome-causal-reasoning" alt></li>
<li><a href="https://github.com/imirzadeh/awesome-causal-inference" target="_blank" rel="noopener">Causal Inference</a> <br><br><img src="https://img.shields.io/badge/author-imirzadeh-be8abf" alt><br><img src="https://img.shields.io/github/stars/imirzadeh/awesome-causal-inference" alt></li>
<li><a href="https://github.com/rguo12/awesome-causality-algorithms" target="_blank" rel="noopener">Causality Algorithms</a> <br><br><img src="https://img.shields.io/badge/author-rguo12-be8abf" alt><br><img src="https://img.shields.io/github/stars/rguo12/awesome-causality-algorithms" alt></li>
<li><a href="https://github.com/napsternxg/awesome-causality" target="_blank" rel="noopener">Causality</a> <br><br><img src="https://img.shields.io/badge/author-napsternxg-be8abf" alt><br><img src="https://img.shields.io/github/stars/napsternxg/awesome-causality" alt></li>
<li><a href="https://github.com/huckiyang/awesome-deep-causal-learning" target="_blank" rel="noopener">Deep Causal Learning</a> <br><br><img src="https://img.shields.io/badge/author-huckiyang-be8abf" alt><br><img src="https://img.shields.io/github/stars/huckiyang/awesome-deep-causal-learning" alt></li>
</ul>
<h1 id="Anomaly-Detection"><a href="#Anomaly-Detection" class="headerlink" title="Anomaly Detection"></a>Anomaly Detection</h1><ul>
<li><p><a href="https://github.com/yzhao062/anomaly-detection-resources" target="_blank" rel="noopener">Anomaly Detection</a> <br><br><img src="https://img.shields.io/badge/author-yzhao062-be8abf" alt><br><img src="https://img.shields.io/github/stars/yzhao062/anomaly-detection-resources" alt></p>
</li>
<li><p><a href="https://github.com/hoya012/awesome-anomaly-detection" target="_blank" rel="noopener">Anomaly Detection</a> <br><br><img src="https://img.shields.io/badge/author-hoya012-be8abf" alt><br><img src="https://img.shields.io/github/stars/hoya012/awesome-anomaly-detection" alt></p>
</li>
<li><a href="https://github.com/rob-med/awesome-TS-anomaly-detection" target="_blank" rel="noopener">Anomaly Detection on Time-Series Data</a> <br><br><img src="https://img.shields.io/badge/author-rob_med-be8abf" alt><br><img src="https://img.shields.io/github/stars/rob-med/awesome-TS-anomaly-detection" alt></li>
</ul>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
  </entry>
  <entry>
    <title>区块链入门（三） —— web3js编写以太坊脚本</title>
    <url>/posts/733c8737.html</url>
    <content><![CDATA[<h1 id="web3-js基础"><a href="#web3-js基础" class="headerlink" title="web3.js基础"></a>web3.js基础</h1><h2 id="web3-js是什么"><a href="#web3-js是什么" class="headerlink" title="web3.js是什么"></a>web3.js是什么</h2><ul>
<li>Web3 JavaScript app API</li>
<li>web3..js 是一个JavaScript API库。要使DApper在以太坊上运行，我们可以使用web3.js库提供的web3对象</li>
<li>web3.js通过RPC调用与本地节点通信，它可以用于任何暴露了RPC层的以太坊节点</li>
<li>web3包含了eth对象 - web3.eth（专门与以太坊区块链交互）和 shh对象 - web3.shh（用于与 Whisper交互）[Whisper是以太坊生态系统的一部分，主要用来做消息传递]</li>
</ul>
<p>如果我们想要在以太坊上开发合约，目前来说最方便的方法就是调用Web3.js库，它会给我们一个Web3对象。我们首先进入geth控制台，直接键入web3，下面对这些弹出的内容进行一个总览。</p>
<p>我们先看到db，db是操作区块链底层数据库的，整个以太坊的底层数据库就是LevelDB，其接口如下：</p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/db.png" alt></p>
<p>然后看到eth，一个我们已经很熟悉的模块：</p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/eth.png" alt></p>
<p>里面含有getBalance,gasPrice等最常用的操作。</p>
<p>再然后是personal，里面包含了我们创建账户的信息：</p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/personal.png" alt></p>
<p>还有shh等等，这里就不一一列举了：</p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/shh.png" alt></p>
<h2 id="web3-模块加载"><a href="#web3-模块加载" class="headerlink" title="web3 模块加载"></a>web3 模块加载</h2><ul>
<li>首先需要将 web3 模块安装在项目中，安装方式为（后面可以加版本也可以不加）  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install web3@0.20.1</span><br></pre></td></tr></table></figure></li>
<li>然后创建一个web3实例，设置一个”provider”</li>
<li>为了保证我们的MetaMask设置好的provider不被覆盖掉，在引入web3之前我们一般要做当前环境检查(以v0.20.1为例)：  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if(typeof web3 !&#x3D;&#x3D; &#39;undifined&#39;)&#123;</span><br><span class="line">	web3 &#x3D; new Web3(web3.currentProvider);</span><br><span class="line">&#125;else&#123;</span><br><span class="line">	web3 &#x3D; new Web3(new Web3.providers.HttpProvider(&#39;http:&#x2F;&#x2F;localhost:8545&#39;));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="异步回调（callback）"><a href="#异步回调（callback）" class="headerlink" title="异步回调（callback）"></a>异步回调（callback）</h2><ul>
<li>web3js API 设计的最初目的，主要是为了和本地RPC节点共同使用，所以默认情况下发送的是同步HTTP请求</li>
<li>如果要发送异步请求，可以在函数的最后一个参数位置上，传入一个回调函数，回调函数是可选的(optional)</li>
<li>我们一般采用的风格是所谓的“错误优先”，例如：  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getback(48, function(error, result))&#123;</span><br><span class="line">	if(!error)</span><br><span class="line">    	console.log(JSON.stringify(result));</span><br><span class="line">    else</span><br><span class="line">    	console.error(error);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>我们直接在geth尝试这一过程，并与同步过程对比：</p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/ybdy.png" alt></p>
<p>我们看到输出的内容没有任何区别，不过由刚才的同步调用方式改成了异步调用，那有了更简便的同步调用，我们为何还需要异步调用呢？</p>
<p>同步调用会将当前执行的进程完全阻塞在这里，只有当前面的步骤拿到代码返回之后后面的代码才会执行，所以同步的顺序是指定的，让谁先执行谁就先执行，但劣势也在此，可能会一直被卡在这里，在开发DApp等实际应用的时候，往往都需要用异步，互不干扰。</p>
<h2 id="回调Promise事件"><a href="#回调Promise事件" class="headerlink" title="回调Promise事件"></a>回调Promise事件</h2><p>目前基本上所有的东西大家都默认了状态是异步调用，那我们是否就无法保证顺序了呢？实际上不是的。</p>
<ul>
<li>为了帮助web3集成到不同标准的所有类型项目中，1.0.0版本提供了多种方式来处理异步函数。大多数的web3对象允许将一个回调函数作为最后一个函数参数传入，同时返回一个promise用于链式函数调用。</li>
<li>以太坊作为一个区块链系统，一次请求具有不同的结束阶段。为了满足这样的请求，1.0.0版本将这类函数调用的返回之包成一个“承诺事件”(promiEvent)，这是一个promise和EventEmitter的结合体</li>
<li>PromiEvent的用法就像promise一样，另外还加入了.on,.once和.off方法  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.sendTransaction(&#123;from:&#39;0x123...&#39;, data:&#39;0x432...&#39;&#125;)</span><br><span class="line">.once(&#39;transactionHash&#39;, function(hash)&#123;...&#125;)</span><br><span class="line">.once(&#39;receipt&#39;, function(receipt)&#123;...&#125;)</span><br><span class="line">.on(&#39;confirmation&#39;, function(confNumber, receipt)&#123;...&#125;)</span><br><span class="line">.on(&#39;error&#39;, function&#123;...&#125;)</span><br><span class="line">.then(function(receipt)&#123;&#125;);</span><br></pre></td></tr></table></figure>
回调完成的标志是收到receipt，也就是交易打包进块。</li>
</ul>
<h2 id="应用二进制接口（ABI）"><a href="#应用二进制接口（ABI）" class="headerlink" title="应用二进制接口（ABI）"></a>应用二进制接口（ABI）</h2><ul>
<li>web3.js通过以太坊智能合约的json接口（Application Binary Interface， ABI）创建一个JavaScript对象，用来在js代码中描述</li>
<li>函数（functions）<ul>
<li>type:函数类型，默认“function”，也可能是”constructor”</li>
<li>constant, payable, stateMutability: 函数的状态可变性</li>
<li>inputs, outputs: 函数输入、输出参数描述列表</li>
</ul>
</li>
<li>事件（events）<ul>
<li>type: 类型，总是”event”</li>
<li>inputs: 输入对象列表，包括name、type、indexed</li>
</ul>
</li>
</ul>
<p>我们首先创建一个sol文件，并进行编译，Coin.sol文件如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pragma solidity &gt;<span class="number">0.4</span><span class="number">.22</span>;</span><br><span class="line"></span><br><span class="line">contract Coin&#123;</span><br><span class="line">    address public minter;</span><br><span class="line">    mapping(address=&gt;uint) public balances;</span><br><span class="line">    event Sent(address <span class="keyword">from</span>, address to, uint amount);</span><br><span class="line">    constructor()public&#123;</span><br><span class="line">        minter = msg.sender;</span><br><span class="line">    &#125;</span><br><span class="line">    function mint(address receiver, uint amount)public&#123;</span><br><span class="line">        require(msg.sender == minter);</span><br><span class="line">        balances[receiver] += amount;</span><br><span class="line">    &#125;</span><br><span class="line">    function send(address receiver, uint amount)public&#123;</span><br><span class="line">        require(balances[msg.sender] &gt;= amount);</span><br><span class="line">        balances[msg.sender] -= amount;</span><br><span class="line">        balances[receiver] += amount;</span><br><span class="line">        emit Sent(msg.sender, receiver, amount);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/abi.png" alt></p>
<p>将上面的JSON文件稍微格式化一下：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">[&#123;</span><br><span class="line">	<span class="attr">"inputs"</span>: [],</span><br><span class="line">	<span class="attr">"stateMutability"</span>: <span class="string">"nonpayable"</span>,</span><br><span class="line">	<span class="attr">"type"</span>: <span class="string">"constructor"</span></span><br><span class="line">&#125;, &#123;</span><br><span class="line">	<span class="attr">"anonymous"</span>: <span class="literal">false</span>,</span><br><span class="line">	<span class="attr">"inputs"</span>: [&#123;</span><br><span class="line">		<span class="attr">"indexed"</span>: <span class="literal">false</span>,</span><br><span class="line">		<span class="attr">"internalType"</span>: <span class="string">"address"</span>,</span><br><span class="line">		<span class="attr">"name"</span>: <span class="string">"from"</span>,</span><br><span class="line">		<span class="attr">"type"</span>: <span class="string">"address"</span></span><br><span class="line">	&#125;, &#123;</span><br><span class="line">		<span class="attr">"indexed"</span>: <span class="literal">false</span>,</span><br><span class="line">		<span class="attr">"internalType"</span>: <span class="string">"address"</span>,</span><br><span class="line">		<span class="attr">"name"</span>: <span class="string">"to"</span>,</span><br><span class="line">		<span class="attr">"type"</span>: <span class="string">"address"</span></span><br><span class="line">	&#125;, &#123;</span><br><span class="line">		<span class="attr">"indexed"</span>: <span class="literal">false</span>,</span><br><span class="line">		<span class="attr">"internalType"</span>: <span class="string">"uint256"</span>,</span><br><span class="line">		<span class="attr">"name"</span>: <span class="string">"amount"</span>,</span><br><span class="line">		<span class="attr">"type"</span>: <span class="string">"uint256"</span></span><br><span class="line">	&#125;],</span><br><span class="line">	<span class="attr">"name"</span>: <span class="string">"Sent"</span>,</span><br><span class="line">	<span class="attr">"type"</span>: <span class="string">"event"</span></span><br><span class="line">&#125;, &#123;</span><br><span class="line">	<span class="attr">"inputs"</span>: [&#123;</span><br><span class="line">		<span class="attr">"internalType"</span>: <span class="string">"address"</span>,</span><br><span class="line">		<span class="attr">"name"</span>: <span class="string">""</span>,</span><br><span class="line">		<span class="attr">"type"</span>: <span class="string">"address"</span></span><br><span class="line">	&#125;],</span><br><span class="line">	<span class="attr">"name"</span>: <span class="string">"balances"</span>,</span><br><span class="line">	<span class="attr">"outputs"</span>: [&#123;</span><br><span class="line">		<span class="attr">"internalType"</span>: <span class="string">"uint256"</span>,</span><br><span class="line">		<span class="attr">"name"</span>: <span class="string">""</span>,</span><br><span class="line">		<span class="attr">"type"</span>: <span class="string">"uint256"</span></span><br><span class="line">	&#125;],</span><br><span class="line">	<span class="attr">"stateMutability"</span>: <span class="string">"view"</span>,</span><br><span class="line">	<span class="attr">"type"</span>: <span class="string">"function"</span></span><br><span class="line">&#125;, &#123;</span><br><span class="line">	<span class="attr">"inputs"</span>: [&#123;</span><br><span class="line">		<span class="attr">"internalType"</span>: <span class="string">"address"</span>,</span><br><span class="line">		<span class="attr">"name"</span>: <span class="string">"receiver"</span>,</span><br><span class="line">		<span class="attr">"type"</span>: <span class="string">"address"</span></span><br><span class="line">	&#125;, &#123;</span><br><span class="line">		<span class="attr">"internalType"</span>: <span class="string">"uint256"</span>,</span><br><span class="line">		<span class="attr">"name"</span>: <span class="string">"amount"</span>,</span><br><span class="line">		<span class="attr">"type"</span>: <span class="string">"uint256"</span></span><br><span class="line">	&#125;],</span><br><span class="line">	<span class="attr">"name"</span>: <span class="string">"mint"</span>,</span><br><span class="line">	<span class="attr">"outputs"</span>: [],</span><br><span class="line">	<span class="attr">"stateMutability"</span>: <span class="string">"nonpayable"</span>,</span><br><span class="line">	<span class="attr">"type"</span>: <span class="string">"function"</span></span><br><span class="line">&#125;, &#123;</span><br><span class="line">	<span class="attr">"inputs"</span>: [],</span><br><span class="line">	<span class="attr">"name"</span>: <span class="string">"minter"</span>,</span><br><span class="line">	<span class="attr">"outputs"</span>: [&#123;</span><br><span class="line">		<span class="attr">"internalType"</span>: <span class="string">"address"</span>,</span><br><span class="line">		<span class="attr">"name"</span>: <span class="string">""</span>,</span><br><span class="line">		<span class="attr">"type"</span>: <span class="string">"address"</span></span><br><span class="line">	&#125;],</span><br><span class="line">	<span class="attr">"stateMutability"</span>: <span class="string">"view"</span>,</span><br><span class="line">	<span class="attr">"type"</span>: <span class="string">"function"</span></span><br><span class="line">&#125;, &#123;</span><br><span class="line">	<span class="attr">"inputs"</span>: [&#123;</span><br><span class="line">		<span class="attr">"internalType"</span>: <span class="string">"address"</span>,</span><br><span class="line">		<span class="attr">"name"</span>: <span class="string">"receiver"</span>,</span><br><span class="line">		<span class="attr">"type"</span>: <span class="string">"address"</span></span><br><span class="line">	&#125;, &#123;</span><br><span class="line">		<span class="attr">"internalType"</span>: <span class="string">"uint256"</span>,</span><br><span class="line">		<span class="attr">"name"</span>: <span class="string">"amount"</span>,</span><br><span class="line">		<span class="attr">"type"</span>: <span class="string">"uint256"</span></span><br><span class="line">	&#125;],</span><br><span class="line">	<span class="attr">"name"</span>: <span class="string">"send"</span>,</span><br><span class="line">	<span class="attr">"outputs"</span>: [],</span><br><span class="line">	<span class="attr">"stateMutability"</span>: <span class="string">"nonpayable"</span>,</span><br><span class="line">	<span class="attr">"type"</span>: <span class="string">"function"</span></span><br><span class="line">&#125;]</span><br></pre></td></tr></table></figure>
<p>我们集中看一下下面这小段：<br><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="attr">"anonymous"</span>: <span class="literal">false</span>,</span><br><span class="line">	<span class="attr">"inputs"</span>: [&#123;</span><br><span class="line">		<span class="attr">"indexed"</span>: <span class="literal">false</span>,</span><br><span class="line">		<span class="attr">"internalType"</span>: <span class="string">"address"</span>,</span><br><span class="line">		<span class="attr">"name"</span>: <span class="string">"from"</span>,</span><br><span class="line">		<span class="attr">"type"</span>: <span class="string">"address"</span></span><br><span class="line">	&#125;, &#123;</span><br><span class="line">		<span class="attr">"indexed"</span>: <span class="literal">false</span>,</span><br><span class="line">		<span class="attr">"internalType"</span>: <span class="string">"address"</span>,</span><br><span class="line">		<span class="attr">"name"</span>: <span class="string">"to"</span>,</span><br><span class="line">		<span class="attr">"type"</span>: <span class="string">"address"</span></span><br><span class="line">	&#125;, &#123;</span><br><span class="line">		<span class="attr">"indexed"</span>: <span class="literal">false</span>,</span><br><span class="line">		<span class="attr">"internalType"</span>: <span class="string">"uint256"</span>,</span><br><span class="line">		<span class="attr">"name"</span>: <span class="string">"amount"</span>,</span><br><span class="line">		<span class="attr">"type"</span>: <span class="string">"uint256"</span></span><br><span class="line">	&#125;],</span><br><span class="line">	<span class="attr">"name"</span>: <span class="string">"Sent"</span>,</span><br><span class="line">	<span class="attr">"type"</span>: <span class="string">"event"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>首先是一个<strong>annoymous</strong>，这是一个匿名参数，如果你填了false，我们的事件在日志中的第一条topic就会为空（不写入），主题是对整个事件做的哈希，也就相当于这个事件没有签名了，事实上他出发的其他事件的log仍会计入，只不过没有整个事件签名了。然后是<strong>index</strong>，定义参数时如果设置index=True，则这个参数会被设置成可索引参数，就会被记在topic下。<br>我们可以看到这段JSON对应的是下面这一行代码，于是其他部分我们也很容易一一对上了：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">event Sent(address <span class="keyword">from</span>, address to, uint amount);</span><br></pre></td></tr></table></figure></p>
<p>我们看到合约编译可生成两种文件，一种是字节码，这是要部署到以太坊上的，另一种是根据源码生成ABI，这一套二进制接口是给web3使用的。下面我们安装web3模块：</p>
<ul>
<li>安装nodejs</li>
<li>npm install web3@^0.20.0</li>
<li>npm i npm to update</li>
<li>npm cache verify</li>
<li>npm install -g ethereumjs-testrpc</li>
<li>在终端启动testrpc</li>
<li>切换新的终端，创建文件connect.js，文件内容为  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var Web3 &#x3D; require(&#39;web3&#39;)</span><br><span class="line">var web3 &#x3D; new Web3(new Web3.providers.HttpProvider(&#39;http:&#x2F;&#x2F;localhost:8545&#39;))</span><br><span class="line">console.log(web3.eth.accounts)</span><br><span class="line">console.log(&#39;OK&#39;)</span><br><span class="line">var version &#x3D; web3.version.node;</span><br><span class="line">console.log(version);</span><br></pre></td></tr></table></figure></li>
<li>node connect.js后显示：</li>
</ul>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/web3_1.png" alt></p>
<p>事实上我们也可以一行行在node命令行中输入，这样可以更清晰地观察到结果：</p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/web3_2.png" alt></p>
<p>代码同上，读者自行键入即可。我们还可以获得web3的其他信息：</p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/web3_3.png" alt></p>
<h2 id="批处理请求-batch-requests"><a href="#批处理请求-batch-requests" class="headerlink" title="批处理请求(batch requests)"></a>批处理请求(batch requests)</h2><ul>
<li>批处理请求允许我们将请求排序，然后一起处理它们</li>
<li>注意：批处理请求不会更快，在某些情况下，一次性地发出许多请求会更快，因为请求是异步处理的。（我们想要加速通常会手动进行异步处理）</li>
<li>批处理请求主要用于确保请求的顺序，并串行处理</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">var batch = web3.createBatch();</span><br><span class="line">batch.add(web3.eth.getBalance.request(<span class="string">'0x0000000000000'</span>, <span class="string">'latest'</span>, callback));</span><br><span class="line">batch.add(web3.eth.contract(abi).at(address).balance.requests(address,callback2));</span><br><span class="line">batch.excute();</span><br></pre></td></tr></table></figure>
<h2 id="大数处理-big-numbers"><a href="#大数处理-big-numbers" class="headerlink" title="大数处理(big numbers)"></a>大数处理(big numbers)</h2><ul>
<li>JavaScript中默认的数字精度较小，所以web3.js会自动添加一个依赖库BigNumber，专门用于大数处理</li>
<li>对于数值，我们应该习惯将它转化为BigNumber对象来处理</li>
<li>BigNumber.toString(10)对小数只保留20位浮点精度，所以推荐的做法是，我们内部总是用wei来表示余额（大整数），只有在需要显示给用户看的时候才转化为Ether或其他单位</li>
</ul>
<p>定义方式如下：</p>
<p><img src alt="define_bignumber"></p>
<p>我们看到显示的s:1表示这个数是正数，若为负数s=-1，c则为 字符串拼接结果，e为科学计数法e跟的位数，c是所有有效数字，每14位对BigNumber切割一次形成的数组，toString()可以看到这个数字，也可以在括号内填如希望转化的进制。</p>
<h1 id="常用API-——-基本信息查询"><a href="#常用API-——-基本信息查询" class="headerlink" title="常用API —— 基本信息查询"></a>常用API —— 基本信息查询</h1><p>下面先列举常用命令，后面再一一敲代码~</p>
<h2 id="基本信息查询"><a href="#基本信息查询" class="headerlink" title="基本信息查询"></a>基本信息查询</h2><p><strong>查看web3版本</strong></p>
<ul>
<li><p>v0.2.x.x</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.version.api</span><br></pre></td></tr></table></figure>
</li>
<li><p>v1.0.0</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.version</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>查看web3连接到的节点版本(clientVersion)</strong></p>
<ul>
<li><p>v0.2.x.x</p>
<ul>
<li><p>同步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.version.node</span><br></pre></td></tr></table></figure>
</li>
<li><p>异步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.version.getNode((error,resuIt)&#x3D;&gt;console.log(result))</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>v1.0.0</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getNodeInfo().then(console.log)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>获取network</strong></p>
<ul>
<li><p>v0.2.x.x</p>
<ul>
<li><p>同步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.version.network</span><br></pre></td></tr></table></figure>
</li>
<li><p>异步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.version.getNetwork((err,res)&#x3D;&gt;console.log(res))</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>v1.0.0</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.net.getId().then(console.log)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>获取点以太坊版本</strong></p>
<ul>
<li><p>v0.2.x.x</p>
<ul>
<li><p>同步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.version.ethereum</span><br></pre></td></tr></table></figure>
</li>
<li><p>异步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.version.getEthereum((err,res)&#x3D;&gt;console.log(res))</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>v1.0.0</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getProtocolVersion().then(console.log)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>具体操作见下图：</p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/version.png" alt></p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/version2.png" alt></p>
<h2 id="网络状态查询"><a href="#网络状态查询" class="headerlink" title="网络状态查询"></a>网络状态查询</h2><p><strong>是否有节点连接/监听，返回true</strong></p>
<ul>
<li><p>v0.2.x.x</p>
<ul>
<li><p>同步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.isConnect() 或者 web3.net.listening</span><br></pre></td></tr></table></figure>
</li>
<li><p>异步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.net.getListening((err,res)&#x3D;&gt;console.log(res))</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>v1.0.0</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.net.isListening().then(console.log)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>查看当前连接的peer节点</strong></p>
<ul>
<li><p>v0.2.x.x</p>
<ul>
<li><p>同步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.net.peerCount</span><br></pre></td></tr></table></figure>
</li>
<li><p>异步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.net.getPeerCount((err,res)&#x3D;&gt;console.log(res))</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>v1.0.0</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.net.getPeerCount().then(console.log)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>Provider</strong></p>
<ul>
<li><p>查看当前设置的web3 provider</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.currentPrrovider</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看浏览器环境设置的web3 provider</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.givenProvider</span><br></pre></td></tr></table></figure>
</li>
<li><p>设置provider</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.setProvider(new web3.providers.HttpProvider(&#39;http:&#x2F;&#x2F;localhost:8545&#39;))</span><br></pre></td></tr></table></figure>
<p>需要注意的是，0.20.1版本与1.0.0版本的操作有些出入。</p>
</li>
</ul>
<h2 id="web3通用工具方法"><a href="#web3通用工具方法" class="headerlink" title="web3通用工具方法"></a>web3通用工具方法</h2><ul>
<li>以太单位转换<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3..fromWei</span><br><span class="line">web3..toWei</span><br></pre></td></tr></table></figure></li>
<li>数据类型转换<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.toString</span><br><span class="line">web3.toDecimal</span><br><span class="line">web3.toBigNumber</span><br></pre></td></tr></table></figure></li>
<li>字符编码转换<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.toHex</span><br><span class="line">web3.toAscii</span><br><span class="line">web3.toUtf8</span><br><span class="line">web3.fromUtf8</span><br></pre></td></tr></table></figure></li>
<li>地址相关<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.isAddress</span><br><span class="line">web3.toChecksumAddress</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>注意</strong>：</p>
<ol>
<li>地址是40个16进制字符，比如：0x4DFdd4c39B99C88d795E7a200f05A6A8f5D80A5b</li>
<li>在1.0.0版本中，上述操作大多被放入web3.utils中</li>
</ol>
<h2 id="web3-eth-——-账户相关"><a href="#web3-eth-——-账户相关" class="headerlink" title="web3.eth —— 账户相关"></a>web3.eth —— 账户相关</h2><p><strong>coinbase查询</strong></p>
<ul>
<li><p>v0.2.x.x</p>
<ul>
<li>同步<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.coinbase</span><br></pre></td></tr></table></figure></li>
<li>异步<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getCoinbase((err,res)&#x3D;&gt;console.log(res))</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>v1.0.0</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getCoinbase().then(console.log)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>账户查询</strong></p>
<ul>
<li><p>v0.2.x.x</p>
<ul>
<li>同步<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.accounts</span><br></pre></td></tr></table></figure></li>
<li>异步<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getAccounts((err,res)&#x3D;&gt;console.log(res))</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>v1.0.0</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getAccounts().then(console.log)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="区块相关"><a href="#区块相关" class="headerlink" title="区块相关"></a>区块相关</h2><p><strong>区块高度查询</strong></p>
<ul>
<li><p>同步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.blockNumber</span><br></pre></td></tr></table></figure>
</li>
<li><p>异步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getBlockNumber(callback)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>gasPrice 查询</strong></p>
<ul>
<li><p>同步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.gasPrice</span><br></pre></td></tr></table></figure>
</li>
<li><p>异步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getGasPrice(callback)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="交易相关"><a href="#交易相关" class="headerlink" title="交易相关"></a>交易相关</h2><ul>
<li><p>余额查询</p>
<ul>
<li>同步<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getBalance(addressHexString [, defaultBlock])</span><br></pre></td></tr></table></figure></li>
<li>异步<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getBalance(addressHexString [, defaultBlock] [,callback])</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>交易查询</p>
<ul>
<li>同步<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getTransaction(transactionHash)</span><br></pre></td></tr></table></figure></li>
<li>异步<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getTransaction(transactionHash [,callback])</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>交易收据查询</p>
<ul>
<li><p>同步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getTransactionReceipt(hashString)</span><br></pre></td></tr></table></figure>
</li>
<li><p>异步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getTransactionReceipt(hashString [, callback])</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>估计gas消耗量</p>
<ul>
<li><p>同步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.estimateGas(callObject)</span><br></pre></td></tr></table></figure>
</li>
<li><p>异步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.estimateGas(callObject [, callback])</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>发送交易</p>
<ul>
<li>from： 发送地址</li>
<li>to：接收地址</li>
<li>value：交易金额，以wei为单位，可选</li>
<li>gas：交易消耗gas上限，可选</li>
<li>gasPrice：交易gas单价，可选</li>
<li>data：交易携带的字串数据，可选</li>
<li>nonce：整数nonce值，可选<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.sendTransaction(transactionObject [,callback])</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<p>发送交易过程如下：</p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/trans1.png" alt></p>
<h2 id="消息调用"><a href="#消息调用" class="headerlink" title="消息调用"></a>消息调用</h2><p>消息调用与交易的区别是，当我们想给合约发起调用（调用函数，这时我们使用的是call方法），给别人发币时使用sendTransaction()，而调用合约时其实也可以使用sendTransaction()，但一般我们将不需要提交交易的消息调用上，比如我们不做状态改变（纯计算、查询等）。若引发了状态改变则一定要用sendTransaction()。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>调用对象：与交易对象相同，只是from也是可选的</li>
<li>默认区块：默认”latest“，可以传入指定的区块高度</li>
<li>回调函数：如果没有则为同步调用</li>
</ul>
<h2 id="日志过滤（事件监听）"><a href="#日志过滤（事件监听）" class="headerlink" title="日志过滤（事件监听）"></a>日志过滤（事件监听）</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.filter(filterOptions [.callback])</span><br></pre></td></tr></table></figure>
<ul>
<li><p>filterString可以是”latest”or”pending”</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var filter &#x3D; web3.eth.filter(filterString);</span><br></pre></td></tr></table></figure>
</li>
<li><p>或者可以填入一个日志过滤options</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var filter &#x3D; web3.eth.filter(options);</span><br></pre></td></tr></table></figure>
</li>
<li><p>监听日志变化</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">filter.watch(options, function(error, result)&#123;</span><br><span class="line">	if (!error) console.log(result);</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
</li>
<li><p>停止监听</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">filter.stopWatching()</span><br></pre></td></tr></table></figure>
</li>
<li><p>还可以用传入回调函数的方法，立刻开始监听日志</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.filter(options, function(error, result)&#123;</span><br><span class="line">	if (!error) console.log(result);</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><img src="/posts/Blockchain/filter.png" alt></p>
<h2 id="合约相关"><a href="#合约相关" class="headerlink" title="合约相关"></a>合约相关</h2><h3 id="创建合约"><a href="#创建合约" class="headerlink" title="创建合约"></a>创建合约</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.contract</span><br></pre></td></tr></table></figure>
<p>创建合约有两种方式，第一种方式为传入abi：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var MyContract &#x3D; web3.eth.contract(abiArray);</span><br></pre></td></tr></table></figure>
<p>这时候我们拿到了一个js中的合约实例，但还未和区块链关联起来，我们还需要通过地址初始化合约实例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var contractinstance &#x3D; MyContract.at(address);</span><br></pre></td></tr></table></figure>
<p>或者是部署一个新合约：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var contractinstance &#x3D; MyContract.new([contructorParam1][contructorParam2],&#123;data:&quot;0x12345...&quot;,from:myAccount, gas&#125;)</span><br></pre></td></tr></table></figure>
<p>constructorParam1主要是传入需要赋的初值，data部分其实就是字节码。因此综上所述，在使用web3部署合约时需同时使用abi和字节码。接下来我们开始部署自己的合约：</p>
<p>合约如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pragma solidity &gt;0.6.0;</span><br><span class="line"></span><br><span class="line">contract Coin&#123;</span><br><span class="line">    address public minter;</span><br><span class="line">    mapping(address&#x3D;&gt;uint) public balances;</span><br><span class="line">    event Sent(address from, address to, uint amount);</span><br><span class="line">    constructor()public&#123;</span><br><span class="line">        minter &#x3D; msg.sender;</span><br><span class="line">    &#125;</span><br><span class="line">    function mint(address receiver, uint amount)public&#123;</span><br><span class="line">        require(msg.sender &#x3D;&#x3D; minter);</span><br><span class="line">        balances[receiver] +&#x3D; amount;</span><br><span class="line">    &#125;</span><br><span class="line">    function send(address receiver, uint amount)public&#123;</span><br><span class="line">        require(balances[msg.sender] &gt;&#x3D; amount);</span><br><span class="line">        balances[msg.sender] -&#x3D; amount;</span><br><span class="line">        balances[receiver] +&#x3D; amount;</span><br><span class="line">        </span><br><span class="line">        emit Sent(msg.sender, receiver, amount);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/contract1.png" alt></p>
<p>我们在上面的步骤中，首先将前面已经得到的contract编译过后的abi传入：var coinContract = web3.eth.contract(abi)，然后获得字节码(byteCode)，连同其他参数一起new合约，于是就部署好了一个合约，这里需要注意的是，在传入字节码时需要在最前面加入’0x’，这是由于字节码本身就是16进制的，但编译出来的结果头部并没有带0x，需要手动去加。</p>
<p>我们看一看部署的合约长啥样：</p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/contract2.png" alt></p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/contract3.png" alt></p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/contract4.png" alt></p>
<p>以上是打印结果，然后我们可以通过coinContractInstance.address获得合约地址，同时也可以根据相应接口获得其他信息。</p>
<h3 id="调用合约"><a href="#调用合约" class="headerlink" title="调用合约"></a>调用合约</h3><p>可以通过已创建的合约实例，直接调用合约函数</p>
<ul>
<li><p>直接调用，自动按函数类型决定用sendTransaction还是call</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">myContractInstance.myMethod(param1 [,param2,...][,transactionObject][,defaultBlock][,callback]);</span><br></pre></td></tr></table></figure>
</li>
<li><p>显式以消息调用形式call该函数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">myContractInstance.myMethod.call(param1 [,param2,...][,transactionObject][,defaultBlock][,callback]);</span><br></pre></td></tr></table></figure>
</li>
<li><p>显式以发送交易形式调用该函数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">myContractInstance.myMethod.sendTransaction(param1 [,param2,...][,transactionObject][,defaultBlock][,callback]);</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>最后的callback回调函数可选，若不选则为同步调用，但推荐使用异步调用方式。</p>
<p>我们还是来直接尝试调用一下合约：（由于testrpc不太方便，我在这里改用了ganache）</p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/coin1.png" alt></p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/coin2.png" alt></p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/coin3.png" alt></p>
<p>需要注意的是，这里我们需要在mint的时候写上：{from:web3.eth.accounts[0]}，因为需要让合约知道调用合约的人是谁才能发币。</p>
<p>我们可以看到在ganache-cli中立刻出现了我们刚刚调用的合约情况：</p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/coin4.png" alt></p>
<h3 id="监听合约事件"><a href="#监听合约事件" class="headerlink" title="监听合约事件"></a>监听合约事件</h3><ul>
<li><p>合约的event类似于filter，可以设置过略选项来监听</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var event &#x3D; myContractInstance.MyEvent(&#123;valueA:23&#125; [,additionalFilterObject])</span><br></pre></td></tr></table></figure>
</li>
<li><p>监听事件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">event.watch(function(err,, res)&#x3D;&gt;console.log(res))</span><br></pre></td></tr></table></figure>
</li>
<li><p>可以使用传入回调函数的方法，立刻开始监听事件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var event &#x3D; myContractInstance.MyEvent(&#123;valueA:23&#125;</span><br><span class="line">			[,additionalFilterObject], function(err, res)&#123;</span><br><span class="line">          			if(!err) console.log(res);</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>可以通过以下方式触发监听：</p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/sent.png" alt></p>
]]></content>
      <categories>
        <category>Blockchain</category>
      </categories>
  </entry>
  <entry>
    <title>区块链入门（二） —— web3js</title>
    <url>/posts/67d22044.html</url>
    <content><![CDATA[<h1 id="web3-js基础"><a href="#web3-js基础" class="headerlink" title="web3.js基础"></a>web3.js基础</h1><h2 id="web3-js是什么"><a href="#web3-js是什么" class="headerlink" title="web3.js是什么"></a>web3.js是什么</h2><ul>
<li>Web3 JavaScript app API</li>
<li>web3..js 是一个JavaScript API库。要使DApper在以太坊上运行，我们可以使用web3.js库提供的web3对象</li>
<li>web3.js通过RPC调用与本地节点通信，它可以用于任何暴露了RPC层的以太坊节点</li>
<li>web3包含了eth对象 - web3.eth（专门与以太坊区块链交互）和 shh对象 - web3.shh（用于与 Whisper交互）[Whisper是以太坊生态系统的一部分，主要用来做消息传递]</li>
</ul>
<p>如果我们想要在以太坊上开发合约，目前来说最方便的方法就是调用Web3.js库，它会给我们一个Web3对象。我们首先进入geth控制台，直接键入web3，下面对这些弹出的内容进行一个总览。</p>
<p>我们先看到db，db是操作区块链底层数据库的，整个以太坊的底层数据库就是LevelDB，其接口如下：</p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/db.png" alt></p>
<p>然后看到eth，一个我们已经很熟悉的模块：</p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/eth.png" alt></p>
<p>里面含有getBalance,gasPrice等最常用的操作。</p>
<p>再然后是personal，里面包含了我们创建账户的信息：</p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/personal.png" alt></p>
<p>还有shh等等，这里就不一一列举了：</p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/shh.png" alt></p>
<h2 id="web3-模块加载"><a href="#web3-模块加载" class="headerlink" title="web3 模块加载"></a>web3 模块加载</h2><ul>
<li>首先需要将 web3 模块安装在项目中，安装方式为（后面可以加版本也可以不加）  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install web3@0.20.1</span><br></pre></td></tr></table></figure></li>
<li>然后创建一个web3实例，设置一个”provider”</li>
<li>为了保证我们的MetaMask设置好的provider不被覆盖掉，在引入web3之前我们一般要做当前环境检查(以v0.20.1为例)：  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if(typeof web3 !&#x3D;&#x3D; &#39;undifined&#39;)&#123;</span><br><span class="line">	web3 &#x3D; new Web3(web3.currentProvider);</span><br><span class="line">&#125;else&#123;</span><br><span class="line">	web3 &#x3D; new Web3(new Web3.providers.HttpProvider(&#39;http:&#x2F;&#x2F;localhost:8545&#39;));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="异步回调（callback）"><a href="#异步回调（callback）" class="headerlink" title="异步回调（callback）"></a>异步回调（callback）</h2><ul>
<li>web3js API 设计的最初目的，主要是为了和本地RPC节点共同使用，所以默认情况下发送的是同步HTTP请求</li>
<li>如果要发送异步请求，可以在函数的最后一个参数位置上，传入一个回调函数，回调函数是可选的(optional)</li>
<li>我们一般采用的风格是所谓的“错误优先”，例如：  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getback(48, function(error, result))&#123;</span><br><span class="line">	if(!error)</span><br><span class="line">    	console.log(JSON.stringify(result));</span><br><span class="line">    else</span><br><span class="line">    	console.error(error);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>我们直接在geth尝试这一过程，并与同步过程对比：</p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/ybdy.png" alt></p>
<p>我们看到输出的内容没有任何区别，不过由刚才的同步调用方式改成了异步调用，那有了更简便的同步调用，我们为何还需要异步调用呢？</p>
<p>同步调用会将当前执行的进程完全阻塞在这里，只有当前面的步骤拿到代码返回之后后面的代码才会执行，所以同步的顺序是指定的，让谁先执行谁就先执行，但劣势也在此，可能会一直被卡在这里，在开发DApp等实际应用的时候，往往都需要用异步，互不干扰。</p>
<h2 id="回调Promise事件"><a href="#回调Promise事件" class="headerlink" title="回调Promise事件"></a>回调Promise事件</h2><p>目前基本上所有的东西大家都默认了状态是异步调用，那我们是否就无法保证顺序了呢？实际上不是的。</p>
<ul>
<li>为了帮助web3集成到不同标准的所有类型项目中，1.0.0版本提供了多种方式来处理异步函数。大多数的web3对象允许将一个回调函数作为最后一个函数参数传入，同时返回一个promise用于链式函数调用。</li>
<li>以太坊作为一个区块链系统，一次请求具有不同的结束阶段。为了满足这样的请求，1.0.0版本将这类函数调用的返回之包成一个“承诺事件”(promiEvent)，这是一个promise和EventEmitter的结合体</li>
<li>PromiEvent的用法就像promise一样，另外还加入了.on,.once和.off方法  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.sendTransaction(&#123;from:&#39;0x123...&#39;, data:&#39;0x432...&#39;&#125;)</span><br><span class="line">.once(&#39;transactionHash&#39;, function(hash)&#123;...&#125;)</span><br><span class="line">.once(&#39;receipt&#39;, function(receipt)&#123;...&#125;)</span><br><span class="line">.on(&#39;confirmation&#39;, function(confNumber, receipt)&#123;...&#125;)</span><br><span class="line">.on(&#39;error&#39;, function&#123;...&#125;)</span><br><span class="line">.then(function(receipt)&#123;&#125;);</span><br></pre></td></tr></table></figure>
回调完成的标志是收到receipt，也就是交易打包进块。</li>
</ul>
<h2 id="应用二进制接口（ABI）"><a href="#应用二进制接口（ABI）" class="headerlink" title="应用二进制接口（ABI）"></a>应用二进制接口（ABI）</h2><ul>
<li>web3.js通过以太坊智能合约的json接口（Application Binary Interface， ABI）创建一个JavaScript对象，用来在js代码中描述</li>
<li>函数（functions）<ul>
<li>type:函数类型，默认“function”，也可能是”constructor”</li>
<li>constant, payable, stateMutability: 函数的状态可变性</li>
<li>inputs, outputs: 函数输入、输出参数描述列表</li>
</ul>
</li>
<li>事件（events）<ul>
<li>type: 类型，总是”event”</li>
<li>inputs: 输入对象列表，包括name、type、indexed</li>
</ul>
</li>
</ul>
<p>我们首先创建一个sol文件，并进行编译，Coin.sol文件如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pragma solidity &gt;<span class="number">0.4</span><span class="number">.22</span>;</span><br><span class="line"></span><br><span class="line">contract Coin&#123;</span><br><span class="line">    address public minter;</span><br><span class="line">    mapping(address=&gt;uint) public balances;</span><br><span class="line">    event Sent(address <span class="keyword">from</span>, address to, uint amount);</span><br><span class="line">    constructor()public&#123;</span><br><span class="line">        minter = msg.sender;</span><br><span class="line">    &#125;</span><br><span class="line">    function mint(address receiver, uint amount)public&#123;</span><br><span class="line">        require(msg.sender == minter);</span><br><span class="line">        balances[receiver] += amount;</span><br><span class="line">    &#125;</span><br><span class="line">    function send(address receiver, uint amount)public&#123;</span><br><span class="line">        require(balances[msg.sender] &gt;= amount);</span><br><span class="line">        balances[msg.sender] -= amount;</span><br><span class="line">        balances[receiver] += amount;</span><br><span class="line">        emit Sent(msg.sender, receiver, amount);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/../../%E7%AC%94%E8%AE%B0/Pic/web3js%E4%BA%A4%E4%BA%92/abi.png" alt></p>
<p>将上面的JSON文件稍微格式化一下：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">[&#123;</span><br><span class="line">	<span class="attr">"inputs"</span>: [],</span><br><span class="line">	<span class="attr">"stateMutability"</span>: <span class="string">"nonpayable"</span>,</span><br><span class="line">	<span class="attr">"type"</span>: <span class="string">"constructor"</span></span><br><span class="line">&#125;, &#123;</span><br><span class="line">	<span class="attr">"anonymous"</span>: <span class="literal">false</span>,</span><br><span class="line">	<span class="attr">"inputs"</span>: [&#123;</span><br><span class="line">		<span class="attr">"indexed"</span>: <span class="literal">false</span>,</span><br><span class="line">		<span class="attr">"internalType"</span>: <span class="string">"address"</span>,</span><br><span class="line">		<span class="attr">"name"</span>: <span class="string">"from"</span>,</span><br><span class="line">		<span class="attr">"type"</span>: <span class="string">"address"</span></span><br><span class="line">	&#125;, &#123;</span><br><span class="line">		<span class="attr">"indexed"</span>: <span class="literal">false</span>,</span><br><span class="line">		<span class="attr">"internalType"</span>: <span class="string">"address"</span>,</span><br><span class="line">		<span class="attr">"name"</span>: <span class="string">"to"</span>,</span><br><span class="line">		<span class="attr">"type"</span>: <span class="string">"address"</span></span><br><span class="line">	&#125;, &#123;</span><br><span class="line">		<span class="attr">"indexed"</span>: <span class="literal">false</span>,</span><br><span class="line">		<span class="attr">"internalType"</span>: <span class="string">"uint256"</span>,</span><br><span class="line">		<span class="attr">"name"</span>: <span class="string">"amount"</span>,</span><br><span class="line">		<span class="attr">"type"</span>: <span class="string">"uint256"</span></span><br><span class="line">	&#125;],</span><br><span class="line">	<span class="attr">"name"</span>: <span class="string">"Sent"</span>,</span><br><span class="line">	<span class="attr">"type"</span>: <span class="string">"event"</span></span><br><span class="line">&#125;, &#123;</span><br><span class="line">	<span class="attr">"inputs"</span>: [&#123;</span><br><span class="line">		<span class="attr">"internalType"</span>: <span class="string">"address"</span>,</span><br><span class="line">		<span class="attr">"name"</span>: <span class="string">""</span>,</span><br><span class="line">		<span class="attr">"type"</span>: <span class="string">"address"</span></span><br><span class="line">	&#125;],</span><br><span class="line">	<span class="attr">"name"</span>: <span class="string">"balances"</span>,</span><br><span class="line">	<span class="attr">"outputs"</span>: [&#123;</span><br><span class="line">		<span class="attr">"internalType"</span>: <span class="string">"uint256"</span>,</span><br><span class="line">		<span class="attr">"name"</span>: <span class="string">""</span>,</span><br><span class="line">		<span class="attr">"type"</span>: <span class="string">"uint256"</span></span><br><span class="line">	&#125;],</span><br><span class="line">	<span class="attr">"stateMutability"</span>: <span class="string">"view"</span>,</span><br><span class="line">	<span class="attr">"type"</span>: <span class="string">"function"</span></span><br><span class="line">&#125;, &#123;</span><br><span class="line">	<span class="attr">"inputs"</span>: [&#123;</span><br><span class="line">		<span class="attr">"internalType"</span>: <span class="string">"address"</span>,</span><br><span class="line">		<span class="attr">"name"</span>: <span class="string">"receiver"</span>,</span><br><span class="line">		<span class="attr">"type"</span>: <span class="string">"address"</span></span><br><span class="line">	&#125;, &#123;</span><br><span class="line">		<span class="attr">"internalType"</span>: <span class="string">"uint256"</span>,</span><br><span class="line">		<span class="attr">"name"</span>: <span class="string">"amount"</span>,</span><br><span class="line">		<span class="attr">"type"</span>: <span class="string">"uint256"</span></span><br><span class="line">	&#125;],</span><br><span class="line">	<span class="attr">"name"</span>: <span class="string">"mint"</span>,</span><br><span class="line">	<span class="attr">"outputs"</span>: [],</span><br><span class="line">	<span class="attr">"stateMutability"</span>: <span class="string">"nonpayable"</span>,</span><br><span class="line">	<span class="attr">"type"</span>: <span class="string">"function"</span></span><br><span class="line">&#125;, &#123;</span><br><span class="line">	<span class="attr">"inputs"</span>: [],</span><br><span class="line">	<span class="attr">"name"</span>: <span class="string">"minter"</span>,</span><br><span class="line">	<span class="attr">"outputs"</span>: [&#123;</span><br><span class="line">		<span class="attr">"internalType"</span>: <span class="string">"address"</span>,</span><br><span class="line">		<span class="attr">"name"</span>: <span class="string">""</span>,</span><br><span class="line">		<span class="attr">"type"</span>: <span class="string">"address"</span></span><br><span class="line">	&#125;],</span><br><span class="line">	<span class="attr">"stateMutability"</span>: <span class="string">"view"</span>,</span><br><span class="line">	<span class="attr">"type"</span>: <span class="string">"function"</span></span><br><span class="line">&#125;, &#123;</span><br><span class="line">	<span class="attr">"inputs"</span>: [&#123;</span><br><span class="line">		<span class="attr">"internalType"</span>: <span class="string">"address"</span>,</span><br><span class="line">		<span class="attr">"name"</span>: <span class="string">"receiver"</span>,</span><br><span class="line">		<span class="attr">"type"</span>: <span class="string">"address"</span></span><br><span class="line">	&#125;, &#123;</span><br><span class="line">		<span class="attr">"internalType"</span>: <span class="string">"uint256"</span>,</span><br><span class="line">		<span class="attr">"name"</span>: <span class="string">"amount"</span>,</span><br><span class="line">		<span class="attr">"type"</span>: <span class="string">"uint256"</span></span><br><span class="line">	&#125;],</span><br><span class="line">	<span class="attr">"name"</span>: <span class="string">"send"</span>,</span><br><span class="line">	<span class="attr">"outputs"</span>: [],</span><br><span class="line">	<span class="attr">"stateMutability"</span>: <span class="string">"nonpayable"</span>,</span><br><span class="line">	<span class="attr">"type"</span>: <span class="string">"function"</span></span><br><span class="line">&#125;]</span><br></pre></td></tr></table></figure>
<p>我们集中看一下下面这小段：<br><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="attr">"anonymous"</span>: <span class="literal">false</span>,</span><br><span class="line">	<span class="attr">"inputs"</span>: [&#123;</span><br><span class="line">		<span class="attr">"indexed"</span>: <span class="literal">false</span>,</span><br><span class="line">		<span class="attr">"internalType"</span>: <span class="string">"address"</span>,</span><br><span class="line">		<span class="attr">"name"</span>: <span class="string">"from"</span>,</span><br><span class="line">		<span class="attr">"type"</span>: <span class="string">"address"</span></span><br><span class="line">	&#125;, &#123;</span><br><span class="line">		<span class="attr">"indexed"</span>: <span class="literal">false</span>,</span><br><span class="line">		<span class="attr">"internalType"</span>: <span class="string">"address"</span>,</span><br><span class="line">		<span class="attr">"name"</span>: <span class="string">"to"</span>,</span><br><span class="line">		<span class="attr">"type"</span>: <span class="string">"address"</span></span><br><span class="line">	&#125;, &#123;</span><br><span class="line">		<span class="attr">"indexed"</span>: <span class="literal">false</span>,</span><br><span class="line">		<span class="attr">"internalType"</span>: <span class="string">"uint256"</span>,</span><br><span class="line">		<span class="attr">"name"</span>: <span class="string">"amount"</span>,</span><br><span class="line">		<span class="attr">"type"</span>: <span class="string">"uint256"</span></span><br><span class="line">	&#125;],</span><br><span class="line">	<span class="attr">"name"</span>: <span class="string">"Sent"</span>,</span><br><span class="line">	<span class="attr">"type"</span>: <span class="string">"event"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>首先是一个<strong>annoymous</strong>，这是一个匿名参数，如果你填了false，我们的事件在日志中的第一条topic就会为空（不写入），主题是对整个事件做的哈希，也就相当于这个事件没有签名了，事实上他出发的其他事件的log仍会计入，只不过没有整个事件签名了。然后是<strong>index</strong>，定义参数时如果设置index=True，则这个参数会被设置成可索引参数，就会被记在topic下。<br>我们可以看到这段JSON对应的是下面这一行代码，于是其他部分我们也很容易一一对上了：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">event Sent(address <span class="keyword">from</span>, address to, uint amount);</span><br></pre></td></tr></table></figure></p>
<p>我们看到合约编译可生成两种文件，一种是字节码，这是要部署到以太坊上的，另一种是根据源码生成ABI，这一套二进制接口是给web3使用的。下面我们安装web3模块：</p>
<ul>
<li>安装nodejs</li>
<li>npm install web3@^0.20.0</li>
<li>npm i npm to update</li>
<li>npm cache verify</li>
<li>npm install -g ethereumjs-testrpc</li>
<li>在终端启动testrpc</li>
<li>切换新的终端，创建文件connect.js，文件内容为  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var Web3 &#x3D; require(&#39;web3&#39;)</span><br><span class="line">var web3 &#x3D; new Web3(new Web3.providers.HttpProvider(&#39;http:&#x2F;&#x2F;localhost:8545&#39;))</span><br><span class="line">console.log(web3.eth.accounts)</span><br><span class="line">console.log(&#39;OK&#39;)</span><br><span class="line">var version &#x3D; web3.version.node;</span><br><span class="line">console.log(version);</span><br></pre></td></tr></table></figure></li>
<li>node connect.js后显示：</li>
</ul>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/web3_1.png" alt></p>
<p>事实上我们也可以一行行在node命令行中输入，这样可以更清晰地观察到结果：</p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/web3_2.png" alt></p>
<p>代码同上，读者自行键入即可。我们还可以获得web3的其他信息：</p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/web3_3.png" alt></p>
<h2 id="批处理请求-batch-requests"><a href="#批处理请求-batch-requests" class="headerlink" title="批处理请求(batch requests)"></a>批处理请求(batch requests)</h2><ul>
<li>批处理请求允许我们将请求排序，然后一起处理它们</li>
<li>注意：批处理请求不会更快，在某些情况下，一次性地发出许多请求会更快，因为请求是异步处理的。（我们想要加速通常会手动进行异步处理）</li>
<li>批处理请求主要用于确保请求的顺序，并串行处理</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">var batch = web3.createBatch();</span><br><span class="line">batch.add(web3.eth.getBalance.request(<span class="string">'0x0000000000000'</span>, <span class="string">'latest'</span>, callback));</span><br><span class="line">batch.add(web3.eth.contract(abi).at(address).balance.requests(address,callback2));</span><br><span class="line">batch.excute();</span><br></pre></td></tr></table></figure>
<h2 id="大数处理-big-numbers"><a href="#大数处理-big-numbers" class="headerlink" title="大数处理(big numbers)"></a>大数处理(big numbers)</h2><ul>
<li>JavaScript中默认的数字精度较小，所以web3.js会自动添加一个依赖库BigNumber，专门用于大数处理</li>
<li>对于数值，我们应该习惯将它转化为BigNumber对象来处理</li>
<li>BigNumber.toString(10)对小数只保留20位浮点精度，所以推荐的做法是，我们内部总是用wei来表示余额（大整数），只有在需要显示给用户看的时候才转化为Ether或其他单位</li>
</ul>
<p>定义方式如下：</p>
<p><img src alt="define_bignumber"></p>
<p>我们看到显示的s:1表示这个数是正数，若为负数s=-1，c则为 字符串拼接结果，e为科学计数法e跟的位数，c是所有有效数字，每14位对BigNumber切割一次形成的数组，toString()可以看到这个数字，也可以在括号内填如希望转化的进制。</p>
<h1 id="常用API-——-基本信息查询"><a href="#常用API-——-基本信息查询" class="headerlink" title="常用API —— 基本信息查询"></a>常用API —— 基本信息查询</h1><p>下面先列举常用命令，后面再一一敲代码~</p>
<h2 id="基本信息查询"><a href="#基本信息查询" class="headerlink" title="基本信息查询"></a>基本信息查询</h2><p><strong>查看web3版本</strong></p>
<ul>
<li><p>v0.2.x.x</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.version.api</span><br></pre></td></tr></table></figure>
</li>
<li><p>v1.0.0</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.version</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>查看web3连接到的节点版本(clientVersion)</strong></p>
<ul>
<li><p>v0.2.x.x</p>
<ul>
<li><p>同步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.version.node</span><br></pre></td></tr></table></figure>
</li>
<li><p>异步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.version.getNode((error,resuIt)&#x3D;&gt;console.log(result))</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>v1.0.0</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getNodeInfo().then(console.log)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>获取network</strong></p>
<ul>
<li><p>v0.2.x.x</p>
<ul>
<li><p>同步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.version.network</span><br></pre></td></tr></table></figure>
</li>
<li><p>异步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.version.getNetwork((err,res)&#x3D;&gt;console.log(res))</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>v1.0.0</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.net.getId().then(console.log)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>获取点以太坊版本</strong></p>
<ul>
<li><p>v0.2.x.x</p>
<ul>
<li><p>同步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.version.ethereum</span><br></pre></td></tr></table></figure>
</li>
<li><p>异步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.version.getEthereum((err,res)&#x3D;&gt;console.log(res))</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>v1.0.0</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getProtocolVersion().then(console.log)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>具体操作见下图：</p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/version.png" alt></p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/version2.png" alt></p>
<h2 id="网络状态查询"><a href="#网络状态查询" class="headerlink" title="网络状态查询"></a>网络状态查询</h2><p><strong>是否有节点连接/监听，返回true</strong></p>
<ul>
<li><p>v0.2.x.x</p>
<ul>
<li><p>同步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.isConnect() 或者 web3.net.listening</span><br></pre></td></tr></table></figure>
</li>
<li><p>异步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.net.getListening((err,res)&#x3D;&gt;console.log(res))</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>v1.0.0</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.net.isListening().then(console.log)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>查看当前连接的peer节点</strong></p>
<ul>
<li><p>v0.2.x.x</p>
<ul>
<li><p>同步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.net.peerCount</span><br></pre></td></tr></table></figure>
</li>
<li><p>异步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.net.getPeerCount((err,res)&#x3D;&gt;console.log(res))</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>v1.0.0</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.net.getPeerCount().then(console.log)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>Provider</strong></p>
<ul>
<li><p>查看当前设置的web3 provider</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.currentPrrovider</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看浏览器环境设置的web3 provider</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.givenProvider</span><br></pre></td></tr></table></figure>
</li>
<li><p>设置provider</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.setProvider(new web3.providers.HttpProvider(&#39;http:&#x2F;&#x2F;localhost:8545&#39;))</span><br></pre></td></tr></table></figure>
<p>需要注意的是，0.20.1版本与1.0.0版本的操作有些出入。</p>
</li>
</ul>
<h2 id="web3通用工具方法"><a href="#web3通用工具方法" class="headerlink" title="web3通用工具方法"></a>web3通用工具方法</h2><ul>
<li>以太单位转换<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3..fromWei</span><br><span class="line">web3..toWei</span><br></pre></td></tr></table></figure></li>
<li>数据类型转换<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.toString</span><br><span class="line">web3.toDecimal</span><br><span class="line">web3.toBigNumber</span><br></pre></td></tr></table></figure></li>
<li>字符编码转换<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.toHex</span><br><span class="line">web3.toAscii</span><br><span class="line">web3.toUtf8</span><br><span class="line">web3.fromUtf8</span><br></pre></td></tr></table></figure></li>
<li>地址相关<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.isAddress</span><br><span class="line">web3.toChecksumAddress</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>注意</strong>：</p>
<ol>
<li>地址是40个16进制字符，比如：0x4DFdd4c39B99C88d795E7a200f05A6A8f5D80A5b</li>
<li>在1.0.0版本中，上述操作大多被放入web3.utils中</li>
</ol>
<h2 id="web3-eth-——-账户相关"><a href="#web3-eth-——-账户相关" class="headerlink" title="web3.eth —— 账户相关"></a>web3.eth —— 账户相关</h2><p><strong>coinbase查询</strong></p>
<ul>
<li><p>v0.2.x.x</p>
<ul>
<li>同步<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.coinbase</span><br></pre></td></tr></table></figure></li>
<li>异步<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getCoinbase((err,res)&#x3D;&gt;console.log(res))</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>v1.0.0</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getCoinbase().then(console.log)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>账户查询</strong></p>
<ul>
<li><p>v0.2.x.x</p>
<ul>
<li>同步<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.accounts</span><br></pre></td></tr></table></figure></li>
<li>异步<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getAccounts((err,res)&#x3D;&gt;console.log(res))</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>v1.0.0</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getAccounts().then(console.log)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="区块相关"><a href="#区块相关" class="headerlink" title="区块相关"></a>区块相关</h2><p><strong>区块高度查询</strong></p>
<ul>
<li><p>同步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.blockNumber</span><br></pre></td></tr></table></figure>
</li>
<li><p>异步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getBlockNumber(callback)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>gasPrice 查询</strong></p>
<ul>
<li><p>同步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.gasPrice</span><br></pre></td></tr></table></figure>
</li>
<li><p>异步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getGasPrice(callback)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="交易相关"><a href="#交易相关" class="headerlink" title="交易相关"></a>交易相关</h2><ul>
<li><p>余额查询</p>
<ul>
<li>同步<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getBalance(addressHexString [, defaultBlock])</span><br></pre></td></tr></table></figure></li>
<li>异步<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getBalance(addressHexString [, defaultBlock] [,callback])</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>交易查询</p>
<ul>
<li>同步<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getTransaction(transactionHash)</span><br></pre></td></tr></table></figure></li>
<li>异步<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getTransaction(transactionHash [,callback])</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>交易收据查询</p>
<ul>
<li><p>同步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getTransactionReceipt(hashString)</span><br></pre></td></tr></table></figure>
</li>
<li><p>异步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.getTransactionReceipt(hashString [, callback])</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>估计gas消耗量</p>
<ul>
<li><p>同步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.estimateGas(callObject)</span><br></pre></td></tr></table></figure>
</li>
<li><p>异步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.estimateGas(callObject [, callback])</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>发送交易</p>
<ul>
<li>from： 发送地址</li>
<li>to：接收地址</li>
<li>value：交易金额，以wei为单位，可选</li>
<li>gas：交易消耗gas上限，可选</li>
<li>gasPrice：交易gas单价，可选</li>
<li>data：交易携带的字串数据，可选</li>
<li>nonce：整数nonce值，可选<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.sendTransaction(transactionObject [,callback])</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<p>发送交易过程如下：</p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/trans1.png" alt></p>
<h2 id="消息调用"><a href="#消息调用" class="headerlink" title="消息调用"></a>消息调用</h2><p>消息调用与交易的区别是，当我们想给合约发起调用（调用函数，这时我们使用的是call方法），给别人发币时使用sendTransaction()，而调用合约时其实也可以使用sendTransaction()，但一般我们将不需要提交交易的消息调用上，比如我们不做状态改变（纯计算、查询等）。若引发了状态改变则一定要用sendTransaction()。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>调用对象：与交易对象相同，只是from也是可选的</li>
<li>默认区块：默认”latest“，可以传入指定的区块高度</li>
<li>回调函数：如果没有则为同步调用</li>
</ul>
<h2 id="日志过滤（事件监听）"><a href="#日志过滤（事件监听）" class="headerlink" title="日志过滤（事件监听）"></a>日志过滤（事件监听）</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.filter(filterOptions [.callback])</span><br></pre></td></tr></table></figure>
<ul>
<li><p>filterString可以是”latest”or”pending”</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var filter &#x3D; web3.eth.filter(filterString);</span><br></pre></td></tr></table></figure>
</li>
<li><p>或者可以填入一个日志过滤options</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var filter &#x3D; web3.eth.filter(options);</span><br></pre></td></tr></table></figure>
</li>
<li><p>监听日志变化</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">filter.watch(options, function(error, result)&#123;</span><br><span class="line">	if (!error) console.log(result);</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
</li>
<li><p>停止监听</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">filter.stopWatching()</span><br></pre></td></tr></table></figure>
</li>
<li><p>还可以用传入回调函数的方法，立刻开始监听日志</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.filter(options, function(error, result)&#123;</span><br><span class="line">	if (!error) console.log(result);</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><img src="/posts/Blockchain/filter.png" alt></p>
<h2 id="合约相关"><a href="#合约相关" class="headerlink" title="合约相关"></a>合约相关</h2><h3 id="创建合约"><a href="#创建合约" class="headerlink" title="创建合约"></a>创建合约</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web3.eth.contract</span><br></pre></td></tr></table></figure>
<p>创建合约有两种方式，第一种方式为传入abi：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var MyContract &#x3D; web3.eth.contract(abiArray);</span><br></pre></td></tr></table></figure>
<p>这时候我们拿到了一个js中的合约实例，但还未和区块链关联起来，我们还需要通过地址初始化合约实例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var contractinstance &#x3D; MyContract.at(address);</span><br></pre></td></tr></table></figure>
<p>或者是部署一个新合约：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var contractinstance &#x3D; MyContract.new([contructorParam1][contructorParam2],&#123;data:&quot;0x12345...&quot;,from:myAccount, gas&#125;)</span><br></pre></td></tr></table></figure>
<p>constructorParam1主要是传入需要赋的初值，data部分其实就是字节码。因此综上所述，在使用web3部署合约时需同时使用abi和字节码。接下来我们开始部署自己的合约：</p>
<p>合约如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pragma solidity &gt;0.6.0;</span><br><span class="line"></span><br><span class="line">contract Coin&#123;</span><br><span class="line">    address public minter;</span><br><span class="line">    mapping(address&#x3D;&gt;uint) public balances;</span><br><span class="line">    event Sent(address from, address to, uint amount);</span><br><span class="line">    constructor()public&#123;</span><br><span class="line">        minter &#x3D; msg.sender;</span><br><span class="line">    &#125;</span><br><span class="line">    function mint(address receiver, uint amount)public&#123;</span><br><span class="line">        require(msg.sender &#x3D;&#x3D; minter);</span><br><span class="line">        balances[receiver] +&#x3D; amount;</span><br><span class="line">    &#125;</span><br><span class="line">    function send(address receiver, uint amount)public&#123;</span><br><span class="line">        require(balances[msg.sender] &gt;&#x3D; amount);</span><br><span class="line">        balances[msg.sender] -&#x3D; amount;</span><br><span class="line">        balances[receiver] +&#x3D; amount;</span><br><span class="line">        </span><br><span class="line">        emit Sent(msg.sender, receiver, amount);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/contract1.png" alt></p>
<p>我们在上面的步骤中，首先将前面已经得到的contract编译过后的abi传入：var coinContract = web3.eth.contract(abi)，然后获得字节码(byteCode)，连同其他参数一起new合约，于是就部署好了一个合约，这里需要注意的是，在传入字节码时需要在最前面加入’0x’，这是由于字节码本身就是16进制的，但编译出来的结果头部并没有带0x，需要手动去加。</p>
<p>我们看一看部署的合约长啥样：</p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/contract2.png" alt></p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/contract3.png" alt></p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/contract4.png" alt></p>
<p>以上是打印结果，然后我们可以通过coinContractInstance.address获得合约地址，同时也可以根据相应接口获得其他信息。</p>
<h3 id="调用合约"><a href="#调用合约" class="headerlink" title="调用合约"></a>调用合约</h3><p>可以通过已创建的合约实例，直接调用合约函数</p>
<ul>
<li><p>直接调用，自动按函数类型决定用sendTransaction还是call</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">myContractInstance.myMethod(param1 [,param2,...][,transactionObject][,defaultBlock][,callback]);</span><br></pre></td></tr></table></figure>
</li>
<li><p>显式以消息调用形式call该函数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">myContractInstance.myMethod.call(param1 [,param2,...][,transactionObject][,defaultBlock][,callback]);</span><br></pre></td></tr></table></figure>
</li>
<li><p>显式以发送交易形式调用该函数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">myContractInstance.myMethod.sendTransaction(param1 [,param2,...][,transactionObject][,defaultBlock][,callback]);</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>最后的callback回调函数可选，若不选则为同步调用，但推荐使用异步调用方式。</p>
<p>我们还是来直接尝试调用一下合约：（由于testrpc不太方便，我在这里改用了ganache）</p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/coin1.png" alt></p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/coin2.png" alt></p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/coin3.png" alt></p>
<p>需要注意的是，这里我们需要在mint的时候写上：{from:web3.eth.accounts[0]}，因为需要让合约知道调用合约的人是谁才能发币。</p>
<p>我们可以看到在ganache-cli中立刻出现了我们刚刚调用的合约情况：</p>
<p><img src="/Pic/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20web3js%E7%BC%96%E5%86%99%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%84%9A%E6%9C%AC/coin4.png" alt></p>
<h3 id="监听合约事件"><a href="#监听合约事件" class="headerlink" title="监听合约事件"></a>监听合约事件</h3><ul>
<li><p>合约的event类似于filter，可以设置过略选项来监听</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var event &#x3D; myContractInstance.MyEvent(&#123;valueA:23&#125; [,additionalFilterObject])</span><br></pre></td></tr></table></figure>
</li>
<li><p>监听事件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">event.watch(function(err,, res)&#x3D;&gt;console.log(res))</span><br></pre></td></tr></table></figure>
</li>
<li><p>可以使用传入回调函数的方法，立刻开始监听事件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var event &#x3D; myContractInstance.MyEvent(&#123;valueA:23&#125;</span><br><span class="line">			[,additionalFilterObject], function(err, res)&#123;</span><br><span class="line">          			if(!err) console.log(res);</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>可以通过以下方式触发监听：</p>
<p><img src alt></p>
]]></content>
      <categories>
        <category>Blockchain</category>
      </categories>
  </entry>
  <entry>
    <title>区块链入门（一） —— Solidity</title>
    <url>/posts/e008c9c3.html</url>
    <content><![CDATA[<h1 id="Solidity-源文件布局"><a href="#Solidity-源文件布局" class="headerlink" title="Solidity 源文件布局"></a>Solidity 源文件布局</h1><h2 id="pragm（版本杂注）"><a href="#pragm（版本杂注）" class="headerlink" title="pragm（版本杂注）"></a>pragm（版本杂注）</h2><p>源文件可以被版本杂著pragma所注解，表明要求的编译器版本，例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br></pre></td></tr></table></figure>
<p>在上述限定下，源文件将不允许低于0.4.0版本的编译器编译，也不允许高于0.5.0版本的编译器编译</p>
<h2 id="import"><a href="#import" class="headerlink" title="import"></a>import</h2><p>solidity支持使用import导入其他源文件（语法与JavaScript类似），主要有以下几种：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">// 从<span class="string">"filename"</span>中导入所有的全局符号到当前全局作用域中</span><br><span class="line"><span class="keyword">import</span> <span class="string">"filename"</span></span><br><span class="line"></span><br><span class="line">// 创建一个新的全局符号 symbolName，其成员均来自<span class="string">"filename"</span>中全局符号</span><br><span class="line"><span class="keyword">import</span> * <span class="keyword">as</span> symbolName <span class="keyword">from</span> <span class="string">"filenam"</span></span><br><span class="line"></span><br><span class="line">// 创建新的全局符号  alias 和 symbol2，分别从 <span class="string">"filename"</span>引用 symbol1 和 symbol2</span><br><span class="line"><span class="keyword">import</span> &#123;symbol1 <span class="keyword">as</span> alias, symbol2&#125; <span class="keyword">from</span> <span class="string">"filename"</span></span><br><span class="line"></span><br><span class="line">// 这条语句等同于 <span class="keyword">import</span> * <span class="keyword">as</span> symbolName <span class="keyword">from</span> <span class="string">"filename"</span></span><br><span class="line"><span class="keyword">import</span> <span class="string">"filename"</span> <span class="keyword">as</span> symbolName;</span><br></pre></td></tr></table></figure>
<h1 id="Solidity-值类型"><a href="#Solidity-值类型" class="headerlink" title="Solidity 值类型"></a>Solidity 值类型</h1><div class="table-container">
<table>
<thead>
<tr>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>布尔(bool)</td>
<td>可能的取值为字符串常量值true或false</td>
</tr>
<tr>
<td>整型(int/uint)</td>
<td>分别表示有符号和无符号的不同位数的整型变量；支持关键字uint8到uint256（无符号，从第8位到第256位）以及int8到int256，以8位为步长递增</td>
</tr>
<tr>
<td>定长浮点型(fixed / ufixed)</td>
<td>表示各种大小的有符号和无符号的定长浮点型；在关键字unfixedMxN和fixedMxN中，M表示该类型占用的位数，N表示可用的小数位数（fixed是ufixed128x19的别名）</td>
</tr>
<tr>
<td>地址(address)</td>
<td>存储一个20字节（160位）的值（以太坊地址大小）</td>
</tr>
<tr>
<td>定长字节数组</td>
<td>关键字有bytes1, bytes2, … ,bytes32</td>
</tr>
<tr>
<td>枚举(enum)</td>
<td>一种用户可以定义类型的方法，与C语言类似，默认从0开始递增，一般用来模拟合约的状态</td>
</tr>
<tr>
<td>函数(function)</td>
<td>一种表示函数的类型</td>
</tr>
</tbody>
</table>
</div>
<h1 id="Solidity-引用类型"><a href="#Solidity-引用类型" class="headerlink" title="Solidity 引用类型"></a>Solidity 引用类型</h1><p>Solidity中较难理解的是引用类型，主要有三种：数组(Array)、结构(Struct)、映射(Mapping)</p>
<p><strong>数组(Array)</strong></p>
<ul>
<li>数组可以在声明时指定长度（定长数组），也可以动态调整大小（变长数组、动态数组）</li>
<li>对于存储型（storage）的数组 来说，元素类型可以是任意的（即元素也可以是数组类型、映射类型或者结构体）；对于内存型（memory）的数组来说，元素类型不能是映射（mapping）的类型</li>
</ul>
<p><strong>结构(Struct)</strong></p>
<ul>
<li>Solidit支持通过构造结构体定义新的类型（与C语言的类似）</li>
</ul>
<p><strong>映射(Mapping)</strong></p>
<ul>
<li>映射可以视作哈希表，在实际的初始化过程中创建的每个可能的key，并将其映射到字节形式全是零的值（类型默认值）</li>
</ul>
<h1 id="Solidity-地址类型"><a href="#Solidity-地址类型" class="headerlink" title="Solidity 地址类型"></a>Solidity 地址类型</h1><h2 id="版本更新后的地址类型"><a href="#版本更新后的地址类型" class="headerlink" title="版本更新后的地址类型"></a>版本更新后的地址类型</h2><p><strong>address</strong></p>
<ul>
<li>地址类型存储一个20字节的值（以太坊地址的大小）；地址类型也有成员变量，并作为所有合约的基础</li>
</ul>
<p><strong>address payable(v0.5.0引入)</strong></p>
<ul>
<li>与地址类型基本相同，不过多出了transfer和send两个成员变量</li>
</ul>
<p><strong>两者的转换和区别</strong></p>
<ul>
<li>payable地址是可以发送ether的地址，而普通address不能</li>
<li>允许从payable address到address的隐式转换，而反过来的转换是不可能的（唯一方法是通过uint160进行中间转换）</li>
<li>从0.5.0版本起，合约不再是从地址类型派生而来，但如果它有payable的回退函数，则同样可以显示转换为address或者address payable类型</li>
</ul>
<p>我们可以看到，Solidity目前的发展趋势是越来越严格限制对地址合约交易的运用，这正是出于安全性的考量。</p>
<h2 id="地址类型成员变量"><a href="#地址类型成员变量" class="headerlink" title="地址类型成员变量"></a>地址类型成员变量</h2><ul>
<li>获得该地址的ether余额，以Wei为单位：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&lt;address&gt;.balance(uint256)</span><br></pre></td></tr></table></figure>
<ul>
<li>向指定地址发送数量为amount的ether（以Wei为单位），失败时抛出异常，发送2300gas的矿工费，不可调节</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&lt;address payable&gt;.transfer(uint256 amount)</span><br></pre></td></tr></table></figure>
<ul>
<li>向指定地址发送数量为amount的ether（以Wei为单位），失败时返回false，发送2300gas的矿工费，不可调节(默认是执行成功的，更推荐使用transfer)</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&lt;address payable&gt;.send(uint256 amount) returns(bool)</span><br></pre></td></tr></table></figure>
<ul>
<li>发出底层函数CALL，失败时返回 false，发送所有可用gas，可调节（注意：如果CALL了别人的函数，这一段逻辑的控制权全部放在这个函数中，你不知道这个函数会做什么事情，可能把你的逻辑全部搞乱。。谨慎使用）</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&lt;address&gt;.call(bytes memory) returns(bool, bytes memory)</span><br></pre></td></tr></table></figure>
<ul>
<li>发出底层函数DELEGATECALL，失败时返回 false，发送所有可用gas，可调节</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&lt;address&gt;.delegatecall(bytes memory) returns(bool, bytes memory)</span><br></pre></td></tr></table></figure>
<ul>
<li>发出底层函数STATICCALL，失败时返回 false，发送所有可用gas，可调节</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&lt;address&gt;.staticcall(bytes memory) returns(bool, bytes memory)</span><br></pre></td></tr></table></figure>
<h2 id="地址成员变量用法"><a href="#地址成员变量用法" class="headerlink" title="地址成员变量用法"></a>地址成员变量用法</h2><ul>
<li>balance和transfer<ul>
<li>可以使用balance属性来查询一个地址的余额，可以使用transfer函数像一个payable地址发送以太币（Ether），以Wei为单位：</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">address payable x = address(<span class="number">0x123</span>)</span><br><span class="line">address myAddress = address(this)</span><br><span class="line"><span class="keyword">if</span>(x.balance &lt; <span class="number">10</span> &amp;&amp; myAddress.balance &gt;= <span class="number">10</span>)</span><br><span class="line">	x.transfer(<span class="number">10</span>);   //给x发<span class="number">10</span>Wei</span><br></pre></td></tr></table></figure>
<ul>
<li><p>send</p>
<ul>
<li>send事transfer的低级版本，如果执行失败，当前的合约不会因为异常而终止，但send会返回false</li>
</ul>
</li>
<li><p>call</p>
<ul>
<li>也可以用call来实现转币的操作，通过添加.gas()和.value()修饰器（很底层）</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nameReg.call.gas(<span class="number">1000000</span>).value(<span class="number">1</span> ether)(abi.encodeWithSignature(<span class="string">"refister(string)"</span>, <span class="string">"MyName"</span>));</span><br></pre></td></tr></table></figure>
<h1 id="类型详解"><a href="#类型详解" class="headerlink" title="类型详解"></a>类型详解</h1><h2 id="字符数组-Bytes-Arrays"><a href="#字符数组-Bytes-Arrays" class="headerlink" title="字符数组(Bytes Arrays)"></a>字符数组(Bytes Arrays)</h2><p><strong>定长字符数组</strong></p>
<ul>
<li>属于值类型，bytes1,bytes2,…,bytes32分别代表了长度为1到32的字节序列</li>
<li>有一个.length属性，返回数组长度（只读）</li>
</ul>
<p><strong>变长字符数组</strong></p>
<ul>
<li>属于引用类型，包括bytes和string，不同的事bytes事Hex字符串，而string是UTF-8编码的字符串</li>
</ul>
<h2 id="枚举"><a href="#枚举" class="headerlink" title="枚举"></a>枚举</h2><ul>
<li>枚举类型用于用户自定义一组常量值</li>
<li>与C语言的枚举类型非常相似，对应整型值</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pragma solidity &gt;=<span class="number">0.4</span><span class="number">.0</span> &lt;<span class="number">0.6</span><span class="number">.0</span>;</span><br><span class="line">contract Purchase&#123;</span><br><span class="line">	enum State&#123;Create, Locked, Inactive&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="数组-Array"><a href="#数组-Array" class="headerlink" title="数组(Array)"></a>数组(Array)</h2><ul>
<li>固定大小k和元素类型T的数组被写为T[k]，动态大小的数组为T[]。例如，一个由5个uint的动态数组组成的数组是uint[][5]（定义的方式与C相反）</li>
<li>要访问第三个动态数组中的第二个uint，可以使用x[2][1]</li>
<li>越界访问数组，会导致调用失败回退</li>
<li>如果要添加新元素，则必须使用.push()或将.length增大</li>
<li>变长的storage数组和bytes(不包括string)有一个push()方法。可以将一个新元素附加到数组末端，返回值为当前长度</li>
</ul>
<p><strong>数组实例</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pragma solidity &gt;=<span class="number">0.4</span><span class="number">.16</span> &lt;<span class="number">0.6</span><span class="number">.0</span>;</span><br><span class="line">contract&#123;</span><br><span class="line">	function f(uint len) public pure&#123;</span><br><span class="line">    	// 给a分配了<span class="number">7</span>个对应的存储空间</span><br><span class="line">    	uint[] memory a = new uint[](<span class="number">7</span>);</span><br><span class="line">        // 动态大小数组</span><br><span class="line">        bytes memory b = new bytes(len);</span><br><span class="line">        <span class="keyword">assert</span>(a.length == <span class="number">7</span>);</span><br><span class="line">        <span class="keyword">assert</span>(b.length == len);</span><br><span class="line">        a[<span class="number">6</span>] = <span class="number">8</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="结构-Struct"><a href="#结构-Struct" class="headerlink" title="结构(Struct)"></a>结构(Struct)</h2><ul>
<li>结构类型可以在映射和数组中使用，它们本身可以包含映射和数组</li>
<li>结构不能包含自己类型的成员，但可以作为自己数组的成员，也可以作为自己映射成员的值类型</li>
</ul>
<p><strong>结构实例</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pragma solidity &gt;=<span class="number">0.4</span><span class="number">.0</span> &lt;<span class="number">0.6</span><span class="number">.0</span>;</span><br><span class="line">contract Ballot&#123;</span><br><span class="line">	struct Voter &#123;</span><br><span class="line">    	uint weight;</span><br><span class="line">        bool voted;</span><br><span class="line">        uint vote;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="映射-Mapping"><a href="#映射-Mapping" class="headerlink" title="映射(Mapping)"></a>映射(Mapping)</h2><ul>
<li>声明一个映射：mapping(_KeyType =&gt; _ValueType)</li>
<li>_KeyType可以是任何基本类型，这意味着它可以是任何内置值类型加上字节和字符串，不允许使用用户自定义的或是更复杂的类型，如枚举，映射，结构以及除了bytes和string之外的所有数组类型</li>
<li>_ValueType可以是任何类型，包括映射</li>
</ul>
<p><strong>映射实例</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pragma solidity &gt;=<span class="number">0.4</span><span class="number">.0</span> &lt;<span class="number">0.6</span><span class="number">.0</span>;</span><br><span class="line">contract MappingExample &#123;</span><br><span class="line">	mapping(address =&gt;uint) public balances;</span><br><span class="line">    function update(uint newBalance) public &#123;</span><br><span class="line">    	balances[msg.sender] = newBalance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">contract  MappingUser&#123;</span><br><span class="line">	function f() public returns (uint) &#123;</span><br><span class="line">    	MappingExample m = new MappingExample();</span><br><span class="line">        m.update(<span class="number">100</span>);</span><br><span class="line">        <span class="keyword">return</span> m.balances(address(this));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="Solidity-数据存储位置"><a href="#Solidity-数据存储位置" class="headerlink" title="Solidity 数据存储位置"></a>Solidity 数据存储位置</h1><ul>
<li>所有的复杂类型，即数组、结构和映射类型，都有一个额外属性——”数据位置”，用来说明数据时 保存在内存(memory)中还是存储(storagez)中</li>
<li>根据上下文不同，大多数时候数据有默认的位置，但也可以通过在类型名后增加关键字 storage或memory进行修改</li>
<li>函数参数(包括返回的参数)的数据位置默认是memory，局部变量的数据位置默认是storage，状态变量的数据位置强制是storage</li>
<li>另外还存在第三种 数据位置，calldata，这是一块只读的且不会永久存储的位置，用来存储函数参数，外部函数的参数（非返回参数)的数据位置被强制指定为calldata，效果跟memory差不多</li>
</ul>
<p><strong>总结</strong>：</p>
<ul>
<li>强制指定地数据位置<ul>
<li>外部函数的参数（不包括返回参数）：calldata</li>
<li>状态变量：starage</li>
</ul>
</li>
<li>默认数据位置<ul>
<li>函数参数（包括返回参数）：memory</li>
<li>引用类型地局部变量：storage</li>
<li>值类型地局部变量：栈（stack）</li>
</ul>
</li>
</ul>
<p><strong>特别要求</strong>：</p>
<ul>
<li>公开可见（public visible）的函数参数一定是memory类型，如果要求是storage类型，则必须是private或者internal参数，这是为了防止随意的公开调用占用资源</li>
</ul>
<p><strong>数据存储实例</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br><span class="line">contract C&#123;</span><br><span class="line">	uint[] data1;</span><br><span class="line">    uint[] data2;</span><br><span class="line">    function appendOne() public &#123;</span><br><span class="line">    	append(data1);</span><br><span class="line">    &#125;</span><br><span class="line">    function appendTwo() public &#123;</span><br><span class="line">    	append(data2);</span><br><span class="line">    &#125;</span><br><span class="line">    function append(uint[] storage d) internal &#123;</span><br><span class="line">    	d.push(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="改错题"><a href="#改错题" class="headerlink" title="改错题"></a>改错题</h1><h2 id="T1"><a href="#T1" class="headerlink" title="#T1"></a>#T1</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br><span class="line">contract C&#123;</span><br><span class="line">	uint someVariable;</span><br><span class="line">    uint[] data;</span><br><span class="line">    function f() public&#123;</span><br><span class="line">    	uint[] x;</span><br><span class="line">        x.push(<span class="number">2</span>);</span><br><span class="line">        data = x;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>someVariable在这段代码里面会成为一个计数器，每一次调用f()都会使之递增，这是由于Solidity语法中，未指定的x在这里被设定为一个storage类型的指针(storage pointer)，由于所有状态变量和局部变量的默认存储位置都是在storage中，因此声明了一个可变长度的数组x又未给它赋值，因此在存储空间中它是一个没有分配存储空间的指针，最开始一轮a和b都赋初值0，而x会指向合约定义的整个存储空间的零位置（最开始的地方），也就是a的位置，因此后面在调用x之后a会随之变化。</p>
<p>但是为什么x变化2，而a只变化了1呢？因为我们定义的x这个长度可变的数组在顺序存储中会存储它的长度，找这个变量的时候就会直接找到它的长度，我们想要找到它的元素就会通过它元素的索引值加上本身的位置共同计算出一个哈希，哈希的位置就是元素对应的位置。</p>
<p>因此正确方式为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br><span class="line">contract C&#123;</span><br><span class="line">	uint someVariable;</span><br><span class="line">    uint[] data;</span><br><span class="line">    function f() public&#123;</span><br><span class="line">    	uint[] x = data;</span><br><span class="line">        x.push(<span class="number">2</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="T2"><a href="#T2" class="headerlink" title="#T2"></a>#T2</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br><span class="line">contract C&#123;</span><br><span class="line">	uint[] x;</span><br><span class="line">    function f(uint[] memoryArray) public &#123;</span><br><span class="line">    	x = memoryArray;</span><br><span class="line">        uint[] y = x;</span><br><span class="line">        y[<span class="number">7</span>];</span><br><span class="line">        y.length = <span class="number">2</span>;</span><br><span class="line">        delete x;</span><br><span class="line">        y = memoryArray;</span><br><span class="line">        delete y;</span><br><span class="line">        g(x);</span><br><span class="line">        h(x);</span><br><span class="line">    &#125;</span><br><span class="line">    function g(uint[] storage storageArray) internal &#123;&#125;</span><br><span class="line">    function h(uint[] memoryArray) public &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面这段代码在y = memoryArray处会报错：Type uint256[] memory is not implicitly convertible to expected type uint256[] storage pointer.显见，memoryArray为一个memory类型的变长数组，而要将之赋值给y，由于y是一个storage类型的指针，不会发生拷贝，产生错误。（两块空间的地址意义不同）</p>
<p>因此正确方式为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br><span class="line">contract C&#123;</span><br><span class="line">	uint[] x;</span><br><span class="line">    function f(uint[] memoryArray) public &#123;</span><br><span class="line">    	x = memoryArray;</span><br><span class="line">        uint[] y = x;</span><br><span class="line">        y[<span class="number">7</span>];</span><br><span class="line">        y.length = <span class="number">2</span>;</span><br><span class="line">        delete x;</span><br><span class="line">        uint[]memory z = memoryArray;</span><br><span class="line">        delete z;</span><br><span class="line">        g(x);</span><br><span class="line">        h(x);</span><br><span class="line">    &#125;</span><br><span class="line">    function g(uint[] storage storageArray) internal &#123;&#125;</span><br><span class="line">    function h(uint[] memoryArray) public &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="T3-猜数字游戏"><a href="#T3-猜数字游戏" class="headerlink" title="#T3 猜数字游戏"></a>#T3 猜数字游戏</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pragma solidity &gt;<span class="number">0.4</span><span class="number">.22</span>;</span><br><span class="line">contract Honeypot &#123;</span><br><span class="line">	uint luckyNum = <span class="number">52</span>;</span><br><span class="line">    uint public last;</span><br><span class="line">    struct Guess&#123;</span><br><span class="line">    	address player;</span><br><span class="line">        uint number;</span><br><span class="line">    &#125;</span><br><span class="line">    Guess[] public guessHistory;</span><br><span class="line">    address owner = msg.sender;</span><br><span class="line">    function guess(uint_num) public payable&#123;</span><br><span class="line">    	Guess newGuess;</span><br><span class="line">        newGuess.player = msg.sender;</span><br><span class="line">        newGuess.number = _num;</span><br><span class="line">        guessHistory.push(newGuess);</span><br><span class="line">        <span class="keyword">if</span>(_num == luckyNum)</span><br><span class="line">        	msg.sender.transfer(msg.value*<span class="number">2</span>);</span><br><span class="line">        last = now;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当传入guess的参数52时，发现账户余额净少十个，并没有出现返还的两倍奖励。首先Guess newGuess和T1一样，被声明为一个storage类型的指针，也就是最初会直接指向luckyNum，并将之修改。这是Solidity上的一个钓鱼合约（蜜罐合约），发多少以太币丢多少以太币。另外事实上若将Guess中新得到的luckyNumber输进去是可以成功的，可以将币提出来，但实际上合约创作者不会愚蠢地把luckyNum设置为public。</p>
<p>我们想一下，若将Guess定义中的player和number互换一下次序会发生什么：由于Guess会首先传入调用者写入的内容，也就是number，因此调用者无论输入了 什么数字最终都会显示猜测正确，于是给调用者转钱。</p>
<p>不过上述问题在0.5.0版本之后已被更正，但以太坊上仍有不少钓鱼合约需要我们注意。</p>
<h1 id="函数详解"><a href="#函数详解" class="headerlink" title="函数详解"></a>函数详解</h1><h2 id="函数声明和类型"><a href="#函数声明和类型" class="headerlink" title="函数声明和类型"></a>函数声明和类型</h2><p>在下面的函数声明中：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">function getBrand() public view returns (string)&#123;</span><br><span class="line">	<span class="keyword">return</span> brand;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>getBrand()时函数名称，public view是函数类型,string是返回类型。</p>
<ul>
<li>函数的值类型有两类：内部函数和外部函数</li>
<li>内部函数只能在当前合约内被调用（更具体来说，在当前代码块内，包括内部库函数和继承的函数中），因为它们不能再当前合约上下文的外部被执行。调用一个内部函数是通过跳转到它的入口标签来实现的，就像在当前合约的内部 调用一个函数</li>
<li>外部函数由一个地址和一个函数签名组长城，可以通过外部函数调用传递或者返回</li>
<li>调用内部函数：直接使用名字f</li>
<li>调用外部函数: this.f(当前合约)，a.f(外部合约)</li>
</ul>
<h2 id="函数可见性"><a href="#函数可见性" class="headerlink" title="函数可见性"></a>函数可见性</h2><p>函数的可见性可以指定为external,public,internal或者private；对于状态变量，不能设置为external，默认是internal。</p>
<ul>
<li>external:外部函数作为合约接口的一部分，意味着我们可以从其他他合约和交易中调用。一个挖补函数f不能从内部调用（即f不起作用，但this.f()可以）。当收到大量数据时，外部函数有时会更有效率。</li>
<li>public：public函数是合约接口的一部分，可以在内部或通过消息调用。对于public状态变量，会自动生成一个getter函数。</li>
<li>internal：这些函数和状态变量只能 是内部访问（即从当前合约内部或从它的派生的合约访问），不能用this调用。</li>
<li>private：private函数和状态变量仅在当前按定义 它们的合约中使用，并且不能被派生合约使用。</li>
</ul>
<p>我们在将一个状态变量设置为public时，实际上就是生成一个getter函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">function a() public view returns(uint)&#123;</span><br><span class="line">	<span class="keyword">return</span> a;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="函数状态可变性"><a href="#函数状态可变性" class="headerlink" title="函数状态可变性"></a>函数状态可变性</h2><ul>
<li>pure:纯函数，不允许修改或访问状态</li>
<li>view:不允许修改状态</li>
<li>payable:允许从消息调用中接收以太币</li>
<li>constant:与view相同，一般只修饰状态变量，不允许赋值（只能初始化）</li>
<li>以下情况被认为是修改状态：<ul>
<li>修改状态变量</li>
<li>产生事件</li>
<li>创建其他合约</li>
<li>使用selfdestruct</li>
<li>通过调用发送以太币</li>
<li>通过任何没有标记为view或者pure的函数</li>
<li>使用低级调用（CALL等）</li>
<li>使用包含特定操作码的内联汇编</li>
</ul>
</li>
<li>以下被认为是读取状态：<ul>
<li>读取状态变量</li>
<li>访问this.balance胡总和<address>.balance</address></li>
<li>访问block,tx,msg中任意成员（除msg.sig和msg.data之外）</li>
<li>调用任何未标记为pure的函数</li>
<li>使用包含某些操作码的内联汇编</li>
</ul>
</li>
</ul>
<h2 id="函数修饰器-modifier"><a href="#函数修饰器-modifier" class="headerlink" title="函数修饰器(modifier)"></a>函数修饰器(modifier)</h2><ul>
<li>使用修饰器modifier可以轻松改变函数的行为，例如：它们可以在执行函数之前自动检查某个条件。修饰器modifier是合约的可继承属性，并可能被派生合约覆盖</li>
<li>如果同一个函数有多个修饰器modifier，它们之间以空格隔开，修饰器modifier会依次检查执行</li>
</ul>
<p><strong>modifier实例</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pragma solidity &gt;=<span class="number">0.4</span><span class="number">.22</span> &lt;<span class="number">0.6</span><span class="number">.0</span>;</span><br><span class="line">contract Purchase &#123;</span><br><span class="line">	address public seller;</span><br><span class="line">    modifier onlySeller()&#123;</span><br><span class="line">    	requier(msg.sender == sender, <span class="string">"Only seller can sell."</span>);</span><br><span class="line">        _; // 占位符:原本函数的代码在此执行</span><br><span class="line">    &#125;</span><br><span class="line">    function abort public view onlySeller returns(uint)&#123;</span><br><span class="line">    	// Modifier usage</span><br><span class="line">    	<span class="keyword">return</span> <span class="number">200</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当换一个账户调用f时会报错，判断了require。同理函数修饰器也可以改变下划线 （占位符的位置），改变调用次序。</p>
<h2 id="回退函数-fallback"><a href="#回退函数-fallback" class="headerlink" title="回退函数(fallback)"></a>回退函数(fallback)</h2><ul>
<li>回退函数(fallback function)是合约中的特殊函数，没有名字，不能有参数也不能有返回值</li>
<li>如果在一个合约的调用中，没有其他函数与给定的函数标识符匹配（或没有提供调用数据），那么这个函数（fallback）函数会被执行</li>
<li>每当合约收到以太币（没有任何数据），回退函数就会执行。此外，为了接收以太币，fallback必须标记为payable。如果不存在这样的函数，则合约不能通过常规交易接收以太币</li>
<li>在上下文中通常只有很少的gas可以用来 完成回退函数的调用，所以使用fallback函数的调用尽量廉价很重要</li>
</ul>
<p>回退函数中如果有人加入恶意代码，比如获取地址，比如重复调用合约，就会产生一个比较大的安全隐患。这种现象一般会发生在发币的合约中，恶意账户在回退函数中加入能重复调用合约的代码，从而达成不断获得币的目的。以太坊历史上最大的一次攻击——The Dao，正是由于以太坊在合约中给人转币，调用了transfer方法，但没有判定地址到底是什么样的地址，结果就是黑客写了份合约，注册了The Dao帐号之后触发了函数Transfer往自己合约中转以太，并且调用到了自己写好的回退函数，当然还使用到了其他漏洞大家可以自行了解。</p>
<h1 id="事件"><a href="#事件" class="headerlink" title="事件"></a>事件</h1><ul>
<li>事件是以太坊EVM提供的一种日志基础设施，事件可以用来做操作记录，存储为日志。也可以用来实现一些交互功能，比如同值UI，返回函数调用结果等</li>
<li>当定义的事件触发时，我们可以将时间存储到EVM的交易日志中，日志是区块链中的一种特殊的数据结构，日志与合约关联，与合约的存储和并存入区块链中；只要某个区块可以访问，其相关的日志就可以访问；但在合约中我们不能直接访问日志和事件数据</li>
<li>可以通过日志实现简单支付验证SPV(Simpllified Payment Verification)，如果一个外部实体提供了一个带有这种证明的合约，它可以检查日志是否真实存在于区块链中</li>
</ul>
<h1 id="Solidity异常处理"><a href="#Solidity异常处理" class="headerlink" title="Solidity异常处理"></a>Solidity异常处理</h1><ul>
<li>Solidity使用“状态恢复异常”来处理异常。这样的异常将撤销 对当前调用（及其所有子调用）中的状态 所做的所有更改，并且向调用者返回错误</li>
<li>函数assert和require可用于判断条件，并在不满足条件时抛出异常</li>
<li>assert()一般只应用于测试内部错误，并检查常量</li>
<li>require()应用于确保 满足有效条件（如输入或合约状态变量），或验证调用外部合约的返回值</li>
<li>revert()用于抛出异常，它可以标记一个错误并返回当前调用回退（检查外部）</li>
</ul>
]]></content>
      <categories>
        <category>Blockchain</category>
      </categories>
  </entry>
  <entry>
    <title>matlab/Matlab问题求解</title>
    <url>/posts/49938fa3.html</url>
    <content><![CDATA[<h1 id="函数和子函数"><a href="#函数和子函数" class="headerlink" title="函数和子函数"></a>函数和子函数</h1><p><strong>一个M文件中，可能会有多个函数，其中第一个称为主函数，后面的所有函数称为子函数</strong></p>
<ul>
<li><p>脚本文件中，也可以直接在脚本的最后添加子函数，在当前文件夹内，如果有同名函数，按照子函数$\rightarrow$MATLAB内建函数$\rightarrow$其他$\rightarrow$M文件主函数的顺序访问。子函数最后的<code>end</code>不能省略</p>
</li>
<li><p>一个M文件的主函数通常和M文件名相同（否则MATLAB仍以文件名主名作为识别标准），一个M包含多个函数时，每个函数最后的<code>end</code>或者都省略掉，或者都不省略。</p>
</li>
<li><p>所有的子函数都可以被M文件内的脚本或主函数调用，但无法被其他M文件或命令行直接调用。因此，子函数是一种减少M文件数量，封装外部脚本不直接调用的函数的好方法。</p>
</li>
</ul>
<h3 id="子函数"><a href="#子函数" class="headerlink" title="子函数"></a>子函数</h3><p><strong>编写一个内含子函数的M函数绘图文件</strong></p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">HC = Draw_d(<span class="string">'circle'</span>);</span><br><span class="line">HL = Draw_d(<span class="string">'line'</span>);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Hr</span> = <span class="title">Draw_d</span><span class="params">(flag)</span></span></span><br><span class="line">    <span class="comment">% exm060301.m  	Demo for handles of primary functions and subfunctions</span></span><br><span class="line">    <span class="comment">%       	flag   				%允许使用字符串’line’或’circle’     </span></span><br><span class="line">    <span class="comment">%			Hr					%返回子函数cirline的句柄	</span></span><br><span class="line">    t = (<span class="number">0</span>:<span class="number">50</span>)/<span class="number">50</span>*<span class="number">2</span>*<span class="built_in">pi</span>;				<span class="comment">%0~2pi等分了50个区间</span></span><br><span class="line">    x = <span class="built_in">sin</span>(t);</span><br><span class="line">    y = <span class="built_in">cos</span>(t);</span><br><span class="line">    Hr = @cirline;					<span class="comment">%创建cirline的句柄（一种函数名的不同解读，类似于C++的指针）</span></span><br><span class="line">    feval(Hr, flag, x, y, t);		<span class="comment">%feval结合句柄调用，等价于cirline(flag,x,y,t)</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">cirline</span><span class="params">(wd, x, y, t)</span></span></span><br><span class="line">    <span class="comment">%           wd       		%主函数传递来的flag，可能为’line’或’circle’    </span></span><br><span class="line">    <span class="comment">%           t,x,y		%分别为绘图参数、横坐标与纵坐标    </span></span><br><span class="line">    <span class="keyword">switch</span> wd</span><br><span class="line">        <span class="keyword">case</span> <span class="string">'line'</span></span><br><span class="line">            <span class="built_in">plot</span>(t, x, <span class="string">'b'</span>, t, y, <span class="string">'r'</span>, <span class="string">'LineWidth'</span>, <span class="number">2</span>);</span><br><span class="line">        <span class="keyword">case</span> <span class="string">'circle'</span></span><br><span class="line">            <span class="built_in">plot</span>(x, y, <span class="string">'-g'</span>, <span class="string">'LineWidth'</span>, <span class="number">8</span>);</span><br><span class="line">            axis square off;</span><br><span class="line">        <span class="keyword">otherwise</span></span><br><span class="line">            error(<span class="string">'输入变量只能取“line”或“circle”！'</span>)</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    shg</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p><code>HC</code>的输出结果为：</p>
<p><img src="/Pic/Matlab%E9%97%AE%E9%A2%98%E6%B1%82%E8%A7%A3/circle.png" style="zoom:50%;"></p>
<p><code>HL</code>的输出结果为：</p>
<p><img src="/Pic/Matlab%E9%97%AE%E9%A2%98%E6%B1%82%E8%A7%A3/line.png" style="zoom:50%;"></p>
<p>另外我们可以将<code>t</code>的采样距离缩小，比如绘制正五边形采样点分布：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">t=<span class="number">0</span>:<span class="number">2</span>*<span class="built_in">pi</span>/<span class="number">5</span>:<span class="number">2</span>*<span class="built_in">pi</span>;x=<span class="built_in">cos</span>(t);y=<span class="built_in">sin</span>(t);</span><br><span class="line">HH(<span class="string">'circle'</span>,x,y,t)</span><br><span class="line"><span class="comment">%利用m文件主函数返回的句柄可以间接调用到子函数。</span></span><br><span class="line"><span class="comment">%如果没有返回的句柄，则子函数cirline无法被外部调用</span></span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Matlab%E9%97%AE%E9%A2%98%E6%B1%82%E8%A7%A3/s5.png" style="zoom:50%;"></p>
<h3 id="匿名函数"><a href="#匿名函数" class="headerlink" title="匿名函数"></a>匿名函数</h3><ul>
<li>适用于结构简单、无需创建m文件或子函数体来定义的“一句话函数”</li>
<li>例如：<code>F=@(x) sin(x).*x</code>,就定义了一个自变量为<code>x</code>，函数值<code>F(x)=sin(x).*x</code>的匿名函数。命名上，<code>F</code>称为函数句柄，括号内的<code>x</code>称为参数（参数可以由多个变量构成参数列表），<code>sin(x).*x</code>称为函数主体表达式。</li>
<li>匿名函数可以通过如<code>F(3)</code>或<code>F(x)</code>直接调用，也可以通过<code>feval(F,x)</code>间接调用,有时，函数句柄<code>F</code>还可以作为参数代入一些更为复杂的函数体。</li>
</ul>
<h3 id="函数句柄"><a href="#函数句柄" class="headerlink" title="函数句柄"></a>函数句柄</h3><p>函数的句柄类似于指针，除<code>plot</code>绘图返回值，匿名函数定义外，还可对MATLAB内建函数或用户已定义函数创建句柄。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">hm = @<span class="built_in">magic</span>;</span><br><span class="line">class(hm)           <span class="comment">% ans = 'function_handle'</span></span><br><span class="line">functions(hm)       <span class="comment">% 查询句柄对应函数信息，包含function（函数名）, type（函数类型sinple）, file（文件位置）</span></span><br><span class="line">hm(<span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">16     2     3    13</span><br><span class="line">5    11    10     8</span><br><span class="line">9     7     6    12</span><br><span class="line">4    14    15     1</span><br></pre></td></tr></table></figure>
<p>调用子函数时，函数句柄可以“完全的代替”本身子函数的函数名，格式与子函数直接调用相同。但利用函数句柄多次调用可以大大节省调用的时间（不必重复搜索路径）。</p>
<h1 id="函数极值的数学方法"><a href="#函数极值的数学方法" class="headerlink" title="函数极值的数学方法"></a>函数极值的数学方法</h1><ul>
<li><p><code>[x,fval,exitflag]=fminbnd(fun,x1,x2)</code>可以求一元函数<code>fun</code>在<code>[x1,x2]</code>的一个极小值，<code>fun</code>可使用字符串，匿名函数或函数句柄。返回值列表$x$为极小值点，<code>fval</code>为函数极小值，<code>exitflag&gt;0</code>代表此函数成功找到了一个极值点。其余功能<code>output</code>，<code>option</code>可以通过帮助系统了解用法，它们主要可以让MATLAB显示迭代过程中的各种运算指标。</p>
</li>
<li><p><code>[x,fval,exitflag]=fminsearch(fun,x0)</code>可以利用无导数方法（如单纯形法），从$x_0$点出发，求多元函数<code>fun</code>在在多维空间中的一个极小值，<code>fun</code>建议使用多元匿名函数或多元函数句柄（输入值为向量）。返回值列表$x$为极小值点向量，<code>fval</code>为函数极小值，其余功能与<code>fminbnd</code>类似。</p>
</li>
<li>注意到两个函数均为找一个极小值，有时也称为局部最小值，并不一定是定义域内的全局最小值。希望获取全局最小值，需要设立较好的区间或起始点，或反复遍历所有极值点。</li>
</ul>
<h3 id="划分区间求极值"><a href="#划分区间求极值" class="headerlink" title="划分区间求极值"></a>划分区间求极值</h3><p>例：求$y=e^{-0.1x}\text{sin}^2x-0.5(x+0.1)\text{sin}x$ 在 $-50\le x\le 50$的极小值</p>
<p><img src="/../Pic/matlab/min_sin_exp" alt="image-20201117170312325" style="zoom:50%;"></p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">x1=<span class="number">-50</span>;x2=<span class="number">5</span>;		</span><br><span class="line">yx=@(x)(<span class="built_in">sin</span>(x).^<span class="number">2.</span>*<span class="built_in">exp</span>(<span class="number">-0.1</span>*x)<span class="number">-0.5</span>*<span class="built_in">sin</span>(x).*(x+<span class="number">0.1</span>));    <span class="comment">%定义函数句柄</span></span><br><span class="line">[xc0,fc0,exitflag]=fminbnd(yx,x1,x2)	<span class="comment">%找到的其中一个极小值 </span></span><br><span class="line"></span><br><span class="line">ezplot(yx,[<span class="number">-50</span>,<span class="number">5</span>]);                     <span class="comment">%ezplot同样可用于函数句柄，只需指定x的范围即可</span></span><br><span class="line">xlabel(<span class="string">'x'</span>),grid on </span><br><span class="line"></span><br><span class="line">xx=[<span class="number">-23</span>,<span class="number">-20</span>,<span class="number">-18</span>];                       <span class="comment">%观察最小值疑似存在的两个区段</span></span><br><span class="line">fc=fc0;xc=xc0;                          <span class="comment">%暂时设立最小值点和最小值为初始搜索的结果</span></span><br><span class="line"><span class="keyword">for</span> k=<span class="number">1</span>:<span class="number">2</span></span><br><span class="line">	[xw,fw]=fminbnd(yx,xx(k),xx(k+<span class="number">1</span>));  <span class="comment">%分别计算两个区段的极小值</span></span><br><span class="line">	<span class="keyword">if</span> fw&lt;fc, xc=xw;fc=fw;<span class="keyword">end</span>           <span class="comment">%若有更小的极小值则更换最小值</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">fprintf(<span class="string">'函数最小值%6.5f发生在x=%6.5f处'</span>,fc,xc)</span><br></pre></td></tr></table></figure>
<h3 id="单峰函数求极值之黄金分割法"><a href="#单峰函数求极值之黄金分割法" class="headerlink" title="单峰函数求极值之黄金分割法"></a>单峰函数求极值之黄金分割法</h3><p>对于向内的试探法，从$[a_k,b_k]$开始，当$α_1≈0.618a_k+0.382b_k,α_2≈0.382a_k+0.618b_k$时，探索的效率最高，这样的试探法就成为黄金分割法（0.618法）</p>
<p>黄金分割法的算法复杂度为$O(\text{ln}\frac{b-a}{\epsilon})$，而且可以处理目标函数不可导的特殊情况。操作代码如下：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">x1=<span class="number">-20</span>;x2=<span class="number">-18</span>;      </span><br><span class="line">yx=@(x)(<span class="built_in">sin</span>(x).^<span class="number">2.</span>*<span class="built_in">exp</span>(<span class="number">-0.1</span>*x)<span class="number">-0.5</span>*<span class="built_in">sin</span>(x).*(x+<span class="number">0.1</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">%设立初始最小值</span></span><br><span class="line">minf = yx(x1);</span><br><span class="line"><span class="keyword">if</span>(yx(x2)&lt;minf) </span><br><span class="line">    minf = yx(x2); </span><br><span class="line"><span class="keyword">end</span>		</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>)</span><br><span class="line">    alpha1 = x1*<span class="number">0.618</span>+x2*<span class="number">0.382</span>;</span><br><span class="line">    alpha2 = x1*<span class="number">0.382</span>+x2*<span class="number">0.618</span>;</span><br><span class="line">    <span class="keyword">if</span>(yx(alpha1)&gt;yx(alpha2))</span><br><span class="line">        x1 = alpha1;</span><br><span class="line">        <span class="keyword">if</span>(yx(alpha2)&lt;minf) </span><br><span class="line">            minf = yx(alpha2); </span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        x2 = alpha2;</span><br><span class="line">        <span class="keyword">if</span>(yx(alpha1)&lt;minf)</span><br><span class="line">            minf = yx(alpha1);</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">if</span>(alpha2-alpha1&lt;<span class="number">1e-8</span>)</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">minf, alpha1</span><br></pre></td></tr></table></figure>
<h3 id="牛顿迭代法"><a href="#牛顿迭代法" class="headerlink" title="牛顿迭代法"></a>牛顿迭代法</h3><ul>
<li><p>牛顿迭代法起源于一阶泰勒展开近似 </p>
<script type="math/tex; mode=display">f(x) \approx f\left(x_{0}\right)+f^{\prime}\left(x_{0}\right)\left(x-x_{0}\right)</script><p> 此时, 设$\exist\bar{x},$ 满足 $f(\bar{x})=0$,则给定任意一点 $x,$有  </p>
<script type="math/tex; mode=display">f(x) \approx f(\bar{x})+f^{\prime}(\bar{x})(x-\bar{x})=f^{\prime}(\bar{x})(x-\bar{x})</script><p>移项后即可得到</p>
<script type="math/tex; mode=display">\bar{x} \approx x-\frac{f(x)}{f^{\prime}(x)}</script><p>对于线性函数 $f(x),$ 此法可快速求解 $f(x)=\mathbf{0}$</p>
</li>
<li><p>几何上讲, 牛顿迭代法类似于寻找切线方向并移动至x轴交点, 迭代公式记为：</p>
<script type="math/tex; mode=display">x_{n+1} = x_n-\frac{f(x_n)}{f^`(x_n)}</script></li>
<li><p>对于求局部最小值问题, 因</p>
<script type="math/tex; mode=display">\text{argmin }_x f(x) \Leftrightarrow f^{\prime}(x)=0</script><p> 因此对应的牛顿迭代法公式只需改为导数方程问题，迭代公式：</p>
</li>
</ul>
<script type="math/tex; mode=display">
x_{n+1}=x_{n}-\frac{f^{\prime}\left(x_{n}\right)}{f^{\prime \prime}\left(x_{n}\right)}</script><p>例：求$y=e^{-0.1x}\text{sin}^2x-0.5(x+0.1)\text{sin}x$ 在 $-20\le x\le -18$的最小值，代码如下：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">x1=<span class="number">-20</span>;x2=<span class="number">-18</span>;syms x;		</span><br><span class="line">yx=@(x)(<span class="built_in">sin</span>(x).^<span class="number">2.</span>*<span class="built_in">exp</span>(<span class="number">-0.1</span>*x)<span class="number">-0.5</span>*<span class="built_in">sin</span>(x).*(x+<span class="number">0.1</span>));</span><br><span class="line">yxp = diff(yx,x);		<span class="comment">%MATLAB默认使用sym类型储存导函数表达式</span></span><br><span class="line">yxp2 = diff(yxp,x);		<span class="comment">%二阶导函数表达式</span></span><br><span class="line">x_old = <span class="number">-19</span>;iter = <span class="number">0</span>;	<span class="comment">%迭代初始值与迭代次数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>)</span><br><span class="line">   iter = iter + <span class="number">1</span>;</span><br><span class="line">   x_new = x_old - double(subs(yxp, x, x_old) / subs(yxp2, x, x_old));</span><br><span class="line">   <span class="keyword">if</span>(<span class="built_in">abs</span>(x_new-x_old)&lt;<span class="number">1e-8</span>)</span><br><span class="line">       <span class="keyword">break</span></span><br><span class="line">   <span class="keyword">end</span></span><br><span class="line">   x_old = x_new;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">disp</span>([iter, x_new, yx(x_new)]);</span><br></pre></td></tr></table></figure>
<h1 id="非线性方程组Matlab求解"><a href="#非线性方程组Matlab求解" class="headerlink" title="非线性方程组Matlab求解"></a>非线性方程组Matlab求解</h1><p>求解非线性方程或方程组，除了单调函数二分法、光滑函数牛顿法外，还可以使用MATLAB函数进行求解，主要有以下两种形式：</p>
<ul>
<li><p><code>[x,fval]=fzero(fun,x0)</code>将以$x_0$为初值，尝试寻找函数句柄或匿名函数<code>fun</code>的一个零点，<code>fval</code>为对应函数值</p>
</li>
<li><p><code>[x,fval]=fsolve(fun,x0)</code>将以$x_0$为初值(向量)，尝试寻找函数向量<code>fun</code>的一个零点，<code>fval</code>为对应函数向量值</p>
</li>
</ul>
<p>例：求 $f(t)=sin^2t·e^{-0.1t}-0.5|t|$ 的零点，代码如下：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="comment">% solve函数求解</span></span><br><span class="line">syms t;</span><br><span class="line">ft=<span class="built_in">sin</span>(t)^<span class="number">2</span>*<span class="built_in">exp</span>(<span class="number">-0.1</span>*t)<span class="number">-0.5</span>*<span class="built_in">abs</span>(t);</span><br><span class="line">S = solve(ft, t);</span><br><span class="line">ftS=subs(ft,t,S);</span><br><span class="line"><span class="built_in">disp</span>([S, ftS]);</span><br><span class="line"></span><br><span class="line"><span class="comment">% 作图观察</span></span><br><span class="line">y_C=@(t) <span class="built_in">sin</span>(t).^<span class="number">2.</span>*<span class="built_in">exp</span>(<span class="number">-0.1</span>*t)<span class="number">-0.5</span>*<span class="built_in">abs</span>(t); <span class="comment">%函数句柄形式的定义</span></span><br><span class="line">t=<span class="number">-10</span>:<span class="number">0.01</span>:<span class="number">10</span>;	Y=y_C(t);	<span class="comment">%句柄很多时候可以跟函数名一样使用</span></span><br><span class="line">clf,<span class="built_in">plot</span>(t,Y,<span class="string">'r'</span>);<span class="built_in">hold</span> on</span><br><span class="line"><span class="built_in">plot</span>(t,<span class="built_in">zeros</span>(<span class="built_in">size</span>(t)),<span class="string">'k'</span>);	<span class="comment">%另画一条黑色0函数曲线</span></span><br><span class="line">xlabel(<span class="string">'t'</span>);ylabel(<span class="string">'y(t)'</span>)</span><br><span class="line"><span class="built_in">hold</span> off  </span><br><span class="line"></span><br><span class="line"><span class="comment">% 观察零点位置</span></span><br><span class="line">zoom on		<span class="comment">%鼠标拉出方框，将方框选定区域放大</span></span><br><span class="line">[tt,yy]=ginput(<span class="number">5</span>);	<span class="comment">%鼠标点击五个位置（零点近似值），并记录坐标</span></span><br><span class="line">zoom off		<span class="comment">%回到正常比例</span></span><br></pre></td></tr></table></figure>
<h1 id="多元函数最优化"><a href="#多元函数最优化" class="headerlink" title="多元函数最优化"></a>多元函数最优化</h1><p>例：求$f(x,y)=100(y-x^2)^2+(1-x)^2$的极小值点，代码如下：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">ff=@(x)(<span class="number">100</span>*(x(<span class="number">2</span>)-x(<span class="number">1</span>)^<span class="number">2</span>)^<span class="number">2</span>+(<span class="number">1</span>-x(<span class="number">1</span>))^<span class="number">2</span>);</span><br><span class="line"><span class="comment">%函数句柄，x为输入的(行或列)向量,利用两个元素分别进行计算</span></span><br><span class="line">syms x y,ezsurfc(ff([x,y]),[<span class="number">-2</span>,<span class="number">2</span>,<span class="number">-2</span>,<span class="number">2</span>]) <span class="comment">%将横纵坐标x,y认定为ff二维自定义变量，即可进行surfc操作  </span></span><br><span class="line">format short g <span class="comment">%五位有效数字，省略小数点后尾数的0</span></span><br><span class="line">x0=[<span class="number">-5</span>,<span class="number">-2</span>,<span class="number">2</span>,<span class="number">5</span>;<span class="number">-5</span>,<span class="number">-2</span>,<span class="number">2</span>,<span class="number">5</span>]; <span class="comment">%设立4种不同的搜索起点（每一种为列向量）</span></span><br><span class="line">[sx,sfval,sexit,soutput]=fminsearch(ff,x0)</span><br><span class="line"><span class="comment">%收敛到了四种不同的解，但仅有第一个x=1,y=1是正确的</span></span><br><span class="line">format short e <span class="comment">%短科学计数法</span></span><br><span class="line"><span class="built_in">disp</span>([ff(sx(:,<span class="number">1</span>)),ff(sx(:,<span class="number">2</span>)),ff(sx(:,<span class="number">3</span>)),ff(sx(:,<span class="number">4</span>))]) </span><br><span class="line"><span class="comment">%比较四个极小值点对应的函数值，显然第一个点为四个极小值点中取最小值的 </span></span><br><span class="line"></span><br><span class="line">clear,clc</span><br><span class="line">ff=@(x) (<span class="number">100</span>*(x(<span class="number">2</span>)-x(<span class="number">1</span>)^<span class="number">2</span>)^<span class="number">2</span>+(<span class="number">1</span>-x(<span class="number">1</span>))^<span class="number">2</span>); <span class="comment">%匿名函数需以向量为变量</span></span><br><span class="line">x0=[<span class="number">5</span>,<span class="number">5</span>];                		<span class="comment">%仅接受一种初值计算，以5,5为例</span></span><br><span class="line">options = optimoptions(@fminunc,<span class="string">'OptimalityTolerance'</span>,<span class="number">1e-8</span>);</span><br><span class="line"><span class="comment">%设置迭代的终止条件，以确保误差小于1e-8（默认1e-6）</span></span><br><span class="line">[x,fval] = fminunc(ff,x0,options)</span><br><span class="line"><span class="comment">%求解（前述四种初值点均可以成功找到准确的解）</span></span><br></pre></td></tr></table></figure>
<h3 id="梯度下降法求解多元最小值问题"><a href="#梯度下降法求解多元最小值问题" class="headerlink" title="梯度下降法求解多元最小值问题"></a>梯度下降法求解多元最小值问题</h3><p>将一元最优化问题推广到多元问题$\text{argmin}_{x\in \mathbb{R}^n}\phi(x)$，设$\phi(x)$满足一定的光滑性且其梯度除极值点外不为0向量。则 $\phi(x)$在$x=x^{(k)}$ 下降最快的方向为其负梯度方向：$\boldsymbol{p}^{(k)}=-\nabla \varphi\left(x^{(k)}\right)$。</p>
<p>因此对于凸问题，只需按$x^{(k+1)}=x^{(k)}+\lambda p^{(k)}$进行迭代即可无限接近理论最小值，其中$\lambda&gt;\mathbf{0}$为待定步长。对于非凸问题，迭代有可能会收敛到某个<strong>局部最小值</strong>。</p>
<p>对于多元情形：</p>
<ul>
<li><p>多元问题同样存在最速下降法，不过有时由于最佳步长计算复杂，也可能用固定步长$λ$代替。</p>
</li>
<li><p>多元问题是否为凸问题，等价于目标函数$φ(x)$的Hesse矩阵是否半正定的判定问题。</p>
</li>
</ul>
<p>例：用梯度下降法求$f(x,y)=100(y-x^2)^2+(1-x)^2$的极小值点，代码如下：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">clear,clc</span><br><span class="line">ff=@(x,y) (<span class="number">100</span>*(y-x^<span class="number">2</span>)^<span class="number">2</span>+(<span class="number">1</span>-x)^<span class="number">2</span>);<span class="comment">%函数及其导数</span></span><br><span class="line">dff =@(x,y) [<span class="number">2</span>*x - <span class="number">400</span>*x*(- x^<span class="number">2</span> + y) - <span class="number">2</span>;- <span class="number">200</span>*x^<span class="number">2</span> + <span class="number">200</span>*y];</span><br><span class="line">x0 = <span class="number">-5</span>; y0 = <span class="number">-2</span>;			<span class="comment">%初始条件（可改变）	</span></span><br><span class="line">x_old = x0;y_old = y0;iter=<span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>)</span><br><span class="line">    iter = iter+<span class="number">1</span>;</span><br><span class="line">    Grad = dff(x_old,y_old);	<span class="comment">%梯度方向的获得</span></span><br><span class="line">    lsf = @(lambda) ff(x_old-lambda*Grad(<span class="number">1</span>),y_old-lambda*Grad(<span class="number">2</span>));		<span class="comment">%生成对应方向关于步长的一元函数</span></span><br><span class="line">    [lambda,~]=fminbnd(lsf,<span class="number">0</span>,<span class="number">10</span>);<span class="comment">%搜索最佳步长</span></span><br><span class="line">    x_new=x_old-lambda*Grad(<span class="number">1</span>);</span><br><span class="line">    y_new=y_old-lambda*Grad(<span class="number">2</span>);</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">abs</span>(x_new-x_old)&lt;<span class="number">1e-8</span> &amp;&amp; <span class="built_in">abs</span>(y_new-y_old)&lt;<span class="number">1e-8</span>) 		 <span class="keyword">break</span>; <span class="comment">%当x与y均保持稳定时结束迭代</span></span><br><span class="line">    <span class="keyword">end</span>			</span><br><span class="line">    x_old = x_new;y_old = y_new;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">iter,x_new,y_new</span><br><span class="line">err = ff(x_new,y_new)<span class="number">-0</span></span><br></pre></td></tr></table></figure>
<p>本题使用的最速梯度下降法，虽然速度较慢，但在迭代的收敛性和准确性上，均优于基于单纯形法的MATLAB函数<code>fminsearch</code>，速度上不如新函数<code>fminunc</code></p>
<h3 id="牛顿法解多元最小值问题"><a href="#牛顿法解多元最小值问题" class="headerlink" title="牛顿法解多元最小值问题"></a>牛顿法解多元最小值问题</h3><p>多元问题$\text{argmin}_{x\in \mathbb{R}^n}\phi(x)$在使用最速梯度下降法求解时，由于相邻迭代的梯度方向正交，导致移动方向呈现锯齿型，收敛速度与效率不佳。且对于病态矩阵无健壮性。</p>
<p>定义Hesse矩阵 :</p>
<script type="math/tex; mode=display">
\nabla^{2} f(x, y)=\left[\begin{array}{ll}
\frac{\partial^{2} f}{\partial x^{2}} & \frac{\partial^{2} f}{\partial x \partial y} \\
\frac{\partial^{2} f}{\partial x \partial y} & \frac{\partial^{2} f}{\partial y^{2}}
\end{array}\right]</script><p>多元问题 $argmin_{x \in \mathbb{R}^{n}} \varphi(x)$ 的牛顿迭代公 式为 (注意矩阵相乘后方向可能改变) :</p>
<script type="math/tex; mode=display">
x^{(k+1)}=x^{(k)}-\left.\left(\nabla^{2} f(x, y)\right)^{-1} \nabla f(x, y)\right|_{x^{(k)}}</script><p>牛顿法的一个缺点即Hessian不能出现不可逆的点。但此方法既可以增加收敛的概率，也可以大大减少运行时间。</p>
<p>例：用牛顿法求$f(x,y)=100(y-x^2)^2+(1-x)^2$的极小值点，代码如下：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">clear,clc</span><br><span class="line">ff=@(x,y) (<span class="number">100</span>*(y-x^<span class="number">2</span>)^<span class="number">2</span>+(<span class="number">1</span>-x)^<span class="number">2</span>); </span><br><span class="line">hidff =@(x,y) [ (x - <span class="number">1</span>)/(<span class="number">200</span>*x^<span class="number">2</span> - <span class="number">200</span>*y + <span class="number">1</span>), -(<span class="number">200</span>*x^<span class="number">4</span> - <span class="number">400</span>*x^<span class="number">2</span>*y - x^<span class="number">2</span> + <span class="number">2</span>*x + <span class="number">200</span>*y^<span class="number">2</span> - y)/(<span class="number">200</span>*x^<span class="number">2</span> - <span class="number">200</span>*y + <span class="number">1</span>)];</span><br><span class="line"><span class="comment">%提前计算的迭代步长，即inv(Hessian)*Gradient</span></span><br><span class="line">x0 = <span class="number">-5</span>; y0 = <span class="number">-5</span>;x_old = x0;y_old = y0;iter=<span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>)</span><br><span class="line">    iter = iter+<span class="number">1</span>;</span><br><span class="line">    p = hidff(x_old,y_old);    </span><br><span class="line">    x_new=x_old-p(<span class="number">1</span>);    y_new=y_old-p(<span class="number">2</span>);</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">abs</span>(x_new-x_old)&lt;<span class="number">1e-8</span> &amp;&amp; <span class="built_in">abs</span>(y_new-y_old)&lt;<span class="number">1e-8</span>) <span class="keyword">break</span>; <span class="keyword">end</span></span><br><span class="line">    x_old = x_new;y_old = y_new;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">iter,x_new,y_new</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Matlab</category>
      </categories>
  </entry>
  <entry>
    <title>matlab/Matlab数值线性代数</title>
    <url>/posts/60f341b.html</url>
    <content><![CDATA[<h1 id="矩阵分析"><a href="#矩阵分析" class="headerlink" title="矩阵分析"></a>矩阵分析</h1><h3 id="函数概览"><a href="#函数概览" class="headerlink" title="函数概览"></a>函数概览</h3><div class="table-container">
<table>
<thead>
<tr>
<th>函数调用方式</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>det(A)</code></td>
<td>计算A的行列式</td>
</tr>
<tr>
<td><code>diag(A)</code></td>
<td>取A对角元构成向量或利用向量A生成对角阵</td>
</tr>
<tr>
<td><code>expm(A)</code></td>
<td>计算A的矩阵指数运算</td>
</tr>
<tr>
<td><code>inv(A)</code></td>
<td>计算A的逆矩阵</td>
</tr>
<tr>
<td><code>rank(A)</code></td>
<td>计算A的秩</td>
</tr>
<tr>
<td><code>tril(A)</code></td>
<td>将A化为下三角矩阵（其余元素变为0）</td>
</tr>
<tr>
<td><code>[V D]=eig(A)</code></td>
<td>计算A的特征值保存到D，特征向量保存到V</td>
</tr>
<tr>
<td><code>[V J]=jordan(A)</code></td>
<td>计算A的jordan分解，$AV=VJ$</td>
</tr>
<tr>
<td><code>[U S V]=svd(A)</code></td>
<td>计算A的奇异值分解,$A=USV’$</td>
</tr>
<tr>
<td><code>[L U]=lu(A)</code></td>
<td>计算A的LU分解，$A=LU$</td>
</tr>
<tr>
<td><code>[Q R]=qr(A)</code></td>
<td>计算A的QR分解,$A=QR$</td>
</tr>
</tbody>
</table>
</div>
<h3 id="矩阵的范数"><a href="#矩阵的范数" class="headerlink" title="矩阵的范数"></a>矩阵的范数</h3><ol>
<li><p><code>norm(A)</code>：用于计算矩阵的$2-$范数（也称为谱范数），定义为：</p>
<script type="math/tex; mode=display">||A||_2 = \text{max}_{||x||_2=1}||Ax||_2 = \sqrt{\lambda_{max}(A^TA)}</script></li>
<li><p><code>norm(A, &#39;fro&#39;)</code>：用于计算矩阵的Frobenius范数，即把矩阵拉成一个长向量，再计算其2-向量范数，常用于矩阵的误差分析，定义为：</p>
<script type="math/tex; mode=display">||A||_F=\sqrt{\sum_i(A^TA)_{i,i}} = \sqrt{\text{trace}(A^TA)}</script></li>
<li><p><code>norm(A, 1)</code>：用于计算矩阵的$1-$范数，也称列范数</p>
<script type="math/tex; mode=display">||A||_1 = \text{max}_{||x||_1=1}||Ax||_1 = \text{max}_{1\le j\le n}\sum_{i=1}^m|a_{ij}|</script><p>其中向量$x$的1-范数为向量$x$所有元素绝对值的和</p>
</li>
<li><p><code>norm(A, inf)</code>：用于计算矩阵的$\infty-$范数，也称行范数</p>
<script type="math/tex; mode=display">||A||_{\infty} = \text{max}_{||x||\infty=1}||Ax||_\infty=\text{max}_{1\le  i\le m}\sum_{j=1}^n|a_{ij}|</script><p>其中向量$x$的$\infty$范数即$x$所有元素的最大绝对值</p>
</li>
<li><p><code>sum(sum(A~=0.0))</code>：计算矩阵的$0-$范数（注意这并不是真正的范数），含义为矩阵A的非零元素的个数，记为</p>
<script type="math/tex; mode=display">||A||_0 = \#(A_{ij}\ne0)</script><p>$0-$范数是对矩阵稀疏性的一种最直接、最准确的度量</p>
</li>
<li><p><code>[U S V] = svd(A); norm(diag(S), 1)</code>：计算矩阵的核范数（矩阵A的所有奇异值之和），对核范数的约束是低<br>秩逼近与低秩求解最常用的方法，定义为：</p>
<script type="math/tex; mode=display">||A||_* = \sum_{i=1}^n\sqrt{\lambda_i(A^TA)}</script></li>
</ol>
<h3 id="低秩约束实例"><a href="#低秩约束实例" class="headerlink" title="低秩约束实例"></a>低秩约束实例</h3><ol>
<li><p><strong>强制降秩去噪模型</strong>：通过获取截取主成分来降秩，例如</p>
<script type="math/tex; mode=display">\text{min}_{A^*}||A^*-B||_F</script><script type="math/tex; mode=display">s.t. \text{ rank}(A^*)\le3</script></li>
<li><p><strong>低秩惩罚项模型</strong>：通过对参数$λ&gt;0$的大小调整，以及矩阵本身奇异值与0的逼近程度来自动控制降秩的幅度</p>
<script type="math/tex; mode=display">\text{min}_{A^*}||A^*-B||_F^2+\lambda \text{ rank}(A^*)</script><p>设$A^*$的奇异值为$\bold{\sigma}=[\sigma_1, \sigma_2, … ,\sigma_n]^T$，该模型还可以表示为：</p>
<script type="math/tex; mode=display">\text{min}_{A^*}||A^*-B||_F^2+\lambda ||\sigma||_0</script></li>
<li><p><strong>松弛化低秩惩罚项模型</strong>：为了使模型具有更好的收敛性，可以将奇异值的$ℓ_0$范数更改为$ℓ_1$范数，对应以下模型</p>
<script type="math/tex; mode=display">\text{min}_{A^*}||A^*-B||_F^2+\lambda ||A||_*</script></li>
<li><p>半正定核范数正则化问题，在 $𝑨∗$半正定时，其核范数等于迹：</p>
<script type="math/tex; mode=display">\text{min}_{A^*}||A^*-B||_F^2+\lambda \text{ trace}(A)</script></li>
</ol>
<h3 id="矩阵标量特征的验证"><a href="#矩阵标量特征的验证" class="headerlink" title="矩阵标量特征的验证"></a>矩阵标量特征的验证</h3><h5 id="同阶方阵或“内维”相等的矩阵相乘，交换次序迹不变"><a href="#同阶方阵或“内维”相等的矩阵相乘，交换次序迹不变" class="headerlink" title="同阶方阵或“内维”相等的矩阵相乘，交换次序迹不变"></a>同阶方阵或“内维”相等的矩阵相乘，交换次序迹不变</h5><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">A = <span class="built_in">rand</span>(<span class="number">3</span>, <span class="number">3</span>); B = <span class="built_in">rand</span>(<span class="number">3</span>, <span class="number">3</span>); C = <span class="built_in">rand</span>(<span class="number">3</span>, <span class="number">4</span>); D = <span class="built_in">rand</span>(<span class="number">4</span>, <span class="number">3</span>);</span><br><span class="line">tAB = trace(A*B); tBA = trace(B*A);</span><br><span class="line">tCD = trace(C*D); tDC = trace(D*C);</span><br><span class="line"><span class="built_in">disp</span>([tAB, tBA, tCD, tDC])</span><br></pre></td></tr></table></figure>
<h5 id="经典代数结论-AB-BA-A-·-B"><a href="#经典代数结论-AB-BA-A-·-B" class="headerlink" title="经典代数结论$|AB| = |BA| = |A|·|B|$"></a>经典代数结论$|AB| = |BA| = |A|·|B|$</h5><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">d_A_B = det(A)*det(B);</span><br><span class="line">d_AB = det(A*B); d_BA = det(B*A);</span><br><span class="line">d_CD = det(C*D); d_DC = det(D*C);</span><br><span class="line"><span class="built_in">disp</span>([d_A_B, d_AB, d_BA, d_CD, d_DC])</span><br></pre></td></tr></table></figure>
<p>需要注意到：内维相等的矩阵相乘交换次序行列式可能会改变</p>
<h3 id="矩阵变换与特征值分解"><a href="#矩阵变换与特征值分解" class="headerlink" title="矩阵变换与特征值分解"></a>矩阵变换与特征值分解</h3><ul>
<li><p><code>[R,ci] = rref(A)</code>实现初等变换将$A$化为行阶梯型矩阵,其中$R$储存了行阶梯型的矩阵，$ci$表示阶梯元素(线性独立)的列指标</p>
</li>
<li><p><code>null(A)</code> 得到 A 的零空间（核）的一组标准正交基</p>
</li>
<li><code>orth(A)</code>得到 A 的值空间（像）的一组标准正交基</li>
</ul>
<p><strong><code>rref</code> 化矩阵为行阶梯型矩阵</strong></p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">A = <span class="built_in">magic</span>(<span class="number">4</span>);</span><br><span class="line">[R, ci] = rref(A)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">R &#x3D;</span><br><span class="line"></span><br><span class="line">     1     0     0     1</span><br><span class="line">     0     1     0     3</span><br><span class="line">     0     0     1    -3</span><br><span class="line">     0     0     0     0</span><br><span class="line"></span><br><span class="line">ci &#x3D;</span><br><span class="line"></span><br><span class="line">     1     2     3</span><br></pre></td></tr></table></figure>
<p>上述结果意为A的秩等于3，行阶梯型共有3层，阶梯元素在前三列</p>
<h5 id="矩阵零空间及其含义"><a href="#矩阵零空间及其含义" class="headerlink" title="矩阵零空间及其含义"></a>矩阵零空间及其含义</h5><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">A = <span class="built_in">reshape</span>(<span class="number">1</span>:<span class="number">15</span>,<span class="number">5</span>,<span class="number">3</span>);</span><br><span class="line">X = null(A);            <span class="comment">% 零空间向量</span></span><br><span class="line">S = A * X;              <span class="comment">% 代入后应该得到零向量</span></span><br><span class="line">n=<span class="built_in">size</span>(A,<span class="number">2</span>);			<span class="comment">% A的列数</span></span><br><span class="line">l=<span class="built_in">size</span>(X,<span class="number">2</span>);			<span class="comment">% X的列数（即零空间维数）		</span></span><br><span class="line">n-l==rank(A)			<span class="comment">% 判断矩阵秩是否等于（列数-零空间维数）</span></span><br></pre></td></tr></table></figure>
<p>返回结果为<code>logical 1</code></p>
<h5 id="实矩阵的特征值分解"><a href="#实矩阵的特征值分解" class="headerlink" title="实矩阵的特征值分解"></a>实矩阵的特征值分解</h5><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">A=[<span class="number">1</span>, <span class="number">-3</span> ;<span class="number">2</span>, <span class="number">2</span>/<span class="number">3</span>];</span><br><span class="line">[V,D]=eig(A);            <span class="comment">% 该矩阵有两个复特征根(D对角元)，V为列特征向量构成的矩阵</span></span><br><span class="line">[VR,DR]=cdf2rdf(V,D);    <span class="comment">% 将复数对角型转换为实数块对角型(VR*DR/VR=A)</span></span><br><span class="line">A1 = <span class="built_in">real</span>(V*D/V);</span><br><span class="line">A2 = VR*DR/VR;</span><br><span class="line"><span class="built_in">disp</span>([A1, A2]);</span><br><span class="line">err1 = norm(A-A1, <span class="string">'fro'</span>);</span><br><span class="line">err2 = norm(A-A2, <span class="string">'fro'</span>);</span><br><span class="line"><span class="built_in">disp</span>([err1, err2]);</span><br></pre></td></tr></table></figure>
<h1 id="Matlab解线性方程组"><a href="#Matlab解线性方程组" class="headerlink" title="Matlab解线性方程组"></a>Matlab解线性方程组</h1><p><code>A\b</code>是Matlab最高效的解线性方程组的內建函数，<code>A\B</code>可解矩阵方程。</p>
<p>Matlab对于矩阵A列满秩且有解的情况将提供唯一解，对A列不满秩且有解的情况将随机提供一个解。无解问题将提供最小二乘解。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">A = <span class="built_in">reshape</span>(<span class="number">1</span>:<span class="number">12</span>, <span class="number">4</span>, <span class="number">3</span>);</span><br><span class="line">b = (<span class="number">13</span>:<span class="number">16</span>)';</span><br><span class="line">ra = rank(A); rab = rank([A, b]);</span><br><span class="line"><span class="built_in">disp</span>([ra, rab]);</span><br><span class="line">xs = A\b;										<span class="comment">%求出方程组一个特解记为xs</span></span><br><span class="line">xg = null(A);									<span class="comment">%求对应齐次方程零空间（基础解系）</span></span><br><span class="line">c = <span class="built_in">rand</span>(<span class="number">1</span>);</span><br><span class="line">ba = A*(xs+c*xg);								<span class="comment">%检验任意特解+对应齐次特解是否符合方程组</span></span><br><span class="line">norm(ba-b)										<span class="comment">%向量2-范数的误差分析,新版本误差变小</span></span><br></pre></td></tr></table></figure>
<h5 id="函数Inv与左右除"><a href="#函数Inv与左右除" class="headerlink" title="函数Inv与左右除"></a>函数Inv与左右除</h5><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">rng default</span><br><span class="line">format</span><br><span class="line">A = <span class="built_in">gallery</span>(<span class="string">'randsvd'</span>, <span class="number">300</span>, <span class="number">2e13</span>, <span class="number">2</span>);</span><br><span class="line">x = <span class="built_in">ones</span>(<span class="number">300</span>, <span class="number">1</span>);</span><br><span class="line">b = A * x;</span><br><span class="line">cond(A);</span><br><span class="line"></span><br><span class="line">tic							</span><br><span class="line">xi = inv(A)*b;				<span class="comment">% 先求逆，再相乘浪费时间</span></span><br><span class="line">ti = toc;					<span class="comment">% 将当前计时存储在变量ti中</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">eri = norm(x-xi);			<span class="comment">% 计算解的绝对误差</span></span><br><span class="line">rei = norm(A*xi-b)/norm(b);	<span class="comment">% 计算回代相对误差</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">disp</span>([cond(A)]);            <span class="comment">% 2.0040e+13</span></span><br><span class="line"><span class="built_in">disp</span>([ti, eri, rei])        <span class="comment">% 0.0016    0.1032    0.0048</span></span><br></pre></td></tr></table></figure>
<h3 id="线性方程组的数值迭代法"><a href="#线性方程组的数值迭代法" class="headerlink" title="线性方程组的数值迭代法"></a>线性方程组的数值迭代法</h3><p>从最初的线性方程组<code>Ax=b</code>出发，首先令$A=M-N$，然后有$Mx=Nx+b$，即$x=M^{-1}Nx+M^{-1}b = Bx+f$</p>
<p>数值迭代法会将上述等式右边的<code>x</code>代入上一步的解向量，从而得出下一步的解向量，如：</p>
<script type="math/tex; mode=display">x^{k+1} = Bx^{k}+f</script><p>这种算法在$||B||&lt;1$的情况可保持收敛性，根据$M,N$的不同选取，可以衍生出不同的基本迭代算法。</p>
<h3 id="雅可比迭代法"><a href="#雅可比迭代法" class="headerlink" title="雅可比迭代法"></a>雅可比迭代法</h3><p>采用矩阵分裂记号：$A = D-L-U$，并有$M=D, N = L+U$，其中$D$为对角阵，$L$为下三角阵，$U$为上三角阵。雅可比迭代法的矩阵表现形式为</p>
<script type="math/tex; mode=display">x^{(k+1)} = D^{-1}(L+U)x^{(k)} + D^{-1}b = B_Jx^{(k)} + f</script><p>雅可比迭代法数值实现：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">rng default</span><br><span class="line">A=<span class="built_in">rand</span>(<span class="number">400</span>,<span class="number">400</span>)+<span class="number">5e2</span>*<span class="built_in">eye</span>(<span class="number">400</span>); </span><br><span class="line"><span class="comment">%雅可比迭代法需要对角元明显大于其他元素，否则一旦||B||&gt;=1就会使算法不收敛</span></span><br><span class="line">x=<span class="built_in">rand</span>(<span class="number">400</span>,<span class="number">1</span>);      </span><br><span class="line">b=A*x;  </span><br><span class="line">D=<span class="built_in">diag</span>(<span class="built_in">diag</span>(A));	<span class="comment">%取出A的对角元</span></span><br><span class="line">N = D-A;		<span class="comment">%N=L+U=D-A</span></span><br><span class="line">B = D\N; f = D\b;	<span class="comment">%x=Bx+f雏形已确定</span></span><br><span class="line"></span><br><span class="line">x_old = <span class="built_in">zeros</span>(<span class="number">400</span>,<span class="number">1</span>);<span class="comment">%迭代初值设为0向量</span></span><br><span class="line">err = <span class="number">1e12</span>;		 <span class="comment">%初始误差假设很大	</span></span><br><span class="line">iter = <span class="number">0</span>;		 <span class="comment">%记录总迭代次数</span></span><br><span class="line"><span class="keyword">while</span>(err&gt;<span class="number">1e-6</span>)	 <span class="comment">%当相邻两步绝对误差不超过1e-6迭代即结束</span></span><br><span class="line">    iter = iter + <span class="number">1</span>;</span><br><span class="line">    x_new = B*x_old + f;</span><br><span class="line">    err = norm(x_new-x_old);<span class="comment">%记录该步结果与上一步结果的最新绝对误差</span></span><br><span class="line">    x_old = x_new;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="built_in">disp</span>(iter);                             <span class="comment">%共迭代19次</span></span><br><span class="line">err = norm(x_new-x)				 <span class="comment">%最终绝对误差</span></span><br></pre></td></tr></table></figure>
<h3 id="变分法解线性方程组"><a href="#变分法解线性方程组" class="headerlink" title="变分法解线性方程组"></a>变分法解线性方程组</h3><p>定义$\phi(x) = \frac12x^TAx-b^Tx$，则线性方程组$Ax=b$的解集等于 $\text{argmin}_{x\in \mathbb{R}^n}\phi(x)$的解集，<strong>将线性方程组求解问题转化为最优化问题的方法，称为变分法</strong></p>
<p>由于矩阵A的正定性，最优化问题$\text{argmin}_{x\in \mathbb{R}^n}\phi(x)$为一个向量空间的凸问题，凸问题仅有一个全局最优解，可以通过梯度下降法求解。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">rng default,A0 = <span class="built_in">rand</span>(<span class="number">300</span>,<span class="number">300</span>);</span><br><span class="line">A=A0+A0'+<span class="number">1e3</span>*<span class="built_in">eye</span>(<span class="number">300</span>);	<span class="comment">% A为一个随机的正定矩阵即可</span></span><br><span class="line"><span class="comment">% 在很多实际问题中，比雅可比，高斯-塞德尔方法更加可行</span></span><br><span class="line">x=<span class="built_in">rand</span>(<span class="number">300</span>,<span class="number">1</span>);			</span><br><span class="line">b=A*x;	</span><br><span class="line"></span><br><span class="line">x_old = <span class="built_in">zeros</span>(<span class="number">300</span>,<span class="number">1</span>);	<span class="comment">% 初始迭代值仍设为0向量</span></span><br><span class="line">err = <span class="number">1e12</span>;</span><br><span class="line">iter = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(err&gt;<span class="number">1e-6</span>)		<span class="comment">% 相邻两步误差不超过1e-6则终止迭代</span></span><br><span class="line">    iter = iter + <span class="number">1</span>;</span><br><span class="line">    p = b - A*x_old;		<span class="comment">% 迭代方向（目标函数负梯度）</span></span><br><span class="line">    lambda = (p'*p)/((A*p)'*p); <span class="comment">% 最速迭代步长</span></span><br><span class="line">    x_new = x_old + lambda*p;</span><br><span class="line">    err = norm(x_new-x_old);<span class="comment">% 统计迭代当前步的误差</span></span><br><span class="line">    x_old = x_new;</span><br><span class="line"><span class="keyword">end</span>					</span><br><span class="line">err = norm(x_new-x)      	<span class="comment">% 最终绝对误差    9.2710e-08</span></span><br><span class="line">iter                        <span class="comment">% 循环次数		 8</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>matlab</category>
      </categories>
  </entry>
  <entry>
    <title>天池金融风控入门赛</title>
    <url>/posts/790172fa.html</url>
    <content><![CDATA[<h2 id="Task1-赛题理解"><a href="#Task1-赛题理解" class="headerlink" title="Task1 赛题理解"></a>Task1 赛题理解</h2><p>Tip:本次新人赛是Datawhale与天池联合发起的0基础入门系列赛事第四场 —— 零基础入门金融风控之贷款违约预测挑战赛。 赛题以金融风控中的个人信贷为背景，要求选手根据贷款申请人的数据信息预测其是否有违约的可能，以此判断是否通过此项贷款，这是一个典型的分类问题。通过这道赛题来引导大家了解金融风控中的一些业务背景，解决实际问题，帮助竞赛新人进行自我练习、自我提高。</p>
<p>项目地址：<a href="https://github.com/datawhalechina/team-learning-data-mining/tree/master/FinancialRiskControl" target="_blank" rel="noopener">https://github.com/datawhalechina/team-learning-data-mining/tree/master/FinancialRiskControl</a></p>
<p>比赛地址：<a href="https://tianchi.aliyun.com/competition/entrance/531830/introduction" target="_blank" rel="noopener">https://tianchi.aliyun.com/competition/entrance/531830/introduction</a></p>
<h3 id="1-1-学习目标"><a href="#1-1-学习目标" class="headerlink" title="1.1 学习目标"></a>1.1 学习目标</h3><p>理解赛题数据和目标，清楚评分体系。</p>
<p>完成相应报名，下载数据和结果提交打卡（可提交示例结果），熟悉比赛流程</p>
<h3 id="1-2-了解赛题"><a href="#1-2-了解赛题" class="headerlink" title="1.2 了解赛题"></a>1.2 了解赛题</h3><ul>
<li>赛题概况</li>
<li>数据概况</li>
<li>预测指标</li>
<li>分析赛题</li>
</ul>
<h3 id="1-2-1-赛题概况"><a href="#1-2-1-赛题概况" class="headerlink" title="1.2.1 赛题概况"></a>1.2.1 赛题概况</h3><h5 id="比赛要求参赛选手根据给定的数据集，建立模型，预测金融风险。"><a href="#比赛要求参赛选手根据给定的数据集，建立模型，预测金融风险。" class="headerlink" title="比赛要求参赛选手根据给定的数据集，建立模型，预测金融风险。"></a>比赛要求参赛选手根据给定的数据集，建立模型，预测金融风险。</h5><p>赛题以预测金融风险为任务，数据集报名后可见并可下载，该数据来自某信贷平台的贷款记录，总数据量超过120w，包含47列变量信息，其中15列为匿名变量。为了保证比赛的公平性，将会从中抽取80万条作为训练集，20万条作为测试集A，20万条作为测试集B，同时会对employmentTitle、purpose、postCode和title等信息进行脱敏。</p>
<p>通过这道赛题来引导大家走进金融风控数据竞赛的世界，主要针对于于竞赛新人进行自我练习、自我提高。</p>
<h3 id="1-2-2-数据概况"><a href="#1-2-2-数据概况" class="headerlink" title="1.2.2 数据概况"></a>1.2.2 数据概况</h3><p>一般而言，对于数据在比赛界面都有对应的数据概况介绍（匿名特征除外），说明列的性质特征。了解列的性质会有助于我们对于数据的理解和后续分析。 Tip:匿名特征，就是未告知数据列所属的性质的特征列。</p>
<p>train.csv</p>
<ul>
<li>id 为贷款清单分配的唯一信用证标识</li>
<li>loanAmnt 贷款金额</li>
<li>term 贷款期限（year）</li>
<li>interestRate 贷款利率</li>
<li>installment 分期付款金额</li>
<li>grade 贷款等级</li>
<li>subGrade 贷款等级之子级</li>
<li>employmentTitle 就业职称</li>
<li>employmentLength 就业年限（年）</li>
<li>homeOwnership 借款人在登记时提供的房屋所有权状况</li>
<li>annualIncome 年收入</li>
<li>verificationStatus 验证状态</li>
<li>issueDate 贷款发放的月份</li>
<li>purpose 借款人在贷款申请时的贷款用途类别</li>
<li>postCode 借款人在贷款申请中提供的邮政编码的前3位数字</li>
<li>regionCode 地区编码</li>
<li>dti 债务收入比</li>
<li>delinquency_2years 借款人过去2年信用档案中逾期30天以上的违约事件数</li>
<li>ficoRangeLow 借款人在贷款发放时的fico所属的下限范围</li>
<li>ficoRangeHigh 借款人在贷款发放时的fico所属的上限范围</li>
<li>openAcc 借款人信用档案中未结信用额度的数量</li>
<li>pubRec 贬损公共记录的数量</li>
<li>pubRecBankruptcies 公开记录清除的数量</li>
<li>revolBal 信贷周转余额合计</li>
<li>revolUtil 循环额度利用率，或借款人使用的相对于所有可用循环信贷的信贷金额</li>
<li>totalAcc 借款人信用档案中当前的信用额度总数</li>
<li>initialListStatus 贷款的初始列表状态</li>
<li>applicationType 表明贷款是个人申请还是与两个共同借款人的联合申请</li>
<li>earliesCreditLine 借款人最早报告的信用额度开立的月份</li>
<li>title 借款人提供的贷款名称</li>
<li>policyCode 公开可用的策略_代码=1新产品不公开可用的策略_代码=2</li>
<li>n系列匿名特征 匿名特征n0-n14，为一些贷款人行为计数特征的处理</li>
</ul>
<h3 id="1-2-3-预测指标"><a href="#1-2-3-预测指标" class="headerlink" title="1.2.3 预测指标"></a>1.2.3 预测指标</h3><p>竞赛采用AUC作为评价指标。AUC（Area Under Curve）被定义为 ROC曲线 下与坐标轴围成的面积。</p>
<h5 id="分类算法常见的评估指标如下："><a href="#分类算法常见的评估指标如下：" class="headerlink" title="分类算法常见的评估指标如下："></a>分类算法常见的评估指标如下：</h5><p>1、混淆矩阵（Confuse Matrix）</p>
<ul>
<li>（1）若一个实例是正类，并且被预测为正类，即为真正类TP(True Positive )</li>
<li>（2）若一个实例是正类，但是被预测为负类，即为假负类FN(False Negative )</li>
<li>（3）若一个实例是负类，但是被预测为正类，即为假正类FP(False Positive )</li>
<li>（4）若一个实例是负类，并且被预测为负类，即为真负类TN(True Negative )</li>
</ul>
<p>2、准确率（Accuracy） 准确率是常用的一个评价指标，但是不适合样本不均衡的情况。 <script type="math/tex">Accuracy = \frac{TP + TN}{TP + TN + FP + FN}</script></p>
<p>3、精确率（Precision） 又称查准率，正确预测为正样本（TP）占预测为正样本(TP+FP)的百分比。 <script type="math/tex">Precision = \frac{TP}{TP + FP}</script></p>
<p>4、召回率（Recall） 又称为查全率，正确预测为正样本（TP）占正样本(TP+FN)的百分比。 <script type="math/tex">Recall = \frac{TP}{TP + FN}</script></p>
<p>5、F1 Score 精确率和召回率是相互影响的，精确率升高则召回率下降，召回率升高则精确率下降，如果需要兼顾二者，就需要精确率、召回率的结合F1 Score。 <script type="math/tex">F1-Score = \frac{2}{\frac{1}{Precision} + \frac{1}{Recall}}</script></p>
<p>6、P-R曲线（Precision-Recall Curve） P-R曲线是描述精确率和召回率变化的曲线</p>
<p><a href="https://camo.githubusercontent.com/25688baabbff569136e19f04c812ed80af778351/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303230303931333031303232363132352e706e67" target="_blank" rel="noopener"><img src="/Pic/Untitled/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303230303931333031303232363132352e706e67" alt="p-r"></a></p>
<p>7、ROC（Receiver Operating Characteristic）</p>
<ul>
<li>ROC空间将假正例率（FPR）定义为 X 轴，真正例率（TPR）定义为 Y 轴。</li>
</ul>
<p>TPR：在所有实际为正例的样本中，被正确地判断为正例之比率。 <script type="math/tex">TPR = \frac{TP}{TP + FN}</script> FPR：在所有实际为负例的样本中，被错误地判断为正例之比率。 <script type="math/tex">FPR = \frac{FP}{FP + TN}</script></p>
<p><a href="https://camo.githubusercontent.com/2dfea351fa5eac42caab9e716aa76a20553e4103/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303230303931333031303232363132342e706e67" target="_blank" rel="noopener"><img src="/Pic/Untitled/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303230303931333031303232363132342e706e67" alt="roc.png"></a></p>
<p>8、AUC(Area Under Curve) AUC（Area Under Curve）被定义为 ROC曲线 下与坐标轴围成的面积，显然这个面积的数值不会大于1。又由于ROC曲线一般都处于y=x这条直线的上方，所以AUC的取值范围在0.5和1之间。AUC越接近1.0，检测方法真实性越高;等于0.5时，则真实性最低，无应用价值。</p>
<h5 id="对于金融风控预测类常见的评估指标如下"><a href="#对于金融风控预测类常见的评估指标如下" class="headerlink" title="对于金融风控预测类常见的评估指标如下:"></a>对于金融风控预测类常见的评估指标如下:</h5><p>1、KS(Kolmogorov-Smirnov) KS统计量由两位苏联数学家A.N. Kolmogorov和N.V. Smirnov提出。在风控中，KS常用于评估模型区分度。区分度越大，说明模型的风险排序能力（ranking ability）越强。 K-S曲线与ROC曲线类似，不同在于</p>
<ul>
<li>ROC曲线将真正例率和假正例率作为横纵轴</li>
<li>K-S曲线将真正例率和假正例率都作为纵轴，横轴则由选定的阈值来充当。 公式如下： <script type="math/tex">KS=max(TPR-FPR)</script> KS不同代表的不同情况，一般情况KS值越大，模型的区分能力越强，但是也不是越大模型效果就越好，如果KS过大，模型可能存在异常，所以当KS值过高可能需要检查模型是否过拟合。以下为KS值对应的模型情况，但此对应不是唯一的，只代表大致趋势。</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>KS（%）</th>
<th>好坏区分能力</th>
</tr>
</thead>
<tbody>
<tr>
<td>20以下</td>
<td>不建议采用</td>
</tr>
<tr>
<td>20-40</td>
<td>较好</td>
</tr>
<tr>
<td>41-50</td>
<td>良好</td>
</tr>
<tr>
<td>51-60</td>
<td>很强</td>
</tr>
<tr>
<td>61-75</td>
<td>非常强</td>
</tr>
<tr>
<td>75以上</td>
<td>过于高，疑似存在问题</td>
</tr>
</tbody>
</table>
</div>
<p>2、ROC</p>
<p>3、AUC</p>
<h3 id="1-2-4-赛题流程"><a href="#1-2-4-赛题流程" class="headerlink" title="1.2.4. 赛题流程"></a>1.2.4. 赛题流程</h3><p><a href="https://camo.githubusercontent.com/baf3abb3b945608363c4e7a0be0a8a158629463b/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303230303931333031303232363131302e706e67" target="_blank" rel="noopener"><img src="/Pic/Untitled/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303230303931333031303232363131302e706e67" alt="1_1.png"></a></p>
<h3 id="1-3-代码示例"><a href="#1-3-代码示例" class="headerlink" title="1.3 代码示例"></a>1.3 代码示例</h3><p>本部分为对于数据读取和指标评价的示例。</p>
<h3 id="1-3-1-数据读取pandas"><a href="#1-3-1-数据读取pandas" class="headerlink" title="1.3.1 数据读取pandas"></a>1.3.1 数据读取pandas</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">train &#x3D; pd.read_csv(&#39;train.csv&#39;)</span><br><span class="line">testA &#x3D; pd.read_csv(&#39;testA.csv&#39;)</span><br><span class="line">print(&#39;Train data shape:&#39;,train.shape)</span><br><span class="line">print(&#39;TestA data shape:&#39;,testA.shape)</span><br><span class="line">Train data shape: (800000, 47)</span><br><span class="line">TestA data shape: (200000, 48)</span><br><span class="line">train.head()</span><br></pre></td></tr></table></figure>
<style scoped> .dataframe tbody tr th:only-of-type { vertical-align: middle; }

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.dataframe tbody tr th &#123;</span><br><span class="line">    vertical-align: top;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">.dataframe thead th &#123;</span><br><span class="line">    text-align: right;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</style>

<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>id</th>
<th>loanAmnt</th>
<th>term</th>
<th>interestRate</th>
<th>installment</th>
<th>grade</th>
<th>subGrade</th>
<th>employmentTitle</th>
<th>employmentLength</th>
<th>homeOwnership</th>
<th>…</th>
<th>n5</th>
<th>n6</th>
<th>n7</th>
<th>n8</th>
<th>n9</th>
<th>n10</th>
<th>n11</th>
<th>n12</th>
<th>n13</th>
<th>n14</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>35000.0</td>
<td>5</td>
<td>19.52</td>
<td>917.97</td>
<td>E</td>
<td>E2</td>
<td>320.0</td>
<td>2 years</td>
<td>2</td>
<td>…</td>
<td>9.0</td>
<td>8.0</td>
<td>4.0</td>
<td>12.0</td>
<td>2.0</td>
<td>7.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>2.0</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>18000.0</td>
<td>5</td>
<td>18.49</td>
<td>461.90</td>
<td>D</td>
<td>D2</td>
<td>219843.0</td>
<td>5 years</td>
<td>0</td>
<td>…</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>13.0</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
<td>12000.0</td>
<td>5</td>
<td>16.99</td>
<td>298.17</td>
<td>D</td>
<td>D3</td>
<td>31698.0</td>
<td>8 years</td>
<td>0</td>
<td>…</td>
<td>0.0</td>
<td>21.0</td>
<td>4.0</td>
<td>5.0</td>
<td>3.0</td>
<td>11.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>4.0</td>
</tr>
<tr>
<td>3</td>
<td>3</td>
<td>11000.0</td>
<td>3</td>
<td>7.26</td>
<td>340.96</td>
<td>A</td>
<td>A4</td>
<td>46854.0</td>
<td>10+ years</td>
<td>1</td>
<td>…</td>
<td>16.0</td>
<td>4.0</td>
<td>7.0</td>
<td>21.0</td>
<td>6.0</td>
<td>9.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
</tr>
<tr>
<td>4</td>
<td>4</td>
<td>3000.0</td>
<td>3</td>
<td>12.99</td>
<td>101.07</td>
<td>C</td>
<td>C2</td>
<td>54.0</td>
<td>NaN</td>
<td>1</td>
<td>…</td>
<td>4.0</td>
<td>9.0</td>
<td>10.0</td>
<td>15.0</td>
<td>7.0</td>
<td>12.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>4.0</td>
</tr>
</tbody>
</table>
</div>
<p>5 rows × 47 columns</p>
<h3 id="1-3-2-分类指标评价计算示例"><a href="#1-3-2-分类指标评价计算示例" class="headerlink" title="1.3.2 分类指标评价计算示例"></a>1.3.2 分类指标评价计算示例</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## 混淆矩阵</span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn.metrics import confusion_matrix</span><br><span class="line">y_pred &#x3D; [0, 1, 0, 1]</span><br><span class="line">y_true &#x3D; [0, 1, 1, 0]</span><br><span class="line">print(&#39;混淆矩阵:\n&#39;,confusion_matrix(y_true, y_pred))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">混淆矩阵:</span><br><span class="line"> [[1 1]</span><br><span class="line"> [1 1]]</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## accuracy</span><br><span class="line">from sklearn.metrics import accuracy_score</span><br><span class="line">y_pred &#x3D; [0, 1, 0, 1]</span><br><span class="line">y_true &#x3D; [0, 1, 1, 0]</span><br><span class="line">print(&#39;ACC:&#39;,accuracy_score(y_true, y_pred))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ACC: 0.5</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## Precision,Recall,F1-score</span><br><span class="line">from sklearn import metrics</span><br><span class="line">y_pred &#x3D; [0, 1, 0, 1]</span><br><span class="line">y_true &#x3D; [0, 1, 1, 0]</span><br><span class="line">print(&#39;Precision&#39;,metrics.precision_score(y_true, y_pred))</span><br><span class="line">print(&#39;Recall&#39;,metrics.recall_score(y_true, y_pred))</span><br><span class="line">print(&#39;F1-score:&#39;,metrics.f1_score(y_true, y_pred))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Precision 0.5</span><br><span class="line">Recall 0.5</span><br><span class="line">F1-score: 0.5</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## P-R曲线</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from sklearn.metrics import precision_recall_curve</span><br><span class="line">y_pred &#x3D; [0, 1, 1, 0, 1, 1, 0, 1, 1, 1]</span><br><span class="line">y_true &#x3D; [0, 1, 1, 0, 1, 0, 1, 1, 0, 1]</span><br><span class="line">precision, recall, thresholds &#x3D; precision_recall_curve(y_true, y_pred)</span><br><span class="line">plt.plot(precision, recall)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[&lt;matplotlib.lines.Line2D at 0x2170d0d6108&gt;]</span><br></pre></td></tr></table></figure>
<p><a href="https://camo.githubusercontent.com/62cfda126d963927ceafa23a4b218e155a3d2479/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f323032303039313330313032323639362e706e67" target="_blank" rel="noopener"><img src="/Pic/Untitled/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f323032303039313330313032323639362e706e67" alt="png"></a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## ROC曲线</span><br><span class="line">from sklearn.metrics import roc_curve</span><br><span class="line">y_pred &#x3D; [0, 1, 1, 0, 1, 1, 0, 1, 1, 1]</span><br><span class="line">y_true &#x3D; [0, 1, 1, 0, 1, 0, 1, 1, 0, 1]</span><br><span class="line">FPR,TPR,thresholds&#x3D;roc_curve(y_true, y_pred)</span><br><span class="line">plt.title(&#39;ROC&#39;)</span><br><span class="line">plt.plot(FPR, TPR,&#39;b&#39;)</span><br><span class="line">plt.plot([0,1],[0,1],&#39;r--&#39;)</span><br><span class="line">plt.ylabel(&#39;TPR&#39;)</span><br><span class="line">plt.xlabel(&#39;FPR&#39;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Text(0.5, 0, &#39;FPR&#39;)</span><br></pre></td></tr></table></figure>
<p><a href="https://camo.githubusercontent.com/9b838d2ba8dc4c3ea8dd66859499c78a12d7b4e2/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f323032303039313330313032323639352e706e67" target="_blank" rel="noopener"><img src="/Pic/Untitled/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f323032303039313330313032323639352e706e67" alt="roc.png"></a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">## AUC</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line">y_true = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">y_scores = np.array([<span class="number">0.1</span>, <span class="number">0.4</span>, <span class="number">0.35</span>, <span class="number">0.8</span>])</span><br><span class="line">print(<span class="string">'AUC socre:'</span>,roc_auc_score(y_true, y_scores))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">AUC socre: 0.75</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">## KS值 在实际操作时往往使用ROC曲线配合求出KS值</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</span><br><span class="line">y_pred = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line">y_true = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line">FPR,TPR,thresholds=roc_curve(y_true, y_pred)</span><br><span class="line">KS=abs(FPR-TPR).max()</span><br><span class="line">print(<span class="string">'KS值：'</span>,KS)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">KS值： 0.5238095238095237</span><br></pre></td></tr></table></figure>
<h3 id="1-4-经验总结"><a href="#1-4-经验总结" class="headerlink" title="1.4 经验总结"></a>1.4 经验总结</h3><p>赛题理解是开始比赛的第一步，赛题的理解有助于对竞赛全局的把握。通过赛题理解有助于对赛题的业务逻辑把握，对于后期的特征工程构建和模型选择都尤为重要。</p>
<ul>
<li>在开始比赛之前要对赛题进行充分的了解。</li>
<li>比赛什么时候开始，什么时候结束，什么时候换B榜数据。</li>
<li>和该比赛有没有类似的比赛可以参考借鉴。</li>
<li>线上提交结果的次数往往是有限的，提前了解每日可以提交的次数。</li>
<li>比赛使用的是什么评价指标，可以选择相同的评价指标作为线下验证的方式。</li>
</ul>
<h3 id="1-5-拓展知识——评分卡"><a href="#1-5-拓展知识——评分卡" class="headerlink" title="1.5 拓展知识——评分卡"></a>1.5 拓展知识——评分卡</h3><p>评分卡是一张拥有分数刻度会让相应阈值的表。信用评分卡是用于用户信用的一张刻度表。以下代码是一个非标准评分卡的代码流程，用于刻画用户的信用评分。评分卡是金融风控中常用的一种对于用户信用进行刻画的手段哦！</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#评分卡 不是标准评分卡</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Score</span><span class="params">(prob,P0=<span class="number">600</span>,PDO=<span class="number">20</span>,badrate=None,goodrate=None)</span>:</span></span><br><span class="line">    P0 = P0</span><br><span class="line">    PDO = PDO</span><br><span class="line">    theta0 = badrate/goodrate</span><br><span class="line">    B = PDO/np.log(<span class="number">2</span>)</span><br><span class="line">    A = P0 + B*np.log(<span class="number">2</span>*theta0)</span><br><span class="line">    score = A-B*np.log(prob/(<span class="number">1</span>-prob))</span><br><span class="line">    <span class="keyword">return</span> score</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Match</category>
      </categories>
  </entry>
  <entry>
    <title>推荐系统实战（四）—— 电影协同过滤推荐</title>
    <url>/posts/88b8265c.html</url>
    <content><![CDATA[<p>Movielens数据集可以在<a href="http://files.grouplens.org/datasets/movielens/" target="_blank" rel="noopener">这里</a>下载，本文练习均是基于<a href="http://files.grouplens.org/datasets/movielens/ml-latest-small.zip" target="_blank" rel="noopener">ml-latest-small.zip</a>进行，该数据集较小便于单机使用和运行。</p>
<p>学习目标为：</p>
<ul>
<li>根据用户电影评分数据分别实现User-Based和Item-Based并进行电影评分的预测，然后为用户实现电影推荐</li>
</ul>
<h1 id="基于用户相似度的协同过滤实现"><a href="#基于用户相似度的协同过滤实现" class="headerlink" title="基于用户相似度的协同过滤实现"></a>基于用户相似度的协同过滤实现</h1><p>首先导入需要的包：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import os</span><br><span class="line">from pprint import pprint</span><br></pre></td></tr></table></figure>
<p>定义一个从缓存读取数据的函数，当数据量较大时这种方法会极大加速后面的读取速度</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">CACHE_DIR = <span class="string">"datasets/cache/"</span></span><br><span class="line">DATA_PATH = <span class="string">"datasets/ml-latest-small/ratings.csv"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span><span class="params">(data_path)</span>:</span></span><br><span class="line">    cache_path = os.path.join(CACHE_DIR, <span class="string">"ratings_matrix.cache"</span>)</span><br><span class="line">    print(<span class="string">"-----开始加载数据集-----"</span>)</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(cache_path):</span><br><span class="line">        print(<span class="string">"-----加载缓存中-----"</span>)</span><br><span class="line">        ratings_matrix = pd.read_pickle(cache_path)</span><br><span class="line">        print(<span class="string">"-----从缓存加载数据集完毕-----"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">"-----加载新数据中-----"</span>)</span><br><span class="line">        <span class="comment"># 设置加载的数据字段的类型</span></span><br><span class="line">        dtype = &#123;<span class="string">"userId"</span>: np.int32, <span class="string">"movieId"</span>: np.int32, <span class="string">"rating"</span>: np.float32&#125;</span><br><span class="line">        <span class="comment"># 加载数据，暂时只用前三列数据</span></span><br><span class="line">        ratings = pd.read_csv(data_path, dtype=dtype, usecols=range(<span class="number">3</span>))</span><br><span class="line">        <span class="comment"># 转换为评分矩阵</span></span><br><span class="line">        ratings_matrix = rating.pivot_table(index=[<span class="string">"userId"</span>], columns=[<span class="string">"movieId"</span>], values=<span class="string">"rating"</span>)</span><br><span class="line">        <span class="comment"># 存入缓存文件</span></span><br><span class="line">        ratings_matrix.to_pickle(cache_path)</span><br><span class="line">        print(<span class="string">"-----数据集加载完毕-----"</span>)</span><br><span class="line">    <span class="keyword">return</span> ratings_matrix</span><br></pre></td></tr></table></figure>
<p>然后就是计算用户相似度，这里同时也实现了物品相似度的计算：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_person_similarity</span><span class="params">(ratings_matrix, based=<span class="string">"user"</span>)</span>:</span></span><br><span class="line">    user_similarity_cache_path = os.path.join(CACHE_DIR, <span class="string">"user_similarity.cache"</span>)</span><br><span class="line">    item_similarity_cache_path = os.path.join(CACHE_DIR, <span class="string">"item_similarity.cache"</span>)</span><br><span class="line">    <span class="keyword">if</span> based==<span class="string">"user"</span>:</span><br><span class="line">        <span class="keyword">if</span> os.path.exists(user_similarity_cache_path):</span><br><span class="line">            print(<span class="string">"-----正从缓存加载用户相似度矩阵-----"</span>)</span><br><span class="line">            similarity = pd.read_pickle(user_similarity_cache_path)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">"-----开始计算用户相似度矩阵-----"</span>)</span><br><span class="line">            similarity = ratings_matrix.T.corr()</span><br><span class="line">            similarity.to_pickle(user_similarity_cache_path)</span><br><span class="line">    <span class="keyword">elif</span> based == <span class="string">"item"</span>:</span><br><span class="line">        <span class="keyword">if</span> os.path.exists(item_similarity_cache_path):</span><br><span class="line">            print(<span class="string">"-----正从缓存加载用户相似度矩阵-----"</span>)</span><br><span class="line">            similarity = pd.read_pickle(item_similarity_cache_path)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">"-----开始计算物品相似度矩阵-----"</span>)</span><br><span class="line">            similarity = ratings_matrix.corr()</span><br><span class="line">            similarity.to_pickle(item_similarity_cache_path)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">"Unhandled  'based' value: %s"</span> %based)</span><br><span class="line">    print(<span class="string">"-----相似度矩阵计算/加载完毕-----"</span>)</span><br><span class="line">    <span class="keyword">return</span> similarity</span><br></pre></td></tr></table></figure>
<p>我们首先实现单个用户对单个电影的评分：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(uid, iid, ratings_matrix, user_similar)</span>:</span></span><br><span class="line">    print(<span class="string">"-----开始预测用户&lt;%d&gt;对电影&lt;%d&gt;的评分-----"</span>%(uid, iid))</span><br><span class="line">    <span class="comment"># 找出uid用户的相似用户</span></span><br><span class="line">    similar_users = user_similar[uid].drop([uid]).dropna()</span><br><span class="line">    similar_users = similar_users.where(similar_users&gt;<span class="number">0</span>).dropna()</span><br><span class="line">    <span class="keyword">if</span> similar_users.empty <span class="keyword">is</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">"用户&lt;%d&gt;没有相似的用户"</span>%uid)</span><br><span class="line">    <span class="comment"># 从uid用户的近邻相似用户中选出对iid物品有评分记录的近邻用户</span></span><br><span class="line">    ids = set(ratings_matrix[iid].dropna().index)&amp;set(similar_users.index)</span><br><span class="line">    finally_similar_users = similar_users.ix[list(ids)]</span><br><span class="line">    <span class="comment"># 结合uid用户与其近邻用户的相似度预测uid用户对iid物品的评分</span></span><br><span class="line">    sum_up = <span class="number">0</span> <span class="comment">#评分预测公式分子部分的值</span></span><br><span class="line">    sum_down = <span class="number">0</span> <span class="comment">#评分预测公式分母部分的值</span></span><br><span class="line">    <span class="keyword">for</span> sim_uid, similarity <span class="keyword">in</span> finally_similar_users.iteritems():</span><br><span class="line">        <span class="comment"># 近邻用户的评分数据</span></span><br><span class="line">        sim_user_rated_movies = ratings_matrix.ix[sim_uid].dropna()</span><br><span class="line">        <span class="comment"># 近邻用户对iid物品的评分</span></span><br><span class="line">        sim_user_rating_for_item = sim_user_rated_movies[iid]</span><br><span class="line">        <span class="comment"># 计算分子的值</span></span><br><span class="line">        sum_up += similarity * sim_user_rating_for_item</span><br><span class="line">        <span class="comment"># 计算分母的值</span></span><br><span class="line">        sum_down += similarity</span><br><span class="line">    </span><br><span class="line">    predict_rating = sum_up/sum_down</span><br><span class="line">    print(<span class="string">"预测出用户&lt;%d&gt;对电影&lt;%d&gt;的评分: %0.2f"</span> %((uid, iid, predict_rating)))</span><br><span class="line">    <span class="keyword">return</span> round(predict_rating, <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>定义一个简单的用户对item_ids中的电影预测，item_ids可以直接是电影全集</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_predict_all</span><span class="params">(uid, item_ids, rating_matrix, user_similar)</span>:</span></span><br><span class="line">    item_ids = rating_matrix.columns</span><br><span class="line">    <span class="keyword">for</span> iid <span class="keyword">in</span> item_ids:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            rating = predict(uid, iid, ratings_matrix, user_similar)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            print(e)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">yield</span> uid, iid, rating</span><br></pre></td></tr></table></figure>
<p>我们还可以添加其他过滤规则：过滤 非热门电影或有过评分的电影</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_all</span><span class="params">(uid, ratings_matrix, user_similar, filter_rule=None)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> filter_rule:</span><br><span class="line">        item_ids = ratings_matrix.columns</span><br><span class="line">    <span class="keyword">elif</span> isinstance(filter_rule, str) <span class="keyword">and</span> filter_rule == <span class="string">"unhot"</span>:</span><br><span class="line">        <span class="comment"># 过滤非热门电影</span></span><br><span class="line">        count = ratings_matrix.count()</span><br><span class="line">        item_ids = count.where(count&gt;<span class="number">10</span>).dropna().index</span><br><span class="line">        <span class="comment"># 过滤有过评分的电影</span></span><br><span class="line">    <span class="keyword">elif</span> isinstance(filter_rule, str) <span class="keyword">and</span> filter_rule == <span class="string">"rated"</span>:</span><br><span class="line">        user_ratings = ratings_matrix.ix[uid]</span><br><span class="line">        _ = user_ratings&lt;<span class="number">6</span></span><br><span class="line">        item_ids = _.where(_==<span class="literal">True</span>).dropna().index</span><br><span class="line">    <span class="keyword">elif</span> isinstance(filter_rule, list) <span class="keyword">and</span> set(filter_rule) == set([<span class="string">"unhot"</span>, <span class="string">"rated"</span>]):</span><br><span class="line">        count = ratings_matrix.count()</span><br><span class="line">        ids1 = count.where(count&gt;<span class="number">10</span>).dropna().index</span><br><span class="line">        user_ratings = ratings_matrix.ix[uid]</span><br><span class="line">        _ = user_ratings&lt;<span class="number">6</span></span><br><span class="line">        ids2 = _.where(_==<span class="literal">True</span>).dropna().index</span><br><span class="line">        item_ids = set(ids1) &amp; set(ids2)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">"无效的过滤参数"</span>)</span><br><span class="line">    <span class="keyword">yield</span> <span class="keyword">from</span> _predict_all(uid, item_ids, ratings_matrix, user_similar)</span><br></pre></td></tr></table></figure>
<p>最后我们定义一个函数实现top20的推荐：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">top_k_rs_result</span><span class="params">(uid, k)</span>:</span></span><br><span class="line">    ratings_matrix = load_data(DATA_PATH)</span><br><span class="line">    user_similar = compute_person_similarity(ratings_matrix, based=<span class="string">"user"</span>)</span><br><span class="line">    results = predict_all(uid, ratings_matrix, user_similar, filter_rule=[<span class="string">"unhot"</span>, <span class="string">"rated"</span>])</span><br><span class="line">    <span class="keyword">return</span> sorted(results, key=<span class="keyword">lambda</span> x: x[<span class="number">2</span>], reverse=<span class="literal">True</span>)[:k]</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Recommender system</category>
      </categories>
  </entry>
  <entry>
    <title>推荐系统实战（三）</title>
    <url>/posts/c7c89ecf.html</url>
    <content><![CDATA[<h1 id="推荐系统的冷启动问题"><a href="#推荐系统的冷启动问题" class="headerlink" title="推荐系统的冷启动问题"></a>推荐系统的冷启动问题</h1><h2 id="推荐系统冷启动概念"><a href="#推荐系统冷启动概念" class="headerlink" title="推荐系统冷启动概念"></a>推荐系统冷启动概念</h2><ul>
<li>⽤户冷启动：如何为新⽤户做个性化推荐</li>
<li>物品冷启动：如何将新物品推荐给⽤户（协同过滤）</li>
<li>系统冷启动：⽤户冷启动+物品冷启动</li>
<li>本质是推荐系统依赖历史数据，没有历史数据⽆法预测⽤户偏好</li>
</ul>
<h2 id="用户冷启动"><a href="#用户冷启动" class="headerlink" title="用户冷启动"></a>用户冷启动</h2><ul>
<li><p>收集⽤户特征</p>
<ul>
<li><p>⽤户注册信息：性别、年龄、地域</p>
</li>
<li><p>设备信息：定位、⼿机型号、app列表</p>
</li>
<li><p>社交信息、推⼴素材、安装来源</p>
<p><img src=" /Pic/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%89%EF%BC%89/recommend4.png" style="zoom:67%;"></p>
</li>
</ul>
</li>
<li><p>引导用户填写兴趣</p>
<p><img src=" /Pic/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%89%EF%BC%89/recommend5.png" style="zoom:67%;"></p>
</li>
<li><p>使用其它站点的行为数据, 例如腾讯视频&amp;QQ音乐 今日头条&amp;抖音</p>
</li>
<li><p>新老用户推荐策略的差异</p>
<ul>
<li>新⽤户在冷启动阶段更倾向于热门排⾏榜，⽼⽤户会更加需要长尾推荐</li>
<li>Explore Exploit⼒度</li>
<li>使⽤单独的特征和模型预估</li>
</ul>
</li>
<li><p>举例 性别与电视剧的关系</p>
</li>
</ul>
<p><img src=" /Pic/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%89%EF%BC%89/firststart.png" style="zoom:67%;"></p>
<p><img src=" /Pic/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%89%EF%BC%89/firststart1.png" style="zoom:56%;"></p>
<h2 id="物品冷启动"><a href="#物品冷启动" class="headerlink" title="物品冷启动"></a>物品冷启动</h2><ul>
<li>给物品打标签</li>
<li>利用物品的内容信息，将新物品先投放给曾经喜欢过和它内容相似的其他物品的用户。</li>
</ul>
<p><img src="/Pic/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%89%EF%BC%89/firststart2.png" style="zoom:67%;"></p>
<h2 id="系统冷启动"><a href="#系统冷启动" class="headerlink" title="系统冷启动"></a>系统冷启动</h2><ul>
<li>如果应用缺少用户行为数据，可以做基于内容的推荐</li>
<li>随着用户行为越来越多，可以转到协同过滤</li>
<li>基于内容的推荐和协同过滤的推荐结果都计算出来，加权求和得到最终的推荐结果</li>
</ul>
<h1 id="基于内容的推荐"><a href="#基于内容的推荐" class="headerlink" title="基于内容的推荐"></a>基于内容的推荐</h1><ul>
<li>给物品打标签<ul>
<li>可以是系统提取（从业务数据库中提取）</li>
<li>用户填写</li>
</ul>
</li>
<li>利用标签的文字转换成词向量<ul>
<li>Word2Vec转换成词向量，表示语义</li>
</ul>
</li>
<li>利用词向量构建物品的向量<ul>
<li>一个物品有N个关键词，一个关键词对应一个词向量</li>
<li>对这N个关键词加权求和取平均，得到物品向量</li>
</ul>
</li>
<li>通过物品向量计算相似度<ul>
<li>利用皮尔逊相关系数计算物品向量相似度</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>Recommender system</category>
      </categories>
  </entry>
  <entry>
    <title>推荐系统实战（二）</title>
    <url>/posts/8ad63d9d.html</url>
    <content><![CDATA[<h1 id="推荐算法"><a href="#推荐算法" class="headerlink" title="推荐算法"></a>推荐算法</h1><ul>
<li>推荐模型构建流程</li>
<li>推荐算法概述</li>
<li>基于协同过滤的推荐算法</li>
<li>协同过滤实现</li>
</ul>
<h2 id="一-推荐模型构建流程"><a href="#一-推荐模型构建流程" class="headerlink" title="一 推荐模型构建流程"></a>一 推荐模型构建流程</h2><p>Data(数据)-&gt;Features(特征)-&gt;ML Algorithm(机器学习算法)-&gt;Prediction Output(预测输出)</p>
<ul>
<li>数据清洗/数据处理</li>
</ul>
<p><img src="/Pic/recommend/algorithm1.png" style="zoom:50%;"></p>
<ul>
<li>数据来源<ul>
<li>显性数据<ul>
<li>Rating 打分</li>
<li>Comments 评论/评价</li>
</ul>
</li>
<li>隐形数据<ul>
<li> Order history 历史订单</li>
<li> Cart events    加购物车</li>
<li> Page views    页面浏览</li>
<li> Click-thru      点击</li>
<li> Search log     搜索记录</li>
</ul>
</li>
</ul>
</li>
<li>数据量/数据能否满足要求</li>
<li>特征工程</li>
</ul>
<p><img src="/Pic/recommend/algorithm2.png" style="zoom:50%;"></p>
<ul>
<li>从数据中筛选特征<ul>
<li>一个给定的商品，可能被拥有类似品味或需求的用户购买</li>
<li>使用用户行为数据描述商品</li>
</ul>
</li>
</ul>
<p><img src="/Pic/recommend/algorithm3.png" style="zoom:57%;"></p>
<ul>
<li><p>用数据表示特征</p>
<ul>
<li><p>将所有用户行为合并在一起 ，形成一个user-item 矩阵</p>
<p><img src="/Pic/recommend/algorithm4.png" alt="1545452707102" style="zoom:57%;"></p>
</li>
</ul>
</li>
<li><p>选择合适的算法</p>
</li>
</ul>
<p><img src="/Pic/recommend/algorithm5.png" style="zoom:50%;"></p>
<ul>
<li><p>产生推荐结果</p>
<p><img src="/Pic/recommend/algorithm6.png" style="zoom:50%;"></p>
</li>
</ul>
<h2 id="二-推荐算法概述"><a href="#二-推荐算法概述" class="headerlink" title="二 推荐算法概述"></a>二 推荐算法概述</h2><h3 id="2-1-常用推荐算法"><a href="#2-1-常用推荐算法" class="headerlink" title="2.1 常用推荐算法"></a>2.1 常用推荐算法</h3><ul>
<li>基于内容过滤<ul>
<li>从信息检索，和文本检索发展而来</li>
<li>基于商品描述及用户喜好描述，为用户推荐商品</li>
</ul>
</li>
<li>协同过滤<ul>
<li>基于用户行为为用户推荐感兴趣的商品</li>
<li>行为可以是过往的交易行为和商品评分，这种方式不需要显性的属性信息</li>
</ul>
</li>
<li>混合推荐</li>
</ul>
<h3 id="2-2-基于内容过滤存在的问题"><a href="#2-2-基于内容过滤存在的问题" class="headerlink" title="2.2 基于内容过滤存在的问题"></a>2.2 基于内容过滤存在的问题</h3><ul>
<li><p>需了解商品内容</p>
<ul>
<li>需要人工或自动标注信息</li>
<li>商品内容不能反映所有特点</li>
</ul>
</li>
<li><p>冷启动问题</p>
<ul>
<li>需要花时间学习哪些内容或feature 对用户而言是重要的</li>
</ul>
</li>
<li><p>如果用户兴趣点改变了呢</p>
</li>
<li><p>Lack of serendipity(缺少意外新发现 EE问题)</p>
<p><img src="/Pic/recommend/algorithm7.png" alt="1545453690391" style="zoom:50%;"></p>
</li>
<li><p>基于内容的推荐(Content-based) V.S. 协同过滤(Collaborative Filtering)</p>
</li>
</ul>
<table>
<tr>
<th>推荐方法</th>
<th>优点</th>
<th>缺点</th>
</tr>
<tr>
<td> 基于内容推荐</td>
<td>推荐结果直观,容易解释
不需要领域知识</td>
<td>新用户问题;
复杂属性不好处理;
要有足够数据构造分类器;</td>
</tr>
<tr>
<td> 协同过滤推荐</td>
<td>新异兴趣发现、不需要领域知识;<br>随着时间推移性能提高;<br>推荐个性化、自动化程度高;<br>能处理复杂的非结构化对象;</td>
<td>稀疏问题;
可扩展性问题;
新用户问题;
依赖历史数据集;
系统开始时推荐质量差;</td>
</tr>
</table>


<h2 id="三-基于协同过滤的推荐算法"><a href="#三-基于协同过滤的推荐算法" class="headerlink" title="三 基于协同过滤的推荐算法"></a>三 基于协同过滤的推荐算法</h2><h3 id="3-1-协同过滤算法概述"><a href="#3-1-协同过滤算法概述" class="headerlink" title="3.1 协同过滤算法概述"></a>3.1 协同过滤算法概述</h3><ul>
<li><p>协同过滤算法</p>
<ul>
<li>基于用户行为的推荐</li>
<li>行为可以是过往的交易行为和商品评分，这种方式不需要显性的属性信息</li>
</ul>
</li>
<li><p>协同过滤分类</p>
<ul>
<li>K近邻（neighborhood ）方法<ul>
<li>借助商品的关系或者用户的关系</li>
</ul>
</li>
</ul>
</li>
<li>基于模型的方法<ul>
<li>用隐含变量刻画商品</li>
</ul>
</li>
</ul>
<h3 id="3-2-协同过滤算法之K邻近方法"><a href="#3-2-协同过滤算法之K邻近方法" class="headerlink" title="3.2 协同过滤算法之K邻近方法"></a>3.2 协同过滤算法之K邻近方法</h3><ul>
<li>K邻近方法<br>基于假设 ： “跟你喜好相似的人喜欢的东西你也很有可能喜欢” 或“跟你喜欢的物品类似的物品你也很有可能喜欢 ”</li>
<li>分类<ul>
<li>User-based 方法<ul>
<li>基于user的协同过滤，通过不同用户对item的评分来评测用户之间的相似性，基于用户之间的相似性做出推荐</li>
</ul>
</li>
<li>Item-based方法<ul>
<li>基于item的协同过滤，通过用户对不同item的评分来评测item之间的相似性，基于item之间的相似性做出推荐</li>
</ul>
</li>
</ul>
</li>
<li>基于用户(User-based)<ul>
<li>查找用户相似度 如何预测用户1对于商品4的喜好程度?<ul>
<li>找到和用户1相似的用户且购买过商品4（基于购买记录）即为用户n</li>
<li>根据用户n对商品4的评价，以相似度为权重回填结果</li>
<li>针对所有用户组合，重复上述步骤，直到所有空格都被填满</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/Pic/recommend/knn1.png" alt="1545455898171" style="zoom:67%;"></p>
<ul>
<li><p>找到相似的Item (Item-based)</p>
<ul>
<li>用户1对于商品4的喜好程度?</li>
</ul>
<ol>
<li>从用户1历史记录中，计算商品n和商品4的相似度（以其他用户的历史记录）</li>
<li>将用户1对于商品n的评价，以商品相似度为权重回填</li>
<li>针对所有商品组合，重复上述步骤直到所有空格都被填满</li>
</ol>
</li>
</ul>
<p><img src="/Pic/recommend/knn2.png" alt="1545456021921" style="zoom:67%;"></p>
<ul>
<li>用户&amp;物品矩阵</li>
</ul>
<p><img src="/Pic/recommend/user-itemMatrix.png" style="zoom:50%;"></p>
<ul>
<li>将订单数据填入到用户-物品矩阵</li>
</ul>
<p><img src="/Pic/recommend/user-itemMatrix2.png" style="zoom:50%;"></p>
<ul>
<li>处理用户-物品数据(归一化)</li>
</ul>
<p><img src="/Pic/recommend/user-itemMatrix3.png" style="zoom:50%;"></p>
<ul>
<li>处理用户-物品矩阵 填充矩阵中的空值</li>
</ul>
<p><img src="/Pic/recommend/user-itemMatrix4.png" style="zoom:50%;"></p>
<h3 id="3-3-相似度计算-Similarity-Calculation"><a href="#3-3-相似度计算-Similarity-Calculation" class="headerlink" title="3.3 相似度计算(Similarity Calculation)"></a>3.3 相似度计算(Similarity Calculation)</h3><p><img src="/Pic/recommend/similarity_calc1.png" style="zoom:50%;"></p>
<ul>
<li>数据分类<ul>
<li>实数值(物品评分情况)</li>
<li>布尔值(用户的行为 是否点击 是否收藏)</li>
</ul>
</li>
</ul>
<h4 id="欧氏距离"><a href="#欧氏距离" class="headerlink" title="欧氏距离"></a>欧氏距离</h4><p>欧氏距离是一个欧式空间下度量距离的方法. 两个物体, 都在同一个空间下表示为两个点, 假如叫做p,q, 分别都是n个坐标, 那么欧式距离就是衡量这两个点之间的距离. 欧氏距离不适用于布尔向量之间</p>
<script type="math/tex; mode=display">E(p,q) = \sqrt{\sum_{i=1}^n(p_i-q_i)^2}</script><p>欧氏距离的值是一个非负数, 最大值正无穷, 通常计算相似度的结果希望是[-1,1]或[0,1]之间,一般可以使用如下转化公式:</p>
<script type="math/tex; mode=display">\frac1{1+E(p,q)}</script><h4 id="杰卡德相似度-amp-余弦相似度-amp-皮尔逊相关系数"><a href="#杰卡德相似度-amp-余弦相似度-amp-皮尔逊相关系数" class="headerlink" title="杰卡德相似度&amp;余弦相似度&amp;皮尔逊相关系数"></a>杰卡德相似度&amp;余弦相似度&amp;皮尔逊相关系数</h4><h5 id="余弦相似度"><a href="#余弦相似度" class="headerlink" title="余弦相似度"></a>余弦相似度</h5><p><img src="/Pic/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/similarity_calc5.png" style="zoom:33%;"></p>
<ul>
<li>度量的是两个向量之间的夹角, 用夹角的余弦值来度量相似的情况</li>
<li>两个向量的夹角为0是,余弦值为1, 当夹角为90度是余弦值为0,为180度是余弦值为-1</li>
<li>余弦相似度在度量文本相似度, 用户相似度 物品相似度的时候较为常用</li>
<li>余弦相似度的特点, 与向量长度无关,余弦相似度计算要对向量长度归一化, 两个向量只要方向一致,无论程度强弱, 都可以视为’相似’</li>
<li>余弦相似度对绝对值大小不敏感带来的问题<ul>
<li>用户A对两部电影评分分别是1分和2分, 用户B对同样这两部电影进行评分是4分,5分 用余弦相似度计算,两个用户的相似度达到0.98</li>
<li>可以采用改进的余弦相似度, 先计算向量每个维度上的均值, 然后每个向量在各个维度上都减去均值后,在计算余弦相似度, 用调整的余弦相似度计算得到的相似度是-0.1，计算公式为$s(i,j) = \frac{\sum_{c\in U}(R_{u,i}-\bar R_u)(R_{u,j}-\bar R_u)}{\sqrt{\sum_{u\in U}(R_{u,i}-\bar R_u)^2}\sqrt{\sum_{u\in U}(R_{u,j}-\bar R_u)^2}}$</li>
</ul>
</li>
</ul>
<h5 id="皮尔逊相关系数Pearson"><a href="#皮尔逊相关系数Pearson" class="headerlink" title="皮尔逊相关系数Pearson"></a>皮尔逊相关系数Pearson</h5><script type="math/tex; mode=display">r = \frac{\sum_{i=1}^n(x_i-\bar x)(y_i-\bar y)}{\sqrt{\sum_{i=1}^n(x_i-\bar x)^2}\sqrt{\sum_{i=1}^n}(y_i-\bar y)^2}</script><ul>
<li>实际上也是一种余弦相似度, 不过先对向量做了中心化, 向量a b 各自减去向量的均值后, 再计算余弦相似度</li>
<li>皮尔逊相似度计算结果在-1,1之间 -1表示负相关, 1表示正相关</li>
<li>度量两个变量是不是同增同减</li>
<li>皮尔逊相关系数度量的是两个变量的变化趋势是否一致, <strong>不适合计算布尔值向量之间的相关度</strong></li>
</ul>
<h5 id="杰卡德相似度-Jaccard"><a href="#杰卡德相似度-Jaccard" class="headerlink" title="杰卡德相似度 Jaccard"></a>杰卡德相似度 Jaccard</h5><ul>
<li>两个集合的交集元素个数在并集中所占的比例, 非常适用于布尔向量表示</li>
<li>分子是两个布尔向量做点积计算, 得到的就是交集元素的个数</li>
<li><p>分母是两个布尔向量做或运算, 再求元素和</p>
</li>
<li><p>余弦相似度适合用户评分数据(实数值), 杰卡德相似度适用于隐式反馈数据(0,1布尔值)(是否收藏,是否点击,是否加购物车)</p>
</li>
</ul>
<p><img src="/Pic/recommend/similarity_calc2.png" style="zoom:50%;"></p>
<h4 id="推荐步骤"><a href="#推荐步骤" class="headerlink" title="推荐步骤"></a>推荐步骤</h4><ul>
<li>计算出用户1和其它用户之间的相似度</li>
</ul>
<p><img src="/Pic/recommend/similarity_calc6.png" style="zoom:70%;"></p>
<ul>
<li>按照相似度大小排序, K近邻 如K取4: </li>
</ul>
<p><img src="/Pic/recommend/similarity_calc7.png" style="zoom:70%;"></p>
<ul>
<li>取出近邻用户的购物清单</li>
</ul>
<p><img src="/Pic/recommend/similarity_calc8.png" style="zoom:70%;"></p>
<ul>
<li>去除用户1已经购买过的商品</li>
</ul>
<p><img src="/Pic/recommend/similarity_calc9.png" style="zoom:70%;"></p>
<ul>
<li>在剩余的物品中根据评分排序</li>
</ul>
<p><img src="/Pic/recommend/similarity_calc10.png" style="zoom:70%;"></p>
<h4 id="物品相似度计算案例"><a href="#物品相似度计算案例" class="headerlink" title="物品相似度计算案例"></a>物品相似度计算案例</h4><p><img src="/Pic/recommend/similarity_calc12.png" style="zoom:35%;"></p>
<ul>
<li>找出物品1的相似商品</li>
</ul>
<p><img src="/Pic/recommend/similarity_calc13.png" style="zoom:50%;"></p>
<ul>
<li>选择最近似的物品</li>
</ul>
<p><img src="/Pic/recommend/similarity_calc14.png" style="zoom:50%;"></p>
<h3 id="3-4-基于模型的方法"><a href="#3-4-基于模型的方法" class="headerlink" title="3.4 基于模型的方法"></a>3.4 基于模型的方法</h3><ul>
<li><p>思想</p>
<ul>
<li>通过机器学习算法，在数据中找出模式，并将用户与物品间的互动方式模式化</li>
<li>基于模型的协同过滤方式是构建协同过滤更高级的算法</li>
</ul>
</li>
<li><p>近邻模型的问题</p>
<ul>
<li>物品之间存在相关性, 信息量并不随着向量维度增加而线性增加</li>
<li>矩阵元素稀疏, 计算结果不稳定,增减一个向量维度, 导致近邻结果差异很大的情况存在</li>
</ul>
</li>
<li><p>算法分类</p>
<ul>
<li>基于图的模型</li>
<li>基于矩阵分解的方法</li>
</ul>
</li>
<li><p>基于图的模型</p>
<ul>
<li>基于邻域的模型看做基于图的模型的简单形式</li>
</ul>
<p><img src="/Pic/recommend/graph1.png" alt></p>
<ul>
<li>原理<ul>
<li>将用户的行为数据表示为二分图</li>
<li>基于二分图为用户进行推荐</li>
<li>根据两个顶点之间的路径数、路径长度和经过的顶点数来评价两个顶点的相关性</li>
</ul>
</li>
</ul>
</li>
<li><p>基于矩阵分解的模型</p>
<ul>
<li><p>原理</p>
<ul>
<li><p>根据用户与物品的潜在表现，我们就可以预测用户对未评分的物品的喜爱程度</p>
</li>
<li><p>把原来的大矩阵, 近似分解成两个小矩阵的乘积, 在实际推荐计算时不再使用大矩阵, 而是使用分解得到的两个小矩阵  </p>
</li>
<li><p>用户-物品评分矩阵A是$M \text{x} N$维, 即一共有$M$个用户, $N$个物品 我们选一个很小的数 $K (K&lt;&lt; M, K&lt;&lt;N)$</p>
</li>
<li><p>通过计算得到两个矩阵$U$ 和 $V$，其中$U$是$M \text{x} K$矩阵 , $V$是$N \text{x} K$矩阵，$U_{m\text{x}k} V^{T}_{n\text{x}k}$ 约等于 $A_{m\text{x}n}$</p>
<p>类似这样的计算过程就是矩阵分解</p>
</li>
</ul>
</li>
<li><p>基于矩阵分解的方法</p>
<ul>
<li>ALS交替最小二乘<ul>
<li>ALS-WR(加权正则化交替最小二乘法): alternating-least-squares with weighted-λ –regularization</li>
<li>将用户(user)对商品(item)的评分矩阵分解为两个矩阵：一个是用户对商品隐含特征的偏好矩阵，另一个是商品所包含的隐含特征的矩阵。在这个矩阵分解的过程中，评分缺失项得到了填充，也就是说我们可以基于这个填充的评分来给用户做商品推荐了。</li>
</ul>
</li>
<li>SVD奇异值分解矩阵</li>
</ul>
</li>
</ul>
</li>
<li><p>ALS方法</p>
<p><img src="/Pic/recommend/als1.png" style="zoom:75%;"></p>
<ul>
<li>ALS的矩阵分解算法常应用于推荐系统中，将用户(user)对商品(item)的评分矩阵，分解为用户对商品隐含特征的偏好矩阵，和商品在隐含特征上的映射矩阵。</li>
<li>与传统的矩阵分解SVD方法来分解矩阵$R(R∈ℝm×n)$不同的是，ALS(alternating least squares)希望找到两个低维矩阵，以 $R̃ =XY$来逼近矩阵R，其中 $X∈ℝ_{m×d}，Y∈ℝ_{d×n}$，这样，将问题的复杂度由$O(mn)$转换为$O((m+n)d)$。</li>
<li>计算$X$和$Y$过程：首先用一个小于1的随机数初始化$Y$，并根据公式求$X$，此时就可以得到初始的$XY$矩阵了，根据平方差和得到的X，重新计算并覆盖$Y$，计算差平方和，反复进行以上两步的计算，直到差平方和小于一个预设的数，或者迭代次数满足要求则停止</li>
</ul>
</li>
</ul>
<h3 id="3-5-基于用户的协同过滤实现-User-CF"><a href="#3-5-基于用户的协同过滤实现-User-CF" class="headerlink" title="3.5 基于用户的协同过滤实现 (User CF)"></a>3.5 基于用户的协同过滤实现 (User CF)</h3><h4 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h4><ul>
<li>第一步: 找出和目标用户兴趣类似的用户集合</li>
<li>第二步: 找到集合中用户喜欢的，且目标用户没有听说过的物品推荐给目标用户</li>
</ul>
<h4 id="实现步骤"><a href="#实现步骤" class="headerlink" title="实现步骤"></a>实现步骤</h4><p><strong>计算用户相似度</strong></p>
<ul>
<li>设$N(u)$是用户$u$有过正反馈的物品集合，则Jaccard公式：</li>
</ul>
<p><img src="/Pic/recommend/usercf1.png" style="zoom:80%;"></p>
<ul>
<li>如果用户数目很多，如何优化？<br>答：首先计算出$N(u)\cap N(v) != 0$的用户对$(u,v)$，然后再对这种情况除以分母$\sqrt{(N(u)*N(v))}$</li>
</ul>
<p><img src="/Pic/recommend/usercf2.png" alt></p>
<p><strong>推荐相似用户喜欢的物品</strong></p>
<ul>
<li><p>得到用户之间的兴趣相似度后，UserCF算法会给用户推荐和他兴趣最相似的$K$个用户喜欢的物品。</p>
</li>
<li><p>$S(u, K)$包含和用户u兴趣最接近的$K$个用户，$N(i)$是对物品i有过行为的用户集合，$W_{uv}$是用户u和用户v的兴趣相似度，$r_{vi}$代表用户$v$对物品$i$的兴趣，因为使用的是单一行为的隐反馈数据，所以所有的$r_{vi}$=1</p>
<script type="math/tex; mode=display">p(u,i) = \sum_{v\in S(u,K)\cap N(i)}w_{uv}r_{vi}</script></li>
<li><p>选取$K=3$，用户A对物品c、e没有过行为，因此可以把这两个物品推荐给用户A。</p>
</li>
</ul>
<h3 id="3-6-基于物品的协同过滤实现-Item-CF"><a href="#3-6-基于物品的协同过滤实现-Item-CF" class="headerlink" title="3.6 基于物品的协同过滤实现 (Item CF)"></a>3.6 基于物品的协同过滤实现 (Item CF)</h3><h4 id="思路-1"><a href="#思路-1" class="headerlink" title="思路"></a>思路</h4><ul>
<li>Step 1：计算物品之间的相似度</li>
<li>Step 2：根据物品的相似度和用户的历史行为，为用户生成推荐列表</li>
</ul>
<h4 id="实现步骤-1"><a href="#实现步骤-1" class="headerlink" title="实现步骤"></a>实现步骤</h4><p><img src="/Pic/recommend/itemcf1.png" style="zoom:50%;"></p>
<p><img src="/Pic/recommend/itemcf2.png" style="zoom:50%;"></p>
<h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><p>下面分为0-1型数据及评分型数据分别进行协同过滤，这两者的区别主要在于相关系数的衡量方式不同，其中评分型数据还分为稀疏型和稠密型两种</p>
<h2 id="数据为0-1型-调用和没调用"><a href="#数据为0-1型-调用和没调用" class="headerlink" title="数据为0-1型(调用和没调用)"></a>数据为0-1型(调用和没调用)</h2><h3 id="第一步：计算相似度"><a href="#第一步：计算相似度" class="headerlink" title="第一步：计算相似度"></a>第一步：计算相似度</h3><p><strong>生成数据</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> jaccard_score</span><br><span class="line"></span><br><span class="line">users = [<span class="string">"user1"</span>, <span class="string">"user2"</span>, <span class="string">"user3"</span>, <span class="string">"user4"</span>, <span class="string">"user5"</span>]</span><br><span class="line">items = [<span class="string">"itemA"</span>, <span class="string">"itemB"</span>, <span class="string">"itemC"</span>, <span class="string">"itemD"</span>, <span class="string">"itemE"</span>,]</span><br><span class="line"></span><br><span class="line">datasets = [</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(datasets, columns=items, index=users)</span><br><span class="line">print(df)</span><br></pre></td></tr></table></figure>
<p>生成数据的打印结果为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">       itemA  itemB  itemC  itemD  itemE</span><br><span class="line">user1      1      0      1      1      0</span><br><span class="line">user2      1      0      0      1      1</span><br><span class="line">user3      1      0      1      0      0</span><br><span class="line">user4      0      1      0      1      1</span><br><span class="line">user5      1      1      1      0      1</span><br></pre></td></tr></table></figure>
<p><strong>计算杰卡德相似度</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">jaccard_score(df[<span class="string">"itemA"</span>], df[<span class="string">"itemB"</span>]) <span class="comment"># 0.2</span></span><br></pre></td></tr></table></figure>
<p>用户相似度的计算方式为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> pairwise_distances</span><br><span class="line">user_simility = <span class="number">1</span> - pairwise_distances(df.values, metric=<span class="string">"jaccard"</span>)</span><br><span class="line">user_similar = pd.DataFrame(user_simility, columns=users, index=users)</span><br><span class="line">user_similar</span><br></pre></td></tr></table></figure>
<p>用户相似度的打印结果为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">          user1  user2     user3  user4  user5</span><br><span class="line">user1  1.000000   0.50  0.666667    0.2    0.4</span><br><span class="line">user2  0.500000   1.00  0.250000    0.5    0.4</span><br><span class="line">user3  0.666667   0.25  1.000000    0.0    0.5</span><br><span class="line">user4  0.200000   0.50  0.000000    1.0    0.4</span><br><span class="line">user5  0.400000   0.40  0.500000    0.4    1.0</span><br></pre></td></tr></table></figure>
<p>物品相似度的计算方式为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">item_simility = <span class="number">1</span> - pairwise_distances(df.T.values, metric=<span class="string">"jaccard"</span>)</span><br><span class="line">item_similar = pd.DataFrame(item_simility, columns=items, index=items)</span><br><span class="line">item_similar</span><br></pre></td></tr></table></figure>
<p>用户相似度的打印结果为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">       itemA     itemB  itemC  itemD     itemE</span><br><span class="line">itemA   1.00  0.200000   0.75   0.40  0.400000</span><br><span class="line">itemB   0.20  1.000000   0.25   0.25  0.666667</span><br><span class="line">itemC   0.75  0.250000   1.00   0.20  0.200000</span><br><span class="line">itemD   0.40  0.250000   0.20   1.00  0.500000</span><br><span class="line">itemE   0.40  0.666667   0.20   0.50  1.000000</span><br></pre></td></tr></table></figure>
<h3 id="第二步：进行推荐"><a href="#第二步：进行推荐" class="headerlink" title="第二步：进行推荐"></a>第二步：进行推荐</h3><h4 id="1-为每一个用户找到最相似的K个用户"><a href="#1-为每一个用户找到最相似的K个用户" class="headerlink" title="1. 为每一个用户找到最相似的K个用户"></a>1. 为每一个用户找到最相似的K个用户</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">topN_user = &#123;&#125;</span><br><span class="line">K = <span class="number">2</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> user_similar.index:</span><br><span class="line">    <span class="comment"># 取出一列数据，删除自己后按照相似度排序</span></span><br><span class="line">    _df = user_similar.loc[i].drop([i])</span><br><span class="line">    _df_sorted = _df.sort_values(ascending = <span class="literal">False</span>)</span><br><span class="line">    topK = list(_df_sorted.index[:K])</span><br><span class="line">    topN_user[i] = topK</span><br><span class="line">    </span><br><span class="line">topN_user</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;&#39;user1&#39;: [&#39;user3&#39;, &#39;user2&#39;],</span><br><span class="line"> &#39;user2&#39;: [&#39;user4&#39;, &#39;user1&#39;],</span><br><span class="line"> &#39;user3&#39;: [&#39;user1&#39;, &#39;user5&#39;],</span><br><span class="line"> &#39;user4&#39;: [&#39;user2&#39;, &#39;user5&#39;],</span><br><span class="line"> &#39;user5&#39;: [&#39;user3&#39;, &#39;user4&#39;]&#125;</span><br></pre></td></tr></table></figure>
<h4 id="2-根据TopN的相似用户构建推荐结果"><a href="#2-根据TopN的相似用户构建推荐结果" class="headerlink" title="2. 根据TopN的相似用户构建推荐结果"></a>2. 根据TopN的相似用户构建推荐结果</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rs_results = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> user, sim_users <span class="keyword">in</span> topN_user.items():</span><br><span class="line">    rs_result = set()</span><br><span class="line">    <span class="keyword">for</span> sim_user <span class="keyword">in</span> sim_users:</span><br><span class="line">        rs_result = rs_result.union(set(df.loc[sim_user].replace(<span class="number">0</span>, np.nan).dropna().index))</span><br><span class="line">    <span class="comment"># 过滤掉已经购买的商品</span></span><br><span class="line">    rs_result -= set(df.loc[user].replace(<span class="number">0</span>, np.nan).dropna().index)</span><br><span class="line">    rs_results[user] = rs_result</span><br><span class="line"></span><br><span class="line">rs_results</span><br></pre></td></tr></table></figure>
<p>打印结果为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;&#39;user1&#39;: &#123;&#39;itemE&#39;&#125;,</span><br><span class="line"> &#39;user2&#39;: &#123;&#39;itemB&#39;, &#39;itemC&#39;&#125;,</span><br><span class="line"> &#39;user3&#39;: &#123;&#39;itemB&#39;, &#39;itemD&#39;, &#39;itemE&#39;&#125;,</span><br><span class="line"> &#39;user4&#39;: &#123;&#39;itemA&#39;, &#39;itemC&#39;&#125;,</span><br><span class="line"> &#39;user5&#39;: &#123;&#39;itemD&#39;&#125;&#125;</span><br></pre></td></tr></table></figure>
<h2 id="数据为评分型"><a href="#数据为评分型" class="headerlink" title="数据为评分型"></a>数据为评分型</h2><p>我们采用皮尔逊相关系数$[-1,1]$来计算，其中-1代表强负相关，+1代表强正相关</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">users = [<span class="string">"user1"</span>, <span class="string">"user2"</span>, <span class="string">"user3"</span>, <span class="string">"user4"</span>, <span class="string">"user5"</span>]</span><br><span class="line">items = [<span class="string">"itemA"</span>, <span class="string">"itemB"</span>, <span class="string">"itemC"</span>, <span class="string">"itemD"</span>, <span class="string">"itemE"</span>,]</span><br><span class="line"></span><br><span class="line">datasets = [</span><br><span class="line">    [<span class="number">5</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="literal">None</span>],</span><br><span class="line">    [<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>],</span><br><span class="line">    [<span class="number">4</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">5</span>],</span><br><span class="line">    [<span class="number">3</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">5</span>,<span class="number">4</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">5</span>,<span class="number">5</span>,<span class="number">2</span>,<span class="number">1</span>],</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(datasets, columns=items, index=users)</span><br><span class="line">print(df)</span><br></pre></td></tr></table></figure>
<p>数据长得这个样：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">       itemA  itemB  itemC  itemD  itemE</span><br><span class="line">user1      <span class="number">5</span>      <span class="number">3</span>      <span class="number">4</span>      <span class="number">4</span>    NaN</span><br><span class="line">user2      <span class="number">3</span>      <span class="number">1</span>      <span class="number">2</span>      <span class="number">3</span>    <span class="number">3.0</span></span><br><span class="line">user3      <span class="number">4</span>      <span class="number">3</span>      <span class="number">4</span>      <span class="number">3</span>    <span class="number">5.0</span></span><br><span class="line">user4      <span class="number">3</span>      <span class="number">3</span>      <span class="number">1</span>      <span class="number">5</span>    <span class="number">4.0</span></span><br><span class="line">user5      <span class="number">1</span>      <span class="number">5</span>      <span class="number">5</span>      <span class="number">2</span>    <span class="number">1.0</span></span><br></pre></td></tr></table></figure>
<p>计算相似度方式为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(<span class="string">"用户相似度矩阵为："</span>)</span><br><span class="line">user_similar = df.T.corr()</span><br><span class="line">print(user_similar.round(<span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">print(<span class="string">"物品相似度矩阵为："</span>)</span><br><span class="line">item_similar = df.corr()</span><br><span class="line">print(item_similar.round(<span class="number">4</span>))</span><br></pre></td></tr></table></figure>
<p>打印结果为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">用户相似度矩阵为：</span><br><span class="line">        user1   user2   user3   user4   user5</span><br><span class="line">user1  1.0000  0.8528  0.7071  0.0000 -0.7921</span><br><span class="line">user2  0.8528  1.0000  0.4677  0.4900 -0.9001</span><br><span class="line">user3  0.7071  0.4677  1.0000 -0.1612 -0.4666</span><br><span class="line">user4  0.0000  0.4900 -0.1612  1.0000 -0.6415</span><br><span class="line">user5 -0.7921 -0.9001 -0.4666 -0.6415  1.0000</span><br><span class="line">物品相似度矩阵为：</span><br><span class="line">        itemA   itemB   itemC   itemD   itemE</span><br><span class="line">itemA  1.0000 -0.4767 -0.1231  0.5322  0.9695</span><br><span class="line">itemB -0.4767  1.0000  0.6455 -0.3101 -0.4781</span><br><span class="line">itemC -0.1231  0.6455  1.0000 -0.7206 -0.4276</span><br><span class="line">itemD  0.5322 -0.3101 -0.7206  1.0000  0.5817</span><br><span class="line">itemE  0.9695 -0.4781 -0.4276  0.5817  1.0000</span><br></pre></td></tr></table></figure>
<p>剩下的就和数据为0-1型的讨论一样了。</p>
]]></content>
      <categories>
        <category>Recommender system</category>
      </categories>
  </entry>
  <entry>
    <title>推荐系统实战（一）</title>
    <url>/posts/bac0d145.html</url>
    <content><![CDATA[<h1 id="一、推荐系统简介"><a href="#一、推荐系统简介" class="headerlink" title="一、推荐系统简介"></a>一、推荐系统简介</h1><p>​        个性化推荐(推荐系统)经历了多年的发展，已经成为互联网产品的标配，也是AI成功落地的分支之一，在电商(淘宝/京东)、资讯(今日头条/微博)、音乐(网易云音乐/QQ音乐)、短视频(抖音/快手)等热门应用中,推荐系统都是核心组件之一。</p>
<h2 id="推荐系统产生背景"><a href="#推荐系统产生背景" class="headerlink" title="推荐系统产生背景"></a>推荐系统产生背景</h2><p><strong>信息过载</strong> <strong>&amp;</strong> <strong>用户需求不明确</strong></p>
<ul>
<li>分类⽬录（1990s）：覆盖少量热门⽹站，如Hao123 和 Yahoo</li>
<li>搜索引擎（2000s）：通过搜索词明确需求，如Google 和 Baidu</li>
<li>推荐系统（2010s）：不需要⽤户提供明确的需求，通过分析⽤户的历史⾏为给⽤户的兴趣进⾏建模，从⽽主动给⽤户推荐能够满⾜他们兴趣和需求的信息。</li>
</ul>
<h2 id="什么是推荐系统"><a href="#什么是推荐系统" class="headerlink" title="什么是推荐系统"></a>什么是推荐系统</h2><p>没有明确需求的用户访问了我们的服务, 且服务的物品对用户构成了信息过载, 系统通过一定的规则<strong>对物品进行排序</strong>,并将排在前面的物品展示给用户,这样的系统就是推荐系统</p>
<h2 id="推荐系统-V-S-搜索引擎"><a href="#推荐系统-V-S-搜索引擎" class="headerlink" title="推荐系统 V.S. 搜索引擎"></a>推荐系统 V.S. 搜索引擎</h2><table>
  <tr>
    <th></th>
    <th>搜索</th>
    <th>推荐</th>
  </tr>
  <tr>
    <td> 行为方式 </td>
    <td> 主动 </td>
    <td> 被动 </td>
  </tr>
  <tr>
    <td> 意图 </td>
    <td> 明确 </td>
    <td> 模糊 </td>
  </tr>
  <tr>
    <td> 个性化 </td>
    <td> 弱 </td>
    <td> 强 </td>
  </tr>
  <tr>
    <td> 流量分布 </td>
    <td> 马太效应 </td>
    <td> 长尾效应 </td>
  </tr>
  <tr>
    <td> 目标 </td>
    <td> 快速满足  </td>
    <td> 持续服务 </td>
  </tr>
  <tr>
    <td> 评估指标 </td>
    <td> 简明 </td>
    <td> 复杂 </td>
  </tr>
</table>

<h2 id="推荐系统的作用"><a href="#推荐系统的作用" class="headerlink" title="推荐系统的作用"></a>推荐系统的作用</h2><ul>
<li>高效连接用户和物品, 发现长尾商品</li>
<li>留住用户和内容生产者, 实现商业目标</li>
</ul>
<h2 id="推荐系统的工作原理"><a href="#推荐系统的工作原理" class="headerlink" title="推荐系统的工作原理"></a>推荐系统的工作原理</h2><ul>
<li><strong>社会化推荐</strong> 向朋友咨询, 社会化推荐, 让好友给自己推荐物品</li>
<li><strong>基于内容的推荐</strong> 打开搜索引擎, 输入自己喜欢的演员的名字, 然后看看返回结果中还有什么电影是自己没看过的</li>
<li><strong>基于流行度的推荐</strong> 查看票房排行榜, </li>
<li><strong>基于协同过滤的推荐</strong> 找到和自己历史兴趣相似的用户, 看看他们最近在看什么电影</li>
</ul>
<h2 id="推荐系统的应用场景"><a href="#推荐系统的应用场景" class="headerlink" title="推荐系统的应用场景"></a>推荐系统的应用场景</h2><p><img src="/Pic/recommend/recommend1.png" alt></p>
<h2 id="推荐系统和Web项目的区别"><a href="#推荐系统和Web项目的区别" class="headerlink" title="推荐系统和Web项目的区别"></a>推荐系统和Web项目的区别</h2><ul>
<li>稳定的信息流通系统 V.S. 通过信息过滤实现目标提升 <ul>
<li>web项目: 复杂逻辑 高并发 高可用</li>
<li>推荐系统: 追求指标增长, 留存率/阅读时间/GMV (Gross Merchandise Volume电商网站成交金额)/视频网站VV (Video View)</li>
</ul>
</li>
<li>确定 V.S. 不确定思维<ul>
<li>web项目: 对结果有确定预期</li>
<li>推荐系统: 结果是概率问题</li>
</ul>
</li>
</ul>
<hr>
<h1 id="二、推荐系统评估"><a href="#二、推荐系统评估" class="headerlink" title="二、推荐系统评估"></a>二、推荐系统评估</h1><p>好的推荐系统可以实现用户, 服务提供方, 内容提供方的共赢</p>
<p><img src="/../../Python/RecSys/%25E6%258E%25A8%25E8%258D%2590%25E7%25B3%25BB%25E7%25BB%259F%25E5%25AD%25A6%25E4%25B9%25A0/%25E9%25BB%2591%25E9%25A9%25AC%25E6%258E%25A8%25E8%258D%2590%25E7%25B3%25BB%25E7%25BB%259F%25E5%25AE%259E%25E6%2588%2598%25E7%25AC%25AC%25E4%25BA%258C%25E6%259C%259F/2.%25E6%258E%25A8%25E8%258D%2590%25E7%25B3%25BB%25E7%25BB%259F%25E3%2580%2590%25E9%25A1%25B9%25E7%259B%25AE%25E3%2580%2591%25E5%25AD%25A6%25E4%25B9%25A0%25E8%25B5%2584%25E6%2596%2599/%25E6%258E%25A8%25E8%258D%2590%25E7%25B3%25BB%25E7%25BB%259F%25E9%25A1%25B9%25E7%259B%25AEday01/%25E8%25B5%2584%25E6%2596%2599/%25E8%25AE%25B2%25E4%25B9%2589/img/recommend2.png" alt></p>
<h2 id="显示反馈和隐式反馈"><a href="#显示反馈和隐式反馈" class="headerlink" title="显示反馈和隐式反馈"></a>显示反馈和隐式反馈</h2><table>
  <tr>
    <th></th>
    <th>显示反馈</th>
    <th>隐式反馈</th>
  </tr>
  <tr>
 <td> 例子 </td>
 <td> 电影/书籍评分 
 是否喜欢这个推荐 </td>
 <td> 播放/点击 评论 下载 购买 </td>
  </tr>
  <tr>
    <td> 准确性 </td>
    <td> 高 </td>
    <td> 低 </td>
  </tr>
  <tr>
    <td> 数量 </td>
    <td> 少 </td>
    <td> 多 </td>
  </tr>
  <tr>
    <td> 获取成本 </td>
    <td> 高 </td>
    <td> 低 </td>
  </tr>
</table>

<h2 id="常用评估指标"><a href="#常用评估指标" class="headerlink" title="常用评估指标"></a>常用评估指标</h2><table>
  <tr>
    <td>准确性</td>
    <td>信任度</td>
  </tr>
  <tr>
     <td> 满意度  </td>
     <td> 实时性 </td>
  </tr>
  <tr>
    <td> 覆盖率 </td>
    <td> 鲁棒性 </td>
  </tr>
  <tr>
    <td> 多样性 </td>
    <td> 可扩展性 </td>
  </tr>
  <tr>
    <td> 新颖性 </td>
    <td> 商业⽬标 </td>
  </tr>
  <tr>
    <td> 惊喜度 </td>
    <td> ⽤户留存 </td>
  </tr>
</table>

<ul>
<li>准确性 (理论角度)<ul>
<li>评分预测<ul>
<li>RMSE   MAE</li>
</ul>
</li>
<li>topN推荐<ul>
<li>召回率 精准率</li>
</ul>
</li>
</ul>
</li>
<li>准确性 (业务角度)</li>
</ul>
<p><img src="/Pic/recommend/recommend3.png" alt></p>
<ul>
<li>覆盖度<ul>
<li>信息熵</li>
<li>覆盖率</li>
</ul>
</li>
<li>多样性&amp;新颖性&amp;惊喜性<ul>
<li>多样性：推荐列表中两两物品的不相似性。（相似性如何度量？</li>
<li>新颖性：未曾关注的类别、作者；推荐结果的平均流⾏度</li>
<li>惊喜性：历史不相似（惊）但很满意（喜）</li>
<li>往往需要牺牲准确性</li>
<li>使⽤历史⾏为预测⽤户对某个物品的喜爱程度</li>
<li>系统过度强调实时性</li>
</ul>
</li>
</ul>
<h2 id="Exploitation-amp-Exploration-探索与利用问题"><a href="#Exploitation-amp-Exploration-探索与利用问题" class="headerlink" title="Exploitation &amp; Exploration 探索与利用问题"></a>Exploitation &amp; Exploration 探索与利用问题</h2><ul>
<li>Exploitation(开发 利用)：选择现在可能最佳的⽅案</li>
<li>Exploration(探测 搜索)：选择现在不确定的⼀些⽅案，但未来可能会有⾼收益的⽅案</li>
<li>在做两类决策的过程中，不断更新对所有决策的不确定性的认知，优化<br>长期的⽬标</li>
<li>EE问题实践<ul>
<li>兴趣扩展: 相似话题, 搭配推荐</li>
<li>人群算法: userCF 用户聚类</li>
<li>平衡个性化推荐和热门推荐比例</li>
<li>随机丢弃用户行为历史</li>
<li>随机扰动模型参数</li>
</ul>
</li>
<li>EE可能带来的问题<ul>
<li>探索伤害用户体验, 可能导致用户流失</li>
<li>探索带来的长期收益(留存率)评估周期长, KPI压力大</li>
<li>如何平衡实时兴趣和长期兴趣</li>
<li>如何平衡短期产品体验和长期系统生态</li>
<li>如何平衡大众口味和小众需求</li>
<li>如何避免劣币驱逐良币</li>
</ul>
</li>
</ul>
<h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2><ul>
<li>问卷调查: 成本高</li>
<li>离线评估:<ul>
<li>只能在用户看到过的候选集上做评估, 且跟线上真实效果存在偏差</li>
<li>只能评估少数指标</li>
<li>速度快, 不损害用户体验</li>
</ul>
</li>
<li>在线评估: 灰度发布 &amp; A/B测试</li>
<li>实践: 离线评估和在线评估结合, 定期做问卷调查</li>
</ul>
<hr>
<h1 id="三、推荐系统设计"><a href="#三、推荐系统设计" class="headerlink" title="三、推荐系统设计"></a>三、推荐系统设计</h1><h2 id="推荐系统要素"><a href="#推荐系统要素" class="headerlink" title="推荐系统要素"></a>推荐系统要素</h2><ul>
<li>UI 和 UE(前端界面)</li>
<li>数据 (Lambda架构)</li>
<li>业务知识</li>
<li>算法</li>
</ul>
<h2 id="推荐系统架构"><a href="#推荐系统架构" class="headerlink" title="推荐系统架构"></a>推荐系统架构</h2><ul>
<li><p>推荐系统整体架构</p>
<p><img src="/Pic/recommend/%E6%8E%A8%E8%8D%90%E6%B5%81%E7%A8%8B.png" alt></p>
</li>
<li><p>大数据Lambda架构</p>
<ul>
<li><p>由Twitter工程师Nathan Marz(storm项目发起人)提出</p>
</li>
<li><p>Lambda系统架构提供了一个结合实时数据和Hadoop预先计算的数据环境和混合平台, 提供一个实时的数据视图</p>
</li>
<li><p>分层架构</p>
<ul>
<li>批处理层<ul>
<li>数据不可变, 可进行任何计算, 可水平扩展</li>
<li>高延迟  几分钟~几小时(计算量和数据量不同)</li>
<li>日志收集 Flume</li>
<li>分布式存储 Hadoop</li>
<li>分布式计算 Hadoop MapReduce &amp; spark</li>
<li>视图存储数据库<ul>
<li>nosql(HBase/Cassandra)</li>
<li>Redis/memcache</li>
<li>MySQL</li>
</ul>
</li>
</ul>
</li>
<li>实时处理层<ul>
<li>流式处理, 持续计算</li>
<li>存储和分析某个窗口期内的数据</li>
<li>最终正确性(Eventual accuracy)</li>
<li>实时数据收集 flume &amp; kafka</li>
<li>实时数据分析  spark streaming/storm/flink</li>
</ul>
</li>
<li>服务层<ul>
<li>支持随机读</li>
<li>需要在非常短的时间内返回结果</li>
<li>读取批处理层和实时处理层结果并对其归并</li>
</ul>
</li>
</ul>
</li>
<li><p>Lambda架构图</p>
<p><img src="/Pic/recommend/lambda3.png" alt></p>
</li>
</ul>
</li>
<li><p>推荐算法架构</p>
<ul>
<li>召回阶段(海选)<ul>
<li>召回决定了最终推荐结果的天花板</li>
<li>常用算法:<ul>
<li>基于用户行为的协同过滤</li>
<li>基于内容 (根据用户行为总结出自己的偏好)</li>
<li>基于隐语义</li>
</ul>
</li>
</ul>
</li>
<li>排序阶段<ul>
<li>召回决定了最终推荐结果的天花板, 排序逼近这个极限, 决定了最终的推荐效果</li>
<li>CTR预估 (点击率预估 使用LR算法)</li>
</ul>
</li>
<li>策略调整</li>
</ul>
</li>
</ul>
<p><img src="/Pic/recommend/recommend7.jpeg" alt></p>
<ul>
<li><p>推荐系统的整体架构</p>
<ul>
<li>业务架构</li>
</ul>
<p><img src="/Pic/recommend/rs%E5%9F%BA%E7%A1%80%E4%B8%9A%E5%8A%A1%E6%9E%B6%E6%9E%84.png" alt></p>
<ul>
<li>技术架构</li>
</ul>
<p><img src="/Pic/recommend/rs%E5%9F%BA%E7%A1%80%E6%8A%80%E6%9C%AF%E6%9E%B6%E6%9E%84.png" alt></p>
</li>
</ul>
]]></content>
      <categories>
        <category>Recommender system</category>
      </categories>
  </entry>
  <entry>
    <title>迁移学习（一）</title>
    <url>/posts/2c576f47.html</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>Transfer Learning</category>
      </categories>
  </entry>
  <entry>
    <title>CNN 卷积神经网络</title>
    <url>/posts/d7d85f1a.html</url>
    <content><![CDATA[<h1 id="卷积神经网络简介"><a href="#卷积神经网络简介" class="headerlink" title="卷积神经网络简介"></a>卷积神经网络简介</h1><h2 id="卷积神经网络主要层次"><a href="#卷积神经网络主要层次" class="headerlink" title="卷积神经网络主要层次"></a>卷积神经网络主要层次</h2><ul>
<li>数据输入层：Input layer</li>
<li>卷积计算层：CONV layer</li>
<li>ReLU激活层：ReLU layer</li>
<li>池化层：Pooling layer</li>
<li>全连接层：FC layer</li>
</ul>
<p><strong>激活层建议：</strong></p>
<ul>
<li>CNN尽量不要使用Sigmoid，如果要使用，建议只在全连接层使用</li>
<li>首先使用ReLU，因为迭代速度快，但有可能效果不佳</li>
<li>如果使用ReLU失效，考虑使用Leaky ReLU或者Maxout，一般都能解决的</li>
<li>tanh激活函数在某些情况下有比较好的效果，但是应用场景比较少</li>
</ul>
<p><strong>池化层：</strong> 在池化层中，进行压缩减小特征数量时常用两种策略：</p>
<ul>
<li>Max Pooling：最大池化，一般采用这种方式</li>
<li>Average Pooling：平均池化</li>
</ul>
<p><strong>全连接层：</strong> 两层之间所有神经元都有权重连接；通常情况下，在CNN中，FC层只有在尾部出现</p>
<p><strong>CNN结构</strong>： 一般为：</p>
<ul>
<li>Input</li>
<li>[[CONV ——&gt; ReLU] <em> N ——&gt;Pooling?] </em> M</li>
<li>[FC——&gt;ReLU] * K</li>
<li>FC</li>
</ul>
<h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p><strong>与神经网络/机器学习一样，需要对输入的数据进行预处理操作，主要原因是：</strong></p>
<ul>
<li>输入数据单位不一样，可能会导致神经网络收敛速度慢，训练时间长</li>
<li>数据范围大的输入在模式分类中的作用可能偏大，而数据范围小的作用可能就偏小</li>
<li>由于神经网络中存在的激活函数是由值域限制的，因此需要将网络训练的目标数据映射到激活函数的值域</li>
<li>Sigmoid型激活函数在（0，1）区间以外区域很平缓，区分度太小</li>
</ul>
<p><strong>常见的3种数据预处理方式：</strong></p>
<ul>
<li>去均值<ul>
<li>将输入数据的各个维度中心化到0</li>
</ul>
</li>
<li>归一化<ul>
<li>将输入数据的各个维度的幅度归一化到同样的范围</li>
</ul>
</li>
<li>PCA/白化<ul>
<li>PCA降维</li>
<li>白化是对数据的每个特征轴上的幅度归一化</li>
</ul>
</li>
</ul>
<p><strong>白化使得学习算法的输入具有如下性质：</strong></p>
<ul>
<li>特征之间相关性较低</li>
<li>所有特征具有相同的方差</li>
</ul>
<h1 id="卷积神经网络优缺点"><a href="#卷积神经网络优缺点" class="headerlink" title="卷积神经网络优缺点"></a>卷积神经网络优缺点</h1><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><ul>
<li>共享卷积核（共享参数），对高维数据的处理没有压力</li>
<li>无需选择特征属性，只要训练好权重，即可得到特征值</li>
<li>深层次的网络抽取图像信息比较丰富，表达效果好</li>
</ul>
<h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><ul>
<li>需要调参，需要大量样本，训练迭代次数比较多，最好使用GPU训练</li>
<li>物理含义不明确，从每层输出中很难看出含义</li>
</ul>
<h1 id="卷积神经网络正则化和Dropout"><a href="#卷积神经网络正则化和Dropout" class="headerlink" title="卷积神经网络正则化和Dropout"></a>卷积神经网络正则化和Dropout</h1><p>神经网络的学习能力受神经元数目以及神经网络层次的影响，神经元数目越大，神经网络层次越高，那么神经网络的学习能力越强，那么就有可能出现过拟合的问题。正则化通过给cost函数添加正则项的方式来解决overfitting，Dropout是通过直接修改神经网络的结构来解决overfitting。</p>
<h2 id="Regulation"><a href="#Regulation" class="headerlink" title="Regulation"></a>Regulation</h2><p>正则化的目的是降低模型复杂度，通过在cost函数上添加一个正则项的方式来降低overfitting，主要有L1和L2两种方式</p>
<ul>
<li>L1：若希望知道哪个特征对最后结果产生了比较大的影响则使用之</li>
<li>L2：不在意对特征的分析</li>
</ul>
<h2 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h2><p>通过随即删除神经网络中的神经元来解决overfitting的问题，在每次迭代的时候，只使用部分神经元训练模型获取W和d的值，其目的是：</p>
<ul>
<li>不要CNN具有太多的泛化能力（不能依赖某几个神经元）</li>
<li>多次迭代结果的合并可以增加模型的准确，多个不同模型的合并可以提高其准确率</li>
</ul>
<p>一般情况下，对于同一组训练数据，利用不同的神经网络训练后，求其输出的平均值可以减少overfitting，Dropout就是利用这个原理，每次丢掉一半左右的隐藏神经元，相当于在不同的神经网络上训练，这样就减少了神经元之间的依赖性，即每个神经元不能依赖于某几个其他的神经元（指层与层之间相连接的神经元），使神经网络更加能学习到与其他神经元之间的更加robost的特征，另外Dropout不仅减少overfitting，还能提高准确率</p>
<h1 id="实现卷积神经网络"><a href="#实现卷积神经网络" class="headerlink" title="实现卷积神经网络"></a>实现卷积神经网络</h1><p>参数表：</p>
<ul>
<li>W1：是Layer1到Layer2的权重</li>
<li>b1：是Layer1到Layer2转换的截距</li>
<li>W2：是Layer2到Layer3的权重</li>
<li>b2：是Layer2到Layer3转换的截距</li>
<li>W3：是Layer3到Layer4的权重</li>
<li>b3：是Layer3到Layer4转换的截距</li>
<li>Dropout的概率为 p=0.5</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">p = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(X)</span>:</span></span><br><span class="line">    H1 = np.maximum(<span class="number">0</span>, np.dot(W1, X) + b1)</span><br><span class="line">    U1 = (np.random.rand(*H1.shape) &lt; p) / p</span><br><span class="line">    H1 *= U1</span><br><span class="line">    H2 = np.maximum(<span class="number">0</span>, np.dot(W2, H1) + b2)</span><br><span class="line">    U1 = (np.random.rand(*H2.shape) &lt; p) / p</span><br><span class="line">    H2 *= U2</span><br><span class="line">    out = np.dot(W3, H2) + b3</span><br><span class="line">    <span class="comment"># BP操作，计算梯度（省略）</span></span><br><span class="line">    <span class="comment"># 参数更新（省略）</span></span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(X)</span>:</span></span><br><span class="line">    H1 = np.maximum(<span class="number">0</span>, np.dot(W1, X) + b1)</span><br><span class="line">    H2 = np.maximum(<span class="number">0</span>, np.dot(W2, H1) + b2)</span><br><span class="line">    out = np.dot(W3, H2) + b3</span><br></pre></td></tr></table></figure>
<h1 id="卷积神经网络典型CNN"><a href="#卷积神经网络典型CNN" class="headerlink" title="卷积神经网络典型CNN"></a>卷积神经网络典型CNN</h1><ul>
<li>LeNet：最早用于数字识别的CNN，主要用于字符识别<br><img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1597059891678&amp;di=d80a92349c0e954b2a286ff74993bb1b&amp;imgtype=0&amp;src=http%3A%2F%2F5b0988e595225.cdn.sohucs.com%2Fimages%2F20180514%2Ff9524f078368481f8366c434da8d0e1a.png" alt></li>
<li>AlexNet：2012年ILSVRC比赛冠军，远超第二名的CNN，比LeNet更深，用多层小卷积叠加来替换单个的大卷积<br><img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1597060606682&amp;di=5dae3114e300abb27108fdc2b743c09c&amp;imgtype=0&amp;src=http%3A%2F%2Fimg2018.cnblogs.com%2Fblog%2F439761%2F201901%2F439761-20190129114344192-623663293.jpg" alt></li>
<li>ZF Net：2013 ILSVRC冠军<ul>
<li>基于AlexNet进行微调</li>
<li>Top5错误率11.2%</li>
<li>使用ReLU激活函数和交叉熵损失函数</li>
</ul>
</li>
<li>GoogleNet：2014 ILSVRC冠军(层次很深)<br><img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1597060786492&amp;di=e0bfdd91ac30a5d0061e30084be5190f&amp;imgtype=0&amp;src=http%3A%2F%2Fimage.bubuko.com%2Finfo%2F201803%2F20180307165329526469.png" alt><br><img src="https://ss0.bdstatic.com/70cFuHSh_Q1YnxGkpoWK1HF6hhy/it/u=220584882,329355430&amp;fm=26&amp;gp=0.jpg" alt></li>
<li>VGGNet：2014ILSVRC比赛中算法模型，效果略低于GoogleNet<br><img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1597060916889&amp;di=4d3c057e379782ec0312bee9ea748f30&amp;imgtype=0&amp;src=http%3A%2F%2Flanbing510.info%2Fpublic%2Fimg%2Fposts%2Fvggnet.png" alt></li>
<li>ResNet：2015ILSVRC冠军，结构修正以适应更深层次的CNN训练(残差连接)<ul>
<li>允许模型存在一些shortcuts，可以让研究者成功地训练更深的神经网络，这样也能明显地优化Inception块<br><img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1597061053081&amp;di=9230f77241bff311478913d33f72e0ef&amp;imgtype=0&amp;src=http%3A%2F%2F5b0988e595225.cdn.sohucs.com%2Fimages%2F20170901%2F22800c4024924f8a946ed8a7bc4d1d76.jpeg" alt></li>
</ul>
</li>
</ul>
<h1 id="卷积神经网络案例"><a href="#卷积神经网络案例" class="headerlink" title="卷积神经网络案例"></a>卷积神经网络案例</h1><p>任务：CNN卷积神经网络手写数字</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mnist = input_data.read_data_sets(<span class="string">'MNIST_data'</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">X_holder = tf.placeholder(tf.float32)</span><br><span class="line">y_holder = tf.placeholder(tf.float32)</span><br></pre></td></tr></table></figure>
<pre><code>Extracting MNIST_data\train-images-idx3-ubyte.gz
Extracting MNIST_data\train-labels-idx1-ubyte.gz
Extracting MNIST_data\t10k-images-idx3-ubyte.gz
Extracting MNIST_data\t10k-labels-idx1-ubyte.gz
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X_images = tf.reshape(X_holder, [<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>])</span><br><span class="line"><span class="comment">#convolutional layer 1</span></span><br><span class="line">conv1_Weights = tf.Variable(tf.truncated_normal([<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">32</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">conv1_biases = tf.Variable(tf.constant(<span class="number">0.1</span>, shape=[<span class="number">32</span>]))</span><br><span class="line">conv1_conv2d = tf.nn.conv2d(X_images, conv1_Weights, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>) + conv1_biases</span><br><span class="line">conv1_activated = tf.nn.relu(conv1_conv2d)</span><br><span class="line">conv1_pooled = tf.nn.max_pool(conv1_activated, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line"><span class="comment">#convolutional layer 2</span></span><br><span class="line">conv2_Weights = tf.Variable(tf.truncated_normal([<span class="number">5</span>, <span class="number">5</span>, <span class="number">32</span>, <span class="number">64</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">conv2_biases = tf.Variable(tf.constant(<span class="number">0.1</span>, shape=[<span class="number">64</span>]))</span><br><span class="line">conv2_conv2d = tf.nn.conv2d(conv1_pooled, conv2_Weights, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>) + conv2_biases</span><br><span class="line">conv2_activated = tf.nn.relu(conv2_conv2d)</span><br><span class="line">conv2_pooled = tf.nn.max_pool(conv2_activated, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line"><span class="comment">#full connected layer 1</span></span><br><span class="line">connect1_flat = tf.reshape(conv2_pooled, [<span class="number">-1</span>, <span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>])</span><br><span class="line">connect1_Weights = tf.Variable(tf.truncated_normal([<span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>, <span class="number">1024</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">connect1_biases = tf.Variable(tf.constant(<span class="number">0.1</span>, shape=[<span class="number">1024</span>]))</span><br><span class="line">connect1_Wx_plus_b = tf.add(tf.matmul(connect1_flat, connect1_Weights), connect1_biases)</span><br><span class="line">connect1_activated = tf.nn.relu(connect1_Wx_plus_b)</span><br><span class="line"><span class="comment">#full connected layer 2</span></span><br><span class="line">connect2_Weights = tf.Variable(tf.truncated_normal([<span class="number">1024</span>, <span class="number">10</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">connect2_biases = tf.Variable(tf.constant(<span class="number">0.1</span>, shape=[<span class="number">10</span>]))</span><br><span class="line">connect2_Wx_plus_b = tf.add(tf.matmul(connect1_activated, connect2_Weights), connect2_biases)</span><br><span class="line">predict_y = tf.nn.softmax(connect2_Wx_plus_b)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#loss and train</span></span><br><span class="line">loss = tf.reduce_mean(-tf.reduce_sum(y_holder * tf.log(predict_y), <span class="number">1</span>))</span><br><span class="line">optimizer = tf.train.AdamOptimizer(<span class="number">0.0001</span>)</span><br><span class="line">train = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">session = tf.Session()</span><br><span class="line">session.run(init)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1001</span>):</span><br><span class="line">    train_images, train_labels = mnist.train.next_batch(<span class="number">200</span>)</span><br><span class="line">    session.run(train, feed_dict=&#123;X_holder:train_images, y_holder:train_labels&#125;)</span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        correct_prediction = tf.equal(tf.argmax(predict_y, <span class="number">1</span>), tf.argmax(y_holder, <span class="number">1</span>))</span><br><span class="line">        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line">        test_images, test_labels = mnist.test.next_batch(<span class="number">2000</span>)</span><br><span class="line">        train_accuracy = session.run(accuracy, feed_dict=&#123;X_holder:train_images, y_holder:train_labels&#125;)</span><br><span class="line">        test_accuracy = session.run(accuracy, feed_dict=&#123;X_holder:test_images, y_holder:test_labels&#125;)</span><br><span class="line">        print(<span class="string">'step:%d train accuracy:%.4f test accuracy:%.4f'</span> %(i, train_accuracy, test_accuracy))</span><br></pre></td></tr></table></figure>
<pre><code>step:0 train accuracy:0.0700 test accuracy:0.0685
step:100 train accuracy:0.8650 test accuracy:0.8935
step:200 train accuracy:0.9200 test accuracy:0.9255
step:300 train accuracy:0.9500 test accuracy:0.9460
step:400 train accuracy:0.9600 test accuracy:0.9595
step:500 train accuracy:0.9850 test accuracy:0.9715
step:600 train accuracy:0.9650 test accuracy:0.9680
step:700 train accuracy:0.9700 test accuracy:0.9690
step:800 train accuracy:0.9600 test accuracy:0.9760
step:900 train accuracy:0.9800 test accuracy:0.9765
step:1000 train accuracy:0.9850 test accuracy:0.9760
</code></pre>]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
  </entry>
  <entry>
    <title>Leetcode刷题专题打卡——双指针</title>
    <url>/posts/65675e23.html</url>
    <content><![CDATA[<h1 id="C-和-Python-中的链表结构"><a href="#C-和-Python-中的链表结构" class="headerlink" title="C# 和 Python 中的链表结构"></a>C# 和 Python 中的链表结构</h1><p>本文主要来自<a href="https://github.com/datawhalechina/team-learning-program/blob/master/LeetCodeClassification/4.%20%E5%8F%8C%E6%8C%87%E9%92%88%E6%8A%80%E6%9C%AF.md" target="_blank" rel="noopener">Datawhale组队学习——双指针技术</a>~</p>
<p>Python <code>list</code> 的源码地址：</p>
<p><a href="https://github.com/python/cpython/blob/master/Include/listobject.h" target="_blank" rel="noopener">https://github.com/python/cpython/blob/master/Include/listobject.h</a></p>
<p><a href="https://github.com/python/cpython/blob/master/Objects/listobject.c" target="_blank" rel="noopener">https://github.com/python/cpython/blob/master/Objects/listobject.c</a></p>
<p>C# <code>List&lt;T&gt;</code> 的源码地址：</p>
<p><a href="https://referencesource.microsoft.com/#mscorlib/system/collections/generic/list.cs,cf7f4095e4de7646" target="_blank" rel="noopener">https://referencesource.microsoft.com/#mscorlib/system/collections/generic/list.cs,cf7f4095e4de7646</a></p>
<p>通过阅读源码，我们发现 Python 的 <code>list</code> 与 C# 的 <code>List&lt;T&gt;</code> 一致都是通过动态数组的方式来实现的。</p>
<p>Python 的内置结构中没有链表这种结构，而C# 的内置结构中封装了双向链表 <code>LinkedList&lt;T&gt;</code>，内部结点为 <code>LinkedListNode&lt;T&gt;</code>，源码地址如下：</p>
<p><a href="https://referencesource.microsoft.com/#System/compmod/system/collections/generic/linkedlist.cs,df5a6c7b6b60da4f" target="_blank" rel="noopener">https://referencesource.microsoft.com/#System/compmod/system/collections/generic/linkedlist.cs,df5a6c7b6b60da4f</a></p>
<p><strong>LinkedListNode</strong></p>
<ul>
<li><code>public LinkedListNode&lt;T&gt; Next { get; }</code> -&gt; 获取下一个节点</li>
<li><code>public LinkedListNode&lt;T&gt; Previous { get; }</code> -&gt; 获取上一个节点</li>
<li><code>public T Value { get; set; }</code> -&gt; 获取或设置包含在节点中的值。</li>
</ul>
<p><strong>LinkedList</strong></p>
<ul>
<li><code>public LinkedListNode&lt;T&gt; AddFirst(T value);</code> -&gt; 添加包含指定的值的开头的新节点</li>
<li><code>public LinkedListNode&lt;T&gt; AddLast(T value);</code> -&gt; 添加包含指定的值的末尾的新节点</li>
<li><code>public LinkedListNode&lt;T&gt; AddBefore(LinkedListNode&lt;T&gt; node, T value);</code> -&gt; 添加包含在指定的现有节点前的指定的值的新节点</li>
<li><code>public LinkedListNode&lt;T&gt; AddAfter(LinkedListNode&lt;T&gt; node, T value);</code> -&gt; 添加包含指定的值中指定的现有节点后的新节点</li>
<li><code>public void AddFirst(LinkedListNode&lt;T&gt; node);</code> -&gt; 将指定的新节点添加的开头</li>
<li><code>public void AddLast(LinkedListNode&lt;T&gt; node);</code> -&gt; 将指定的新节点添加的末尾</li>
<li><code>public void AddBefore(LinkedListNode&lt;T&gt; node, LinkedListNode&lt;T&gt; newNode);</code> -&gt; 在指定的现有节点之前添加指定的新节点</li>
<li><code>public void AddAfter(LinkedListNode&lt;T&gt; node, LinkedListNode&lt;T&gt; newNode);</code> -&gt; 在指定的现有节点之后添加指定的新节点</li>
<li><code>public bool Remove(T value);</code> -&gt; 移除从指定的值的第一个匹配项</li>
<li><code>public void Remove(LinkedListNode&lt;T&gt; node);</code> -&gt; 移除指定的节点</li>
<li><code>public void RemoveFirst();</code> -&gt; 删除的开始处的节点</li>
<li><code>public void RemoveLast();</code> -&gt; 删除节点的末尾</li>
<li><code>public LinkedListNode&lt;T&gt; Find(T value);</code> -&gt; 查找包含指定的值的第一个节点。</li>
<li><code>public LinkedListNode&lt;T&gt; FindLast(T value);</code> -&gt; 查找包含指定的值的最后一个节点。</li>
<li><code>public void Clear();</code> -&gt; 删除所有节点</li>
<li><code>public int Count { get; }</code> -&gt; 获取中实际包含的节点数</li>
<li><code>public LinkedListNode&lt;T&gt; First { get; }</code> -&gt; 获取的第一个节点</li>
<li><code>public LinkedListNode&lt;T&gt; Last { get; }</code> -&gt; 获取的最后一个节点</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">public static void LinkedListSample()</span><br><span class="line">&#123;</span><br><span class="line">    LinkedList&lt;int&gt; lst = new LinkedList&lt;int&gt;();</span><br><span class="line">    lst.AddFirst(<span class="number">3</span>);</span><br><span class="line">    lst.AddLast(<span class="number">1</span>);</span><br><span class="line">    lst.AddLast(<span class="number">4</span>);</span><br><span class="line">    foreach (int item <span class="keyword">in</span> lst)</span><br><span class="line">    &#123;</span><br><span class="line">        Console.Write(item+<span class="string">" "</span>); </span><br><span class="line">    &#125;</span><br><span class="line">    Console.WriteLine();</span><br><span class="line">    </span><br><span class="line">    LinkedListNode&lt;int&gt; cur = lst.Find(<span class="number">3</span>);</span><br><span class="line">    lst.AddBefore(cur, <span class="number">2</span>);</span><br><span class="line">    foreach (int item <span class="keyword">in</span> lst)</span><br><span class="line">    &#123;</span><br><span class="line">        Console.Write(item + <span class="string">" "</span>); </span><br><span class="line">    &#125;</span><br><span class="line">    Console.WriteLine();</span><br><span class="line">    </span><br><span class="line">    lst.Remove(<span class="number">3</span>);</span><br><span class="line">    foreach (int item <span class="keyword">in</span> lst)</span><br><span class="line">    &#123;</span><br><span class="line">        Console.Write(item + <span class="string">" "</span>); </span><br><span class="line">    &#125;</span><br><span class="line">    Console.WriteLine();</span><br><span class="line">    lst.Clear();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// <span class="number">3</span> <span class="number">1</span> <span class="number">4</span></span><br><span class="line">// <span class="number">2</span> <span class="number">3</span> <span class="number">1</span> <span class="number">4</span></span><br><span class="line">// <span class="number">2</span> <span class="number">1</span> <span class="number">4</span></span><br></pre></td></tr></table></figure>
<h1 id="反转链表"><a href="#反转链表" class="headerlink" title="反转链表"></a>反转链表</h1><blockquote>
<ul>
<li>题号：206</li>
<li>难度：简单</li>
<li><a href="https://leetcode-cn.com/problems/reverse-linked-list/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/reverse-linked-list/</a></li>
</ul>
</blockquote>
<p>反转一个单链表。</p>
<p><strong>示例</strong>:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入: 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;NULL</span><br><span class="line">输出: 5-&gt;4-&gt;3-&gt;2-&gt;1-&gt;NULL</span><br></pre></td></tr></table></figure>
<p><strong>进阶</strong>:</p>
<p>你可以迭代或递归地反转链表。你能否用两种方法解决这道题？</p>
<p><strong>思路：利用双指针的方式</strong></p>
<p><code>p1</code>作为前面的指针探路，<code>p2</code>作为后面的指针跟进，顺着链表跑一圈，搞定问题。</p>
<p><strong>C# 语言</strong></p>
<ul>
<li>状态：通过</li>
<li>27 / 27 个通过测试用例</li>
<li>执行用时: 116 ms, 在所有 C# 提交中击败了 97.50% 的用户</li>
<li>内存消耗: 23.3 MB, 在所有 C# 提交中击败了 5.26% 的用户</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Definition <span class="keyword">for</span> singly-linked list.</span><br><span class="line"> * public class ListNode &#123;</span><br><span class="line"> *     public int val;</span><br><span class="line"> *     public ListNode next;</span><br><span class="line"> *     public ListNode(int x) &#123; val = x; &#125;</span><br><span class="line"> * &#125;</span><br><span class="line"> */</span><br><span class="line"></span><br><span class="line">public <span class="class"><span class="keyword">class</span> <span class="title">Solution</span></span></span><br><span class="line">&#123;</span><br><span class="line">    public ListNode ReverseList(ListNode head)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (head == null || head.next == null)</span><br><span class="line">            <span class="keyword">return</span> head;</span><br><span class="line">            </span><br><span class="line">        ListNode p1 = head;</span><br><span class="line">        ListNode p2 = null;</span><br><span class="line">        <span class="keyword">while</span> (p1 != null)</span><br><span class="line">        &#123;</span><br><span class="line">            ListNode temp = p1.next;</span><br><span class="line">            p1.next = p2;</span><br><span class="line">            p2 = p1;</span><br><span class="line">            p1 = temp;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> p2;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>Python 语言</strong></p>
<ul>
<li>执行结果：通过</li>
<li>执行用时：36 ms, 在所有 Python3 提交中击败了 92.27% 的用户</li>
<li>内存消耗：14.6 MB, 在所有 Python3 提交中击败了 17.65% 的用户</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.next = None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reverseList</span><span class="params">(self, head: ListNode)</span> -&gt; ListNode:</span></span><br><span class="line">        <span class="keyword">if</span> head <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> head.next <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> head</span><br><span class="line">        p1 = head</span><br><span class="line">        p2 = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">while</span> p1 <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            temp = p1.next</span><br><span class="line">            p1.next = p2</span><br><span class="line">            p2 = p1</span><br><span class="line">            p1 = temp</span><br><span class="line">        <span class="keyword">return</span> p2</span><br></pre></td></tr></table></figure>
<h1 id="删除链表的倒数第N个节点"><a href="#删除链表的倒数第N个节点" class="headerlink" title="删除链表的倒数第N个节点"></a>删除链表的倒数第N个节点</h1><blockquote>
<ul>
<li>题号：19</li>
<li>难度：中等</li>
<li><a href="https://leetcode-cn.com/problems/remove-nth-node-from-end-of-list/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/remove-nth-node-from-end-of-list/</a></li>
</ul>
</blockquote>
<p>给定一个链表，删除链表的倒数第<code>n</code>个节点，并且返回链表的头结点。</p>
<p><strong>示例</strong>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">给定一个链表: 1-&gt;2-&gt;3-&gt;4-&gt;5, 和 n &#x3D; 2.</span><br><span class="line"></span><br><span class="line">当删除了倒数第二个节点后，链表变为 1-&gt;2-&gt;3-&gt;5.</span><br></pre></td></tr></table></figure>
<p><strong>说明</strong>：</p>
<p>给定的<code>n</code>保证是有效的。</p>
<p><strong>进阶</strong>：</p>
<p>你能尝试使用一趟扫描实现吗？</p>
<p><strong>思路：利用双指针的方式</strong></p>
<p>使用两个指针，前面的指针<code>p1</code>先走<code>n</code>步，接着让后面的指针<code>p2</code>与<code>p1</code>同步走，<code>p1</code>走到终点，<code>p2</code>即走到要移除的结点位置。</p>
<p><strong>C# 语言</strong></p>
<ul>
<li>执行结果：通过</li>
<li>执行用时：104 ms, 在所有 C# 提交中击败了 86.93% 的用户</li>
<li>内存消耗：24.6 MB, 在所有 C# 提交中击败了 100.00% 的用户</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Definition <span class="keyword">for</span> singly-linked list.</span><br><span class="line"> * public class ListNode &#123;</span><br><span class="line"> *     public int val;</span><br><span class="line"> *     public ListNode next;</span><br><span class="line"> *     public ListNode(int x) &#123; val = x; &#125;</span><br><span class="line"> * &#125;</span><br><span class="line"> */</span><br><span class="line">public <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span></span><br><span class="line">&#123;</span><br><span class="line">    public ListNode RemoveNthFromEnd(ListNode head, int n) </span><br><span class="line">    &#123;</span><br><span class="line">        ListNode p1 = head;</span><br><span class="line">        ListNode p2 = head;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span> (n &gt; <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            p1 = p1.next;</span><br><span class="line">            n--;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (p1 == null) //移除头结点</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> head.next;</span><br><span class="line">        &#125;</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">while</span> (p1.next != null)</span><br><span class="line">        &#123;</span><br><span class="line">            p1 = p1.next;</span><br><span class="line">            p2 = p2.next;</span><br><span class="line">        &#125;</span><br><span class="line">            </span><br><span class="line">        p2.next = p2.next.next;</span><br><span class="line">        <span class="keyword">return</span> head;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>Python 语言</strong></p>
<ul>
<li>执行结果：通过</li>
<li>执行用时：48 ms, 在所有 Python3 提交中击败了 23.58% 的用户</li>
<li>内存消耗：13.5 MB, 在所有 Python3 提交中击败了 7.83% 的用户</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.next = None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">removeNthFromEnd</span><span class="params">(self, head: ListNode, n: int)</span> -&gt; ListNode:</span></span><br><span class="line">        p2 = head</span><br><span class="line">        p1 = head</span><br><span class="line">        <span class="keyword">while</span> (n &gt; <span class="number">0</span>):</span><br><span class="line">            p1 = p1.next</span><br><span class="line">            n -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (p1 <span class="keyword">is</span> <span class="literal">None</span>):  <span class="comment"># 移除头结点</span></span><br><span class="line">            <span class="keyword">return</span> head.next</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (p1.next):</span><br><span class="line">            p2 = p2.next</span><br><span class="line">            p1 = p1.next</span><br><span class="line"></span><br><span class="line">        p2.next = p2.next.next</span><br><span class="line">        <span class="keyword">return</span> head</span><br></pre></td></tr></table></figure>
<h1 id="删除排序链表中的重复元素"><a href="#删除排序链表中的重复元素" class="headerlink" title="删除排序链表中的重复元素"></a>删除排序链表中的重复元素</h1><blockquote>
<ul>
<li>题号：83</li>
<li>难度：简单</li>
<li><a href="https://leetcode-cn.com/problems/remove-duplicates-from-sorted-list/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/remove-duplicates-from-sorted-list/</a></li>
</ul>
</blockquote>
<p>给定一个排序链表，删除所有重复的元素，使得每个元素只出现一次。</p>
<p><strong>示例 1:</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入: 1-&gt;1-&gt;2</span><br><span class="line">输出: 1-&gt;2</span><br></pre></td></tr></table></figure>
<p><strong>示例 2:</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入: 1-&gt;1-&gt;2-&gt;3-&gt;3</span><br><span class="line">输出: 1-&gt;2-&gt;3</span><br></pre></td></tr></table></figure>
<p><strong>思路：利用双指针的方式</strong></p>
<p><code>p1</code>作为前面的指针探路，<code>p2</code>作为后面的指针跟进，如果遇到重复元素，<code>p2.next</code>跳过去，<code>p1</code>跑完整个链表所有重复元素都被摘下来。</p>
<p><strong>C# 语言</strong></p>
<ul>
<li>执行结果：通过</li>
<li>执行用时：160 ms, 在所有 C# 提交中击败了 5.23% 的用户</li>
<li>内存消耗：25.9 MB, 在所有 C# 提交中击败了 5.72% 的用户</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Definition <span class="keyword">for</span> singly-linked list.</span><br><span class="line"> * public class ListNode &#123;</span><br><span class="line"> *     public int val;</span><br><span class="line"> *     public ListNode next;</span><br><span class="line"> *     public ListNode(int x) &#123; val = x; &#125;</span><br><span class="line"> * &#125;</span><br><span class="line"> */</span><br><span class="line"> </span><br><span class="line">public <span class="class"><span class="keyword">class</span> <span class="title">Solution</span></span></span><br><span class="line">&#123;</span><br><span class="line">    public ListNode DeleteDuplicates(ListNode head)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (head == null)</span><br><span class="line">            <span class="keyword">return</span> head;</span><br><span class="line"></span><br><span class="line">        ListNode p1 = head.next;</span><br><span class="line">        ListNode p2 = head;</span><br><span class="line">        <span class="keyword">while</span> (p1 != null)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (p1.val == p2.val)</span><br><span class="line">                p2.next = p1.next;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                p2 = p2.next;</span><br><span class="line">            p1 = p1.next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> head;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>Python 语言</strong></p>
<ul>
<li>执行结果：通过</li>
<li>执行用时：52 ms, 在所有 Python3 提交中击败了 33.88% 的用户</li>
<li>内存消耗：13.5 MB, 在所有 Python3 提交中击败了 12.75% 的用户</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.next = None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">deleteDuplicates</span><span class="params">(self, head: ListNode)</span> -&gt; ListNode:</span></span><br><span class="line">        <span class="keyword">if</span> head <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> head</span><br><span class="line">            </span><br><span class="line">        p1 = head.next</span><br><span class="line">        p2 = head</span><br><span class="line">        <span class="keyword">while</span> p1 <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> p1.val == p2.val:</span><br><span class="line">                p2.next = p1.next</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                p2 = p2.next</span><br><span class="line">            p1 = p1.next</span><br><span class="line">        <span class="keyword">return</span> head</span><br></pre></td></tr></table></figure>
<h1 id="环形链表"><a href="#环形链表" class="headerlink" title="环形链表"></a>环形链表</h1><blockquote>
<ul>
<li>题号：141</li>
<li>难度：简单</li>
<li><a href="https://leetcode-cn.com/problems/linked-list-cycle/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/linked-list-cycle/</a></li>
</ul>
</blockquote>
<p>给定一个链表，判断链表中是否有环。</p>
<p>为了表示给定链表中的环，我们使用整数<code>pos</code> 来表示链表尾连接到链表中的位置（索引从 0 开始）。 如果<code>pos</code>是 -1，则在该链表中没有环。</p>
<p><strong>示例 1</strong>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入：head &#x3D; [3,2,0,-4], pos &#x3D; 1</span><br><span class="line">输出：true</span><br><span class="line">解释：链表中有一个环，其尾部连接到第二个节点。</span><br></pre></td></tr></table></figure>
<p><a href="https://camo.githubusercontent.com/cd5220a0a26ddf8118bf375cd5fc24dfba2b7c9d/68747470733a2f2f696d67636f6e766572742e6373646e696d672e636e2f6148523063484d364c79396863334e6c64484d756247566c64474e765a47557459323475593239744c32467361586c3162693173597931316347787659575176645842736232466b637938794d4445344c7a45794c7a41334c324e70636d4e316247467962476c756132566b62476c7a64433577626d63" target="_blank" rel="noopener"><img src="https://camo.githubusercontent.com/cd5220a0a26ddf8118bf375cd5fc24dfba2b7c9d/68747470733a2f2f696d67636f6e766572742e6373646e696d672e636e2f6148523063484d364c79396863334e6c64484d756247566c64474e765a47557459323475593239744c32467361586c3162693173597931316347787659575176645842736232466b637938794d4445344c7a45794c7a41334c324e70636d4e316247467962476c756132566b62476c7a64433577626d63" alt="img"></a></p>
<p><strong>示例 2</strong>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入：head &#x3D; [1,2], pos &#x3D; 0</span><br><span class="line">输出：true</span><br><span class="line">解释：链表中有一个环，其尾部连接到第一个节点。</span><br></pre></td></tr></table></figure>
<p><a href="https://camo.githubusercontent.com/f7fe61639e25fc0daa447dc76ccb142ee39328d9/68747470733a2f2f696d67636f6e766572742e6373646e696d672e636e2f6148523063484d364c79396863334e6c64484d756247566c64474e765a47557459323475593239744c32467361586c3162693173597931316347787659575176645842736232466b637938794d4445344c7a45794c7a41334c324e70636d4e316247467962476c756132566b62476c7a644639305a584e304d693577626d63" target="_blank" rel="noopener"><img src="https://camo.githubusercontent.com/f7fe61639e25fc0daa447dc76ccb142ee39328d9/68747470733a2f2f696d67636f6e766572742e6373646e696d672e636e2f6148523063484d364c79396863334e6c64484d756247566c64474e765a47557459323475593239744c32467361586c3162693173597931316347787659575176645842736232466b637938794d4445344c7a45794c7a41334c324e70636d4e316247467962476c756132566b62476c7a644639305a584e304d693577626d63" alt="img"></a></p>
<p><strong>示例 3</strong>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入：head &#x3D; [1], pos &#x3D; -1</span><br><span class="line">输出：false</span><br><span class="line">解释：链表中没有环。</span><br></pre></td></tr></table></figure>
<p><a href="https://camo.githubusercontent.com/332d8c08fdfe76b34bbef13c625d43c172785998/68747470733a2f2f696d67636f6e766572742e6373646e696d672e636e2f6148523063484d364c79396863334e6c64484d756247566c64474e765a47557459323475593239744c32467361586c3162693173597931316347787659575176645842736232466b637938794d4445344c7a45794c7a41334c324e70636d4e316247467962476c756132566b62476c7a644639305a584e304d793577626d63" target="_blank" rel="noopener"><img src="https://camo.githubusercontent.com/332d8c08fdfe76b34bbef13c625d43c172785998/68747470733a2f2f696d67636f6e766572742e6373646e696d672e636e2f6148523063484d364c79396863334e6c64484d756247566c64474e765a47557459323475593239744c32467361586c3162693173597931316347787659575176645842736232466b637938794d4445344c7a45794c7a41334c324e70636d4e316247467962476c756132566b62476c7a644639305a584e304d793577626d63" alt="img"></a></p>
<p><strong>进阶</strong>：</p>
<p>你能用 O(1)（即，常量）内存解决此问题吗？</p>
<p><strong>思路：利用双指针的方式</strong></p>
<p>通常情况下，判断是否包含了重复的元素，我们使用<code>Hash</code>的方式来做。对于单链表的这种场景，我们也可以使用双指针的方式。</p>
<p>第一个指针 <code>p1</code> 每次移动两个节点，第二个指针 <code>p2</code> 每次移动一个节点，如果该链表存在环的话，第一个指针一定会再次碰到第二个指针，反之，则不存在环。</p>
<p>比如：<code>head = [1,2,3,4,5]</code>，奇数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">p1：1   3   5   2   4   1</span><br><span class="line">p2：1   2   3   4   5   1</span><br></pre></td></tr></table></figure>
<p>比如：<code>head = [1,2,3,4]</code>，偶数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">p1：1   3   1   3   1</span><br><span class="line">p2：1   2   3   4   1</span><br></pre></td></tr></table></figure>
<p><strong>C# 语言</strong></p>
<ul>
<li>状态：通过</li>
<li>执行用时: 112 ms, 在所有 C# 提交中击败了 98.43% 的用户</li>
<li>内存消耗: 24.9 MB, 在所有 C# 提交中击败了 5.13% 的用户</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Definition <span class="keyword">for</span> singly-linked list.</span><br><span class="line"> * public class ListNode &#123;</span><br><span class="line"> *     public int val;</span><br><span class="line"> *     public ListNode next;</span><br><span class="line"> *     public ListNode(int x) &#123;</span><br><span class="line"> *         val = x;</span><br><span class="line"> *         next = null;</span><br><span class="line"> *     &#125;</span><br><span class="line"> * &#125;</span><br><span class="line"> */</span><br><span class="line">public class Solution &#123;</span><br><span class="line">    public bool HasCycle(ListNode head) &#123;</span><br><span class="line">        ListNode p1 = head;</span><br><span class="line">        ListNode p2 = head;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (p1 != null &amp;&amp; p1.next != null)</span><br><span class="line">        &#123;</span><br><span class="line">            p1 = p1.next.next;</span><br><span class="line">            p2 = p2.next;</span><br><span class="line">            <span class="keyword">if</span> (p1 == p2)</span><br><span class="line">                <span class="keyword">return</span> true;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> false;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>Python 语言</strong></p>
<ul>
<li>执行结果：通过</li>
<li>执行用时：56 ms, 在所有 Python3 提交中击败了 60.97% 的用户</li>
<li>内存消耗：16.6 MB, 在所有 Python3 提交中击败了 11.81% 的用户</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.next = None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">hasCycle</span><span class="params">(self, head: ListNode)</span> -&gt; bool:</span></span><br><span class="line">        p1 = head</span><br><span class="line">        p2 = head</span><br><span class="line">        <span class="keyword">while</span> p1 <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> p1.next <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            p1 = p1.next.next</span><br><span class="line">            p2 = p2.next</span><br><span class="line">            <span class="keyword">if</span> p1 == p2:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<h1 id="排序链表"><a href="#排序链表" class="headerlink" title="排序链表"></a>排序链表</h1><blockquote>
<ul>
<li>题号：148</li>
<li>难度：中等</li>
<li><a href="https://leetcode-cn.com/problems/sort-list/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/sort-list/</a></li>
</ul>
</blockquote>
<p>在 O(n log n) 时间复杂度和常数级空间复杂度下，对链表进行排序。</p>
<p><strong>示例 1:</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入: 4-&gt;2-&gt;1-&gt;3</span><br><span class="line">输出: 1-&gt;2-&gt;3-&gt;4</span><br></pre></td></tr></table></figure>
<p><strong>示例 2:</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入: -1-&gt;5-&gt;3-&gt;4-&gt;0</span><br><span class="line">输出: -1-&gt;0-&gt;3-&gt;4-&gt;5</span><br></pre></td></tr></table></figure>
<p><strong>思路：模仿并归排序的思路，典型的回溯算法。</strong></p>
<p>如果待排的元素存储在数组中，我们可以用并归排序。而这些元素存储在链表中，我们无法直接利用并归排序，只能借鉴并归排序的思想对算法进行修改。</p>
<p>并归排序的思想是将待排序列进行分组，直到包含一个元素为止，然后回溯合并两个有序序列，最后得到排序序列。</p>
<p>对于链表我们可以递归地将当前链表分为两段，然后merge，分两段的方法是使用双指针法，<code>p1</code>指针每次走两步，<code>p2</code>指针每次走一步，直到<code>p1</code>走到末尾，这时<code>p2</code>所在位置就是中间位置，这样就分成了两段。</p>
<p><strong>C# 语言</strong></p>
<ul>
<li>状态：通过</li>
<li>16 / 16 个通过测试用例</li>
<li>执行用时: 124 ms, 在所有 C# 提交中击败了 100.00% 的用户</li>
<li>内存消耗: 29 MB, 在所有 C# 提交中击败了 25.00% 的用户</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Definition <span class="keyword">for</span> singly-linked list.</span><br><span class="line"> * public class ListNode &#123;</span><br><span class="line"> *     public int val;</span><br><span class="line"> *     public ListNode next;</span><br><span class="line"> *     public ListNode(int x) &#123; val = x; &#125;</span><br><span class="line"> * &#125;</span><br><span class="line"> */</span><br><span class="line"> </span><br><span class="line">public <span class="class"><span class="keyword">class</span> <span class="title">Solution</span></span></span><br><span class="line">&#123;</span><br><span class="line">    public ListNode SortList(ListNode head)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (head == null)</span><br><span class="line">            <span class="keyword">return</span> null;</span><br><span class="line">        <span class="keyword">return</span> MergeSort(head);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    private ListNode MergeSort(ListNode node)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (node.next == null)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> node;</span><br><span class="line">        &#125;</span><br><span class="line">        ListNode p1 = node;</span><br><span class="line">        ListNode p2 = node;</span><br><span class="line">        ListNode cut = null;</span><br><span class="line">        <span class="keyword">while</span> (p1 != null &amp;&amp; p1.next != null)</span><br><span class="line">        &#123;</span><br><span class="line">            cut = p2;</span><br><span class="line">            p2 = p2.next;</span><br><span class="line">            p1 = p1.next.next;</span><br><span class="line">        &#125;</span><br><span class="line">        cut.next = null;</span><br><span class="line">        ListNode l1 = MergeSort(node);</span><br><span class="line">        ListNode l2 = MergeSort(p2);</span><br><span class="line">        <span class="keyword">return</span> MergeTwoLists(l1, l2);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private ListNode MergeTwoLists(ListNode l1, ListNode l2)</span><br><span class="line">    &#123;</span><br><span class="line">        ListNode pHead = new ListNode(<span class="number">-1</span>);</span><br><span class="line">        ListNode temp = pHead;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (l1 != null &amp;&amp; l2 != null)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (l1.val &lt; l2.val)</span><br><span class="line">            &#123;</span><br><span class="line">                temp.next = l1;</span><br><span class="line">                l1 = l1.next;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">            &#123;</span><br><span class="line">                temp.next = l2;</span><br><span class="line">                l2 = l2.next;</span><br><span class="line">            &#125;</span><br><span class="line">            temp = temp.next;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (l1 != null)</span><br><span class="line">            temp.next = l1;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (l2 != null)</span><br><span class="line">            temp.next = l2;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> pHead.next;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>Python 语言</strong></p>
<ul>
<li>执行结果：通过</li>
<li>执行用时：216 ms, 在所有 Python3 提交中击败了 75.99% 的用户</li>
<li>内存消耗：20.7 MB, 在所有 Python3 提交中击败了 28.57% 的用户</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.next = None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sortList</span><span class="params">(self, head: ListNode)</span> -&gt; ListNode:</span></span><br><span class="line">        <span class="keyword">if</span> head <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> head</span><br><span class="line">        <span class="keyword">return</span> self.mergeSort(head)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mergeSort</span><span class="params">(self, node: ListNode)</span> -&gt; ListNode:</span></span><br><span class="line">        <span class="keyword">if</span> node.next <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> node</span><br><span class="line">        p1 = node</span><br><span class="line">        p2 = node</span><br><span class="line">        cute = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">while</span> p1 <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> p1.next <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            cute = p2</span><br><span class="line">            p2 = p2.next</span><br><span class="line">            p1 = p1.next.next</span><br><span class="line">        cute.next = <span class="literal">None</span></span><br><span class="line">        l1 = self.mergeSort(node)</span><br><span class="line">        l2 = self.mergeSort(p2)</span><br><span class="line">        <span class="keyword">return</span> self.mergeTwoLists(l1, l2)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mergeTwoLists</span><span class="params">(self, l1: ListNode, l2: ListNode)</span> -&gt; ListNode:</span></span><br><span class="line">        pHead = ListNode(<span class="number">-1</span>)</span><br><span class="line">        temp = pHead</span><br><span class="line">        <span class="keyword">while</span> l1 <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> l2 <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> l1.val &lt; l2.val:</span><br><span class="line">                temp.next = l1</span><br><span class="line">                l1 = l1.next</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                temp.next = l2</span><br><span class="line">                l2 = l2.next</span><br><span class="line">            temp = temp.next</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> l1 <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            temp.next = l1</span><br><span class="line">        <span class="keyword">if</span> l2 <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            temp.next = l2</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> pHead.next</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
  </entry>
  <entry>
    <title>每日论文（3）—— Field-aware Factorization Machines for CTR Prediction</title>
    <url>/posts/5e950681.html</url>
    <content><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>FM和FFM模型是最近几年提出的模型，凭借其在数据量比较大并且特征稀疏的情况下，仍然能够得到优秀的性能和效果的特性，屡次在各大公司举办的CTR预估比赛中获得不错的战绩。美团技术团队在搭建DSP的过程中，探索并使用了FM和FFM模型进行CTR和CVR预估，并且取得了不错的效果。本文旨在把我们对FM和FFM原理的探索和应用的经验介绍给有兴趣的读者。</p>
<p>在计算广告领域，点击率CTR（click-through rate）和转化率CVR（conversion rate）是衡量广告流量的两个关键指标。准确的估计CTR、CVR对于提高流量的价值，增加广告收入有重要的指导作用。预估CTR/CVR，业界常用的方法有人工特征工程 + LR(Logistic Regression)、GBDT(Gradient Boosting Decision Tree) + LR<a href="http://blog.csdn.net/lilyth_lilyth/article/details/48032119" target="_blank" rel="noopener">[1]</a><a href="http://www.cnblogs.com/Matrix_Yao/p/4773221.html" target="_blank" rel="noopener">[2]</a><a href="http://blog.csdn.net/lilyth_lilyth/article/details/48032119" target="_blank" rel="noopener">[3]</a>、FM（Factorization Machine）<a href="http://www.cnblogs.com/Matrix_Yao/p/4773221.html" target="_blank" rel="noopener">[2]</a><a href="http://www.algo.uni-konstanz.de/members/rendle/pdf/Rendle2010FM.pdf" target="_blank" rel="noopener">[7]</a>和FFM（Field-aware Factorization Machine）<a href="http://www.csie.ntu.edu.tw/~r01922136/slides/ffm.pdf" target="_blank" rel="noopener">[9]</a>模型。在这些模型中，FM和FFM近年来表现突出，分别在由Criteo和Avazu举办的CTR预测竞赛中夺得冠军<a href="https://www.kaggle.com/c/criteo-display-ad-challenge" target="_blank" rel="noopener">[4]</a><a href="https://www.kaggle.com/c/avazu-ctr-prediction" target="_blank" rel="noopener">[5]</a>。</p>
<p>考虑到FFM模型在CTR预估比赛中的不俗战绩，美团技术团队在搭建DSP（Demand Side Platform）<a href="https://en.wikipedia.org/wiki/Demand-side_platform" target="_blank" rel="noopener">[6]</a>平台时，在站内CTR/CVR的预估上使用了该模型，取得了不错的效果。本文是基于对FFM模型的深度调研和使用经验，从原理、实现和应用几个方面对FFM进行探讨，希望能够从原理上解释FFM模型在点击率预估上取得优秀效果的原因。因为FFM是在FM的基础上改进得来的，所以我们首先引入FM模型，本文章节组织方式如下：</p>
<ol>
<li>首先介绍FM的原理。</li>
<li>其次介绍FFM对FM的改进。</li>
<li>然后介绍FFM的实现细节。</li>
<li>最后介绍模型在DSP场景的应用。</li>
</ol>
<h1 id="FM的原理"><a href="#FM的原理" class="headerlink" title="FM的原理"></a>FM的原理</h1><p>FM（Factorization Machine）是由Konstanz大学Steffen Rendle（现任职于Google）于2010年最早提出的，旨在解决稀疏数据下的特征组合问题<a href="http://www.algo.uni-konstanz.de/members/rendle/pdf/Rendle2010FM.pdf" target="_blank" rel="noopener">[7]</a>。下面以一个示例引入FM模型。假设一个广告分类的问题，根据用户和广告位相关的特征，预测用户是否点击了广告。源数据如下<a href="http://www.cs.cmu.edu/~wcohen/10-605/2015-guest-lecture/FM.pdf" target="_blank" rel="noopener">[8]</a></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left"><strong>Clicked?</strong></th>
<th style="text-align:left">Country</th>
<th style="text-align:left">Day</th>
<th style="text-align:left">Ad_type</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>1</strong></td>
<td style="text-align:left">USA</td>
<td style="text-align:left">26/11/15</td>
<td style="text-align:left">Movie</td>
</tr>
<tr>
<td style="text-align:left"><strong>0</strong></td>
<td style="text-align:left">China</td>
<td style="text-align:left">1/7/14</td>
<td style="text-align:left">Game</td>
</tr>
<tr>
<td style="text-align:left"><strong>1</strong></td>
<td style="text-align:left">China</td>
<td style="text-align:left">19/2/15</td>
<td style="text-align:left">Game</td>
</tr>
</tbody>
</table>
</div>
<p>“Clicked?“是label，Country、Day、Ad_type是特征。由于三种特征都是categorical类型的，需要经过独热编码（One-Hot Encoding）转换成数值型特征。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left"><strong>Clicked?</strong></th>
<th style="text-align:left">Country=USA</th>
<th style="text-align:left">Country=China</th>
<th style="text-align:left">Day=26/11/15</th>
<th style="text-align:left">Day=1/7/14</th>
<th style="text-align:left">Day=19/2/15</th>
<th style="text-align:left">Ad_type=Movie</th>
<th style="text-align:left">Ad_type=Game</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>1</strong></td>
<td style="text-align:left">1</td>
<td style="text-align:left">0</td>
<td style="text-align:left">1</td>
<td style="text-align:left">0</td>
<td style="text-align:left">0</td>
<td style="text-align:left">1</td>
<td style="text-align:left">0</td>
</tr>
<tr>
<td style="text-align:left"><strong>0</strong></td>
<td style="text-align:left">0</td>
<td style="text-align:left">1</td>
<td style="text-align:left">0</td>
<td style="text-align:left">1</td>
<td style="text-align:left">0</td>
<td style="text-align:left">0</td>
<td style="text-align:left">1</td>
</tr>
<tr>
<td style="text-align:left"><strong>1</strong></td>
<td style="text-align:left">0</td>
<td style="text-align:left">1</td>
<td style="text-align:left">0</td>
<td style="text-align:left">0</td>
<td style="text-align:left">1</td>
<td style="text-align:left">0</td>
<td style="text-align:left">1</td>
</tr>
</tbody>
</table>
</div>
<p>由上表可以看出，经过One-Hot编码之后，大部分样本数据特征是比较稀疏的。上面的样例中，每个样本有7维特征，但平均仅有3维特征具有非零值。实际上，这种情况并不是此例独有的，在真实应用场景中这种情况普遍存在。例如，CTR/CVR预测时，用户的性别、职业、教育水平、品类偏好，商品的品类等，经过One-Hot编码转换后都会导致样本数据的稀疏性。特别是商品品类这种类型的特征，如商品的末级品类约有550个，采用One-Hot编码生成550个数值特征，但每个样本的这550个特征，有且仅有一个是有效的（非零）。由此可见，数据稀疏性是实际问题中不可避免的挑战。</p>
<p>One-Hot编码的另一个特点就是导致特征空间大。例如，商品品类有550维特征，一个categorical特征转换为550维数值特征，特征空间剧增。</p>
<p>同时通过观察大量的样本数据可以发现，某些特征经过关联之后，与label之间的相关性就会提高。例如，“USA”与“Thanksgiving”、“China”与“Chinese New Year”这样的关联特征，对用户的点击有着正向的影响。换句话说，来自“China”的用户很可能会在“Chinese New Year”有大量的浏览、购买行为，而在“Thanksgiving”却不会有特别的消费行为。这种关联特征与label的正向相关性在实际问题中是普遍存在的，如“化妆品”类商品与“女”性，“球类运动配件”的商品与“男”性，“电影票”的商品与“电影”品类偏好等。因此，引入两个特征的组合是非常有意义的。</p>
<p>多项式模型是包含特征组合的最直观的模型。在多项式模型中，特征 xixi 和 xjxj 的组合采用 xixjxixj 表示，即 xixi 和 xjxj 都非零时，组合特征 xixjxixj 才有意义。从对比的角度，本文只讨论二阶多项式模型。模型的表达式如下</p>
<script type="math/tex; mode=display">y(x)=w_0+∑_{i=1}^nw_ix_i+∑_{i=1}^n∑_{j=i+1}^nw_{ij}x_ix_j</script><p>其中，$n$代表样本的特征数量，$x_i$是第$i$个特征的值，$w_0$、$w_i$、$w_{ij}$是模型参数。</p>
<p>从上式可以看出，组合特征的参数一共有$\frac{n(n−1)}{2}$个，任意两个参数都是独立的。然而，在数据稀疏性普遍存在的实际应用场景中，二次项参数的训练是很困难的。其原因是，每个参数$w_{ij}$的训练需要大量$x_{i}$和$x_{j}$都非零的样本；由于样本数据本来就比较稀疏，满足“$x_{i}$和 $x_{j}$都非零”的样本将会非常少。训练样本的不足，很容易导致参数$w_{ij}$不准确，最终将严重影响模型的性能。</p>
<p>那么，如何解决二次项参数的训练问题呢？矩阵分解提供了一种解决思路。在model-based的协同过滤中，一个rating矩阵可以分解为user矩阵和item矩阵，每个user和item都可以采用一个隐向量表示<a href="http://www.cs.cmu.edu/~wcohen/10-605/2015-guest-lecture/FM.pdf" target="_blank" rel="noopener">[8]</a>。比如在下图中的例子中，我们把每个user表示成一个二维向量，同时把每个item表示成一个二维向量，两个向量的点积就是矩阵中user对item的打分。</p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2016/1a91e67b.png" alt="img" style="zoom:70%;"></p>
<p>类似地，所有二次项参数$w_{ij}$可以组成一个对称阵 WW（为了方便说明FM的由来，对角元素可以设置为正实数），那么这个矩阵就可以分解为$W=V^TV$，$V$的第$j$列便是第$j$维特征的隐向量。换句话说，每个参数$w_{ij}=⟨vi,vj⟩$，这就是FM模型的核心思想。因此，FM的模型方程为（本文不讨论FM的高阶形式）</p>
<script type="math/tex; mode=display">y(x)=w_0+∑_{i=1}^nw_ix_i+∑_{i=1}^n∑_{j=i+1}^n⟨vi,vj⟩x_ix_j</script><p>其中，$v_i$是第$i$维特征的隐向量，$⟨⋅,⋅⟩⟨⋅,⋅⟩ $代表向量点积。隐向量的长度为$k（k&lt;&lt;nk&lt;&lt;n）$，包含$k$个描述特征的因子。根据公式，二次项的参数数量减少为$kn$个，远少于多项式模型的参数数量。另外，参数因子化使得$x_hx_i$的参数和$x_ix_j$的参数不再是相互独立的，因此我们可以在样本稀疏的情况下相对合理地估计FM的二次项参数。具体来说，$x_hx_i$和$x_ix_j$的系数分别为 $⟨v_h,v_i⟩$ 和 $⟨v_i,v_j⟩$，它们之间有共同项$vi$。也就是说，所有包含“$xi$的非零组合特征”（存在某个$j≠i$，使得$x_ix_j≠0$）的样本都可以用来学习隐向量$v_i$，这很大程度上避免了数据稀疏性造成的影响。而在多项式模型中，$w_{hi}$和$w_{ij}$是相互独立的。</p>
<p>显而易见，上式是一个通用的拟合方程，可以采用不同的损失函数用于解决回归、二元分类等问题，比如可以采用MSE（Mean Square Error）损失函数来求解回归问题，也可以采用Hinge/Cross-Entropy损失来求解分类问题。当然，在进行二元分类时，FM的输出需要经过sigmoid变换，这与Logistic回归是一样的。直观上看，FM的复杂度是$O(kn2)$。但是FM的二次项可以化简，其复杂度可以优化到$O(kn)$<a href="http://www.algo.uni-konstanz.de/members/rendle/pdf/Rendle2010FM.pdf" target="_blank" rel="noopener">[7]</a>。由此可见，FM可以在线性时间对新样本作出预测。</p>
<script type="math/tex; mode=display">\sum_{i=1}^n \sum_{j=i+1}^n \langle \mathbf{v}_i, \mathbf{v}_j \rangle x_i x_j = \frac{1}{2} \sum_{f=1}^k \left(\left( \sum_{i=1}^n v_{i, f} x_i \right)^2 - \sum_{i=1}^n v_{i, f}^2 x_i^2 \right)</script><p>我们再来看一下FM的训练复杂度，利用SGD（Stochastic Gradient Descent）训练模型。模型各个参数的梯度如下</p>
<script type="math/tex; mode=display">\begin{aligned}\frac{\partial}{\partial\theta} y (\mathbf{x}) = \left\{\begin{array}{ll}
1, & \text{if}\; \theta\; \text{is}\; w_0\\ \
x_i, & \text{if}\; \theta\; \text{is}\; w_i\\ \
x_i \sum_{j=1}^n v_{j, f} x_j - v_{i, f} x_i^2, & \text{if}\; \theta\; \text{is}\; v_{i, f}
\end{array}\right.\end{aligned}</script><p>其中，$v_{j, f}$是隐向量$( \mathbf{v}_j )$ 的第$f$个元素。由于$\sum_{j=1}^n v_{j, f} x_j$只与$f$有关，而与$i$无关，在每次迭代过程中，只需计算一次所有$f$的$\sum_{j=1}^n v_{j, f} x_j$，就能够方便地得到所有$v_{i, f}$的梯度。显然，计算所有$f$的$\sum_{j=1}^n v_{j, f} x_j$的复杂度是$O(kn)$；已知$ \sum_{j=i1}^n v_{j, f} x_j$时，计算每个参数梯度的复杂度是$O(1)$；得到梯度后，更新每个参数的复杂度是$O(1)$；模型参数一共有<script type="math/tex">nk + n + 1</script>个。因此，FM参数训练的复杂度也是$O(kn)$。综上可知，FM可以在线性时间训练和预测，是一种非常高效的模型。</p>
<h2 id><a href="#" class="headerlink" title=" "></a> </h2><p>FM是一种比较灵活的模型，通过合适的特征变换方式，FM可以模拟二阶多项式核的SVM模型、MF模型、SVD++模型等<a href="http://www.algo.uni-konstanz.de/members/rendle/pdf/Rendle2010FM.pdf" target="_blank" rel="noopener">[7]</a>。</p>
<p>相比SVM的二阶多项式核而言，FM在样本稀疏的情况下是有优势的；而且，FM的训练/预测复杂度是线性的，而二项多项式核SVM需要计算核矩阵，核矩阵复杂度就是N平方。</p>
<p>相比MF而言，我们把MF中每一项的rating分改写为$r_{ui} \sim \beta_u + \gamma_i + x_u^T y_i )$，从公式中可以看出，这相当于只有两类特征$u$ 和 $i$ 的FM模型。对于FM而言，我们可以加任意多的特征，比如user的历史购买平均值，item的历史购买平均值等，但是MF只能局限在两类特征。SVD++与MF类似，在特征的扩展性上都不如FM，在此不再赘述。</p>
<h1 id="FFM对FM的改进"><a href="#FFM对FM的改进" class="headerlink" title="FFM对FM的改进"></a>FFM对FM的改进</h1><p>FFM（Field-aware Factorization Machine）最初的概念来自Yu-Chin Juan（阮毓钦，毕业于中国台湾大学，现在美国Criteo工作）与其比赛队员，是他们借鉴了来自Michael Jahrer的论文<a href="https://kaggle2.blob.core.windows.net/competitions/kddcup2012/2748/media/Opera.pdf" target="_blank" rel="noopener">[14]</a>中的field概念提出了FM的升级版模型。通过引入field的概念，FFM把相同性质的特征归于同一个field。以上面的广告分类为例，“Day=26/11/15”、“Day=1/7/14”、“Day=19/2/15”这三个特征都是代表日期的，可以放到同一个field中。同理，商品的末级品类编码生成了550个特征，这550个特征都是说明商品所属的品类，因此它们也可以放到同一个field中。简单来说，同一个categorical特征经过One-Hot编码生成的数值特征都可以放到同一个field，包括用户性别、职业、品类偏好等。在FFM中，每一维特征 $x_i $，针对其它特征的每一种field$ f_j$，都会学习一个隐向量$\mathbf{v}_{i, f_j}$。因此，隐向量不仅与特征相关，也与field相关。也就是说，“Day=26/11/15”这个特征与“Country”特征和“Ad_type&rdquo;特征进行关联的时候使用不同的隐向量，这与“Country”和“Ad_type”的内在差异相符，也是FFM中“field-aware”的由来。</p>
<p>假设样本的$n$个特征属于$f$个field，那么FFM的二次项有$nf$个隐向量。而在FM模型中，每一维特征的隐向量只有一个。FM可以看作FFM的特例，是把所有特征都归属到一个field时的FFM模型。根据FFM的field敏感特性，可以导出其模型方程。</p>
<script type="math/tex; mode=display">y(\mathbf{x}) = w_0 + \sum_{i=1}^n w_i x_i + \sum_{i=1}^n \sum_{j=i+1}^n \langle \mathbf{v}_{i, f_j}, \mathbf{v}_{j, f_i} \rangle x_i x_j</script><p>其中，$f_j$是第$j$个特征所属的field。如果隐向量的长度为$k$，那么FFM的二次参数有$nfk$个，远多于FM模型的$nk$个。此外，由于隐向量与field相关，FFM二次项并不能够化简，其预测复杂度是$O(kn^2)$。</p>
<p>下面以一个例子简单说明FFM的特征组合方式</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">User</th>
<th style="text-align:left">Movie</th>
<th style="text-align:left">Genre</th>
<th style="text-align:left">Price</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">YuChin</td>
<td style="text-align:left">3Idiots</td>
<td style="text-align:left">Comedy, Drama</td>
<td style="text-align:left">$9.99</td>
</tr>
</tbody>
</table>
</div>
<p>这条记录可以编码成5个特征，其中“Genre=Comedy”和“Genre=Drama”属于同一个field，“Price”是数值型，不用One-Hot编码转换。为了方便说明FFM的样本格式，我们将所有的特征和对应的field映射成整数编号。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">Field name</th>
<th style="text-align:left">Field index</th>
<th style="text-align:left">Feature name</th>
<th style="text-align:left">Feature index</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">User</td>
<td style="text-align:left"><strong>1</strong></td>
<td style="text-align:left">User=YuChin</td>
<td style="text-align:left"><strong>1</strong></td>
</tr>
<tr>
<td style="text-align:left">Movie</td>
<td style="text-align:left"><strong>2</strong></td>
<td style="text-align:left">Movie=3Idiots</td>
<td style="text-align:left"><strong>2</strong></td>
</tr>
<tr>
<td style="text-align:left">Genre</td>
<td style="text-align:left"><strong>3</strong></td>
<td style="text-align:left">Genre=Comedy</td>
<td style="text-align:left"><strong>3</strong></td>
</tr>
<tr>
<td style="text-align:left">Price</td>
<td style="text-align:left"><strong>4</strong></td>
<td style="text-align:left">Genre=Drama</td>
<td style="text-align:left"><strong>4</strong></td>
</tr>
<tr>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
<td style="text-align:left">Price</td>
<td style="text-align:left"><strong>5</strong></td>
</tr>
</tbody>
</table>
</div>
<p>那么，FFM的组合特征有10项，如下：</p>
<script type="math/tex; mode=display">⟨v1,2,v2,1⟩⋅1⋅1+⟨v1,3,v3,1⟩⋅1⋅1+⟨v1,3,v4,1⟩⋅1⋅1\\+⟨v1,4,v5,1⟩⋅1⋅9.99 +⟨v2,3,v3,2⟩⋅1⋅1+⟨v2,3,v4,2⟩⋅1⋅1\\+⟨v2,4,v5,2⟩⋅1⋅9.99 +⟨v3,3,v4,3⟩⋅1⋅1+⟨v3,4,v5,3⟩⋅1⋅9.99\\+⟨v4,4,v5,3⟩⋅1⋅9.99</script><p>其中，红色是field编号，蓝色是特征编号，绿色是此样本的特征取值。二次项的系数是通过与特征field相关的隐向量点积得到的，二次项共有$\frac{n(n−1)}{2}$个。</p>
<h1 id="FFM的实现细节"><a href="#FFM的实现细节" class="headerlink" title="FFM的实现细节"></a>FFM的实现细节</h1><p>Yu-Chin Juan实现了一个C++版的FFM模型，源码可从Github下载<a href="https://github.com/guestwalk/libffm" target="_blank" rel="noopener">[10]</a>。这个版本的FFM省略了常数项和一次项，模型方程如下。</p>
<script type="math/tex; mode=display">\phi(\mathbf{w}, \mathbf{x}) = \sum_{j_1, j_2 \in \mathcal{C}_2} \langle \mathbf{w}_{j_1, f_2}, \mathbf{w}_{j_2, f_1} \rangle x_{j_1} x_{j_2}</script><p>其中，$\mathcal{C}_2$是非零特征的二元组合，$j_1$是特征，属于field$f_1$，$\mathbf{w}_{j_1, f_2}$是特征$j_1$对field$f_2$的隐向量。此FFM模型采用logistic loss作为损失函数，和L2惩罚项，因此只能用于二元分类问题。</p>
<script type="math/tex; mode=display">\min_{\mathbf{w}} \sum_{i=1}^L \log \big( 1 + \exp\{ -y_i \phi (\mathbf{w}, \mathbf{x}_i ) \} \big) + \frac{\lambda}{2} \| \mathbf{w} \|^2</script><p>其中，$y_i \in \{-1, 1\}$是第$i$个样本的label，$L$是训练样本数量，$\lambda$是惩罚项系数。模型采用SGD优化，优化流程如下。</p>
<p><img src="/Pic/%E6%AF%8F%E6%97%A5%E8%AE%BA%E6%96%87%EF%BC%883%EF%BC%89%E2%80%94%E2%80%94%20Field-aware%20Factorization%20Machines%20for%20CTR%20Prediction/0ba057eb.png" style="zoom:50%;"></p>
<p>参考$Algorithm\; 1$, 下面简单解释一下FFM的SGD优化过程。<br>算法的输入$tr$、$va$、$pa$分别是训练样本集、验证样本集和训练参数设置。</p>
<ol>
<li>根据样本特征数量$tr.n$、field的个数$tr.m$和训练参数$pa$，生成初始化模型，即随机生成模型的参数；</li>
<li>如果归一化参数$pa.norm$为真，计算训练和验证样本的归一化系数，样本$i$的归一化系数为<br>$R[i] = \frac{1}{| \mathbf{X}[i] |}$对每一轮迭代，如果随机更新参数$pa.rand$为真，随机打乱训练样本的顺序；</li>
<li><p>对每一个训练样本，执行如下操作</p>
<ul>
<li>计算每一个样本的FFM项，即公式中的输出$\phi$；</li>
<li>计算每一个样本的训练误差，如算法所示，这里采用的是交叉熵损失函数$\log ( 1 + e\phi )$；</li>
<li>利用单个样本的损失函数计算梯度$g_\Phi$，再根据梯度更新模型参数；</li>
</ul>
</li>
<li><p>对每一个验证样本，计算样本的FFM输出，计算验证误差；</p>
</li>
<li>重复步骤3~5，直到迭代结束或验证误差达到最小。</li>
</ol>
<p>在SGD寻优时，代码采用了一些小技巧，对于提升计算效率是非常有效的。</p>
<p><strong>第一，梯度分步计算</strong>。采用SGD训练FFM模型时，只采用单个样本的损失函数来计算模型参数的梯度。</p>
<script type="math/tex; mode=display">\mathcal{L} = \mathcal{L}_{err} + \mathcal{L}_{reg} = \log \big( 1 + \exp\{ -y_i \phi(\mathbf{w}, \mathbf{x}_i )\} \big) + \frac{\lambda}{2} \| \mathbf{w} \|^2</script><script type="math/tex; mode=display">\frac{\partial\mathcal{L}}{\partial\mathbf{w}} = \frac{\partial\mathcal{L}_{err}}{\partial\phi}\cdot \frac{\partial\phi}{\partial\mathbf{w}} + \frac{\partial\mathcal{L}_{reg}}{\partial\mathbf{w}}</script><p>上面的公式表明，$\frac{\partial\mathcal{L}_{err}}{\partial\phi}$与具体的模型参数无关。因此，每次更新模型时，只需计算一次，之后直接调用$\frac{\partial\mathcal{L}_{err}}{\partial\phi}$的值即可。对于更新$nfk$个模型参数，这种方式能够极大提升运算效率。</p>
<p><strong>第二，自适应学习率</strong>。此版本的FFM实现没有采用常用的指数递减的学习率更新策略，而是利用$nfk$个浮点数的临时空间，自适应地更新学习率。学习率是参考AdaGrad算法计算的<a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#AdaGrad" target="_blank" rel="noopener">[11]</a>，按如下方式更新</p>
<script type="math/tex; mode=display">w^{`}_{j_1, f_2} = w_{j_1, f_2} - \frac{\eta}{\sqrt{1 + \sum_t (g^t_{w_{j_1, f_2}})^2 }}\cdot g_{w_{j_1, f_2}}</script><p>其中，$w_{j_1, f_2}$是特征$j_1$对field$f_2$隐向量的一个元素，元素下标未标出；$g_{w_{j_1, f_2}}$是损失函数对参数$w_{j_1, f_2}$的梯度；$g^t_{w_{j_1, f_2}}$是第$t$次迭代的梯度；$\eta$是初始学习率。可以看出，随着迭代的进行，每个参数的历史梯度会慢慢累加，导致每个参数的学习率逐渐减小。另外，每个参数的学习率更新速度是不同的，与其历史梯度有关，根据AdaGrad的特点，对于样本比较稀疏的特征，学习率高于样本比较密集的特征，因此每个参数既可以比较快速达到最优，也不会导致验证误差出现很大的震荡。</p>
<p>第三，OpenMP多核并行计算。OpenMP是用于共享内存并行系统的多处理器程序设计的编译方案，便于移植和多核扩展<a href="http://openmp.org/wp/openmp-specifications/" target="_blank" rel="noopener">[12]</a>。FFM的源码采用了OpenMP的API，对参数训练过程SGD进行了多线程扩展，支持多线程编译。因此，OpenMP技术极大地提高了FFM的训练效率和多核CPU的利用率。在训练模型时，输入的训练参数ns_threads指定了线程数量，一般设定为CPU的核心数，便于完全利用CPU资源。</p>
<p>第四，SSE3指令并行编程。SSE3全称为数据流单指令多数据扩展指令集3，是CPU对数据层并行的关键指令，主要用于多媒体和游戏的应用程序中<a href="http://blog.csdn.net/gengshenghong/article/details/7008704" target="_blank" rel="noopener">[13]</a>。SSE3指令采用128位的寄存器，同时操作4个单精度浮点数或整数。SSE3指令的功能非常类似于向量运算。例如，$a$和$b$采用SSE3指令相加($a$和$b$分别包含4个数据)，其功能是$a$中的4个元素与$b$中4个元素对应相加，得到4个相加后的值。采用SSE3指令后，向量运算的速度更加快捷，这对包含大量向量运算的FFM模型是非常有利的。</p>
<p>除了上面的技巧之外，FFM的实现中还有很多调优技巧需要探索。例如，代码是按field和特征的编号申请参数空间的，如果选取了非连续或过大的编号，就会造成大量的内存浪费；在每个样本中加入值为1的新特征，相当于引入了因子化的一次项，避免了缺少一次项带来的模型偏差等。</p>
<h1 id="模型在DSP场景的应用"><a href="#模型在DSP场景的应用" class="headerlink" title="模型在DSP场景的应用"></a>模型在DSP场景的应用</h1><p>在DSP的场景中，FFM主要用来预估站内的CTR和CVR，即一个用户对一个商品的潜在点击率和点击后的转化率。</p>
<p>CTR和CVR预估模型都是在线下训练，然后用于线上预测。两个模型采用的特征大同小异，主要有三类：用户相关的特征、商品相关的特征、以及用户-商品匹配特征。用户相关的特征包括年龄、性别、职业、兴趣、品类偏好、浏览/购买品类等基本信息，以及用户近期点击量、购买量、消费额等统计信息。商品相关的特征包括所属品类、销量、价格、评分、历史CTR/CVR等信息。用户-商品匹配特征主要有浏览/购买品类匹配、浏览/购买商家匹配、兴趣偏好匹配等几个维度。</p>
<p>为了使用FFM方法，所有的特征必须转换成“field_id:feat_id:value”格式，field_id代表特征所属field的编号，feat_id是特征编号，value是特征的值。数值型的特征比较容易处理，只需分配单独的field编号，如用户评论得分、商品的历史CTR/CVR等。categorical特征需要经过One-Hot编码成数值型，编码产生的所有特征同属于一个field，而特征的值只能是0或1，如用户的性别、年龄段，商品的品类id等。除此之外，还有第三类特征，如用户浏览/购买品类，有多个品类id且用一个数值衡量用户浏览或购买每个品类商品的数量。这类特征按照categorical特征处理，不同的只是特征的值不是0或1，而是代表用户浏览或购买数量的数值。按前述方法得到field_id之后，再对转换后特征顺序编号，得到feat_id，特征的值也可以按照之前的方法获得。</p>
<p>CTR、CVR预估样本的类别是按不同方式获取的。CTR预估的正样本是站内点击的用户-商品记录，负样本是展现但未点击的记录；CVR预估的正样本是站内支付（发生转化）的用户-商品记录，负样本是点击但未支付的记录。构建出样本数据后，采用FFM训练预估模型，并测试模型的性能。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left">#(field)</th>
<th style="text-align:left">#(feature)</th>
<th style="text-align:left">AUC</th>
<th style="text-align:left">Logloss</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">站内CTR</td>
<td style="text-align:left">39</td>
<td style="text-align:left">2456</td>
<td style="text-align:left">0.77</td>
<td style="text-align:left">0.38</td>
</tr>
<tr>
<td style="text-align:left">站内CVR</td>
<td style="text-align:left">67</td>
<td style="text-align:left">2441</td>
<td style="text-align:left">0.92</td>
<td style="text-align:left">0.13</td>
</tr>
</tbody>
</table>
</div>
<p>由于模型是按天训练的，每天的性能指标可能会有些波动，但变化幅度不是很大。这个表的结果说明，站内CTR/CVR预估模型是非常有效的。</p>
<p>在训练FFM的过程中，有许多小细节值得特别关注。</p>
<p><strong>第一，样本归一化</strong>。FFM默认是进行样本数据的归一化，即$pa.norm$为真；若此参数设置为假，很容易造成数据$inf$溢出，进而引起梯度计算的$nan$错误。因此，样本层面的数据是推荐进行归一化的。</p>
<p><strong>第二，特征归一化</strong>。CTR/CVR模型采用了多种类型的源特征，包括数值型和categorical类型等。但是，categorical类编码后的特征取值只有0或1，较大的数值型特征会造成样本归一化后categorical类生成特征的值非常小，没有区分性。例如，一条用户-商品记录，用户为“男”性，商品的销量是5000个（假设其它特征的值为零），那么归一化后特征“sex=male”（性别为男）的值略小于0.0002，而“volume”（销量）的值近似为1。特征“sex=male”在这个样本中的作用几乎可以忽略不计，这是相当不合理的。因此，将源数值型特征的值归一化到$[0,1]$是非常必要的。</p>
<p><strong>第三，省略零值特征</strong>。从FFM模型的表达式(4)可以看出，零值特征对模型完全没有贡献。包含零值特征的一次项和组合项均为零，对于训练模型参数或者目标值预估是没有作用的。因此，可以省去零值特征，提高FFM模型训练和预测的速度，这也是稀疏样本采用FFM的显著优势。</p>
<p>本文主要介绍了FFM的思路来源和理论原理，并结合源码说明FFM的实际应用和一些小细节。从理论上分析，FFM的参数因子化方式具有一些显著的优势，特别适合处理样本稀疏性问题，且确保了较好的性能；从应用结果来看，站内CTR/CVR预估采用FFM是非常合理的，各项指标都说明了FFM在点击率预估方面的卓越表现。当然，FFM不一定适用于所有场景且具有超越其他模型的性能，合适的应用场景才能成就FFM的“威名”。</p>
<ol>
<li><a href="http://blog.csdn.net/lilyth_lilyth/article/details/48032119" target="_blank" rel="noopener">http://blog.csdn.net/lilyth_lilyth/article/details/48032119</a></li>
<li><a href="http://www.cnblogs.com/Matrix_Yao/p/4773221.html" target="_blank" rel="noopener">http://www.cnblogs.com/Matrix_Yao/p/4773221.html</a></li>
<li><a href="http://www.herbrich.me/papers/adclicksfacebook.pdf" target="_blank" rel="noopener">http://www.herbrich.me/papers/adclicksfacebook.pdf</a></li>
<li><a href="https://www.kaggle.com/c/criteo-display-ad-challenge" target="_blank" rel="noopener">https://www.kaggle.com/c/criteo-display-ad-challenge</a></li>
<li><a href="https://www.kaggle.com/c/avazu-ctr-prediction" target="_blank" rel="noopener">https://www.kaggle.com/c/avazu-ctr-prediction</a></li>
<li><a href="https://en.wikipedia.org/wiki/Demand-side_platform" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Demand-side_platform</a></li>
<li><a href="http://www.algo.uni-konstanz.de/members/rendle/pdf/Rendle2010FM.pdf" target="_blank" rel="noopener">http://www.algo.uni-konstanz.de/members/rendle/pdf/Rendle2010FM.pdf</a></li>
<li><a href="http://www.cs.cmu.edu/~wcohen/10-605/2015-guest-lecture/FM.pdf" target="_blank" rel="noopener">http://www.cs.cmu.edu/~wcohen/10-605/2015-guest-lecture/FM.pdf</a></li>
<li><a href="http://www.csie.ntu.edu.tw/~r01922136/slides/ffm.pdf" target="_blank" rel="noopener">http://www.csie.ntu.edu.tw/~r01922136/slides/ffm.pdf</a></li>
<li><a href="https://github.com/guestwalk/libffm" target="_blank" rel="noopener">https://github.com/guestwalk/libffm</a></li>
<li><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#AdaGrad" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Stochastic_gradient_descent#AdaGrad</a></li>
<li><a href="http://openmp.org/wp/openmp-specifications/" target="_blank" rel="noopener">http://openmp.org/wp/openmp-specifications/</a></li>
<li><a href="http://blog.csdn.net/gengshenghong/article/details/7008704" target="_blank" rel="noopener">http://blog.csdn.net/gengshenghong/article/details/7008704</a></li>
<li><a href="https://kaggle2.blob.core.windows.net/competitions/kddcup2012/2748/media/Opera.pdf" target="_blank" rel="noopener">https://kaggle2.blob.core.windows.net/competitions/kddcup2012/2748/media/Opera.pdf</a></li>
</ol>
<p>本文转载自<a href="https://tech.meituan.com/2016/03/03/deep-understanding-of-ffm-principles-and-practices.html" target="_blank" rel="noopener">美团技术团队博客文章</a>，并在原基础上稍作修改，这个博客的质量确实很好提供了很多美团实践的例子~</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
  </entry>
  <entry>
    <title>Leetcode刷题专题打卡——查找</title>
    <url>/posts/171a3f59.html</url>
    <content><![CDATA[<p>注：由于<a href="https://github.com/datawhalechina/team-learning-program/blob/master/LeetCodeClassification/1.%E5%88%86%E6%B2%BB.md" target="_blank" rel="noopener">Datawhale组队学习资料</a>中对查找也讲的太美丽了，本文以直接搬运为主，对算法进行优化为辅，感兴趣的可以直接上Github相应组队学习内容中进行学习。</p>
<h1 id="一-查找表"><a href="#一-查找表" class="headerlink" title="一.查找表"></a>一.查找表</h1><h2 id="考虑的基本数据结构"><a href="#考虑的基本数据结构" class="headerlink" title="考虑的基本数据结构"></a>考虑的基本数据结构</h2><p><strong>第一类： 查找有无—set</strong></p>
<p>元素’a’是否存在，通常用set：集合</p>
<p>set只存储键，而不需要对应其相应的值。</p>
<p>set中的键不允许重复</p>
<p><strong>第二类： 查找对应关系(键值对应)—dict</strong></p>
<p>元素’a’出现了几次：dict—&gt;字典</p>
<p>dict中的键不允许重复</p>
<p><strong>第三类： 改变映射关系—map</strong></p>
<p>通过将原有序列的关系映射统一表示为其他</p>
<h2 id="算法应用"><a href="#算法应用" class="headerlink" title="算法应用"></a>算法应用</h2><h3 id="LeetCode-349-Intersection-Of-Two-Arrays-1"><a href="#LeetCode-349-Intersection-Of-Two-Arrays-1" class="headerlink" title="LeetCode 349 Intersection Of Two Arrays 1"></a>LeetCode 349 Intersection Of Two Arrays 1</h3><h4 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h4><p>给定两个数组nums,求两个数组的公共元素。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">如nums1 &#x3D; [1,2,2,1],nums2 &#x3D; [2,2]</span><br><span class="line"></span><br><span class="line">结果为[2]</span><br><span class="line">结果中每个元素只能出现一次</span><br><span class="line">出现的顺序可以是任意的</span><br></pre></td></tr></table></figure>
<h4 id="分析实现"><a href="#分析实现" class="headerlink" title="分析实现"></a>分析实现</h4><p>由于每个元素只出现一次，因此不需要关注每个元素出现的次数，用set的数据结构就可以了。记录元素的有和无。</p>
<p>把nums1记录为set，判断nums2的元素是否在set中，是的话，就放在一个公共的set中，最后公共的set就是我们要的结果。</p>
<p>代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def intersection(self, nums1: List[int], nums2: List[int]) -&gt; List[int]:</span><br><span class="line">        nums1 &#x3D; set(nums1)</span><br><span class="line">        return set([i for i in nums2 if i in nums1])</span><br></pre></td></tr></table></figure>
<p>也可以通过set的内置方法来实现，直接求set的交集：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def intersection(self, nums1: List[int], nums2: List[int]) -&gt; List[int]:</span><br><span class="line">        set1 &#x3D; set(nums1)</span><br><span class="line">        set2 &#x3D; set(nums2)</span><br><span class="line">        return set2 &amp; set1</span><br></pre></td></tr></table></figure>
<h3 id="LeetCode-350-Intersection-Of-Two-Arrays-2"><a href="#LeetCode-350-Intersection-Of-Two-Arrays-2" class="headerlink" title="LeetCode 350 Intersection Of Two Arrays 2"></a>LeetCode 350 Intersection Of Two Arrays 2</h3><h4 id="题目描述-1"><a href="#题目描述-1" class="headerlink" title="题目描述"></a>题目描述</h4><p>给定两个数组nums,求两个数组的交集。</p>
<p>— 如nums1=[1,2,2,1],nums=[2,2]</p>
<p>— 结果为[2,2]</p>
<p>— 出现的顺序可以是任意的</p>
<h4 id="分析实现-1"><a href="#分析实现-1" class="headerlink" title="分析实现"></a>分析实现</h4><p>元素出现的次数有用，那么对于存储次数就是有意义的，所以选择数据结构时，就应该选择dict的结构，通过字典的比较来判断；</p>
<p>记录每个元素的同时要记录这个元素的频次。</p>
<p>记录num1的字典，遍历nums2，比较nums1的字典的nums的key是否大于零，从而进行判断。</p>
<p>代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def intersect(self, nums1: List[int], nums2: List[int]) -&gt; List[int]:</span><br><span class="line">        from collections import Counter</span><br><span class="line">        nums1_dict &#x3D; Counter(nums1)</span><br><span class="line">        res &#x3D; []</span><br><span class="line">        for num in nums2:</span><br><span class="line">            if nums1_dict[num] &gt; 0:</span><br><span class="line">                # 说明找到了一个元素即在num1也在nums2</span><br><span class="line">                res.append(num)</span><br><span class="line">                nums1_dict[num] -&#x3D; 1</span><br><span class="line">        return res</span><br></pre></td></tr></table></figure>
<h3 id="LeetCode-242-Intersection-Of-Two-Arrays-2"><a href="#LeetCode-242-Intersection-Of-Two-Arrays-2" class="headerlink" title="LeetCode 242 Intersection Of Two Arrays 2"></a>LeetCode 242 Intersection Of Two Arrays 2</h3><h4 id="题目描述-2"><a href="#题目描述-2" class="headerlink" title="题目描述"></a>题目描述</h4><p>给定两个字符串 s 和 t ，编写一个函数来判断 t 是否是 s 的字母异位词。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">示例1:</span><br><span class="line"></span><br><span class="line">输入: s &#x3D; &quot;anagram&quot;, t &#x3D; &quot;nagaram&quot;</span><br><span class="line">输出: true</span><br><span class="line"></span><br><span class="line">示例 2:</span><br><span class="line"></span><br><span class="line">输入: s &#x3D; &quot;rat&quot;, t &#x3D; &quot;car&quot;</span><br><span class="line">输出: false</span><br></pre></td></tr></table></figure>
<h4 id="分析实现-2"><a href="#分析实现-2" class="headerlink" title="分析实现"></a>分析实现</h4><p>判断异位词即判断变换位置后的字符串和原来是否相同，那么不仅需要存储元素，还需要记录元素的个数。可以选择dict的数据结构，将字符串s和t都用dict存储，而后直接比较两个dict是否相同。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def isAnagram(self, s: str, t: str) -&gt; bool:</span><br><span class="line">        from collections import Counter</span><br><span class="line">        s &#x3D; Counter(s)</span><br><span class="line">        t &#x3D; Counter(t)</span><br><span class="line">        if s &#x3D;&#x3D; t:</span><br><span class="line">            return True</span><br><span class="line">        else:</span><br><span class="line">            return False</span><br></pre></td></tr></table></figure>
<h3 id="LeetCode-202-Happy-number"><a href="#LeetCode-202-Happy-number" class="headerlink" title="LeetCode 202 Happy number"></a>LeetCode 202 Happy number</h3><h4 id="题目描述-3"><a href="#题目描述-3" class="headerlink" title="题目描述"></a>题目描述</h4><p>编写一个算法来判断一个数是不是“快乐数”。</p>
<p>一个“快乐数”定义为：对于一个正整数，每一次将该数替换为它每个位置上的数字的平方和，然后重复这个过程直到这个数变为 1，也可能是无限循环但始终变不到 1。如果可以变为 1，那么这个数就是快乐数。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">示例: </span><br><span class="line">输入: 19</span><br><span class="line">输出: true</span><br><span class="line">解释: </span><br><span class="line">1^2 + 9^2 &#x3D; 82</span><br><span class="line">8^2 + 2^2 &#x3D; 68</span><br><span class="line">6^2 + 8^2 &#x3D; 100</span><br><span class="line">1^2 + 0^2 + 0^2 &#x3D; 1</span><br></pre></td></tr></table></figure>
<h4 id="分析实现-3"><a href="#分析实现-3" class="headerlink" title="分析实现"></a>分析实现</h4><p>这道题目思路很明显，当n不等于1时就循环，每次循环时，将其最后一位到第一位的数依次平方求和，比较求和是否为1。</p>
<p>难点在于，什么时候跳出循环？</p>
<p>开始笔者的思路是，循环个100次，还没得出结果就false，但是小学在算无限循环小数时有一个特征，就是当除的数中，和之前历史的得到的数有重合时，这时就是无限循环小数。</p>
<p>那么这里也可以按此判断，因为只需要判断有或无，不需要记录次数，故用set的数据结构。每次对求和的数进行append，当新一次求和的值存在于set中时，就return false.</p>
<p>代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def isHappy(self, n: int) -&gt; bool:</span><br><span class="line">        already &#x3D; set()</span><br><span class="line">        while n !&#x3D; 1:</span><br><span class="line">            sum &#x3D; 0</span><br><span class="line">            while n &gt; 0:</span><br><span class="line">                # 取n的最后一位数</span><br><span class="line">                tmp &#x3D; n % 10   </span><br><span class="line">                sum +&#x3D; tmp ** 2</span><br><span class="line">                # 将n的最后一位截掉</span><br><span class="line">                n &#x2F;&#x2F;&#x3D; 10</span><br><span class="line">            # 如果求的和在过程中出现过</span><br><span class="line">            if sum in already:</span><br><span class="line">                return False</span><br><span class="line">            else:</span><br><span class="line">                already.add(sum)</span><br><span class="line">            n &#x3D; sum</span><br><span class="line">        return True</span><br></pre></td></tr></table></figure>
<h4 id="tips"><a href="#tips" class="headerlink" title="tips"></a>tips</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#一般对多位数计算的套路是：</span><br><span class="line">#循环从后向前取位数</span><br><span class="line">while n &gt;0 :</span><br><span class="line">#取最后一位： </span><br><span class="line">tmp &#x3D; n % 10</span><br><span class="line">#再截掉最后一位：</span><br><span class="line">n &#x3D; n &#x2F;&#x2F; 10</span><br></pre></td></tr></table></figure>
<h3 id="LeetCode-290-Word-Pattern"><a href="#LeetCode-290-Word-Pattern" class="headerlink" title="LeetCode 290 Word Pattern"></a>LeetCode 290 Word Pattern</h3><h4 id="题目描述-4"><a href="#题目描述-4" class="headerlink" title="题目描述"></a>题目描述</h4><p>给出一个模式(pattern)以及一个字符串，判断这个字符串是否符合模式</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">示例1:</span><br><span class="line">输入: pattern &#x3D; &quot;abba&quot;, </span><br><span class="line">str &#x3D; &quot;dog cat cat dog&quot;</span><br><span class="line">输出: true</span><br><span class="line"></span><br><span class="line">示例 2:</span><br><span class="line">输入:pattern &#x3D; &quot;abba&quot;, </span><br><span class="line">str &#x3D; &quot;dog cat cat fish&quot;</span><br><span class="line">输出: false</span><br><span class="line"></span><br><span class="line">示例 3:</span><br><span class="line">输入: pattern &#x3D; &quot;aaaa&quot;, str &#x3D; &quot;dog cat cat dog&quot;</span><br><span class="line">输出: false</span><br><span class="line"></span><br><span class="line">示例 4:</span><br><span class="line">输入: pattern &#x3D; &quot;abba&quot;, str &#x3D; &quot;dog dog dog dog&quot;</span><br><span class="line">输出: false</span><br></pre></td></tr></table></figure>
<h4 id="分析实现-4"><a href="#分析实现-4" class="headerlink" title="分析实现"></a>分析实现</h4><p>抓住变与不变，笔者开始的思路是选择了dict的数据结构，比较count值和dict对应的keys的个数是否相同，但是这样无法判断顺序的关系，如测试用例：’aba’,’cat cat dog’。</p>
<p>那么如何能<strong>既考虑顺序</strong>，也考虑<strong>键值对应的关系</strong>呢？</p>
<p>抓住变与不变，变的是键，但是不变的是各个字典中，对应的相同index下的值，如dict1[index] = dict2[index]，那么我们可以创建两个新的字典，遍历index对两个新的字典赋值，并比较value。</p>
<p>还有一个思路比较巧妙，既然不同，那么可以考虑怎么让它们相同，将原来的dict通过map映射为相同的key，再比较相同key的dict是否相同。</p>
<p>代码实现如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def wordPattern(self,pattern, str):</span><br><span class="line">        str &#x3D; str.split()</span><br><span class="line">        return list(map(pattern.index,pattern)) &#x3D;&#x3D; list(map(str.index,str))</span><br></pre></td></tr></table></figure>
<h4 id="tips-1"><a href="#tips-1" class="headerlink" title="tips"></a>tips</h4><ol>
<li>因为str是字符串，不是由单个字符组成，所以开始需要根据空格拆成字符list：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">str &#x3D; str.split()</span><br></pre></td></tr></table></figure>
<ol>
<li>通过map将字典映射为index的list:</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">map(pattern.index, pattern)</span><br></pre></td></tr></table></figure>
<ol>
<li>map是通过hash存储的，不能直接进行比较，需要转换为list比较list</li>
</ol>
<h3 id="LeetCode-205-Isomorphic-Strings"><a href="#LeetCode-205-Isomorphic-Strings" class="headerlink" title="LeetCode 205 Isomorphic Strings"></a>LeetCode 205 Isomorphic Strings</h3><h4 id="题目描述-5"><a href="#题目描述-5" class="headerlink" title="题目描述"></a>题目描述</h4><p>给定两个字符串 s 和 t，判断它们是否是同构的。</p>
<p>如果 s 中的字符可以被替换得到 t ，那么这两个字符串是同构的。</p>
<p>所有出现的字符都必须用另一个字符替换，同时保留字符的顺序。两个字符不能映射到同一个字符上，但字符可以映射自己本身。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">示例 1:</span><br><span class="line">输入: s &#x3D; &quot;egg&quot;, t &#x3D; &quot;add&quot;</span><br><span class="line">输出: true</span><br><span class="line"></span><br><span class="line">示例 2:</span><br><span class="line">输入: s &#x3D; &quot;foo&quot;, t &#x3D; &quot;bar&quot;</span><br><span class="line">输出: false</span><br><span class="line"></span><br><span class="line">示例 3:</span><br><span class="line">输入: s &#x3D; &quot;paper&quot;, t &#x3D; &quot;title&quot;</span><br><span class="line">输出: true</span><br></pre></td></tr></table></figure>
<h4 id="分析实现-5"><a href="#分析实现-5" class="headerlink" title="分析实现"></a>分析实现</h4><p>思路与上题一致，可以考虑通过建两个dict，比较怎样不同，也可以将不同转化为相同。</p>
<p>直接用上题的套路代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def isIsomorphic(self, s: str, t: str) -&gt; bool:</span><br><span class="line">        return list(map(s.index,s)) &#x3D;&#x3D; list(map(t.index,t))</span><br></pre></td></tr></table></figure>
<h3 id="LeetCode-451-Sort-Characters-By-Frequency"><a href="#LeetCode-451-Sort-Characters-By-Frequency" class="headerlink" title="LeetCode 451 Sort Characters By Frequency"></a>LeetCode 451 Sort Characters By Frequency</h3><h4 id="题目描述-6"><a href="#题目描述-6" class="headerlink" title="题目描述"></a>题目描述</h4><p>给定一个字符串，请将字符串里的字符按照出现的频率降序排列。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">示例 1:</span><br><span class="line">输入:</span><br><span class="line">&quot;tree&quot;</span><br><span class="line">输出:</span><br><span class="line">&quot;eert&quot;</span><br><span class="line"></span><br><span class="line">示例 2:</span><br><span class="line">输入:</span><br><span class="line">&quot;cccaaa&quot;</span><br><span class="line">输出:</span><br><span class="line">&quot;cccaaa&quot;</span><br><span class="line"></span><br><span class="line">示例 3:</span><br><span class="line">输入:</span><br><span class="line">&quot;Aabb&quot;</span><br><span class="line">输出:</span><br><span class="line">&quot;bbAa&quot;</span><br></pre></td></tr></table></figure>
<h4 id="分析实现-6"><a href="#分析实现-6" class="headerlink" title="分析实现"></a>分析实现</h4><p>对于相同频次的字母，顺序任意，需要考虑大小写，返回的是字符串。</p>
<p>使用字典统计频率，对字典的value进行排序，最终根据key的字符串乘上value次数，组合在一起输出。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def frequencySort(self, s: str) -&gt; str:</span><br><span class="line">        from collections import Counter</span><br><span class="line">        s_dict &#x3D; Counter(s)</span><br><span class="line">        # sorted返回的是列表元组</span><br><span class="line">        s &#x3D; sorted(s_dict.items(), key&#x3D;lambda item:item[1], reverse &#x3D; True)</span><br><span class="line">        # 因为返回的是字符串</span><br><span class="line">        res &#x3D; &#39;&#39;</span><br><span class="line">        for key, value in s:</span><br><span class="line">            res +&#x3D; key * value   </span><br><span class="line">        return res</span><br></pre></td></tr></table></figure>
<h4 id="tips-2"><a href="#tips-2" class="headerlink" title="tips"></a>tips</h4><ol>
<li>通过sorted的方法进行value排序，对字典排序后无法直接按照字典进行返回，返回的为列表元组：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 对value值由大到小排序</span><br><span class="line">s &#x3D; sorted(s_dict.items(), key&#x3D;lambda item:item[1], reverse &#x3D; True)</span><br><span class="line"></span><br><span class="line"># 对key由小到大排序</span><br><span class="line">s &#x3D; sorted(s_dict.items(), key&#x3D;lambda item:item[0])</span><br></pre></td></tr></table></figure>
<ol>
<li>输出为字符串的情况下，可以由字符串直接进行拼接:</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 由key和value相乘进行拼接</span><br><span class="line">&#39;s&#39; * 5 + &#39;d&#39;*2</span><br></pre></td></tr></table></figure>
<h1 id="二-对撞指针"><a href="#二-对撞指针" class="headerlink" title="二. 对撞指针"></a>二. 对撞指针</h1><h1 id="LeetCode-1-Two-Sum"><a href="#LeetCode-1-Two-Sum" class="headerlink" title="LeetCode 1 Two Sum"></a>LeetCode 1 Two Sum</h1><h2 id="题目描述-7"><a href="#题目描述-7" class="headerlink" title="题目描述"></a>题目描述</h2><p>给出一个整型数组nums，返回这个数组中两个数字的索引值i和j，使得nums[i] + nums[j]等于一个给定的target值，两个索引不能相等。</p>
<p>如：nums= [2,7,11,15],target=9 返回[0,1]</p>
<h2 id="审题"><a href="#审题" class="headerlink" title="审题:"></a>审题:</h2><p>需要考虑：</p>
<ol>
<li>开始数组是否有序；</li>
<li>索引从0开始计算还是1开始计算？</li>
<li>没有解该怎么办？</li>
<li>有多个解怎么办？保证有唯一解。</li>
</ol>
<h2 id="分析实现-7"><a href="#分析实现-7" class="headerlink" title="分析实现"></a>分析实现</h2><h2 id="暴力法O-n-2"><a href="#暴力法O-n-2" class="headerlink" title="暴力法O(n^2)"></a>暴力法O(n^2)</h2><p>时间复杂度为O(n^2),第一遍遍历数组，第二遍遍历当前遍历值之后的元素，其和等于target则return。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def twoSum(self, nums: List[int], target: int) -&gt; List[int]:</span><br><span class="line">        len_nums &#x3D; len(nums)</span><br><span class="line">        for i in range(len_nums):</span><br><span class="line">            for j in range(i+1,len_nums):</span><br><span class="line">                if nums[i] + nums[j] &#x3D;&#x3D; target:</span><br><span class="line">                    return [i,j]</span><br></pre></td></tr></table></figure>
<h2 id="排序-指针对撞-O-n-O-nlogn-O-n"><a href="#排序-指针对撞-O-n-O-nlogn-O-n" class="headerlink" title="排序+指针对撞(O(n)+O(nlogn)=O(n))"></a>排序+指针对撞(O(n)+O(nlogn)=O(n))</h2><p>在数组篇的LeetCode 167题中，也遇到了找到两个数使得它们相加之和等于目标数，但那是对于排序的情况，因此也可以使用上述的思路来完成。</p>
<p>因为问题本身不是有序的，因此需要对原来的数组进行一次排序，排序后就可以用O(n)的指针对撞进行解决。</p>
<p>但是问题是，返回的是数字的索引，如果只是对数组的值进行排序，那么数组原来表示的索引的信息就会丢失，所以在排序前要进行些处理。</p>
<p><strong>错误代码示例—只使用dict来进行保存：</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def twoSum(self, nums: List[int], target: int) -&gt; List[int]:</span><br><span class="line">        record &#x3D; dict()</span><br><span class="line">        for index in range(len(nums)):</span><br><span class="line">            record[nums[index]] &#x3D; index </span><br><span class="line">        nums.sort()</span><br><span class="line">        l,r &#x3D; 0,len(nums)-1</span><br><span class="line">        while l &lt; r:</span><br><span class="line">            if nums[l] + nums[r] &#x3D;&#x3D; target:</span><br><span class="line">                return [record[nums[l]],record[nums[r]]]</span><br><span class="line">            elif nums[l] + nums[r] &lt; target:</span><br><span class="line">                l +&#x3D; 1</span><br><span class="line">            else:</span><br><span class="line">                r -&#x3D; 1</span><br></pre></td></tr></table></figure>
<p>当遇到<strong>相同的元素的索引</strong>问题时，会不满足条件：</p>
<p>如：[3,3] 6</p>
<p>在排序前先使用一个额外的数组<strong>拷贝</strong>一份原来的数组，对于两个相同元素的索引问题，使用一个<strong>bool型变量</strong>辅助将两个索引都找到，总的时间复杂度为O(n)+O(nlogn) = O(nlogn)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def twoSum(self, nums: List[int], target: int) -&gt; List[int]:</span><br><span class="line">        record &#x3D; dict()</span><br><span class="line">        nums_copy &#x3D; nums.copy()</span><br><span class="line">        sameFlag &#x3D; True;</span><br><span class="line">        nums.sort()</span><br><span class="line">        l,r &#x3D; 0,len(nums)-1</span><br><span class="line">        while l &lt; r:</span><br><span class="line">            if nums[l] + nums[r] &#x3D;&#x3D; target:</span><br><span class="line">                break</span><br><span class="line">            elif nums[l] + nums[r] &lt; target:</span><br><span class="line">                l +&#x3D; 1</span><br><span class="line">            else:</span><br><span class="line">                r -&#x3D; 1</span><br><span class="line">        res &#x3D; []</span><br><span class="line">        for i in range(len(nums)):</span><br><span class="line">            if nums_copy[i] &#x3D;&#x3D; nums[l] and sameFlag:</span><br><span class="line">                res.append(i)</span><br><span class="line">                sameFlag &#x3D; False</span><br><span class="line">            elif nums_copy[i] &#x3D;&#x3D; nums[r]:</span><br><span class="line">                res.append(i)</span><br><span class="line">        return res</span><br></pre></td></tr></table></figure>
<h3 id="小套路"><a href="#小套路" class="headerlink" title="小套路:"></a>小套路:</h3><p>如果只是对数组的值进行排序，那么数组原来表示的索引的信息就会丢失的情况，可以在排序前：</p>
<h3 id="更加pythonic的实现"><a href="#更加pythonic的实现" class="headerlink" title="更加pythonic的实现"></a>更加pythonic的实现</h3><p>通过list(enumerate(nums))开始实现下标和值的绑定，不用专门的再copy加bool判断。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nums &#x3D; list(enumerate(nums))</span><br><span class="line">nums.sort(key &#x3D; lambda x:x[1])</span><br><span class="line">i,j &#x3D; 0, len(nums)-1</span><br><span class="line">while i &lt; j:</span><br><span class="line">    if nums[i][1] + nums[j][1] &gt; target:</span><br><span class="line">        j -&#x3D; 1</span><br><span class="line">    elif nums[i][1] + nums[j][1] &lt; target:</span><br><span class="line">        i +&#x3D; 1</span><br><span class="line">    else:</span><br><span class="line">        if nums[j][0] &lt; nums[i][0]:</span><br><span class="line">            nums[j],nums[i] &#x3D; nums[i],nums[j]</span><br><span class="line">        return num[i][0],nums[j][0]</span><br></pre></td></tr></table></figure>
<p><strong>拷贝数组 + bool型变量辅助</strong></p>
<h2 id="查找表—O-n"><a href="#查找表—O-n" class="headerlink" title="查找表—O(n)"></a>查找表—O(n)</h2><p>遍历数组过程中，当遍历到元素v时，可以只看v前面的元素，是否含有target-v的元素存在。</p>
<ol>
<li>如果查找成功，就返回解；</li>
<li>如果没有查找成功，就把v放在查找表中，继续查找下一个解。</li>
</ol>
<p>即使v放在了之前的查找表中覆盖了v，也不影响当前v元素的查找。因为只需要找到两个元素，只需要找target-v的另一个元素即可。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def twoSum(self, nums: List[int], target: int) -&gt; List[int]:</span><br><span class="line">        record &#x3D; dict()</span><br><span class="line">        for i in range(len(nums)):</span><br><span class="line">            complement &#x3D; target - nums[i]</span><br><span class="line">            # 已经在之前的字典中找到这个值</span><br><span class="line">            if record.get(complement) is not None:</span><br><span class="line">                res &#x3D; [i,record[complement]]</span><br><span class="line">                return res</span><br><span class="line">            record[nums[i]] &#x3D; i</span><br></pre></td></tr></table></figure>
<p>只进行一次循环，故时间复杂度O(n),空间复杂度为O(n)</p>
<h2 id="补充思路："><a href="#补充思路：" class="headerlink" title="补充思路："></a>补充思路：</h2><p>通过enumerate来把索引和值进行绑定，进而对value进行sort，前后对撞指针进行返回。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def twoSum(self, nums: List[int], target: int) -&gt; List[int]:</span><br><span class="line">        nums &#x3D; list(enumerate(nums))</span><br><span class="line">        # 根据value来排序</span><br><span class="line">        nums.sort(key &#x3D; lambda x:x[1])</span><br><span class="line">        l,r &#x3D; 0, len(nums)-1</span><br><span class="line">        while l &lt; r:</span><br><span class="line">            if nums[l][1] + nums[r][1] &#x3D;&#x3D; target:</span><br><span class="line">                return nums[l][0],nums[r][0]</span><br><span class="line">            elif nums[l][1] + nums[r][1] &lt; target:</span><br><span class="line">                l +&#x3D; 1</span><br><span class="line">            else:</span><br><span class="line">                r -&#x3D; 1</span><br></pre></td></tr></table></figure>
<h1 id="LeetCode-15-3Sum"><a href="#LeetCode-15-3Sum" class="headerlink" title="LeetCode 15 3Sum"></a>LeetCode 15 3Sum</h1><h2 id="题目描述-8"><a href="#题目描述-8" class="headerlink" title="题目描述"></a>题目描述</h2><p>给出一个整型数组，寻找其中的所有不同的三元组(a,b,c)，使得a+b+c=0</p>
<p>注意：答案中不可以包含重复的三元组。</p>
<p>如：nums = [-1, 0, 1, 2, -1, -4]，</p>
<p>结果为：[[-1, 0, 1],[-1, -1, 2]]</p>
<h2 id="审题-1"><a href="#审题-1" class="headerlink" title="审题"></a>审题</h2><ol>
<li>数组不是有序的；</li>
<li>返回结果为全部解，多个解的顺序是否需要考虑？—不需要考虑顺序</li>
<li>什么叫不同的三元组？索引不同即不同，还是值不同？—题目定义的是，值不同才为不同的三元组</li>
<li>没有解时怎么返回？—空列表</li>
</ol>
<h2 id="分析实现-8"><a href="#分析实现-8" class="headerlink" title="分析实现"></a>分析实现</h2><p>因为上篇中已经实现了Two Sum的问题，因此对于3Sum，首先想到的思路就是，开始固定一个k，然后在其后都当成two sum问题来进行解决，但是这样就ok了吗？</p>
<h3 id="没有考虑重复元素导致错误"><a href="#没有考虑重复元素导致错误" class="headerlink" title="没有考虑重复元素导致错误"></a>没有考虑重复元素导致错误</h3><p>直接使用Two Sum问题中的查找表的解法，根据第一层遍历的i，将i之后的数组作为two sum问题进行解决。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def threeSum(self, nums: [int]) -&gt; [[int]]:</span><br><span class="line">        res &#x3D; []</span><br><span class="line">        for i in range(len(nums)):</span><br><span class="line">            num &#x3D; 0 - nums[i]</span><br><span class="line">            record &#x3D; dict()</span><br><span class="line">            for j in range(i + 1, len(nums)):</span><br><span class="line">                complement &#x3D; num - nums[j]</span><br><span class="line">                # 已经在之前的字典中找到这个值</span><br><span class="line">                if record.get(complement) is not None:</span><br><span class="line">                    res_lis &#x3D; [nums[i], nums[j], complement]</span><br><span class="line">                    res.append(res_lis)</span><br><span class="line">                record[nums[j]] &#x3D; i</span><br><span class="line">        return res</span><br></pre></td></tr></table></figure>
<p>但是这样会导致一个错误，错误用例如下:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入：</span><br><span class="line">[-1,0,1,2,-1,-4]</span><br><span class="line">输出：</span><br><span class="line">[[-1,1,0],[-1,-1,2],[0,-1,1]]</span><br><span class="line">预期结果：</span><br><span class="line">[[-1,-1,2],[-1,0,1]]</span><br></pre></td></tr></table></figure>
<p>代码在实现的过程中没有把第一次遍历的i的索引指向相同元素的情况排除掉，于是出现了当i指针后面位置的元素有和之前访问过的相同的值，于是重复遍历。</p>
<p>那么可以考虑，开始时对nums数组进行排序，排序后，当第一次遍历的指针k遇到下一个和前一个指向的值重复时，就将其跳过。为了方便计算，在第二层循环中，可以使用<strong>对撞指针</strong>的套路：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 对撞指针套路</span><br><span class="line">l,r &#x3D; 0, len(nums)-1</span><br><span class="line">while l &lt; r:</span><br><span class="line">    if nums[l] + nums[r] &#x3D;&#x3D; target:</span><br><span class="line">        return nums[l],nums[r]</span><br><span class="line">    elif nums[l] + nums[r] &lt; target:</span><br><span class="line">        l +&#x3D; 1</span><br><span class="line">    else:</span><br><span class="line">        r -&#x3D; 1</span><br></pre></td></tr></table></figure>
<p>其中需要注意的是，在里层循环中，也要考虑重复值的情况，因此当值相等时，再次移动指针时，需要保证其指向的值和前一次指向的值不重复，因此可以：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 对撞指针套路</span><br><span class="line">l,r &#x3D; 0, len(nums)-1</span><br><span class="line">while l &lt; r:</span><br><span class="line">    sum &#x3D; nums[i] + nums[l] + nums[r]</span><br><span class="line">    if sum &#x3D;&#x3D; target:</span><br><span class="line">        res.append([nums[i],nums[l],nums[r])</span><br><span class="line">        l +&#x3D; 1</span><br><span class="line">        r -&#x3D; 1</span><br><span class="line">        while l &lt; r and nums[l] &#x3D;&#x3D; nums[l-1]: l +&#x3D; 1</span><br><span class="line">        while l &lt; r and nums[r] &#x3D;&#x3D; nums[r+1]: r -&#x3D; 1</span><br><span class="line">    elif sum &lt; target:</span><br><span class="line">        l +&#x3D; 1</span><br><span class="line">    else:</span><br><span class="line">        r -&#x3D; 1</span><br></pre></td></tr></table></figure>
<p>再调整下遍历的范围，因为设了3个索引：i，l，r。边界情况下，r索引指向len-1, l指向len-2，索引i遍历的边界为len-3，故for循环是从0到len-2。</p>
<p>代码实现如下：</p>
<h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def threeSum(self, nums: [int]) -&gt; [[int]]:</span><br><span class="line">        nums.sort()</span><br><span class="line">        res &#x3D; []</span><br><span class="line">        for i in range(len(nums)-2):</span><br><span class="line">            # 因为是排序好的数组，如果最小的都大于0可以直接排除</span><br><span class="line">            if nums[i] &gt; 0: break</span><br><span class="line">            # 排除i的重复值</span><br><span class="line">            if i &gt; 0 and nums[i] &#x3D;&#x3D; nums[i-1]: continue</span><br><span class="line">            l,r &#x3D; i+1, len(nums)-1</span><br><span class="line">            while l &lt; r:</span><br><span class="line">                sum &#x3D; nums[i] + nums[l] + nums[r]</span><br><span class="line">                if sum &#x3D;&#x3D; 0:</span><br><span class="line">                    res.append([nums[i],nums[l],nums[r]])</span><br><span class="line">                    l +&#x3D; 1</span><br><span class="line">                    r -&#x3D; 1</span><br><span class="line">                    while l &lt; r and nums[l] &#x3D;&#x3D; nums[l-1]: l +&#x3D; 1</span><br><span class="line">                    while l &lt; r and nums[r] &#x3D;&#x3D; nums[r+1]: r -&#x3D; 1</span><br><span class="line">                elif sum &lt; 0:</span><br><span class="line">                    l +&#x3D; 1</span><br><span class="line">                else:</span><br><span class="line">                    r -&#x3D; 1</span><br><span class="line">        return res</span><br></pre></td></tr></table></figure>
<h2 id="小套路-1"><a href="#小套路-1" class="headerlink" title="小套路"></a>小套路</h2><ol>
<li>采用<strong>for + while</strong>的形式来处理三索引；</li>
<li>当数组不是有序时需要注意，有序的特点在哪里，有序就可以用哪些方法解决？无序的话不便在哪里？</li>
<li>对撞指针套路：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 对撞指针套路</span><br><span class="line">l,r &#x3D; 0, len(nums)-1</span><br><span class="line">while l &lt; r:</span><br><span class="line">    if nums[l] + nums[r] &#x3D;&#x3D; target:</span><br><span class="line">        return nums[l],nums[r]</span><br><span class="line">    elif nums[l] + nums[r] &lt; target:</span><br><span class="line">        l +&#x3D; 1</span><br><span class="line">    else:</span><br><span class="line">        r -&#x3D; 1</span><br></pre></td></tr></table></figure>
<ol>
<li>处理重复值的套路：先转换为有序数组，再循环判断其与上一次值是否重复：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 1.</span><br><span class="line">for i in range(len(nums)):</span><br><span class="line">    if i &gt; 0 and nums[i] &#x3D;&#x3D; nums[i-1]: continue</span><br><span class="line"># 2.</span><br><span class="line">while l &lt; r:</span><br><span class="line">    while l &lt; r and nums[l] &#x3D;&#x3D; nums[l-1]: l +&#x3D; 1</span><br></pre></td></tr></table></figure>
<h1 id="LeetCode-18-4Sum"><a href="#LeetCode-18-4Sum" class="headerlink" title="LeetCode 18 4Sum"></a>LeetCode 18 4Sum</h1><h2 id="题目描述-9"><a href="#题目描述-9" class="headerlink" title="题目描述"></a>题目描述</h2><p>给出一个整形数组，寻找其中的所有不同的四元组(a,b,c,d)，使得a+b+c+d等于一个给定的数字target。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">如:</span><br><span class="line">nums &#x3D; [1, 0, -1, 0, -2, 2]，target &#x3D; 0</span><br><span class="line"></span><br><span class="line">结果为：</span><br><span class="line">[[-1,  0, 0, 1],[-2, -1, 1, 2],[-2,  0, 0, 2]]</span><br></pre></td></tr></table></figure>
<h2 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a>题目分析</h2><p>4Sum可以当作是3Sum问题的扩展，注意事项仍是一样的，同样是不能返回重复值得解。首先排序。接着从[0,len-1]遍历i，跳过i的重复元素，再在[i+1,len-1]中遍历j，得到i，j后，再选择首尾的l和r，通过对撞指针的思路，四数和大的话r—，小的话l++,相等的话纳入结果list，最后返回。</p>
<p>套用3Sum得代码，在其前加一层循环，对边界情况进行改动即可:</p>
<ol>
<li>原来3个是到len-2,现在外层循环是到len-3;</li>
<li>在中间层得迭代中，当第二个遍历得值在第一个遍历得值之后且后项大于前项时，认定为重复；</li>
<li>加些边界条件判断：当len小于4时，直接返回；当只有4个值且长度等于target时，直接返回本身即可。</li>
</ol>
<p>代码实现如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def fourSum(self, nums: List[int], target: int) -&gt; List[List[int]]:</span><br><span class="line">        nums.sort()</span><br><span class="line">        res &#x3D; []</span><br><span class="line">        if len(nums) &lt; 4: return res</span><br><span class="line">        if len(nums) &#x3D;&#x3D; 4 and sum(nums) &#x3D;&#x3D; target:</span><br><span class="line">            res.append(nums)</span><br><span class="line">            return res</span><br><span class="line">        for i in range(len(nums)-3):</span><br><span class="line">            if i &gt; 0 and nums[i] &#x3D;&#x3D; nums[i-1]: continue</span><br><span class="line">            for j in range(i+1,len(nums)-2):</span><br><span class="line">                if j &gt; i+1 and nums[j] &#x3D;&#x3D; nums[j-1]: continue</span><br><span class="line">                l,r &#x3D; j+1, len(nums)-1</span><br><span class="line">                while l &lt; r:</span><br><span class="line">                    sum_value &#x3D; nums[i] + nums[j] + nums[l] + nums[r]</span><br><span class="line">                    if sum_value &#x3D;&#x3D; target:</span><br><span class="line">                        res.append([nums[i],nums[j],nums[l],nums[r]])</span><br><span class="line">                        l +&#x3D; 1</span><br><span class="line">                        r -&#x3D; 1</span><br><span class="line">                        while l &lt; r and nums[l] &#x3D;&#x3D; nums[l-1]: l +&#x3D; 1</span><br><span class="line">                        while l &lt; r and nums[r] &#x3D;&#x3D; nums[r+1]: r -&#x3D; 1</span><br><span class="line">                    elif sum_value &lt; target:</span><br><span class="line">                        l +&#x3D; 1</span><br><span class="line">                    else:</span><br><span class="line">                        r -&#x3D; 1</span><br><span class="line">        return res</span><br></pre></td></tr></table></figure>
<p>还可以使用combinations(nums, 4)来对原数组中得4个元素全排列，在开始sort后，对排列得到得元素进行set去重。但单纯利用combinations实现会超时。</p>
<h2 id="超出时间限制"><a href="#超出时间限制" class="headerlink" title="超出时间限制"></a>超出时间限制</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def fourSum(self, nums: List[int], target: int) -&gt; List[List[int]]:</span><br><span class="line">        nums.sort()</span><br><span class="line">        from itertools import combinations</span><br><span class="line">        res &#x3D; []</span><br><span class="line">        for i in combinations(nums, 4):</span><br><span class="line">            if sum(i) &#x3D;&#x3D; target:</span><br><span class="line">                res.append(i)</span><br><span class="line">        res &#x3D; set(res)</span><br><span class="line">        return res</span><br></pre></td></tr></table></figure>
<h1 id="LeetCode-16-3Sum-Closest"><a href="#LeetCode-16-3Sum-Closest" class="headerlink" title="LeetCode 16 3Sum Closest"></a>LeetCode 16 3Sum Closest</h1><h2 id="题目描述-10"><a href="#题目描述-10" class="headerlink" title="题目描述"></a>题目描述</h2><p>给出一个整形数组，寻找其中的三个元素a,b,c，使得a+b+c的值最接近另外一个给定的数字target。</p>
<p>如：给定数组 nums = [-1，2，1，-4], 和 target = 1.</p>
<p>与 target 最接近的三个数的和为 2. (-1 + 2 + 1 = 2).</p>
<h2 id="分析实现-9"><a href="#分析实现-9" class="headerlink" title="分析实现"></a>分析实现</h2><p>这道题也是2sum,3sum等题组中的，只不过变形的地方在于不是找相等的target，而是找最近的。</p>
<p>那么开始时可以随机设定一个三个数的和为结果值，在每次比较中，先判断三个数的和是否和target相等，如果相等直接返回和。如果不相等，则判断三个数的和与target的差是否小于这个结果值时，如果小于则进行则进行替换，并保存和的结果值。</p>
<h3 id="伪代码"><a href="#伪代码" class="headerlink" title="伪代码"></a>伪代码</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 先排序</span><br><span class="line">nums.sort()</span><br><span class="line"># 随机选择一个和作为结果值</span><br><span class="line">res &#x3D; nums[0] + nums[1] + nums[2]</span><br><span class="line"># 记录这个差值</span><br><span class="line">diff &#x3D; abs(nums[0]+nums[1]+nums[2]-target)</span><br><span class="line"># 第一遍遍历</span><br><span class="line">for i in range(len(nums)):</span><br><span class="line">    # 标记好剩余元素的l和r</span><br><span class="line">    l,r &#x3D; i+1, len(nums-1)</span><br><span class="line">    while l &lt; r:</span><br><span class="line">        if 后续的值等于target:</span><br><span class="line">            return 三个数值得和</span><br><span class="line">        else:</span><br><span class="line">            if 差值小于diff:</span><br><span class="line">                更新diff值</span><br><span class="line">                更新res值</span><br><span class="line">            if 和小于target:</span><br><span class="line">                将l移动</span><br><span class="line">            else:(开始已经排除了等于得情况，要判断和大于target)</span><br><span class="line">                将r移动</span><br></pre></td></tr></table></figure>
<h3 id="3Sum问题两层遍历得套路代码："><a href="#3Sum问题两层遍历得套路代码：" class="headerlink" title="3Sum问题两层遍历得套路代码："></a>3Sum问题两层遍历得套路代码：</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nums.sort()</span><br><span class="line">res &#x3D; []</span><br><span class="line">for i in range(len(nums)-2):</span><br><span class="line">    l,r &#x3D; i+1, len(nums)-1</span><br><span class="line">    while l &lt; r:</span><br><span class="line">        sum &#x3D; nums[i] + nums[l] + nums[r]</span><br><span class="line">        if sum &#x3D;&#x3D; 0:</span><br><span class="line">            res.append([nums[i],nums[l],nums[r]])</span><br><span class="line">        elif sum &lt; 0:</span><br><span class="line">            l +&#x3D; 1</span><br><span class="line">        else:</span><br><span class="line">            r -&#x3D; 1</span><br></pre></td></tr></table></figure>
<h3 id="代码实现："><a href="#代码实现：" class="headerlink" title="代码实现："></a>代码实现：</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def threeSumClosest(self, nums: List[int], target: int) -&gt; int:</span><br><span class="line">        nums.sort()</span><br><span class="line">        diff &#x3D; abs(nums[0]+nums[1]+nums[2]-target)</span><br><span class="line">        res &#x3D; nums[0] + nums[1] + nums[2]</span><br><span class="line">        for i in range(len(nums)):</span><br><span class="line">            l,r &#x3D; i+1,len(nums)-1</span><br><span class="line">            t &#x3D; target - nums[i]</span><br><span class="line">            while l &lt; r:</span><br><span class="line">                if nums[l] + nums[r] &#x3D;&#x3D; t:</span><br><span class="line">                    return nums[i] + t</span><br><span class="line">                else:</span><br><span class="line">                    if abs(nums[l]+nums[r]-t) &lt; diff:</span><br><span class="line">                        diff &#x3D; abs(nums[l]+nums[r]-t)</span><br><span class="line">                        res &#x3D; nums[i]+nums[l]+nums[r]</span><br><span class="line">                    if nums[l]+nums[r] &lt; t:</span><br><span class="line">                        l +&#x3D; 1</span><br><span class="line">                    else:</span><br><span class="line">                        r -&#x3D; 1</span><br><span class="line">        return res</span><br></pre></td></tr></table></figure>
<p>时间复杂度为O(n^2)，空间复杂度为O(1);</p>
<h1 id="LeetCode-454-4SumⅡ"><a href="#LeetCode-454-4SumⅡ" class="headerlink" title="LeetCode 454 4SumⅡ"></a>LeetCode 454 4SumⅡ</h1><h2 id="题目描述-11"><a href="#题目描述-11" class="headerlink" title="题目描述"></a>题目描述</h2><p>给出四个整形数组A,B,C,D,寻找有多少i,j,k,l的组合,使得A[i]+B[j]+C[k]+D[l]=0。其中,A,B,C,D中均含有相同的元素个数N，且0&lt;=N&lt;=500；</p>
<p>输入:</p>
<p>A = [ 1, 2] B = [-2,-1] C = [-1, 2] D = [ 0, 2]</p>
<p>输出:2</p>
<h2 id="分析实现-10"><a href="#分析实现-10" class="headerlink" title="分析实现"></a>分析实现</h2><p>这个问题同样是Sum类问题得变种，其将同一个数组的条件，变为了四个数组中，依然可以用查找表的思想来实现。</p>
<p>首先可以考虑把D数组中的元素都放入查找表，然后遍历前三个数组，判断target减去每个元素后的值是否在查找表中存在，存在的话，把结果值加1。那么查找表的数据结构选择用set还是dict？考虑到数组中可能存在重复的元素，而重复的元素属于不同的情况，因此用dict存储，最后的结果值加上dict相应key的value，代码如下：</p>
<h3 id="O-n-3-代码"><a href="#O-n-3-代码" class="headerlink" title="$O(n^3)$代码"></a>$O(n^3)$代码</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from collections import Counter</span><br><span class="line">record &#x3D; Counter()</span><br><span class="line"># 先建立数组D的查找表</span><br><span class="line">for i in range(len(D)):</span><br><span class="line">    record[D[i]] +&#x3D; 1</span><br><span class="line">res &#x3D; 0 </span><br><span class="line">for i in range(len(A)):</span><br><span class="line">    for j in range(len(B)):</span><br><span class="line">        for k in range(len(C)):</span><br><span class="line">            num_find &#x3D; 0-A[i]-B[j]-C[k]</span><br><span class="line">            if record.get(num_find) !&#x3D; None:</span><br><span class="line">                res +&#x3D; record(num_find)</span><br><span class="line">return res</span><br></pre></td></tr></table></figure>
<p>但是对于题目中给出的数据规模：N&lt;=500，如果N为500时，n^3的算法依然消耗很大，能否再进行优化呢？</p>
<p>根据之前的思路继续往前走，如果只遍历两个数组，那么就可以得到O(n^2)级别的算法，但是遍历两个数组，那么还剩下C和D两个数组，上面的值怎么放？</p>
<p>对于查找表问题而言，<strong>很多时候到底要查找什么</strong>，是解决的关键。对于C和D的数组，可以通过dict来记录其中和的个数，之后遍历结果在和中进行查找。代码如下：</p>
<h3 id="O-n-2-级代码"><a href="#O-n-2-级代码" class="headerlink" title="$O(n^2)$级代码"></a>$O(n^2)$级代码</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def fourSumCount(self, A: List[int], B: List[int], C: List[int], D: List[int]) -&gt; int:</span><br><span class="line">        from collections import Counter</span><br><span class="line">        record &#x3D; Counter()</span><br><span class="line">        for i in range(len(A)):</span><br><span class="line">            for j in range(len(B)):</span><br><span class="line">                record[A[i]+B[j]] +&#x3D; 1</span><br><span class="line">        res &#x3D; 0</span><br><span class="line">        for i in range(len(C)):</span><br><span class="line">            for j in range(len(D)):</span><br><span class="line">                find_num &#x3D; 0 - C[i] - D[j]</span><br><span class="line">                if record.get(find_num) !&#x3D; None:</span><br><span class="line">                    res +&#x3D; record[find_num]</span><br><span class="line">        return res</span><br></pre></td></tr></table></figure>
<p>再使用Pythonic的列表生成式和sum函数进行优化，如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def fourSumCount(self, A: List[int], B: List[int], C: List[int], D: List[int]) -&gt; int:</span><br><span class="line">        record &#x3D; collections.Counter(a + b for a in A for b in B)</span><br><span class="line">        return sum(record.get(- c - d, 0) for c in C for d in D)</span><br></pre></td></tr></table></figure>
<h1 id="LeetCode-49-Group-Anagrams"><a href="#LeetCode-49-Group-Anagrams" class="headerlink" title="LeetCode 49 Group Anagrams"></a>LeetCode 49 Group Anagrams</h1><h2 id="题目描述-12"><a href="#题目描述-12" class="headerlink" title="题目描述"></a>题目描述</h2><p>给出一个字符串数组，将其中所有可以通过颠倒字符顺序产生相同结果的单词进行分组。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">示例:</span><br><span class="line">输入: [&quot;eat&quot;, &quot;tea&quot;, &quot;tan&quot;, &quot;ate&quot;, &quot;nat&quot;, &quot;bat&quot;],</span><br><span class="line">输出:[[&quot;ate&quot;,&quot;eat&quot;,&quot;tea&quot;],[&quot;nat&quot;,&quot;tan&quot;],[&quot;bat&quot;]]</span><br><span class="line"></span><br><span class="line">说明：</span><br><span class="line">所有输入均为小写字母。</span><br><span class="line">不考虑答案输出的顺序。</span><br></pre></td></tr></table></figure>
<h2 id="分析实现-11"><a href="#分析实现-11" class="headerlink" title="分析实现"></a>分析实现</h2><p>在之前LeetCode 242的问题中，对字符串t和s来判断，判断t是否是s的字母异位词。当时的方法是通过构建t和s的字典，比较字典是否相同来判断是否为异位词。</p>
<p>在刚开始解决这个问题时，我也局限于了这个思路，以为是通过移动指针，来依次比较两个字符串是否对应的字典相等，进而确定异位词列表，再把异位词列表添加到结果集res中。于是有：</p>
<h3 id="错误思路"><a href="#错误思路" class="headerlink" title="错误思路"></a>错误思路</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nums &#x3D; [&quot;eat&quot;, &quot;tea&quot;, &quot;tan&quot;, &quot;ate&quot;, &quot;nat&quot;, &quot;bat&quot;]</span><br><span class="line"></span><br><span class="line">from collections import Counter</span><br><span class="line">cum &#x3D; []</span><br><span class="line">for i in range(len(nums)):</span><br><span class="line">    l,r &#x3D; i+1,len(nums)-1</span><br><span class="line">    i_dict &#x3D; Counter(nums[i])</span><br><span class="line">    res &#x3D; []</span><br><span class="line">    if nums[i] not in cum:</span><br><span class="line">        res.append(nums[i])</span><br><span class="line">    while l &lt; r:</span><br><span class="line">        l_dict &#x3D; Counter(nums[l])</span><br><span class="line">        r_dict &#x3D; Counter(nums[r])</span><br><span class="line">        if i_dict &#x3D;&#x3D; l_dict and l_dict &#x3D;&#x3D; r_dict:</span><br><span class="line">            res.append(nums[l],nums[r])</span><br><span class="line">            l +&#x3D; 1</span><br><span class="line">            r -&#x3D; 1</span><br><span class="line">        elif i_dict &#x3D;&#x3D; l_dict:</span><br><span class="line">            res.append(nums[l])</span><br><span class="line">            l +&#x3D; 1</span><br><span class="line">        elif i_dict &#x3D;&#x3D; r_dict:</span><br><span class="line">            res.append(nums[r])</span><br><span class="line">            r -&#x3D; 1</span><br><span class="line">        else:</span><br><span class="line">            l +&#x3D; 1</span><br><span class="line">    print(res)</span><br><span class="line">    cum.append(res)</span><br><span class="line">......................................</span><br></pre></td></tr></table></figure>
<p>这时发现长长绵绵考虑不完，而且还要注意指针的条件，怎样遍历才能遍历所有的情况且判断列表是否相互间包含。。。</p>
<p>于是立即开始反思是否哪块考虑错了?回顾第一开始的选择数据结构，在dict和list中，自己错误的选择了list来当作数据结构，进而用指针移动来判断元素的情况。而<strong>没有利用题目中不变的条件</strong>。</p>
<p>题目的意思，对异位词的进行分组，同异位词的分为一组，那么考虑对这一组内什么是相同的，且这个相同的也能作为不同组的判断条件。</p>
<p>不同组的判断条件，就可以用数据结构dict中的key来代表，那么什么相同的适合当作key呢？</p>
<p>这时回顾下下LeetCode 242，当时是因为异位字符串中包含的<strong>字符串的字母个数</strong>都是相同的，故把字母当作key来进行判断是否为异位词。</p>
<p>但是对于本题，把每个字符串的字母dict，再当作字符串数组的dict的key，显然不太合适，那么对于异位词，还有什么是相同的？</p>
<p>显然，如果将字符串统一排序，<strong>异位词排序后的字符串</strong>，显然都是相同的。那么就可以把其当作key，把遍历的数组中的异位词当作value，对字典进行赋值，进而遍历字典的value，得到结果list。</p>
<p>需要注意的细节是，<strong>字符串和list之间的转换</strong>：</p>
<ol>
<li>默认构造字典需为list的字典；</li>
<li>排序使用sorted()函数，而不用list.sort()方法，因为其不返回值；</li>
<li>通过’’.join(list)，将list转换为字符串；</li>
<li>通过str.split(‘,’)将字符串整个转换为list中的一项；</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def groupAnagrams(self, strs: List[str]) -&gt; List[List[str]]:</span><br><span class="line">        from collections import defaultdict</span><br><span class="line">        strs_dict &#x3D; defaultdict(list)</span><br><span class="line">        res &#x3D; []</span><br><span class="line">        for str in strs:</span><br><span class="line">            key &#x3D; &#39;&#39;.join(sorted(list(str)))</span><br><span class="line">            strs_dict[key] +&#x3D; str.split(&#39;,&#39;)</span><br><span class="line">        for v in strs_dict.values():</span><br><span class="line">            res.append(v)</span><br><span class="line">        return res</span><br></pre></td></tr></table></figure>
<p>再将能用列表生成式替换的地方替换掉,代码实现如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def groupAnagrams(self, strs: List[str]) -&gt; List[List[str]]:</span><br><span class="line">        from collections import defaultdict</span><br><span class="line">        strs_dict &#x3D; defaultdict(list)</span><br><span class="line">        for str in strs:</span><br><span class="line">            key &#x3D; &#39;&#39;.join(sorted(list(str)))</span><br><span class="line">            strs_dict[key] +&#x3D; str.split(&#39;,&#39;)</span><br><span class="line">        return [v for v in strs_dict.values()]</span><br></pre></td></tr></table></figure>
<h1 id="LeetCode-447-Number-of-Boomerangs"><a href="#LeetCode-447-Number-of-Boomerangs" class="headerlink" title="LeetCode 447 Number of Boomerangs"></a>LeetCode 447 Number of Boomerangs</h1><h2 id="题目描述-13"><a href="#题目描述-13" class="headerlink" title="题目描述"></a>题目描述</h2><p>给出一个平面上的n个点，寻找存在多少个由这些点构成的三元组(i,j,k)，<strong>使得i,j两点的距离等于i,k两点的距离</strong>。</p>
<p>其中n最多为500,且所有的点坐标的范围在[-10000,10000]之间。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入:</span><br><span class="line">[[0,0],[1,0],[2,0]]</span><br><span class="line"></span><br><span class="line">输出:</span><br><span class="line">2</span><br><span class="line">解释:</span><br><span class="line">两个结果为： [[1,0],[0,0],[2,0]] 和 [[1,0],[2,0],[0,0]]</span><br></pre></td></tr></table></figure>
<h2 id="分析实现-12"><a href="#分析实现-12" class="headerlink" title="分析实现"></a>分析实现</h2><h3 id="原始思路"><a href="#原始思路" class="headerlink" title="原始思路"></a>原始思路</h3><p>题目的要求是：使得i,j两点的距离等于i,k两点的距离，那么相当于是比较三个点之间距离的，那么开始的思路就是三层遍历，i从0到len，j从i+1到len，k从j+1到len，然后比较三个点的距离，相等则结果数加一。</p>
<p>显然这样的时间复杂度为O(n^3)，对于这道题目，能否用查找表的思路进行解决优化？</p>
<h3 id="查找表"><a href="#查找表" class="headerlink" title="查找表"></a>查找表</h3><p>之前的查找表问题，大多是通过<strong>构建一个查找表</strong>，而避免了在查找中再内层嵌套循环，从而降低了时间复杂度。那么可以考虑在这道题中，可以通过查找表进行代替哪两层循环。</p>
<p>当i,j两点距离等于i,k时，用查找表的思路，等价于：对距离key(i,j或i,k的距离)，其值value(个数)为2。</p>
<p>那么就可以做一个查找表，用来查找相同距离key的个数value是多少。遍历每一个节点i，扫描得到其他点到节点i的距离，在查找表中，对应的键就是距离的值，对应的值就是距离值得个数。</p>
<p>在拿到对于元素i的距离查找表后，接下来就是排列选择问题了：</p>
<ol>
<li>如果当距离为x的值有2个时，那么选择j,k的可能情况有：第一次选择有2种，第二次选择有1种，为2*1；</li>
<li>如果当距离为x的值有3个时，那么选择j,k的可能的情况有：第一次选择有3种，第二次选择有2种，为3*2;</li>
<li>那么当距离为x的值有n个时，选择j,k的可能情况有：第一次选择有n种，第二次选择有n-1种。</li>
</ol>
<h3 id="距离"><a href="#距离" class="headerlink" title="距离"></a>距离</h3><p>对于距离值的求算，按照欧式距离的方法进行求算的话，容易产生浮点数，可以将根号去掉，用差的平方和来进行比较距离。</p>
<p>实现代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def numberOfBoomerangs(self, points: List[List[int]]) -&gt; int:</span><br><span class="line">        res &#x3D; 0</span><br><span class="line">        from collections import Counter</span><br><span class="line">        for i in points:</span><br><span class="line">            record &#x3D; Counter()</span><br><span class="line">            for j in points:</span><br><span class="line">                if i !&#x3D; j:</span><br><span class="line">                    record[self.dis(i,j)] +&#x3D; 1</span><br><span class="line">            for k,v in record.items():</span><br><span class="line">                res +&#x3D; v*(v-1)</span><br><span class="line">        return res</span><br><span class="line">    def dis(self,point1,point2):</span><br><span class="line">        return (point1[0]-point2[0]) ** 2 + (point1[1]-point2[1]) ** 2</span><br></pre></td></tr></table></figure>
<h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><p>对实现的代码进行优化：</p>
<ol>
<li>将for循环遍历改为列表生成式;</li>
<li>对sum+=的操作，考虑使用sum函数。</li>
<li>对不同的函数使用闭包的方式内嵌；</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def numberOfBoomerangs(self, points: List[List[int]]) -&gt; int:</span><br><span class="line">        from collections import Counter</span><br><span class="line">        def f(x1, y1):</span><br><span class="line">            # 对一个i下j,k的距离值求和</span><br><span class="line">            d &#x3D; Counter((x2 - x1) ** 2 + (y2 - y1) ** 2 for x2, y2 in points)</span><br><span class="line">            return sum(t * (t-1) for t in d.values())</span><br><span class="line">        # 对每个i的距离进行求和</span><br><span class="line">        return sum(f(x1, y1) for x1, y1 in points)</span><br></pre></td></tr></table></figure>
<h1 id="LeetCode-149-Max-Points-on-a-Line"><a href="#LeetCode-149-Max-Points-on-a-Line" class="headerlink" title="LeetCode 149 Max Points on a Line"></a>LeetCode 149 Max Points on a Line</h1><h2 id="题目描述-14"><a href="#题目描述-14" class="headerlink" title="题目描述"></a>题目描述</h2><p>给定一个二维平面，平面上有 n 个点，求最多有多少个点在同一条直线上。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">示例 1:</span><br><span class="line">输入: [[1,1],[2,2],[3,3]]</span><br><span class="line">输出: 3</span><br><span class="line"></span><br><span class="line">示例 2:</span><br><span class="line">输入: [[1,1],[3,2],[5,3],[4,1],[2,3],[1,4]]</span><br><span class="line">输出: 4</span><br></pre></td></tr></table></figure>
<h2 id="分析实现-13"><a href="#分析实现-13" class="headerlink" title="分析实现"></a>分析实现</h2><p>本道题目的要求是：看有多少个点在同一条直线上，那么判断点是否在一条直线上，其实就等价于判断i,j两点的斜率是否等于i,k两点的斜率。</p>
<p>回顾上道447题目中的要求：使得i,j两点的距离等于i,k两点的距离，那么在这里，直接考虑使用查找表实现，即<strong>查找相同斜率key的个数value是多少</strong>。</p>
<p>在上个问题中，i和j，j和i算是两种不同的情况，但是这道题目中，这是属于相同的两个点， 因此在对遍历每个i,查找与i相同斜率的点时，不能再对结果数res++，而应该取查找表中的最大值。如果有两个斜率相同时，返回的应该是3个点，故返回的是结果数+1。</p>
<p>查找表实现套路如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def maxPoints(self,points):</span><br><span class="line">        res &#x3D; 0</span><br><span class="line">        from collections import defaultdict</span><br><span class="line">        for i in range(len(points)):</span><br><span class="line">            record &#x3D; defaultdict(int)</span><br><span class="line">            for j in range(len(points)):</span><br><span class="line">                if i !&#x3D; j:</span><br><span class="line">                    record[self.get_Slope(points,i,j)] +&#x3D; 1</span><br><span class="line">            for v in record.values():</span><br><span class="line">                res &#x3D; max(res, v)</span><br><span class="line">        return res + 1</span><br><span class="line">    def get_Slope(self,points,i,j):</span><br><span class="line">        return (points[i][0] - points[j][0]) &#x2F; (points[i][1] - points[j][1])</span><br></pre></td></tr></table></figure>
<p>但是这样会出现一个问题，即斜率的求算中，有时会出现直线为垂直的情况，故需要对返回的结果进行判断，如果分母为0，则返回inf，如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def get_Slope(self,points,i,j):</span><br><span class="line">    if points[i][1] - points[j][1] &#x3D;&#x3D; 0:</span><br><span class="line">        return float(&#39;Inf&#39;)</span><br><span class="line">    else:</span><br><span class="line">        return (points[i][0] - points[j][0]) &#x2F; (points[i][1] - points[j][1])</span><br></pre></td></tr></table></figure>
<p>再次提交，发现对于空列表的测试用例会判断错误，于是对边界情况进行判断，如果初始长度小于等于1,则直接返回len：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if len(points) &lt;&#x3D; 1:</span><br><span class="line">    return len(points)</span><br></pre></td></tr></table></figure>
<p>再次提交，对于相同元素的测试用例会出现错误，回想刚才的过程，当有相同元素时，题目的要求是算作两个不同的点，但是在程序运行时，会将其考虑为相同的点，return回了inf。但在实际运行时，需要对相同元素的情况单独考虑。</p>
<p>于是可以设定samepoint值，遍历时判断，如果相同时，same值++,最后取v+same的值作为结果数。</p>
<p>考虑到如果全是相同值，那么这时dict中的record为空，也要将same值当作结果数返回，代码实现如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def maxPoints(self,points):</span><br><span class="line">        if len(points) &lt;&#x3D; 1:</span><br><span class="line">            return len(points)</span><br><span class="line">        res &#x3D; 0</span><br><span class="line">        from collections import defaultdict</span><br><span class="line">        for i in range(len(points)):</span><br><span class="line">            record &#x3D; defaultdict(int)</span><br><span class="line">            samepoint &#x3D; 0</span><br><span class="line">            for j in range(len(points)):</span><br><span class="line">                if points[i][0] &#x3D;&#x3D; points[j][0] and points[i][1] &#x3D;&#x3D; points[j][1]:</span><br><span class="line">                    samepoint +&#x3D; 1</span><br><span class="line">                else:</span><br><span class="line">                    record[self.get_Slope(points,i,j)] +&#x3D; 1</span><br><span class="line">            for v in record.values():</span><br><span class="line">                res &#x3D; max(res, v+samepoint)</span><br><span class="line">            res &#x3D; max(res, samepoint)</span><br><span class="line">        return res</span><br><span class="line">    def get_Slope(self,points,i,j):</span><br><span class="line">        if points[i][1] - points[j][1] &#x3D;&#x3D; 0:</span><br><span class="line">            return float(&#39;Inf&#39;)</span><br><span class="line">        else:</span><br><span class="line">            return (points[i][0] - points[j][0]) &#x2F; (points[i][1] - points[j][1])</span><br></pre></td></tr></table></figure>
<p>时间复杂度为O(n^2)，空间复杂度为O(n)</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>遍历时多用索引，而不要直接用值进行遍历；</p>
<h1 id="三-滑动数组"><a href="#三-滑动数组" class="headerlink" title="三. 滑动数组"></a>三. 滑动数组</h1><h1 id="LeetCode-219-Contains-Dupliccate-Ⅱ"><a href="#LeetCode-219-Contains-Dupliccate-Ⅱ" class="headerlink" title="LeetCode 219 Contains Dupliccate Ⅱ"></a>LeetCode 219 Contains Dupliccate Ⅱ</h1><h2 id="题目描述-15"><a href="#题目描述-15" class="headerlink" title="题目描述"></a>题目描述</h2><p>给出一个整形数组nums和一个整数k，是否存在索引i和j，使得nums[i]==nums[j]，且i和J之间的差不超过k。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">示例1:</span><br><span class="line">输入: nums &#x3D; [1,2,3,1], k &#x3D; 3</span><br><span class="line">输出: true</span><br><span class="line"></span><br><span class="line">示例 2:</span><br><span class="line">输入: nums &#x3D; [1,2,3,1,2,3], k &#x3D; 2</span><br><span class="line">输出: false</span><br></pre></td></tr></table></figure>
<h2 id="分析实现-14"><a href="#分析实现-14" class="headerlink" title="分析实现"></a>分析实现</h2><p>翻译下这个题目：在这个数组中，如果有两个元素索引i和j，它们对应的元素是相等的，且索引j-i是小于等于k，那么就返回True，否则返回False。</p>
<p>因为对于这道题目可以用暴力解法双层循环，即：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for i in range(len(nums)):</span><br><span class="line">    for j in range(i+1,len(nums)):</span><br><span class="line">        if i &#x3D;&#x3D; j:</span><br><span class="line">            return True</span><br><span class="line">return False</span><br></pre></td></tr></table></figure>
<p>故这道题目可以考虑使用滑动数组来解决：</p>
<p>固定滑动数组的长度为K+1，当这个滑动数组内如果能找到两个元素的值相等，就可以保证两个元素的索引的差是小于等于k的。如果当前的滑动数组中没有元素相同，就右移滑动数组的右边界r,同时将左边界l右移。查看r++的元素是否在l右移过后的数组里，如果不在就将其添加数组，在的话返回true表示两元素相等。</p>
<p>因为滑动数组中的元素是不同的，考虑用set作为数据结构：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def containsNearbyDuplicate(self, nums: List[int], k: int) -&gt; bool:</span><br><span class="line">        record &#x3D; set()</span><br><span class="line">        for i in range(len(nums)):</span><br><span class="line">            if nums[i] in record:</span><br><span class="line">                return True</span><br><span class="line">            record.add(nums[i])</span><br><span class="line">            if len(record) &#x3D;&#x3D; k+1:</span><br><span class="line">                record.remove(nums[i-k])</span><br><span class="line">        return False</span><br></pre></td></tr></table></figure>
<p>时间复杂度为O(n)，空间复杂度为O(n)</p>
<h1 id="LeetCode-220-Contains-Dupliccate-Ⅲ"><a href="#LeetCode-220-Contains-Dupliccate-Ⅲ" class="headerlink" title="LeetCode 220 Contains Dupliccate Ⅲ"></a>LeetCode 220 Contains Dupliccate Ⅲ</h1><h2 id="题目描述-16"><a href="#题目描述-16" class="headerlink" title="题目描述"></a>题目描述</h2><p>给定一个整数数组，判断数组中是否有两个不同的索引 i 和 j，使得nums [i] 和nums [j]的差的绝对值最大为 t，并且 i 和 j 之间的差的绝对值最大为 ķ。</p>
<p>示例 1:</p>
<p>输入: nums = [1,2,3,1], k = 3, t = 0</p>
<p>输出: true</p>
<p>示例 2:</p>
<p>输入: nums = [1,0,1,1], k = 1, t = 2</p>
<p>输出: true</p>
<p>示例 3:</p>
<p>输入: nums = [1,5,9,1,5,9], k = 2, t = 3</p>
<p>输出: false</p>
<h2 id="分析实现-15"><a href="#分析实现-15" class="headerlink" title="分析实现"></a>分析实现</h2><p>相比较上一个问题，这个问题多了一个限定条件，条件不仅索引差限定k，数值差也限定为了t。</p>
<p>将索引的差值固定，于是问题和上道一样，同样转化为了固定长度K+1的滑动窗口内，是否存在两个值的差距不超过 t，考虑使用<strong>滑动窗口</strong>的思想来解决。</p>
<p>在遍历的过程中，目的是要在“已经出现、但还未滑出滑动窗口”的所有数中查找，是否有一个数与滑动数组中的数的<strong>差的绝对值</strong>最大为 t。对于差的绝对值最大为t，实际上等价于所要找的这个元素v的范围是在v-t到v+t之间，即查找“滑动数组”中的元素有没有[v-t，v+t]范围内的数存在。</p>
<p>因为只需证明是否存在即可，这时判断的逻辑是：如果在滑动数组<strong>查找比v-t大的最小的元素</strong>,如果这个元素小于等于v+t,即可以证明存在[v-t,v+t]。</p>
<p>那么实现过程其实和上题是一致的，只是上题中的判断条件是<strong>在查找表中找到和nums[i]相同的元素</strong>，而这题中的判断条件是<strong>查找比v-t大的最小的元素，判断其小于等于v+t</strong>，下面是实现的框架：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def containsNearbyDuplicate(self, nums: List[int], k: int) -&gt; bool:</span><br><span class="line">        record &#x3D; set()</span><br><span class="line">        for i in range(len(nums)):</span><br><span class="line">            if 查找的比v-t大的最小的元素 &lt;&#x3D; v+t:</span><br><span class="line">                return True</span><br><span class="line">            record.add(nums[i])</span><br><span class="line">            if len(record) &#x3D;&#x3D; k+1:</span><br><span class="line">                record.remove(nums[i-k])</span><br><span class="line">        return False</span><br></pre></td></tr></table></figure>
<p>接下来考虑，如何查找比v-t大的最小的元素呢？</p>
<p>【注：C++中有lower_bound(v-t)的实现，py需要自己写函数】</p>
<p>当然首先考虑可以通过O(n)的解法来完成，如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def lower_bound(self,array,v):</span><br><span class="line">    array &#x3D; list(array)</span><br><span class="line">    for i in range(len(array)):</span><br><span class="line">        if array[i] &gt;&#x3D; v:</span><br><span class="line">            return i</span><br><span class="line">    return -1</span><br></pre></td></tr></table></figure>
<p>但是滑动数组作为set，是有序的数组。对于有序的数组，应该第一反应就是<strong>二分查找</strong>，于是考虑二分查找实现，查找比v-t大的最小的元素：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def lower_bound(self, nums, target):</span><br><span class="line">    low, high &#x3D; 0, len(nums)-1</span><br><span class="line">    while low&lt;high:</span><br><span class="line">        mid &#x3D; int((low+high)&#x2F;2)</span><br><span class="line">        if nums[mid] &lt; target:</span><br><span class="line">            low &#x3D; mid+1</span><br><span class="line">        else:</span><br><span class="line">            high &#x3D; mid</span><br><span class="line">    return low if nums[low] &gt;&#x3D; target else -1</span><br></pre></td></tr></table></figure>
<p>整体代码实现如下，时间复杂度为O(nlogn),空间复杂度为O(n):</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def containsNearbyAlmostDuplicate(self, nums, k, t) -&gt; bool:</span><br><span class="line">        record &#x3D; set()</span><br><span class="line">        for i in range(len(nums)):</span><br><span class="line">            if len(record) !&#x3D; 0:</span><br><span class="line">                rec &#x3D; list(record)</span><br><span class="line">                find_index &#x3D; self.lower_bound(rec,nums[i]-t)</span><br><span class="line">                if find_index !&#x3D; -1 and rec[find_index] &lt;&#x3D; nums[i] + t:</span><br><span class="line">                    return True</span><br><span class="line">            record.add(nums[i])</span><br><span class="line">            if len(record) &#x3D;&#x3D; k + 1:</span><br><span class="line">                record.remove(nums[i - k])</span><br><span class="line">        return False</span><br><span class="line">    def lower_bound(self, nums, target):</span><br><span class="line">        low, high &#x3D; 0, len(nums)-1</span><br><span class="line">        while low&lt;high:</span><br><span class="line">            mid &#x3D; int((low+high)&#x2F;2)</span><br><span class="line">            if nums[mid] &lt; target:</span><br><span class="line">                low &#x3D; mid+1</span><br><span class="line">            else:</span><br><span class="line">                high &#x3D; mid</span><br><span class="line">        return low if nums[low] &gt;&#x3D; target else -1</span><br></pre></td></tr></table></figure>
<p>当然。。。在和小伙伴一起刷的时候，这样写的O(n^2)的结果会比上面要高，讨论的原因应该是上面的步骤存在着大量set和list的转换导致，对于py，仍旧是考虑算法思想实现为主，下面是O(n^2)的代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def containsNearbyAlmostDuplicate(self, nums: List[int], k: int, t: int) -&gt; bool:</span><br><span class="line">        if t &#x3D;&#x3D; 0 and len(nums) &#x3D;&#x3D; len(set(nums)):</span><br><span class="line">            return False</span><br><span class="line">        for i in range(len(nums)):</span><br><span class="line">            for j in range(1,k+1):</span><br><span class="line">                if i+j &gt;&#x3D; len(nums): break</span><br><span class="line">                if abs(nums[i+j]-nums[i]) &lt;&#x3D; t: return True</span><br><span class="line">        return False</span><br></pre></td></tr></table></figure>
<h2 id="小套路："><a href="#小套路：" class="headerlink" title="小套路："></a>小套路：</h2><p>二分查找实现，查找比v-t大的最小的元素：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def lower_bound(self, nums, target):</span><br><span class="line">    low, high &#x3D; 0, len(nums)-1</span><br><span class="line">    while low&lt;high:</span><br><span class="line">        mid &#x3D; int((low+high)&#x2F;2)</span><br><span class="line">        if nums[mid] &lt; target:</span><br><span class="line">            low &#x3D; mid+1</span><br><span class="line">        else:</span><br><span class="line">            high &#x3D; mid</span><br><span class="line">    return low if nums[low] &gt;&#x3D; target else -1</span><br></pre></td></tr></table></figure>
<p>二分查找实现，查找比v-t大的最小的元素：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def upper_bound(nums, target):</span><br><span class="line">    low, high &#x3D; 0, len(nums)-1</span><br><span class="line">    while low&lt;high:</span><br><span class="line">        mid&#x3D;(low+high)&#x2F;2</span><br><span class="line">        if nums[mid]&lt;&#x3D;target:</span><br><span class="line">            low &#x3D; mid+1</span><br><span class="line">        else:#&gt;</span><br><span class="line">            high &#x3D; mid</span><br><span class="line">            pos &#x3D; high</span><br><span class="line">    if nums[low]&gt;target:</span><br><span class="line">        pos &#x3D; low</span><br><span class="line">    return -1</span><br></pre></td></tr></table></figure>
<h1 id="四-二分查找"><a href="#四-二分查找" class="headerlink" title="四. 二分查找"></a>四. 二分查找</h1><h2 id="理解"><a href="#理解" class="headerlink" title="理解"></a>理解</h2><p>查找在算法题中是很常见的，但是怎么最大化查找的效率和写出bugfree的代码才是难的部分。一般查找方法有顺序查找、二分查找和双指针，推荐一开始可以直接用顺序查找，如果遇到TLE的情况再考虑剩下的两种，毕竟AC是最重要的。</p>
<p>一般二分查找的对象是有序或者由有序部分变化的（可能暂时理解不了，看例题即可），但还存在一种可以运用的地方是按值二分查找，之后会介绍。</p>
<h2 id="代码模板"><a href="#代码模板" class="headerlink" title="代码模板"></a>代码模板</h2><p>总体来说二分查找是比较简单的算法，网上看到的写法也很多，掌握一种就可以了。 以下是我的写法，参考C++标准库里的写法。这种写法比较好的点在于：</p>
<ul>
<li>1.即使区间为空、答案不存在、有重复元素、搜索开/闭区间的上/下界也同样适用</li>
<li>2.+-1 的位置调整只出现了一次，而且最后返回lo还是hi都是对的，无需纠结</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def firstBadVersion(self, arr):</span><br><span class="line">        # 第一点</span><br><span class="line">        lo, hi &#x3D; 0, len(arr)-1</span><br><span class="line">        while lo &lt; hi:</span><br><span class="line">            # 第二点</span><br><span class="line">            mid &#x3D; (lo+hi) &#x2F;&#x2F; 2</span><br><span class="line">            # 第三点</span><br><span class="line">            if f(x):</span><br><span class="line">                lo &#x3D; mid + 1</span><br><span class="line">            else:</span><br><span class="line">                hi &#x3D; mid</span><br><span class="line">        return lo</span><br></pre></td></tr></table></figure>
<p><strong>解释</strong>：</p>
<ul>
<li>第一点：lo和hi分别对应搜索的上界和下界，但不一定为0和arr最后一个元素的下标。</li>
<li>第二点：因为Python没有溢出，int型不够了会自动改成long int型，所以无需担心。如果再苛求一点，可以把这一行改成</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mid &#x3D; lo + (hi-lo) &#x2F;&#x2F; 2</span><br><span class="line"># 之所以 &#x2F;&#x2F;2 这部分不用位运算 &gt;&gt; 1 是因为会自动优化，效率不会提升</span><br></pre></td></tr></table></figure>
<ul>
<li>第三点： 比较重要的就是这个f(x)，在带入模板的情况下，写对函数就完了。</li>
</ul>
<p>那么我们一步一步地揭开二分查找的神秘面纱，首先来一道简单的题。</p>
<h2 id="LeetCode-35-Search-Insert-Position"><a href="#LeetCode-35-Search-Insert-Position" class="headerlink" title="LeetCode 35. Search Insert Position"></a>LeetCode 35. Search Insert Position</h2><p>给定排序数组和目标值，如果找到目标，则返回索引。如果不是，则返回按顺序插入索引的位置的索引。 您可以假设数组中没有重复项。</p>
<p><strong>Example</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Example 1:</span><br><span class="line">Input: [1,3,5,6], 5</span><br><span class="line">Output: 2</span><br><span class="line"></span><br><span class="line">Example 2:</span><br><span class="line">Input: [1,3,5,6], 2</span><br><span class="line">Output: 1</span><br><span class="line"></span><br><span class="line">Example 3:</span><br><span class="line">Input: [1,3,5,6], 7</span><br><span class="line">Output: 4</span><br><span class="line"></span><br><span class="line">Example 4:</span><br><span class="line">Input: [1,3,5,6], 0</span><br><span class="line">Output: 0</span><br></pre></td></tr></table></figure>
<p><strong>分析：</strong> 这里要注意的点是 high 要设置为 len(nums) 的原因是像第三个例子会超出数组的最大值，所以要让 lo 能到 这个下标。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def searchInsert(self, nums: List[int], target: int) -&gt; int:        </span><br><span class="line">        lo, hi &#x3D; 0, len(nums)</span><br><span class="line">        while lo &lt; hi:</span><br><span class="line">            mid &#x3D; (lo + hi) &#x2F;&#x2F; 2</span><br><span class="line">            if nums[mid] &lt; target:</span><br><span class="line">                lo &#x3D; mid + 1</span><br><span class="line">            else:</span><br><span class="line">                hi &#x3D; mid</span><br><span class="line">        return lo</span><br></pre></td></tr></table></figure>
<h2 id="LeetCode540-Single-Element-in-a-Sorted-Array"><a href="#LeetCode540-Single-Element-in-a-Sorted-Array" class="headerlink" title="LeetCode540. Single Element in a Sorted Array"></a>LeetCode540. Single Element in a Sorted Array</h2><p>您将获得一个仅由整数组成的排序数组，其中每个元素精确出现两次，但一个元素仅出现一次。 找到只出现一次的单个元素。</p>
<p><strong>Example</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Example 1:</span><br><span class="line"></span><br><span class="line">Input: [1,1,2,3,3,4,4,8,8]</span><br><span class="line">Output: 2</span><br><span class="line"></span><br><span class="line">Example 2:</span><br><span class="line"></span><br><span class="line">Input: [3,3,7,7,10,11,11]</span><br><span class="line">Output: 10</span><br></pre></td></tr></table></figure>
<p><strong>分析：</strong> 异或的巧妙应用！如果mid是偶数，那么和1异或的话，那么得到的是mid+1，如果mid是奇数，得到的是mid-1。如果相等的话，那么唯一的元素还在这之后，往后找就可以了。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def singleNonDuplicate(self, nums):</span><br><span class="line">        lo, hi &#x3D; 0, len(nums) - 1</span><br><span class="line">        while lo &lt; hi:</span><br><span class="line">            mid &#x3D; (lo + hi) &#x2F;&#x2F; 2</span><br><span class="line">            if nums[mid] &#x3D;&#x3D; nums[mid ^ 1]:</span><br><span class="line">                lo &#x3D; mid + 1</span><br><span class="line">            else:</span><br><span class="line">                hi &#x3D; mid</span><br><span class="line">        return nums[lo]</span><br></pre></td></tr></table></figure>
<p><strong>是不是还挺简单哈哈，那我们来道HARD难度的题!</strong></p>
<h2 id="LeetCode-410-Split-Array-Largest-Sum"><a href="#LeetCode-410-Split-Array-Largest-Sum" class="headerlink" title="LeetCode 410. Split Array Largest Sum"></a>LeetCode 410. Split Array Largest Sum</h2><p>给定一个由非负整数和整数m组成的数组，您可以将该数组拆分为m个非空连续子数组。编写算法以最小化这m个子数组中的最大和。</p>
<p><strong>Example</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Input:</span><br><span class="line">nums &#x3D; [7,2,5,10,8]</span><br><span class="line">m &#x3D; 2</span><br><span class="line"></span><br><span class="line">Output:</span><br><span class="line">18</span><br><span class="line"></span><br><span class="line">Explanation:</span><br><span class="line">There are four ways to split nums into two subarrays.</span><br><span class="line">The best way is to split it into [7,2,5] and [10,8],</span><br><span class="line">where the largest sum among the two subarrays is only 18.</span><br></pre></td></tr></table></figure>
<p><strong>分析：</strong></p>
<ul>
<li>这其实就是二分查找里的按值二分了，可以看出这里的元素就无序了。但是我们的目标是找到一个合适的最小和，换个角度理解我们要找的值在最小值max(nums)和sum(nums)内，而这两个值中间是连续的。是不是有点难理解，那么看代码吧</li>
<li>辅助函数的作用是判断当前的“最小和”的情况下，区间数是多少，来和m判断</li>
<li>这里的下界是数组的最大值是因为如果比最大值小那么一个区间就装不下，数组的上界是数组和因为区间最少是一个，没必要扩大搜索的范围</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def splitArray(self, nums: List[int], m: int) -&gt; int:</span><br><span class="line"></span><br><span class="line">        def helper(mid):</span><br><span class="line">            res &#x3D; tmp &#x3D; 0</span><br><span class="line">            for num in nums:</span><br><span class="line">                if tmp + num &lt;&#x3D; mid:</span><br><span class="line">                    tmp +&#x3D; num</span><br><span class="line">                else:</span><br><span class="line">                    res +&#x3D; 1</span><br><span class="line">                    tmp &#x3D; num</span><br><span class="line">            return res + 1</span><br><span class="line"></span><br><span class="line">        lo, hi &#x3D; max(nums), sum(nums)</span><br><span class="line">        while lo &lt; hi:</span><br><span class="line">            mid &#x3D; (lo + hi) &#x2F;&#x2F; 2</span><br><span class="line">            if helper(mid) &gt; m:</span><br><span class="line">                lo &#x3D; mid + 1</span><br><span class="line">            else:</span><br><span class="line">                hi &#x3D; mid</span><br><span class="line">        return lo</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
  </entry>
  <entry>
    <title>每日论文（2）—— Wide &amp; Deep Learning for Recommender Systems</title>
    <url>/posts/8f9592f5.html</url>
    <content><![CDATA[<p>今天的论文是《<a href="https://arxiv.org/pdf/1606.07792.pdf" target="_blank" rel="noopener">Wide &amp; Deep Learning for Recommender Systems</a>》，这篇论文是谷歌在2016年提出的算法。</p>
<p>在开始之前我们提几个要点：</p>
<ul>
<li>这个模型与FM不一样，应用前提是已经对大量的购买（点击）信息做了召回（压缩了数据集）然后才做的推荐</li>
<li>Wide&amp;Deep模型需要手动做特征工程</li>
<li>论文很容易读懂，篇幅很短内容不难建议直接看一遍！</li>
</ul>
<h1 id="论文要点"><a href="#论文要点" class="headerlink" title="论文要点"></a>论文要点</h1><h2 id="FM它不香吗"><a href="#FM它不香吗" class="headerlink" title="FM它不香吗"></a>FM它不香吗</h2><p>之前我们已经学了FM模型，不是已经很好了吗，为啥还要整这个Wide&amp;Deep呢？其缺点在于：当query-item矩阵是稀疏并且是high-rank的时候（比如user有特殊的爱好，或item比较小众），很难非常效率的学习出低维度的表示。这种情况下，大部分的query-item都没有什么关系。但是dense embedding会导致几乎所有的query-item预测值都是非0的，这就导致了推荐过度泛化，会推荐一些不那么相关的物品。相反，简单的linear model却可以通过cross-product transformation来记住这些<strong>exception rules</strong>，cross-product transformation是什么意思后面再提。</p>
<h2 id="Memorization-和-Generalization"><a href="#Memorization-和-Generalization" class="headerlink" title="Memorization 和 Generalization"></a>Memorization 和 Generalization</h2><p>Memorization 和 Generalization是推荐系统很常见的两个概念，其中Memorization指的是通过用户与商品的交互信息矩阵学习规则，而Generalization则是泛化规则。我们前面介绍的FM算法就是很好的Generalization的例子，它可以根据交互信息学习到一个比较短的矩阵$V$，其中$v_{i}$储存着每个用户特征的压缩表示（embedding），而协同过滤与SVD都是靠记住用户之前与哪些物品发生了交互从而推断出的推荐结果，这两者推荐结果当然存在一些差异，我们的Wide&amp;Deep模型就能够融合这两种推荐结果做出最终的推荐，得到一个比之前的推荐结果都好的模型。</p>
<p>可以这么说：Memorization趋向于更加保守，推荐用户之前有过行为的items。相比之下，generalization更加趋向于提高推荐系统的多样性（diversity）。Memorization只需要使用一个线性模型即可实现，而Generalization需要使用DNN实现。</p>
<h2 id="Cross-product-transformation"><a href="#Cross-product-transformation" class="headerlink" title="Cross-product transformation"></a>Cross-product transformation</h2><p>Wide中使用Cross-product transformation来生成组合特征，也就是手动的二阶特征提取，作用是学习组合特征并为模型增加非线性性，说的文邹邹一点：</p>
<script type="math/tex; mode=display">\phi_k = \prod_{i=1}^dx_i^{c_{ki}}</script><p>这个式子什么意思读者可以自行找原论文看看，大体意思就是两个特征都同时为1这个新的特征才能为1，否则就是0，说白了就是一个特征组合。用原论文的例子举例：</p>
<blockquote>
<p>AND(user_installed_app=QQ, impression_app=WeChat)，当特征user_installed_app=QQ,和特征impression_app=WeChat取值都为1的时候，组合特征AND(user_installed_app=QQ, impression_app=WeChat)的取值才为1，否则为0。</p>
</blockquote>
<h2 id="操作流程"><a href="#操作流程" class="headerlink" title="操作流程"></a>操作流程</h2><ul>
<li><p><strong>Retrieval </strong>：利用机器学习模型和一些人为定义的规则，来返回最匹配当前Query的一个小的items集合，这个集合就是最终的推荐列表的候选集。</p>
</li>
<li><p><strong>Ranking</strong>：</p>
<ul>
<li><p>收集更细致的用户特征，如：</p>
<ul>
<li>User features（年龄、性别、语言、民族等）</li>
<li>Contextual features(上下文特征：设备，时间等)</li>
<li>Impression features（展示特征：app age、app的历史统计信息等）</li>
</ul>
</li>
<li><p>将特征分别传入Wide和Deep<strong>一起做训练</strong>。在训练的时候，根据最终的loss计算出gradient，反向传播到Wide和Deep两部分中，分别训练自己的参数（wide组件只需要填补deep组件的不足就行了，所以需要比较少的cross-product feature transformations，而不是full-size wide Model）</p>
<ul>
<li>训练方法是用mini-batch stochastic optimization。</li>
<li>Wide组件是用FTRL（Follow-the-regularized-leader） + L1正则化学习。</li>
<li>Deep组件是用AdaGrad来学习。</li>
</ul>
</li>
<li><p>训练完之后推荐TopN</p>
</li>
</ul>
</li>
</ul>
<h1 id="上代码"><a href="#上代码" class="headerlink" title="上代码"></a>上代码</h1><p>在Tensorflow的库中是已经内置了Wide-Deep model的，想要查看源代码了解具体实现过程可以看<a href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/keras/premade/wide_deep.py#L34-L219" target="_blank" rel="noopener">这里</a>。下面参考<a href="https://www.tensorflow.org/api_docs/python/tf/keras/experimental/WideDeepModel" target="_blank" rel="noopener">Tensorflow官网的示例代码</a>进行讲解。我们用到的数据集下载链接<a href="https://archive.ics.uci.edu/ml/machine-learning-databases/adult/" target="_blank" rel="noopener">戳这里</a>。</p>
<p>首先看全局实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tf.keras.experimental.WideDeepModel(</span><br><span class="line">    linear_model, dnn_model, activation=<span class="literal">None</span>, **kwargs</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>这一步很容易看出来就是将linear_model与dnn_model拼接在了一起，对应于Wide-Deep FM中的最后一步。比如我们可以将linear_model与dnn_model做一个最简单的实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">linear_model = LinearModel()</span><br><span class="line">dnn_model = keras.Sequential([keras.layers.Dense(units=<span class="number">64</span>),</span><br><span class="line">                             keras.layers.Dense(units=<span class="number">1</span>)])</span><br><span class="line">combined_model = WideDeepModel(linear_model, dnn_model)</span><br><span class="line">combined_model.compile(optimizer=[<span class="string">'sgd'</span>, <span class="string">'adam'</span>], <span class="string">'mse'</span>, [<span class="string">'mse'</span>])</span><br><span class="line"><span class="comment"># define dnn_inputs and linear_inputs as separate numpy arrays or</span></span><br><span class="line"><span class="comment"># a single numpy array if dnn_inputs is same as linear_inputs.</span></span><br><span class="line">combined_model.fit([linear_inputs, dnn_inputs], y, epochs)</span><br><span class="line"><span class="comment"># or define a single `tf.data.Dataset` that contains a single tensor or</span></span><br><span class="line"><span class="comment"># separate tensors for dnn_inputs and linear_inputs.</span></span><br><span class="line">dataset = tf.data.Dataset.from_tensors(([linear_inputs, dnn_inputs], y))</span><br><span class="line">combined_model.fit(dataset, epochs)</span><br></pre></td></tr></table></figure>
<p>这里第一步就是直接调用一个keras.experimental中的linear_model，第二步简单实现了一个全连接神经网络，第三步使用WideDeepModel将前两步产生的两个model拼接在一起，形成最终的combined_model，接着就是常规的compile和fit了。</p>
<p>除此之外线性模型与DNN模型在联合训练之前均可进行分别训练：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">linear_model = LinearModel()</span><br><span class="line">linear_model.compile(<span class="string">'adagrad'</span>, <span class="string">'mse'</span>)</span><br><span class="line">linear_model.fit(linear_inputs, y, epochs)</span><br><span class="line">dnn_model = keras.Sequential([keras.layers.Dense(units=<span class="number">1</span>)])</span><br><span class="line">dnn_model.compile(<span class="string">'rmsprop'</span>, <span class="string">'mse'</span>)</span><br><span class="line">dnn_model.fit(dnn_inputs, y, epochs)</span><br><span class="line">combined_model = WideDeepModel(linear_model, dnn_model)</span><br><span class="line">combined_model.compile(optimizer=[<span class="string">'sgd'</span>, <span class="string">'adam'</span>], <span class="string">'mse'</span>, [<span class="string">'mse'</span>])</span><br><span class="line">combined_model.fit([linear_inputs, dnn_inputs], y, epochs)</span><br></pre></td></tr></table></figure>
<p>这里前三行代码训练了一个线性模型，中间三行代码训练了一个DNN模型，最后三行代码则将两个模型联合训练，以上就完成了对Tensorflow的WideDeepModel的调用，其中每个函数有一些其他参数我们这里不详细说明，读者若有需要可自行在tensorflow官网查询，另外该部分的源代码在Tensorflow的Github上有展示，<a href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/keras/premade/wide_deep.py#L34-L219" target="_blank" rel="noopener">链接在这</a>。</p>
<p>参考链接：</p>
<ul>
<li>论文原文：<a href="https://arxiv.org/pdf/1606.07792.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1606.07792.pdf</a></li>
<li>这篇博客翻译的很到位，也有不少补充：<a href="https://blog.csdn.net/u010352603/article/details/80590129" target="_blank" rel="noopener">https://blog.csdn.net/u010352603/article/details/80590129</a></li>
<li>tensorflow官网的WideDeepModel：<a href="https://www.tensorflow.org/api_docs/python/tf/keras/experimental/WideDeepModel" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf/keras/experimental/WideDeepModel</a></li>
</ul>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
  </entry>
  <entry>
    <title>Leetcode刷题专题打卡 —— 动态规划</title>
    <url>/posts/f1bf1d15.html</url>
    <content><![CDATA[<h1 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h1><p>动态规划常常适用于<strong>有重叠子问题</strong>和<strong>最优子结构</strong>性质的问题，动态规划方法<strong>所耗时间往往远少于朴素解法</strong>。</p>
<h2 id="主要思想"><a href="#主要思想" class="headerlink" title="主要思想"></a>主要思想</h2><p>若要解一个给定问题，我们需要解其不同部分（即子问题），再根据子问题的解以得出原问题的解。动态规划往往用于优化递归问题，例如斐波那契数列，如果运用递归的方式来求解会重复计算很多相同的子问题，利用动态规划的思想可以减少计算量。</p>
<p>动态规划法仅仅解决每个子问题一次，具有天然剪枝的功能，从而减少计算量，</p>
<p>一旦某个给定子问题的解已经算出，则将其记忆化存储，以便下次需要同一个子问题解之时直接查表。</p>
<h2 id="动态规划模板步骤"><a href="#动态规划模板步骤" class="headerlink" title="动态规划模板步骤"></a>动态规划模板步骤</h2><ul>
<li>确定动态规划状态</li>
<li>写出状态转移方程（画出状态转移表）</li>
<li>考虑初始化条件</li>
<li>考虑输出状态</li>
<li>考虑对时间，空间复杂度的优化（Bonus）</li>
</ul>
<h1 id="例题详解"><a href="#例题详解" class="headerlink" title="例题详解"></a>例题详解</h1><p>接下来，我们对每个步骤进行详细的讲解，并给出不同题目中考虑的不同方式，争取让大家吃透动态规划的套路。 我们以最经典的动态规划题目——<a href="https://leetcode-cn.com/problems/longest-increasing-subsequence/" target="_blank" rel="noopener">Leetcode 300.最长上升子序列</a> 为例子。</p>
<h2 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h2><p>给定一个无序的整数数组，找到其中最长上升子序列的长度。</p>
<p>示例:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入: [10,9,2,5,3,7,101,18]</span><br><span class="line">输出: 4 </span><br><span class="line">解释: 最长的上升子序列是 [2,3,7,101]，它的长度是 4。</span><br></pre></td></tr></table></figure>
<p>说明:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">可能会有多种最长上升子序列的组合，你只需要输出对应的长度即可。</span><br><span class="line">你算法的时间复杂度应该为 O(n2) 。</span><br></pre></td></tr></table></figure>
<h2 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h2><p><strong>第一步：确定动态规划状态</strong></p>
<ul>
<li><p>是否存在状态转移?</p>
</li>
<li><p>什么样的状态比较好转移，找到对求解问题最方便的状态转移?</p>
<p>想清楚到底是直接用需要求的，比如长度作为dp保存的变量还是用某个判断问题的状态比如是否是回文子串来作为方便求解的状态</p>
<p>该题目可以直接用一个一维数组<code>dp</code>来存储转移状态，<code>dp[i]</code>可以定义为以<code>nums[i]</code>这个数结尾的最长递增子序列的长度。举个实际例子，比如在<code>nums[10,9,2,5,3,7,101,18]</code>中，<code>dp[0]</code>表示数字10的最长递增子序列长度，那就是本身，所以为1，对于<code>dp[5]</code>对应的数字7来说的最长递增子序列是<code>[2,5,7]</code>（或者<code>[2,3,7]</code>）所以<code>dp[5]=3</code>。</p>
</li>
</ul>
<p><strong>第二步：写出一个好的状态转移方程</strong></p>
<ul>
<li><p>使用<strong>数学归纳法</strong>思维，写出准确的状态方程</p>
<p>比如还是用刚刚那个<code>nums</code>数组，我们<strong>思考一下是如何得到<code>dp[5]=3</code>的</strong>：既然是递增的子序列，我们只要找到<code>nums[5]</code> (也就是7)前面那些结尾比7小的子序列，然后把7接到最后，就可以形成一个新的递增的子序列，也就是这个新的子序列也就是在找到的前面那些数后面加上7，相当长度加1。当然可能会找到很多不同的子序列，比如刚刚在上面列举的，但是只需要找到长度最长的作为<code>dp[5]</code>的值就行。总结来说就是比较当前<code>dp[i]</code>的长度和<code>dp[i]</code>对应产生新的子序列长度，我们用<code>j</code>来表示所有比<code>i</code>小的组数中的索引，可以用如下代码公式表示</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for i in range(len(nums)):</span><br><span class="line">    for j in range(i):</span><br><span class="line">    	if nums[i]&gt;nums[j]:</span><br><span class="line">    		dp[i]&#x3D;max(dp[i],dp[j]+1)</span><br></pre></td></tr></table></figure>
<p><strong>Tips:</strong> 在实际问题中，如果不能很快得出这个递推公式，可以先尝试一步一步把前面几步写出来，如果还是不行很可能就是 dp 数组的定义不够恰当，需要回到第一步重新定义 dp 数组的含义；或者可能是 dp 数组存储的信息还不够，不足以推出下一步的答案，需要把 dp 数组扩大成二维数组甚至三维数组。</p>
</li>
</ul>
<p><strong>第三步：考虑初始条件</strong></p>
<p> 这是决定整个程序能否跑通的重要步骤，当我们确定好状态转移方程，我们就需要考虑一下边界值，边界值考虑主要又分为三个地方：</p>
<ul>
<li><p>dp数组整体的初始值</p>
</li>
<li><p>dp数组(二维)i=0和j=0的地方</p>
</li>
<li><p>dp存放状态的长度，是整个数组的长度还是数组长度加一，这点需要特别注意。</p>
<p>对于本问题，子序列最少也是自己，所以长度为1，这样我们就可以方便的把所有的<code>dp</code>初始化为1，再考虑长度问题，由于<code>dp[i]</code>代表的是<code>nums[i]</code>的最长子序列长度，所以并不需要加一。 所以用代码表示就是<code>dp=[1]*len(nums)</code></p>
<p><strong>Tips：</strong>还有一点需要注意，找到一个方便的状态转移会使问题变得非常简单。举个例子，对于<a href="https://leetcode-cn.com/problems/triangle/" target="_blank" rel="noopener">Leetcode120.三角形最小路径和</a>问题，大多数人刚开始想到的应该是自顶向下的定义状态转移的思路，也就是从最上面的数开始定义状态转移，但是这题优化的解法则是通过定义由下到上的状态转移方程会大大简化问题，同样的对于<a href="https://leetcode-cn.com/problems/maximum-subarray/solution/" target="_blank" rel="noopener">Leetcode53.最大子序和</a>也是采用从下往上遍历，保证每个子问题都是已经算好的。这个具体我们在题目中会讲到。</p>
<p>这里额外总结几种Python常用的初始化方法：</p>
<ul>
<li><p>对于产生一个全为1，长度为n的数组：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. dp&#x3D;[1 for _ in range(n)]</span><br><span class="line">2. dp&#x3D;[1]*n</span><br></pre></td></tr></table></figure>
</li>
<li><p>对于产生一个全为0，长度为m，宽度为n的二维矩阵：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. dp&#x3D;[[0 for _ in range(n)] for _ in range(m)]</span><br><span class="line">2. dp&#x3D;[[0]*n for _ in range(m)]</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<p><strong>第四步：考虑输出状态</strong></p>
<p>主要有以下三种形式，对于具体问题，我们一定要想清楚到底dp数组里存储的是哪些值，最后我们需要的是数组中的哪些值：</p>
<ul>
<li><p>返回dp数组中最后一个值作为输出，一般对应二维dp问题。</p>
</li>
<li><p>返回dp数组中最大的那个数字，一般对应记录最大值问题。</p>
</li>
<li><p>返回保存的最大值，一般是<code>Maxval=max(Maxval,dp[i])</code>这样的形式。</p>
<p><strong>Tips：</strong>这个公式必须是在满足递增的条件下，也就是<code>nums[i]&gt;nums[j]</code>的时候才能成立，并不是<code>nums[i]</code>前面所有数字都满足这个条件的，理解好这个条件就很容易懂接下来在输出时候应该是<code>max(dp)</code>而不是<code>dp[-1]</code>，原因就是dp数组由于计算递增的子序列长度，所以dp数组里中间可能有值会是比最后遍历的数值大的情况，每次遍历<code>nums[j]</code>所对应的位置都是比<code>nums[i]</code>小的那个数。举个例子，比如<code>nums=[1,3,6,7,9,4,10,5,6]</code>,而最后<code>dp=[1,2,3,4,5,3,6,4,5]</code>。 总结一下，最后的结果应该返回dp数组中值最大的数。</p>
<p>最后加上考虑数组是否为空的判断条件，下面是该问题完整的代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def lengthOfLIS(self, nums: List[int]) -&gt; int:</span><br><span class="line">    if not nums:return 0  #判断边界条件</span><br><span class="line">    dp&#x3D;[1]*len(nums)      #初始化dp数组状态</span><br><span class="line">    for i in range(len(nums)):</span><br><span class="line">    for j in range(i):</span><br><span class="line">    if nums[i]&gt;nums[j]:   #根据题目所求得到状态转移方程</span><br><span class="line">    dp[i]&#x3D;max(dp[i],dp[j]+1)</span><br><span class="line">    return max(dp)  #确定输出状态</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>第五步：考虑对时间，空间复杂度的优化（Bonus）</strong></p>
<p><strong>切入点：</strong> 我们看到，之前方法遍历dp列表需要$O(N)$，计算每个<code>dp[i]</code>需要$O(N)$的时间，所以总复杂度是$O(N^2)$</p>
<p>前面遍历dp列表的时间复杂度肯定无法降低了，但是我们看后面在每轮遍历<code>[0,i]</code>的<code>dp[i]</code>元素的时间复杂度可以考虑设计状态定义，使得整个dp为一个排序列表，这样我们自然想到了可以利用二分法来把时间复杂度降到了$O(NlogN)$。这里由于篇幅原因，如果大家感兴趣的话详细的解题步骤可以看好心人写的<a href="https://leetcode-cn.com/problems/longest-increasing-subsequence/solution/dong-tai-gui-hua-er-fen-cha-zhao-tan-xin-suan-fa-p/" target="_blank" rel="noopener">二分方法+动态规划详解</a></p>
<p><strong>模板总结：</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for i in range(len(nums)):</span><br><span class="line">    for j in range(i):</span><br><span class="line">            dp[i]&#x3D;最值(dp[i],dp[j]+...)</span><br></pre></td></tr></table></figure>
<p>对于子序列问题，很多也都是用这个模板来进行解题，比如<a href="https://leetcode-cn.com/problems/maximum-subarray/solution/" target="_blank" rel="noopener">Leetcode53.最大子序和</a>。此外，其他情况的子序列问题可能需要二维的dp数组来记录状态，比如：<a href="https://leetcode-cn.com/problems/longest-palindromic-substring/" target="_blank" rel="noopener">Leetcode5. 最长回文子串</a>（下面会讲到） 、 <a href="https://leetcode-cn.com/problems/longest-common-subsequence/" target="_blank" rel="noopener">Leetcode1143. 最长公共子序列</a> (当涉及到两个字符串/数组时) 如果你觉得刚刚那题有点难的话，不如我们从简单一点的题目开始理解一下这类子序列问题。接下来所有题目我们都按照那五个步骤考虑</p>
<h1 id="算法应用"><a href="#算法应用" class="headerlink" title="算法应用"></a>算法应用</h1><h2 id="Leetcode-674-最长连续递增序列"><a href="#Leetcode-674-最长连续递增序列" class="headerlink" title="Leetcode 674.最长连续递增序列"></a><a href="https://leetcode-cn.com/problems/longest-continuous-increasing-subsequence/" target="_blank" rel="noopener">Leetcode 674.最长连续递增序列</a></h2><h3 id="题目描述-1"><a href="#题目描述-1" class="headerlink" title="题目描述"></a>题目描述</h3><p>给定一个未经排序的整数数组，找到最长且连续的的递增序列。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">示例 1:</span><br><span class="line">输入: [1,3,5,4,7]</span><br><span class="line">输出: 3</span><br><span class="line">解释: 最长连续递增序列是 [1,3,5], 长度为3。</span><br><span class="line">尽管 [1,3,5,7] 也是升序的子序列, 但它不是连续的，因为5和7在原数组里被4隔开。</span><br></pre></td></tr></table></figure>
<h3 id="解题思路-1"><a href="#解题思路-1" class="headerlink" title="解题思路"></a>解题思路</h3><p>这道题是不是一眼看过去和上题非常的像，没错了，这个题目最大的不同就是<strong>连续</strong>两个字，这样就让这个问题简单很多了，因为如果要求连续的话，那么就不需要和上题一样遍历两遍数组，只需要比较前后的值是不是符合递增的关系。</p>
<ul>
<li><strong>第一步：确定动态规划状态</strong> 对于这个问题，我们的状态<strong>dp[i]也是以nums[i]这个数结尾的最长递增子序列的长度</strong></li>
<li><strong>第二步：写出状态转移方程</strong> 这个问题，我们需要分两种情况考虑，第一种情况是如果遍历到的数<code>nums[i]</code>后面一个数不是比他大或者前一个数不是比他小，也就是所谓的不是连续的递增，那么这个数列最长连续递增序列就是他本身，也就是长度为1。 第二种情况就是如果满足有递增序列，就意味着当前状态只和前一个状态有关，<code>dp[i]</code>只需要在前一个状态基础上加一就能得到当前最长连续递增序列的长度。总结起来，状态的转移方程可以写成 <code>dp[i]=dp[i-1]+1</code></li>
<li><strong>第三步：考虑初始化条件</strong> 和上面最长子序列相似，这个题目的初始化状态就是一个一维的全为1的数组。</li>
<li><strong>第四步：考虑输出状态</strong> 与上题相似，这个问题输出条件也是求dp数组中最大的数。</li>
<li><strong>第五步：考虑是否可以优化</strong> 这个题目只需要一次遍历就能求出连续的序列，所以在时间上已经没有可以优化的余地了，空间上来看的话也是一维数组，并没有优化余地。</li>
</ul>
<p>综上所述，可以很容易得到最后的代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def findLengthOfLCIS(self, nums: List[int]) -&gt; int:</span><br><span class="line">    if not nums:return 0  #判断边界条件</span><br><span class="line">    dp&#x3D;[1]*len(nums)      #初始化dp数组状态</span><br><span class="line">    #注意需要得到前一个数，所以从1开始遍历，否则会超出范围</span><br><span class="line">    for i in range(1,len(nums)): </span><br><span class="line">        if nums[i]&gt;nums[i-1]:#根据题目所求得到状态转移方程</span><br><span class="line">        	dp[i]&#x3D;dp[i-1]+1</span><br><span class="line">        else:</span><br><span class="line">        	dp[i]&#x3D;1</span><br><span class="line">    return max(dp)  #确定输出状态</span><br></pre></td></tr></table></figure>
<p><strong>总结: 通过这个题目和例题的比较，我们需要理清子序列和子数组（连续序列）的差别，前者明显比后者要复杂一点，因为前者是不连续的序列，后者是连续的序列，从复杂度来看也很清楚能看到即使穷举子序列也比穷举子数组要复杂很多。</strong></p>
<p>承接上面的话题，我们接下来继续来看一个子序列问题，这次是另外一种涉及二维状态的题目。</p>
<h2 id="Leetcode5-最长回文子串"><a href="#Leetcode5-最长回文子串" class="headerlink" title="Leetcode5. 最长回文子串"></a><a href="https://leetcode-cn.com/problems/longest-palindromic-substring/" target="_blank" rel="noopener">Leetcode5. 最长回文子串</a></h2><h3 id="题目描述-2"><a href="#题目描述-2" class="headerlink" title="题目描述"></a>题目描述</h3><p>给定一个字符串 s，找到 s 中最长的回文子串。你可以假设 s 的最大长度为 1000。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">示例 1：</span><br><span class="line"></span><br><span class="line">输入: &quot;babad&quot;</span><br><span class="line">输出: &quot;bab&quot;</span><br><span class="line">注意: &quot;aba&quot; 也是一个有效答案。</span><br></pre></td></tr></table></figure>
<h3 id="解题思路-2"><a href="#解题思路-2" class="headerlink" title="解题思路"></a>解题思路</h3><ul>
<li><p><strong>第一步：确定动态规划状态</strong> 与上面两题不同的是，这个题目必须用二维的dp数组来记录状态，主要原因就是子串有回文的限制。用两个指针来记录子串的位置可以很好的实现子串的回文要求，又因为最后结果需要返回的是子串，这里不同于之前题目的用dp保存长度，我们必须找到具体哪个部分符合回文子串的要求。这里插一句，其实也有求回文子串长度的题目<a href="https://leetcode-cn.com/problems/longest-palindromic-subsequence/" target="_blank" rel="noopener">Leetcode516. 最长回文子序列</a>,如果有兴趣可以看一下。这里我们定义<code>dp[i][j]</code>表示子串s从i到j是否为回文子串。</p>
</li>
<li><p><strong>第二步：写出状态转移方程</strong> 首先我们需要知道符合回文的条件：</p>
<ul>
<li><p>字符串首尾两个字符必须相等，否则肯定不是回文。</p>
</li>
<li><p>当字符串首尾两个字符相等时：如果子串是回文，整体就是回文，这里就有了动态规划的思想，出现了子问题；相反，如果子串不是回文，那么整体肯定不是。 对于字符串<code>s,s[i,j]</code>的子串是<code>s[i+1,j-1]</code>，如果子串只有本身或者空串，那肯定是回文子串了，所以我们讨论的状态转移方程不是对于<code>j-1-(i+1)+1&lt;2</code>的情况(整理得<code>j-i&lt;3</code>)，当<code>s[i]</code>和<code>s[j]</code>相等并且<code>j-i&lt;3</code>时，我们可以直接得出<code>dp[i][j]</code>是True。</p>
<p>综上所述，可以得到状态转移方程</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if s[i]&#x3D;&#x3D;s[j]:</span><br><span class="line">	if j-i&lt;3:</span><br><span class="line">		dp[i][j]&#x3D;True</span><br><span class="line">	else:</span><br><span class="line">		dp[i][j]&#x3D;dp[i+1][j-1]</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><strong>第三步：考虑初始化条件</strong> 我们需要建立一个二维的初始状态是False的来保存状态的数组来表示dp，又因为考虑只有一个字符的时候肯定是回文串，所以dp表格的对角线<code>dp[i][i]</code>肯定是True。</p>
</li>
<li><p><strong>第四步：考虑输出状态</strong> 这里dp表示的是从<code>i</code>到<code>j</code>是否是回文子串，这样一来就告诉我们子串的起始位置和结束位置，但是由于我们需要找到最长的子串，所以我们优化一下可以只记录起始位置和当前长度（当然你要是喜欢记录终止位置和当前长度也是没问题的）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if dp[i][j]: #只要dp[i][j]成立就表示是回文子串，然后我们记录位置，返回有效答案</span><br><span class="line">    cur_len&#x3D;j-i+1</span><br><span class="line">    if cur_len&gt;max_len:</span><br><span class="line">    	max_len&#x3D;cur_len</span><br><span class="line">    	start&#x3D;i</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>第五步：考虑对时间，空间复杂度的优化</strong> 对于这个问题，时间和空间都可以进一步优化，对于空间方面的优化：这里采用一种叫中心扩散的方法来进行，而对于时间方面的优化，则是用了Manacher‘s Algorithm（马拉车算法）来进行优化。具体的实现可以参考<a href="https://leetcode-cn.com/problems/longest-palindromic-substring/solution/zhong-xin-kuo-san-dong-tai-gui-hua-by-liweiwei1419/" target="_blank" rel="noopener">动态规划、Manacher 算法</a></p>
<p>这里给出比较容易理解的经典方法的代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def longestPalindrome(self, s: str) -&gt; str:</span><br><span class="line">       length&#x3D;len(s)</span><br><span class="line">       if length&lt;2:  #判断边界条件</span><br><span class="line">           return s</span><br><span class="line">       dp&#x3D;[[False for _ in range(length)]for _ in range(length)] #定义dp状态矩阵</span><br><span class="line">       #定义初试状态，这步其实可以省略</span><br><span class="line">       # for i in range(length):</span><br><span class="line">       #     dp[i][i]&#x3D;True</span><br><span class="line">       </span><br><span class="line">       max_len&#x3D;1</span><br><span class="line">       start&#x3D;0 #后续记录回文串初试位置</span><br><span class="line">       for j in range(1,length):</span><br><span class="line">           for i in range(j):</span><br><span class="line">               #矩阵中逐个遍历</span><br><span class="line">               if s[i]&#x3D;&#x3D;s[j]:</span><br><span class="line">                   if j-i&lt;3:</span><br><span class="line">                       dp[i][j]&#x3D;True</span><br><span class="line">                   else:</span><br><span class="line">                       dp[i][j]&#x3D;dp[i+1][j-1]</span><br><span class="line">               if dp[i][j]: #记录位置，返回有效答案</span><br><span class="line">                   cur_len&#x3D;j-i+1</span><br><span class="line">                   if cur_len&gt;max_len:</span><br><span class="line">                       max_len&#x3D;cur_len</span><br><span class="line">                       start&#x3D;i</span><br><span class="line">       return s[start:start+max_len]</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>总结：这个是一个二维dp的经典题目，需要注意的就是定义dp数组的状态是什么，这里不用长度作为dp值而用是否是回文子串这个状态来存储也是一个比较巧妙的方法，使得题目变得容易理解。</strong></p>
<p>看了这么多套路相信你也对动态规划有点感觉了，这里再介绍一个求长度的子序列问题。</p>
<h2 id="Leetcode516-最长回文子序列"><a href="#Leetcode516-最长回文子序列" class="headerlink" title="Leetcode516. 最长回文子序列"></a><a href="https://leetcode-cn.com/problems/longest-palindromic-subsequence/" target="_blank" rel="noopener">Leetcode516. 最长回文子序列</a></h2><h3 id="题目描述-3"><a href="#题目描述-3" class="headerlink" title="题目描述"></a>题目描述</h3><p>给定一个字符串s，找到其中最长的回文子序列。可以假设s的最大长度为1000。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">示例 1:</span><br><span class="line">输入:</span><br><span class="line">&quot;bbbab&quot;</span><br><span class="line">输出:</span><br><span class="line">4</span><br></pre></td></tr></table></figure>
<h3 id="解题思路-3"><a href="#解题思路-3" class="headerlink" title="解题思路"></a>解题思路</h3><p>这个问题和上面的例题也非常相似，直接套用动态规划套路也可以很快解决出来：</p>
<ul>
<li><p><strong>第一步：确定动态规划状态</strong> 这里求的是最长子串的长度，所以我们可以直接定义一个二维的<code>dp[i][j]</code>来表示字符串第<code>i</code>个字符到第<code>j</code>个字符的长度，子问题也就是每个子回文字符串的长度。</p>
</li>
<li><p><strong>第二步：写出状态转移方程</strong> 我们先来具体分析一下整个题目状态转移的规律。对于<code>d[i][j]</code>,我们根据上题的分析依然可以看出， 当<code>s[i]</code>和<code>s[j]</code>相等时，<code>s[i+1...j-1]</code>这个字符串加上2就是最长回文子序列； 当<code>s[i]</code>和<code>s[j]</code>不相等时，就说明可能只有其中一个出现在s[i,j]的最长回文子序列中，我们只需要取<code>s[i-1,j-1]</code>加上<code>s[i]</code>或者<code>s[j]</code>的数值中较大的； 综上所述，状态转移方程也就可以写成：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if s[i]&#x3D;&#x3D;s[j]:</span><br><span class="line">     dp[i][j]&#x3D; dp[i+1][j-1]+2</span><br><span class="line">else:</span><br><span class="line">	 dp[i][j]&#x3D;max(dp[i][j-1],dp[i+1][j])</span><br></pre></td></tr></table></figure>
<p>但是问题来了，具体我们应该怎么求每个状态的值呢？这里介绍一种利用状态转移表法写出状态转移方程，我们通过把<code>dp[i][j]</code>的状态转移直接画成一张二维表格，我们所要做的也就是往这张表中填充所有的状态，进而得到我们想要的结果。如下图：</p>
</li>
</ul>
<p><a href="https://camo.githubusercontent.com/5f94afddb30d65a77d72a9a83feffb7e8b0e5cce/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f323032303034303832303438343038392e706e67" target="_blank" rel="noopener"><img src="https://camo.githubusercontent.com/5f94afddb30d65a77d72a9a83feffb7e8b0e5cce/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f323032303034303832303438343038392e706e67" alt="img"></a></p>
<p>我们用字符串为”<strong>cbbd</strong>“作为输入来举例子，每次遍历就是求出右上角那些红色的值，通过上面的图我们会发现，按照一般的习惯都会先计算第一行的数值，但是当我们计算<code>dp[0,2]</code>的时候，我们会需要<code>dp[1,2]</code>，按照这个逻辑，我们就可以很容易发现遍历从下往上遍历会很方便计算。</p>
<ul>
<li><p><strong>第三步：考虑初始化条件</strong> 很明显看出来的当只有一个字符的时候，最长回文子序列就是1，所以可以得到<code>dp[i][j]=1(i=j)</code> 接下来我们来看看 当<code>i&gt;j</code>时，不符合题目要求，不存在子序列，所以直接初始化为0。 当<code>i&lt;j</code>时，每次计算表中对应的值就会根据前一个状态的值来计算。</p>
</li>
<li><p><strong>第四步：考虑输出状态</strong></p>
<p>我们想要求最长子序列的时候，我们可以直接看出来<code>dp[0][-1]</code>是最大的值，直接返回这个值就是最后的答案。</p>
</li>
<li><p><strong>第五步：考虑对时间，空间复杂度的优化</strong> 对于这个题目，同样可以考虑空间复杂度的优化，因为我们在计算<code>dp[i][j]</code>的时候，只用到左边和下边。如果改为用一维数组存储，那么左边和下边的信息也需要存在数组里，所以我们可以考虑在每次变化前用临时变量<code>tmp</code>记录会发生变化的左下边信息。所以状态转移方程就变成了：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if s[i] &#x3D;&#x3D; s[j]:</span><br><span class="line">    tmp, dp[j] &#x3D; dp[j], tmp + 2</span><br><span class="line">else:</span><br><span class="line">    dp[j] &#x3D;max(dp[j],dp[j-1])</span><br></pre></td></tr></table></figure>
<p>这里给出基本版的实现代码，如果需要优化后的可以看<a href="https://leetcode-cn.com/problems/longest-palindromic-subsequence/solution/dong-tai-gui-hua-jiang-wei-kong-jian-ya-suo-te-shu/" target="_blank" rel="noopener">空间压缩优化解法</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def longestPalindromeSubseq(self, s: str) -&gt; int:</span><br><span class="line">        n&#x3D;len(s)</span><br><span class="line">        dp&#x3D;[[0]*n for _ in range(n)]  #定义动态规划状态转移矩阵</span><br><span class="line">        for i in range(n):  #   初始化对角线，单个字符子序列就是1</span><br><span class="line">            dp[i][i]&#x3D;1</span><br><span class="line">        for i in range(n,-1,-1):  #从右下角开始往上遍历</span><br><span class="line">            for j in range(i+1,n):</span><br><span class="line">                if s[i]&#x3D;&#x3D;s[j]:   #当两个字符相等时，直接子字符串加2</span><br><span class="line">                    dp[i][j]&#x3D; dp[i+1][j-1]+2  </span><br><span class="line">                else:           #不相等时，取某边最长的字符</span><br><span class="line">                    dp[i][j]&#x3D;max(dp[i][j-1],dp[i+1][j])</span><br><span class="line">        return dp[0][-1]   #返回右上角位置的状态就是最长</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>总结：对于二维的数组的动态规划，采用了画状态转移表的方法来得到输出的状态，这种方法更加直观能看出状态转移的具体过程，同时也不容易出错。当然具体选择哪种方法则需要根据具体题目来确定，如果状态转移方程比较复杂的利用这种方法就能简化很多。</strong></p>
<p><strong>模板总结：</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for i in range(len(nums)):</span><br><span class="line">    for j in range(n):</span><br><span class="line">    	if s[i]&#x3D;&#x3D;s[j]:</span><br><span class="line">            dp[i][j]&#x3D;dp[i][j]+...</span><br><span class="line">        else:</span><br><span class="line">        	dp[i][j]&#x3D;最值(...)</span><br></pre></td></tr></table></figure>
<p>当然，动态规划除了解决子序列问题，也可以用来解决其他实际的问题，比如之前提到过的各种AI的经典算法，接下来我们来看一道动态规划的高频面试题，也是实际开发中很常用的。</p>
<h2 id="Leetcode72-编辑距离"><a href="#Leetcode72-编辑距离" class="headerlink" title="Leetcode72. 编辑距离"></a><a href="https://leetcode-cn.com/problems/edit-distance/" target="_blank" rel="noopener">Leetcode72. 编辑距离</a></h2><p>说到编辑距离（Edit distance），大家可能都比较熟悉。在自然语言处理（Natural Language Processing，又NLP）中，编辑距离是计算文本相似度的一种基本距离计算方式。简单来说，就是只能通过替换，删除，插入操作，将一串字符串变为另一串字符串的操作数。而求最小编辑距离的过程，就是一个典型的动态规划的过程。</p>
<p>如果计算两个字符串的编辑距离，我们可以看做是父问题，那他的子问题自然就是如何求更小字符串之间的编辑距离。那上面提到，动态规划不仅要将父问题拆分成子问题，更要记下子问题的解，以达到节省空间和时间的效果。</p>
<p>给定两个单词 word1 和 word2，计算出将 word1 转换成 word2 所使用的最少操作数 。</p>
<h3 id="题目描述-4"><a href="#题目描述-4" class="headerlink" title="题目描述"></a>题目描述</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">你可以对一个单词进行如下三种操作：</span><br><span class="line"></span><br><span class="line">插入一个字符</span><br><span class="line">删除一个字符</span><br><span class="line">替换一个字符</span><br><span class="line">示例 1:</span><br><span class="line"></span><br><span class="line">输入: word1 &#x3D; &quot;horse&quot;, word2 &#x3D; &quot;ros&quot;</span><br><span class="line">输出: 3</span><br><span class="line">解释: </span><br><span class="line">horse -&gt; rorse (将 &#39;h&#39; 替换为 &#39;r&#39;)</span><br><span class="line">rorse -&gt; rose (删除 &#39;r&#39;)</span><br><span class="line">rose -&gt; ros (删除 &#39;e&#39;)</span><br></pre></td></tr></table></figure>
<h3 id="解题思路-4"><a href="#解题思路-4" class="headerlink" title="解题思路"></a>解题思路</h3><ul>
<li><strong>第一步：确定动态规划状态</strong></li>
</ul>
<p>这个题目涉及到两个字符串，所以我们最先想到就是用两维数组来保存转移状态，定义<code>dp[i][j]</code>为字符串word1长度为<code>i</code>和字符串word2长度为<code>j</code>时，word1转化成word2所执行的最少操作次数的值。</p>
<ul>
<li><p><strong>第二步：写出状态转移方程</strong></p>
<p>关于这个问题的状态转移方程其实很难想到，这里提供的一个方向就是试着举个例子，然后通过例子的变化记录每一步变化得到的最少次数，来找到删除，插入，替换操作的状态转移方程具体应该怎么写。 我们采用从末尾开始遍历<code>word1</code>和<code>word2</code>， 当<code>word1[i]</code>等于<code>word2[j]</code>时，说明两者完全一样，所以<code>i</code>和<code>j</code>指针可以任何操作都不做，用状态转移式子表示就是<code>dp[i][j]=dp[i-1][j-1]</code>，也就是前一个状态和当前状态是一样的。 当<code>word1[i]</code>和<code>word2[j]</code>不相等时，就需要对三个操作进行递归了，这里就需要仔细思考状态转移方程的写法了。 对于<strong>插入</strong>操作，当我们在word1中插入一个和word2一样的字符，那么word2就被匹配了，所以可以直接表示为<code>dp[i][j-1]+1</code> 对于<strong>删除</strong>操作，直接表示为<code>dp[i-1][j]+1</code> 对于<strong>替换</strong>操作，直接表示为<code>dp[i-1][j-1]+1</code> 所以状态转移方程可以写成<code>min(dp[i][j-1]+1,dp[i-1][j]+1,dp[i-1][j-1]+1)</code></p>
</li>
<li><p><strong>第三步：考虑初始化条件</strong> 我们还是利用dp转移表法来找到状态转移的变化（读者可以自行画一张dp表，具体方法在求最长子序列中已经演示过了），这里我们用空字符串来额外加入到word1和word2中，这样的目的是方便记录每一步操作，例如如果其中一个是空字符串，那么另外一个字符至少的操作数都是1，就从1开始计数操作数，以后每一步都执行插入操作，也就是当<code>i=0</code>时，<code>dp[0][j]=j</code>,同理可得，如果另外一个是空字符串，则对当前字符串执行删除操作就可以了，也就是<code>dp[i][0]=i</code>。</p>
</li>
<li><p><strong>第四步：考虑输出状态</strong> 在转移表中我们可以看到，可以从左上角一直遍历到左下角的值，所以最终的编辑距离就是最后一个状态的值，对应的就是<code>dp[-1][-1]</code>。</p>
</li>
<li><p><strong>第五步：考虑对时间，空间复杂度的优化</strong> 和上题一样，这里由于<code>dp[i][j]</code>只和dp表中附近的三个状态（左边，右边和左上边）有关，所以同样可以进行压缩状态转移的空间存储，如果觉得有兴趣可以参考<a href="https://leetcode-cn.com/u/lyncien/" target="_blank" rel="noopener">@Lyncien</a>的解法,对于时间方面应该并没有可以优化的方法。</p>
</li>
</ul>
<p>总结起来代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def minDistance(self, word1, word2):</span><br><span class="line"> #m,n 表示两个字符串的长度</span><br><span class="line"> m&#x3D;len(word1) </span><br><span class="line"> n&#x3D;len(word2)</span><br><span class="line"> #构建二维数组来存储子问题</span><br><span class="line"> dp&#x3D;[[0 for _ in range(n+1)] for _ in range(m+1)]</span><br><span class="line"> #考虑边界条件，第一行和第一列的条件</span><br><span class="line"> for i in range(n+1):</span><br><span class="line">     dp[0][i]&#x3D;i  #对于第一行，每次操作都是前一次操作基础上增加一个单位的操作</span><br><span class="line"> for j in range(m+1):</span><br><span class="line">     dp[j][0]&#x3D;j #对于第一列也一样，所以应该是1,2,3,4,5...</span><br><span class="line"> for i in range(1,m+1):  #对其他情况进行填充</span><br><span class="line">     for j in range(1,n+1):</span><br><span class="line">         if word1[i-1]&#x3D;&#x3D;word2[j-1]: #当最后一个字符相等的时候，就不会产生任何操作代价，所以与dp[i-1][j-1]一样</span><br><span class="line">             dp[i][j]&#x3D;dp[i-1][j-1]</span><br><span class="line">         else:</span><br><span class="line">             dp[i][j]&#x3D;min(dp[i-1][j],dp[i][j-1],dp[i-1][j-1])+1 #分别对应删除，添加和替换操作</span><br><span class="line"> return dp[-1][-1] #返回最终状态就是所求最小的编辑距离</span><br></pre></td></tr></table></figure>
<h3 id="动态时间规整"><a href="#动态时间规整" class="headerlink" title="动态时间规整"></a>动态时间规整</h3><p>说完NLP里的相似度计算，咱们再来看看语音识别里有没有类似的算法用到动态规划呢？答案是肯定的。这个算法就叫动态时间规整（Dynamic time warping），简称DTW，一听名字是不是感觉就很动态规划。DTW算法是传统语音识别中的重要方法，起初是用于孤立词的语音识别，判断两段语音是否为同一个单词。实际上，只要是时间序列都可以用来计算相似度，不局限于语音识别当中，例如股市的交易策略，手势识别等等场景都有应用。</p>
<p>在语音信号中，有一个很大的问题就是，信号长度并不相等，即使是同一个人说同一个单词，也会有语速上的差别。那这个时候基于欧几里得距离（Euclidean Distance）的方法就不奏效了，但是两个时间序列形状上又非常的相似，于是我们就希望可以通过某种对齐的方式来衡量这两个时间序列的相似性。我们用所有相似点之间的距离和来表示这种相似度，称之为规整路径距离。</p>
<p>如果上面的题目看起来还是有点吃力的话，接下我们来来看轻松一点的题目，下面的题目和斐波那契数列求解类似，既可用迭代也可用动态规划做。</p>
<h2 id="Leetcode198-打家劫舍"><a href="#Leetcode198-打家劫舍" class="headerlink" title="Leetcode198. 打家劫舍"></a><a href="https://leetcode-cn.com/problems/house-robber/" target="_blank" rel="noopener">Leetcode198. 打家劫舍</a></h2><p>你是一个专业的小偷，计划偷窃沿街的房屋。每间房内都藏有一定的现金，影响你偷窃的唯一制约因素就是相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警。</p>
<h3 id="题目描述-5"><a href="#题目描述-5" class="headerlink" title="题目描述"></a>题目描述</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">给定一个代表每个房屋存放金额的非负整数数组，计算你在不触动警报装置的情况下，能够偷窃到的最高金额。</span><br><span class="line"></span><br><span class="line">示例 1:</span><br><span class="line"></span><br><span class="line">输入: [1,2,3,1]</span><br><span class="line">输出: 4</span><br><span class="line">解释: 偷窃 1 号房屋 (金额 &#x3D; 1) ，然后偷窃 3 号房屋 (金额 &#x3D; 3)。</span><br><span class="line">     偷窃到的最高金额 &#x3D; 1 + 3 &#x3D; 4 。</span><br></pre></td></tr></table></figure>
<h3 id="解题思路-5"><a href="#解题思路-5" class="headerlink" title="解题思路"></a>解题思路</h3><p>这个问题不复杂，其实利用一般的迭代可以直接解出来，但是这里讲动态规划，所以还是按照标准的套路来</p>
<ul>
<li><p><strong>第一步：确定动态规划状态</strong> 直接定义题目所求的偷窃的最高金额，所以<code>dp[i]</code>表示偷窃第<code>i</code>号房子能得到的最高金额。</p>
</li>
<li><p><strong>第二步：写出状态转移方程</strong> 如果我们不考虑限制条件相邻两个房子不能抢，那么问题就很简单。想得到第<code>i</code>个房间偷窃到的最高金额的时候，我们会考虑子问题前<code>i-1</code>间的最高金额<code>dp[i-1]</code>，然后再加上当前房间的金额，所以最后可以表达为<code>dp[i]=dp[i-1]+nums[i]</code>。 需要注意的是，这里限制了相邻两个房子是不能抢的，接下来我们就要考虑两种情况。 如果抢了第i个房间，那么第<code>i-1</code>肯定是不能抢的，这个时候需要再往前一间，用第<code>i-2</code>间的金额加上当前房间的金额，得到的状态转移方程是<code>dp[i]=dp[i-2]+nums[i]</code>。 如果没有抢第<code>i</code>个房间，那么肯定抢了第<code>i-1</code>间的金额，所以直接有<code>dp[i]=dp[i-1]</code>。</p>
<p>最后综合一下两种情况，就可以很快得到状态转移方程：<code>dp[i]=max(dp[i-2]+nums[i],dp[i-1])</code></p>
</li>
<li><p><strong>第三步：考虑初始化条件</strong> 初始化条件需要考虑第一个房子和第二个房子，之后的房子都可以按照规律直接求解，当我们只有一个房子的时候，自然只抢那间房子，当有两间房的时候，就抢金额较大的那间。综合起来就是<code>dp[0]=nums[0]，dp[1]=max(nums[0],nums[1])</code>。</p>
</li>
<li><p><strong>第四步:考虑输出状态</strong> 直接返回状态转移数组的最后一个值就是所求的最大偷窃金额。</p>
</li>
<li><p><strong>第五步：考虑对时间，空间复杂度的优化</strong> 时间复杂度为$O(N)$不能再优化了，空间复杂度方面如果用动态规划是不能优化，但是如果用迭代的方法只存储临时变量来记录每一步计算结果，这样可以降到$O(1)$。</p>
</li>
</ul>
<p>这里给出动态规划版本的实现代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def rob(self, nums):</span><br><span class="line"></span><br><span class="line">   if(not nums):   #特殊情况处理</span><br><span class="line">       return 0</span><br><span class="line">   if len(nums)&#x3D;&#x3D;1:</span><br><span class="line">       return nums[0]</span><br><span class="line">   n&#x3D;len(nums)</span><br><span class="line">   dp&#x3D;[0]*n    #初始化状态转移数组</span><br><span class="line">   dp[0]&#x3D;nums[0]  #第一个边界值处理</span><br><span class="line">   dp[1]&#x3D;max(nums[0],nums[1])#第二个边界值处理</span><br><span class="line">   for i in range(2,n):</span><br><span class="line">       dp[i]&#x3D;max(dp[i-2]+nums[i],dp[i-1]) #状态转移方程</span><br><span class="line">   return dp[-1]</span><br></pre></td></tr></table></figure>
<h2 id="Leetcode213-打家劫舍-II"><a href="#Leetcode213-打家劫舍-II" class="headerlink" title="Leetcode213. 打家劫舍 II"></a><a href="https://leetcode-cn.com/problems/house-robber-ii/" target="_blank" rel="noopener">Leetcode213. 打家劫舍 II</a></h2><p>你是一个专业的小偷，计划偷窃沿街的房屋，每间房内都藏有一定的现金。这个地方所有的房屋都围成一圈，这意味着第一个房屋和最后一个房屋是紧挨着的。同时，相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警。</p>
<h3 id="题目描述-6"><a href="#题目描述-6" class="headerlink" title="题目描述"></a>题目描述</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">给定一个代表每个房屋存放金额的非负整数数组，计算你在不触动警报装置的情况下，能够偷窃到的最高金额。</span><br><span class="line"></span><br><span class="line">示例 1:</span><br><span class="line"></span><br><span class="line">输入: [2,3,2]</span><br><span class="line">输出: 3</span><br><span class="line">解释: 你不能先偷窃 1 号房屋（金额 &#x3D; 2），然后偷窃 3 号房屋（金额 &#x3D; 2）, 因为他们是相邻的。</span><br></pre></td></tr></table></figure>
<h3 id="解题思路-6"><a href="#解题思路-6" class="headerlink" title="解题思路"></a>解题思路</h3><ul>
<li><p><strong>第一步：确定动态规划状态</strong></p>
<p>直接定义题目所求的偷窃的最高金额，所以<code>dp[i]</code>表示偷窃第<code>i</code>号房子能得到的最高金额。</p>
</li>
<li><p><strong>第二步：写出状态转移方程</strong></p>
<p>和上个题目类似，这个题目不一样的是现在所有房屋都围成一个圈，相比于上个问题又增加了一个限制，这样一来第一个房子和最后一个房子只能选择其中一个偷窃了。所有我们把这个问题拆分成两个问题：</p>
<ul>
<li>偷窃了第一个房子，此时对应的是<code>nums[1:]</code>，得到最大的金额value是<code>v1</code>。</li>
<li>偷窃了最后一个房子，此时对应的是<code>nums[:n-1]</code>(其中n是所有房子的数量)，得到的最大金额value是<code>v2</code>。 最后的结果就是取这两种情况的最大值，即<code>max(v1,v2)</code>。</li>
</ul>
<p>每个子问题就和上题是一样的了，所以可以直接得到状态转移方程还是<code>dp[i]=max(dp[i-2]+nums[i],dp[i-1])</code></p>
</li>
<li><p><strong>第三步：考虑初始化条件</strong> 初始化一个房子和两个房子的情况就是<code>dp[0]=nums[0]，dp[1]=max(nums[0],nums[1])</code>。</p>
</li>
<li><p><strong>第四步：考虑输出状态</strong> 直接返回状态转移数组的最后一个值就是所求的最大偷窃金额。</p>
</li>
<li><p><strong>第五步：考虑对时间，空间复杂度的优化</strong></p>
</li>
</ul>
<p>时间复杂度为$O(N)$不能再优化了，空间复杂度方面如果用动态规划是不能优化，但是如果用迭代的方法只存储临时变量来记录每一步计算结果，这样可以降到$O(1)$。</p>
<p>最后的代码实现：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def rob(self, nums: List[int]) -&gt; int:</span><br><span class="line">        if not nums:</span><br><span class="line">            return 0</span><br><span class="line">        elif len(nums)&lt;&#x3D;2:</span><br><span class="line">            return max(nums)</span><br><span class="line">        def helper(nums):</span><br><span class="line">            if len(nums)&lt;&#x3D;2:</span><br><span class="line">                return max(nums)</span><br><span class="line">            dp&#x3D;[0]*len(nums)</span><br><span class="line">            dp[0]&#x3D;nums[0]</span><br><span class="line">            dp[1]&#x3D;max(nums[0],nums[1])</span><br><span class="line">            for i in range(2,len(nums)):</span><br><span class="line">                dp[i]&#x3D;max(dp[i-1],dp[i-2]+nums[i])</span><br><span class="line">            return dp[-1]</span><br><span class="line">        return max(helper(nums[1:]),helper(nums[:-1]))</span><br></pre></td></tr></table></figure>
<h1 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h1><p>动态规划是算法中比较难的类型，但是其实主要是掌握一种思维，有了这种思维，其实很难的问题都能一步一步解决好。最后再推荐一些比较优质的动态规划文章。</p>
<p><a href="https://www.jiqizhixin.com/articles/2019-09-29-5" target="_blank" rel="noopener">掌握动态规划，助你成为优秀的算法工程师</a></p>
<p>推荐MIT的动态规划练习资料，这份资料通过动态规划经典的问题让我们很清晰的了解到这个算法的魅力所在，对于新手入门动态规划是一个很不错的资料。<a href="https://people.cs.clemson.edu/~bcdean/dp_practice/" target="_blank" rel="noopener">Dynamic Programming Practice Problems</a></p>
<p>五分钟学算法的动态规划系列: <a href="https://mp.weixin.qq.com/s?__biz=MzUyNjQxNjYyMg==&amp;mid=2247485288&amp;idx=1&amp;sn=fd043fc723f38bcaecc90d9945981f8a&amp;chksm=fa0e68e9cd79e1ffd965205bb06b1731539bf2e0bbc5991664f5d1d9721b346ec08c85bb9042&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">浅谈什么是动态规划以及相关的「股票」算法题</a> <a href="https://mp.weixin.qq.com/s?__biz=MzUyNjQxNjYyMg==&amp;mid=2247486904&amp;idx=1&amp;sn=099d5560ab25c0163349dff0c7f51490&amp;chksm=fa0e6239cd79eb2fe6e831d7debba60aa906721d592b8766a944ef88bf91bf82568c20d71891&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">有了四步解题法模板，再也不害怕动态规划!</a> <a href="https://mp.weixin.qq.com/s?__biz=MzUyNjQxNjYyMg==&amp;mid=2247486923&amp;idx=2&amp;sn=6c1c8aeb4db68522e67ddf8c1e933660&amp;chksm=fa0e624acd79eb5cdb410808921609a830b9b9221e813e4eb89cf551ca48f317668d44b095d2&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">（进阶版）有了四步解题法模板，再也不害怕动态规划！</a></p>
<p>主要参考的Leetcode 优秀题解： <a href="https://leetcode-cn.com/problems/longest-increasing-subsequence/solution/dong-tai-gui-hua-she-ji-fang-fa-zhi-pai-you-xi-jia/" target="_blank" rel="noopener">动态规划设计方法&amp;&amp;纸牌游戏讲解二分解法</a> <a href="https://leetcode-cn.com/problems/longest-palindromic-substring/solution/zhong-xin-kuo-san-dong-tai-gui-hua-by-liweiwei1419/" target="_blank" rel="noopener">动态规划、Manacher 算法</a> <a href="https://leetcode-cn.com/problems/edit-distance/solution/bian-ji-ju-chi-mian-shi-ti-xiang-jie-by-labuladong/" target="_blank" rel="noopener">编辑距离面试题详解</a> <a href="https://leetcode-cn.com/problems/house-robber-ii/solution/213-da-jia-jie-she-iidong-tai-gui-hua-jie-gou-hua-/" target="_blank" rel="noopener">打家劫舍 II（动态规划，结构化思路，清晰题解）</a></p>
]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
  </entry>
  <entry>
    <title>每日论文（1）——Factorization Machines</title>
    <url>/posts/f2b8e904.html</url>
    <content><![CDATA[<p>今天的论文阅读是<a href="https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf" target="_blank" rel="noopener">Factorization Machines</a></p>
<h1 id="FM模型的引入"><a href="#FM模型的引入" class="headerlink" title="FM模型的引入"></a>FM模型的引入</h1><h2 id="逻辑回归模型及其缺点"><a href="#逻辑回归模型及其缺点" class="headerlink" title="逻辑回归模型及其缺点"></a>逻辑回归模型及其缺点</h2><p>FM模型其实是一种思路，具体的应用稍少。一般来说做推荐CTR预估时最简单的思路就是将特征做线性组合（逻辑回归LR），传入sigmoid中得到一个概率值，本质上这就是一个线性模型，因为sigmoid是单调增函数不会改变里面的线性模型的CTR预测顺序，因此逻辑回归模型效果会比较差。也就是LR的缺点有：</p>
<ul>
<li>是一个线性模型</li>
<li>每个特征对最终输出结果独立，需要手动特征交叉（$x_i*x_j$），比较麻烦</li>
</ul>
<h2 id="二阶交叉项的考虑及改进"><a href="#二阶交叉项的考虑及改进" class="headerlink" title="二阶交叉项的考虑及改进"></a>二阶交叉项的考虑及改进</h2><p>由于LR模型的上述缺陷（主要是手动做特征交叉比较麻烦），干脆就考虑所有的二阶交叉项，也就是将目标函数由原来的</p>
<script type="math/tex; mode=display">y = w_0+\sum_{i=1}^nw_ix_i</script><p>变为</p>
<script type="math/tex; mode=display">y = w_0+\sum_{i=1}^nw_ix_i+\sum_{i=1}^{n-1}\sum_{i+1}^nw_{ij}x_ix_j</script><p>但这个式子有一个问题，<strong>只有当$x_i$与$x_j$均不为0时这个二阶交叉项才会生效</strong>，后面这个特征交叉项本质是和多项式核SVM等价的，为了解决这个问题，我们的FM登场了！</p>
<p>FM模型使用了如下的优化函数：</p>
<script type="math/tex; mode=display">y = w_0+\sum_{i=1}^nw_ix_i+\sum_{i=1}^{n}\sum_{i+1}^n\lt v_i,v_j\gt x_ix_j</script><p>事实上做的唯一改动就是把$w_{ij}$替换成了$\lt v_i,v_j\gt$，大家应该就看出来了，这实际上就有深度学习的意味在里面了，实质上就是给每个$x_i$计算一个encoding，然后将两个向量之间的encoding做内积得到之前所谓的$w_{ij}$好处就是这个模型泛化能力强 ，即使两个特征之前从未在训练集中<strong>同时</strong>出现，我们也不至于像之前一样训练不出$w_{ij}$，事实上只需要$x_i$和其他的$x_k$同时出现过就可以计算出$x_i$的embedding！</p>
<h1 id="FM公式的理解"><a href="#FM公式的理解" class="headerlink" title="FM公式的理解"></a>FM公式的理解</h1><p>从公式来看，模型前半部分就是普通的LR线性组合，后半部分的交叉项：特征组合。首先，单从模型表达能力上来看，FM是要强于LR的，至少它不会比LR弱，当交叉项参数$w_{ij}$全为0的时候，整个模型就退化为普通的LR模型。对于有$n$个特征的模型，特征组合的参数数量共有$1+2+3+\cdots  + n-1=\frac{n(n-1)}{2}$个，并且任意两个参数之间是独立的。所以说特征数量比较多的时候，特征组合之后，维度自然而然就高了。</p>
<blockquote>
<p>定理：任意一个实对称矩阵（正定矩阵）$W$都存在一个矩阵$V$，使得 $W=V.V^{T}$成立。</p>
</blockquote>
<p>类似地，所有二次项参数$\omega_{ij}$可以组成一个对称阵$W$（为了方便说明FM的由来，对角元素可以设置为正实数），那么这个矩阵就可以分解为$W=V^TV$，$V$ 的第$j$列($v_{j}$)便是第$j$维特征($x_{j}$)的隐向量。</p>
<script type="math/tex; mode=display">
\hat{y}(X) = \omega_{0}+\sum_{i=1}^{n}{\omega_{i}x_{i}}+\sum_{i=1}^{n-1}{\sum_{j=i+1}^{n} \color{red}{<v_{i},v_{j}>x_{i}x_{j}}}</script><p>需要估计的参数有$\omega_{0}∈ R$，$\omega_{i}∈ R$，$V∈ R$，$&lt; \cdot, \cdot&gt;$是长度为$k$的两个向量的点乘，公式如下：</p>
<script type="math/tex; mode=display"><v_{i},v_{j}> = \sum_{f=1}^{k}{v_{i,f}\cdot v_{j,f}}</script><p>上面的公式中： </p>
<ul>
<li>$\omega_{0}$为全局偏置；</li>
<li>$\omega_{i}$是模型第$i$个变量的权重;</li>
<li>$\omega_{ij} = &lt; v_{i}, v_{j}&gt;$特征$i$和$j$的交叉权重;</li>
<li>$v_{i} $是第$i$维特征的隐向量;</li>
<li>$&lt;\cdot, \cdot&gt;$代表向量点积;</li>
<li>$k(k&lt;&lt;n)$为隐向量的长度，包含 $k$ 个描述特征的因子。</li>
</ul>
<p>FM模型中二次项的参数数量减少为 $kn $个，远少于多项式模型的参数数量。另外，参数因子化使得 $x_{h}x_{i}$ 的参数和 $x_{i}x_{j}$ 的参数不再是相互独立的，因此我们可以在样本稀疏的情况下相对合理地估计FM的二次项参数。具体来说，$x_{h}x_{i}$ 和 $x_{i}x_{j}$的系数分别为 $\lt v_{h},v_{i}\gt$ 和 $\lt v_{i},v_{j}\gt$ ，它们之间有共同项 $v_{i}$ 。也就是说，所有包含“ $x_{i}$ 的非零组合特征”（存在某个 $j \ne i$ ，使得 $x_{i}x_{j}\neq 0$ ）的样本都可以用来学习隐向量$v_{i}$，这很大程度上避免了数据稀疏性造成的影响。而在多项式模型中,$w_{hi}$ 和 $w_{ij}$ 是相互独立的。</p>
<p>显而易见，FM的公式是一个通用的拟合方程，可以采用不同的损失函数用于解决regression、classification等问题，比如可以采用MSE（Mean Square Error）loss function来求解回归问题，也可以采用Hinge/Cross-Entropy loss来求解分类问题。当然，在进行二元分类时，FM的输出需要使用sigmoid函数进行变换，该原理与LR是一样的。直观上看，FM的复杂度是 $O(kn^2)$ 。但是FM的二次项可以化简，其复杂度可以优化到 $O(kn)$ 。由此可见，FM可以在线性时间对新样本作出预测。</p>
<p><strong>证明</strong>：</p>
<p>由<script type="math/tex">ab+ac+bc = \frac{1}{2}\left[(a+b+c)^2-(a^2+b^2+c^2) \right]</script></p>
<script type="math/tex; mode=display">\begin{align} \sum_{i=1}^{n-1}{\sum_{j=i+1}^{n}{<v_i,v_j>x_ix_j}}
&= \frac{1}{2}\sum_{i=1}^{n}{\sum_{j=1}^{n}{<v_i,v_j>x_ix_j}} - \frac{1}{2} {\sum_{i=1}^{n}{<v_i,v_i>x_ix_i}} \\
&= \frac{1}{2} \left( \sum_{i=1}^{n}{\sum_{j=1}^{n}{\sum_{f=1}^{k}{v_{i,f}v_{j,f}x_ix_j}}} - \sum_{i=1}^{n}{\sum_{f=1}^{k}{v_{i,f}v_{i,f}x_ix_i}} \right) \\
&= \frac{1}{2}\sum_{f=1}^{k}{\left[ \left( \sum_{i=1}^{n}{v_{i,f}x_i} \right) \cdot \left( \sum_{j=1}^{n}{v_{j,f}x_j} \right) - \sum_{i=1}^{n}{v_{i,f}^2 x_i^2} \right]} \\
&= \frac{1}{2}\sum_{f=1}^{k}{\left[ \left( \sum_{i=1}^{n}{v_{i,f}x_i} \right)^2 - \sum_{i=1}^{n}{v_{i,f}^2 x_i^2} \right]} \end{align}</script><p><strong>解释</strong>：</p>
<ul>
<li>$v_{i,f}$ 是一个具体的值；</li>
<li>第1个等号：对称矩阵 $W$ 对角线上半部分；</li>
<li>第2个等号：把向量内积 $v_{i}$,$v_{j}$ 展开成累加和的形式；</li>
<li>第3个等号：提出公共部分；</li>
<li>第4个等号： $i$ 和 $j$ 相当于是一样的，表示成平方过程。</li>
</ul>
<h2 id="SGD训练参数"><a href="#SGD训练参数" class="headerlink" title="SGD训练参数"></a>SGD训练参数</h2><p>使用SGD进行训练，可以推导出SGD的参数更新方式：</p>
<script type="math/tex; mode=display">\begin{equation}
\frac{\partial \hat{y}(x)}{\partial \theta} = \left\{\begin{array}
{lr} 1, & if \ \theta\ is\ \omega_{0} \\
x_{i}, & if\ \theta\ is\ \omega_i \\
x_{i} \sum_{j=1}^{n}{v_{j,f} \ x_{j} - v_{i,f} \ x_{i}^2} & if\ \theta\ is\ v_{i,f} \end{array} \right.
\end{equation}</script><p>上式中，$\sum_{j=1}^{n} v_{j,f} \ x_{j}$ 的计算与变量$i$相互独立，因此可以预先计算得到。每个梯度的计算时间复杂度都为$O(1)$，模型的参数总数量为 $nk + n + 1$，在数据稀疏条件下，参数更新所需要的所有时间为$ O(k n)$。</p>
<h2 id="FM算法的问题"><a href="#FM算法的问题" class="headerlink" title="FM算法的问题"></a>FM算法的问题</h2><ol>
<li>特征之间两两组合容易导致维度灾难；</li>
<li>组合后的特征未必有效，可能存在特征冗余现象；</li>
<li>组合后特征样本非常稀疏，如果原始样本中不存在对应的组合，则无法学习参数，那么该组合就显得无效。</li>
</ol>
<h1 id="FM模型的应用"><a href="#FM模型的应用" class="headerlink" title="FM模型的应用"></a>FM模型的应用</h1><p>最直接的想法就是直接把FM得到的结果放进sigmoid中输出一个概率值，由此做CTR预估，事实上我们也可以做召回。</p>
<p>由于FM模型是利用两个特征的Embedding做内积得到二阶特征交叉的权重，那么我们可以将训练好的FM特征取出离线存好，之后用来做KNN向量检索。</p>
<p>工业应用的具体操作步骤：</p>
<ul>
<li>离线训练好FM模型（学习目标可以是CTR）</li>
<li>将训练好的FM模型Embedding取出</li>
<li>将每个uid对应的Embedding做avg pooling（平均）形成该用户最终的Embedding，item也做同样的操作</li>
<li>将所有的Embedding向量放入Faiss等</li>
<li>线上uid发出请求，取出对应的user embedding，进行检索召回</li>
</ul>
<h1 id="代码实践"><a href="#代码实践" class="headerlink" title="代码实践"></a>代码实践</h1><p>直接看Github官方仓库：<a href="https://github.com/coreylynch/pyFM，里面有介绍如何安装以及使用，下面搬运一遍：" target="_blank" rel="noopener">https://github.com/coreylynch/pyFM，里面有介绍如何安装以及使用，下面搬运一遍：</a></p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p><strong>方法一：直接pip install</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip install git+https:&#x2F;&#x2F;github.com&#x2F;coreylynch&#x2F;pyFM</span><br></pre></td></tr></table></figure>
<p><strong>方法二：手动安装</strong></p>
<p>输入上面这行代码应能下载这个包并安装，如果安装失败可能是网络原因，这时可以考虑手动下载这个包然后手动<code>python setup.py install</code>安装，这时候通常会报错，去掉setup.py文件里面的<code>libraries=[“m”]</code>一行再重新安装即可</p>
<p>具体操作是：</p>
<ul>
<li>在<a href="https://github.com/coreylynch/pyFM中手动下载包" target="_blank" rel="noopener">https://github.com/coreylynch/pyFM中手动下载包</a></li>
<li>将包解压，更改里面的setup.py文件，去掉setup.py文件里面的<code>libraries=[“m”]</code>一行</li>
<li>cd到当前文件夹下<code>python setup.py install</code></li>
</ul>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>这部分主要作为简单上手让读者了解如何使用这个包~</p>
<p><strong>第一步：导包</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyfm <span class="keyword">import</span> pylibfm</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> DictVectorizer</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>
<p><strong>第二步：创建训练集并转换成one-hot编码的特征形式</strong> </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train = [</span><br><span class="line">    &#123;<span class="string">"user"</span>: <span class="string">"1"</span>, <span class="string">"item"</span>: <span class="string">"5"</span>, <span class="string">"age"</span>: <span class="number">19</span>&#125;,</span><br><span class="line">    &#123;<span class="string">"user"</span>: <span class="string">"2"</span>, <span class="string">"item"</span>: <span class="string">"43"</span>, <span class="string">"age"</span>: <span class="number">33</span>&#125;,</span><br><span class="line">    &#123;<span class="string">"user"</span>: <span class="string">"3"</span>, <span class="string">"item"</span>: <span class="string">"20"</span>, <span class="string">"age"</span>: <span class="number">55</span>&#125;,</span><br><span class="line">    &#123;<span class="string">"user"</span>: <span class="string">"4"</span>, <span class="string">"item"</span>: <span class="string">"10"</span>, <span class="string">"age"</span>: <span class="number">20</span>&#125;,</span><br><span class="line">]</span><br><span class="line">v = DictVectorizer()</span><br><span class="line">X = v.fit_transform(train)</span><br><span class="line">print(X.toarray())</span><br></pre></td></tr></table></figure>
<p>看看结果，对比一下维度是否符合预期：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[[19.  0.  0.  0.  1.  1.  0.  0.  0.]</span><br><span class="line"> [33.  0.  0.  1.  0.  0.  1.  0.  0.]</span><br><span class="line"> [55.  0.  1.  0.  0.  0.  0.  1.  0.]</span><br><span class="line"> [20.  1.  0.  0.  0.  0.  0.  0.  1.]]</span><br></pre></td></tr></table></figure>
<p><strong>第三步：创建标签</strong></p>
<p>这里简单创建了一个全1的标签：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y = np.repeat(<span class="number">1.0</span>,X.shape[<span class="number">0</span>])</span><br><span class="line">y</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([1., 1., 1., 1.])</span><br></pre></td></tr></table></figure>
<p><strong>第四步：训练并预测</strong></p>
<p>就和调用<code>sklearn</code>的包是一样的用法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fm = pylibfm.FM()</span><br><span class="line">fm.fit(X,y)</span><br><span class="line">fm.predict(v.transform(&#123;<span class="string">"user"</span>: <span class="string">"1"</span>, <span class="string">"item"</span>: <span class="string">"10"</span>, <span class="string">"age"</span>: <span class="number">24</span>&#125;))</span><br></pre></td></tr></table></figure>
<h2 id="电影评分数据集实战"><a href="#电影评分数据集实战" class="headerlink" title="电影评分数据集实战"></a>电影评分数据集实战</h2><p>数据集在这里下载，数据集本地具体保存路径读者自行阅读代码找找： <a href="http://www.grouplens.org/system/files/ml-100k.zip" target="_blank" rel="noopener">http://www.grouplens.org/system/files/ml-100k.zip</a></p>
<p><strong>导包，并定义一个导入指定格式数据集的函数</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> DictVectorizer</span><br><span class="line"><span class="keyword">from</span> pyfm <span class="keyword">import</span> pylibfm</span><br><span class="line"></span><br><span class="line"><span class="comment"># Read in data</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadData</span><span class="params">(filename,path=<span class="string">"ml-100k/"</span>)</span>:</span></span><br><span class="line">    data = []</span><br><span class="line">    y = []</span><br><span class="line">    users=set()</span><br><span class="line">    items=set()</span><br><span class="line">    <span class="keyword">with</span> open(path+filename) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">            (user,movieid,rating,ts)=line.split(<span class="string">'\t'</span>)</span><br><span class="line">            data.append(&#123; <span class="string">"user_id"</span>: str(user), <span class="string">"movie_id"</span>: str(movieid)&#125;)</span><br><span class="line">            y.append(float(rating))</span><br><span class="line">            users.add(user)</span><br><span class="line">            items.add(movieid)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (data, np.array(y), users, items)</span><br></pre></td></tr></table></figure>
<p><strong>导入训练集和测试集，并转换格式</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">(train_data, y_train, train_users, train_items) = loadData(<span class="string">"ua.base"</span>)</span><br><span class="line">(test_data, y_test, test_users, test_items) = loadData(<span class="string">"ua.test"</span>)</span><br><span class="line">v = DictVectorizer()</span><br><span class="line">X_train = v.fit_transform(train_data)</span><br><span class="line">X_test = v.transform(test_data)</span><br></pre></td></tr></table></figure>
<p><strong>训练模型并测试</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Build and train a Factorization Machine</span></span><br><span class="line">fm = pylibfm.FM(num_factors=<span class="number">10</span>, num_iter=<span class="number">100</span>, verbose=<span class="literal">True</span>, task=<span class="string">"regression"</span>, initial_learning_rate=<span class="number">0.001</span>, learning_rate_schedule=<span class="string">"optimal"</span>)</span><br><span class="line">fm.fit(X_train,y_train)</span><br></pre></td></tr></table></figure>
<p><strong>预测结果打印误差</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">preds = fm.predict(X_test)</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line">print(<span class="string">"FM MSE: %.4f"</span> % mean_squared_error(y_test,preds))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FM MSE: 0.8873</span><br></pre></td></tr></table></figure>
<h2 id="分类任务实战"><a href="#分类任务实战" class="headerlink" title="分类任务实战"></a>分类任务实战</h2><p><strong>搞数据</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> DictVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> pyfm <span class="keyword">import</span> pylibfm</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_classification</span><br><span class="line"></span><br><span class="line">X, y = make_classification(n_samples=<span class="number">1000</span>,n_features=<span class="number">100</span>, n_clusters_per_class=<span class="number">1</span>)</span><br><span class="line">data = [ &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> dict(zip(i, range(len(i)))).items()&#125;  <span class="keyword">for</span> i <span class="keyword">in</span> X]</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=<span class="number">0.1</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">v = DictVectorizer()</span><br><span class="line">X_train = v.fit_transform(X_train)</span><br><span class="line">X_test = v.transform(X_test)</span><br></pre></td></tr></table></figure>
<p><strong>建模型</strong></p>
<p>我们可以看到主要改变的参数是<code>num_factors</code>和<code>tasks</code>，读者可以想想为什么</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fm = pylibfm.FM(num_factors=<span class="number">50</span>, num_iter=<span class="number">10</span>, verbose=<span class="literal">True</span>, task=<span class="string">"classification"</span>, initial_learning_rate=<span class="number">0.0001</span>, learning_rate_schedule=<span class="string">"optimal"</span>)</span><br><span class="line">fm.fit(X_train,y_train)</span><br></pre></td></tr></table></figure>
<p>由于是分类任务，误差函数肯定不一样</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> log_loss</span><br><span class="line">print(<span class="string">"Validation log loss: %.4f"</span> % log_loss(y_test,fm.predict(X_test)))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Validation log loss: 1.3678</span><br></pre></td></tr></table></figure>
<p>参考链接：</p>
<ul>
<li>论文原文：<a href="https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf" target="_blank" rel="noopener">https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf</a></li>
<li>贪心学院FM模型公开课</li>
<li>Github仓库：<a href="https://github.com/coreylynch/pyFM" target="_blank" rel="noopener">https://github.com/coreylynch/pyFM</a></li>
<li>一篇翻译的很好的博客：<a href="https://www.csuldw.com/2019/02/08/2019-02-08-fm-algorithm-theory/，但主要只介绍了原论文的前一半，后一半主要是各种实验暂时不看" target="_blank" rel="noopener">https://www.csuldw.com/2019/02/08/2019-02-08-fm-algorithm-theory/，但主要只介绍了原论文的前一半，后一半主要是各种实验暂时不看</a></li>
</ul>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
  </entry>
  <entry>
    <title>leetcode刷题专题打卡——分治法</title>
    <url>/posts/3e1907bd.html</url>
    <content><![CDATA[<h1 id="关于分治法"><a href="#关于分治法" class="headerlink" title="关于分治法"></a>关于分治法</h1><h2 id="引文"><a href="#引文" class="headerlink" title="引文"></a>引文</h2><p>MapReduce（分治算法的应用） 是 Google 大数据处理的三驾马车之一，另外两个是 GFS 和 Bigtable。它在倒排索引、PageRank 计算、网页分析等搜索引擎相关的技术中都有大量的应用。</p>
<p>尽管开发一个 MapReduce 看起来很高深，感觉遥不可及。实际上，万变不离其宗，它的本质就是分治算法思想，分治算法。如何理解分治算法？为什么说 MapRedue 的本质就是分治算法呢？</p>
<h2 id="主要思想"><a href="#主要思想" class="headerlink" title="主要思想"></a>主要思想</h2><p>分治算法的主要思想是将原问题<strong>递归地分成</strong>若干个子问题，直到子问题<strong>满足边界条件</strong>，停止递归。将子问题逐个击破(一般是同种方法)，将已经解决的子问题合并，最后，算法会<strong>层层合并</strong>得到原问题的答案。</p>
<p>和动态规划相比，分治法是一种二分的递归算法，例如，要解决4，先解决1、1、1、1，然后在这基础上解决2、2，然后再解决4，而动态规划是“叠加式”算法，例如，要解决4，先解决1，然后2，然后3，然后再4</p>
<h2 id="分治法的步骤"><a href="#分治法的步骤" class="headerlink" title="分治法的步骤"></a>分治法的步骤</h2><ul>
<li>分：<strong>递归地</strong>将问题<strong>分解</strong>为各个的子<strong>问题</strong>(性质相同的、相互独立的子问题)；</li>
<li>治：将这些规模更小的子问题<strong>逐个击破</strong>；</li>
<li>合：将已解决的子问题<strong>逐层合并</strong>，最终得出原问题的解；</li>
</ul>
<p><a href="https://camo.githubusercontent.com/415d803c0966b64248633ddd46843c902819206a/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303230303430383230343435303730312e706e67" target="_blank" rel="noopener"><img src="/Pic/leetcode%E5%88%B7%E9%A2%98%E4%B8%93%E9%A2%98%E6%89%93%E5%8D%A1%E2%80%94%E2%80%94%E5%88%86%E6%B2%BB%E6%B3%95/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303230303430383230343435303730312e706e67" alt="img"></a></p>
<h2 id="分治法适用的情况"><a href="#分治法适用的情况" class="headerlink" title="分治法适用的情况"></a>分治法适用的情况</h2><ul>
<li>原问题的<strong>计算复杂度</strong>随着问题的规模的增加而增加。</li>
<li>原问题<strong>能够被分解</strong>成更小的子问题。</li>
<li>子问题的<strong>结构和性质</strong>与原问题一样，并且<strong>相互独立</strong>，子问题之间<strong>不包含</strong>公共的子子问题。</li>
<li>原问题分解出的子问题的解<strong>可以合并</strong>为该问题的解。</li>
</ul>
<h2 id="伪代码"><a href="#伪代码" class="headerlink" title="伪代码"></a>伪代码</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">divide_conquer</span><span class="params">(problem, paraml, param2,...)</span>:</span></span><br><span class="line">    <span class="comment"># 不断切分的终止条件</span></span><br><span class="line">    <span class="keyword">if</span> problem <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        print_result</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="comment"># 准备数据</span></span><br><span class="line">    data=prepare_data(problem)</span><br><span class="line">    <span class="comment"># 将大问题拆分为小问题</span></span><br><span class="line">    subproblems=split_problem(problem, data)</span><br><span class="line">    <span class="comment"># 处理小问题，得到子结果</span></span><br><span class="line">    subresult1=self.divide_conquer(subproblems[<span class="number">0</span>],p1,..…)</span><br><span class="line">    subresult2=self.divide_conquer(subproblems[<span class="number">1</span>],p1,...)</span><br><span class="line">    subresult3=self.divide_conquer(subproblems[<span class="number">2</span>],p1,.…)</span><br><span class="line">    <span class="comment"># 对子结果进行合并 得到最终结果</span></span><br><span class="line">    result=process_result(subresult1, subresult2, subresult3,...)</span><br></pre></td></tr></table></figure>
<h2 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h2><p> 通过应用举例分析理解分治算法的原理其实并不难，但是要想灵活应用并在编程中体现这种思想中却并不容易。所以，这里这里用分治算法应用在排序的时候的一个栗子，加深对分治算法的理解。</p>
<p>相关概念：</p>
<ul>
<li><strong>有序度</strong>：表示一组数据的有序程度</li>
<li><strong>逆序度</strong>：表示一组数据的无序程度</li>
</ul>
<p>一般通过<strong>计算有序对或者逆序对的个数</strong>，来表示数据的有序度或逆序度。</p>
<p>假设我们有 <code>n</code> 个数据，我们期望数据从小到大排列，那完全有序的数据的有序度就是 $n(n-1)/2$，逆序度等于 0；相反，倒序排列的数据的有序度就是 0，逆序度是 $n(n-1)/2$。</p>
<p><strong>Q：如何编程求出一组数据的有序对个数或者逆序对个数呢？</strong></p>
<p>因为有序对个数和逆序对个数的求解方式是类似的，所以这里可以只思考逆序对（常接触的）个数的求解方法。</p>
<ul>
<li>方法1<ul>
<li>拿数组里的每个数字跟它后面的数字比较，看有几个比它小的。</li>
<li>把比它小的数字个数记作 <code>k</code>，通过这样的方式，把每个数字都考察一遍之后，然后对每个数字对应的 <code>k</code> 值求和</li>
<li>最后得到的总和就是逆序对个数。</li>
<li>这样操作的时间复杂度是$O(n^2)$（需要两层循环过滤）。那有没有更加高效的处理方法呢？这里尝试套用分治的思想来求数组 A 的逆序对个数。</li>
</ul>
</li>
<li>方法2<ul>
<li>首先将数组分成前后两半 A1 和 A2，分别计算 A1 和 A2 的逆序对个数 K1 和 K2</li>
<li>然后再计算 A1 与 A2 之间的逆序对个数 K3。那数组 A 的逆序对个数就等于 K1+K2+K3。</li>
<li>注意使用分治算法其中一个要求是，<strong>子问题合并的代价不能太大</strong>，否则就起不了降低时间复杂度的效果了。</li>
<li><strong>如何快速计算出两个子问题 A1 与 A2 之间的逆序对个数呢？这里就要借助归并排序算法了。（这里先回顾一下归并排序思想）</strong>如何借助归并排序算法来解决呢？归并排序中有一个非常关键的操作，就是将两个有序的小数组，合并成一个有序的数组。实际上，在这个合并的过程中，可以计算这两个小数组的逆序对个数了。每次合并操作，我们都计算逆序对个数，把这些计算出来的逆序对个数求和，就是这个数组的逆序对个数了。</li>
</ul>
</li>
</ul>
<h1 id="Leetcode题解"><a href="#Leetcode题解" class="headerlink" title="Leetcode题解"></a>Leetcode题解</h1><h2 id="169-多数元素"><a href="#169-多数元素" class="headerlink" title="169. 多数元素"></a><a href="https://leetcode-cn.com/problems/majority-element/" target="_blank" rel="noopener">169. 多数元素</a></h2><ul>
<li><p>题目描述</p>
<p>给定一个大小为 n 的数组，找到其中的众数。众数是指在数组中出现次数大于 [n/2] 的元素。</p>
<p>你可以假设数组是非空的，并且给定的数组总是存在众数。</p>
<p>示例 1:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入: [3,2,3]</span><br><span class="line">输出: 3</span><br></pre></td></tr></table></figure>
<p>示例 2:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入: [2,2,1,1,1,2,2]</span><br><span class="line">输出: 2</span><br></pre></td></tr></table></figure>
</li>
<li><p>解题思路</p>
<ul>
<li><p>确定切分的终止条件</p>
<p>直到所有的子问题都是长度为 1 的数组，停止切分。</p>
</li>
<li><p>准备数据，将大问题切分为小问题</p>
<p>递归地将原数组二分为左区间与右区间，直到最终的数组只剩下一个元素，将其返回</p>
</li>
<li><p>处理子问题得到子结果，并合并</p>
<ul>
<li>长度为 1 的子数组中唯一的数显然是众数，直接返回即可。</li>
<li>如果它们的众数相同，那么显然这一段区间的众数是它们相同的值。</li>
<li>如果他们的众数不同，比较两个众数在整个区间内出现的次数来决定该区间的众数</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="分治法解题代码"><a href="#分治法解题代码" class="headerlink" title="分治法解题代码"></a>分治法解题代码</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">majorityElement2</span><span class="params">(self, nums)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 【不断切分的终止条件】</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> nums:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> len(nums) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> nums[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># 【准备数据，并将大问题拆分为小问题】</span></span><br><span class="line">        left = self.majorityElement(nums[:len(nums)//<span class="number">2</span>])</span><br><span class="line">        right = self.majorityElement(nums[len(nums)//<span class="number">2</span>:])</span><br><span class="line">        <span class="comment"># 【处理子问题，得到子结果】</span></span><br><span class="line">        <span class="comment"># 【对子结果进行合并 得到最终结果】</span></span><br><span class="line">        <span class="keyword">if</span> left == right:</span><br><span class="line">            <span class="keyword">return</span> left</span><br><span class="line">        <span class="keyword">if</span> nums.count(left) &gt; nums.count(right):</span><br><span class="line">            <span class="keyword">return</span> left</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> right</span><br></pre></td></tr></table></figure>
<p>结果不太理想：</p>
<p><img src="/Pic/leetcode%E5%88%B7%E9%A2%98%E4%B8%93%E9%A2%98%E6%89%93%E5%8D%A1%E2%80%94%E2%80%94%E5%88%86%E6%B2%BB%E6%B3%95/result169.png" alt></p>
<h3 id="官方思路"><a href="#官方思路" class="headerlink" title="官方思路"></a>官方思路</h3><h4 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h4><p>我们使用哈希映射（HashMap）来存储每个元素以及出现的次数。对于哈希映射中的每个键值对，键表示一个元素，值表示该元素出现的次数。</p>
<p>我们用一个循环遍历数组 nums 并将数组中的每个元素加入哈希映射中。在这之后，我们遍历哈希映射中的所有键值对，返回值最大的键。我们同样也可以在遍历数组 nums 时候使用打擂台的方法，维护最大的值，这样省去了最后对哈希映射的遍历。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">majorityElement</span><span class="params">(self, nums)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line"></span><br><span class="line">        counts = collections.Counter(nums)</span><br><span class="line">        <span class="keyword">return</span> max(counts.keys(), key=counts.get)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/leetcode%E5%88%B7%E9%A2%98%E4%B8%93%E9%A2%98%E6%89%93%E5%8D%A1%E2%80%94%E2%80%94%E5%88%86%E6%B2%BB%E6%B3%95/result169_1.png" alt></p>
<h4 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h4><p>如果将数组 nums 中的所有元素按照单调递增或单调递减的顺序排序，那么下标为 $\lfloor \dfrac{n}{2} \rfloor$ 的元素（下标从 0 开始）一定是众数。Python实现更为简单：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">majorityElement</span><span class="params">(self, nums)</span>:</span></span><br><span class="line">        nums.sort()</span><br><span class="line">        <span class="keyword">return</span> nums[len(nums)//<span class="number">2</span>]</span><br></pre></td></tr></table></figure>
<p><strong>复杂度分析</strong></p>
<ul>
<li><p>时间复杂度：$O(n\log n)$。将数组排序的时间复杂度为 $O(n\log n)$。</p>
</li>
<li><p>空间复杂度：$O(\log n)$。如果使用语言自带的排序算法，需要使用$O(\log n)$的栈空间。如果自己编写堆排序，则只需要使用 $O(1)$ 的额外空间。</p>
</li>
</ul>
<p>运行结果很美丽：</p>
<p><img src="/Pic/leetcode%E5%88%B7%E9%A2%98%E4%B8%93%E9%A2%98%E6%89%93%E5%8D%A1%E2%80%94%E2%80%94%E5%88%86%E6%B2%BB%E6%B3%95/result169_2.png" alt></p>
<h4 id="随机化"><a href="#随机化" class="headerlink" title="随机化"></a>随机化</h4><p>因为超过$\lfloor \dfrac{n}{2}⌋$的数组下标被众数占据了，这样我们随机挑选一个下标对应的元素并验证，有很大的概率能找到众数。实现代码也很简单：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">majorityElement</span><span class="params">(self, nums)</span>:</span></span><br><span class="line">        majority_count = len(nums)//<span class="number">2</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            candidate = random.choice(nums)</span><br><span class="line">            <span class="keyword">if</span> sum(<span class="number">1</span> <span class="keyword">for</span> elem <span class="keyword">in</span> nums <span class="keyword">if</span> elem == candidate) &gt; majority_count:</span><br><span class="line">                <span class="keyword">return</span> candidate</span><br></pre></td></tr></table></figure>
<p><strong>复杂度分析</strong></p>
<p>时间复杂度：理论上最坏情况下的时间复杂度为$O(\infty)$，因为如果我们的运气很差，这个算法会一直找不到众数，随机挑选无穷多次，所以最坏时间复杂度是没有上限的。然而，运行的期望时间是线性的。为了更简单地分析，先说服你自己：由于众数占据超过数组一半的位置，期望的随机次数会小于众数占据数组恰好一半的情况。因此，我们可以计算随机的期望次数（下标为 prob 为原问题，mod 为众数恰好占据数组一半数目的问题）：</p>
<script type="math/tex; mode=display">\begin{aligned} E(iters_{prob})\le& E(iter_{mod})\\=&\lim_{n-\rightarrow\infty}\sum_{i=1}^ni\frac1{2^i}\\=&2\end{aligned}</script><p>计算方法为：当众数恰好占据数组的一半时，第一次随机我们有$\frac{1}{2}$的概率找到众数，如果没有找到，则第二次随机时，包含上一次我们有 $\frac{1}{4} $的概率找到众数，以此类推。因此期望的次数为$i * \frac{1}{2^i}$的和，可以计算出这个和为$2$，说明期望的随机次数是常数。每一次随机后，我们需要的时间判断这个数是否为众数，因此期望的时间复杂度为$O(n)$。</p>
<p>空间复杂度：$O(1)$。随机方法只需要常数级别的额外空间。</p>
<p>结果也不赖：</p>
<p><img src="/Pic/leetcode%E5%88%B7%E9%A2%98%E4%B8%93%E9%A2%98%E6%89%93%E5%8D%A1%E2%80%94%E2%80%94%E5%88%86%E6%B2%BB%E6%B3%95/result169_3.png" alt></p>
<h4 id="Boyer-Moore投票算法"><a href="#Boyer-Moore投票算法" class="headerlink" title="Boyer-Moore投票算法"></a>Boyer-Moore投票算法</h4><p>这个算法具体内容可以戳github官方解答，Boyer-Moore 算法的本质和分治十分类似。我们首先给出 Boyer-Moore 算法的详细步骤：</p>
<ul>
<li>我们维护一个候选众数 candidate 和它出现的次数 count。初始时 candidate 可以为任意值，count 为 0；</li>
<li><p>我们遍历数组 nums 中的所有元素，对于每个元素 x，在判断 x 之前，如果 count 的值为 0，我们先将 x 的值赋予 candidate，随后我们判断 x：</p>
<ul>
<li>如果 x 与 candidate 相等，那么计数器 count 的值增加 1；</li>
<li>如果 x 与 candidate 不等，那么计数器 count 的值减少 1。</li>
</ul>
</li>
<li><p>在遍历完成后，candidate 即为整个数组的众数。</p>
</li>
</ul>
<p>这个算法没有具体证明，但确实是空间复杂度和时间复杂度均最好的算法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">majorityElement</span><span class="params">(self, nums)</span>:</span></span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        candidate = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> nums:</span><br><span class="line">            <span class="keyword">if</span> count == <span class="number">0</span>:</span><br><span class="line">                candidate = num</span><br><span class="line">            count += (<span class="number">1</span> <span class="keyword">if</span> num == candidate <span class="keyword">else</span> <span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> candidate</span><br></pre></td></tr></table></figure>
<p><strong>复杂度分析</strong></p>
<ul>
<li><p>时间复杂度：$O(n)$。Boyer-Moore 算法只对数组进行了一次遍历。</p>
</li>
<li><p>空间复杂度：$O(1)$。Boyer-Moore 算法只需要常数级别的额外空间。</p>
</li>
</ul>
<p>执行结果也蛮牛逼的：</p>
<p><img src="/Pic/leetcode%E5%88%B7%E9%A2%98%E4%B8%93%E9%A2%98%E6%89%93%E5%8D%A1%E2%80%94%E2%80%94%E5%88%86%E6%B2%BB%E6%B3%95/result169_4.png" alt></p>
<h2 id="53-最大子序和"><a href="#53-最大子序和" class="headerlink" title="53. 最大子序和"></a><a href="https://leetcode-cn.com/problems/maximum-subarray/" target="_blank" rel="noopener">53. 最大子序和</a></h2><ul>
<li><p>题目描述</p>
<p>给定一个整数数组 <code>nums</code> ，找到一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。</p>
<p>示例:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入: [-2,1,-3,4,-1,2,1,-5,4],</span><br><span class="line">输出: 6</span><br><span class="line">解释: 连续子数组 [4,-1,2,1] 的和最大为6。</span><br></pre></td></tr></table></figure>
</li>
<li><p>解题思路</p>
<ul>
<li><p>确定切分的终止条件</p>
<p>直到所有的子问题都是长度为 1 的数组，停止切分。</p>
</li>
<li><p>准备数据，将大问题切分为小问题</p>
<p>递归地将原数组二分为左区间与右区间，直到最终的数组只剩下一个元素，将其返回</p>
</li>
<li><p>处理子问题得到子结果，并合并</p>
<ul>
<li>将数组切分为左右区间<ul>
<li>对与左区间：从右到左计算左边的最大子序和</li>
<li>对与右区间：从左到右计算右边的最大子序和</li>
</ul>
</li>
<li>由于左右区间计算累加和的方向不一致，因此，左右区间直接合并相加之后就是整个区间的和</li>
<li>最终返回左区间的元素、右区间的元素、以及整个区间(相对子问题)和的最大值</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="分治法解题代码-1"><a href="#分治法解题代码-1" class="headerlink" title="分治法解题代码"></a>分治法解题代码</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxSubArray</span><span class="params">(self, nums)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 【确定不断切分的终止条件】</span></span><br><span class="line">        n = len(nums)</span><br><span class="line">        <span class="keyword">if</span> n == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> nums[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 【准备数据，并将大问题拆分为小的问题】</span></span><br><span class="line">        left = self.maxSubArray(nums[:len(nums)//<span class="number">2</span>])</span><br><span class="line">        right = self.maxSubArray(nums[len(nums)//<span class="number">2</span>:])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 【处理小问题，得到子结果】</span></span><br><span class="line">        <span class="comment">#　从右到左计算左边的最大子序和</span></span><br><span class="line">        max_l = nums[len(nums)//<span class="number">2</span> <span class="number">-1</span>] <span class="comment"># max_l为该数组的最右边的元素</span></span><br><span class="line">        tmp = <span class="number">0</span> <span class="comment"># tmp用来记录连续子数组的和</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range( len(nums)//<span class="number">2</span><span class="number">-1</span> , <span class="number">-1</span> , <span class="number">-1</span> ):<span class="comment"># 从右到左遍历数组的元素</span></span><br><span class="line">            tmp += nums[i]</span><br><span class="line">            max_l = max(tmp ,max_l)</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 从左到右计算右边的最大子序和</span></span><br><span class="line">        max_r = nums[len(nums)//<span class="number">2</span>]</span><br><span class="line">        tmp = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nums)//<span class="number">2</span>,len(nums)):</span><br><span class="line">            tmp += nums[i]</span><br><span class="line">            max_r = max(tmp,max_r)</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 【对子结果进行合并 得到最终结果】</span></span><br><span class="line">        <span class="comment"># 返回三个中的最大值</span></span><br><span class="line">        <span class="keyword">return</span> max(left,right,max_l+ max_r)</span><br></pre></td></tr></table></figure>
<h2 id="50-Pow-x-n"><a href="#50-Pow-x-n" class="headerlink" title="50. Pow(x, n)"></a><a href="https://leetcode-cn.com/problems/powx-n/" target="_blank" rel="noopener">50. Pow(x, n)</a></h2><ul>
<li><p>题目描述</p>
<p>实现 <code>pow(x, n)</code>，即计算 <code>x</code> 的 <code>n</code> 次幂函数。</p>
<p>示例 1:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入: 2.00000, 10</span><br><span class="line">输出: 1024.00000</span><br></pre></td></tr></table></figure>
<p>示例 2:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入: 2.10000, 3</span><br><span class="line">输出: 9.26100</span><br></pre></td></tr></table></figure>
<p>示例 3:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入: 2.00000, -2</span><br><span class="line">输出: 0.25000</span><br><span class="line">解释: 2^-2 &#x3D; (1&#x2F;2)^2 &#x3D; 1&#x2F;4 &#x3D; 0.25</span><br></pre></td></tr></table></figure>
<p>说明:</p>
<p><code>-100.0 &lt; x &lt; 100.0</code> <code>n</code>是 32 位有符号整数，其数值范围是$[−2^{31}, 2^{31} − 1] $。</p>
</li>
<li><p>解题思路</p>
<ul>
<li><p>确定切分的终止条件</p>
<p>对<code>n</code>不断除以2，并更新<code>n</code>，直到为0，终止切分</p>
</li>
<li><p>准备数据，将大问题切分为小问题</p>
<p>对<code>n</code>不断除以2，更新</p>
</li>
<li><p>处理子问题得到子结果，并合并</p>
<ul>
<li><code>x</code>与自身相乘更新<code>x</code></li>
<li>如果$n\%2 ==1$<ul>
<li>将<code>p</code>乘以<code>x</code>之后赋值给<code>p</code>(初始值为1)，返回<code>p</code></li>
</ul>
</li>
</ul>
</li>
<li><p>最终返回<code>p</code></p>
</li>
</ul>
</li>
</ul>
<h3 id="分治法解题代码-快速幂-递归"><a href="#分治法解题代码-快速幂-递归" class="headerlink" title="分治法解题代码 (快速幂+递归)"></a>分治法解题代码 (快速幂+递归)</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">myPow</span><span class="params">(self, x, n)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type x: float</span></span><br><span class="line"><span class="string">        :type n: int</span></span><br><span class="line"><span class="string">        :rtype: float</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 处理n为负的情况</span></span><br><span class="line">        <span class="keyword">if</span> n &lt; <span class="number">0</span> :</span><br><span class="line">            x = <span class="number">1</span>/x</span><br><span class="line">            n = -n</span><br><span class="line">        <span class="comment"># 【确定不断切分的终止条件】</span></span><br><span class="line">        <span class="keyword">if</span> n == <span class="number">0</span> :</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 【准备数据，并将大问题拆分为小的问题】</span></span><br><span class="line">        <span class="keyword">if</span> n%<span class="number">2</span> ==<span class="number">1</span>:</span><br><span class="line">          <span class="comment"># 【处理小问题，得到子结果】</span></span><br><span class="line">          p = x * self.myPow(x,n<span class="number">-1</span>)<span class="comment"># 【对子结果进行合并 得到最终结果】</span></span><br><span class="line">          <span class="keyword">return</span> p</span><br><span class="line">        <span class="keyword">return</span> self.myPow(x*x,n/<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/leetcode%E5%88%B7%E9%A2%98%E4%B8%93%E9%A2%98%E6%89%93%E5%8D%A1%E2%80%94%E2%80%94%E5%88%86%E6%B2%BB%E6%B3%95/50_1.png" alt></p>
<h3 id="快速幂-迭代"><a href="#快速幂-迭代" class="headerlink" title="快速幂 + 迭代"></a>快速幂 + 迭代</h3><p>具体解析可以见<a href="https://leetcode-cn.com/problems/powx-n/solution/powx-n-by-leetcode-solution/" target="_blank" rel="noopener">Leetcode官方解答</a>，这里仅简要说明。</p>
<p>若</p>
<script type="math/tex; mode=display">n = 2^{i_0}+2^{i_1}+···+2^{i_k}</script><p>那么</p>
<script type="math/tex; mode=display">x^n = x^{2^{i_0}}*x^{2^{i_1}}*···*x^{2^{i_k}}</script><p>这样一来，我们从$x$开始不断平方，得到$x^2,x^4, x^8, x^{16},…$，如果$n$的第$k$个（从右往左数）二进制位为1，那么我们将对应的$x^{2^k}$计入答案累乘，代码实现为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">myPow</span><span class="params">(self, x: float, n: int)</span>:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">quickMul</span><span class="params">(N)</span>:</span></span><br><span class="line">            ans = <span class="number">1.0</span></span><br><span class="line">            <span class="comment"># 贡献的初始值为 x</span></span><br><span class="line">            x_contribute = x</span><br><span class="line">            <span class="comment"># 在对 N 进行二进制拆分的同时计算答案</span></span><br><span class="line">            <span class="keyword">while</span> N &gt; <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">if</span> N % <span class="number">2</span> == <span class="number">1</span>:</span><br><span class="line">                    <span class="comment"># 如果 N 二进制表示的最低位为 1，那么需要计入贡献</span></span><br><span class="line">                    ans *= x_contribute</span><br><span class="line">                <span class="comment"># 将贡献不断地平方</span></span><br><span class="line">                x_contribute *= x_contribute</span><br><span class="line">                <span class="comment"># 舍弃 N 二进制表示的最低位，这样我们每次只要判断最低位即可</span></span><br><span class="line">                N //= <span class="number">2</span></span><br><span class="line">            <span class="keyword">return</span> ans</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> quickMul(n) <span class="keyword">if</span> n &gt;= <span class="number">0</span> <span class="keyword">else</span> <span class="number">1.0</span> / quickMul(-n)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/leetcode%E5%88%B7%E9%A2%98%E4%B8%93%E9%A2%98%E6%89%93%E5%8D%A1%E2%80%94%E2%80%94%E5%88%86%E6%B2%BB%E6%B3%95/50.png" alt></p>
<p>参考链接：</p>
<ul>
<li><a href="https://github.com/datawhalechina/team-learning-program/blob/master/LeetCodeClassification/1.分治.md" target="_blank" rel="noopener">https://github.com/datawhalechina/team-learning-program/blob/master/LeetCodeClassification/1.%E5%88%86%E6%B2%BB.md</a></li>
<li><a href="https://leetcode-cn.com/problems/majority-element/solution/duo-shu-yuan-su-by-leetcode-solution/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/majority-element/solution/duo-shu-yuan-su-by-leetcode-solution/</a></li>
</ul>
]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
  </entry>
  <entry>
    <title>金融分析基础（十三）—— 双均线区间突破模型</title>
    <url>/posts/add9b4f4.html</url>
    <content><![CDATA[<h1 id="模型概述"><a href="#模型概述" class="headerlink" title="模型概述"></a>模型概述</h1><p>移动平均线有很好的方向性、稳定性和趋势性，通过对均线的金叉死叉以及多头排列等可以判断出做空进场的时机及趋势，但当行情出现震荡或无明显趋势时，双均线系统会产生假信号使我们最终产生亏损，这也是所有线性系统的致命缺陷。区间突破可以过滤一部分的震荡，但当趋势出现是往往会提早出场或者反向做单，因此它不具有明显的趋势性 和持仓的稳定性，因此结合线性以及区间的优点得到我们的双均线区间突破模型。</p>
<p><strong>策略要点</strong></p>
<ul>
<li>定义长短两条均线</li>
<li>计算均线的金叉死叉周期内的高低点</li>
<li>将均线系统与区间高低点结合使用</li>
</ul>
<blockquote>
<p>开仓条件：</p>
<ul>
<li>双均线多头排列且突破区间高点，开多</li>
<li>双均线空头排列且突破区间低点，开空</li>
</ul>
<p>平仓条件：</p>
<ul>
<li>跟踪止盈止损出场</li>
<li>趋势反转正反手出场</li>
</ul>
</blockquote>
<h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><p>在TB中编写如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Params</span><br><span class="line">    Numeric N1(14);</span><br><span class="line">    Numeric N2(31);</span><br><span class="line">	Numeric SS(1);</span><br><span class="line">	Numeric TR(4);</span><br><span class="line">Vars</span><br><span class="line">	BoolSeries condition1;</span><br><span class="line">	BoolSeries condition2;</span><br><span class="line">	BoolSeries condition3;</span><br><span class="line">	BoolSeries condition4;</span><br><span class="line">	BoolSeries condition5;</span><br><span class="line">	BoolSeries condition6;</span><br><span class="line">	NumericSeries var1;</span><br><span class="line">	NumericSeries var2;</span><br><span class="line">	NumericSeries bka;</span><br><span class="line">	NumericSeries bkx;</span><br><span class="line">	NumericSeries var3;</span><br><span class="line">	NumericSeries var4;</span><br><span class="line">	NumericSeries var3op;</span><br><span class="line">	NumericSeries var4op;</span><br><span class="line">	NumericSeries Myprice;</span><br><span class="line">	NumericSeries Myprice2;</span><br><span class="line">	NumericSeries Myprice3;</span><br><span class="line">	NumericSeries LowerAfterEntry;</span><br><span class="line">	NumericSeries HigherAfterEntry;</span><br><span class="line">Begin</span><br><span class="line">	var1 &#x3D; Average(C[1], N1);&#x2F;&#x2F;短周期均线</span><br><span class="line">	var2 &#x3D; Average(C[1], N2);&#x2F;&#x2F;中周期均线</span><br><span class="line">	</span><br><span class="line">	condition1 &#x3D; CrossOver(var1, var2);&#x2F;&#x2F;金叉</span><br><span class="line">	condition2 &#x3D; CrossUnder(var1, var2);&#x2F;&#x2F;死叉</span><br><span class="line">	</span><br><span class="line">	If(condition1)&#123;</span><br><span class="line">		bka &#x3D; CurrentBar;</span><br><span class="line">	&#125;</span><br><span class="line">	If(condition2)&#123;</span><br><span class="line">		bkx &#x3D; CurrentBar;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	var3 &#x3D; Highest(H[1],(bka-bkx)+1);&#x2F;&#x2F;计算本次金叉至上次死叉的时间范围内的高点</span><br><span class="line">	var4 &#x3D; Lowest(L[1], (bkx-bka)+1);&#x2F;&#x2F;计算本次死叉至上次金叉的时间范围内的低点</span><br><span class="line">	</span><br><span class="line">	condition3 &#x3D; condition1 and bka&gt;bkx and bka&gt;0 and bkx&gt;0 and CurrentBar&gt;0;&#x2F;&#x2F;当均线金叉同时满足bka&gt;bkx且bka与bkx都不为0时条件3成立（多头条件）</span><br><span class="line">	If(condition3)&#123;</span><br><span class="line">		var3op &#x3D; var3;&#x2F;&#x2F;条件3成立时将var3赋值给var3op，保存金叉时的最高点到全局变量var3op里</span><br><span class="line">	&#125;</span><br><span class="line">	condition4 &#x3D; condition2 and bkx&gt;bka and bka&gt;0 and bkx&gt;0 and CurrentBar&gt;0;&#x2F;&#x2F;当均线死叉同时满足bkx&gt;bka且bka与bkx都不为0时条件3成立（多头条件）</span><br><span class="line">	If(condition4)&#123;</span><br><span class="line">		var4op &#x3D; var4;&#x2F;&#x2F;条件4成立时将var4赋值给var4op，保存死叉时的最低点到全局变量var4op里</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	condition5 &#x3D; var1 &gt; var2 and CrossOver(C[1], var3op);&#x2F;&#x2F;当短周期均线大于中周期均线且价格突破最高点条件成立</span><br><span class="line">	If(condition5 and MarketPosition&lt;&gt;1)&#123;</span><br><span class="line">		Myprice &#x3D; Open;&#x2F;&#x2F;保存本根bar的开盘价</span><br><span class="line">		Buy(SS, Myprice);&#x2F;&#x2F;按开盘价开多头</span><br><span class="line">		LowerAfterEntry &#x3D; EntryPrice;&#x2F;&#x2F;保存多头开仓价格</span><br><span class="line">	&#125;</span><br><span class="line">	condition6 &#x3D; var1 &lt; var2 and CrossUnder(C[1], var4op);&#x2F;&#x2F;当短周期均线小于中周期均线且价格突破最低点条件成立</span><br><span class="line">	If(condition6 and MarketPosition&lt;&gt;-1)&#123;</span><br><span class="line">		Myprice &#x3D; open;&#x2F;&#x2F;保存本根bar的开盘价</span><br><span class="line">		SellShort(SS, Myprice);&#x2F;&#x2F;按开盘价开空头</span><br><span class="line">		HigherAfterEntry &#x3D; EntryPrice;&#x2F;&#x2F;保存空头开仓价格</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	&#x2F;&#x2F;跟踪止盈止损，记录多头最低价和空头最高价</span><br><span class="line">	If(MarketPosition&#x3D;&#x3D;1 and BarsSinceEntry&#x3D;&#x3D;0)&#123;&#x2F;&#x2F;有多头持仓，刚进场时的本根bar线序号</span><br><span class="line">		HigherAfterEntry &#x3D; HigherAfterEntry[1];</span><br><span class="line">		LowerAfterEntry &#x3D; Max(LowerAfterEntry,low);&#x2F;&#x2F;多头出场的参考价格</span><br><span class="line">	&#125;</span><br><span class="line">	If(MarketPosition&#x3D;&#x3D;-1 and BarsSinceEntry&#x3D;&#x3D;0)&#123;&#x2F;&#x2F;有空头持仓，刚进场时的本根bar线序号</span><br><span class="line">		HigherAfterEntry &#x3D; Min(HigherAfterEntry, High);</span><br><span class="line">		LowerAfterEntry &#x3D; LowerAfterEntry[1];</span><br><span class="line">	&#125;</span><br><span class="line">	If(MarketPosition&lt;&gt;0 and BarsSinceEntry&gt;&#x3D;1)&#123;&#x2F;&#x2F;不再是本根bar线</span><br><span class="line">		HigherAfterEntry &#x3D; Min(HigherAfterEntry, High);</span><br><span class="line">		LowerAfterEntry &#x3D; Max(LowerAfterEntry,low);</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	&#x2F;&#x2F;执行部分，跟踪出场</span><br><span class="line">	</span><br><span class="line">	Myprice2 &#x3D; LowerAfterEntry - Open * TR &#x2F; 100;&#x2F;&#x2F;多头出场线</span><br><span class="line">	PlotNumeric(&quot;Myprice2&quot;, Myprice2);</span><br><span class="line">	If(MarketPosition&#x3D;&#x3D;1 and Low&lt;&#x3D;Myprice2 and BarsSinceEntry&gt;0);&#123;&#x2F;&#x2F;当持有多头持仓，最新价格跌破止损线，同时平仓信号和开仓信号不在同一跟bar线</span><br><span class="line">		Myprice2 &#x3D; Min(Myprice2, Open);&#x2F;&#x2F;如果跳空击破，取值最新的bar线的开盘价，若不是，去出场线价格</span><br><span class="line">		Sell(SS, Myprice2);&#x2F;&#x2F;多头平仓</span><br><span class="line">		Commentary(&quot;多头出场&quot;);</span><br><span class="line">	&#125;</span><br><span class="line">	Myprice3 &#x3D; HigherAfterEntry + Open + TR &#x2F; 100;</span><br><span class="line">	PlotNumeric(&quot;Myprice3&quot;, Myprice3);</span><br><span class="line">	If(MarketPosition &#x3D;&#x3D; -1 and High &gt;&#x3D; Myprice3 and BarsSinceEntry &gt; 0)&#123;&#x2F;&#x2F;当空头持仓，最新价格突破出场线，同时平仓信号和开仓信号不在同一根bar线</span><br><span class="line">		Myprice3 &#x3D; Max(Myprice3, Open);&#x2F;&#x2F;如果跳空击破，取值最新的bar线的开盘价，若不是，去出场线价格</span><br><span class="line">		BuyToCover(SS, Myprice3);&#x2F;&#x2F;空头平仓</span><br><span class="line">		Commentary(&quot;空头出场&quot;);</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">End</span><br></pre></td></tr></table></figure>
<p>大家可以跑一下结果看看情况~</p>
]]></content>
      <categories>
        <category>Quantitative Investment</category>
      </categories>
  </entry>
  <entry>
    <title>金融量化分析基础（十二）—— 短线突破交易策略剖析</title>
    <url>/posts/2957980b.html</url>
    <content><![CDATA[<p>短线突破策略来自Larry Williams《短线交易秘诀》一书中价格波动突破——动能的突破一章。</p>
<h1 id="《短线交易秘诀》原文"><a href="#《短线交易秘诀》原文" class="headerlink" title="《短线交易秘诀》原文"></a>《短线交易秘诀》原文</h1><p>趋势是从我称之为“价格活动的爆炸点”开始的。更明确地说，假如价格在一小时、一天、一周、一月中，<strong>发生爆炸性的上扬或下挫</strong>，市场就会持续朝那个方向前进，<strong>直到有一股等量或更大的相反爆炸性力量出现为止</strong>，这就是众所周知的价格波动扩张，或称“波动突破”，这是道格·布利根据我1980年的早期著作所创造的概念。</p>
<p>它的意思是说，价格从中心点产生一股爆炸性突破，由此建立了整个趋势。在此我们会遇到两个问题：第一，<strong>什么是爆炸性突破（向上或向下的变动幅度要多大）；第二，我们要选择哪一点作为衡量价格扩张的起点。</strong></p>
<p>采用<strong>每日区间的价差</strong>，即每日最高价与最低价的差距。这个数值可以代表市场每天的波动幅度，只有当波动幅度超过近期波幅，趋势才会发生变化。用昨日区间做比较较为准确。例如，昨日大麦的区间价差是12美分，如果今天的价差区间超出12美分某个百分点，趋势大概就会改变了，至少我们值得赌它会改变。这清楚地代表着价格受到某些新刺激朝着某个方向变动的轨迹。价格就像其他物体，有了动力之后就会向某个方向前进。</p>
<p>这样的结论引出第二个问题：我们要从哪一点开始来衡量价格扩张的变动是向上还是向下？ </p>
<p>大多数交易员都认为我们应该从今天的收盘价开始算起。这是很典型的想法,我们通常是用收盘价衡量价格的变动,但这不是正确的答案。我等一下会讨论这点,先让我们考虑应该用哪些点来衡量扩张的起点。我的结论是,<strong>最适合加减某个波动扩张值的价格点是明天的开盘价</strong>。我一向都使用这个开盘价的技巧来进行交易。<br>我们可以用这种方式来发现另一可能让我们获利的价格扩张机会。我不会因为发现这种技术就马上进行交易,而会在时机合适的时候,用它做为判断是否进场的技巧。</p>
<p>所有我了解的进场技巧,从移动平均线到趋势线,到振荡指标,以及颇受欢迎的简单数学表格等等,从来没有一个系统化的进场技巧比价格波动突破更能让人持续获利。这是我进行买卖交易、研究或所见过的所有交易中,最经常采用的一种技巧。现在让我们来看看使用这基本观念的几个方法。</p>
<p><strong>简单的每日区间突破模式</strong></p>
<p>从前面的叙述里,我们已经知道应该把突破的价值幅度加到明天的开盘价位上。现在问题出现了,最佳的价值幅度应该是多少？有很多数值都很好,<strong>但最简单的一种就是把今日区间的某个比重加到明天的开盘价</strong>。我在20年前初次发现这个简单的方法,之后就经常用它赚到钱。<br>灵活而善于推理的交易员应该提出：“在看涨的日子里,能不能在更接近价格波动扩张的地方买进；在看跌的日子里,我们是否可以选择更低的价位进场？至于出场时机,是否能在上涨或下跌趋势明显的日子持有仓位更久？这样的问题可能会没完没了,但仍必须提出来,以便让绩效达到更好。”</p>
<p><strong>如何观察价格波动</strong></p>
<p>第三种衡量价格潜在波动扩张的方法,是<strong>观察价格在过去几天内波动的情形</strong>。麦克·查立克用一套他设计并命名为“鹰爪”的系统来诠释这个概念,其基本概念就是<strong>观察过去几年来价格从某一点到下一点之间的波动状态</strong>。可供作研究的这类时点相当多。</p>
<p>我观察市场活动所用的方法第一步是,衡量3天前最高点到今天最低点之间的价格变动量；第二步是用一天前最高点减去3天前的最低点,算出波动的差距；最后,以这些数据中的最大值作为价格波动的衡量基准,然后设计出价格的缓冲值,以做为明天开盘价的加项（买价）或减项（卖价）。</p>
<p>这套系统表现还不错：由1982年至1998年间标准普尔500指数期货的表现结果来看,它是赚钱的。其规则为：在超过开盘价位80％的波动价值之处买进；在低于开盘价120％的波动价值处卖出,用1750美元作为止损点,认赔杀出。这套系统从1982年到1998年间赚了122837美元,每笔交易平均获利228美元。</p>
<p><strong>如何表现得更好</strong></p>
<p>通常大家总是会问,我们可以表现的更好吗？我们能做得更好的最后一招就是<strong>用每周交易日作筛选来大幅提升绩效</strong>。现在先跳过这一点并引进一个基本面的参考量：<strong>债券价格对股价的影响</strong>。</p>
<p>现在试着把这项观念当成是一个过滤器。规则很简单,只要今天的债券收盘价高于5天前的价格,就是买进信号；而当债券价格低于35天前的价格时,则是卖出信号。我们的理由是建立在常识之上：<strong>债券价格较高时表示股市看涨；债券价格较低时表示股市看跌</strong>。</p>
<p>这样作的结果差异很大！平均每笔交易的获利由228美元升高到281美元,而最大平仓亏损金额从13025美元陡降到5250美元。但最棒的是,在原先采用“没有过滤”的交易当中,最惨的时候输掉8150美元,但此处以债券为过滤器之后,最大的损失不过是2075美元而已！</p>
<p><strong>更进一步的思考</strong></p>
<p>假如你能够提出下面这个问题,那你差不多就可以出师了：如果债券市场已经帮我们确认了股市是处于多头或空头,此时如果我们采用每周交易日的最佳信号从事交易,那么结果将会如何？</p>
<p>再一次的结果是事实胜于雄辩：将所有的资料组合起来,我们赢得短线交易的机会会更大。请注意交易笔数是大幅下降,这表示我们暴露在风险中的机会变小,而每笔交易的平均获利却增加了。我们的利润虽然降到76400美元,但每笔平均获利跳升到444美元,最大平仓亏损金额维持在5921美元的水准,但获利的比率则高达90％。</p>
<p>我们在这里所做的,是把不符合我们三项条件的交易全都过滤出来。在短期波动中,利用这种过滤后的方式进行交易,可以让你比其他短线交易员更早一、两年享受清闲的生活。而且这有额外的好处：你可以通过使用过滤的方式把交易的需求交给市场做决定。这意味着你无须每天都做交易,自然而然地会迫使你减少交易的次数。积极的交易员往往是输家,挑选时机进场投机的人更有机会成为赢家,因为我们把筹码放在对我们有利的地方,这才算是智慧的投机。</p>
<h1 id="短线区间突破策略"><a href="#短线区间突破策略" class="headerlink" title="短线区间突破策略"></a>短线区间突破策略</h1><p>我们可以对Larry的策略做一些改进，得到以下思路：</p>
<blockquote>
<p><strong>价格开盘后突破昨日振幅的一定比例</strong>并且<strong>今日高点高于昨日最高价</strong>则开多</p>
<p><strong>浮盈达到止损幅度的N倍</strong>或<strong>价格跌破开仓日的开盘价</strong>则平多</p>
</blockquote>
]]></content>
      <categories>
        <category>Quantitative Investment</category>
      </categories>
  </entry>
  <entry>
    <title>金融量化分析基础（十一）—— 大小周期双频率策略</title>
    <url>/posts/f41ee879.html</url>
    <content><![CDATA[<div id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <div class="hbe-input-container">
  <input type="password" id="hbePass" placeholder="" />
    <label for="hbePass">Hey, password is required here.</label>
    <div class="bottom-line"></div>
  </div>
  <script id="hbeData" type="hbeData" data-hmacdigest="abdf1dc46d1019e864c768b57921563146c8e2b59baffb46aef50eca64cd896b">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</script>
</div>
<script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>Quantitative Investment</category>
      </categories>
  </entry>
  <entry>
    <title>金融量化分析基础（十）—— 程序化交易实战问题及对策</title>
    <url>/posts/b7b393e5.html</url>
    <content><![CDATA[<h1 id="实盘与回测结果的偏离"><a href="#实盘与回测结果的偏离" class="headerlink" title="实盘与回测结果的偏离"></a>实盘与回测结果的偏离</h1><p>我们在网络上常见到各种几百块钱就能买到一个回测很漂亮的策略，激动地准备实现财富自由。但开始真金白银地去交易时，就不是那么回事儿了。其实用脚指头想一想，有这么好的策略为什么卖家不自己用，反而只卖几百块？</p>
<p>容易想到的问题就是：</p>
<ol>
<li>指数与合约价格的偏离<ul>
<li>指数是各个合约加权平均产生的结果，指数显得更光滑，是加权平均数，噪音比较小，常会好于合约价格</li>
<li>实际交易时只能用 合约不能用指数</li>
<li>减小指数与合约间的误差的方法：用合约配比来模拟指数</li>
</ul>
</li>
<li>低估交易成本（滑点、佣金、手续费等）<ul>
<li>滑点影响最大，非正规平台往往有更高的滑点和交易成本，尤其是交易现货的平台</li>
<li>开仓越频繁，交易成本越高</li>
</ul>
</li>
<li>止损止盈价格的陷阱</li>
</ol>
<p>上面讲了实盘与回测的区别，关于回测时本身可能出现的问题下面也一一列举了：</p>
<h2 id="为什么要回测"><a href="#为什么要回测" class="headerlink" title="为什么要回测"></a>为什么要回测</h2><p>我们首先来看一下什么叫做回测。回测就是基于历史数据，尽可能真实地还原实际交易过程，并检验交易策略绩效的过程。这样做有三个目的：</p>
<ol>
<li><p>验证交易信号的准确度；</p>
</li>
<li><p>验证交易逻辑和你的想法是否可行；</p>
</li>
<li><p>发现交易系统中的缺陷，并改进原始策略。</p>
</li>
</ol>
<hr>
<h2 id="回测陷阱之信号闪烁"><a href="#回测陷阱之信号闪烁" class="headerlink" title="回测陷阱之信号闪烁"></a>回测陷阱之信号闪烁</h2><p>交易策略在回测时是基于静态的历史数据。而真实的交易的数据是动态的。举个例子：如果最高价大于昨天的收盘价就买入开仓。这个开仓条件在实盘中，如果K线还未走完，那么最高价就是动态的，交易信号就有可能来回闪烁。而在回测时，回测引擎是基于静态的历史数据是可以模拟撮合成交的。</p>
<hr>
<h2 id="回测陷阱之未来函数"><a href="#回测陷阱之未来函数" class="headerlink" title="回测陷阱之未来函数"></a>回测陷阱之未来函数</h2><p>未来函数是用到了未来的价格，也就是说当前的条件在未来可能会被修改，同样未来函数也能造成信号闪烁的原因。所以任何函数都具有未来函数特性，比如说 Z 字函数。</p>
<hr>
<h2 id="回测陷阱之偷价"><a href="#回测陷阱之偷价" class="headerlink" title="回测陷阱之偷价"></a>回测陷阱之偷价</h2><p>　　所谓偷价行为是指利用过去的价格去交易。举个例子：如果最高价大于某个固定价位即以开盘价买入。这个条件就是在偷价格，因为在实盘中，最高价大于某个价位时，价格已经高于开盘价一定距离了，这时用开盘价是买不到的。但在回测中，是有买入信号的，并且能成交。</p>
<p>　　还有一种情况，如果价格跳空高开与策略设定的固定价格，回测时可以以固定价格成交，但是在实盘中这个固定价格显然是买不到的。</p>
<hr>
<h2 id="回测陷阱之不可能成交的价格"><a href="#回测陷阱之不可能成交的价格" class="headerlink" title="回测陷阱之不可能成交的价格"></a>回测陷阱之不可能成交的价格</h2><p>不能成交的价格分为几种情况：</p>
<ul>
<li>在实盘中，涨停时一般情况下是买不到的，反过来跌停也是如此。但是在回测中却是可以成交的。</li>
<li>交易所撮合机制是：价格优先、时间优先。有些品种盘口会经常有巨量订单，实盘时如果挂单买卖，需要等待盘口厚度，才能成交甚至不能成交。但是在回测时，挂单买卖是可以成交的。比如下面这张图的盘口厚度：</li>
</ul>
<p><img src="/../../Desktop/1/1.jpg" alt="img"></p>
<ul>
<li><p>如果套利类策略，那么回测利润是很高的，因为回测时每次都已经假设了抢到了这些价差。真实的情况下，很多价差都抢不到，或者只抢到了一条腿，一般来说肯定是不利于你的方向的那条先成交，那么就需要马上去补另一条腿，这时候滑点已经不是1、2个点了，而套利策略本身就赚这几个点的价差，这种情况是回测中无法模拟的。真实利润完全不如回测。</p>
</li>
<li><p>黑天鹅事件。如下图红圈处，在外汇瑞郎黑天鹅事件中，尽管表面上看有开盘价、最高价、最低价、收盘价，其实当天的极端行情中，中间的价格是真空，大量的止损单，造成踩踏事件，流动性为零，成交难度非常大，但是在回测中却能止损。</p>
</li>
</ul>
<p><img src="/../../Desktop/1/2.jpg" alt="img"></p>
<hr>
<h2 id="回测陷阱之过度拟合"><a href="#回测陷阱之过度拟合" class="headerlink" title="回测陷阱之过度拟合"></a>回测陷阱之过度拟合</h2><p><img src="/../../Desktop/1/3.jpg" alt="img"></p>
<p>针对量化交易来说，回测是基于历史数据，但历史数据的样本是有限的，如果交易策略的参数过多，或者交易逻辑过于复杂，导致交易策略过多的适应历史数据。</p>
<p>量化策略的建模过程本质上就是一个从大量的貌似随机的数据中找寻局部非随机数据的过程，如果不借助统计学的知识，很容易落入过度拟合的陷阱。</p>
<p><img src="/../../Desktop/1/4.jpg" alt="img"></p>
<p>　　如果说天文学星座是一阶过拟合的话，那么星座性格学说是二阶过拟合。</p>
<p><img src="/../../Desktop/1/5.jpg" alt="img"></p>
<p>所以，不要自欺欺人。如果发现样本外数据表现不好，又觉得丢掉模型太可惜或者不愿意承认自己这个模型不行，而对着样本外数据继续做模型优化，直到样本外数据上也表现得一样好，那最后受伤的一定是你的真金白银。</p>
<hr>
<h2 id="回测陷阱之幸存者偏差"><a href="#回测陷阱之幸存者偏差" class="headerlink" title="回测陷阱之幸存者偏差"></a>回测陷阱之幸存者偏差</h2><p>　　举个通俗的例子来解释什么是幸存者偏差：</p>
<p>　　1、某宝卖降落伞的商品都是好评。因为降落伞有问题的人都不存在了。</p>
<p>　　2、某电台记者在高铁上采访乘客是否买到车票。因为买不到车票的人根本上不了车。</p>
<p>　　3、媒体宣传买彩票可以中大奖。因为媒体不会宣传没有中奖的人。</p>
<p>　　4。站在风口，猪都会飞。</p>
<p>　　通过上面例子可以看到，实际上人们接受到的信息其实是经过筛选后的结果，因此生存者偏差造成的结果就是往往一开始就有大量的数据或样本被忽略了，导致基于生存者偏差的结论偏离实际。</p>
<p>　　那么在量化回测中，就要小心了。回测的结果也有其运气成分，许多情况下回测出来的结果，可能是在众多次数的回测中表现较好的一次。</p>
<p><img src="/../../Desktop/1/6.jpg" alt="img"></p>
<p>　　金融市场中明星多、寿星少。如果交易者的策略刚好与市场行情契合，那么每年的行情就能造就一些明星。但是很难见到连续 3 年以上持续稳定盈利的寿星。</p>
<p>　　作为一个交易者，不管是量化交易也好，还是手工交易也好。都要扪心自问，自己的盈利究竟是来自于好运气，还是能力。往往许多人把自己的好运气当做自己的能力。</p>
<hr>
<h2 id="回测陷阱之小样本统计"><a href="#回测陷阱之小样本统计" class="headerlink" title="回测陷阱之小样本统计"></a>回测陷阱之小样本统计</h2><p>　　尽管拥有庞大数据的历史，但面对浩瀚无尽且不可预测的未来，历史数据就显得极度匮乏。即便是以现有的全部历史数据来验证，交易策略也不能被证实，但是可以被证伪，那么在证伪策略的时候，就需要尽量多的历史数据，来证伪策略本身。而不是拿很小样本的测试来说明问题。</p>
<hr>
<h2 id="回测陷阱之点差"><a href="#回测陷阱之点差" class="headerlink" title="回测陷阱之点差"></a>回测陷阱之点差</h2><p>　　盯过盘的都知道，买一价和卖一价的价格是至少一个点差的，不活跃的品种点差会更大，如果在发生信号后保证成交，得以对手价去下单，一般和信号模拟价相比要损失一个点差左右的，所以在写交易模型编写时必须要扣除点差，特别是在写交易频率较高的日内模型时特别重要，好多这类策略都是如果没有计算点差，那测试报告的资金曲线几乎是一根笔直的斜向上的直线，一旦加上点差，立马变为亏损。</p>
<hr>
<h2 id="回测陷阱之冲击成本"><a href="#回测陷阱之冲击成本" class="headerlink" title="回测陷阱之冲击成本"></a>回测陷阱之冲击成本</h2><p>　　无论多么精细的回测引擎，其回测只是基于在静态数据，很难模拟出真实的交易环境。举个例子：下单价格是1050买入，但实际成交价可能是1051。造成这种现象的原理有很多，比如：极端行情时流动性真空、网络延迟、软硬件系统、服务器响应等。</p>
<p>不加滑点回测：</p>
<p><img src="/../../Desktop/1/7.jpg" alt="img"></p>
<p>加滑点回测：</p>
<p><img src="/../../Desktop/1/8.jpg" alt="img"></p>
<p>　　但是在回测中是理想环境，没有价格冲击成本，回测时的成交就是1050。特别是高频或短线策略，想象一下，在回测中成千上万次交易，其回测结果也是不真实的。如下图：</p>
<p><img src="/../../Desktop/1/9.jpg" alt="img"></p>
<hr>
<h2 id="回测陷阱之风险收益比"><a href="#回测陷阱之风险收益比" class="headerlink" title="回测陷阱之风险收益比"></a>回测陷阱之风险收益比</h2><p>　　交易策略的几何年化收益率/最大回撤的比值在2以上。对于一些粗糙模型，在单个品种上很难让几何年化收益率/最大回撤这个比值大于2，如果在相关度低的多品种上进行组合投资，使组合投资报告上的几何年化收益率/最大回撤这个比值大于2，也是可以的。</p>
<p>下面的策略长期能赚钱，那才不正常。</p>
<p><img src="/../../Desktop/1/10.jpg" alt="img"></p>
<p><img src="/../../Desktop/1/11.jpg" alt="img"></p>
<h1 id="仓位多少合适"><a href="#仓位多少合适" class="headerlink" title="仓位多少合适"></a>仓位多少合适</h1><h2 id="轻仓重仓，无法一概而论"><a href="#轻仓重仓，无法一概而论" class="headerlink" title="轻仓重仓，无法一概而论"></a>轻仓重仓，无法一概而论</h2><p>在实战交易中，有的人偏好一直轻仓，从容应对，风险第一。有的人喜欢偶尔重仓，有的放矢，重锤出击。</p>
<p>量化之王西蒙斯，由于交易标的分散，所以对单个标的的仓位实行轻仓，而金融巨鳄索罗斯却相反，对狙击英镑，泰铢等战役，都是重仓押注。巴菲特的老师格雷厄姆，通过持有大量股票，每个股票都极其轻仓的方法来分散风险，进行获利。</p>
<p>而股神巴菲特则反其道而行之，对深入研究看好的公司，进行集中重仓，这才有了现在千亿美金的财富，用巴菲特自己的话说，从分散到集中的转变，如同自己从猿人进化到了人类。</p>
<p>我们在实际的外汇交易过程中，仓位也没有教科书般的标准答案，因为仓位和交易者的心理承受能力，和交易系统有关，所以在不同的人眼里，有着不同的理解。</p>
<h2 id="凯利公式计算仓位"><a href="#凯利公式计算仓位" class="headerlink" title="凯利公式计算仓位"></a>凯利公式计算仓位</h2><p>凯利公式：$F = P-\frac{1-P}{B}$，$P$为胜率，$B$为赔率（盈亏比），根据凯利公式可以算出每一次交易止损位应放在哪里。例如$P=35\%$，$B=2$，则$F = 0.35-\frac{0.6}2 = 5\%$，也就是每次最大允许$5\%$的亏损</p>
<p>想要具体了解可以看<a href="https://www.fxeye.com/201901286504347500.html" target="_blank" rel="noopener">参考链接3</a>，其中讲述了最常用的7种仓位控制方法。</p>
<h1 id="过多追求胜率"><a href="#过多追求胜率" class="headerlink" title="过多追求胜率"></a>过多追求胜率</h1><ul>
<li>胜率不是越高越好</li>
<li>过度追求胜率往往导致过拟合</li>
</ul>
<blockquote>
<p>“就专业交易员而言，其获利交易百分率经常低于40%”                 ———-《高级技术分析》</p>
<p>“如果期货外汇交易有20％的成功率，那他就非常走运了。”        ———-《操盘建议—全球顶尖交易员的成功实践和心路历程》</p>
<p>“任何人进入金融市场，如果他预期将有一半以上的交易会获利，这项预期会被很粗鲁的惊醒。”        ———-《专业投机原理》</p>
</blockquote>
<p><strong>如何提高盈亏比才是赚钱关键？</strong></p>
<p>盈亏比是滞后指标，等你做了很多交易以后，你统计了自己的盈亏比大概是多少。这时你才会知道自己盈亏比大概是多少。</p>
<p>所以我们入场，很难以盈亏比来指导。你能赚多少，是市场给的，不是你算出来的。如果强制性设置盈亏比，很可能盈利变亏损，也可能踏空行情。笔者认为相对而言，设置止损容易，盈利后合理的盈利出场点更难，给出几个建议：</p>
<ol>
<li><p>因此应该按你的交易系统做好交易计划，在你所遵循的行情判断的走势发生变化时按照止盈出场。</p>
</li>
<li><p>根据交易计划盈利后，建议将成本线设置为强制出场点，保证至少不亏损。</p>
</li>
<li><p>有一定的浮盈空间，可以适度拿盈利博取更大的行情，扩大盈亏比！再结合自身情况进行匹配选择，最终慢慢完善自己的交易体系！坚持执行，保证交易的一致性！</p>
</li>
</ol>
<h1 id="缺乏规则的主观干预"><a href="#缺乏规则的主观干预" class="headerlink" title="缺乏规则的主观干预"></a>缺乏规则的主观干预</h1><ul>
<li>规则时程序化交易的精髓</li>
<li>主管干预的结果通常不如不干预（长期来看）</li>
</ul>
<p>可以看看这篇访谈：<a href="http://ds.hexun.com/article/detail_96.html" target="_blank" rel="noopener">王阳军：必须要相信自己的策略，不要人为主观地去干预它</a></p>
<h1 id="长假日是否要减仓或平仓"><a href="#长假日是否要减仓或平仓" class="headerlink" title="长假日是否要减仓或平仓"></a>长假日是否要减仓或平仓</h1><ul>
<li>用历史回测来检验是否需要减仓</li>
<li>减仓或平仓往往效果不如不减（长期实盘交易来看）</li>
</ul>
<p>参考链接：</p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/31373112" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/31373112</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/111789502" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/111789502</a></li>
<li><a href="https://www.fxeye.com/201901286504347500.html" target="_blank" rel="noopener">https://www.fxeye.com/201901286504347500.html</a></li>
<li><a href="https://www.jianshu.com/p/74e6c8a93eb2" target="_blank" rel="noopener">https://www.jianshu.com/p/74e6c8a93eb2</a></li>
</ul>
]]></content>
      <categories>
        <category>Quantitative Investment</category>
      </categories>
  </entry>
  <entry>
    <title>金融量化分析基础（九）—— 如何平滑收益曲线</title>
    <url>/posts/167437d7.html</url>
    <content><![CDATA[<h1 id="什么是平滑"><a href="#什么是平滑" class="headerlink" title="什么是平滑"></a>什么是平滑</h1><p>先来看两个曲线。</p>
<p><img src="/../../Desktop/1" alt="img"></p>
<p><img src="/../../Desktop/2" alt="img"></p>
<p>很明显，下面的曲线更好。上面的曲线也是盈利的曲线，可为什么看起来会有这样明显的差别？原因就在于<strong>回撤小</strong>，所以下面的曲线更加平滑。</p>
<h1 id="平滑曲线常用的方式"><a href="#平滑曲线常用的方式" class="headerlink" title="平滑曲线常用的方式"></a>平滑曲线常用的方式</h1><p>我们平滑收益曲线通常用是三种方式：多元化、仓位控制与资产曲线管理。</p>
<h2 id="多元化"><a href="#多元化" class="headerlink" title="多元化"></a>多元化</h2><p>注意：相关程度越低越好，负相关效果更好</p>
<ul>
<li>多品种：操作品种的多少。品种间关联程度低，可以进行风险对冲的更平滑。例如只操作黄金一个商品，和同时操作黄金、咖啡、日元和沪深300指数这个投资组合相比，在稳定盈利的前提下，一般是后面的组合收益曲线更平滑。尽管股票、商品、汇率、利率等市场也会存在同涨同跌的情形，但毕竟不同品类会出现“板块轮动”，涨跌的节奏不会完全一样。此消彼长之间，收益曲线就会平滑一些。</li>
<li>多策略：不同的策略加载在同一个品种（多个不同品种）上</li>
<li>多参数：参数的最佳区域是随时间改变的，永远不知道哪个参数效果最好，可以在策略上 加载多套参数，总体而言 不会太差（到处撒网不至于网网空）</li>
<li>多周期：同一个策略可以应用在不同周期二点图表上（找出哪些周期可以利用这一策略使收益为正），可以试着用不常用（非整数）的周期</li>
<li>多市场：可以进行多市场组合，如国别地区、股票期货，对资金和知识要求较高</li>
</ul>
<h3 id="多品种的权重分配（头寸分配与调整）"><a href="#多品种的权重分配（头寸分配与调整）" class="headerlink" title="多品种的权重分配（头寸分配与调整）"></a>多品种的权重分配（头寸分配与调整）</h3><ul>
<li>等合约价值：每个合约都有一定价值，让权重配置能使两种品种的合约价值相等</li>
<li>等保证金金额：与等合约价值类似</li>
<li>等风险分配：在设置止损位时使得每个交易品种的止损金额相等</li>
<li>等最大回撤：在历史回撤报告中可找出每个品种的最大回撤，根据历史最大回撤数值找到最大公倍数从而分配权重 </li>
<li>等单跳价值</li>
</ul>
<h2 id="仓位控制（根本）"><a href="#仓位控制（根本）" class="headerlink" title="仓位控制（根本）"></a>仓位控制（根本）</h2><ul>
<li>凯利公式：$F = P-\frac{1-P}B$，其中$P$为胜率，$B$为赔率（盈亏比），$F$为下注金额（在期货交易中体现为每一手交易应该设置的止损位，每次交易应该允许的最大损失）。赌博与期货使用情况不同需要调整</li>
<li>操作仓位的轻重。轻仓的更平滑。例如：每次用1%的资本冒险，开仓错了，资金回撤1%；每次用10%的资本冒险，开仓错了，资金回撤10%。将10%的资金用于一个品种，和50%的资金用于一个品种，在市场出现不利波动时，回撤幅度自然也是不一样的。在命中率和回报比确定的前提下，风险资金比例越大，持仓仓位越重，回撤越大，就这么简单。</li>
</ul>
<h2 id="资产曲线管理"><a href="#资产曲线管理" class="headerlink" title="资产曲线管理"></a>资产曲线管理</h2><ul>
<li><p>若策略有失效的可能，或行情对走势不利则暂停做交易，若对策略很有信息相信资产曲线会重新走上支撑位，就在这个期间等待，不再进行交易，从而避免较大的回撤，使得交易曲线更光滑。在突破前期高点红线的位置重新做交易。</p>
</li>
<li><p>资产收益曲线在每次往下回撤10%到15%之后必定会有一波上涨，可以平时不交易，关注模拟盘中的资产收益曲线，当资产曲线往下回撤10-15%后开始交易，当资产曲线又增长了10-15%就停止交易</p>
</li>
</ul>
<h1 id="曲线平滑真的那么令人高兴吗"><a href="#曲线平滑真的那么令人高兴吗" class="headerlink" title="曲线平滑真的那么令人高兴吗"></a>曲线平滑真的那么令人高兴吗</h1><p>现在我们的问题是：平滑的资金曲线真的是一件令人高兴的事吗？如果你还在追求减少回撤，你会觉得平滑的曲线确实是好事。但当身临其境时，也许并非如此。</p>
<p>平滑的收益曲线意味着回撤幅度更小，但资金增长的幅度同样变得平滑。</p>
<ul>
<li>当你轻仓的时候，资金在增长，你会不会后悔，“早知道多进一点了”？</li>
<li>当你采取多品种对冲策略时候，手中的组合大赚小赔，你会不会后悔，“早知道会止损，就不动某某品种了”？</li>
</ul>
<p>亏损令人感到沮丧，少赚也会让人沮丧。这种沮丧就像惦记着该买没买又开出了大奖的彩票，挥之不去，余音不绝。</p>
<p>因此，当你在追求小幅度回撤的时候，当你在为着平滑的曲线努力的时候，有必要想清楚，能不能抵抗上面两种感受带来的失落和沮丧？那是平滑的代价，也是利润对风险的妥协。事实上我们应该追求两件事：</p>
<ul>
<li><strong>首先，搞清楚适合自己的MDD%（Max Drawdown），然后努力控制住它。</strong></li>
</ul>
<p>一般来讲，无论什么样的风险偏好，这个比值以不超过30%为宜。30%的浮亏对于回本来讲需要实现43%左右的盈利，比亏损幅度高出了40个百分点。超过这个水平，回本难度变大，浮亏基本就是“被套”了。</p>
<p>控制MDD%的方法有很多。比如，随着浮亏的加大，逐级降低R值；设立警戒线，必要时停止交易，通过无风险品种获取固定收益弥补亏损后继续操作；多品种小仓位操作不同市场的不同品种，对冲波动风险等。这些方法不一而足，但背后有一个共同的逻辑：<strong>控制好你的交易冲动和欲望</strong>。</p>
<ul>
<li><strong>其次，在自己能接受的MDD%水平上尽量将收益率最大化，找到盈利的方法，努力提高MAR比值。</strong></li>
</ul>
<p>要结合最大回撤比确定交易策略。你确定的MDD%只有5%，那么就不要动用2成仓位以上的资金；你确定的MDD%可以到达25%，那么可以适当的下重手，以2%的R值去交易。总之，无论怎么设计、规划，确定MDD%以后再找方法。</p>
<p>交易的目的不在于收益率，而在于保持一致性。<strong>通过保持一致性，确保稳定的MAR比值。这才是我们追求“平滑的收益曲线/资金曲线”背后的东西。</strong></p>
<p>参考链接：</p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/19832895" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/19832895</a></li>
<li>人人宽客量化交易课程</li>
</ul>
]]></content>
      <categories>
        <category>Quantitative Investment</category>
      </categories>
  </entry>
  <entry>
    <title>金融量化分析基础（八）—— 量化策略交易风险防范</title>
    <url>/posts/7224cc4c.html</url>
    <content><![CDATA[<p>量化交易此种交易模式最显著的缺点就是，如果指数往一个方向发生显著变化，数量巨大且量化运算模式相似的量化基金会在同一时间段触发，造成短时间内指数价格大幅度向此方向发生变化。 面对此情景，就非常有必要探讨金融市场量化交易策略和风险，这对有效降低极端行情的发生有着至关重要的作用。<strong>量化交易一定会失效，不同的只是时间长短</strong>，因此我们需要判断量化交易策略何时失效。</p>
<h1 id="量化交易的策略"><a href="#量化交易的策略" class="headerlink" title="量化交易的策略"></a>量化交易的策略</h1><h2 id="趋势动量类策略"><a href="#趋势动量类策略" class="headerlink" title="趋势动量类策略"></a>趋势动量类策略</h2><p>趋势动量类策略的内在含义主要是以市场均衡理论为根本，<strong>在一个事件发生后，市场将达到供需的新平衡</strong>，这个周期就形成了原始趋势。</p>
<p>在价格趋于平稳阶段，因为市场参与者所获取的信息在时间上存在着一定的延迟，以及受到的情感上的影响，所以其价格一般来讲就不会发生变化。量化投资者通过对统计手段的利用，然后充分的挖掘量价数据，从而以某些特别指定因子变化的概率分布为基础，最终将某类资产价格计算出来，并通过对这些统计量和仓位管理算法的密切联系来实施交易的策略。</p>
<p>此种类型的算法和大部分数量化策略并无差异，其可以在把握好长尾风险的同时，借由长期交易来实现累积收益的目标。其根<strong>本内涵在于经济中个体的从众跟风心理</strong>，在现如今备受关注的行为金融学中，市场投资决策者在面对突然事件时，过于注重眼前信息的原理，在技术分析法中也有着非常高的使用概率。</p>
<h2 id="均值回归类策略"><a href="#均值回归类策略" class="headerlink" title="均值回归类策略"></a>均值回归类策略</h2><p>均值回归策略有着较强的适用性，在动量策略中所提到的驱使会在相应周期内发生多头行情或者空头行情的现象， 以此来对短期内来回交易次数过多的情况实施改进，其根本内涵在于价格需要和价值呈正比，<strong>从长远分析来看价格始终 围绕着价值在来回发生变化</strong>，即存在长期偏离正常价格的可能性，大多数情况下会在相应时间内表现出<strong>基差收敛的特征</strong>。通过对此特征的利用，量化投资者不但能够通过定价模型将 资产长期价值的均值和价格偏离的情况计算出来，而且<strong>在超过一定阈值时通过做多或做空某资产价格的方法，从而等待其对价值的收敛</strong>。</p>
<p>但因为在定价资产价格的过程中会受到不同原因的影响，所以配对交易就自然而然地成为在实战中应用性非常强的一种交易策略。如在权益市场当中，将埃克森美孚和福特组成风险中性的配对交易，在大宗商品交易场所中， 可将玉米和大豆当成一组均值回归的交易对象，假如其价格对比另一价格偏离大于阈值，<strong>卖出过高估计价格的资产并看好等价的价格低谷的资产，等待价差收敛</strong>。</p>
<p>基本来讲，<strong>套利策略也称之为回归型策略</strong>，如跨期等其实从根本来看都可以归之为对标产品合约，创建配对交易组合，可以获取广泛的应用，但由于交易机会如跨期等实质上都属于为寻找对标产品合约，建立配对交易组合，此类策略有着众多的应用，但因为交易机会暴露 时间过短，所以就经常需要借助技术的支持，以便可以加快交易的速度，从而在交易上占据绝对性的优势。</p>
<h2 id="技术情绪"><a href="#技术情绪" class="headerlink" title="技术情绪"></a>技术情绪</h2><p>技术情绪策略，实质上主要是<strong>通过行为金融学知识和技术方法的有机联系，从而最大程度上寻找和发现市场中隐藏的基本规律</strong>，如期权市场通过对历史平均水平相对变化的观察，来将其作为市场情绪指标，然后再依据历史基准水平的情况来评估市场情绪的情况。</p>
<p>另外，针对限价订单薄，高频量交易者可实施进一步的研究，然后通过充分的挖掘众多历史订单薄数据，从而预先推知多空博弈在未来一段周期内所带给市场价格的变化。此种交易主要应用在市商中，做市商通过对价格的变现来实现盈利的目标。</p>
<p>技术情绪类策略经常是对某种情况的深层次挖掘，并无特殊规定的模式。虽然价格变化在整个过程中贯穿，但这并不代表价格并不存在缺口的情况，即一旦出现两根相邻 k 线的趋势，就会发生上述的结果。 此种缺口主要是指股的开盘价使 K 线图发生空档的情况，然后当成趋势操作的信号，一旦发生跳空缺口回补就可清仓停止损失时停止盈利。</p>
<h1 id="量化交易的风险"><a href="#量化交易的风险" class="headerlink" title="量化交易的风险"></a>量化交易的风险</h1><h2 id="在历史数据的选用上容易出现幸存者偏差"><a href="#在历史数据的选用上容易出现幸存者偏差" class="headerlink" title="在历史数据的选用上容易出现幸存者偏差"></a>在历史数据的选用上容易出现幸存者偏差</h2><p>由于权益投资市场中向外提供的公司股票数据，大部分是当前上市公司的股票，而在投资决策模型中，反而并没有将 一些未持续经营公司作为训练数据输入到其中，显而易见，这是一种缺乏对关键步骤重视的表现，而如此一来，就出现了回溯测试和实盘交易两者之间结果偏差的情况。</p>
<h2 id="数据来源的风险（未来函数）"><a href="#数据来源的风险（未来函数）" class="headerlink" title="数据来源的风险（未来函数）"></a>数据来源的风险（未来函数）</h2><p>在训练以往各时间段K线走势图时需要注意尽量不要出现将未知变量当成已知因子的情况，随着数据获取的区域越来越大，所以此种情况很难发现，由此就需要交易员增强对不同类型数据来源的认识。</p>
<p>如公司发布的年报季报、国家每年发布的CPI、GDP、基尼系数、恩格尔系数等， 其审核后的发布时间均明显后于统计描述时间，这样的结果极易造成对特定发布时间的忽视。针对此种情况，就可以通过检查清单来避免此种风险的发生。</p>
<h2 id="拟合风险"><a href="#拟合风险" class="headerlink" title="拟合风险"></a>拟合风险</h2><p>在模型训练过程中，经常会应用到一些机器学习算法，但采取这些手段极易产生拟合风险，特别是在一些研究方向训练数据中比较少，所以就需要进一步提升模型的泛化能力。</p>
<p>如参数项设置的越简单，那么就预示着其模型也并无明显的复杂性，有着非常高的泛化能力，不但如此，其算法欠拟合程度也会得到较好的改善，降低预测价格的能力，而这就离不开策略开发工作者的支持，依据模型的情况来寻找最佳的平衡点。</p>
<h2 id="交易成本风险"><a href="#交易成本风险" class="headerlink" title="交易成本风险"></a>交易成本风险</h2><p>事实上对于量化交易而言，手续费等交易成本对其有着不可或缺的作用，所以就非常有必要设置独立的成本函数，然后评估每次开仓信号的预期收益和成本间的关系，过度的开仓会增加成本，而过于严格的开仓条件，则不可避免地会减少交易数量，进而导致交易频率在整个交易中发生明显地变化。</p>
<p>其实，量化交易的本质在于借由概率，最终对盈利情况进行统计，在小交易样本下，产品的投资回报率更多情况下极易会受到长尾的干扰，致使预测无法顺利地进行。</p>
<h2 id="市场风格分形风险"><a href="#市场风格分形风险" class="headerlink" title="市场风格分形风险"></a>市场风格分形风险</h2><p>交易策略的差异性，极易受到市场风格分形的影响，如均值回归策略和趋势跟踪策略就是最好的例子，即前者在震荡市中有着更为显著的收益，而后者则更适宜于在牛市和熊市中。</p>
<h1 id="策略失效"><a href="#策略失效" class="headerlink" title="策略失效"></a>策略失效</h1><h2 id="怎样判断策略失效"><a href="#怎样判断策略失效" class="headerlink" title="怎样判断策略失效"></a>怎样判断策略失效</h2><ul>
<li>最大回撤判断：大于历史最大回撤的150%</li>
<li>收益曲线走势判断</li>
</ul>
<h2 id="突发行情的止损与取舍"><a href="#突发行情的止损与取舍" class="headerlink" title="突发行情的止损与取舍"></a>突发行情的止损与取舍</h2><ul>
<li>峰值止损：当价格变动超过某个峰值立刻停止，但不能判断随后又迅速拉回的情形</li>
<li>均值止损：会参考几条K线，看一段时间内的价格变化确定是否止损，反应不那么快，是看一段时间的行情</li>
<li>速率止损：考虑价格变化幅度与变化时间，兼顾了前两者</li>
</ul>
<p>上面三种各有优缺点，交易者可以根据自己对市场的理解与交易品种的特征决定止损方式，或者做一个组合得到自认为最优的止损方案。</p>
<h2 id="跟踪止盈止损的陷阱"><a href="#跟踪止盈止损的陷阱" class="headerlink" title="跟踪止盈止损的陷阱"></a>跟踪止盈止损的陷阱</h2><p>常见的看似很优秀的量化策略常面临跟踪止盈止损的陷阱，这体现在实盘效果永远比回测效果差，我们应当如何防范跟踪止盈止损的陷阱，有以下亮点：</p>
<ul>
<li>回落幅度不能设置过小</li>
<li>在不影响策略运行的情况下，尽量使用小周期的K线</li>
</ul>
<h2 id="量化策略风险防范"><a href="#量化策略风险防范" class="headerlink" title="量化策略风险防范"></a>量化策略风险防范</h2><ul>
<li>指数与合约的不同步误差：在量化策略中，无论是回测还是调试通常都是使用某一商品的指数，交易时是交易商品的具体合约，这两者之间存在误差！</li>
<li>交易成本：交易所需手续费；期货公司佣金；软件平台费用；滑点成本；云端服务器租金；数据费用 ；税金；心理成本</li>
<li>软硬件事故</li>
</ul>
<h3 id="交易成本"><a href="#交易成本" class="headerlink" title="交易成本"></a>交易成本</h3><h4 id="滑点成本"><a href="#滑点成本" class="headerlink" title="滑点成本"></a>滑点成本</h4><p>对于交易而言，最大的成本来自于手续费和滑点。中长线交易对这点成本很无所谓，别小看这点成本，对于短线客来说，几次下来对利润有很大吞噬。手续费不说了，要找到想的对便宜的交易商，可以多了解本行业，或者做个居间人代理，手续费相对低一些。</p>
<p><strong>滑点是指客户下单交易点位与实际交易点位有差别的一种交易现象</strong>。很多人知道什么叫滑点，但是至于滑点是怎么产生的就不知道了。有的人说行情变化大时，所以有滑点；甚至有人因此说，不滑点是不可能的，其实这不正确。正确的说法是滑点要么是交易商故意的，要么是交易商服务跟不上。</p>
<p>第一是人为方面的因素，比如黄金交易商后台人为操控，使得黄金交易平台行情报价与实际报价存在差别，从而导致黄金白银交易者在该买入的时候没有及时买入，卖出的时候没有及时卖出。一般来说投资者很难分辨滑点是由什么因素造成的，因此也就给一些不良交易商带来了获取不正当利益的机会。</p>
<p>第二是硬件方面的因素，比如黄金价bai格行情波动剧烈时，网络延迟，软件系统以及服务器响应等方面造成成交价格与挂单价格不一致。</p>
<h4 id="股票投资增值税"><a href="#股票投资增值税" class="headerlink" title="股票投资增值税"></a>股票投资增值税</h4><p>投资收益要区分不同的情况，投资国债的投资收益是免交税的，其他的投资如股权投资等是要纳税的；对于分回的投资收益还必须确认是税前的还是税后的。如果是税后的，一是要看被投资企业的企业所得税率是否与公司的税率相同，若相同则不用补交若，不同(被投资企业税率小于公司)则要按差价补税。如果是税前的，分回后并入公司的利润缴税。</p>
<p>投资收益下交增值税的有关情况：</p>
<ol>
<li><p>公司取得投资收益，应该按25%的税率缴纳企业所得税。</p>
</li>
<li><p>投资所分的利润、利息、股息、红利所得。投资收益在税收上是作为企业所得税的应税项目，应依法计征企业所得税。</p>
</li>
</ol>
<h3 id="如何防范软硬件事故"><a href="#如何防范软硬件事故" class="headerlink" title="如何防范软硬件事故"></a>如何防范软硬件事故</h3><ul>
<li>租用云服务器</li>
<li>建立应急预案</li>
<li>建立监督报警机制</li>
<li>随时可以用手机登陆账户进行操作</li>
<li>关注交易平台的群消息</li>
</ul>
<p>参考链接：</p>
<ul>
<li>魏平.金融市场量化交易策略与风险探讨[J].现代营销(下旬刊),2020(01):37-38.</li>
</ul>
]]></content>
      <categories>
        <category>Quantitative Investment</category>
      </categories>
  </entry>
  <entry>
    <title>金融量化分析基础（七）—— 避免未来函数</title>
    <url>/posts/3e13cfa8.html</url>
    <content><![CDATA[<div id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <div class="hbe-input-container">
  <input type="password" id="hbePass" placeholder="" />
    <label for="hbePass">Hey, password is required here.</label>
    <div class="bottom-line"></div>
  </div>
  <script id="hbeData" type="hbeData" data-hmacdigest="ab277805dcf7eda2f20dfb15a51729ae7b0cc00f6f5a7f7d78f1dcf19eb34db0">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</script>
</div>
<script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>Quantitative Investment</category>
      </categories>
  </entry>
  <entry>
    <title>金融量化分析基础（六）—— 常用的止损止盈方法</title>
    <url>/posts/9e920d41.html</url>
    <content><![CDATA[<div id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <div class="hbe-input-container">
  <input type="password" id="hbePass" placeholder="" />
    <label for="hbePass">Hey, password is required here.</label>
    <div class="bottom-line"></div>
  </div>
  <script id="hbeData" type="hbeData" data-hmacdigest="3aec92fdf9e25bdc82204d29ac1d2bc6b3c30a9d5145ca1dbbc7d986fd78e19f">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</script>
</div>
<script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>Quantitative Investment</category>
      </categories>
  </entry>
  <entry>
    <title>金融量化分析基础（五）—— 策略优化的方法与陷阱</title>
    <url>/posts/3d4d876a.html</url>
    <content><![CDATA[<div id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <div class="hbe-input-container">
  <input type="password" id="hbePass" placeholder="" />
    <label for="hbePass">Hey, password is required here.</label>
    <div class="bottom-line"></div>
  </div>
  <script id="hbeData" type="hbeData" data-hmacdigest="1b63082c8946ae6d1cb85e9c9158f4214f74b1fcc6c5daf41fae051c85cc7f7e">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</script>
</div>
<script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>Quantitative Investment</category>
      </categories>
  </entry>
  <entry>
    <title>金融量化分析基础（四）—— 回测报告分析</title>
    <url>/posts/ba7b3298.html</url>
    <content><![CDATA[<div id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <div class="hbe-input-container">
  <input type="password" id="hbePass" placeholder="" />
    <label for="hbePass">Hey, password is required here.</label>
    <div class="bottom-line"></div>
  </div>
  <script id="hbeData" type="hbeData" data-hmacdigest="e5538000ba79ac948228a0365cce75173f94a48dd1a65c30f78718eccfeca1ac">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</script>
</div>
<script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>Quantitative Investment</category>
      </categories>
  </entry>
  <entry>
    <title>金融量化分析基础（三）—— 高频交易</title>
    <url>/posts/135a295c.html</url>
    <content><![CDATA[<div id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <div class="hbe-input-container">
  <input type="password" id="hbePass" placeholder="" />
    <label for="hbePass">Hey, password is required here.</label>
    <div class="bottom-line"></div>
  </div>
  <script id="hbeData" type="hbeData" data-hmacdigest="27ff3043b8f627760a37717da44d659d9d514012cd02c4692049d98d29c4b6a1">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</script>
</div>
<script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>Quantitative Investment</category>
      </categories>
  </entry>
  <entry>
    <title>金融量化分析基础（二）—— 套利</title>
    <url>/posts/12d4b8eb.html</url>
    <content><![CDATA[<div id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <div class="hbe-input-container">
  <input type="password" id="hbePass" placeholder="" />
    <label for="hbePass">Hey, password is required here.</label>
    <div class="bottom-line"></div>
  </div>
  <script id="hbeData" type="hbeData" data-hmacdigest="0e536ea5ad66ccd0c1c0c399aa03b5f3e7be1456618bef1e7df7ecdfc0151fa4">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</script>
</div>
<script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>Quantitative Investment</category>
      </categories>
  </entry>
  <entry>
    <title>金融量化分析基础（一）—— 名词大赏</title>
    <url>/posts/4250a155.html</url>
    <content><![CDATA[<h1 id="股票"><a href="#股票" class="headerlink" title="股票"></a>股票</h1><ul>
<li>股票是股份公司发给出资人的一种凭证，股票的持票者就是股份公司的股东</li>
<li>股票的面值与市值：<ul>
<li>面值表示票面金额</li>
<li>市值表示市场价值</li>
</ul>
</li>
<li>上市/IPO：企业通过证券交易所公开向社会增发股票以募集资金</li>
<li><p>股票的作用</p>
<ul>
<li>出资证明、证明股东身份、对公司经营发表意见</li>
<li>公司分红、交易获利</li>
</ul>
</li>
<li><p>股票的分类</p>
<ul>
<li>股票按业绩分类：<ul>
<li>蓝筹股：资本雄厚、信誉优良的公司的股票</li>
<li>绩优股：业绩优良的公司的股票</li>
<li>ST股：特别处理股票，连续两年亏损或每股净 资产低于股票面值</li>
</ul>
</li>
<li>股票按上市地区分类<ul>
<li>A股：中国大陆上市，人民币认购买卖（T+1，涨跌幅10%）</li>
<li>B股：中国大陆上市，外币认购买卖（T+1，T+3）</li>
<li>H股：中国香港上市（T+0，涨跌幅不做限制）</li>
<li>N股：美国纽约上市</li>
<li>S股：新加坡 上市</li>
</ul>
</li>
</ul>
</li>
<li><p>股票市场的构成</p>
<ul>
<li>上市公司</li>
<li>投资者（包括机构投资者）</li>
<li>证监会、证券业协会、交易所<ul>
<li>上海证券交易所：只有一个主板（沪指 ）</li>
<li>深圳证券交易所：<ul>
<li>主板：大型成熟企业（深成指）</li>
<li>中小板：经营规模较小</li>
<li>创业板：尚处于成长期的创业企业</li>
</ul>
</li>
</ul>
</li>
<li>证券中介机构</li>
</ul>
</li>
<li><p>影响股价的因素</p>
<ul>
<li>市场内部因素</li>
<li>基本面因素</li>
<li>政策因素</li>
</ul>
</li>
<li><p>股票买卖</p>
<ul>
<li>委托买卖股票：个人不能直接买卖，需要在券商开户，进行委托购买</li>
<li>股票交易日：周一到周五（非法定节假日和交易所休市日）</li>
<li>股票交易时间：<ul>
<li>9：15-9：25    开盘集合竞价时间</li>
<li>9：30-11：30   前市，连续竞价时间</li>
<li>13：00-15：00    后市，连续竞价时间</li>
<li>14：57-15：00    深交所收盘集合竞价时间</li>
</ul>
</li>
<li>T+1交易制度：股票买入后当天不能卖出，要在买入后的下一个交易日才能卖出</li>
</ul>
</li>
</ul>
<h1 id="金融分析"><a href="#金融分析" class="headerlink" title="金融分析"></a>金融分析</h1><ul>
<li>基本面分析<ul>
<li>宏观经济基本面分析：国家的财政政策、货币政策等</li>
<li>行业分析</li>
<li>公司分析：财务数据、业绩报告</li>
</ul>
</li>
<li>技术面分析：各项技术指标<ul>
<li>K线</li>
<li>平均线</li>
<li>KDJ</li>
<li>MACD</li>
</ul>
</li>
</ul>
<h1 id="金融量化投资"><a href="#金融量化投资" class="headerlink" title="金融量化投资"></a>金融量化投资</h1><ul>
<li>量化投资：利用计算机技术并且采用一定的数学模型去实践投资理念，实现投资策略的过程</li>
<li><p>量化投资的优势：</p>
<ul>
<li>避免主观情绪、人性弱点和认知偏差，选择更加客观</li>
<li>能同时包括多角度的观察和多层次的模型</li>
<li>及时跟踪市场变化，不断发现新的统计模型，寻找交易机会</li>
<li>再决定投资策略后，能通过 回测验证其效果</li>
</ul>
</li>
<li><p>量化策略：通过一套固定的逻辑来分析、判断和决策，自动化地进行股票交易</p>
<ul>
<li>核心内容：<ul>
<li>选股</li>
<li>择时</li>
<li>仓位管理</li>
<li>止盈止损</li>
</ul>
</li>
<li>策略的周期<ul>
<li>产生想法</li>
<li>实现策略</li>
<li>检验策略：回测、模拟交易</li>
<li>实盘交易</li>
<li>优化策略、放弃策略</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>Quantitative Investment</category>
      </categories>
  </entry>
  <entry>
    <title>HOG特征描述算子-行人检测</title>
    <url>/posts/91c329d0.html</url>
    <content><![CDATA[<h1 id="HOG特征"><a href="#HOG特征" class="headerlink" title="HOG特征"></a>HOG特征</h1><h2 id="HOG特征概述"><a href="#HOG特征概述" class="headerlink" title="HOG特征概述"></a>HOG特征概述</h2><p>方向梯度直方图（Histogram of Oriented Gradient, HOG）特征是一种在计算机视觉和图像处理中用来进行物体检测的特征描述子。它通过计算和统计图像局部区域的梯度方向直方图来构成特征。Hog特征结合SVM分类器已经被广泛应用于图像识别中，尤其在行人检测中获得了极大的成功。需要提醒的是，HOG+SVM进行行人检测的方法是法国研究人员Dalal在2005的CVPR上提出的，而如今虽然有很多行人检测算法不断提出，但基本都是以HOG+SVM的思路为主。</p>
<p><strong>主要思想</strong></p>
<p>在一副图像中，局部目标的表象和形状（appearance and shape）能够被梯度或边缘的方向密度分布很好地描述。（本质：梯度的统计信息，而梯度主要存在于边缘的地方）。</p>
<p><strong>具体的实现方法</strong></p>
<p>首先将图像分成小的连通区域，我们把它叫细胞单元（胞元）。然后采集细胞单元中各像素点的梯度的或边缘的方向直方图。最后把这些直方图组合起来就可以构成特征描述器。</p>
<p><strong>提高性能</strong></p>
<p>把这些局部直方图在图像的更大的范围内（我们把它叫区间或block）进行对比度归一化（contrast-normalized），所采用的方法是：先计算各直方图在这个区间（block）中的密度，然后根据这个密度对区间中的各个细胞单元做归一化。通过这个归一化后，能对光照变化和阴影获得更好的效果。</p>
<p><strong>优点</strong></p>
<ul>
<li>由于HOG是在图像的局部方格单元上操作，所以它对图像几何的和光学的形变都能保持很好的不变性，这两种形变只会出现在更大的空间领域上；</li>
<li>在粗的空域抽样、精细的方向抽样以及较强的局部光学归一化等条件下，只要行人大体上能够保持直立的姿势，可以容许行人有一些细微的肢体动作，这些细微的动作可以被忽略而不影响检测效果。因此HOG特征是特别适合于做图像中的人体检测的。</li>
</ul>
<h2 id="HOG特征提取方法"><a href="#HOG特征提取方法" class="headerlink" title="HOG特征提取方法"></a>HOG特征提取方法</h2><p>大体来说，首先对输入的图片进行预处理，然后计算像素点的梯度特特性，包括梯度幅值和梯度方向。然后投票统计形成梯度直方图，然后对blocks进行normalize，最后收集到HOG feature（其实是一行多维的vector）放到SVM里进行监督学习，从而实现行人的检测。</p>
<p><img src="/posts/CV/hog1.png" alt></p>
<p>将上述过程拆分如下，下面分别进行讲解。</p>
<h3 id="灰度化（将图像看做一个-x-y-z-（灰度）的三维图像）；"><a href="#灰度化（将图像看做一个-x-y-z-（灰度）的三维图像）；" class="headerlink" title="灰度化（将图像看做一个$x,y,z$（灰度）的三维图像）；"></a>灰度化（将图像看做一个$x,y,z$（灰度）的三维图像）；</h3><ul>
<li>灰度处理是可选操作，因为灰度图像和彩色图像都可以用于计算梯度图。对于彩色图像，先对三通道颜色值分别计算梯度，然后取梯度值最大的那个作为该像素的梯度。</li>
</ul>
<h3 id="采用Gamma校正法对输入图像进行颜色空间的标准化（归一化）"><a href="#采用Gamma校正法对输入图像进行颜色空间的标准化（归一化）" class="headerlink" title="采用Gamma校正法对输入图像进行颜色空间的标准化（归一化）"></a>采用Gamma校正法对输入图像进行颜色空间的标准化（归一化）</h3><p><strong>目的是调节图像的对比度，降低图像局部的阴影和光照变化所造成的影响，同时可以抑制噪音的干扰；</strong></p>
<ul>
<li>伽马矫正公式：$f(I)=I^{\gamma}$，其中$I$表示原图像<ul>
<li>当$\gamma&lt;1$时，输入图像的低灰度值区域动态范围变大，进而图像低灰度值区域对比度得以增强；在高灰度值区域，动态范围变小，进而图像高灰度值区域对比度得以降低。 最终，图像整体的灰度变亮。</li>
<li>当$\gamma&gt;1$时，输入图像的高灰度值区域动态范围变小，进而图像低灰度值区域对比度得以降低；在高灰度值区域，动态范围变大，进而图像高灰度值区域对比度得以增强。 最终，图像整体的灰度变暗。</li>
<li>比如可以取$\gamma=\frac12$</li>
</ul>
</li>
</ul>
<p>灰度图转化以及Gamma校正处理代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv2.imread(<span class="string">'*.png'</span>, <span class="number">0</span>)</span><br><span class="line">img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)</span><br><span class="line">img2 = np.power(img/float(np.max(img)),<span class="number">1</span>/<span class="number">2.2</span>)</span><br><span class="line">plt.imshow(img2)</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="计算图像每个像素的梯度（包括大小和方向）"><a href="#计算图像每个像素的梯度（包括大小和方向）" class="headerlink" title="计算图像每个像素的梯度（包括大小和方向）"></a>计算图像每个像素的梯度（包括大小和方向）</h3><p><strong>主要是为了捕获轮廓信息，同时进一步弱化光照的干扰。</strong></p>
<ul>
<li>为了得到梯度直方图，那么首先需要计算图像水平方向和垂直方向梯度。一般使用特定的卷积核对图像滤波实现，可选用的卷积模板有：soble算子、Prewitt算子、Roberts模板等等。一般采用soble算子，OpenCV也是如此，最常用的方法是：首先用$[-1,0,1]$梯度算子对原图像做卷积运算，得到$x$方向（水平方向，以向右为正方向）的梯度分量gradscalx，然后用$[1,0,-1]^T$梯度算子对原图像做卷积运算，得到$y$方向（竖直方向，以向上为正方向）的梯度分量gradscaly。然后再用以上公式计算该像素点的梯度大小和方向。</li>
<li><p>利用soble水平和垂直算子与输入图像卷积计算$dx、dy$的计算方式为：</p>
<script type="math/tex; mode=display">Sobel_X=\begin{bmatrix}1\\0\\-1\end{bmatrix}*\begin{bmatrix}1&2&1\end{bmatrix}=\begin{bmatrix}1&2&1\\0&0&0\\-1&-2&-1\end{bmatrix}\\Sobel_X=\begin{bmatrix}1\\2\\1\end{bmatrix}*\begin{bmatrix}1&0&-1\end{bmatrix}=\begin{bmatrix}1&0&-1\\2&0&-2\\1&0&-1\end{bmatrix}</script><script type="math/tex; mode=display">d_x=f(x,y)*Sobel_X(x,y)\\
d_y=f(x,y)*Sobel_Y(x,y)</script><p>或者更广泛地说：</p>
<script type="math/tex; mode=display">d_x=H(x+1,y)-H(x-1,y)</script><script type="math/tex; mode=display">d_y=H(x,y+1)-H(x,y-1)</script><p>其中$H(x,y)$为像素点$(x,y)$处的像素值。</p>
</li>
<li><p>进一步可以得到图像梯度的幅值：</p>
<script type="math/tex; mode=display">M(x,y)=\sqrt{d_x^2(x,y)+d_y^2(x,y)}</script><p>为了简化计算，幅值也可以作如下近似：</p>
<script type="math/tex; mode=display">M(x,y)=|d_x(x,y)|+|d_y(x,y)|</script><p>而梯度方向为：</p>
<script type="math/tex; mode=display">\alpha(x,y)=tan^{-1}(\frac{G_y(x,y)}{G_x(x,y)})</script></li>
<li><p>计算梯度代码如下：</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Read image</span></span><br><span class="line">img = cv2.imread(<span class="string">'*.jpg'</span>)</span><br><span class="line">img = np.float32(img) / <span class="number">255.0</span>  <span class="comment"># 归一化</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算x和y方向的梯度</span></span><br><span class="line">gx = cv2.Sobel(img, cv2.CV_32F, <span class="number">1</span>, <span class="number">0</span>, ksize=<span class="number">1</span>)</span><br><span class="line">gy = cv2.Sobel(img, cv2.CV_32F, <span class="number">0</span>, <span class="number">1</span>, ksize=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算合梯度的幅值和方向（角度）</span></span><br><span class="line">mag, angle = cv2.cartToPolar(gx, gy, angleInDegrees=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h3 id="为每个细胞单元构建梯度方向直方图"><a href="#为每个细胞单元构建梯度方向直方图" class="headerlink" title="为每个细胞单元构建梯度方向直方图"></a>为每个细胞单元构建梯度方向直方图</h3><p><strong>将图像划分成小cells（例如$6*6$像素/cell），统计每个cell的梯度直方图（不同梯度的个数），即可形成每个cell的descriptor</strong></p>
<ul>
<li><p>经过前两步计算，每一个像素点都会有两个值：梯度幅值/梯度方向。在这一步中，图像被分成若干个8×8的cell(每个cell可以是矩形圆形或是星形)，例如我们将图像resize至64x128的大小，那么这幅图像就被划分为8x16个8x8的cell单元，并为每个8×8的cell计算梯度直方图。当然，cell的划分也可以是其他值：16x16，8x16等，根据具体的场景确定。</p>
</li>
<li><p>在计算梯度直方图，让我们先了解一下为什么我们将图像分成若干个cell?这是因为如果对一整张梯度图逐像素计算，其中的有效特征是非常稀疏的，不但运算量大，而且会受到一些噪声干扰。于是我们就使用局部特征描述符来表示一个更紧凑的特征，计算这种局部cell上的梯度直方图更具鲁棒性。</p>
</li>
<li><p>以8x8的cell为例，一个8x8的cell包含了8x8x2 = 128个值，因为每个像素包括梯度的大小和方向。在HOG中，每个8x8的cell的梯度直方图本质是一个由9个数值组成的向量， 对应于0、20、40、60…160的梯度方向(角度)。那么原本cell中8x8x2 = 128个值就由长度为9的向量来表示，用这种梯度直方图的表示方法，大大降低了计算量，同时又对光照等环境变化更加地鲁棒。首先看下图：</p>
</li>
</ul>
<p><img src="/posts/CV/hog2.png" alt></p>
<ul>
<li><p>左图是衣服64x128的图像，被划分为8x16个8x8的cell；中间的图像表示一个cell中的梯度矢量，箭头朝向代表梯度方向，箭头长度代表梯度大小。右图是 8×8 的cell中表示梯度的原始数值，注意角度的范围介于0到180度之间，而不是0到360度， 这被称为“无符号”梯度，因为两个完全相反的方向被认为是相同的。</p>
</li>
<li><p>接下来，我们来计算cell中像素的梯度直方图，将0-180度分成9等份，称为9个bins，分别是0，20，40…160。然后对每个bin中梯度的贡献进行统计：</p>
</li>
</ul>
<p><img src="/posts/CV/hog3.png" alt></p>
<p>统计方法是一种加权投票统计， 如上图所示，某像素的梯度幅值为13.6，方向为36，36度两侧的角度bin分别为20度和40度，那么就按一定加权比例分别在20度和40度对应的bin加上梯度值，加权公式为：</p>
<ul>
<li>20度对应的bin：$((40-36)/20) * 13.6$，分母的20表示20等份，而不是20度；</li>
<li>40度对应的bin：$(36-20)/20) * 13.6$，分母的20表示20等份，而不是20度；</li>
</ul>
<p>还有一个细节需要注意，如果某个像素的梯度角度大于160度，也就是在160度到180度之间，那么把这个像素对应的梯度值按比例分给0度和160度对应的bin。如左下图绿色圆圈中的角度为165度，幅值为85，则按照同样的加权方式将85分别加到0度和160度对应的bin中。</p>
<p><img src="/posts/CV/hog4.png" alt></p>
<p>对整个cell进行投票统计，正是在HOG特征描述子中创建直方图的方式，最终得到由9个数值组成的向量—梯度方向图：</p>
<p><img src="/posts/CV/hog5.png" alt></p>
<h3 id="把细胞单元组合成大的block，块内归一化梯度直方图"><a href="#把细胞单元组合成大的block，块内归一化梯度直方图" class="headerlink" title="把细胞单元组合成大的block，块内归一化梯度直方图"></a>把细胞单元组合成大的block，块内归一化梯度直方图</h3><p><strong>将每几个cell组成一个block（例如$3*3$cell/block或4cell/block），一个block内所有cell的特征descriptor串联起来便得到该block的HOG特征descriptor</strong></p>
<p>由于局部光照的变化以及前景-背景对比度的变化，使得梯度强度的变化范围非常大。这就需要对梯度强度做归一化。</p>
<p>作者采取的办法是：把各个细胞单元组合成大的、空间上连通的区间（blocks）。这样，一个block内所有cell的特征向量串联起来便得到该block的HOG特征。这些区间是互有重叠的，这就意味着：每一个单元格的特征会以不同的结果多次出现在最后的特征向量中。我们将归一化之后的块描述符（向量）就称之为HOG描述符。</p>
<p><strong>归一化能够进一步地对光照、阴影和边缘进行压缩。</strong>归一化的方法有很多：L1-norm、L2-norm、max/min等等，一般选择L2-norm。具体方式为：</p>
<ul>
<li>一个cell有一个梯度方向直方图，包含9个数值，一个block有4个cell，那么一个block就有4个梯度方向直方图，将这4个直方图拼接成长度为36的向量，然后对这个向量进行归一化。</li>
<li>而每一个block将按照上图滑动的方式进行重复计算，直到整个图像的block都计算完成</li>
</ul>
<h3 id="收集HOG特征，将block串联得到image"><a href="#收集HOG特征，将block串联得到image" class="headerlink" title="收集HOG特征，将block串联得到image"></a>收集HOG特征，将block串联得到image</h3><p>最后一步就是将检测窗口中所有重叠的块进行HOG特征的收集，并将它们结合成最终的特征向量供分类使用。将图像image内的所有block的HOG特征descriptor串联起来就可以得到该image（你要检测的目标）的HOG特征descriptor，这个就是最终的可供分类使用的特征向量。</p>
<h3 id="HOG过程梳理及特征维数"><a href="#HOG过程梳理及特征维数" class="headerlink" title="HOG过程梳理及特征维数"></a>HOG过程梳理及特征维数</h3><ul>
<li>把样本图像分割为若干个像素的单元（cell），把梯度方向平均划分为9个区间（bin）</li>
<li>在每个单元里面对所有像素的梯度方向在各个方向区间进行直方图统计，得到一个9维的特征向量</li>
<li>每相邻的4个单元构成一个块（block），把一个块内的特征向量联起来得到36维的特征向量</li>
<li>用块对样本图像进行扫描，扫描步长为一个单元</li>
<li>最后将所有块的特征串联起来，就得到了人体的特征</li>
</ul>
<p>例如，对于$64<em>128$的图像而言，每$8</em>8$的像素组成一个cell，每$2<em>2$个cell组成一个块，因为每个cell有9个特征，所以每个块内有$4</em>9=36$个特征，以8个像素为步长，那么，水平方向将有7个扫描窗口，垂直方向将有15个扫描窗口。也就是说，$64<em>128$的图片，总共有$36</em>7*15=3780$个特征。</p>
<h1 id="HOG行人检测"><a href="#HOG行人检测" class="headerlink" title="HOG行人检测"></a>HOG行人检测</h1><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><ol>
<li>提取正负样本hog特征</li>
<li>投入svm分类器训练，得到model</li>
<li>由model生成检测子</li>
<li>利用检测子检测负样本，得到hardexample</li>
<li>提取hardexample的hog特征并结合第一步中的特征一起投入训练，得到最终检测子。</li>
</ol>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    src = cv.imread(<span class="string">"*.jpg"</span>)</span><br><span class="line">    cv.imshow(<span class="string">"input"</span>, src)</span><br><span class="line"></span><br><span class="line">    hog = cv.HOGDescriptor()</span><br><span class="line">    hog.setSVMDetector(cv.HOGDescriptor_getDefaultPeopleDetector())</span><br><span class="line">    <span class="comment"># Detect people in the image</span></span><br><span class="line">    (rects, weights) = hog.detectMultiScale(src,</span><br><span class="line">                                            winStride=(<span class="number">2</span>,<span class="number">4</span>),</span><br><span class="line">                                            padding=(<span class="number">8</span>, <span class="number">8</span>),</span><br><span class="line">                                            scale=<span class="number">1.2</span>,</span><br><span class="line">                                            useMeanshiftGrouping=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">for</span> (x, y, w, h) <span class="keyword">in</span> rects:</span><br><span class="line">        cv.rectangle(src, (x, y), (x + w, y + h), (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    cv.imshow(<span class="string">"hog-detector"</span>, src)</span><br><span class="line">    cv.imwrite(<span class="string">"hog-detector.jpg"</span>,src)</span><br><span class="line">    cv.waitKey(<span class="number">0</span>)</span><br><span class="line">    cv.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>可视化方式为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> feature, exposure</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">image = cv2.imread(<span class="string">'sp_g.jpg'</span>)</span><br><span class="line">image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">fd, hog_image = feature.hog(image, orientations=<span class="number">9</span>, pixels_per_cell=(<span class="number">8</span>, <span class="number">8</span>),</span><br><span class="line">                    cells_per_block=(<span class="number">2</span>, <span class="number">4</span>), visualize=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Rescale histogram for better display</span></span><br><span class="line">hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(<span class="number">0</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">cv2.namedWindow(<span class="string">"img"</span>,cv2.WINDOW_NORMAL)</span><br><span class="line">cv2.imshow(<span class="string">'img'</span>, image)</span><br><span class="line">cv2.namedWindow(<span class="string">"hog"</span>,cv2.WINDOW_NORMAL)</span><br><span class="line">cv2.imshow(<span class="string">'hog'</span>, hog_image_rescaled)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)==ord(<span class="string">'q'</span>)</span><br></pre></td></tr></table></figure>
<p>我们的实验图片为：</p>
<p><img src="/posts/CV/xr.jpg" alt></p>
<p>实验结果为：</p>
<p><img src="/posts/CV/hd.jpg" alt></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>HOG算法具有以下优点：</p>
<ol>
<li>HOG描述的是边缘结构特征，可以描述物体的结构信息</li>
<li>对光照影响不敏感</li>
<li>分块的处理可以使特征得到更为紧凑的表示</li>
</ol>
<p>HOG算法具有以下缺点：</p>
<ol>
<li>特征描述子获取过程复杂，维数较高，导致实时性差</li>
<li>遮挡问题很难处理</li>
<li>对噪声比较敏感</li>
</ol>
<blockquote>
<p>参考链接</p>
<ul>
<li><a href="https://blog.csdn.net/liulina603/article/details/8291093" target="_blank" rel="noopener">https://blog.csdn.net/liulina603/article/details/8291093</a></li>
<li><a href="https://www.cnblogs.com/hehuaizhou/p/13206415.html" target="_blank" rel="noopener">https://www.cnblogs.com/hehuaizhou/p/13206415.html</a></li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>CV</category>
      </categories>
  </entry>
  <entry>
    <title>Haar特征描述算子-人脸检测</title>
    <url>/posts/7e50584a.html</url>
    <content><![CDATA[<h1 id="人脸检测例子"><a href="#人脸检测例子" class="headerlink" title="人脸检测例子"></a>人脸检测例子</h1><h2 id="人脸检测"><a href="#人脸检测" class="headerlink" title="人脸检测"></a>人脸检测</h2><p>在开始介绍Haar特征描述算子之前，为了便于理解，我们直接看具体怎么通过opencv调用训练好的haar模型，从而实现人脸识别。首先Mark一下一些已经训练好的haar的模型，可以直接下载，里面包含了多种人类特征检测的训练模型，包括脸、身体、眼睛、笑脸等，链接<a href="https://github.com/opencv/opencv/tree/master/data/haarcascades" target="_blank" rel="noopener">戳我</a></p>
<p>我们打开的github链接长这样：</p>
<p><img src="/posts/CV/haar1.png" alt></p>
<p>我们下载其中一个haarcascade_frontalface_default.xml作为示例（点Raw后下载网页）。然后我们导入待识别图：</p>
<p><img src="/posts/CV/4.jpg" alt></p>
<p>执行以下代码，即可获得人脸检测的结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">"Pic/1.jpg"</span>)</span><br><span class="line"></span><br><span class="line">face_engine = cv2.CascadeClassifier(cv2.data.haarcascades+<span class="string">'haarcascade_frontalface_default.xml'</span>)</span><br><span class="line"></span><br><span class="line">faces = face_engine.detectMultiScale(img,scaleFactor=<span class="number">1.3</span>,minNeighbors=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (x,y,w,h) <span class="keyword">in</span> faces:</span><br><span class="line">    img = cv2.rectangle(img,(x,y),(x+w,y+h),(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">'img'</span>,img)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>检测结果不负众望：</p>
<p><img src="/posts/CV/reba.png" alt></p>
<p>我们留意到以上代码的face_engine步骤，其作用是导入人脸级联分类器引擎，’.xml’文件里包含训练出来的人脸特征。随后用人脸级联分类器引擎进行人脸识别，返回的faces为人脸坐标列表，1.3是放大比例，5是重复识别次数。</p>
<h2 id="人脸检测和人眼检测"><a href="#人脸检测和人眼检测" class="headerlink" title="人脸检测和人眼检测"></a>人脸检测和人眼检测</h2><p>我们也可以尝试前面xml文件中的人眼检测：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#导入opencv</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入人脸级联分类器引擎，'.xml'文件里包含训练出来的人脸特征，cv2.data.haarcascades即为存放所有级联分类器模型文件的目录</span></span><br><span class="line">face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+<span class="string">'haarcascade_frontalface_default.xml'</span>)</span><br><span class="line"><span class="comment"># 导入人眼级联分类器引擎吗，'.xml'文件里包含训练出来的人眼特征</span></span><br><span class="line">eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+<span class="string">'haarcascade_eye.xml'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读入一张图片，引号里为图片的路径，需要你自己手动设置</span></span><br><span class="line">img = cv2.imread(<span class="string">'image3.png'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用人脸级联分类器引擎进行人脸识别，返回的faces为人脸坐标列表，1.3是放大比例，5是重复识别次数</span></span><br><span class="line">faces = face_cascade.detectMultiScale(img, <span class="number">1.3</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对每一张脸，进行如下操作</span></span><br><span class="line"><span class="keyword">for</span> (x,y,w,h) <span class="keyword">in</span> faces:</span><br><span class="line">    <span class="comment"># 画出人脸框，蓝色（BGR色彩体系），画笔宽度为2</span></span><br><span class="line">    img = cv2.rectangle(img,(x,y),(x+w,y+h),(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 框选出人脸区域，在人脸区域而不是全图中进行人眼检测，节省计算资源</span></span><br><span class="line">    face_area = img[y:y+h, x:x+w]</span><br><span class="line">    eyes = eye_cascade.detectMultiScale(face_area)</span><br><span class="line">    <span class="comment"># 用人眼级联分类器引擎在人脸区域进行人眼识别，返回的eyes为眼睛坐标列表</span></span><br><span class="line">    <span class="keyword">for</span> (ex,ey,ew,eh) <span class="keyword">in</span> eyes:</span><br><span class="line">        <span class="comment">#画出人眼框，绿色，画笔宽度为1</span></span><br><span class="line">        cv2.rectangle(face_area,(ex,ey),(ex+ew,ey+eh),(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在"img2"窗口中展示效果图</span></span><br><span class="line">cv2.imshow(<span class="string">'img2'</span>,img)</span><br><span class="line"><span class="comment"># 监听键盘上任何按键，如有案件即退出并关闭窗口，并将图片保存为output.jpg</span></span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br><span class="line">cv2.imwrite(<span class="string">'output.jpg'</span>,img)</span><br></pre></td></tr></table></figure>
<p>上面的代码最值得注意的就是face_area = img[y:y+h, x:x+w]，这一步会将人脸区域框出来，在其中执行人眼检测。同样对上图进行检测，结果如下：</p>
<p><img src="/posts/CV/output.jpg" alt></p>
<p>结果还行吧。</p>
<h2 id="调用电脑摄像头进行实时人脸识别和人眼识别"><a href="#调用电脑摄像头进行实时人脸识别和人眼识别" class="headerlink" title="调用电脑摄像头进行实时人脸识别和人眼识别"></a>调用电脑摄像头进行实时人脸识别和人眼识别</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line">face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+<span class="string">'haarcascade_frontalface_default.xml'</span>)</span><br><span class="line"></span><br><span class="line">eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+<span class="string">'haarcascade_eye.xml'</span>)</span><br><span class="line"><span class="comment"># 调用摄像头摄像头</span></span><br><span class="line">cap = cv2.VideoCapture(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">    <span class="comment"># 获取摄像头拍摄到的画面</span></span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">    faces = face_cascade.detectMultiScale(frame, <span class="number">1.3</span>, <span class="number">5</span>)</span><br><span class="line">    img = frame</span><br><span class="line">    <span class="keyword">for</span> (x,y,w,h) <span class="keyword">in</span> faces:</span><br><span class="line">    	<span class="comment"># 画出人脸框，蓝色，画笔宽度微</span></span><br><span class="line">        img = cv2.rectangle(img,(x,y),(x+w,y+h),(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="number">2</span>)</span><br><span class="line">    	<span class="comment"># 框选出人脸区域，在人脸区域而不是全图中进行人眼检测，节省计算资源</span></span><br><span class="line">        face_area = img[y:y+h, x:x+w]</span><br><span class="line">        eyes = eye_cascade.detectMultiScale(face_area)</span><br><span class="line">    	<span class="comment"># 用人眼级联分类器引擎在人脸区域进行人眼识别，返回的eyes为眼睛坐标列表</span></span><br><span class="line">        <span class="keyword">for</span> (ex,ey,ew,eh) <span class="keyword">in</span> eyes:</span><br><span class="line">            <span class="comment">#画出人眼框，绿色，画笔宽度为1</span></span><br><span class="line">            cv2.rectangle(face_area,(ex,ey),(ex+ew,ey+eh),(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 实时展示效果画面</span></span><br><span class="line">    cv2.imshow(<span class="string">'frame2'</span>,img)</span><br><span class="line">    <span class="comment"># 每5毫秒监听一次键盘动作</span></span><br><span class="line">    <span class="keyword">if</span> cv2.waitKey(<span class="number">5</span>) &amp; <span class="number">0xFF</span> == ord(<span class="string">'q'</span>):</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 最后，关闭所有窗口</span></span><br><span class="line">cap.release()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>以上我们都可以通过调整参数调整精度要求。</p>
<h1 id="Haar原理解析"><a href="#Haar原理解析" class="headerlink" title="Haar原理解析"></a>Haar原理解析</h1><h2 id="Haar特征"><a href="#Haar特征" class="headerlink" title="Haar特征"></a>Haar特征</h2><p>Haar特征包含三种：边缘特征、线性特征、中心特征和对角线特征。每种分类器都从图片中提取出对应的特征。有点类似于卷积神经网络中的卷积核，每个卷积核提取出对应的特征。</p>
<p>我们最基础的卷积核（划掉），哦不haar特征为下图中的Basic Haar Set：</p>
<p><img src="/posts/CV/haar2.jpg" alt></p>
<p>我们通常将Haar特征分为以下三类，我们根据名字就可以分辨出这三类的用途:</p>
<ul>
<li><p>第一类是边缘特征：<br><img src="/posts/CV/haar3.png" alt></p>
</li>
<li><p>第二类是线性特征：<br><img src="/posts/CV/haar4.png" alt></p>
</li>
<li><p>第三类是中心特征：<br><img src="/posts/CV/haar5.jpg" alt></p>
</li>
</ul>
<p>特征模板内有白色和黑色两种矩形，并定义该模板的特征值为白色矩形像素和减去黑色矩形像素和。Haar特征值反映了图像的灰度变化情况。</p>
<p>例如：脸部的一些特征能由矩形特征简单的描述，如：眼睛要比脸颊颜色要深，鼻梁两侧比鼻梁颜色要深，嘴巴比周围颜色要深等。但矩形特征只对一些简单的图形结构，如边缘、线段较敏感，所以只能描述特定走向（水平、垂直、对角）的结构。由于有时候人脸未必是定向的，可能是会有歪曲的，因此我们可以训练旋转一定角度的矩形特征来识别人脸。</p>
<p><img src="/posts/CV/haar6.png" alt></p>
<p>总而言之，Haar特征就是利用一些固定的特征来模拟人脸中的相关特征。</p>
<p>矩形特征可位于图像任意位置，大小也可以任意改变，所以矩形特征值是矩形模版类别、矩形位置和矩形大小这三个因素的函数。故类别、大小和位置的变化，使得很小的检测窗口含有非常多的矩形特征，如：在24*24像素大小的检测窗口内矩形特征数量可以达到16万个。这样就有两个问题需要解决了：</p>
<p>（1）如何快速计算那么多的特征？—-积分图大显神通；</p>
<p>（2）哪些矩形特征才是对分类器分类最有效的？—-如通过AdaBoost算法来训练。</p>
<h2 id="积分图构建"><a href="#积分图构建" class="headerlink" title="积分图构建"></a>积分图构建</h2><p>在一个图像窗口中，可以提取出大量的Haar矩形特征区域，如果在计算Haar特征值时，每次都遍历矩形特征区域，将会造成大量重复计算，严重浪费时间。积分图是一种快速计算矩形特征的方法，主要思想是将图像起始像素点到每一个像素点之间所形成的矩形区域的像素值的和，作为一个元素保存下来，即将原始图像转换为积分图(或者求和图)，当求某一矩形区域的像素和时，只需要索引矩形区域4个角点在积分图中的取值，进行普通的加减运算，即可求得Haar特征值，整个过程只需遍历一次图像，计算特征的时间复杂度为常数(O(1))(O(1))，可以大大提升计算效率。<br>积分图中元素的公式定义如下：</p>
<script type="math/tex; mode=display">ii(x,y) = \sum_{k\le x,l\le y}f(k,l)</script><p>上式含义是在$(x,y)$位置处，积分图中元素为原图像中对应像素左上角所有像素值之和，$ii(x,y)$表示一个积分图像。在具体实现时，可用下式进行迭代运算:</p>
<script type="math/tex; mode=display">s(x,y) = s(x,y-1)+i(x,y)</script><script type="math/tex; mode=display">ii(x,y) = ii(x-1,y)+s(x,y)</script><p>其中$s$是行方向的累加和，初始值$s(x,-1)=0,ii(-1,y)=0$，但这个公式不是很好（为什么？），一个比较好的替代是下面这个公式：</p>
<script type="math/tex; mode=display">ii(x,y) = ii(x-1,y)+ii(x,y-1)+f(x,y)-ii(i-1,j-1)</script><h2 id="计算Haar特征值"><a href="#计算Haar特征值" class="headerlink" title="计算Haar特征值"></a>计算Haar特征值</h2><h3 id="矩形特征"><a href="#矩形特征" class="headerlink" title="矩形特征"></a>矩形特征</h3><p>构建好积分图后，图像中任何矩形区域的像素值累加和都可以通过简单的加减运算快速得到，如下图所示，矩形区域D的像素和值计算公式如下：</p>
<p>$\operatorname{Sum}(D)=i i\left(x_{4}, y_{4}\right)-i i\left(x_{2}, y_{2}\right)-i i\left(x_{3}, y_{3}\right)+i i\left(x_{1}, y_{1}\right)$</p>
<p><img src="/posts/CV/haar7.png" alt></p>
<p>矩形区域求和示意图 在下图中，以水平向右为$x$轴正方向，垂直向下为$y$轴正方向，可定义积分图公式Summed Area Table$(S A T(x, y))$</p>
<script type="math/tex; mode=display">
S A T(x, y)=\Sigma_{x^{\prime} \leq x, y^{\prime} \leq y} i\left(x^{\prime}, y^{\prime}\right)</script><p>以及迭代求解式</p>
<script type="math/tex; mode=display">
\begin{array}{c}
S A T(x, y)=S A T(x, y-1)+S A T(x-1, y)-S A T(x-1, y-1)+I(x, y) \\
S A T(-1, y)=0, S A T(x,-1)=0
\end{array}</script><p>对于左上角坐标为$(x, y),$宽高为$(w, h)$的矩形区域$r(x, y, w, h, 0),$可利用积分图$S A T(x, y)$求取像素和值</p>
<script type="math/tex; mode=display">
\operatorname{RecSum}(r)=S A T(x+w-1, y+h-1)+S A T(x-1, y-1)-S A T(x+w-1, y-1)-S A T(x-1, y+h-1)</script><p><img src="/posts/CV/haar8.png" alt></p>
<h3 id="旋转矩形特征"><a href="#旋转矩形特征" class="headerlink" title="旋转矩形特征"></a>旋转矩形特征</h3><p>对于旋转矩形特征，相应的有$45$°倾斜积分图用于快速计算Haar特征值，如下图所示，倾斜积分图的定义为像素点左上角$45$°区域和左下角$45$°区域的像素和，公式表示如下：</p>
<script type="math/tex; mode=display">RSAT(x, y)=\Sigma_{x^{\prime} \leq x, x^{\prime} \leq x-\left|y-y^{\prime}\right|} i\left(x^{\prime}, y^{\prime}\right)</script><p>其递推公式计算如下：</p>
<script type="math/tex; mode=display">\begin{array}{c}
R S A T(x, y)=R S A T(x-1, y-1)+R S A T(x-1, y)-R S A T(x-2, y-1)+I(x, y) \\
R S A T(x, y)=R S A T(x, y)+R S A T(x-1, y+1)-R S A T(x-2, y) \\
\end{array}</script><p>其中$R S A T(-1, y)=R S A T(-2, y)=R S A T(x,-1)=0$</p>
<p>也可直接通过下式递归计算:</p>
<script type="math/tex; mode=display">R S A T(x, y)=R S A T(x-1, y-1)+R S A T(x+1, y-1)-R S A T(x, y-2)+I(x-1, y)+I(x, y)</script><p>以上3个积分图计算公式是等价的。</p>
<p>如下图所示，构建好倾斜积分图后，可快速计算倾斜矩形区域r$=\left(x, y, w, h, 45^{\circ}\right)$的像素和值</p>
<p><img src="/posts/CV/haar9.png" alt></p>
<script type="math/tex; mode=display">\operatorname{RecSum}(r)=R S A T(x+w, y+w)+R S A T(x-h, y+h)-R S A T(x, y)-R S A T(x+w-h, y+w+h)</script><h3 id="举个例子"><a href="#举个例子" class="headerlink" title="举个例子"></a>举个例子</h3><p>了解了特征值的计算之后，我们来看看不同的特征值的含义是什么。我们选取MIT人脸库中2706个大小为$20*20$的人脸正样本图像，计算如下图所示的Haar特征：</p>
<p><img src="/posts/CV/haar10.jpg" alt></p>
<p>左边对应的人眼区域，右边无具体意义。</p>
<p><img src="/posts/CV/harr11.png" alt></p>
<p>可以看到，图中2个不同Haar特征在同一组样本中具有不同的特征值分布，左边特征计算出的特征值基本都大于0（对样本的区分度大），而右边特征的特征值基本均匀分布于0两侧（对样本的区分度小）。所以，正是由于样本中Haar特征值分布不均匀，导致了不同Haar特征分类效果不同。显而易见，对正负样本区分度越大的特征分类效果越好，即红色曲线对应图中的的左边Haar特征分类效果好于右边Haar特征。</p>
<p>那么看到这里，应该理解了下面2个问题：</p>
<ol>
<li>在检测窗口通过平移+缩放可以产生一系列Haar特征，这些特征由于位置和大小不同，分类效果也不同；</li>
<li>通过计算Haar特征的特征值，可以有将图像矩阵映射为1维特征值，有效实现了降维。</li>
</ol>
<h2 id="Haar特征归一化"><a href="#Haar特征归一化" class="headerlink" title="Haar特征归一化"></a>Haar特征归一化</h2><p>从上图我们可以发现，仅仅一个$128$维大小的Haar特征计算出的特征值变化范围从$-2000~+6000$，跨度非常大。这种跨度大的特性不利于量化评定特征值，所以需要进行“归一化”，压缩特征值范围。假设当前检测窗口中的图像像素为$i(x,y)$，当前检测窗口为$w∗h$大小（例如上图中为2020大小），OpenCV采用如下方式“归一化”：</p>
<ol>
<li>计算检测窗口中图像的灰度值和灰度值平方和：$sum=\sum i(x,y)$</li>
</ol>
<script type="math/tex; mode=display">sq_{sum}=\sum i^2(x,y)</script><ol>
<li>计算平均值：</li>
</ol>
<script type="math/tex; mode=display">mean = \frac{sum}{w*h}</script><script type="math/tex; mode=display">sq_{mean}=\frac{sq_{sum}}{w*h}</script><ol>
<li><p>计算归一化因子：</p>
<script type="math/tex; mode=display">varNormFactor=\sqrt{sq_{mean}-mean^2}</script></li>
<li><p>归一化特征值：$normValue=\frac{featureValue}{varNormFactor}$之后使用归一化的特征值$normValue$与阈值对比。</p>
</li>
</ol>
<h2 id="级联"><a href="#级联" class="headerlink" title="级联"></a>级联</h2><h3 id="白话解释"><a href="#白话解释" class="headerlink" title="白话解释"></a>白话解释</h3><p>这里我们并不打算详细阐述AdaBoost的完整工作机制以及一些更细节的部分，我们将从宏观层面来看级联的流程。</p>
<p><strong>基于Haar特征的cascade级联分类器</strong>是Paul Viola和 Michael Jone在2001年的论文”Rapid Object Detection using a Boosted Cascade of Simple Features”中提出的一种有效的物体检测方法。</p>
<p><strong>Cascade级联分类器的训练方法：Adaboost</strong></p>
<p>级联分类器的函数是通过大量带人脸和不带人脸的图片通过机器学习得到的。对于人脸识别来说，需要几万个特征，通过机器学习找出人脸分类效果最好、错误率最小的特征。训练开始时，所有训练集中的图片具有相同的权重，对于被分类错误的图片，提升权重，重新计算出新的错误率和新的权重。直到错误率或迭代次数达到要求。这种方法叫做Adaboost，在Opencv中可以直接调用级联分类器函数。</p>
<p><strong>将弱分类器聚合成强分类器</strong></p>
<p>最终的分类器是这些弱分类器的加权和。之所以称之为弱分类器是因为每个分类器不能单独分类图片，但是将他们聚集起来就形成了强分类器。论文表明，只需要200个特征的分类器在检测中的精确度达到了95%。最终的分类器大约有6000个特征。(将超过160000个特征减小到6000个，这是非常大的进步了）。</p>
<p><strong>级联的含义：需过五关斩六将才能被提取出来</strong></p>
<p>事实上，一张图片绝大部分的区域都不是人脸。如果对一张图片的每个角落都提取6000个特征，将会浪费巨量的计算资源。</p>
<p>如果能找到一个简单的方法能够检测某个窗口是不是人脸区域，如果该窗口不是人脸区域，那么就只看一眼便直接跳过，也就不用进行后续处理了，这样就能集中精力判别那些可能是人脸的区域。 为此，有人引入了Cascade 分类器。它不是将6000个特征都用在一个窗口，而是将特征分为不同的阶段，然后一个阶段一个阶段的应用这些特征(通常情况下，前几个阶段只有很少量的特征)。如果窗口在第一个阶段就检测失败了，那么就直接舍弃它，无需考虑剩下的特征。如果检测通过，则考虑第二阶段的特征并继续处理。如果所有阶段的都通过了，那么这个窗口就是人脸区域。 作者的检测器将6000+的特征分为了38个阶段，前五个阶段分别有1，10，25，25，50个特征(前文图中提到的识别眼睛和鼻梁的两个特征实际上是Adaboost中得到的最好的两个特征)。根据作者所述，平均每个子窗口只需要使用6000+个特征中的10个左右。</p>
<p>简单地说，在进行人脸检测的过程中，需要使用一个强分类器，且其由多个弱分类器组成。那么其中的每个弱分类器都只包含一个Haar特征。每个分类器都将确定一个阈值，如果某区域的处理差值小于该阈值，则被归为负类，反之则进行下一级的弱分类，最终经过多个弱分类器后，可完成检测。其分类过程如下图所示：</p>
<p><img src="/posts/CV/haar13.png" alt></p>
<h3 id="举个例子-1"><a href="#举个例子-1" class="headerlink" title="举个例子"></a>举个例子</h3><p><img src="/posts/CV/haar12.png" alt></p>
<ol>
<li>首先，对于一幅图像，它可能存在K个面部特征，假设这些面部特征可以用来区分眼睛、眉毛、鼻子、嘴等特征。</li>
<li>确定一些超参数，如滑动窗口的大小，及窗口的移动步长。窗口从上往下，从左向右地滑动。在滑动的过程中，每次都可以计算出一个数值$K$。</li>
<li>滑动结束时，将得到的特征值进行排序，并选取一个最佳特征值（最优阈值），使得在该特征值下，对于该特征而言，样本的加权错误率最低。这样就训练出了一个弱分类器。</li>
<li>因为面部特征的不同，我们将采用不同的滑动窗口进行特征提取。所以根据不同的窗口识别不同的特征，进而训练出了不同的弱分类器。</li>
<li>对于每个弱分类器都将计算它的错误率，选择错误率最低的K个弱分类器，组合成强分类器。</li>
<li>一组样本投入强分类器后，在每个渐进的阶段，分类器逐渐在较少的图像窗口上使用更多的特征（负类被丢弃）。如果某个矩形区域在所有弱分类器中都被归结为正类，那么可以认为该区域是存在人脸的。</li>
</ol>
<p>其中，弱分类器训练的具体步骤如下：</p>
<ol>
<li>对于每个特征$f$，计算所有训练样本的特征值，并将其排序：</li>
<li>扫描一遍排好序的特征值，对排好序的表中的每个元素，计算下面四个值：<ul>
<li>计算全部正例的权重和$T^+$；</li>
<li>计算全部负例的权重和$T^-$；</li>
<li>计算该元素前之前的正例的权重和$S^+$；</li>
<li>计算该元素前之前的负例的权重和$S^-$</li>
</ul>
</li>
<li>选取当前元素的特征值$F_{k,j}$和它前面的一个特征值$F_{k,j−1}$之间的数作为阈值，所得到的弱分类器就在当前元素处把样本分开 —— 也就是说这个阈值对应的弱分类器将当前元素前的所有元素分为人脸（或非人脸），而把当前元素后（含）的所有元素分为非人脸（或人脸）。该阈值的分类误差为：</li>
</ol>
<script type="math/tex; mode=display">e=min(S^++(T^−−S^−),S^−+(T^+−S^+))</script><p>于是，通过把这个排序表从头到尾扫描一遍就可以为弱分类器选择使分类误差最小的阈值（最优阈值），也就是选取了一个最佳弱分类器。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="训练步骤"><a href="#训练步骤" class="headerlink" title="训练步骤"></a>训练步骤</h3><p>从上面所述内容我们可以总结Haar分类器训练的五大步骤：</p>
<ol>
<li>准备人脸、非人脸样本集；</li>
<li>使用Haar特征做检测；</li>
<li>使用积分图（Integral Image）对Haar特征求值进行加速；</li>
<li>使用AdaBoost算法训练区分人脸和非人脸的强分类器；</li>
<li>使用筛选式级联把强分类器级联到一起，提高准确率</li>
</ol>
<h3 id="Haar的局限性"><a href="#Haar的局限性" class="headerlink" title="Haar的局限性"></a>Haar的局限性</h3><ul>
<li>仅为人脸检测，非人脸“辩识”，即只能框出人脸的位置，看不出人脸是谁。</li>
<li>仅能标出静态图片和视频帧上的人脸、人眼和微笑，不能进行“活体识别”，即不能看出这张脸是真人还是手机上的照片，如果用于人脸打卡签到、人脸支付的话会带来潜在的安全风险。</li>
<li>仅为普通的机器学习方法，没有用到深度学习和深层神经网络。</li>
</ul>
<blockquote>
<p>参考链接：</p>
</blockquote>
<ul>
<li><a href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_objdetect/py_face_detection/py_face_detection.html#face-detection" target="_blank" rel="noopener">https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_objdetect/py_face_detection/py_face_detection.html#face-detection</a></li>
<li><a href="https://github.com/TommyZihao/zihaoopencv/blob/master/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B%E4%B8%8E%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E3%80%90%E5%AD%90%E8%B1%AA%E5%85%84opencv-python%E6%95%99%E7%A8%8B%E3%80%91.md" target="_blank" rel="noopener">https://github.com/TommyZihao/zihaoopencv/blob/master/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B%E4%B8%8E%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E3%80%90%E5%AD%90%E8%B1%AA%E5%85%84opencv-python%E6%95%99%E7%A8%8B%E3%80%91.md</a></li>
<li><a href="https://github.com/datawhalechina/team-learning/blob/master/03%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80%EF%BC%9A%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%EF%BC%88%E4%B8%8B%EF%BC%89/Task03%20Haar%E7%89%B9%E5%BE%81%E6%8F%8F%E8%BF%B0%E7%AE%97%E5%AD%90.md" target="_blank" rel="noopener">https://github.com/datawhalechina/team-learning/blob/master/03%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80%EF%BC%9A%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%EF%BC%88%E4%B8%8B%EF%BC%89/Task03%20Haar%E7%89%B9%E5%BE%81%E6%8F%8F%E8%BF%B0%E7%AE%97%E5%AD%90.md</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/100217697" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/100217697</a></li>
<li><a href="https://blog.csdn.net/chutu2018/article/details/106983147/" target="_blank" rel="noopener">https://blog.csdn.net/chutu2018/article/details/106983147/</a></li>
<li><a href="https://blog.csdn.net/playezio/article/details/80471000" target="_blank" rel="noopener">https://blog.csdn.net/playezio/article/details/80471000</a></li>
<li><a href="https://www.cnblogs.com/recoverableTi/p/13214405.html" target="_blank" rel="noopener">https://www.cnblogs.com/recoverableTi/p/13214405.html</a></li>
</ul>
]]></content>
      <categories>
        <category>CV</category>
      </categories>
  </entry>
  <entry>
    <title>LBP特征描述算子-人脸检测</title>
    <url>/posts/2b071c91.html</url>
    <content><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>LBP（Local Binary Pattern，局部二值模式）特征是一种用来描述图像局部纹理特征的算子，它具有旋转不变性和灰度不变性的优点，用于图像局部纹理特征提取。</p>
<p><strong>注意初基本LBP没有旋转不变性</strong></p>
<h2 id="基本LBP"><a href="#基本LBP" class="headerlink" title="基本LBP"></a>基本LBP</h2><p>基本LBP十分简单，我们对原图像的每一个像素点（边界除外）可以抽取出以之为中心的3×3矩阵，为了计算中间点的LBP，我们用除了中间点此外的8个点依次与中间点比较，比它(也就是15)大的记成1，比它小的记成0，如下图所示：</p>
<p><img src="/posts/CV/lbp.png" alt></p>
<p>用公式可以表示成：</p>
<script type="math/tex; mode=display">LBP(x_c,y_c) = \sum^{p-1}_{p=0}2^ps(i_p-i_c)</script><p>其中$(x_c,y_c)$是中心像素，$i_c$是中心像素灰度值，$i_n$是相邻像素的灰度值，$s$是一个符号函数：</p>
<script type="math/tex; mode=display">s(x) = \left\{
\begin{aligned}
1 ,x \ge 0\\
0 ,x \lt 0
\end{aligned}
\right.</script><h2 id="圆形LBP算子"><a href="#圆形LBP算子" class="headerlink" title="圆形LBP算子"></a>圆形LBP算子</h2><p>原始LBP算子计算区域为像素点的周围8个点，在图像尺寸和频率纹理发生改变时会出现很大的偏差，不能正确反映像素点周围的纹理信息。为适应不同尺寸纹理特征，LBP原作者将圆形邻域代替正方形邻域。同时<strong>增加了旋转不变的特性，在对LBP特征值的存储部分，也进行了改进</strong>。</p>
<p>改进后的LBP算子长成这个样：</p>
<p><img src="/posts/CV/lbp2.jpg" alt></p>
<p>上面是不同半径与采样点数量的LBP算子</p>
<p>我们将领域由正方形变为圆形后，面对的第一个问题就是如何获得采样点的坐标，获得方法为：</p>
<script type="math/tex; mode=display">x_t = x_d + R\cos(2\pi\frac{p}{P})</script><script type="math/tex; mode=display">y_t = y_d - R\sin(2\pi\frac{p}{P})</script><p>看到上面这个简单的取圆周上的点的函数，我们又想到，事实上实际操作时得到的坐标未必是整数，也就无从单论这个点的像素值，因此我们需要用一个方法利用取点周围的值来定义获得的非整数坐标的像素值，在这里我们使用<strong>双线性插值法</strong>（当然我们可以使用其他插值法，不过opencv使用的是双线性插值）。</p>
<p>双线性插值又是什么意思呢？说白了双线性插值几乎就是一个线性插值，只不过是有两个变量的插值函数的线性插值扩展，其核心思想是在两个方向分别进行一次线性插值，如下：（下述一维插值均使用拉格朗日插值法表示）</p>
<p><img src="/posts/CV/xxcz.jpg" alt></p>
<ul>
<li>第一步：$X$方向的线性插值，在$Q_{12},Q_{22}$中插入蓝色点$R2，Q11，Q21$中插入蓝色点$R1$；</li>
<li>第二步：$Y$方向的线性插值 ,通过第一步计算出的$R1$与$R2$在$y$方向上插值计算出$P$点。</li>
</ul>
<p>首先由于线性插值的结果与插值的顺序无关，同时首先进行$Y$方向的插值，然后进行$X$方向的插值，所得到的结果是一样的，因此<strong>双线性插值的结果与先进行哪个方向的插值无关</strong>。如果选择一个坐标系统使得四个已知点坐标分别为$(0, 0),(0, 1),(1, 0)$和$(1, 1)$，那么插值公式就可以化简为</p>
<script type="math/tex; mode=display">f(x,y)=f(0,0)(1-x)(1-y)+f(1,0)x(1-y)+f(0,1)(1-x)y+f(1,1)xy</script><p>表示成矩阵形式即为：</p>
<script type="math/tex; mode=display">f(x,y)=\left[ \begin{matrix} 1-x & x \end{matrix} \right ] \left[ \begin{matrix} f(0,0) & f(0,1\\f(1,0) & f(1,1) \end{matrix} \right ]\left[ \begin{matrix} 1-y\\y \end{matrix} \right ]</script><p>我们看到右边项其实正是二维泰勒公式的前几项，而由已知的一维拉格朗日线性插值法的展开式可知，上述等式实际上就是<strong>拉格朗日插值法的二维形式</strong>。</p>
<p>实际上到目前为止，我们得到的LBP方法仍然不具有旋转不变性，这也很好理解，我们只是取了一个圆周而已，当圆周上旋转（起始选点位置发生变化）LBP当然也会发生变化，那我们要做什么才能让一个圆周确定唯一一个LBP算子呢（<strong>也就是说对于同一个圆周需要有一个固定的顺序</strong>），我们可以对圆上所有点遍历，将遍历到的点作为初始点计算圆周的LBP，然后选取其中LBP最小的特征值作为LBP中心像素点的特征值。用数学表示为：</p>
<script type="math/tex; mode=display">LBP_{P、R}^{ri} = \min \{ ROR(LBP_{P、R}^i) \}</script><p>其中$ROR（x，i）$执顺时针方向将$P$位数$x$移动$i$次。对于图像像素而言，就是将邻域集合按照时钟方向旋转很多次，直到当前旋转下构成的LBP值最小。如下图所示：</p>
<p><img src="/posts/CV/lbp3.jpg" alt></p>
<p>问题来了，我们为什么要选择最小的，选最大的或者选中位数、平均数它不香吗？我也不知道hhhh，大家可以看看下面参考链接的原论文（我看了看似乎也没有讲），若有新的想法欢迎在下面留言交流~</p>
<p>如下图所示，对于8个采样点，将有36种唯一的旋转不变二值模式：【黑点为0，白点为1】</p>
<p><img src="/posts/CV/lbp4.png" alt></p>
<h2 id="LBP等价模式（ULBP）"><a href="#LBP等价模式（ULBP）" class="headerlink" title="LBP等价模式（ULBP）"></a>LBP等价模式（ULBP）</h2><p>基于上面的讨论：<strong>对于8个采样点，灰度不变性LBP（基本LBP）将产生256种输出，旋转不变性LBP将产生36个输出，而基于unifrom的旋转不变LBP将只有9中输出</strong>。第一个是由于中心像素附近有八个像素（有八个可以填0,1的位置），因此共有$2^8=256$种输出，旋转不变性LBP已于上面一一列举，基于uniform的旋转不变性LBP将于下面叙述：</p>
<p>一个LBP算子可以产生不同的二进制模式，对于半径为$R$的圆形区域内含有$P$个采样点的LBP算子将会产生$P^2$种模式。很显然，随着邻域集内采样点数的增加，二进制模式的种类是急剧增加的。例如：$5×5$邻域内（基本LBP）$20$个采样点，有$2^20＝1,048,576$种二进制模式。如此多的二值模式无论对于纹理的提取还是对于纹理的识别、分类及信息的存取都是不利的。同时，过多的模式种类对于纹理的表达是不利的。例如，将LBP算子用于纹理分类或人脸识别时，常采用LBP模式的统计直方图来表达图像的信息，而较多的模式种类将使得数据量过大，且直方图过于稀疏。因此，需要对原始的LBP模式进行降维，使得数据量减少的情况下能最好的代表图像的信息。</p>
<p>为了解决二进制模式过多的问题，提高统计性，Ojala提出了采用一种“等价模式”（Uniform Pattern）来对LBP算子的模式种类进行降维。Ojala等认为，在实际图像中，绝大多数LBP模式最多只包含两次从1到0或从0到1的跳变。因此，Ojala将“等价模式”定义为：当某个LBP所对应的循环二进制数从0到1或从1到0最多有两次跳变时，该LBP所对应的二进制就称为一个等价模式类。如00000000（0次跳变），00000111（只含一次从0到1的跳变），10001111（先由1跳到0，再由0跳到1，共两次跳变）都是等价模式类。除等价模式类以外的模式都归为另一类，称为混合模式类，例如10010111（共四次跳变）</p>
<p>通过这样的改进，二进制模式的种类大大减少，而不会丢失任何信息。模式数量由原来的2P种减少为$P( P-1)+2+1$种，其中$P$表示邻域集内的采样点数。对于$3×3$邻域内$8$个采样点来说，二进制模式由原始的$256$种减少为$58$种，这使得特征向量的维数更少，并且可以减少高频噪声带来的影响。</p>
<p>举个例子：采样点数8个，即256个LBP特征值，分成59类：跳变0次——2个，跳变1次——0个，跳变2次——56个，跳变3次——0个，跳变4次——140个，跳变5次——0个，跳变6次——56个，跳变7次——0个，跳变8次——2个。</p>
<p>另外LBP还有许多其他变形，比如MB-LBP（Multiscale Block LBP）特征等，就不在此一一阐述。</p>
<h1 id="LBP检测原理"><a href="#LBP检测原理" class="headerlink" title="LBP检测原理"></a>LBP检测原理</h1><h2 id="LBP特征统计直方图"><a href="#LBP特征统计直方图" class="headerlink" title="LBP特征统计直方图"></a>LBP特征统计直方图</h2><p>显而易见的是，上述提取的LBP算子在每个像素点都可以得到一个LBP“编码”，那么，对一幅图像（记录的是每个像素点的灰度值）提取其原始的LBP算子之后，得到的原始LBP特征依然是“一幅图片”（记录的是每个像素点的LBP值）。</p>
<p>在LBP的应用中，如纹理分类、人脸分析等，一般都不将LBP图谱作为特征向量用于分类识别，而是<strong>采用LBP特征谱的统计直方图作为特征向量用于分类识别</strong>。这是因为从上面的分析我们可以看出，这个“特征”跟位置信息是紧密相关的。直接对两幅图片提取这种“特征”，并进行判别分析的话，会因为“位置没有对准”而产生很大的误差。后来，研究人员发现，可以<strong>将一幅图片划分为若干的子区域</strong>，对每个子区域内的每个像素点都提取LBP特征，然后，在每个子区域内建立LBP特征的统计直方图。如此一来，<strong>每个子区域，就可以用一个统计直方图来进行描述</strong>；整个图片就由若干个统计直方图组成；</p>
<p>例如：一幅$100<em>100$像素大小的图片，划分为$10</em>10=100$个子区域（可以通过多种方式来划分区域），每个子区域的大小为$10<em>10$像素；在每个子区域内的每个像素点，提取其LBP特征，然后，建立统计直方图；这样，这幅图片就有$10</em>10$个子区域，也就有了$10<em>10$个统计直方图，利用这$10</em>10$个统计直方图，就可以描述这幅图片了。之后，我们利用各种相似性度量函数，就可以判断两幅图像之间的相似性了；</p>
<h2 id="对LBP特征向量进行提取的步骤"><a href="#对LBP特征向量进行提取的步骤" class="headerlink" title="对LBP特征向量进行提取的步骤"></a>对LBP特征向量进行提取的步骤</h2><ol>
<li>计算图像的LBP特征图像（对每个像素点获得一个LBP）</li>
<li>将LBP特征图像进行分块，Opencv中默认将LBP特征图像分成8行8列64块区域</li>
<li>计算每块区域特征图像的直方图cell_LBPH，将直方图进行归一化，直方图大小为$1*numPatterns$</li>
<li>将上面计算的每块区域特征图像的直方图按分块的空间顺序依次排列成一行，形成LBP特征向量，大小为$1<em>（numPatterns</em>64）$</li>
<li>用机器学习的方法对LBP特征向量进行训练，用来检测和识别目标</li>
</ol>
<p>举例说明LBPH的维度：采样点为8个，如果用的是原始的LBP或Extended LBP特征，其LBP特征值的模式为256种，则一幅图像的LBP特征向量维度为：$64<em>256=16384$维，而如果使用的UniformPatternLBP特征，其LBP值的模式为59种，其特征向量维度为：$64</em>59=3776$维，可以看出，使用等价模式特征，其特征向量的维度大大减少，这意味着使用机器学习方法进行学习的时间将大大减少，而性能上没有受到很大影响。</p>
<h1 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h1><h2 id="人脸检测"><a href="#人脸检测" class="headerlink" title="人脸检测"></a>人脸检测</h2><p>首先我们导入周杰伦的图片：</p>
<p><img src="/posts/CV/jay.jpg" alt></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">img= cv.imread(<span class="string">'Pic/jay.jpg'</span>)</span><br><span class="line">gray = cv.cvtColor(img, code=cv.COLOR_BGR2GRAY)</span><br><span class="line">face_detect = cv.CascadeClassifier(<span class="string">"lbpcascade_frontalface_improved.xml"</span>)</span><br></pre></td></tr></table></figure>
<p>上面几行代码是导入相关包，导入图片，转换灰度图，欸第四行是什么东西？第四行是一个训练模型的xml文件，下载地址为：<a href="https://github.com/opencv/opencv/blob/master/data/lbpcascades/lbpcascade_frontalface_improved.xml" target="_blank" rel="noopener">戳这里</a></p>
<p>这个文件（模型）内容为：</p>
<p><img src="/posts/CV/train.png" alt></p>
<p>咱先不管它是个啥，直接用就vans~（不然的话还得跑一堆训练数据从头训练，再问就是懒）</p>
<p>下面两行代码会调用前面训练好的模型进行人脸检测：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 检查人脸 按照1.1倍放到 周围最小像素为5</span></span><br><span class="line">face_zone = face_detect.detectMultiScale(gray, scaleFactor = <span class="number">2</span>, minNeighbors = <span class="number">2</span>)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'识别人脸的信息：\n'</span>,face_zone)</span><br></pre></td></tr></table></figure>
<p>要理解上面传入的参数，就得看一看对应的源代码定义部分：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">cv::CascadeClassifier::detectMultiScale(</span><br><span class="line">    <span class="keyword">const</span> cv::Mat&amp; image, <span class="comment">// 输入待检测的图像（灰度）</span></span><br><span class="line">    <span class="built_in">vector</span>&lt;cv::Rect&gt;&amp; objects, <span class="comment">// 输出的目标窗口</span></span><br><span class="line">    <span class="keyword">double</span> scaleFactor = <span class="number">1.1</span>, <span class="comment">// 尺度系数</span></span><br><span class="line">    <span class="keyword">int</span> minNeighbors = <span class="number">3</span>, <span class="comment">// 需要的邻域数</span></span><br><span class="line">    <span class="keyword">int</span> flags = <span class="number">0</span>, <span class="comment">// flag (旧风格的cascades)</span></span><br><span class="line">    cv::Size minSize = cv::Size(), <span class="comment">// 最小检测窗口</span></span><br><span class="line">    cv::Size maxSize = cv::Size() <span class="comment">// 最大检测窗口</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<p>需要的邻域数我的理解就是中心点依赖的周围的像素点的半径（有不妥请指正）</p>
<p>下一步就是绘制检测框框：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 绘制矩形和圆形检测人脸</span></span><br><span class="line"><span class="keyword">for</span> x, y, w, h <span class="keyword">in</span> face_zone:</span><br><span class="line">    <span class="comment"># 绘制矩形人脸区域</span></span><br><span class="line">    cv.rectangle(img, pt1 = (x, y), pt2 = (x+w, y+h), color = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>], thickness=<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 绘制圆形人脸区域 radius表示半径</span></span><br><span class="line">    cv.circle(img, center = (x + w//<span class="number">2</span>, y + h//<span class="number">2</span>), radius = w//<span class="number">2</span>, color = [<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>], thickness = <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>然后就是一些附加的通用操作：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 设置图片可以手动调节大小</span></span><br><span class="line">cv.namedWindow(<span class="string">"Easmount-CSDN"</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图片</span></span><br><span class="line">cv.imshow(<span class="string">"Easmount-CSDN"</span>, img)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 等待显示 设置任意键退出程序</span></span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>我们看一看结果长啥样：</p>
<p><img src="/posts/CV/jayoutput.png" alt></p>
<h2 id="LBP源码分析"><a href="#LBP源码分析" class="headerlink" title="LBP源码分析"></a>LBP源码分析</h2><p><strong>注：下面的源码都是使用Cpp实现（直接copy的），内容较多，可略过不看</strong></p>
<p>下面是原始LBP的旧版源码：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">LBP</span> <span class="params">(IplImage *src,IplImage *dst)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> tmp[<span class="number">8</span>]=&#123;<span class="number">0</span>&#125;;</span><br><span class="line">    CvScalar s;</span><br><span class="line"></span><br><span class="line">    IplImage * temp = cvCreateImage(cvGetSize(src), IPL_DEPTH_8U,<span class="number">1</span>);</span><br><span class="line">    uchar *data=(uchar*)src-&gt;imageData;</span><br><span class="line">    <span class="keyword">int</span> step=src-&gt;widthStep;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"step"</span>&lt;&lt;step&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;src-&gt;height<span class="number">-1</span>;i++)</span><br><span class="line">      <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">1</span>;j&lt;src-&gt;width<span class="number">-1</span>;j++)</span><br><span class="line">      &#123;</span><br><span class="line">          <span class="keyword">int</span> sum=<span class="number">0</span>;</span><br><span class="line">          <span class="keyword">if</span>(data[(i<span class="number">-1</span>)*step+j<span class="number">-1</span>]&gt;data[i*step+j])</span><br><span class="line">            tmp[<span class="number">0</span>]=<span class="number">1</span>;</span><br><span class="line">          <span class="keyword">else</span></span><br><span class="line">            tmp[<span class="number">0</span>]=<span class="number">0</span>;</span><br><span class="line">          <span class="keyword">if</span>(data[i*step+(j<span class="number">-1</span>)]&gt;data[i*step+j])</span><br><span class="line">            tmp[<span class="number">1</span>]=<span class="number">1</span>;</span><br><span class="line">          <span class="keyword">else</span></span><br><span class="line">            tmp[<span class="number">1</span>]=<span class="number">0</span>;</span><br><span class="line">          <span class="keyword">if</span>(data[(i+<span class="number">1</span>)*step+(j<span class="number">-1</span>)]&gt;data[i*step+j])</span><br><span class="line">            tmp[<span class="number">2</span>]=<span class="number">1</span>;</span><br><span class="line">          <span class="keyword">else</span></span><br><span class="line">            tmp[<span class="number">2</span>]=<span class="number">0</span>;</span><br><span class="line">          <span class="keyword">if</span> (data[(i+<span class="number">1</span>)*step+j]&gt;data[i*step+j])</span><br><span class="line">            tmp[<span class="number">3</span>]=<span class="number">1</span>;</span><br><span class="line">      	  <span class="keyword">else</span></span><br><span class="line">            tmp[<span class="number">3</span>]=<span class="number">0</span>;</span><br><span class="line">          <span class="keyword">if</span> (data[(i+<span class="number">1</span>)*step+(j+<span class="number">1</span>)]&gt;data[i*step+j])</span><br><span class="line">            tmp[<span class="number">4</span>]=<span class="number">1</span>;</span><br><span class="line">          <span class="keyword">else</span></span><br><span class="line">            tmp[<span class="number">4</span>]=<span class="number">0</span>;</span><br><span class="line">          <span class="keyword">if</span>(data[i*step+(j+<span class="number">1</span>)]&gt;data[i*step+j])</span><br><span class="line">            tmp[<span class="number">5</span>]=<span class="number">1</span>;</span><br><span class="line">          <span class="keyword">else</span></span><br><span class="line">            tmp[<span class="number">5</span>]=<span class="number">0</span>;</span><br><span class="line">          <span class="keyword">if</span>(data[(i<span class="number">-1</span>)*step+(j+<span class="number">1</span>)]&gt;data[i*step+j])</span><br><span class="line">            tmp[<span class="number">6</span>]=<span class="number">1</span>;</span><br><span class="line">          <span class="keyword">else</span></span><br><span class="line">            tmp[<span class="number">6</span>]=<span class="number">0</span>;</span><br><span class="line">          <span class="keyword">if</span>(data[(i<span class="number">-1</span>)*step+j]&gt;data[i*step+j])</span><br><span class="line">            tmp[<span class="number">7</span>]=<span class="number">1</span>;</span><br><span class="line">          <span class="keyword">else</span></span><br><span class="line">            tmp[<span class="number">7</span>]=<span class="number">0</span>;</span><br><span class="line">          <span class="comment">//计算LBP编码</span></span><br><span class="line">            s.val[<span class="number">0</span>]=(tmp[<span class="number">0</span>]*<span class="number">1</span>+tmp[<span class="number">1</span>]*<span class="number">2</span>+tmp[<span class="number">2</span>]*<span class="number">4</span>+tmp[<span class="number">3</span>]*<span class="number">8</span>+tmp[<span class="number">4</span>]*<span class="number">16</span>+tmp[<span class="number">5</span>]*<span class="number">32</span>+tmp[<span class="number">6</span>]*<span class="number">64</span>+tmp[<span class="number">7</span>]*<span class="number">128</span>);</span><br><span class="line">        cvSet2D(dst,i,j,s);写入LBP图像</span><br><span class="line">      &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码旧版LBP的实现代码，我们可以看见中间大段地逻辑都是在判断周围地像素点和中心像素点谁打谁小，其他代码逻辑也没有难度。</p>
<p>下面是原始LBP的新版源码(cpp)：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> _tp&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">getOriginLBPFeature</span><span class="params">(InputArray _src,OutputArray _dst)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Mat src = _src.getMat();</span><br><span class="line">    _dst.create(src.rows<span class="number">-2</span>,src.cols<span class="number">-2</span>,CV_8UC1);</span><br><span class="line">    Mat dst = _dst.getMat();</span><br><span class="line">    dst.setTo(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;src.rows<span class="number">-1</span>;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">1</span>;j&lt;src.cols<span class="number">-1</span>;j++)</span><br><span class="line">        &#123;</span><br><span class="line">            _tp center = src.at&lt;_tp&gt;(i,j);</span><br><span class="line">            <span class="keyword">unsigned</span> <span class="keyword">char</span> lbpCode = <span class="number">0</span>;</span><br><span class="line">            lbpCode |= (src.at&lt;_tp&gt;(i<span class="number">-1</span>,j<span class="number">-1</span>) &gt; center) &lt;&lt; <span class="number">7</span>;</span><br><span class="line">            lbpCode |= (src.at&lt;_tp&gt;(i<span class="number">-1</span>,j  ) &gt; center) &lt;&lt; <span class="number">6</span>;</span><br><span class="line">            lbpCode |= (src.at&lt;_tp&gt;(i<span class="number">-1</span>,j+<span class="number">1</span>) &gt; center) &lt;&lt; <span class="number">5</span>;</span><br><span class="line">            lbpCode |= (src.at&lt;_tp&gt;(i  ,j+<span class="number">1</span>) &gt; center) &lt;&lt; <span class="number">4</span>;</span><br><span class="line">            lbpCode |= (src.at&lt;_tp&gt;(i+<span class="number">1</span>,j+<span class="number">1</span>) &gt; center) &lt;&lt; <span class="number">3</span>;</span><br><span class="line">            lbpCode |= (src.at&lt;_tp&gt;(i+<span class="number">1</span>,j  ) &gt; center) &lt;&lt; <span class="number">2</span>;</span><br><span class="line">            lbpCode |= (src.at&lt;_tp&gt;(i+<span class="number">1</span>,j<span class="number">-1</span>) &gt; center) &lt;&lt; <span class="number">1</span>;</span><br><span class="line">            lbpCode |= (src.at&lt;_tp&gt;(i  ,j<span class="number">-1</span>) &gt; center) &lt;&lt; <span class="number">0</span>;</span><br><span class="line">            dst.at&lt;uchar&gt;(i<span class="number">-1</span>,j<span class="number">-1</span>) = lbpCode;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;python</span><br></pre></td></tr></table></figure>
<p>嗯…看起来也差不多，但代码好看多了hhh。</p>
<p>圆形LBP的源码：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> _tp&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">getCircularLBPFeature</span><span class="params">(InputArray _src,OutputArray _dst,<span class="keyword">int</span> radius,<span class="keyword">int</span> neighbors)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Mat src = _src.getMat();</span><br><span class="line">    <span class="comment">//LBP特征图像的行数和列数的计算要准确</span></span><br><span class="line">    _dst.create(src.rows<span class="number">-2</span>*radius,src.cols<span class="number">-2</span>*radius,CV_8UC1);</span><br><span class="line">    Mat dst = _dst.getMat();</span><br><span class="line">    dst.setTo(<span class="number">0</span>);</span><br><span class="line">    <span class="comment">//循环处理每个像素</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=radius;i&lt;src.rows-radius;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j=radius;j&lt;src.cols-radius;j++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">//获得中心像素点的灰度值</span></span><br><span class="line">            _tp center = src.at&lt;_tp&gt;(i,j);</span><br><span class="line">            <span class="keyword">unsigned</span> <span class="keyword">char</span> lbpCode = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> k=<span class="number">0</span>;k&lt;neighbors;k++)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="comment">//根据公式计算第k个采样点的坐标，这个地方可以优化，不必每次都进行计算radius*cos，radius*sin</span></span><br><span class="line">                <span class="keyword">float</span> x = i + <span class="keyword">static_cast</span>&lt;<span class="keyword">float</span>&gt;(radius * <span class="built_in">cos</span>(<span class="number">2.0</span> * CV_PI * k / neighbors));</span><br><span class="line">                <span class="keyword">float</span> y = j - <span class="keyword">static_cast</span>&lt;<span class="keyword">float</span>&gt;(radius * <span class="built_in">sin</span>(<span class="number">2.0</span> * CV_PI * k / neighbors));</span><br><span class="line">                <span class="comment">//根据取整结果进行双线性插值，得到第k个采样点的灰度值</span></span><br><span class="line"></span><br><span class="line">                <span class="comment">//1.分别对x，y进行上下取整</span></span><br><span class="line">                <span class="keyword">int</span> x1 = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(<span class="built_in">floor</span>(x));</span><br><span class="line">                <span class="keyword">int</span> x2 = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(<span class="built_in">ceil</span>(x));</span><br><span class="line">                <span class="keyword">int</span> y1 = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(<span class="built_in">floor</span>(y));</span><br><span class="line">                <span class="keyword">int</span> y2 = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(<span class="built_in">ceil</span>(y));</span><br><span class="line"></span><br><span class="line">                <span class="comment">//2.计算四个点(x1,y1),(x1,y2),(x2,y1),(x2,y2)的权重</span></span><br><span class="line">                <span class="comment">//下面的权重计算方式有个问题，如果四个点都相等，则权重全为0，计算出来的插值为0</span></span><br><span class="line">                <span class="comment">//float w1 = (x2-x)*(y2-y); //(x1,y1)</span></span><br><span class="line">                <span class="comment">//float w2 = (x2-x)*(y-y1); //(x1,y2)</span></span><br><span class="line">                <span class="comment">//float w3 = (x-x1)*(y2-y); //(x2,y1)</span></span><br><span class="line">                <span class="comment">//float w4 = (x-x1)*(y-y1); //(x2,y2)</span></span><br><span class="line"></span><br><span class="line">                <span class="comment">//将坐标映射到0-1之间</span></span><br><span class="line">                <span class="keyword">float</span> tx = x - x1;</span><br><span class="line">                <span class="keyword">float</span> ty = y - y1;</span><br><span class="line">                <span class="comment">//根据0-1之间的x，y的权重计算公式计算权重</span></span><br><span class="line">                <span class="keyword">float</span> w1 = (<span class="number">1</span>-tx) * (<span class="number">1</span>-ty);</span><br><span class="line">                <span class="keyword">float</span> w2 =    tx  * (<span class="number">1</span>-ty);</span><br><span class="line">                <span class="keyword">float</span> w3 = (<span class="number">1</span>-tx) *    ty;</span><br><span class="line">                <span class="keyword">float</span> w4 =    tx  *    ty;</span><br><span class="line">                <span class="comment">//3.根据双线性插值公式计算第k个采样点的灰度值</span></span><br><span class="line">                <span class="keyword">float</span> neighbor = src.at&lt;_tp&gt;(x1,y1) * w1 + src.at&lt;_tp&gt;(x1,y2) *w2                     + src.at&lt;_tp&gt;(x2,y1) * w3 +src.at&lt;_tp&gt;(x2,y2) *w4;</span><br><span class="line">                <span class="comment">//通过比较获得LBP值，并按顺序排列起来</span></span><br><span class="line">                lbpCode |= (neighbor&gt;center) &lt;&lt;(neighbors-k<span class="number">-1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            dst.at&lt;uchar&gt;(i-radius,j-radius) = lbpCode;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下面是优化版本：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">//圆形LBP特征计算，效率优化版本，声明时默认neighbors=8</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> _tp&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">getCircularLBPFeatureOptimization</span><span class="params">(InputArray _src,OutputArray _dst,<span class="keyword">int</span> radius,<span class="keyword">int</span> neighbors)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Mat src = _src.getMat();</span><br><span class="line">    <span class="comment">//LBP特征图像的行数和列数的计算要准确</span></span><br><span class="line">    _dst.create(src.rows<span class="number">-2</span>*radius,src.cols<span class="number">-2</span>*radius,CV_8UC1);</span><br><span class="line">    Mat dst = _dst.getMat();</span><br><span class="line">    dst.setTo(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> k=<span class="number">0</span>;k&lt;neighbors;k++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">//计算采样点对于中心点坐标的偏移量rx，ry</span></span><br><span class="line">        <span class="keyword">float</span> rx = <span class="keyword">static_cast</span>&lt;<span class="keyword">float</span>&gt;(radius * <span class="built_in">cos</span>(<span class="number">2.0</span> * CV_PI * k / neighbors));</span><br><span class="line">        <span class="keyword">float</span> ry = -<span class="keyword">static_cast</span>&lt;<span class="keyword">float</span>&gt;(radius * <span class="built_in">sin</span>(<span class="number">2.0</span> * CV_PI * k / neighbors));</span><br><span class="line">        <span class="comment">//为双线性插值做准备</span></span><br><span class="line">        <span class="comment">//对采样点偏移量分别进行上下取整</span></span><br><span class="line">        <span class="keyword">int</span> x1 = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(<span class="built_in">floor</span>(rx));</span><br><span class="line">        <span class="keyword">int</span> x2 = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(<span class="built_in">ceil</span>(rx));</span><br><span class="line">        <span class="keyword">int</span> y1 = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(<span class="built_in">floor</span>(ry));</span><br><span class="line">        <span class="keyword">int</span> y2 = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(<span class="built_in">ceil</span>(ry));</span><br><span class="line">        <span class="comment">//将坐标偏移量映射到0-1之间</span></span><br><span class="line">        <span class="keyword">float</span> tx = rx - x1;</span><br><span class="line">        <span class="keyword">float</span> ty = ry - y1;</span><br><span class="line">        <span class="comment">//根据0-1之间的x，y的权重计算公式计算权重，权重与坐标具体位置无关，与坐标间的差值有关</span></span><br><span class="line">        <span class="keyword">float</span> w1 = (<span class="number">1</span>-tx) * (<span class="number">1</span>-ty);</span><br><span class="line">        <span class="keyword">float</span> w2 =    tx  * (<span class="number">1</span>-ty);</span><br><span class="line">        <span class="keyword">float</span> w3 = (<span class="number">1</span>-tx) *    ty;</span><br><span class="line">        <span class="keyword">float</span> w4 =    tx  *    ty;</span><br><span class="line">        <span class="comment">//循环处理每个像素</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=radius;i&lt;src.rows-radius;i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=radius;j&lt;src.cols-radius;j++)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="comment">//获得中心像素点的灰度值</span></span><br><span class="line">                _tp center = src.at&lt;_tp&gt;(i,j);</span><br><span class="line">                <span class="comment">//根据双线性插值公式计算第k个采样点的灰度值</span></span><br><span class="line">                <span class="keyword">float</span> neighbor = src.at&lt;_tp&gt;(i+x1,j+y1) * w1 + src.at&lt;_tp&gt;(i+x1,j+y2) *w2                     + src.at&lt;_tp&gt;(i+x2,j+y1) * w3 +src.at&lt;_tp&gt;(i+x2,j+y2) *w4;</span><br><span class="line">                <span class="comment">//LBP特征图像的每个邻居的LBP值累加，累加通过与操作完成，对应的LBP值通过移位取得</span></span><br><span class="line">                dst.at&lt;uchar&gt;(i-radius,j-radius) |= (neighbor&gt;center) &lt;&lt;(neighbors-k<span class="number">-1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>旋转不变性圆形LBP：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> _tp&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">getRotationInvariantLBPFeature</span><span class="params">(InputArray _src,OutputArray _dst,<span class="keyword">int</span> radius,<span class="keyword">int</span> neighbors)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Mat src = _src.getMat();</span><br><span class="line">    <span class="comment">//LBP特征图像的行数和列数的计算要准确</span></span><br><span class="line">    _dst.create(src.rows<span class="number">-2</span>*radius,src.cols<span class="number">-2</span>*radius,CV_8UC1);</span><br><span class="line">    Mat dst = _dst.getMat();</span><br><span class="line">    dst.setTo(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> k=<span class="number">0</span>;k&lt;neighbors;k++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">//计算采样点对于中心点坐标的偏移量rx，ry</span></span><br><span class="line">        <span class="keyword">float</span> rx = <span class="keyword">static_cast</span>&lt;<span class="keyword">float</span>&gt;(radius * <span class="built_in">cos</span>(<span class="number">2.0</span> * CV_PI * k / neighbors));</span><br><span class="line">        <span class="keyword">float</span> ry = -<span class="keyword">static_cast</span>&lt;<span class="keyword">float</span>&gt;(radius * <span class="built_in">sin</span>(<span class="number">2.0</span> * CV_PI * k / neighbors));</span><br><span class="line">        <span class="comment">//为双线性插值做准备</span></span><br><span class="line">        <span class="comment">//对采样点偏移量分别进行上下取整</span></span><br><span class="line">        <span class="keyword">int</span> x1 = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(<span class="built_in">floor</span>(rx));</span><br><span class="line">        <span class="keyword">int</span> x2 = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(<span class="built_in">ceil</span>(rx));</span><br><span class="line">        <span class="keyword">int</span> y1 = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(<span class="built_in">floor</span>(ry));</span><br><span class="line">        <span class="keyword">int</span> y2 = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(<span class="built_in">ceil</span>(ry));</span><br><span class="line">        <span class="comment">//将坐标偏移量映射到0-1之间</span></span><br><span class="line">        <span class="keyword">float</span> tx = rx - x1;</span><br><span class="line">        <span class="keyword">float</span> ty = ry - y1;</span><br><span class="line">        <span class="comment">//根据0-1之间的x，y的权重计算公式计算权重，权重与坐标具体位置无关，与坐标间的差值有关</span></span><br><span class="line">        <span class="keyword">float</span> w1 = (<span class="number">1</span>-tx) * (<span class="number">1</span>-ty);</span><br><span class="line">        <span class="keyword">float</span> w2 =    tx  * (<span class="number">1</span>-ty);</span><br><span class="line">        <span class="keyword">float</span> w3 = (<span class="number">1</span>-tx) *    ty;</span><br><span class="line">        <span class="keyword">float</span> w4 =    tx  *    ty;</span><br><span class="line">        <span class="comment">//循环处理每个像素</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=radius;i&lt;src.rows-radius;i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=radius;j&lt;src.cols-radius;j++)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="comment">//获得中心像素点的灰度值</span></span><br><span class="line">                _tp center = src.at&lt;_tp&gt;(i,j);</span><br><span class="line">                <span class="comment">//根据双线性插值公式计算第k个采样点的灰度值</span></span><br><span class="line">                <span class="keyword">float</span> neighbor = src.at&lt;_tp&gt;(i+x1,j+y1) * w1 + src.at&lt;_tp&gt;(i+x1,j+y2) *w2                     + src.at&lt;_tp&gt;(i+x2,j+y1) * w3 +src.at&lt;_tp&gt;(i+x2,j+y2) *w4;</span><br><span class="line">                <span class="comment">//LBP特征图像的每个邻居的LBP值累加，累加通过与操作完成，对应的LBP值通过移位取得</span></span><br><span class="line">                dst.at&lt;uchar&gt;(i-radius,j-radius) |= (neighbor&gt;center) &lt;&lt;(neighbors-k<span class="number">-1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//进行旋转不变处理</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;dst.rows;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;dst.cols;j++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">unsigned</span> <span class="keyword">char</span> currentValue = dst.at&lt;uchar&gt;(i,j);</span><br><span class="line">            <span class="keyword">unsigned</span> <span class="keyword">char</span> minValue = currentValue;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> k=<span class="number">1</span>;k&lt;neighbors;k++)</span><br><span class="line">            &#123;</span><br><span class="line">    <span class="comment">//循环左移</span></span><br><span class="line">                <span class="keyword">unsigned</span> <span class="keyword">char</span> temp = (currentValue&gt;&gt;(neighbors-k)) | (currentValue&lt;&lt;k);</span><br><span class="line">                <span class="keyword">if</span>(temp &lt; minValue)</span><br><span class="line">                &#123;</span><br><span class="line">                    minValue = temp;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            dst.at&lt;uchar&gt;(i,j) = minValue;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>参考链接：</p>
</blockquote>
<ol>
<li><a href="https://www.cnblogs.com/lxy2017/p/3927280.html" target="_blank" rel="noopener">https://www.cnblogs.com/lxy2017/p/3927280.html</a></li>
<li><a href="http://www.cse.msu.edu/~rossarun/BiometricsTextBook/Papers/Face/Ojala_LBP_PAMI02.pdf" target="_blank" rel="noopener">http://www.cse.msu.edu/~rossarun/BiometricsTextBook/Papers/Face/Ojala_LBP_PAMI02.pdf</a></li>
<li><a href="https://www.cnblogs.com/urglyfish/p/12424087.html" target="_blank" rel="noopener">https://www.cnblogs.com/urglyfish/p/12424087.html</a></li>
<li><a href="https://blog.csdn.net/qq_26898461/article/details/46875517" target="_blank" rel="noopener">https://blog.csdn.net/qq_26898461/article/details/46875517</a></li>
<li><a href="http://www.mamicode.com/info-detail-2947114.html" target="_blank" rel="noopener">http://www.mamicode.com/info-detail-2947114.html</a></li>
</ol>
]]></content>
      <categories>
        <category>CV</category>
      </categories>
  </entry>
  <entry>
    <title>Harris特征点检测器-兴趣点检测</title>
    <url>/posts/5f014252.html</url>
    <content><![CDATA[<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><h2 id="特征提取（检测）"><a href="#特征提取（检测）" class="headerlink" title="特征提取（检测）"></a>特征提取（检测）</h2><p>基于特征的图像配准方法是图像配准中最常见的方法之一。它不是直接利用图像像素值，而是通过像素值导出的符号特征（如特征点、特征线、特征区域）来实现图像配准，因此可以克服利用灰度信息进行图像配准的缺点，优势主要体现在以下三个方面：</p>
<ol>
<li>利用特征点而不是图像灰度信息，大大减少了在匹配过程中的计算量；</li>
<li>特征点的匹配度量值相对位置变化比较敏感，可以提高匹配的精度；</li>
<li>特征点的提取过程可以减少噪声的影响，对灰度变化、图像形变以及遮挡等都有较好的适应</li>
</ol>
<p>总结起来，就是：<strong>特征点又被称为兴趣点或者角点</strong>，是图像的重要特征。要定义图像，我们需要关注的是<strong>图像中的特征点而不是绝对位置信息</strong>，特征点比如我们肉眼看到的突出的角点、边缘端点、极值点等。</p>
<p>用于<strong>特征点提取</strong>的算子称为“兴趣点提取检测算子”，常用的算子有：<strong>Harris角点检测、FAST特征检测、SIFT特征检测和SURF特征检测</strong>，且这些算子大都是对于<strong>图像的灰度图色彩空间</strong>上进行的像素值的计算！</p>
<p>让我们把目光放长远点看，图像的局部特征当然不只有角点一种，列举如下：</p>
<ul>
<li>角点：Harris算子，SUSAN算子, FAST算子。</li>
<li>梯度特征点：SIFT、SURF、GLOH、ASIFT、PSIFT算子 等。</li>
<li>边缘特征（线型）：Canny算子, Marr算子。</li>
<li>纹理特征：灰度共生矩阵，小波Gabor算子。</li>
</ul>
<p>于是我们可以看到这一节Harris特征点提取的地位是图像局部特征之一的一种提取方法。</p>
<h2 id="角点"><a href="#角点" class="headerlink" title="角点"></a>角点</h2><p>我们先看下面这个讲解：</p>
<p><img src="/posts/CV/harris1.png" alt></p>
<p>角点（特征点）是当窗口向各方向移动，都会引起像素值发生很大变化的一个位置点（右图）；边缘特征是仅当窗口单方向上来回移动，才会引起像素值发生较大变化的一个位置区域（中图）；平坦区域是无论窗口移动方向如何，都不会引起像素值发生很大的变化的区域（左图）。</p>
<h2 id="Harris算法"><a href="#Harris算法" class="headerlink" title="Harris算法"></a>Harris算法</h2><p>图像梯度表示一种现象：像素值发生了很大变化。<br>从表现形式来看，在数学中可以用微分或者导数表示；在数字图像中是二维离散函数求梯度后使用差分近似求导；在实操中，即计算图像中每个像素的某个领域内的灰度变化差值（细化流程：设置合适的算子与窗口大小进行卷积运算）。</p>
<p>具体的数学推导如下：</p>
<p>将图像窗口平移$[u,v]$产生灰度变化$E(u,v)$</p>
<script type="math/tex; mode=display">E(u,v) = \sum_{x,y}w(x,y)[I(x+u,y+v)-I(x,y)]^2</script><p>其中$w(x,y)$为窗口函数，可以用高斯分布或0-1分布刻画，$I(x+u,y+v)$和$I(x,y)$分别为平移后与平移前的图像灰度，对上式进行泰勒展开可得：</p>
<script type="math/tex; mode=display">E(u,v) = \sum_{x,y}w(x,y)[I_xu+T_yv+O((u^2,v^2))]^2</script><p>略去$O$项，最终可得：</p>
<script type="math/tex; mode=display">E(x,y)\approx[u, v] [\begin{matrix}I_x^2 & I_xI_y \\ I_xI_y & I_y^2 \end{matrix}] [\begin{matrix} u \\ v \end{matrix}]  = [u, v] M [\begin{matrix} u \\ v \end{matrix}]</script><p>其中$M = \sum_{x,y}w(x,y) [\begin{matrix}I_x^2 &amp; I_xI_y \\ I_xI_y &amp; I_y^2 \end{matrix}]$</p>
<p>我们只需要讨论这个2×2的矩阵M，M的特征值记为$\lambda_1, \lambda_2$，这两个特征值分别代表沿$x,y$两个方向上灰度值的变化速度。由前面角点以及边缘特征的定义，我们可以得到：</p>
<ol>
<li>当两个特征值$λ_1$和$λ_2$都偏小的时候，表示窗口沿任意方向移动都会使灰度变化很细微，该点处于图像的平坦区域。</li>
<li>当$λ_1&gt;&gt;λ_2$或者$λ_1&lt;&lt;λ_2$时，说明该点向水平（垂直）方向移动时变化会很明显，而向垂直（水平）方向则变化不明显，该点处于图像的边缘区。</li>
<li>当两个特征值$λ_1$和$λ_2$都很大的时候，表示窗口沿任意方向移动都会使灰度变化很明显，该点位置就是图像角点的位置。</li>
</ol>
<p>也就得到了下面这张图所示：</p>
<p><img src="/posts/CV/harris2.png" alt></p>
<h2 id="角点响应函数CRF"><a href="#角点响应函数CRF" class="headerlink" title="角点响应函数CRF"></a>角点响应函数CRF</h2><p>实际中我们很少判断两个特征值，更多的是使用角点响应函数，计算方法如下：</p>
<script type="math/tex; mode=display">R = detM - k(traceM)^2</script><p>其中$detM = \lambda_1\lambda_2,traceM = \lambda_1+\lambda_2,k$为一个修正值，经验取值为$0.04-0.06$，算出响应值之后，根据$R$与阈值$T$的比较来判断是否为角点。</p>
<ol>
<li>当$|R|$很小时，$R\lt T$ , 认为该点处于图像的平坦区域。</li>
<li>当$R&lt;0$时，$R\lt T$ , 认为该点处于图像的边缘区。</li>
<li>当$R&gt;0$时，$R&gt;T$, 认为该点位置就是图像角点。</li>
</ol>
<h2 id="附注"><a href="#附注" class="headerlink" title="附注"></a>附注</h2><ol>
<li>自定义阈值T决定角点的数量</li>
<li>Harris角点的检测算子对亮度和对比度的变化不敏感（光照敏感性），也就是说，对亮度和对比度的仿射变换并不会改变Harris响应的极值点出现的位置。</li>
<li>Harris检测算子具有旋转不变性，即特征位置发生转动，特征值并不会发生变化。</li>
<li>Harris检测算子不具有尺度不变性，即尺度的变化，会将角点变为边缘，或者边缘变为角点。而将Harris角点检测算子与高斯尺度空间表示相结合，使Harris角点检测算子具有尺度的不变性。</li>
</ol>
<h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><p>首先我导入最可爱的松鼠图，获得图片的尺寸信息：</p>
<p><img src="/posts/CV/animal.jpg" alt></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># detector parameters</span></span><br><span class="line">block_size = <span class="number">3</span></span><br><span class="line">sobel_size = <span class="number">3</span></span><br><span class="line">k = <span class="number">0.04</span></span><br><span class="line"></span><br><span class="line">image = cv2.imread(<span class="string">'Pic/animal.jpg'</span>)</span><br><span class="line"></span><br><span class="line">print(image.shape)</span><br><span class="line">height = image.shape[<span class="number">0</span>]</span><br><span class="line">width = image.shape[<span class="number">1</span>]</span><br><span class="line">channels = image.shape[<span class="number">2</span>]</span><br><span class="line">print(<span class="string">"width: %s  height: %s  channels: %s"</span> % (width, height, channels))</span><br></pre></td></tr></table></figure>
<p>然后将一个三维的BGR彩色图像转化为一张二维的数据类型为float32灰度图：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</span><br><span class="line">gray_img = np.float32(gray_img)</span><br></pre></td></tr></table></figure>
<p>下面一行代码运用Harris角点检测算法进行角点的检测<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">corners_img = cv2.cornerHarris(gray_img, block_size, sobel_size, k)</span><br></pre></td></tr></table></figure></p>
<p>定义一个显示函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cv_show</span><span class="params">(name, img)</span>:</span></span><br><span class="line">    cv2.imshow(name, img)</span><br><span class="line">    cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>显示得到的图像为（好诡异）：</p>
<p><img src="/posts/CV/corner_img.png" alt></p>
<p>随后我们构造卷积核(kernel为3×2全1矩阵)，对图像进行膨胀操作：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">dst = cv2.dilate(corners_img, kernel)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">"dst"</span>,dst)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>由于膨胀后的图像与上一个比起来看不出什么变化就不进行展示了。我们使用膨胀的原因就是非极大值抑制，其原理是：在一个窗口内，如果有多个角点则用值最大的那个角点，其他的角点都删除，窗口大小这里我们用3*3，程序中通过图像的膨胀运算来达到检测极大值的目的，因为默认参数的膨胀运算就是用窗口内的最大值替代当前的灰度值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> r <span class="keyword">in</span> range(height):</span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> range(width):</span><br><span class="line">        <span class="comment"># 拿出每一个位置的像素值。</span></span><br><span class="line">        pix = dst[r, c]</span><br><span class="line">        <span class="comment"># 这里选用的参数k是0.05</span></span><br><span class="line">        <span class="keyword">if</span> pix &gt; <span class="number">0.05</span> * dst.max():</span><br><span class="line">            <span class="comment"># cicle 参数：图像二维数组、中心位置坐标、半径、颜色、thickness：圆形轮廓的粗细</span></span><br><span class="line">            <span class="comment"># 其中，thickness 正值表示圆形轮廓的粗细，而负厚度表示要绘制实心圆。</span></span><br><span class="line">            <span class="comment"># 颜色 可以是三通道的元组模式，其中如果用cv显示将被解析为BGR,如果用plt则RGB</span></span><br><span class="line">            cv2.circle(image, (c, r), <span class="number">5</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>上述代码似乎跑的比较慢，我们也可以使用简化版的代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"></span><br><span class="line">filename = <span class="string">'Pic/animal.jpg'</span></span><br><span class="line">img = cv.imread(filename)</span><br><span class="line">gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)</span><br><span class="line">gray = np.float32(gray)</span><br><span class="line">dst = cv.cornerHarris(gray,<span class="number">2</span>,<span class="number">3</span>,<span class="number">0.04</span>)</span><br><span class="line"><span class="comment">#result用于标记角点，并不重要</span></span><br><span class="line">dst = cv.dilate(dst,<span class="literal">None</span>)</span><br><span class="line"><span class="comment">#最佳值的阈值，它可能因图像而异。</span></span><br><span class="line">img[dst&gt;<span class="number">0.01</span>*dst.max()]=[<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>]</span><br><span class="line">cv.imshow(<span class="string">'dst'</span>,img)</span><br><span class="line"><span class="keyword">if</span> cv.waitKey(<span class="number">0</span>) &amp; <span class="number">0xff</span> == <span class="number">27</span>:</span><br><span class="line">    cv.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>得到的图像如下:</p>
<p><img src="/posts/CV/img1.png" alt></p>
<p>我们修改阈值参数(修改为0.03)，图像如下：</p>
<p><img src="/posts/CV/img2.png" alt></p>
<p>以上就是Harris特征点检测的的全部内容啦~</p>
<blockquote>
<p>参考文章：<br><a href="https://blog.csdn.net/bymar/article/details/104503450/" target="_blank" rel="noopener">https://blog.csdn.net/bymar/article/details/104503450/</a><br><a href="https://blog.csdn.net/m0_38052500/article/details/106877072?utm_source=blogxgwz7" target="_blank" rel="noopener">https://blog.csdn.net/m0_38052500/article/details/106877072?utm_source=blogxgwz7</a><br><a href="https://blog.csdn.net/pbymw8iwm/article/details/82624898" target="_blank" rel="noopener">https://blog.csdn.net/pbymw8iwm/article/details/82624898</a><br><a href="https://blog.csdn.net/weixin_41923000/article/details/88631944" target="_blank" rel="noopener">https://blog.csdn.net/weixin_41923000/article/details/88631944</a><br><a href="http://www.woshicver.com/Sixth/5_2_%E5%93%88%E9%87%8C%E6%96%AF%E8%A7%92%E6%A3%80%E6%B5%8B/" target="_blank" rel="noopener">http://www.woshicver.com/Sixth/5_2_%E5%93%88%E9%87%8C%E6%96%AF%E8%A7%92%E6%A3%80%E6%B5%8B/</a></p>
</blockquote>
]]></content>
      <categories>
        <category>CV</category>
      </categories>
  </entry>
  <entry>
    <title>受限玻尔兹曼机</title>
    <url>/posts/e20ce036.html</url>
    <content><![CDATA[<h1 id="受限玻尔兹曼机模型"><a href="#受限玻尔兹曼机模型" class="headerlink" title="受限玻尔兹曼机模型"></a>受限玻尔兹曼机模型</h1><p>Restricted Boltzmann machines are some of the most common building blocks of <strong>deep probabilistic models</strong>. They are undirected probabilistic graphical models containing a layer of observable variables and a single layer of latent variables.</p>
<p>RBM根据MLE原理来估计预定义分布中的参数，以便预定义分布能尽可能地逼近产生观测数据的未知分布。多个RBM分层堆叠而成的DBN(deep belief networks)构成深度学习的主要框架。如下图：</p>
<p><img src="/Pic/%E5%8F%97%E9%99%90%E7%8E%BB%E5%B0%94%E5%85%B9%E6%9B%BC%E6%9C%BA/1.webp" alt></p>
<p>具体模型为：</p>
<script type="math/tex; mode=display">p(v, h) = \frac{1}{Z}\text{exp}(-E(v,h))</script><p>其中$E(v, h)$是能量函数，定义如下：</p>
<script type="math/tex; mode=display">E(v, h) = -b^Tv - c^Th - v^TWh</script><p>$Z$为正规化函数，定义如下：</p>
<script type="math/tex; mode=display">Z = \sum_v\sum_h\text{exp}(-E(v, h))</script><p>目标函数是极大化概率似然函数$\prod{p(v, h)}$，因此我们希望$E(v, h)$尽可能小，将能量中的点积写成求和式：</p>
<script type="math/tex; mode=display">E(v, h) = -b^Tv-c^Th-v^TWh = -\sum_kb_kv_k - \sum_jc_jh_j - \sum_j\sum_kW_{jk}h_jv_k</script><p>如果$b_k&gt;0$，因为$v_k \in \{0,1\}$，那么要使得能量最小，我们更希望$v_k=1$；反之如果$b_k&lt;0$，我们更希望$v_k=0$。用同样的方式对$b_j,W_{jk}$进行分析，总结如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>系数的情形</th>
<th>我们倾向的选择</th>
</tr>
</thead>
<tbody>
<tr>
<td>$b_k&gt;0$</td>
<td>$v_k=1$</td>
</tr>
<tr>
<td>$b_k&lt;0$</td>
<td>$v_k=0$</td>
</tr>
<tr>
<td>$c_j&gt;0$</td>
<td>$h_j =1$</td>
</tr>
<tr>
<td>$c_j&lt;0$</td>
<td>$h_j =0$</td>
</tr>
<tr>
<td>$W_{jk} &gt; 0$</td>
<td>$h_jv_k =1$</td>
</tr>
<tr>
<td>$W_{jk} &lt; 0$</td>
<td>$h_jv_k =0$</td>
</tr>
</tbody>
</table>
</div>
<p>接着考虑如何最大化$\prod p(v,h)$，这个式子中有$Z$，而$Z$是指数的求和，不大好处理，所以我们不优化这个式子，考虑条件概率$p(h|v)$</p>
<script type="math/tex; mode=display">\begin{equation}\begin{split} p(h|v) &=\frac{p(h,v)}{p(v)}\\ &= \frac{ \frac 1 Z \exp\Big(-E (v,h)\Big)}{ \sum_h \frac 1 Z \exp\Big(-E (v,h)\Big)}\\ &=\frac{ \exp\Big(-E (v,h)\Big)}{ \sum_h \exp\Big(-E (v,h)\Big)}\\ &=\frac{ \exp\Big( b^Tv + c^Th +v^TWh \Big)}{ \sum_h \exp\Big( b^Tv + c^Th +v^TWh \Big)} \\ &= \frac{\exp \Big( b^Tv \Big)\exp\Big( c^Th +v^TWh \Big)}{\exp \Big( b^Tv \Big) \sum_h \exp\Big( c^Th +v^TWh \Big)}\\ &= \frac{\exp\Big( c^Th +v^TWh \Big)}{\sum_h \exp\Big( c^Th +v^TWh \Big)}\\ &= \frac{\exp\Big( \sum_j c_jh_j +\sum_j v^T W_{:j}h_j \Big)}{Z^{'}}\\ &= \frac{1}{Z^{'}} \prod_{j=1}^n \exp \Big( c_jh_j +v^T W_{:j}h_j \Big) \end{split}\end{equation}</script><p>这里$Z^{‘}=\sum_h \exp\Big( c^Th +v^TWh \Big),W_{:j}$是$W$的第$j$列</p>
<p>注意$Z^{‘}$是常数，上式将概率分解为有关$h_1,…,h_n$项的乘积，所以这个式子告诉我们$p(h_1|v),…,p(h_n|v)$条件独立：</p>
<script type="math/tex; mode=display">p(h|v) =\prod _{j=1}^n p(h_j|v)</script><p>并且</p>
<script type="math/tex; mode=display">p(h_j|v) \propto \exp \Big( c_jh_j +v^T W_{:j}h_j \Big)</script><p>我们利用上式计算$p(h_j=1|v),p(h_j=0|v)$</p>
<script type="math/tex; mode=display">\begin{aligned} p(h_j=1|v) &= \frac{p(h_j=1,v)}{p(v)}\\ &= \frac{p(h_j=1,v)}{p(h_j=0,v)+p(h_j=1,v)}\\ &= \frac{ \exp \Big( c_j +v^T W_{:j} \Big)}{\exp(0)+\exp \Big( c_j +v^T W_{:j} \Big) }\\ &= \text{sigmoid} (c_j +v^TW_{:j}) \end{aligned}</script><script type="math/tex; mode=display">\begin{aligned} p(h_j=0|v) &= 1-p(h_j=1|v) \\ &= 1 - \text{sigmoid} (c_j +v^TW_{:j}) \end{aligned}</script><p>其中$\text{sigmoid}(z) = \frac{1}{1+e^{-z}}$<br>由$v,h$的对称性，同理可得</p>
<script type="math/tex; mode=display">p(v|h) = \prod _{i=1}^n p(v_i|h)\\ p(v_i=1|h) = \text{sigmoid} (b_i +W_{i:}h) \\ p(v_i=0|h) =1- \text{sigmoid} (b_i +W_{i:}h)</script><p>其中$W_{i:}$表示$W$的第$i$行</p>
<h1 id="RBM-Gibbs-Sampling"><a href="#RBM-Gibbs-Sampling" class="headerlink" title="RBM Gibbs Sampling"></a>RBM Gibbs Sampling</h1><p>根据条件独立性，可以得到如下取样的方法：</p>
<ul>
<li><p>取样$h^{(l)} ∼ P(h|v^{(l)} )$：我们可以在给定$v^{(l)}$的条件下同时并且独立的对$h^{(l)}$中的每个元素取样。</p>
</li>
<li><p>取样$v^{(l+1)} ∼ P(v|h^{(l)} )$由条件独立性，我们可以在给定$h^{(l)}$的条件下同时并且独立的对$v^{(l+1)}$中的每个元素取样。</p>
</li>
</ul>
<p>这种取样方法叫做<strong>Gibbs Sampling</strong></p>
<h1 id="训练受限玻尔兹曼机"><a href="#训练受限玻尔兹曼机" class="headerlink" title="训练受限玻尔兹曼机"></a>训练受限玻尔兹曼机</h1><p>这里考虑如何训练受限玻尔兹曼机，我们的目标肯定是极大化概率似然函数，或者等价地，极大化对数概率似然函数，我们进行如下处理：</p>
<script type="math/tex; mode=display">\begin{aligned} \ell (W,b,c) &= \sum_{t=1}^n \log P(v^{(t)})\\ &= \sum_{t=1}^n \log \sum _h P(v^{(t)},h)\\ &= \sum_{t=1}^n \log \sum _h \frac 1 Z \exp\Big(-E (v^{(t)},h)\Big)\\ &= \sum_{t=1}^n \log \frac 1 Z \sum _h \exp\Big(-E (v^{(t)},h)\Big)\\ &= \sum_{t=1}^n \log \sum _h \exp\Big(-E (v^{(t)},h)\Big) - \sum_{t=1}^n \log Z\\ &= \sum_{t=1}^n \log \sum _h \exp\Big(-E (v^{(t)},h)\Big) - n \log Z\\ &= \sum_{t=1}^n \log \sum _h \exp\Big(-E (v^{(t)},h)\Big) - n \log \sum _{v,h} \exp\Big(-E (v,h)\Big)\\ \end{aligned}</script><p>令$\theta =\{b,c,W\}$，我们来对上式关于$\theta$求梯度：</p>
<script type="math/tex; mode=display">\begin{aligned} \nabla_\theta \ell (W,b,c) &=\nabla_\theta\sum_{t=1}^n \log \sum _h \exp\Big(-E (v^{(t)},h)\Big) - n \nabla_\theta\log \sum _{v,h} \exp\Big(-E (v,h)\Big)\\ &=\sum_{t=1}^n \frac{\nabla_\theta \sum _h \exp\Big(-E (v^{(t)},h)\Big)}{ \sum _h \exp\Big(-E (v^{(t)},h)\Big)} - n\frac{\nabla_\theta \sum _{v,h} \exp\Big(-E (v,h)\Big)}{ \sum _{v,h} \exp\Big(-E (v,h)\Big)}\\ &=\sum_{t=1}^n \frac{ \sum _h \exp\Big(-E (v^{(t)},h)\Big) \nabla_\theta \Big( -E (v^{(t)},h)\Big)}{ \sum _h \exp\Big(-E (v^{(t)},h)\Big)}- n\frac{ \sum _{v,h}\exp\Big(-E (v,h)\Big)\nabla_\theta \Big( -E (v,h)\Big)}{ \sum _{v,h}\exp\Big(-E (v,h)\Big)}\ \end{aligned}</script><p>注意，所以上述两项都可以看成随机变量的期望，所以可以写成如下形式：</p>
<script type="math/tex; mode=display">\begin{aligned} \nabla_\theta \ell (W,b,c) &= \sum_{t=1}^n \mathbb E_{P(h|v^{(t)})}\Big[ \nabla_\theta \Big( -E (v^{(t)},h)\Big)\Big] - n \mathbb E_{P(h,v)}\Big[ \nabla_\theta \Big( -E (v,h)\Big)\Big] \end{aligned}</script><p>第一项可以理解关于data的，第二项可以理解为关于model的。</p>
<p>我们利用能量的定义分别对上式再进行处理</p>
<script type="math/tex; mode=display">\begin{aligned} \nabla_W \Big( -E (v,h)\Big) &= \frac{\partial}{\partial W} \Big(b^Tv + c^Th +v^TWh\Big)\\ &= hv^T \end{aligned}\\ \begin{aligned} \nabla_b \Big( -E (v,h)\Big) &= \frac{\partial}{\partial b} \Big(b^Tv + c^Th +v^TWh\Big)\\ &= v \end{aligned}\\ \begin{aligned} \nabla_c \Big( -E (v,h)\Big) &= \frac{\partial}{\partial c} \Big(b^Tv + c^Th +v^TWh\Big)\\ &=h \end{aligned}</script><p>记</p>
<script type="math/tex; mode=display">\hat h^{(t)} = \mathbb E_{P(h|v^{(t)})}[h] =P(h=1|v^{(t)})= \text{sigmoid}(c+{v^{(t)}}^TW)</script><p>带入上式可得</p>
<script type="math/tex; mode=display">\nabla_W \ell (W,b,c) = \sum_{t=1}^n \hat h^{(t)}{v^{(t)}}^T - n \mathbb E_{P(h,v)}[ hv^T] \\ \nabla_b \ell (W,b,c) = \sum_{t=1}^n {v^{(t)}}^T - n \mathbb E_{P(h,v)}[ v] \\ \nabla_c \ell (W,b,c) = \sum_{t=1}^n \hat h^{(t)} - n \mathbb E_{P(h,v)}[ h]</script><p>但是注意<script type="math/tex">\mathbb E_{P(h,v)}\Big[ \nabla_\theta \Big( -E (v,h)\Big)\Big]</script>依旧涉及到<script type="math/tex">Z = \sum_v \sum_h \exp\Big(-E (v,h)\Big)</script>非常难计算，所以实际上我们会用如下近似：</p>
<script type="math/tex; mode=display">\mathbb E_{P(h,v)}\Big[ \nabla_\theta \Big( -E (v,h)\Big)\Big] \approx \nabla_\theta \Big( -E (v,h)\Big) \Big| _{v=\hat v ,h=\hat h}</script><p>对上述式子运用此近似可得</p>
<script type="math/tex; mode=display">\nabla_W \ell (W,b,c) \approx \sum_{t=1}^n h(v^{(t)}){v^{(t)}}^T - n h(\tilde v ) \tilde v ^T \\ \nabla_b \ell (W,b,c) \approx \sum_{t=1}^n {v^{(t)}}^T - n \tilde v \\ \nabla_c \ell (W,b,c) \approx \sum_{t=1}^n h(v^{(t)}) - n h(\tilde v )</script><p>实际中我们会使用随机梯度，所以更新式如下</p>
<script type="math/tex; mode=display">W = W+ \alpha \Big( h(v^{(t)}){v^{(t)}}^T - h(\tilde v ) \tilde v ^T\Big) \\ b= b+ \alpha \Big( h(v^{(t)}) - h(\tilde v )\Big) \\ c = c+ \alpha \Big( v^{(t)} -\tilde v\Big)</script><p>注意这里之所以使用加号是因为这里要最大化目标和函数，所以使用梯度上升。</p>
<p>算法总结<br>把上述内容总结起来，就可以得到如下算法：</p>
<ul>
<li><p>对每个训练数据v^{(t)}</p>
<ul>
<li>从$v^{(t)}$开始使用$k$步Gibbs Sampling生成样本$\tilde v$</li>
<li>更新参数<script type="math/tex; mode=display">W = W+ \alpha \Big( h(v^{(t)}){v^{(t)}}^T - h(\tilde v ) \tilde v ^T\Big) \\ b= b+ \alpha \Big( h(v^{(t)}) - h(\tilde v )\Big) \\ c = c+ \alpha \Big( v^{(t)} -\tilde v\Big)</script></li>
</ul>
</li>
<li><p>返回至1直至停止条件满足</p>
</li>
</ul>
<p>参考链接：</p>
<ul>
<li><a href="https://uwaterloo.ca/data-analytics/sites/ca.data-analytics/files/uploads/files/dbn2.pdf" target="_blank" rel="noopener">https://uwaterloo.ca/data-analytics/sites/ca.data-analytics/files/uploads/files/dbn2.pdf</a></li>
<li><a href="https://www.jianshu.com/p/378e4c93411a" target="_blank" rel="noopener">https://www.jianshu.com/p/378e4c93411a</a></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>GAN学习（一）</title>
    <url>/posts/ba35fcf2.html</url>
    <content><![CDATA[<h1 id="啥是GAN网络"><a href="#啥是GAN网络" class="headerlink" title="啥是GAN网络"></a>啥是GAN网络</h1><h2 id="通俗地理解GAN网络"><a href="#通俗地理解GAN网络" class="headerlink" title="通俗地理解GAN网络"></a>通俗地理解GAN网络</h2><p>GAN的全称是Generative adversarial network（对抗神经网络）：</p>
<ul>
<li>Gererative：生成模型</li>
<li>Adversarial：使用对抗的方法训练</li>
<li>Networks：使用神经网络</li>
</ul>
<p>由他的名字我们可以知道对抗神经网络是通过对抗的方法去学习数据分布的生成网络，它其实是两个网络的组合，可以理解为一个网络生成模拟数据（生成网络Generator），另一个网络判断生成的数据是真实的还是模拟的（判别网络Discriminator）。生成网络要不断优化自己生成的数据让判别网络判断不出来（纳什均衡），判别网络也要优化自己让自己判断得更准确。二者关系形成对抗，因此叫对抗神经网络。下面这段形象的比喻来自<a href="https://arxiv.org/pdf/1406.2661.pdf" target="_blank" rel="noopener">论文原文</a>：</p>
<blockquote>
<p>The generative model can be thought of as analogous to a team of counterfeiters, trying to produce fake currency and use it without detection, while the discriminative model is analogous to the police, trying to detect the counterfeit currency.    </p>
</blockquote>
<p>常用的模型大多可以分为两类，生成模型（Generative Model）和判别模型（Discriminative Model）。前者的输出是“看起来很逼真”的虚假数据，例如合成人脸图片、撰写新闻报道，应当和真实的数据尽可能相似；相比之下，后者一般实现一个从复杂结构数据到简单判别结果的映射（Mapping），例如判断图片是猫还是狗、文本所表达的情绪为积极或者消极。</p>
<p>根据以上的定义，GAN显然属于生成模型，因为我们希望通过GAN生成一些以假乱真的合成数据。进一步而言，生成模型可以分为无条件（Unconditional）和有条件（Conditional）两类，其中前者的生成结果完全随机，后者的生成结果则是可控的，例如生成男性或女性的人脸图片、撰写符合某个话题的新闻报道。</p>
<p>总结<strong>对抗学习和监督学习的区别：</strong></p>
<ul>
<li>监督学习：有明确的标签信息，类似于教小朋友画画</li>
<li>对抗学习：小朋友自己模仿，由大人来鉴别好坏</li>
</ul>
<p><strong>GAN网络唯一需要记住的公式：</strong></p>
<script type="math/tex; mode=display">\text{min}_G \text{max}_DV(D, G)</script><p>其中</p>
<script type="math/tex; mode=display">V(D,G)=\mathbb{E}_{x\text{~}p(x)}[\text{log}D(x)]+\mathbb{E}_{z\text{~}q(z)}[\text{log}(1-D(G(z)))]</script><p>$G$的目的：$G$希望自己生成的数据越真实越好，即$G$希望$D(G(z))$尽可能大，此时$V(D,G)$会变小</p>
<p>$D$的目的：$D$的能力越强，$D(x)$应该越大，$D(G(x))$应该越小，此时$V(D,G)$应该越大，即$\text{max}D$</p>
<p><strong>由于两个网络都需要训练，因此训练其中一个网络时需要锁定另外一个网络，通过迭代的方式可以训练好网络</strong></p>
<h2 id="如何更通俗地理解GAN网络"><a href="#如何更通俗地理解GAN网络" class="headerlink" title="如何更通俗地理解GAN网络"></a>如何更通俗地理解GAN网络</h2><p>有人说GAN强大之处在于可以自动的学习原始真实样本集的数据分布，不管这个分布多么的复杂，只要训练的足够好就可以学出来。针对这一点，感觉有必要好好理解一下为什么别人会这么说。</p>
<p>我们知道，传统的机器学习方法，我们一般都会定义一个什么模型让数据去学习。比如说假设我们知道原始数据属于高斯分布呀，只是不知道高斯分布的参数，这个时候我们定义高斯分布，然后利用数据去学习高斯分布的参数得到我们最终的模型。再比如说我们定义一个分类器，比如SVM，然后强行让数据进行东变西变，进行各种高维映射，最后可以变成一个简单的分布，SVM可以很轻易的进行二分类分开，其实SVM已经放松了这种映射关系了，但是也是给了一个模型，这个模型就是核映射（什么径向基函数等等），说白了其实也好像是你事先知道让数据该怎么映射一样，只是核映射的参数可以学习罢了。</p>
<p>所有的这些方法都在直接或者间接的告诉数据你该怎么映射一样，只是不同的映射方法能力不一样。那么我们再来看看GAN，生成模型最后可以通过噪声生成一个完整的真实数据（比如人脸），说明生成模型已经掌握了从随机噪声到人脸数据的分布规律了，有了这个规律，想生成人脸还不容易。然而这个规律我们开始知道吗？显然不知道，如果让你说从随机噪声到人脸应该服从什么分布，你不可能知道。这是一层层映射之后组合起来的非常复杂的分布映射规律。然而GAN的机制可以学习到，也就是说GAN学习到了真实样本集的数据分布。<br>还有人说GAN强大之处在于可以自动的定义潜在损失函数。 什么意思呢，这应该说的是判别网络可以自动学习到一个好的判别方法，其实就是等效的理解为可以学习到好的损失函数，来比较好或者不好的判别出来结果。虽然大的loss函数还是我们人为定义的，基本上对于多数GAN也都这么定义就可以了，但是判别网络潜在学习到的损失函数隐藏在网络之中，不同的问题这个函数就不一样，所以说可以自动学习这个潜在的损失函数。</p>
<p>总而言之：<strong>GAN网络最强大的地方就是可以帮助我们建立模型，而不像传统的网络那样是在已有模型上帮我们更新参数而已。同时，GAN网络是一种无监督的学习方式，它的泛化性非常好。</strong></p>
<h2 id="GAN的应用场景"><a href="#GAN的应用场景" class="headerlink" title="GAN的应用场景"></a>GAN的应用场景</h2><ol>
<li>数据生成，主要指图像生成。常用的有DCGAN WGAN，BEGAN；</li>
<li>GAN本身也是一种无监督学习的典范，因此它在无监督学习，半监督学习领域都有广泛的应用；</li>
<li>不仅在生成领域，GAN在分类领域也占有一席之地，简单来说，就是替换判别器为一个分类器，做多分类任务，而生成器仍然做生成任务，辅助分类器训练；</li>
<li>GAN可以和强化学习结合，目前一个比较好的例子就是seq-GAN；可以与迁移学习结合（Mind2Mind）</li>
<li>目前比较有意思的应用就是GAN用在图像风格迁移，图像降噪修复，图像超分辨率了，都有比较好的结果；</li>
<li>图像数据增强。</li>
</ol>
<blockquote>
<p>GAN也可以用在NLP领域，但GAN在CV界所取得的进展和成果远远多于自然语言处理（Natural Language Processing，NLP），一个主要原因就是<strong>图片的表示是“连续”的，即当像素值发生微小变化时，视觉上并不会察觉出明显的区别</strong>。相比之下，NLP任务中一般会将字或词作为最基础的语义单元，而<strong>字和词的表示是“离散”的</strong>，即我们很难统一规定，当一个字或词发生微小变化时，对应的语义是哪一个其他的字或词。字或词的这种“离散跳变性”，无疑加大了GAN训练时的困难和不稳定性，从而导致GAN在NLP领域中的发展和应用相对较少</p>
</blockquote>
<h2 id="GAN的优点"><a href="#GAN的优点" class="headerlink" title="GAN的优点"></a>GAN的优点</h2><ul>
<li>GAN是一种生成式模型，相较于其他模型（玻尔兹曼机和GSNs）只用到了反向传播，不需要复杂的马尔可夫链</li>
<li>相较于其他所有模型，GAN可以生成更加清晰真实的样本</li>
<li>GAN采用的是一种无监督的学习方式训练，可以广泛用在无监督学习和半监督学习的领域</li>
<li>相对于变分自编码器，GANs没有引入任何决定性偏置，变分方法引入决定性偏置（需要先采样），因为它们优化对数似然的下界，而不是似然度本身，这看起来导致了VAEs生成的实例比GANs更模糊</li>
<li>相比VAEs，GANs没有变分下界，如果鉴别器训练良好，那么生成器可以完美的学习到训练样本的分布，换句话说，GANs是渐进一致的，而VAE是有偏差的</li>
<li>GAN应用在一些场景上，比如图片风格迁移，超分辨率 ，图像补全，去噪，避免了损失函数设计的困难，只要有一个基准，直接上判别器，剩下就交给对抗训练了</li>
</ul>
<h2 id="GAN存在的问题"><a href="#GAN存在的问题" class="headerlink" title="GAN存在的问题"></a>GAN存在的问题</h2><h3 id="Non-Convergence（不收敛）"><a href="#Non-Convergence（不收敛）" class="headerlink" title="Non-Convergence（不收敛）"></a>Non-Convergence（不收敛）</h3><p>训练GAN需要达到纳什均衡，有时候做不到（目前找不到一定可以做到的方法），训练GAN相比VAE不稳定。</p>
<h3 id="Mode-Collapse（模式坍塌）"><a href="#Mode-Collapse（模式坍塌）" class="headerlink" title="Mode-Collapse（模式坍塌）"></a>Mode-Collapse（模式坍塌）</h3><p>可以理解为生成的内容没有多样性，这种情况一般出现在GAN训练不稳定时，具体表现为生成出来的结果非常差，即使加长训练时间后也不能得到很好的改善。</p>
<p>原因：</p>
<ul>
<li>GAN采用的是对抗训练的方式，G的梯度更新来自D，所以G生成的好不好取决于D的评价</li>
<li>如果某一次G生成的样本并不是很好，但D给出了很好的评价，或者是G生成的结果中的一些特征得到了D的认可，这时候G就会认为自己输出的是正确的，那么接下来认为这样输出D仍会给出较高的评价（实际上G输出的并不好）</li>
<li>进入一种“死循环”，最终生成结果丢失一些信息，特征不全</li>
</ul>
<h1 id="具体咋做-代码"><a href="#具体咋做-代码" class="headerlink" title="具体咋做(代码)"></a>具体咋做(代码)</h1><p>我们康一康伪代码咋写：</p>
<p><img src="/Pic/GAN%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89/1.png" alt></p>
<p>根据这个伪代码我们很容易可以完成我们的实验流程。首先以造小狗的假图片为例：首先需要一个生成小狗图片的模型，我们称之为generator，还有一个判断小狗图片是否是真假的判别模型discrimator。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator_model</span><span class="params">()</span>:</span></span><br><span class="line">    model = Sequential()</span><br><span class="line">    model.add(Dense(input_dim=<span class="number">1000</span>, output_dim=<span class="number">1024</span>))</span><br><span class="line">    model.add(Activation(<span class="string">'tanh'</span>))</span><br><span class="line">    model.add(Dense(<span class="number">128</span> * <span class="number">8</span> * <span class="number">8</span>))</span><br><span class="line">    model.add(BatchNormalization())</span><br><span class="line">    model.add(Activation(<span class="string">'tanh'</span>))</span><br><span class="line">    model.add(Reshape((<span class="number">8</span>, <span class="number">8</span>, <span class="number">128</span>), input_shape=(<span class="number">8</span> * <span class="number">8</span> * <span class="number">128</span>,)))</span><br><span class="line">    model.add(UpSampling2D(size=(<span class="number">4</span>, <span class="number">4</span>)))</span><br><span class="line">    model.add(Conv2D(<span class="number">64</span>, (<span class="number">5</span>, <span class="number">5</span>), padding=<span class="string">'same'</span>))</span><br><span class="line">    model.add(Activation(<span class="string">'tanh'</span>))</span><br><span class="line">    model.add(UpSampling2D(size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">    model.add(Conv2D(<span class="number">3</span>, (<span class="number">5</span>, <span class="number">5</span>), padding=<span class="string">'same'</span>))</span><br><span class="line">    model.add(Activation(<span class="string">'tanh'</span>))</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<p>生成器接受一个1000维的随机生成的数组，然后输出一个64×64×3通道的图片数据。判别器则输入64，64，3的图片，输出1或者0，代表图片是否是狗：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">discriminator_model</span><span class="params">()</span>:</span></span><br><span class="line">    model = Sequential()</span><br><span class="line">    model.add(Conv2D(<span class="number">64</span>, (<span class="number">5</span>, <span class="number">5</span>), padding=<span class="string">'same'</span>, input_shape=(<span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>)))</span><br><span class="line">    model.add(Activation(<span class="string">'tanh'</span>))</span><br><span class="line">    model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">    model.add(Conv2D(<span class="number">128</span>, (<span class="number">5</span>, <span class="number">5</span>)))</span><br><span class="line">    model.add(Activation(<span class="string">'tanh'</span>))</span><br><span class="line">    model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">    model.add(Flatten())</span><br><span class="line">    model.add(Dense(<span class="number">1024</span>))</span><br><span class="line">    model.add(Activation(<span class="string">'tanh'</span>))</span><br><span class="line">    model.add(Dense(<span class="number">1</span>))</span><br><span class="line">    model.add(Activation(<span class="string">'sigmoid'</span>))</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<p>下面就是GAN网络的核心部分：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator_containing_discriminator</span><span class="params">(g, d)</span>:</span></span><br><span class="line">    model = Sequential()</span><br><span class="line">    model.add(g)</span><br><span class="line">    <span class="comment"># 判别器参数不进行修改</span></span><br><span class="line">    d.trainable = <span class="literal">False</span></span><br><span class="line">    model.add(d)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<p>这个模型由生成器与判别器组成：上半部分是生成网络，下半部分是判别网络，生成网络首先生成假图，然后送入判别网络中进行判断，这里有一个d.trainable=False，意思是，只调整生成器，判别的的参数不做更改。</p>
<p>下面对生成网络进行训练：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(BATCH_SIZE)</span>:</span></span><br><span class="line">    <span class="comment"># 载入训练参数</span></span><br><span class="line">    X_train = load_data(path)</span><br><span class="line">    X_train = (X_train.astype(np.float32) - <span class="number">127.5</span>)/<span class="number">127.5</span></span><br><span class="line">    d = discriminator_model()</span><br><span class="line">    g = generator_model()</span><br><span class="line">    d_on_g = generator_containing_discriminator(g, d)</span><br><span class="line">    d_optim = SGD(lr=<span class="number">0.0005</span>, momentum=<span class="number">0.9</span>, nesterov=<span class="literal">True</span>)</span><br><span class="line">    g_optim = SGD(lr=<span class="number">0.0005</span>, momentum=<span class="number">0.9</span>, nesterov=<span class="literal">True</span>)</span><br><span class="line">    g.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=<span class="string">"SGD"</span>)</span><br><span class="line">    d_on_g.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=g_optim)</span><br><span class="line">    d.trainable = <span class="literal">True</span></span><br><span class="line">    d.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=d_optim)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(g_epoch_num):</span><br><span class="line">        print(<span class="string">"Epoch is"</span>, epoch)</span><br><span class="line">        <span class="comment"># 训练一个batchsize里面的数据</span></span><br><span class="line">        <span class="keyword">for</span> index <span class="keyword">in</span> range(int(X_train.shape[<span class="number">0</span>]/BATCH_SIZE)):</span><br><span class="line">            <span class="comment"># 产生随机噪声</span></span><br><span class="line">            noise = np.random.uniform(<span class="number">-1</span>, <span class="number">1</span>, size=(BATCH_SIZE, <span class="number">1000</span>))</span><br><span class="line">            <span class="comment"># 这里面都是真图片</span></span><br><span class="line">            image_batch = X_train[index*BATCH_SIZE:(index+<span class="number">1</span>)*BATCH_SIZE]</span><br><span class="line">            <span class="comment"># 这里产生假图片</span></span><br><span class="line">            generated_images = g.predict(noise, verbose=<span class="number">0</span>)</span><br><span class="line">            cv2.imshow(<span class="string">'generator_dog_image'</span>, generated_images[<span class="number">0</span>, :, :, :])</span><br><span class="line">            cv2.waitKey(<span class="number">10</span>)</span><br><span class="line">            <span class="comment"># 将真图片与假图片拼接在一起</span></span><br><span class="line">            X = np.concatenate((image_batch, generated_images))</span><br><span class="line">            <span class="comment"># 前64张图片标签为1,即真图，后64张照片为假图</span></span><br><span class="line">            y = [<span class="number">1</span>] * BATCH_SIZE + [<span class="number">0</span>] * BATCH_SIZE</span><br><span class="line">            <span class="comment"># 对于判别器进行训练，不断提高判别器的识别精度</span></span><br><span class="line">            d_loss = d.train_on_batch(X, y)</span><br><span class="line">            <span class="comment"># 再次产生随机噪声</span></span><br><span class="line">            noise = np.random.uniform(<span class="number">-1</span>, <span class="number">1</span>, (BATCH_SIZE, <span class="number">1000</span>))</span><br><span class="line">            <span class="comment"># 设置判别器的参数不可调整</span></span><br><span class="line">            d.trainable = <span class="literal">False</span></span><br><span class="line">            <span class="comment"># 在此我们送入噪声，并认为这些噪声是真实的标签</span></span><br><span class="line">            g_loss = d_on_g.train_on_batch(noise, [<span class="number">1</span>] * BATCH_SIZE)</span><br><span class="line">            <span class="comment"># 此时设置判别器可以被训练，参数可以被修改</span></span><br><span class="line">            d.trainable = <span class="literal">True</span></span><br><span class="line">            <span class="comment"># 打印损失值</span></span><br><span class="line">            print(<span class="string">"Epoch is : %s, batch %d d_loss : %s, g_loss : %f"</span> % (epoch, index, d_loss, g_loss))</span><br><span class="line">            <span class="keyword">if</span> index % <span class="number">10</span> == <span class="number">9</span>:</span><br><span class="line">                g.save_weights(<span class="string">'generator'</span>, <span class="literal">True</span>)</span><br><span class="line">                d.save_weights(<span class="string">'discriminator'</span>, <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>训练完之后自然就要生成图像：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate</span><span class="params">(BATCH_SIZE, nice=False)</span>:</span></span><br><span class="line">    g = generator_model()</span><br><span class="line">    g.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=<span class="string">"SGD"</span>)</span><br><span class="line">    g.load_weights(<span class="string">'generator'</span>)</span><br><span class="line">    <span class="keyword">if</span> nice:</span><br><span class="line">        d = discriminator_model()</span><br><span class="line">        d.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=<span class="string">"SGD"</span>)</span><br><span class="line">        d.load_weights(<span class="string">'discriminator'</span>)</span><br><span class="line">        noise = np.random.uniform(<span class="number">-1</span>, <span class="number">1</span>, (BATCH_SIZE*<span class="number">20</span>, <span class="number">1000</span>))</span><br><span class="line">        generated_images = g.predict(noise, verbose=<span class="number">1</span>)</span><br><span class="line">        d_pret = d.predict(generated_images, verbose=<span class="number">1</span>)</span><br><span class="line">        index = np.arange(<span class="number">0</span>, BATCH_SIZE*<span class="number">20</span>)</span><br><span class="line">        index.resize((BATCH_SIZE*<span class="number">20</span>, <span class="number">1</span>))</span><br><span class="line">        pre_with_index = list(np.append(d_pret, index, axis=<span class="number">1</span>))</span><br><span class="line">        pre_with_index.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">0</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">        nice_images = np.zeros((BATCH_SIZE,) + generated_images.shape[<span class="number">1</span>:<span class="number">3</span>], dtype=np.float32)</span><br><span class="line">        nice_images = nice_images[:, :, :, <span class="literal">None</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(BATCH_SIZE):</span><br><span class="line">            idx = int(pre_with_index[i][<span class="number">1</span>])</span><br><span class="line">            nice_images[i, :, :, <span class="number">0</span>] = generated_images[idx, :, :, <span class="number">0</span>]</span><br><span class="line">        image = combine_images(nice_images)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">16</span>):</span><br><span class="line">            noise = np.random.uniform(<span class="number">-1</span>, <span class="number">1</span>, (BATCH_SIZE, <span class="number">1000</span>))</span><br><span class="line">            generated_images = g.predict(noise, verbose=<span class="number">1</span>)</span><br><span class="line">            img = np.zeros((generated_images.shape[<span class="number">0</span>], generated_images.shape[<span class="number">1</span>], <span class="number">3</span>), dtype=np.uint8)</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">64</span>):</span><br><span class="line">                img = generated_images[j, :, :, :]</span><br><span class="line">                cv2.imshow(<span class="string">'test1'</span>, img)</span><br><span class="line">                cv2.waitKey(<span class="number">10</span>)</span><br><span class="line">                cv2.imwrite(<span class="string">"./dog_images/generated_image"</span> + str(i) + <span class="string">'_'</span> + str(j) + <span class="string">".png"</span>, img*<span class="number">127.5</span>+<span class="number">127.5</span>)</span><br><span class="line"></span><br><span class="line">            print(<span class="string">'i : i'</span>, i)</span><br></pre></td></tr></table></figure>
<p>参考链接：</p>
<ul>
<li><a href="https://www.sohu.com/a/325882199_114877" target="_blank" rel="noopener">https://www.sohu.com/a/325882199_114877</a></li>
<li><a href="https://www.leiphone.com/news/201907/Sv3AtCsT4w2W6roc.html" target="_blank" rel="noopener">https://www.leiphone.com/news/201907/Sv3AtCsT4w2W6roc.html</a></li>
<li><a href="https://blog.csdn.net/LEE18254290736/article/details/97371930" target="_blank" rel="noopener">https://blog.csdn.net/LEE18254290736/article/details/97371930</a></li>
<li><a href="https://blog.csdn.net/LEEANG121/article/details/104113406" target="_blank" rel="noopener">https://blog.csdn.net/LEEANG121/article/details/104113406</a></li>
<li><a href="https://arxiv.org/pdf/1406.2661.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1406.2661.pdf</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/114838349" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/114838349</a></li>
<li><a href="https://aistudio.baidu.com/aistudio/education/lessonvideo/496803" target="_blank" rel="noopener">https://aistudio.baidu.com/aistudio/education/lessonvideo/496803</a></li>
</ul>
]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
  </entry>
  <entry>
    <title>Opencv计算机视觉基础：（六）图像金字塔与轮廓检测</title>
    <url>/posts/511ffd8d.html</url>
    <content><![CDATA[<h1 id="图像金字塔"><a href="#图像金字塔" class="headerlink" title="图像金字塔"></a>图像金字塔</h1><p>图像金字塔是<strong>图像中多尺度表达</strong>的一种，最主要用于<strong>图像的分割</strong>，是一种<strong>以多分辨率来解释图像的有效但概念简单的结构</strong>。</p>
<p>图像金字塔最初用于机器视觉和图像压缩，<strong>一幅图像的金字塔是一系列以金字塔形状排列的分辨率逐步降低，且来源于同一张原始图的图像集合</strong>。其通过梯次向下采样获得，直到达到某个终止条件才停止采样。金字塔的底部是待处理图像的高分辨率表示，而顶部是低分辨率的近似。我们将一层一层的图像比喻成金字塔，<strong>层级越高，则图像越小，分辨率越低</strong>。</p>
<p>首先我们看一下图像金字塔长啥样：</p>
<p><img src="/Pic/Opencv%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80%EF%BC%9A%EF%BC%88%E5%85%AD%EF%BC%89%E5%9B%BE%E5%83%8F%E9%87%91%E5%AD%97%E5%A1%94%E4%B8%8E%E8%BD%AE%E5%BB%93%E6%A3%80%E6%B5%8B/Pyramid_1.png" alt></p>
<p>左边的图是高斯金字塔，右边的图是拉普拉斯金字塔。假设我们有一张$800<em>800$的图像，我们可以对其进行往上层变换，由于越离金字塔尖的图像会越小，可能就变成了$400</em>400$的图像了，然后依次往上走，越来越小，这样我们就把一张图像变成了一系列不同大小的图像。你可能就会问这样的图像金字塔有什么用呢？我们以后将做特征提取，这时候我们不一定只是对原图像进行特征提取，可能会对好几层金字塔进行特征提取，每一层提取出来的结果是不一样的，最后再综合在一起。</p>
<p>我们下面分别介绍两种图像金字塔——高斯金字塔与拉普拉斯金字塔：</p>
<h2 id="高斯金字塔"><a href="#高斯金字塔" class="headerlink" title="高斯金字塔"></a>高斯金字塔</h2><p>高斯金字塔的主要采样方法分为两种——向上采样和向下采样。这两个名称恰好和金字塔的图像相反，向下采样是指将图像变得越来越小，也就对应从金字塔塔底到塔尖的过程；反过来向上采样对应从金字塔塔尖到塔底的过程。</p>
<h3 id="向下采样"><a href="#向下采样" class="headerlink" title="向下采样"></a>向下采样</h3><p><img src="/posts/CV/Pyramid_2.png" alt></p>
<p>如上图所示，首先我们对内核做卷积操作，将内核与位置相乘后累加，除以总数归一化，随后我们将所有偶数行去掉。</p>
<h3 id="向上采样"><a href="#向上采样" class="headerlink" title="向上采样"></a>向上采样</h3><p><img src="/posts/CV/Pyramid_3.png" alt></p>
<p>我们的原图像为：</p>
<p><img src="/Pic/CV/AM.png" alt></p>
<p>首先我们直接对原像素矩阵扩充，然后用之前同样的内核对原图像进行卷积操作，得到近似放大图像，实现代码为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">up=cv2.pyrUp(img)</span><br><span class="line">cv_show(up,<span class="string">'up'</span>)</span><br><span class="line"><span class="keyword">print</span> (up.shape)</span><br></pre></td></tr></table></figure>
<p>这里关键就是pyrUp函数，这是做了一个向上采样，得到的图像为：</p>
<p><img src="/Pic/CV/upAM.png" alt></p>
<p>我们可以看到这张图片明显变大了，既然图片能变大，当然也能变小：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">down=cv2.pyrDown(img)</span><br><span class="line">cv_show(down,<span class="string">'down'</span>)</span><br><span class="line"><span class="keyword">print</span> (down.shape)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/CV/downAM.png" alt></p>
<p>我们看到该图片确实比原图小了一半。那么有一个问题，我们将图片放大之后再缩小，图片能恢复原状吗？显然是不行的，采样之后得到的图像只是一个近似值，我们可以通过对得到的两个图像相减得到两个图像的差值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">up=cv2.pyrUp(img)</span><br><span class="line">up_down=cv2.pyrDown(up)</span><br><span class="line">cv_show(img-up_down,<span class="string">'img-up_down'</span>)</span><br></pre></td></tr></table></figure>
<p>得到的结果蛮酷炫的：</p>
<p><img src="/Pic/CV/imgup_down.png" alt></p>
<h2 id="拉普拉斯金字塔"><a href="#拉普拉斯金字塔" class="headerlink" title="拉普拉斯金字塔"></a>拉普拉斯金字塔</h2><p>拉普拉斯金字塔用来从金字塔低层图像重建上层未采样图像，在数字图像处理中也即是预测残差，可以对图像进行最大程度的还原，配合高斯金字塔一起使用。其原理稍为复杂，我们直接看代码较为直观：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">laplacian</span><span class="params">(gaussian_pyramid, up_times=<span class="number">5</span>)</span>:</span></span><br><span class="line">    laplacian_pyramid = [gaussian_pyramid[<span class="number">-1</span>]]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(up_times, <span class="number">0</span>, <span class="number">-1</span>):</span><br><span class="line">        <span class="comment"># i的取值为5,4,3,2,1,0也就是拉普拉斯金字塔有6层</span></span><br><span class="line">        temp_pyrUp = cv2.pyrUp(gaussian_pyramid[i])</span><br><span class="line">        temp_lap = cv2.subtract(gaussian_pyramid[i<span class="number">-1</span>], temp_pyrUp)</span><br><span class="line">        laplacian_pyramid.append(temp_lap)</span><br><span class="line">    <span class="keyword">return</span> laplacian_pyramid</span><br></pre></td></tr></table></figure>
<p>简单地说拉普拉斯金字塔记录了高斯金字塔每一级下采样后再上采样与下采样前的差异，目的是为了能够完全地还原采样前的图像，差异记录过程为：</p>
<script type="math/tex; mode=display">L_i = G_i-Up(Down(G_i))</script><p>获取拉普拉斯金字塔第一层结果的方式为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">down=cv2.pyrDown(img)</span><br><span class="line">down_up=cv2.pyrUp(down)</span><br><span class="line">l_1=img-down_up</span><br><span class="line">cv_show(l_1,<span class="string">'l_1'</span>)</span><br></pre></td></tr></table></figure>
<p>当然也可以用同样 的方式获取其他层，这里不再对其进行更详细的介绍。</p>
<h1 id="轮廓检测"><a href="#轮廓检测" class="headerlink" title="轮廓检测"></a>轮廓检测</h1><h2 id="轮廓绘制"><a href="#轮廓绘制" class="headerlink" title="轮廓绘制"></a>轮廓绘制</h2><p>首先介绍我们的常用函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cv2.findContours(img,mode,method)</span><br></pre></td></tr></table></figure>
<p><strong>mode：轮廓检索模式</strong></p>
<ul>
<li>RETR_EXTERNAL ：只检索最外面的轮廓；</li>
<li>RETR_LIST：检索所有的轮廓，并将其保存到一条链表当中；</li>
<li>RETR_CCOMP：检索所有的轮廓，并将他们组织为两层：顶层是各部分的外部边界，第二层是空洞的边界；</li>
<li>RETR_TREE：检索所有的轮廓，并重构嵌套轮廓的整个层次（一般直接使用这个就够了）；</li>
</ul>
<p><strong>method:轮廓逼近方法</strong></p>
<ul>
<li>CHAIN_APPROX_NONE：以Freeman链码的方式输出轮廓，所有其他方法输出多边形（顶点的序列）；</li>
<li>CHAIN_APPROX_SIMPLE:压缩水平的、垂直的和斜的部分，也就是，函数只保留他们的终点部分。</li>
</ul>
<p>我们在进行轮廓检测时，为了更高的准确率，常使用二值图像，因此我们的常用流程为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">'car.png'</span>)</span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line">ret, thresh = cv2.threshold(gray, <span class="number">127</span>, <span class="number">255</span>, cv2.THRESH_BINARY)</span><br><span class="line">cv_show(thresh,<span class="string">'thresh'</span>)</span><br></pre></td></tr></table></figure>
<p>上面代码中第一步是读入图像，第二步是将图像转换为灰度图，第三步将灰度图转化为二值图像（像素值大于127的像素点为1，小于127的像素点为0），我们传入的图像为：</p>
<p><img src="/Pic/CV/car.png" alt></p>
<p>转化后的图像为：</p>
<p><img src="/Pic/CV/thresh.png" alt></p>
<p>下面我们使用检测函数进行检测：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">binary, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)</span><br></pre></td></tr></table></figure>
<p>binary实际上就是我们原来的二值图像，而contours则是边界信息，我们可以查看一下他的维度：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.array(contours).shape</span><br></pre></td></tr></table></figure>
<p>返回值为$(2579,)$，我们也可以#传入绘制图像，轮廓，轮廓索引，颜色模式，线条厚度，展示轮廓图像，注意需要copy，要不原图会变：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">draw_img = img.copy()</span><br><span class="line">res = cv2.drawContours(draw_img, contours, <span class="number">-1</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)</span><br><span class="line">cv_show(res,<span class="string">'res'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/CV/res23.png" alt></p>
<p>我们改变一下参数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">draw_img = img.copy()</span><br><span class="line">res = cv2.drawContours(draw_img, contours, <span class="number">0</span>, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">2</span>)</span><br><span class="line">cv_show(res,<span class="string">'res'</span>)</span><br></pre></td></tr></table></figure>
<p>我们可以看到第三个参数实际上是表示绘制轮廓的范围，参数为-1时默认全部绘制；第四个参数为BGR通道，即希望用什么颜色来绘制，第五个参数为线条宽度，具体大家可以自行尝试（建议换一张简单的几何图像对第三个参数进行尝试）。</p>
<p>下面有一个很有意思的地方，我们的轮廓由于是一个闭合曲线，因此我们可以计算他们的面积：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cnt = contours[<span class="number">0</span>]</span><br><span class="line"><span class="comment">#面积</span></span><br><span class="line">cv2.contourArea(cnt)</span><br><span class="line"><span class="comment">#周长，True表示闭合的</span></span><br><span class="line">cv2.arcLength(cnt,<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h2 id="轮廓近似"><a href="#轮廓近似" class="headerlink" title="轮廓近似"></a>轮廓近似</h2><p>如下图，我们可以改变阈值对轮廓做不同层次的近似（轮廓真实点与直线距离小于某个阈值时可以认为归为这条直线内部），最终可以将轮廓划分成尽可能少的图像。</p>
<p><img src="/Pic/CV/contours3.png" alt></p>
<p>我们直接来看如何实现这样一个轮廓近似，首先我们给图像描出一个轮廓：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">'contours2.png'</span>)</span><br><span class="line"></span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line">ret, thresh = cv2.threshold(gray, <span class="number">127</span>, <span class="number">255</span>, cv2.THRESH_BINARY)</span><br><span class="line">binary, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)</span><br><span class="line">cnt = contours[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">draw_img = img.copy()</span><br><span class="line">res = cv2.drawContours(draw_img, [cnt], <span class="number">-1</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)</span><br><span class="line">cv_show(res,<span class="string">'res'</span>)</span><br></pre></td></tr></table></figure>
<p>原图像为：</p>
<p><img src="/Pic/CV/contours2.png" alt></p>
<p>绘制的轮廓结果为：</p>
<p><img src="/Pic/CV/ctor.png" alt></p>
<p>我们近似轮廓的代码其实很简单：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">epsilon = <span class="number">0.15</span>*cv2.arcLength(cnt,<span class="literal">True</span>) </span><br><span class="line">approx = cv2.approxPolyDP(cnt,epsilon,<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">draw_img = img.copy()</span><br><span class="line">res = cv2.drawContours(draw_img, [approx], <span class="number">-1</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)</span><br><span class="line">cv_show(res,<span class="string">'res'</span>)</span><br></pre></td></tr></table></figure>
<p>其中第一个参数为传入待近似的轮廓，第二个参数传入阈值，这个阈值通常是通过轮廓的周长进行设定，这里取了0.15倍的周长，近似轮廓结果如下：</p>
<p><img src alt><img src="/Pic/CV/ctor2.png" alt="ctor2"></p>
<p>我们可以看到近似效果其实很不好，我们可以缩减阈值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">epsilon = <span class="number">0.02</span>*cv2.arcLength(cnt,<span class="literal">True</span>) </span><br><span class="line">approx = cv2.approxPolyDP(cnt,epsilon,<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">draw_img = img.copy()</span><br><span class="line">res = cv2.drawContours(draw_img, [approx], <span class="number">-1</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)</span><br><span class="line">cv_show(res,<span class="string">'res'</span>)</span><br><span class="line">cv2.imwrite(<span class="string">"ctor2.png"</span>, res)</span><br></pre></td></tr></table></figure>
<p>得到的结果如下：</p>
<p><img src="/Pic/CV/ctor3.png" alt></p>
<p>结果比原来好了很多，我们还可以继续修改参数得到我们最满意的结果。</p>
<h2 id="外接图形"><a href="#外接图形" class="headerlink" title="外接图形"></a>外接图形</h2><p>我们也可以对图像的轮廓做外接矩形或外接圆等，具体做法为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">'contours.png'</span>)</span><br><span class="line"></span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line">ret, thresh = cv2.threshold(gray, <span class="number">127</span>, <span class="number">255</span>, cv2.THRESH_BINARY)</span><br><span class="line">binary, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)</span><br><span class="line">cnt = contours[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">x,y,w,h = cv2.boundingRect(cnt)</span><br><span class="line">img = cv2.rectangle(img,(x,y),(x+w,y+h),(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">2</span>)</span><br><span class="line">cv_show(img,<span class="string">'img'</span>)</span><br></pre></td></tr></table></figure>
<p>传入的图像为：</p>
<p><img src="/Pic/CV/contours.png" alt></p>
<p>绘制出来的结果长成这个样子：</p>
<p><img src="/Pic/CV/ctor4.png" alt></p>
<p>同样也可以绘制外接圆：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">(x,y),radius = cv2.minEnclosingCircle(cnt) </span><br><span class="line">center = (int(x),int(y)) </span><br><span class="line">radius = int(radius) </span><br><span class="line">img = cv2.circle(img,center,radius,(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">2</span>)</span><br><span class="line">cv_show(img,<span class="string">'img'</span>)</span><br></pre></td></tr></table></figure>
<h1 id="模板匹配"><a href="#模板匹配" class="headerlink" title="模板匹配"></a>模板匹配</h1><p>模板匹配就是将模板在原图像上滑动，计算模板与原图像的差异程度，计算差异程度的方法有6种，计算结果将存放在矩阵中作为结果输出，假设原图像大小为$A×B$，而模板大小为$a×b$，则输出结果的矩阵为$(A-a+1)×(B-b+1)$。</p>
<p>首先传入模板图像和原图像：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">"lena.jpg"</span>, <span class="number">0</span>)</span><br><span class="line">template = cv2.imread(<span class="string">"face.jpg"</span>, <span class="number">0</span>)</span><br><span class="line">h, w = template.shape[:<span class="number">2</span>]</span><br></pre></td></tr></table></figure>
<p>然后就调包进行模板匹配：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">res = cv2.matchTemplate(img, template, cv2.TM_SQDIFF)</span><br></pre></td></tr></table></figure>
<p>第三个参数为选择的计算差异程度的方法，建议选择归一化的结果，比如TM_CCORR_NORMED，得到的结果将更可靠。为了得到边框的位置，我们可以看左上角和右下角两个点的位置：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)</span><br></pre></td></tr></table></figure>
<p>然后大家可以根据这两个点计算一波画个矩形框框。</p>
<p>若待匹配结果有多个图像，比如行人检测，我们自然也可以自己设定阈值，找到匹配程度大于阈值的位置：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">threshold &#x3D; 0.6</span><br><span class="line">loc &#x3D; np.where(res&gt;&#x3D;threshold)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>CV</category>
      </categories>
  </entry>
  <entry>
    <title>Opencv计算机视觉基础：（五）Canny边缘检测 </title>
    <url>/posts/dcd951b.html</url>
    <content><![CDATA[<h1 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h1><h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><ol>
<li><p>使用高斯滤波器，以平滑图像，滤除噪声。</p>
</li>
<li><p>计算图像中每个像素点的梯度强度和方向。</p>
</li>
<li><p>应用非极大值（Non-Maximum Suppression）抑制，以消除边缘检测带来的杂散响应。</p>
</li>
<li><p>应用双阈值（Double-Threshold）检测来确定真实的和潜在的边缘。</p>
</li>
<li><p>通过抑制孤立的弱边缘最终完成边缘检测。</p>
</li>
</ol>
<h2 id="具体来说"><a href="#具体来说" class="headerlink" title="具体来说"></a>具体来说</h2><p>首先我们有一个归一化后的<strong>高斯滤波器</strong>，然后完成我们前面说的<strong>平滑处理</strong>：</p>
<p><img src="/posts/CV/canny_1.png" alt></p>
<p>如前一篇文章我们进行<strong>图像梯度</strong>的计算：</p>
<p><img src="/posts/CV/canny_2.png" alt></p>
<p><strong>非极大值抑制</strong>可以用线性插值法来实现：</p>
<p><img src="/posts/CV/canny_3.png" alt></p>
<p>也可以简化操作：</p>
<p><img src="/posts/CV/canny_6.png" alt></p>
<p>其本质就是比较当前点与周围两点的梯度幅值大小，若他是最大的就保存下来，若不是就要抑制。</p>
<p>然后我们通过一个<strong>双阈值检测</strong>，检测过程如下：</p>
<p><img src="/posts/CV/canny_5.png" alt></p>
<h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><p>我们下面设置了两个不同的阈值（双阈值检测的min和max）进行对比：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img=cv2.imread(<span class="string">"lena.jpg"</span>,cv2.IMREAD_GRAYSCALE)</span><br><span class="line"></span><br><span class="line">v1=cv2.Canny(img,<span class="number">80</span>,<span class="number">150</span>)</span><br><span class="line">v2=cv2.Canny(img,<span class="number">50</span>,<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">res = np.hstack((v1,v2))</span><br><span class="line">cv_show(res,<span class="string">'res'</span>)</span><br></pre></td></tr></table></figure>
<p>结果为：</p>
<p><img src="/posts/CV/cannycompare.png" alt></p>
<p>我们可以看到，两个阈值都比较小的一组边界更细致，更多边界信息被刻画到，但也可能 考虑进了更多噪音点。</p>
<p>我们可以从下面的例子看到更明显的对比：</p>
<p>我们导入一排汽车的图片：</p>
<p><img src="/posts/CV/car.png" alt></p>
<p>我们对其进行同上处理，结果为：</p>
<p><img src="/posts/CV/cannycompare2.png" alt></p>
<p>我们看到右边图中明显多出了很多信息。</p>
<h1 id="概念解释"><a href="#概念解释" class="headerlink" title="概念解释"></a>概念解释</h1><h2 id="非极大值抑制"><a href="#非极大值抑制" class="headerlink" title="非极大值抑制"></a>非极大值抑制</h2><p>非极大值抑制（Non-Maximum Suppression，NMS），顾名思义就是抑制不是极大值的元素，可以理解为局部最大搜索。这个局部代表的是一个邻域，邻域有两个参数可变，一是邻域的维数，二是邻域的大小。这里不讨论通用的NMS算法(参考论文《Efficient Non-Maximum Suppression》对1维和2维数据的NMS实现)，而是用于目标检测中提取分数最高的窗口的。例如在行人检测中，滑动窗口经提取特征，经分类器分类识别后，每个窗口都会得到一个分数。但是滑动窗口会导致很多窗口与其他窗口存在包含或者大部分交叉的情况。这时就需要用到NMS来选取那些邻域里分数最高（是行人的概率最大），并且抑制那些分数低的窗口。</p>
<p>简单地说，经过一个算法进行人脸识别，其中有多个窗口，有的窗口覆盖了一部分人脸，有的窗口覆盖了整个人脸，非极大值抑制可以筛选出含全部人脸的部分，剔除掉只含部分人脸的部分。</p>
<p><img src="/posts/CV/nms.png" alt></p>
<p>例如在上图中我们的目的就是要去除左边冗余的检测框，留下最好的那个（右边）。</p>
<h2 id="双阈值检测"><a href="#双阈值检测" class="headerlink" title="双阈值检测"></a>双阈值检测</h2><p><strong>目的：</strong>检测过程中有一些边界候选值，要对其进行过滤找真实边界。</p>
<p><strong>具体方法：</strong></p>
<ol>
<li>根据图像选取合适的高阈值和低阈值，通常高阈值是低阈值的2到3倍</li>
<li>如果某一像素的梯度值高于高阈值，则保留</li>
<li>如果某一像素的梯度值低于低阈值，则舍弃</li>
<li>如果某一像素的梯度值介于高低阈值之间，则从该像素的8邻域的寻找像素梯度值，如果存在像素梯度值高于高阈值，则保留，如果没有，则舍弃</li>
</ol>
<p>伪代码实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">st = zeros(row,col);%定义一个双阈值图像</span><br><span class="line">TL = <span class="number">0.1</span> * max(max(jd));%低阈值</span><br><span class="line">TH = <span class="number">0.12</span>* max(max(jd));%高阈值</span><br><span class="line"><span class="keyword">for</span> i = <span class="number">1</span>  : row</span><br><span class="line">    <span class="keyword">for</span> j = <span class="number">1</span> : col</span><br><span class="line">        <span class="keyword">if</span> (jd(i, j) &lt; TL)</span><br><span class="line">            st(i,j) = <span class="number">0</span>;</span><br><span class="line">        elseif (jd(i, j) &gt; TH)</span><br><span class="line">            st(i,j) = <span class="number">1</span> ;</span><br><span class="line">        %对TL &lt; Nms(i, j) &lt; TH 使用<span class="number">8</span>连通区域确定</span><br><span class="line">        elseif (jd(i, j)&lt;TH&amp;&amp;jd(i, j)&gt;TL)</span><br><span class="line">            su =[jd(i<span class="number">-1</span>,j<span class="number">-1</span>), jd(i<span class="number">-1</span>,j), jd(i<span class="number">-1</span>,j+<span class="number">1</span>);</span><br><span class="line">                       jd(i,j<span class="number">-1</span>),    jd(i,j),   jd(i,j+<span class="number">1</span>);</span><br><span class="line">                       jd(i+<span class="number">1</span>,j<span class="number">-1</span>), jd(i+<span class="number">1</span>,j), jd(i+<span class="number">1</span>,j+<span class="number">1</span>)];</span><br><span class="line">            Max = max(su);</span><br><span class="line">            <span class="keyword">if</span> Max&gt;=TH</span><br><span class="line">                st(i,j) = <span class="number">1</span> ;</span><br><span class="line">            end</span><br><span class="line"></span><br><span class="line">        end</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line">imshow(st)%输出用prewitt模板处理后的梯度幅值图片</span><br><span class="line">title(<span class="string">'最终输出的图像'</span>)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>CV</category>
      </categories>
  </entry>
  <entry>
    <title>Opencv计算机视觉基础：（四）图像梯度处理 </title>
    <url>/posts/33b97531.html</url>
    <content><![CDATA[<h1 id="Sobel算子"><a href="#Sobel算子" class="headerlink" title="Sobel算子"></a>Sobel算子</h1><p>梯度是图像中两个实体的边缘，我们可以算一算这个点的左边是什么，右边是什么，上面是什么，下面是什么，因此 我们主要考虑两个方向———上下、左右。</p>
<p><img src="/posts/CV/sobel_1.png" alt></p>
<p>在上面这张图中，A是一个3×3的矩阵，我们计算左右梯度也就是左乘上图左边的矩阵（卷积核），；同理我们计算上下梯度就是左乘上图右边的矩阵。我们可以看到相邻的像素值的权重会被增大，这不正是前面说的高斯滤波的感觉了吗。综上所述，就是下减上，右减左。</p>
<p>我们先导入要计算梯度的图片：</p>
<p><img src="/posts/CV/pie.png" alt></p>
<p>导入图片并定义show函数的代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">'pie.png'</span>,cv2.IMREAD_GRAYSCALE)</span><br><span class="line">cv2.imshow(<span class="string">"img"</span>,img)</span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cv_show</span><span class="params">(img,name)</span>:</span></span><br><span class="line">    cv2.imshow(name,img)</span><br><span class="line">    cv2.waitKey()</span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>我们看一下Sobel算子函数的调用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dst = cv2.Sobel(src, depth, dx, dy, ksize)</span><br></pre></td></tr></table></figure>
<ul>
<li>depth:图像的深度，一般指定为-1即可</li>
<li>dx和dy分别表示水平和竖直方向</li>
<li>ksize是Sobel算子的大小</li>
</ul>
<p>我们使用一下Sobel函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sobelx = cv2.Sobel(img,cv2.CV_64F,<span class="number">1</span>,<span class="number">0</span>,ksize=<span class="number">3</span>)</span><br><span class="line">cv_show(sobelx,<span class="string">'sobelx'</span>)</span><br></pre></td></tr></table></figure>
<p>结果为：</p>
<p><img src="/posts/CV/sobel1.png" alt></p>
<p>我们看到传入了一个新的参数：cv2.CV_64F，这个参数是什么意思呢？我们在计算梯度的时候结果不一定是正数，假如结果是负数，图像的像素默认是0-255，一般情况下在图像展示时会被归为0，因此上如图右边本该是白色的框框就变成黑色了。后面对应dx，dy的位置分别为1和0，这意味着只看x轴不看y轴。</p>
<p>我们如果想让右边被抹掉的框框也变为白色，我们可以对相减的得到负数取绝对值，也就是把得到的结果做转换，具体操作为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sobelx = cv2.Sobel(img,cv2.CV_64F,<span class="number">1</span>,<span class="number">0</span>,ksize=<span class="number">3</span>)</span><br><span class="line">sobelx = cv2.convertScaleAbs(sobelx)</span><br><span class="line">cv_show(sobelx,<span class="string">'sobelx'</span>)</span><br></pre></td></tr></table></figure>
<p>结果如下：</p>
<p><img src="/posts/CV/sobel2.png" alt></p>
<p>同理我们可以对y方向的梯度也做同样的操作：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sobely = cv2.Sobel(img,cv2.CV_64F,<span class="number">0</span>,<span class="number">1</span>,ksize=<span class="number">3</span>)</span><br><span class="line">sobely = cv2.convertScaleAbs(sobely)</span><br><span class="line">cv_show(sobely,<span class="string">'sobely'</span>)</span><br></pre></td></tr></table></figure>
<p>结果为：</p>
<p><img src="/posts/CV/sobel3.png" alt></p>
<p>现在我们得到了x方向的梯度和y方向的梯度，我们可以计算一个总和，我们可以计算平方和开根号，也可以取绝对值相加，我们在下面对得到的x和y进行求和：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sobelxy = cv2.addWeighted(sobelx,<span class="number">0.5</span>,sobely,<span class="number">0.5</span>,<span class="number">0</span>)</span><br><span class="line">cv_show(sobelxy,<span class="string">'sobelxy'</span>)</span><br></pre></td></tr></table></figure>
<p>下面是得到的图像的效果：</p>
<p><img src="/posts/CV/sobel4.png" alt></p>
<p>我们在这里不建议直接计算，直接计算方式为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sobelxy=cv2.Sobel(img,cv2.CV_64F,<span class="number">1</span>,<span class="number">1</span>,ksize=<span class="number">3</span>)</span><br><span class="line">sobelxy = cv2.convertScaleAbs(sobelxy)</span><br><span class="line">cv_show(sobelxy,<span class="string">'sobelxy'</span>)</span><br></pre></td></tr></table></figure>
<p>结果为：</p>
<p><img src="/posts/CV/sobel5.png" alt></p>
<p>我们可以看到直接计算的效果不是很好，下面我们对Lena的图像进行操作，原始图像为：</p>
<p><img src="/posts/CV/lena.jpg" alt></p>
<p>转化后的图像为：</p>
<p><img src="/posts/CV/lenaSobel.jpg" alt></p>
<p>代码为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">'lena.jpg'</span>,cv2.IMREAD_GRAYSCALE)</span><br><span class="line">sobelx = cv2.Sobel(img,cv2.CV_64F,<span class="number">1</span>,<span class="number">0</span>,ksize=<span class="number">3</span>)</span><br><span class="line">sobelx = cv2.convertScaleAbs(sobelx)</span><br><span class="line">sobely = cv2.Sobel(img,cv2.CV_64F,<span class="number">0</span>,<span class="number">1</span>,ksize=<span class="number">3</span>)</span><br><span class="line">sobely = cv2.convertScaleAbs(sobely)</span><br><span class="line">sobelxy = cv2.addWeighted(sobelx,<span class="number">0.5</span>,sobely,<span class="number">0.5</span>,<span class="number">0</span>)</span><br><span class="line">cv_show(sobelxy,<span class="string">'sobelxy'</span>)</span><br></pre></td></tr></table></figure>
<p>下面我们再介绍两个算子——Scharr算子和Laplacian算子</p>
<h1 id="其他算子"><a href="#其他算子" class="headerlink" title="其他算子"></a>其他算子</h1><p>我们先直观地看一下这两个算子的卷积核：</p>
<p><strong>Scharr算子</strong></p>
<p><img src="/posts/CV/scharr.png" alt></p>
<p><strong>Laplacian算子</strong></p>
<p><img src="/posts/CV/l.png" alt></p>
<p>Scharr算子对结果的差异更敏感一些，而Laplacian算子相比于Sobel算子以及Scharr算子会对一些变化更敏感，因为Laplacian算子使用了二阶导，也就是一阶导的变化率，但Laplacian的缺陷是对噪音点比较敏感，因此一般Laplacian算子并不会单独使用，一般是结合其他工具使用。</p>
<p>下面我们进行一个对比试验：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">'lena.jpg'</span>,cv2.IMREAD_GRAYSCALE)</span><br><span class="line">sobelx = cv2.Sobel(img,cv2.CV_64F,<span class="number">1</span>,<span class="number">0</span>,ksize=<span class="number">3</span>)</span><br><span class="line">sobely = cv2.Sobel(img,cv2.CV_64F,<span class="number">0</span>,<span class="number">1</span>,ksize=<span class="number">3</span>)</span><br><span class="line">sobelx = cv2.convertScaleAbs(sobelx)</span><br><span class="line">sobely = cv2.convertScaleAbs(sobely)</span><br><span class="line">sobelxy =  cv2.addWeighted(sobelx,<span class="number">0.5</span>,sobely,<span class="number">0.5</span>,<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">scharrx = cv2.Scharr(img,cv2.CV_64F,<span class="number">1</span>,<span class="number">0</span>)</span><br><span class="line">scharry = cv2.Scharr(img,cv2.CV_64F,<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">scharrx = cv2.convertScaleAbs(scharrx)</span><br><span class="line">scharry = cv2.convertScaleAbs(scharry)</span><br><span class="line">scharrxy =  cv2.addWeighted(scharrx,<span class="number">0.5</span>,scharry,<span class="number">0.5</span>,<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">laplacian = cv2.Laplacian(img,cv2.CV_64F)</span><br><span class="line">laplacian = cv2.convertScaleAbs(laplacian)</span><br><span class="line"></span><br><span class="line">res = np.hstack((sobelxy,scharrxy,laplacian))</span><br><span class="line">cv_show(res,<span class="string">'res'</span>)</span><br></pre></td></tr></table></figure>
<p>对比结果为：</p>
<p><img src="/posts/CV/concat.jpg" alt></p>
]]></content>
      <categories>
        <category>CV</category>
      </categories>
  </entry>
  <entry>
    <title>Opencv计算机视觉基础：（三）图像形态学处理</title>
    <url>/posts/1f4ed7b2.html</url>
    <content><![CDATA[<h1 id="腐蚀操作"><a href="#腐蚀操作" class="headerlink" title="腐蚀操作"></a>腐蚀操作</h1><p>图像腐蚀操作的前提（大多为）图像数据为二值，我们看下面这张图：</p>
<p><img src="/posts/CV/dige.png" alt></p>
<p>我们看到这两个字的很多地方有溢出来的白线，我们希望去掉这些白线，即转化后结果为：</p>
<p><img src="/posts/CV/fushi.png" alt></p>
<p>同时我们还观察到上图的线条都变细了，这就是腐蚀操作做的事，我们再来仔细看一下腐蚀操作：</p>
<p>原图如下：</p>
<p><img src="/posts/CV/pie.png" alt></p>
<p>腐蚀操作后如下：</p>
<p><img src="/posts/CV/pie2.png" alt></p>
<p>我们在上面进行了如下操作：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">kernel = np.ones((<span class="number">30</span>,<span class="number">30</span>),np.uint8)</span><br><span class="line">erosion_1 = cv2.erode(pie,kernel,iterations = <span class="number">1</span>)</span><br><span class="line">erosion_2 = cv2.erode(pie,kernel,iterations = <span class="number">2</span>)</span><br><span class="line">erosion_3 = cv2.erode(pie,kernel,iterations = <span class="number">3</span>)</span><br><span class="line">res = np.hstack((erosion_1,erosion_2,erosion_3))</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">'res'</span>, res)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>也就是进行了不同次数的腐蚀，第一张图循环次数是一次，第二张图两次，第三张图三次，依次展现出上面的图像，并且我们注意到我们的kernel是30×30的，如果我们指定更大的kernel值，比如50×50，是否预期会有更大的腐蚀面积（白色的区域更少），我们看一看实验结果：</p>
<p><img src="/posts/CV/pie3.png" alt></p>
<p>我们看到果然是符合预期的。</p>
<h1 id="膨胀操作"><a href="#膨胀操作" class="headerlink" title="膨胀操作"></a>膨胀操作</h1><p>腐蚀的逆操作不就是膨胀操作吗，比如我们最开始将字上面的刺儿都去掉了，但线条变细了，我们想让它变粗一些，我们可以执行膨胀操作：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">kernel = np.ones((<span class="number">3</span>,<span class="number">3</span>),np.uint8)</span><br><span class="line">dige_dilate = cv2.dilate(dige_erosion,kernel,iterations = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">'dilate'</span>, dige_dilate)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>和前面的腐蚀操作一样，这里需要定义kernel和iterations，我们会用框框（由kernel大小定义）去框住图片中的区域，每框一次如果有白色的像素点我们就会将整个框框内都变为白色，这不正好和腐蚀操作相反吗。我们同样对前面的初始园执行膨胀操作：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pie = cv2.imread(<span class="string">'pie.png'</span>)</span><br><span class="line"></span><br><span class="line">kernel = np.ones((<span class="number">30</span>,<span class="number">30</span>),np.uint8) </span><br><span class="line">dilate_1 = cv2.dilate(pie,kernel,iterations = <span class="number">1</span>)</span><br><span class="line">dilate_2 = cv2.dilate(pie,kernel,iterations = <span class="number">2</span>)</span><br><span class="line">dilate_3 = cv2.dilate(pie,kernel,iterations = <span class="number">3</span>)</span><br><span class="line">res = np.hstack((dilate_1,dilate_2,dilate_3))</span><br><span class="line">cv2.imshow(<span class="string">'res'</span>, res)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>结果为：</p>
<p><img src="/posts/CV/pie4.png" alt></p>
<h1 id="开运算"><a href="#开运算" class="headerlink" title="开运算"></a>开运算</h1><p><strong>对于最开始的任务，我们希望能既去掉毛刺又不破坏原来的图像，我们会进行一个腐蚀后膨胀的操作，开运算正是帮我们省去了这两部，直接一步到位~</strong>，具体操作为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 开：先腐蚀，再膨胀</span></span><br><span class="line">img = cv2.imread(<span class="string">'dige.png'</span>)</span><br><span class="line"></span><br><span class="line">kernel = np.ones((<span class="number">5</span>,<span class="number">5</span>),np.uint8) </span><br><span class="line">opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">'opening'</span>, opening)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>结果与我们做了两步操作后相同：</p>
<p><img src="/posts/CV/dege45.png" alt></p>
<h1 id="闭运算"><a href="#闭运算" class="headerlink" title="闭运算"></a>闭运算</h1><p>闭运算就和开运算相反，先做膨胀后做腐蚀：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 闭：先膨胀，再腐蚀</span></span><br><span class="line">img = cv2.imread(<span class="string">'dige.png'</span>)</span><br><span class="line"></span><br><span class="line">kernel = np.ones((<span class="number">5</span>,<span class="number">5</span>),np.uint8) </span><br><span class="line">closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">'closing'</span>, closing)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>在这张图上，旁边的线反而被加粗了。</p>
<p><img src="/posts/CV/dege12.png" alt></p>
<h1 id="梯度运算"><a href="#梯度运算" class="headerlink" title="梯度运算"></a>梯度运算</h1><p>当我们想要关注边界信息时，我们可以对原图像执行一次腐蚀得到p1，再对原图像执行一次膨胀操作得到p2，用p2-p1就得到了边界的信息：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gradient = cv2.morphologyEx(pie, cv2.MORPH_GRADIENT, kernel)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">'gradient'</span>, gradient)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>打印结果为：</p>
<p><img src="/posts/CV/tidu.png" alt></p>
<h1 id="礼帽和黑帽"><a href="#礼帽和黑帽" class="headerlink" title="礼帽和黑帽"></a>礼帽和黑帽</h1><ul>
<li>礼帽 = 原始输入-开运算结果</li>
<li>黑帽 = 闭运算-原始输入</li>
</ul>
<p>我们看到礼帽就是最开始剩下的那些刺的全体，而黑帽就是变粗之后的刺，具体调用如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#礼帽</span></span><br><span class="line">img = cv2.imread(<span class="string">'dige.png'</span>)</span><br><span class="line">tophat = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)</span><br><span class="line">cv2.imshow(<span class="string">'tophat'</span>, tophat)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>CV</category>
      </categories>
  </entry>
  <entry>
    <title>Opencv计算机视觉基础：（二）阈值与平滑处理</title>
    <url>/posts/5d7ec7e5.html</url>
    <content><![CDATA[<h1 id="图像阈值"><a href="#图像阈值" class="headerlink" title="图像阈值"></a>图像阈值</h1><p><strong>ret, dst = cv2.threshold(src, thresh, maxval, type)</strong></p>
<ul>
<li>src： 输入图，只能输入单通道图像，通常来说为灰度图</li>
<li>dst： 输出图</li>
<li>thresh： 阈值</li>
<li>maxval： 当像素值超过了阈值（或者小于阈值，根据type来决定），所赋予的值</li>
<li><p>type：二值化操作的类型，包含以下5种类型： cv2.THRESH_BINARY； cv2.THRESH_BINARY_INV； cv2.THRESH_TRUNC； cv2.THRESH_TOZERO；cv2.THRESH_TOZERO_INV</p>
</li>
<li><p>cv2.THRESH_BINARY           超过阈值部分取maxval（最大值），否则取0</p>
</li>
<li>cv2.THRESH_BINARY_INV    THRESH_BINARY的反转</li>
<li>cv2.THRESH_TRUNC            大于阈值部分设为阈值，否则不变</li>
<li>cv2.THRESH_TOZERO          大于阈值部分不改变，否则设为0</li>
<li>cv2.THRESH_TOZERO_INV  THRESH_TOZERO的反转</li>
</ul>
<p>原图像为：</p>
<p><img src="/posts/CV/cat.jpg" alt></p>
<p>对上述阈值处理的具体操作如下：</p>
<p><img src="/posts/CV/tc1.png" alt></p>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ret, thresh1 = cv2.threshold(img_gray, <span class="number">127</span>, <span class="number">255</span>, cv2.THRESH_BINARY)</span><br><span class="line">ret, thresh2 = cv2.threshold(img_gray, <span class="number">127</span>, <span class="number">255</span>, cv2.THRESH_BINARY_INV)</span><br><span class="line">ret, thresh3 = cv2.threshold(img_gray, <span class="number">127</span>, <span class="number">255</span>, cv2.THRESH_TRUNC)</span><br><span class="line">ret, thresh4 = cv2.threshold(img_gray, <span class="number">127</span>, <span class="number">255</span>, cv2.THRESH_TOZERO)</span><br><span class="line">ret, thresh5 = cv2.threshold(img_gray, <span class="number">127</span>, <span class="number">255</span>, cv2.THRESH_TOZERO_INV)</span><br><span class="line"></span><br><span class="line">titles = [<span class="string">'Original Image'</span>, <span class="string">'BINARY'</span>, <span class="string">'BINARY_INV'</span>, <span class="string">'TRUNC'</span>, <span class="string">'TOZERO'</span>, <span class="string">'TOZERO_INV'</span>]</span><br><span class="line">images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">6</span>):</span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">3</span>, i + <span class="number">1</span>), plt.imshow(images[i], <span class="string">'gray'</span>)</span><br><span class="line">    plt.title(titles[i])</span><br><span class="line">    plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h1 id="图像平滑"><a href="#图像平滑" class="headerlink" title="图像平滑"></a>图像平滑</h1><p>目的是通过滤波等操作尽可能去掉图像上的噪音点。我们首先看一张带有噪声的lena图片：</p>
<p><img src="/posts/CV/lenaNoise.png" alt></p>
<h2 id="均值滤波"><a href="#均值滤波" class="headerlink" title="均值滤波"></a>均值滤波</h2><p>我们要做平滑处理，就是需要对一定窗口大小的图片矩阵进行变化，我们可以做均值滤波，也就是将窗口内像素点取平均代替原有值，具体实现也十分简单，只需要传入图片以及滤波窗口大小即可：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">blur = cv2.blur(img, (<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">cv2.imshow(<span class="string">'blur'</span>, blur)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>结果为：</p>
<p><img src="/posts/CV/blur.jpg" alt></p>
<h2 id="方框滤波"><a href="#方框滤波" class="headerlink" title="方框滤波"></a>方框滤波</h2><p>除此之外，我们还可以构建方框滤波，方框滤波和均值滤波几乎相同 ，不过比之多了两个参数，颜色通道是否一致，若希望一致则填入-1，通常都不需要改动；另外还有normalize，也就是是否需要做归一化操作，当不适用normalize时可能会发生越界现象，而当normalize指定为True时方框滤波就与均值滤波完全一样：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">box = cv2.boxFilter(img,<span class="number">-1</span>,(<span class="number">3</span>,<span class="number">3</span>), normalize=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">'box'</span>, box)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>若指定normalize=False，显示图像为：</p>
<p><img src="/posts/CV/blur2.jpg" alt></p>
<p>我们看到大多数地方是全白一片，我们可以感觉到，当值之和大于255时，会直接将值定为255，不再如前面所述会取模。</p>
<h2 id="高斯滤波"><a href="#高斯滤波" class="headerlink" title="高斯滤波"></a>高斯滤波</h2><p>下面是著名的高斯滤波，高斯滤波会对同个窗口的不同位置的值设置不同的权重，最终加权平均取得这个窗口的最终值，对于一个3×3的窗口而言，上下左右离中心的距离最近，会将权重设的稍微高些，而四个角落离得距离较远，因此就会将权重设的稍微低些，比之均值滤波更合理，也就相当于构建权重矩阵进行滤波。</p>
<p>下面是高斯滤波的调用方式：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 高斯滤波</span></span><br><span class="line"><span class="comment"># 高斯模糊的卷积核里的数值是满足高斯分布，相当于更重视中间的</span></span><br><span class="line">aussian = cv2.GaussianBlur(img, (<span class="number">5</span>, <span class="number">5</span>), <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">'aussian'</span>, aussian)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p><img src="/posts/CV/aussian.jpg" alt></p>
<p>我们可以看出高斯滤波的噪音点没有那么明显了。</p>
<h2 id="中值滤波"><a href="#中值滤波" class="headerlink" title="中值滤波"></a>中值滤波</h2><p>中值就是将数从小到大排序取中位数，当我们数据有噪音点时，中值滤波可以立刻去除噪音点。</p>
<p>具体调用如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 中值滤波</span></span><br><span class="line"><span class="comment"># 相当于用中值代替</span></span><br><span class="line">median = cv2.medianBlur(img, <span class="number">5</span>)  <span class="comment"># 中值滤波</span></span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">'median'</span>, median)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>滤波结果如下：</p>
<p><img src="/posts/CV/median.jpg" alt></p>
<p>最终我们可以通过下面操作将所有图像拼接在一起：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">res = np.hstack((blur,aussian,median))</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">'median vs average'</span>, res)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>结果为：</p>
<p><img src="/posts/CV/concate.jpg" alt></p>
]]></content>
      <categories>
        <category>CV</category>
      </categories>
  </entry>
  <entry>
    <title>Opencv计算机视觉基础：（一）图像基本操作</title>
    <url>/posts/f4ba5069.html</url>
    <content><![CDATA[<p>首先展示以下实例原图像给大家萌一萌：</p>
<p><img src="/posts/CV/animal.jpg" alt></p>
<h1 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h1><p>下面直接列举需要搭建的环境：</p>
<ol>
<li>Anaconda+python大环境（相信大家都早已安装好了，若没有请前往百度搜索自行安装）</li>
<li>opencv以及扩展包的安装：<ul>
<li>直接在命令行输入以下两行分别安装即可：<blockquote>
<p>pip install opencv-python<br>pip install opencv-contrib-python</p>
</blockquote>
</li>
<li>若在第一个opencv-python中指定了版本号，比如（pip install opencv-python==4.2.0），需要注意在第二行的安装中也需要输入相同的版本号，opencv-contrib-python相当于给opencv-python添加了额外的扩展，比如特征提取的算法等。</li>
<li>若安装出错建议多安装几次（很可能是网络的问题），实在安装不了可以直接去官网下载，需要注意选择适当的python版本以及windows位数的安装包进行下载</li>
<li>安装完之后进入python，导入相应的包并查看版本号，若无异常就可以进入正题啦~<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">   <span class="keyword">import</span> cv2</span><br><span class="line">cv2.__version__</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ol>
<h1 id="图像读取"><a href="#图像读取" class="headerlink" title="图像读取"></a>图像读取</h1><p>我们看到的每一张彩色图片事实上都是由RGB三个颜色通道堆叠而成，每个通道实际上是一个矩阵，里面的每个元素大小从0-256不等，对于灰度图则只有一个通道。</p>
<p>我们很容易通过以下代码验证：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">"Pic/animal.jpg"</span>)</span><br><span class="line">print(img)</span><br><span class="line"></span><br><span class="line">img2 = cv2.imread(<span class="string">"Pic/animal.jpg"</span>, cv2.IMREAD_GRAYSCALE)</span><br><span class="line">print(img2)</span><br></pre></td></tr></table></figure>
<p>当我们想要查看图像，可以通过下面三行代码实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cv2.imshow(<span class="string">"image1"</span>, img)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>上面第一行imshow是用于展示图像；第二行waitKey是控制图片显示时间，若设置为0则当鼠标单击图像会消失，若设置为一个&gt;0的数，该数会转化成毫秒显示图像，比如可以试试20000；第三行是控制窗口关闭的，要注意区分cv2.destroyAllWindows()和cv2.destroyWindow()的区别。为了便于调用，可以将这三行代码写成一个函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cv_show</span><span class="params">(name, img)</span>:</span></span><br><span class="line">    cv2.imshow(name, img)</span><br><span class="line">    cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>可以通过img.shape显示图像形状：</p>
<p><img src="/posts/CV/shape.png" alt></p>
<p>正如前例所述，图像转换的命令为：</p>
<ul>
<li><p>cv2.IMREAD_COLOR:彩色图像</p>
</li>
<li><p>cv2.IMREAD_GRAYSCACLE:灰度图像</p>
</li>
</ul>
<h1 id="视频读取"><a href="#视频读取" class="headerlink" title="视频读取"></a>视频读取</h1><p>读取视频的代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">vc = cv2.VideoCapture(<span class="string">"Video/turtle.mp4"</span>)</span><br></pre></td></tr></table></figure>
<p>可以通过下面代码读取视频每一帧：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> vc.isOpened():</span><br><span class="line">    open, frame = vc.read()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    open = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>可以通过下面完整代码调节视频速度：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">vc = cv2.VideoCapture(<span class="string">"Video/turtle.mp4"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> open:</span><br><span class="line">    ret, frame = vc.read()</span><br><span class="line">    <span class="keyword">if</span> frame <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">if</span> ret == <span class="literal">True</span>:</span><br><span class="line">        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)</span><br><span class="line">        cv2.imshow(<span class="string">"result1"</span>, gray)</span><br><span class="line">        <span class="keyword">if</span> cv2.waitKey(<span class="number">100</span>) &amp; <span class="number">0xFF</span> == <span class="number">27</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">vc.release()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>其主要思想是将视频转化为帧，然后定时一张张播放图片，可以修改waitKey控制播放进度。</p>
<h1 id="图片基本操作"><a href="#图片基本操作" class="headerlink" title="图片基本操作"></a>图片基本操作</h1><h2 id="截取图片及像素转换"><a href="#截取图片及像素转换" class="headerlink" title="截取图片及像素转换"></a>截取图片及像素转换</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">"Pic/animal.jpg"</span>)</span><br><span class="line">cat = img[<span class="number">0</span>:<span class="number">200</span>,<span class="number">0</span>:<span class="number">200</span>]</span><br><span class="line">cv_show(<span class="string">"cat"</span>, cat)</span><br></pre></td></tr></table></figure>
<p>上述直接通过索引截取对应的部分矩阵（图像），可以通过以下代码实现分割RGB通道：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">b, g, r = cv2.split(img)</span><br></pre></td></tr></table></figure>
<p>这其中需要注意的是，通道的顺序并不是RGB，而是BGR！</p>
<p>我们切分完之后，若希望看各个通道的图像，可以通过下面三块代码实现：</p>
<p><img src="/posts/CV/rgb.png" alt></p>
<p>其中红图的结果如下：</p>
<p><img src="/posts/CV/B.png" alt></p>
<p>若想要重新将bgr通道组合在一起，可以通过merge函数实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img = cv2.merge((b, g, r))</span><br><span class="line">img.shape</span><br></pre></td></tr></table></figure>
<h2 id="边界填充"><a href="#边界填充" class="headerlink" title="边界填充"></a>边界填充</h2><p>我们做卷积时，常常会给图像做一个边界的填充，具体实现方式及效果如下：</p>
<p><img src="/posts/CV/border1.png" alt></p>
<p><img src="/posts/CV/border2.png" alt></p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">top_size, bottom_size, left_size, right_size = (<span class="number">50</span>, <span class="number">50</span>, <span class="number">50</span>, <span class="number">50</span>)</span><br><span class="line"></span><br><span class="line">replicate = cv2.copyMakeBorder(img, top_size, bottom_size, left_size, right_size, borderType=cv2.BORDER_REPLICATE)</span><br><span class="line">reflect = cv2.copyMakeBorder(img, top_size, bottom_size, left_size, right_size, borderType=cv2.BORDER_REFLECT)</span><br><span class="line">reflect101 = cv2.copyMakeBorder(img, top_size, bottom_size, left_size, right_size, borderType=cv2.BORDER_REFLECT_101)</span><br><span class="line">wrap = cv2.copyMakeBorder(img, top_size, bottom_size, left_size, right_size, borderType=cv2.BORDER_WRAP)</span><br><span class="line">constant = cv2.copyMakeBorder(img, top_size, bottom_size, left_size, right_size, borderType=cv2.BORDER_CONSTANT, value=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.subplot(<span class="number">231</span>), plt.imshow(img, <span class="string">"gray"</span>), plt.title(<span class="string">"ORIGINAL"</span>)</span><br><span class="line">plt.subplot(<span class="number">232</span>), plt.imshow(replicate, <span class="string">"gray"</span>), plt.title(<span class="string">"REPLICATE"</span>)</span><br><span class="line">plt.subplot(<span class="number">233</span>), plt.imshow(reflect, <span class="string">"gray"</span>), plt.title(<span class="string">"REFLECT"</span>)</span><br><span class="line">plt.subplot(<span class="number">234</span>), plt.imshow(reflect101, <span class="string">"gray"</span>), plt.title(<span class="string">"REFLECT_101"</span>)</span><br><span class="line">plt.subplot(<span class="number">235</span>), plt.imshow(wrap, <span class="string">"gray"</span>), plt.title(<span class="string">"WRAP"</span>)</span><br><span class="line">plt.subplot(<span class="number">236</span>), plt.imshow(constant, <span class="string">"gray"</span>), plt.title(<span class="string">"CONSTANT"</span>)</span><br><span class="line">plt.savefig(<span class="string">"border2.png"</span>)</span><br></pre></td></tr></table></figure>
<p>下面解释一下这几个填充原理：</p>
<ul>
<li>第一个是BORDER_REPLICATE，顾名思义就是直接复制边界像素；</li>
<li>第二个BORDER_REFLECT是反射法，也就是对感兴趣的图像中的像素子两边进行复制，比如fedcba|abcdefgh|hgfedcb；</li>
<li>第三个BORDER_REFLECT_101也是反射法，但是以最边缘像素为轴对称反射；</li>
<li>第四个BORDER_WRAP是外包装法：cdefgh|abcdefgh|abcdefg</li>
<li>第五个为常量法，使用常数值填充（在图中很明显为黑色边框）</li>
</ul>
<h2 id="数值计算"><a href="#数值计算" class="headerlink" title="数值计算"></a>数值计算</h2><p>我们可以直接把图片所有像素点做同一运算：比如下图所示的给所有像素加10：</p>
<p><img src="/posts/CV/add.png" alt></p>
<p>若两图像维度一致也可以直接相加：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img_1 = img_ + img</span><br><span class="line">cv2.imwrite(<span class="string">"add.png"</span>, img_1)</span><br><span class="line">cv_show(<span class="string">"Add"</span>, img_1)</span><br></pre></td></tr></table></figure>
<p>得到的图像也挺有趣的：</p>
<p><img src="/posts/CV/add1.png" alt></p>
<p>我们可以感觉到有些像素点变化有些大，这是由于当两个图像的像素点直接相加时，由于像素最高为256，若越界就会自动对256取余，因此图像有些部分比较怪异。</p>
<h2 id="图像融合"><a href="#图像融合" class="headerlink" title="图像融合"></a>图像融合</h2><p>我们可以将两张同大小的图片按比例融合到一张图片中，当我们发现这两张图片大小不一致，我们需要将图片resize成大小一致的图片方能进行融合，操作如下：</p>
<p><img src="/posts/CV/merge.png" alt></p>
<p>结果如下：</p>
<p><img src="/posts/CV/merge1.png" alt></p>
<p>具体操作为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">res = cv2.addWeighted(img1, <span class="number">0.4</span>, img3, <span class="number">0.6</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>其中0.4与0.6分别为这两张图片的权重，最后的0为偏置项，可以设置为其他值调节亮度。</p>
<p>另外，resize操作还可以不指定数值，而只是写出图像倍数关系，比如 ：</p>
<p><img src="/posts/CV/resize1.png" alt></p>
<p>具体操作如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">res1 = cv2.resize(res, (<span class="number">0</span>, <span class="number">0</span>), fx=<span class="number">3</span>,fy=<span class="number">1</span>)</span><br><span class="line">plt.imshow(res1)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>CV</category>
      </categories>
  </entry>
  <entry>
    <title>时间序列实战（四）</title>
    <url>/posts/127b555b.html</url>
    <content><![CDATA[<p>我们实际中一个时间序列可能有上千种特征，我们很难一个个提取，可以使用TSFRESH库帮我们提取时间序列 特征，这个库能提取的特征包括最大最小值，均值，峰值数目，中位数等等，据说能够提取出超过4000种特征，官方文档<a href="https://tsfresh.readthedocs.io/en/latest/" target="_blank" rel="noopener">戳这里</a></p>
<p>我们首先导入一堆包：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> tsfresh.examples.robot_execution_failures <span class="keyword">import</span> download_robot_execution_failures, load_robot_execution_failures</span><br><span class="line"><span class="keyword">from</span> tsfresh.utilities.dataframe_functions <span class="keyword">import</span> impute</span><br><span class="line"><span class="keyword">from</span> tsfresh.feature_extraction <span class="keyword">import</span> ComprehensiveFCParameters</span><br><span class="line"><span class="keyword">from</span> tsfresh <span class="keyword">import</span> extract_features, extract_relevant_features, select_features</span><br></pre></td></tr></table></figure>
<p>然后远程加载数据集：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">download_robot_execution_failures()</span><br><span class="line">df, y = load_robot_execution_failures()</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>
<p>得到的数据长这样：</p>
<p><img src="/Pic/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%AE%9E%E6%88%98%EF%BC%88%E5%9B%9B%EF%BC%89/image-20200828233524683.png" alt="image-20200828233524683"></p>
<p>我们的目的是预测时间序列数据是否为异常值，首先我们需要看看啥样的数据是正常的啥样是异常的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[df.id==<span class="number">3</span>][[<span class="string">"time"</span>, <span class="string">"F_x"</span>, <span class="string">"F_y"</span>, <span class="string">"F_z"</span>, <span class="string">"T_x"</span>, <span class="string">"T_y"</span>, <span class="string">"T_z"</span>]].plot(x=<span class="string">"time"</span>, title=<span class="string">"Success example (id 3)"</span>, figsize=(<span class="number">12</span>, <span class="number">6</span>));</span><br><span class="line">df[df.id==<span class="number">20</span>][[<span class="string">"time"</span>, <span class="string">"F_x"</span>, <span class="string">"F_y"</span>, <span class="string">"F_z"</span>, <span class="string">"T_x"</span>, <span class="string">"T_y"</span>, <span class="string">"T_z"</span>]].plot(x=<span class="string">"time"</span>, title=<span class="string">"Success example (id 20)"</span>, figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%AE%9E%E6%88%98%EF%BC%88%E5%9B%9B%EF%BC%89/df_see.png" alt></p>
<p><img src="/Pic/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%AE%9E%E6%88%98%EF%BC%88%E5%9B%9B%EF%BC%89/df_see1.png" alt></p>
<p>第一个是正常的，第二个是异常的，我们人眼应该是很容易区分的，接下来我们基于时间序列做特征提取：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">extraction_settings = ComprehensiveFCParameters()</span><br><span class="line">X = extract_features(df, column_id=<span class="string">"id"</span>, column_sort=<span class="string">"time"</span>, default_fc_parameters=extraction_settings, impute_function=impute)</span><br></pre></td></tr></table></figure>
<p>然后就会出现一个特征提取的进度条，完成了特征提取，打印一下X看看结果是啥：</p>
<p><img src="/Pic/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%AE%9E%E6%88%98%EF%BC%88%E5%9B%9B%EF%BC%89/image-20200828234027149.png" alt="image-20200828234027149"></p>
<p>这里一共提取出了 4578种时间序列特征，接下来我们需要筛选特征，提取最相关特征：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X_filtered = extract_relevant_features(df, y, column_id=<span class="string">"id"</span>, column_sort=<span class="string">"time"</span>, default_fc_parameters=extraction_settings)</span><br></pre></td></tr></table></figure>
<p>代码和前面的没啥区别，提取完之后还剩下635个特征：</p>
<p><img src="/Pic/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%AE%9E%E6%88%98%EF%BC%88%E5%9B%9B%EF%BC%89/image-20200828234350277.png" alt="image-20200828234350277"></p>
<p>接下来将数据进行<code>train_test_split</code>等一系列分类常规操作完成分类：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X_train, X_test, X_filtered_train, X_filtered_test, y_train, y_test = train_test_split(X, X_filtered, y, test_size=<span class="number">.4</span>)</span><br><span class="line">clf = DecisionTreeClassifier()</span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line">print(classification_report(y_test, clf.predict(X_test)))</span><br></pre></td></tr></table></figure>
<p>打印结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">       False       0.97      1.00      0.98        28</span><br><span class="line">        True       1.00      0.88      0.93         8</span><br><span class="line"></span><br><span class="line">    accuracy                           0.97        36</span><br><span class="line">   macro avg       0.98      0.94      0.96        36</span><br><span class="line">weighted avg       0.97      0.97      0.97        36</span><br></pre></td></tr></table></figure>
<p>可以看到结果还是很不错的~我们看看经过<code>filtered</code>处理后的结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">clf = DecisionTreeClassifier()</span><br><span class="line">clf.fit(X_filtered_train, y_train)</span><br><span class="line">print(classification_report(y_test, clf.predict(X_filtered_test)))</span><br></pre></td></tr></table></figure>
<p>打印输出和前面的一模一样===</p>
]]></content>
      <categories>
        <category>TimeSeries</category>
      </categories>
  </entry>
  <entry>
    <title>时间序列实战（三）</title>
    <url>/posts/a5564c3e.html</url>
    <content><![CDATA[<h1 id="数据获取"><a href="#数据获取" class="headerlink" title="数据获取"></a>数据获取</h1><p>我们下面借助<code>pandas_datareader</code>库中的<code>get_data_tiingo</code>获得我们的股票交易数据，首先我们需要在<code>tiingo</code>上注册我们的账号，然后<code>tiingo</code>会给我们提供一个<code>api-key</code>，我们下面假设这个<code>api-key</code>值为<code>API</code>，大家可以将这个<code>api-key</code>传入环境变量中，这样可以避免很多重复操作。</p>
<p>导入我们需要的包：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas_datareader <span class="keyword">as</span> pdr</span><br><span class="line"><span class="keyword">import</span> os</span><br></pre></td></tr></table></figure>
<p>读取我们的GOOG股票数据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = pdr.get_data_tiingo(<span class="string">'GOOG'</span>, api_key=API)</span><br><span class="line"><span class="comment"># 设置了环境变量并命名为TIINGO_API_KEY后可以将api-key指定为os.getenv('TIINGO_API_KEY')</span></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>
<p>我们得到的数据长这样：</p>
<p><img src="/Pic/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%89%EF%BC%89/image-20200828164456136.png" alt="image-20200828164456136"></p>
<p>我们可以<code>plot</code>一下闭盘价：</p>
<p><img src="data:image/png;base64,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" alt="img"></p>
<p>我们再介绍另一个接口<code>IEX</code>，这个接口访问速度比较快，大家可以根据自己的需要进行选择，同样我们也需要在<code>IEX</code>官网注册得到一个账号与<code>api-key</code>，然后我们试着读取数据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas_datareader.data <span class="keyword">as</span> web</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line">start = datetime(<span class="number">2016</span>, <span class="number">9</span>, <span class="number">1</span>)</span><br><span class="line">end = datetime(<span class="number">2018</span>, <span class="number">9</span>, <span class="number">1</span>)</span><br><span class="line">f = web.DataReader(<span class="string">'F'</span>, <span class="string">'iex'</span>, start, end, api_key=API)</span><br><span class="line">f.loc[<span class="string">'2018-08-31'</span>]</span><br></pre></td></tr></table></figure>
<p>得到这样的一个东东：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">open             9.64</span><br><span class="line">high             9.68</span><br><span class="line">low              9.40</span><br><span class="line">close            9.48</span><br><span class="line">volume    76424884.00</span><br><span class="line">Name: 2018-08-31, dtype: float64</span><br></pre></td></tr></table></figure>
<p>可以看得出来数据比<code>tiingo</code>的少了一些，这里只有四个主要的数据，下面简要介绍一下这两个接口（平台）的区别。</p>
<ul>
<li><code>Tiingo</code>是一个跟踪平台，提供股票、基金(equities, mutual funds and ETFs)的历史收盘价格的数据<code>API</code>。需要免费注册才能获得<code>API</code>密钥。免费账户是有费率限制的，可以访问有限数量的数据(目前为500个symbols)。</li>
<li>投资者交易所(IEX)通过API提供广泛的数据。历史股票价格的有效期最长可达15年。这些读卡器的使用需要IEX云控制台的可发布API密钥，该密钥可以存储IEX_API_KEY环境变量中。</li>
</ul>
<p>更多的接口大家可以戳<a href="https://www.jianshu.com/p/315157a46c61" target="_blank" rel="noopener">参考链接一</a>，作者写的很详细~</p>
<h1 id="数据观察与处理"><a href="#数据观察与处理" class="headerlink" title="数据观察与处理"></a>数据观察与处理</h1><p>由于索引标签是一个<code>multiindex</code>，先将其转换成正常的时间序列索引：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[<span class="string">"index_"</span>] = df.index.droplevel().values</span><br><span class="line">df.set_index(<span class="string">"index_"</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>
<p>现在看起来可不正常多了：</p>
<p><img src="/Pic/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%89%EF%BC%89/image-20200828172958170.png" alt="image-20200828172958170"></p>
<p>我们可以将股票数据按周重排，这里利用到我们时间序列实战（一）中的知识：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">stock_week = df[<span class="string">"close"</span>].resample(<span class="string">"W-MON"</span>).mean()</span><br><span class="line">stock_week.head()</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">index_</span><br><span class="line">2015-08-31    618.250</span><br><span class="line">2015-09-07    604.770</span><br><span class="line">2015-09-14    619.548</span><br><span class="line">2015-09-21    635.742</span><br><span class="line">2015-09-28    615.542</span><br><span class="line">Freq: W-MON, Name: close, dtype: float64</span><br></pre></td></tr></table></figure>
<p>下面我们可以使用神奇的切片方法获得我们的训练数据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">stock_train = stock_week[<span class="string">"2015"</span>:<span class="string">"2019"</span>]</span><br><span class="line">stock_train.tail()</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">index_</span><br><span class="line">2019-12-02    1305.3550</span><br><span class="line">2019-12-09    1325.6260</span><br><span class="line">2019-12-16    1349.7900</span><br><span class="line">2019-12-23    1352.4420</span><br><span class="line">2019-12-30    1347.9975</span><br><span class="line">Freq: W-MON, Name: close, dtype: float64</span><br></pre></td></tr></table></figure>
<p>时间序列的切片方法还真是得天独厚，下面我们根据这个新的数据画一个图：</p>
<p><img src="data:image/png;base64,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" alt="img"></p>
<p>其实和前面的图差距不大，可以看出这个图的浮动比较大，平稳性也较差，因此我们需要先做一个一阶差分或二阶差分：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">stock_diff = stock_train.diff()</span><br><span class="line">stock_diff = stock_diff.dropna()</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(stock_diff)</span><br><span class="line">plt.title(<span class="string">"diff_1"</span>)</span><br></pre></td></tr></table></figure>
<p><img src="data:image/png;base64,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" alt="img"></p>
<p>可以看出一阶差分之后的图还是比较平稳的，我们暂时认为一阶差分已经足够了。</p>
<h1 id="模型建立与预测"><a href="#模型建立与预测" class="headerlink" title="模型建立与预测"></a>模型建立与预测</h1><p>下面我们分别看指标<code>ACF</code>和<code>PACF</code>的值，首先导入相应的包：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line"><span class="keyword">import</span> statsmodels.formula.api <span class="keyword">as</span> smf</span><br><span class="line"><span class="keyword">import</span> statsmodels.tsa.api <span class="keyword">as</span> smt</span><br><span class="line"><span class="keyword">from</span> statsmodels.tsa.api <span class="keyword">import</span> graphics</span><br></pre></td></tr></table></figure>
<p>调用函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">acf = graphics.plot_acf(stock_diff, lags=<span class="number">20</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%89%EF%BC%89/acf.png" alt></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">acf = graphics.plot_acf(stock_diff, lags=<span class="number">20</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%89%EF%BC%89/pacf.png" alt></p>
<p>由<code>ACF</code>和<code>PACF</code>图可以看出<code>q</code>值和<code>p</code>值的取值</p>
<p>下面我们训练一个模型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = sm.tsa.ARIMA(stock_train, order=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>), freq=<span class="string">"W-MON"</span>)</span><br><span class="line">results = model.fit()</span><br></pre></td></tr></table></figure>
<p>可以输出一下预测结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pred = results.predict(<span class="string">"20200106"</span>, <span class="string">"20200831"</span>, dynamic=<span class="literal">True</span>, typ=<span class="string">"levels"</span>)</span><br><span class="line">print(pred)</span><br></pre></td></tr></table></figure>
<p>一般来说我们使用这个预测都是只能判断股票大概走势，我们可以画一下图：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">6</span>, <span class="number">6</span>))</span><br><span class="line">plt.xticks(rotation=<span class="number">45</span>)</span><br><span class="line">plt.plot(pred)</span><br><span class="line">plt.plot(stock_week)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%89%EF%BC%89/res.png" alt></p>
<p>这个股票的波动比较剧烈，咱也不能要求太多了hhh就酱吧~</p>
<p>参考链接：</p>
<ul>
<li><a href="https://www.jianshu.com/p/315157a46c61" target="_blank" rel="noopener">https://www.jianshu.com/p/315157a46c61</a></li>
</ul>
]]></content>
      <categories>
        <category>TimeSeries</category>
      </categories>
  </entry>
  <entry>
    <title>时间序列实战（二）</title>
    <url>/posts/538fa423.html</url>
    <content><![CDATA[<h1 id="数据平稳性与差分法"><a href="#数据平稳性与差分法" class="headerlink" title="数据平稳性与差分法"></a>数据平稳性与差分法</h1><p>在时间序列数据中一个很重要的模型是ARIMA模型，当我们拿到一个股票数据我们希望预测他未来的情况或者是获得前一个月的天气情况想要知道下一个月的天气情况，我们就可以根据ARIMA模型建立一个回归或分析。当然进行预测之前我们拿到的时间序列模型是需要有惯性的（平稳性）：</p>
<blockquote>
<p>平稳性要求经由样本时间序列所得到的拟合曲线在未来的一短期间内仍能顺着现有的形态延续下去，平稳性要求序列的均值和方差不发生明显变化</p>
</blockquote>
<p>平稳性又衍生出两个概念：严平稳和弱平稳</p>
<ul>
<li>严平稳：严平稳表示的分布不随时间的改变而改变。如：白噪声（正态），无论怎么取都是期望为0，方差为1</li>
<li>弱平稳：期望与相关系数（依赖性）不变，未来某时刻的t的值就要依赖于它的过去信息，所以需要依赖性</li>
</ul>
<p>为了让数据不发生明显变化 ，一个方法就是差分法：时间序列在t与t-1时刻的差值，我们首先导入相应的包，读取经典的机场乘客数据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> os, re</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line">dateparse = <span class="keyword">lambda</span> date: datetime.strptime(date, <span class="string">"%Y-%m"</span>)</span><br><span class="line">data = pd.read_csv(<span class="string">"data/AirPassengers.csv"</span>, parse_dates=[<span class="string">"Month"</span>], index_col=<span class="string">"Month"</span>, date_parser=dateparse)</span><br></pre></td></tr></table></figure>
<p>dataparse的作用是将原来的不规整的月份信息转变成datetime承认的时间信息，我们看一下数据长什么样：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data.head()</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">            #Passengers</span><br><span class="line">Month                                  </span><br><span class="line">1949-01-01          112</span><br><span class="line">1949-02-01          118</span><br><span class="line">1949-03-01          132</span><br><span class="line">1949-04-01          129</span><br><span class="line">1949-05-01          121</span><br></pre></td></tr></table></figure>
<p>经过初步的处理这个数据已经是一个标准的时间序列数据，我们直接观察该数据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line">data.plot(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/image-20200823095328888.png" alt="image-20200823095328888" style="zoom:67%;"></p>
<p>可以看到这个数据集不是很平稳，我们可以对其做一阶差分以及二阶差分，其中二阶差分是在一阶差分的基础上再做的一次差分：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对数据做差分</span></span><br><span class="line">data[<span class="string">"diff_1"</span>] = data[<span class="string">"#Passengers"</span>].diff(<span class="number">1</span>)</span><br><span class="line">data[<span class="string">"diff_2"</span>] = data[<span class="string">"diff_1"</span>].diff(<span class="number">1</span>)</span><br><span class="line">data.plot(subplots=<span class="literal">True</span>, figsize=(<span class="number">18</span>, <span class="number">12</span>))</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/image-20200823095444737.png" alt="image-20200823095444737"></p>
<p>可以看到数据变得平稳多了，这将有助于我们做进一步的数据探索。</p>
<h1 id="ARIMA模型"><a href="#ARIMA模型" class="headerlink" title="ARIMA模型"></a>ARIMA模型</h1><p>ARIMA是由三个英文字母的缩写组合而成：AR、MA和I，下面一一阐述。</p>
<p><strong>自回归模型（AR）</strong></p>
<ul>
<li>描述当前值和历史之之间的关系，用变量自身的历史时间数据对自身进行预测，因此数据必须具有自相关性，若自相关系数（$\phi_i$）小于0.5则不宜采用，自回归只适用于预测与自身前期相关的现象</li>
<li>自回归模型必须满足平稳性的要求，因此自回归模型首先需要整差分项</li>
<li>p阶自回归过程的公式定义：$y_t = \mu+\sum_{i=1}^p\gamma_i y_{t-i}+\epsilon_t$，其中$y_t$是当前值，$\mu$是常数项，$p$是阶数，$\gamma_i$是相关系数，$\epsilon_t$是误差</li>
</ul>
<p><strong>移动平均模型（MA）</strong></p>
<ul>
<li>移动平均模型关注的是自回归模型中的误差项的累加</li>
<li><p>$q$阶自回归过程的公式的定义：$y_t = \mu+\epsilon_t+\sum_{i=1}^q\phi_i\epsilon_{t-i}$</p>
</li>
<li><p>移动平均法能有效地消除预测中地随机波动</p>
</li>
</ul>
<p><strong>自回归移动平均模型</strong></p>
<ul>
<li>自回归与移动平均的结合</li>
<li>公式定义：$y_t = \mu+\sum_{i=1}^p\gamma_i y_{t-i}+\epsilon_t+\sum_{i=1}^q\phi_i\epsilon_{t-i}$</li>
<li>ARIMA中的I指的是差分</li>
<li>原理：将非平稳的时间序列转化为平稳的时间序列然后将因变量仅对它的滞后值以及随机误差项的现值和滞后值进行回归建立的模型</li>
</ul>
<p>我们可以直接使用statsmodels包中的函数实现这一过程，只需传入三个参数：$(p,d,q)$，其中$p$和$q$分别为自回归模型和移动平均模型的阶数称为自回归项与移动平均项，$d$为使时间序列成为平稳时所做的差分阶数（通常使用一阶）：</p>
<h1 id="相关函数评估方法"><a href="#相关函数评估方法" class="headerlink" title="相关函数评估方法"></a>相关函数评估方法</h1><p><strong>自相关函数ACF（autocorrelation function）</strong></p>
<ul>
<li><p>有序的随机变量序列与其自身相比较，自相关函数反应了同一序列在不同时序取值之间的相关性（对原数据与其N阶差分算相关系数）</p>
</li>
<li><p>公式为：$ACF(k) = \rho_k = \frac{Cov(y_t,y_{t-k})}{Var(y_t)}$，$\rho_k$的取值范围为$[-1,1]$</p>
</li>
</ul>
<p><strong>偏自相关函数PACF（partial autocorrelation function）</strong></p>
<ul>
<li>对于一个平稳$AR(p)$模型，求出滞后$k$自相关系数$p(k)$时实际上得到的并不是$x(t)$与$x(t-k)$之间的单纯相关关系</li>
<li>$x(t)$同时还会受到中间$k-1$个随机变量$x(t-1),x(t-2),…,x(t-k+1)$的影响，而这$k-1$个随机变量又和$x(t-k)$具有相关关系，所以自相关系数$p(k)$里实际掺杂了其他变量对$x(t)$与$x(t-k)$的影响</li>
<li>剔除了中间$k-1$个随机变量$x(t-1),x(t-2),…,x(t-k+1)$的干扰后$x(t-k)$对$x(t)$影响的相关程度</li>
<li>ACF还包含了其他变量的影响，而偏自相关系数PACF是严格这两个变量之间的相关性</li>
</ul>
<h1 id="建立ARIMA模型"><a href="#建立ARIMA模型" class="headerlink" title="建立ARIMA模型"></a>建立ARIMA模型</h1><h2 id="ARIMA建模流程"><a href="#ARIMA建模流程" class="headerlink" title="ARIMA建模流程"></a>ARIMA建模流程</h2><ul>
<li>将序列平稳（差分法确定d）</li>
<li>p和q阶数确定：ACF和PACF</li>
<li>ARIMA(p,d,q)</li>
</ul>
<h2 id="ARIMA-p-d-q-阶数确定"><a href="#ARIMA-p-d-q-阶数确定" class="headerlink" title="ARIMA(p,d,q)阶数确定"></a>ARIMA(p,d,q)阶数确定</h2><p>我们首先导入所需的库：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line"><span class="keyword">import</span> statsmodels.formula.api <span class="keyword">as</span> smf</span><br><span class="line"><span class="keyword">import</span> statsmodels.tsa.api <span class="keyword">as</span> smt</span><br></pre></td></tr></table></figure>
<p>然后调用两个函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dateparse = <span class="keyword">lambda</span> date: datetime.strptime(date, <span class="string">"%Y-%m"</span>)</span><br><span class="line">data = pd.read_csv(<span class="string">"data/AirPassengers.csv"</span>, parse_dates=[<span class="string">"Month"</span>], index_col=<span class="string">"Month"</span>, date_parser=dateparse)</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line"></span><br><span class="line">ax1 = fig.add_subplot(<span class="number">211</span>)</span><br><span class="line">fig = sm.graphics.tsa.plot_acf(data, lags=<span class="number">20</span>, ax=ax1)</span><br><span class="line">ax1.xaxis.set_ticks_position(<span class="string">"bottom"</span>)</span><br><span class="line">fig.tight_layout();</span><br><span class="line"></span><br><span class="line">ax2 = fig.add_subplot(<span class="number">212</span>)</span><br><span class="line">fig = sm.graphics.tsa.plot_pacf(data, lags=<span class="number">20</span>, ax=ax2)</span><br><span class="line">ax1.xaxis.set_ticks_position(<span class="string">"bottom"</span>)</span><br><span class="line">fig.tight_layout();</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/acf.png" alt="acf"></p>
<p>上图即为得到的结果，阴影部分表示置信区间，这里可以看出不同阶数的自相关性的变化规律。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>模型</th>
<th>ACF</th>
<th>PACF</th>
</tr>
</thead>
<tbody>
<tr>
<td>$AR(p)$</td>
<td>衰减趋于零（几何型或震荡型）</td>
<td>$p$阶后截尾</td>
</tr>
<tr>
<td>$MA(q)$</td>
<td>$q$阶后截尾</td>
<td>衰减趋于零（几何型或震荡型）</td>
</tr>
<tr>
<td>$ARMA(p,q)$</td>
<td>$q$阶后衰减趋于零（几何型或震荡型）</td>
<td>$p$阶后衰减趋于零（几何型或震荡型）</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>截尾：落在置信区间内（95%的点都符合该规则）</p>
</blockquote>
<p>在上面的PACF图中我们可以看到$p=2$就截尾了，因此我们可以直接取$p$为2，我们同时也可以看到ACF图中约为13截尾，因此取$q=13$。</p>
<p>我们也可以画出散点图，本质和前面一样，不过更直观：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 散点图</span></span><br><span class="line">lags = <span class="number">9</span></span><br><span class="line">ncols = <span class="number">3</span></span><br><span class="line">nrows = int(np.ceil(lags/ncols))</span><br><span class="line"></span><br><span class="line">fig, axes = plt.subplots(ncols=ncols, nrows=nrows, figsize=(<span class="number">4</span>*ncols, <span class="number">4</span>*nrows))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ax, lag <span class="keyword">in</span> zip(axes.flat, np.arange(<span class="number">1</span>, lags+<span class="number">1</span>, <span class="number">1</span>)):</span><br><span class="line">    lag_str = <span class="string">"t-&#123;&#125;"</span>.format(lag)</span><br><span class="line">    X = (pd.concat([data, data.shift(-lag)], axis=<span class="number">1</span>, keys=[<span class="string">"#Passengers"</span>]+[lag_str]).dropna())</span><br><span class="line">    X.plot(ax=ax, kind=<span class="string">"scatter"</span>, y=<span class="string">"#Passengers"</span>, x=lag_str);</span><br><span class="line">    corr = X.corr().as_matrix()[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 若是新版本的pandas，应使用corr = X.corr().value[0][1]</span></span><br><span class="line">    ax.set_ylabel(<span class="string">"Original"</span>)</span><br><span class="line">    ax.set_title(<span class="string">"Lag:&#123;&#125;(corr=&#123;:.2f&#125;)"</span>.format(lag_str, corr));</span><br><span class="line">    ax.set_aspect(<span class="string">"equal"</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/lag.png" alt="lag"></p>
<p>为了方便我们可以整一个画图函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tsplot</span><span class="params">(y, lags=None, title=<span class="string">""</span>, figsize=<span class="params">(<span class="number">14</span>, <span class="number">8</span>)</span>)</span>:</span></span><br><span class="line">    fig = plt.figure(figsize=figsize)</span><br><span class="line">    layout = (<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">    ts_ax = plt.subplot2grid(layout, (<span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">    hist_ax = plt.subplot2grid(layout, (<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">    acf_ax = plt.subplot2grid(layout, (<span class="number">1</span>, <span class="number">0</span>))</span><br><span class="line">    pacf_ax = plt.subplot2grid(layout, (<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    </span><br><span class="line">    y.plot(ax=ts_ax)</span><br><span class="line">    ts_ax.set_title(title)</span><br><span class="line">    y.plot(ax=hist_ax, kind=<span class="string">"hist"</span>, bins=<span class="number">25</span>)</span><br><span class="line">    hist_ax.set_title(<span class="string">"Histogram"</span>)</span><br><span class="line">    smt.graphics.plot_acf(y, lags=lags, ax=acf_ax)</span><br><span class="line">    smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax)</span><br><span class="line">    [ax.set_xlim(<span class="number">0</span>) <span class="keyword">for</span> ax <span class="keyword">in</span> [acf_ax, pacf_ax]]</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    <span class="keyword">return</span> ts_ax, acf_ax, pacf_ax</span><br></pre></td></tr></table></figure>
<p>以后需要用到直接调用即可：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tsplot(data, title=<span class="string">"Passenger count"</span>, lags=<span class="number">36</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/image-20200823111537908.png" alt="image-20200823111537908"></p>
<h2 id="参数选择"><a href="#参数选择" class="headerlink" title="参数选择"></a>参数选择</h2><p>下面我们切分数据集</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dateparse = <span class="keyword">lambda</span> date: datetime.strptime(date, <span class="string">"%Y-%m"</span>)</span><br><span class="line">data = pd.read_csv(<span class="string">"data/AirPassengers.csv"</span>, parse_dates=[<span class="string">"Month"</span>], index_col=<span class="string">"Month"</span>, date_parser=dateparse)</span><br><span class="line"></span><br><span class="line">n_train = int(<span class="number">0.8</span>*len(data))</span><br><span class="line">n_forcast = len(data)-n_train</span><br><span class="line"></span><br><span class="line">ts_train = data.iloc[:n_train][<span class="string">"#Passengers"</span>]</span><br><span class="line">ts_test = data.iloc[n_train:][<span class="string">"#Passengers"</span>]</span><br><span class="line">print(ts_train.shape, ts_test.shape)</span><br><span class="line">ts_train.head()</span><br></pre></td></tr></table></figure>
<p>然后可以建立模型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arima211 = sm.tsa.SARIMAX(ts_train, order=(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>), enforce_stationarity=<span class="literal">False</span>, enforce_invertibility=<span class="literal">False</span>)</span><br><span class="line">model_results = arima200.fit()</span><br><span class="line">model_results.summary()</span><br></pre></td></tr></table></figure>
<p>结果如下:</p>
<p><img src="/Pic/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/1.png" style="zoom:75%;"></p>
<p>下面我们希望对<code>order</code>的可能取值范围进行调参，我们编写以下函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 选择order参数</span></span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"></span><br><span class="line">p_min = <span class="number">1</span></span><br><span class="line">d_min = <span class="number">1</span></span><br><span class="line">q_min = <span class="number">1</span></span><br><span class="line">p_max = <span class="number">4</span></span><br><span class="line">d_max = <span class="number">1</span></span><br><span class="line">q_max = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">results_bic = pd.DataFrame(index=[<span class="string">"AR&#123;&#125;"</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(p_min, p_max+<span class="number">1</span>)],</span><br><span class="line">                           columns=[<span class="string">"MA&#123;&#125;"</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(q_min, q_max+<span class="number">1</span>)])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> p, d, q <span class="keyword">in</span> itertools.product(range(p_min, p_max+<span class="number">1</span>), range(d_min, d_max+<span class="number">1</span>), range(q_min, q_max+<span class="number">1</span>)):</span><br><span class="line">    <span class="keyword">if</span> p==<span class="number">1</span> <span class="keyword">and</span> d==<span class="number">1</span> <span class="keyword">and</span> q==<span class="number">1</span>:</span><br><span class="line">        results_bic.loc[<span class="string">"AR&#123;&#125;"</span>.format(p), <span class="string">"MA&#123;&#125;"</span>.format(q)] = np.nan</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        model = sm.tsa.SARIMAX(ts_train, order=(p, d, q), enforce_invertibility=<span class="literal">False</span>, enforce_stationarity=<span class="literal">False</span>)</span><br><span class="line">        results = model.fit()</span><br><span class="line">        results_bic.loc[<span class="string">"AR&#123;&#125;"</span>.format(p), <span class="string">"MA&#123;&#125;"</span>.format(q)] = results.bic</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">results_bic = results_bic[results_bic.columns].astype(float)</span><br></pre></td></tr></table></figure>
<p>可以看到<code>results_bic</code>是这个玩意：</p>
<p><img src="/Pic/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/2.png" alt></p>
<p>可以展示一下热力图：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">10</span>, <span class="number">8</span>))</span><br><span class="line">ax = sns.heatmap(results_bic, mask=results_bic.isnull(), ax=ax, annot=<span class="literal">True</span>, fmt=<span class="string">".2f"</span>);</span><br><span class="line">ax.set_title(<span class="string">"BIC"</span>)</span><br><span class="line">plt.savefig(<span class="string">"output/Pic/BIC_passenger1.png"</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/BIC_passenger1-1598513021481.png" alt></p>
<p>上面的<code>BIC</code>是什么意思呢，下面我们讲一下<code>AIC</code>与<code>BIC</code>：</p>
<p><strong>AIC</strong>：赤池信息准则（Akaike Information Criterion）$AIC = 2k - 2ln(L)$</p>
<p><strong>BIC</strong>：贝叶斯信息准则（Bayesian Information Criterion）$BIC = kln(n) - 2ln(L)$</p>
<p>其中$k$为模型参数个数，$n$为样本数量，$L$为似然函数，由这两个公式我们可以看出，无论是<code>AIC</code>还是<code>BIC</code>都是越低越好（选择更简单的模型）</p>
<p>我们可以直接调用<code>arma_order_select_ic</code>函数得到最佳的AIC和BIC的结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_results = sm.tsa.arma_order_select_ic(ts_train, ic=[<span class="string">"aic"</span>,<span class="string">"bic"</span>], trend=<span class="string">"nc"</span>, max_ar=<span class="number">4</span>, max_ma=<span class="number">4</span>)</span><br><span class="line">print(<span class="string">"AIC"</span>, train_results.aic_min_order)</span><br><span class="line">print(<span class="string">"BIC"</span>, train_results.bic_min_order)</span><br></pre></td></tr></table></figure>
<p>输出结果为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">AIC (<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">BIC (<span class="number">3</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>这两个结果还有些差异，我们可以自行选择。</p>
<h2 id="模型残差检验"><a href="#模型残差检验" class="headerlink" title="模型残差检验"></a>模型残差检验</h2><ul>
<li><code>ARIMA</code>模型的残差是否是平均值为0且方差为常数的正态分布</li>
<li><code>QQ</code>图：线性即正态分布</li>
</ul>
<p>上述可以调用函数得到结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model_results.plot_diagnostics(figsize=(<span class="number">16</span>, <span class="number">12</span>))</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/model_results-1598513536956.png" alt></p>
<p>可以看到<code>QQ</code>图近似呈一条直线，残差还是比较理想的可以通过检测。</p>
]]></content>
      <categories>
        <category>TimeSeries</category>
      </categories>
  </entry>
  <entry>
    <title>泰坦尼克号生存率预测</title>
    <url>/posts/c65daabc.html</url>
    <content><![CDATA[<p>我们首先在Kaggle上找到对应的竞赛页面，报名参赛下载数据，于是我们得到了一个train.csv和test.csv文件，由于这个比赛比较简单，我们也简简单单地先按照套路完成数据探索（数据可视化）、数据预处理、模型搭建以及跑测试结果这几个步骤。现在我们开动吧~</p>
<h1 id="数据概述与可视化"><a href="#数据概述与可视化" class="headerlink" title="数据概述与可视化"></a>数据概述与可视化</h1><h2 id="数据概述"><a href="#数据概述" class="headerlink" title="数据概述"></a>数据概述</h2><p>首先我们导入我们的训练数据和测试数据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_data = pd.read_csv(<span class="string">"input/train.csv"</span>, index_col=<span class="number">0</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">"input/test.csv"</span>, index_col=<span class="number">0</span>)</span><br><span class="line">train_data.head()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/1.png" alt></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_data.describe()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/2.png" alt></p>
<p>通过describe()函数我们可以简单地看出哪些是数值型数据哪些是字符型数据，对于字符型数据我们当然要转换成数值型数据来处理，比如可以转换成0-1编码的数值型，但需要注意的是，对于一些数值型数据却未必就不需要进一步的处理了，比如Pclass特征，从名字我们就可以看出这是标识仓位等级的特征，取值范围为[1, 2, 3]，这个特征我们不应该简单地当作一个数值型数据放进分类模型中直接跑，应该把它转变为one-hot编码，标识乘客不同的仓位，这一步我们将在数据预处理步骤完成。</p>
<p>我们再看看数据中值为null的数据，这是我们后面需要进一步处理的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_data.isnull().sum().sort_values(ascending=<span class="literal">False</span>).head(<span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<p>显示结果为：</p>
<blockquote>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">Cabin       687</span><br><span class="line">Age         177</span><br><span class="line">Embarked      2</span><br><span class="line">Fare          0</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure>
</blockquote>
<h2 id="数据可视化"><a href="#数据可视化" class="headerlink" title="数据可视化"></a>数据可视化</h2><p>为了这篇文章看起来内容多一点（误），我们可以画多点图来展示数据信息，想直接进行数据预处理的读者可以跳过这部分，这部分内容大多来自<a href="https://www.kaggle.com/nadintamer/titanic-survival-predictions-beginner" target="_blank" rel="noopener">Kaggle官网的一篇notebook</a>。</p>
<h3 id="性别与生存率"><a href="#性别与生存率" class="headerlink" title="性别与生存率"></a>性别与生存率</h3><p>首先我们应该还记得电影里感人的“女士优先”策略：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.barplot(x=<span class="string">"Sex"</span>, y=<span class="string">"Survived"</span>, data=train_data)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/sex.png" alt></p>
<p>这里我们可以看出女性的生存率远大于男性，这也很符合电影的情节。</p>
<h3 id="仓位等级（社会等级）与生存率"><a href="#仓位等级（社会等级）与生存率" class="headerlink" title="仓位等级（社会等级）与生存率"></a>仓位等级（社会等级）与生存率</h3><p>我们还可以猜测不同仓位的乘客应有不同的获救率：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#draw a bar plot of survival by Pclass</span></span><br><span class="line">sns.barplot(x=<span class="string">"Pclass"</span>, y=<span class="string">"Survived"</span>, data=train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#print percentage of people by Pclass that survived</span></span><br><span class="line">print(<span class="string">"Percentage of Pclass = 1 who survived:"</span>, train[<span class="string">"Survived"</span>][train[<span class="string">"Pclass"</span>] == <span class="number">1</span>].value_counts(normalize = <span class="literal">True</span>)[<span class="number">1</span>]*<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Percentage of Pclass = 2 who survived:"</span>, train[<span class="string">"Survived"</span>][train[<span class="string">"Pclass"</span>] == <span class="number">2</span>].value_counts(normalize = <span class="literal">True</span>)[<span class="number">1</span>]*<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Percentage of Pclass = 3 who survived:"</span>, train[<span class="string">"Survived"</span>][train[<span class="string">"Pclass"</span>] == <span class="number">3</span>].value_counts(normalize = <span class="literal">True</span>)[<span class="number">1</span>]*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/pclass.png" alt></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Percentage of Pclass &#x3D; 1 who survived: 62.96296296296296</span><br><span class="line">Percentage of Pclass &#x3D; 2 who survived: 47.28260869565217</span><br><span class="line">Percentage of Pclass &#x3D; 3 who survived: 24.236252545824847</span><br></pre></td></tr></table></figure>
<p>数据结果还是很现实的，贵的仓位自然有更高的生存率 ，不然我花这冤枉钱干嘛，生死面前不是人人平等。</p>
<blockquote>
<p>As predicted, people with higher socioeconomic class had a higher rate of survival. (62.9% vs. 47.3% vs. 24.2%)</p>
</blockquote>
<h3 id="家属数与生存率"><a href="#家属数与生存率" class="headerlink" title="家属数与生存率"></a>家属数与生存率</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#draw a bar plot for SibSp vs. survival</span></span><br><span class="line">sns.barplot(x=<span class="string">"SibSp"</span>, y=<span class="string">"Survived"</span>, data=train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#I won't be printing individual percent values for all of these.</span></span><br><span class="line">print(<span class="string">"Percentage of SibSp = 0 who survived:"</span>, train[<span class="string">"Survived"</span>][train[<span class="string">"SibSp"</span>] == <span class="number">0</span>].value_counts(normalize = <span class="literal">True</span>)[<span class="number">1</span>]*<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Percentage of SibSp = 1 who survived:"</span>, train[<span class="string">"Survived"</span>][train[<span class="string">"SibSp"</span>] == <span class="number">1</span>].value_counts(normalize = <span class="literal">True</span>)[<span class="number">1</span>]*<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Percentage of SibSp = 2 who survived:"</span>, train[<span class="string">"Survived"</span>][train[<span class="string">"SibSp"</span>] == <span class="number">2</span>].value_counts(normalize = <span class="literal">True</span>)[<span class="number">1</span>]*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Percentage of SibSp &#x3D; 0 who survived: 34.53947368421053</span><br><span class="line">Percentage of SibSp &#x3D; 1 who survived: 53.588516746411486</span><br><span class="line">Percentage of SibSp &#x3D; 2 who survived: 46.42857142857143</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/sibsp.png" alt></p>
<p>这里可以看出，有一个兄弟姐妹的一般有更高的生存率，所以快去鼓励爸爸妈妈生个弟弟妹妹吧~</p>
<blockquote>
<p>In general, it’s clear that people with more siblings or spouses aboard were less likely to survive. However, contrary to expectations, people with no siblings or spouses were less to likely to survive than those with one or two. (34.5% vs 53.4% vs. 46.4%)</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#draw a bar plot for Parch vs. survival</span></span><br><span class="line">sns.barplot(x=<span class="string">"Parch"</span>, y=<span class="string">"Survived"</span>, data=train)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/patch.png" alt></p>
<p>看起来独自旅游的人们生存率更低，想想眼眶竟湿润了</p>
<blockquote>
<p>People with less than four parents or children aboard are more likely to survive than those with four or more. Again, people traveling alone are less likely to survive than those with 1-3 parents or children.</p>
</blockquote>
<h3 id="年龄与生存率"><a href="#年龄与生存率" class="headerlink" title="年龄与生存率"></a>年龄与生存率</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#sort the ages into logical categories</span></span><br><span class="line">train[<span class="string">"Age"</span>] = train[<span class="string">"Age"</span>].fillna(<span class="number">-0.5</span>)</span><br><span class="line">test[<span class="string">"Age"</span>] = test[<span class="string">"Age"</span>].fillna(<span class="number">-0.5</span>)</span><br><span class="line">bins = [<span class="number">-1</span>, <span class="number">0</span>, <span class="number">5</span>, <span class="number">12</span>, <span class="number">18</span>, <span class="number">24</span>, <span class="number">35</span>, <span class="number">60</span>, np.inf]</span><br><span class="line">labels = [<span class="string">'Unknown'</span>, <span class="string">'Baby'</span>, <span class="string">'Child'</span>, <span class="string">'Teenager'</span>, <span class="string">'Student'</span>, <span class="string">'Young Adult'</span>, <span class="string">'Adult'</span>, <span class="string">'Senior'</span>]</span><br><span class="line">train[<span class="string">'AgeGroup'</span>] = pd.cut(train[<span class="string">"Age"</span>], bins, labels = labels)</span><br><span class="line">test[<span class="string">'AgeGroup'</span>] = pd.cut(test[<span class="string">"Age"</span>], bins, labels = labels)</span><br><span class="line"></span><br><span class="line"><span class="comment">#draw a bar plot of Age vs. survival</span></span><br><span class="line">sns.barplot(x=<span class="string">"AgeGroup"</span>, y=<span class="string">"Survived"</span>, data=train)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/age.png" alt></p>
<p>这张图表绘制用到了pandas的一个方法：cut（），可以用这个方法对数据进行切分，我们得到很显然的一个结论，婴儿的生存率神他妈高（我觉得很大一部分原因是不占空间）</p>
<h3 id="仓位特征是否存在与生存率"><a href="#仓位特征是否存在与生存率" class="headerlink" title="仓位特征是否存在与生存率"></a>仓位特征是否存在与生存率</h3><p>这是个奇怪的指标，据作者描述：</p>
<blockquote>
<p>I think the idea here is that people with recorded cabin numbers are of higher socioeconomic class, and thus more likely to survive. </p>
</blockquote>
<p>好吧我们看看：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">test[<span class="string">"CabinBool"</span>] = (test[<span class="string">"Cabin"</span>].notnull().astype(<span class="string">'int'</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#calculate percentages of CabinBool vs. survived</span></span><br><span class="line">print(<span class="string">"Percentage of CabinBool = 1 who survived:"</span>, train[<span class="string">"Survived"</span>][train[<span class="string">"CabinBool"</span>] == <span class="number">1</span>].value_counts(normalize = <span class="literal">True</span>)[<span class="number">1</span>]*<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Percentage of CabinBool = 0 who survived:"</span>, train[<span class="string">"Survived"</span>][train[<span class="string">"CabinBool"</span>] == <span class="number">0</span>].value_counts(normalize = <span class="literal">True</span>)[<span class="number">1</span>]*<span class="number">100</span>)</span><br><span class="line"><span class="comment">#draw a bar plot of CabinBool vs. survival</span></span><br><span class="line">sns.barplot(x=<span class="string">"CabinBool"</span>, y=<span class="string">"Survived"</span>, data=train)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Percentage of CabinBool &#x3D; 1 who survived: 66.66666666666666</span><br><span class="line">Percentage of CabinBool &#x3D; 0 who survived: 29.985443959243085</span><br></pre></td></tr></table></figure>
</blockquote>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/cabin_.png" alt></p>
<p>脑洞确实大，结果确实不赖~</p>
<h3 id="热力图"><a href="#热力图" class="headerlink" title="热力图"></a>热力图</h3><p>我们还可以给数据画上美丽的热力图，虽然没什么卵用：</p>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/sns.png" alt></p>
<h1 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h1><h2 id="拼接数据集"><a href="#拼接数据集" class="headerlink" title="拼接数据集"></a>拼接数据集</h2><p>首先我们讲训练集中的Survived特征提取出来，这是我们需要预测的目标函数，这部分也是train_data和test_data的不同点，接着我们可以讲训练集和测试集的数据拼接起来一起进行数据预处理，当然在实际中我们是无从得知测试数据的，但在比赛中为了方便我们可以统一进行处理：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y_train = train_data.pop(<span class="string">"Survived"</span>)</span><br><span class="line">data_all = pd.concat((train_data, test_data), axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h2 id="处理Name特征，提取出Title"><a href="#处理Name特征，提取出Title" class="headerlink" title="处理Name特征，提取出Title"></a>处理Name特征，提取出Title</h2><p>从左往右看我们首先可以看到Name这个特征是比较碍眼的，很多人可能直接把它去掉了，但仔细观察我们可以发现这一列特征里都含有名字的前缀，比如”Mr.”，”Mrs.“，”Miss”等，只要学过小学一年级英语的都知道这个特征在一定程度上会代表阶级地位，婚配情况等，我们可以将这个特征做一个映射，实现方式如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">title = pd.DataFrame()</span><br><span class="line">title[<span class="string">"Title"</span>] = data_all[<span class="string">"Name"</span>].map(<span class="keyword">lambda</span> name:name.split(<span class="string">","</span>)[<span class="number">1</span>].split(<span class="string">"."</span>)[<span class="number">0</span>].strip())</span><br><span class="line"><span class="comment"># title.head()</span></span><br><span class="line">Title_Dictionary = &#123;</span><br><span class="line">    <span class="string">"Capt"</span>:       <span class="string">"Officer"</span>,</span><br><span class="line">    <span class="string">"Col"</span>:        <span class="string">"Officer"</span>,</span><br><span class="line">    <span class="string">"Major"</span>:      <span class="string">"Officer"</span>,</span><br><span class="line">    <span class="string">"Jonkheer"</span>:   <span class="string">"Royalty"</span>,</span><br><span class="line">    <span class="string">"Don"</span>:        <span class="string">"Royalty"</span>,</span><br><span class="line">    <span class="string">"Sir"</span> :       <span class="string">"Royalty"</span>,</span><br><span class="line">    <span class="string">"Dr"</span>:         <span class="string">"Officer"</span>,</span><br><span class="line">    <span class="string">"Rev"</span>:        <span class="string">"Officer"</span>,</span><br><span class="line">    <span class="string">"the Countess"</span>:<span class="string">"Royalty"</span>,</span><br><span class="line">    <span class="string">"Dona"</span>:       <span class="string">"Royalty"</span>,</span><br><span class="line">    <span class="string">"Mme"</span>:        <span class="string">"Mrs"</span>,</span><br><span class="line">    <span class="string">"Mlle"</span>:       <span class="string">"Miss"</span>,</span><br><span class="line">    <span class="string">"Ms"</span>:         <span class="string">"Mrs"</span>,</span><br><span class="line">    <span class="string">"Mr"</span> :        <span class="string">"Mr"</span>,</span><br><span class="line">    <span class="string">"Mrs"</span> :       <span class="string">"Mrs"</span>,</span><br><span class="line">    <span class="string">"Miss"</span> :      <span class="string">"Miss"</span>,</span><br><span class="line">    <span class="string">"Master"</span> :    <span class="string">"Master"</span>,</span><br><span class="line">    <span class="string">"Lady"</span> :      <span class="string">"Royalty"</span></span><br><span class="line">&#125;</span><br><span class="line">title[ <span class="string">'Title'</span> ] = title.Title.map(Title_Dictionary)</span><br><span class="line">title = pd.get_dummies(title.Title)</span><br><span class="line"><span class="comment"># title.head()</span></span><br><span class="line">data_all = pd.concat((data_all, title), axis=<span class="number">1</span>)</span><br><span class="line">data_all.pop(<span class="string">"Name"</span>)</span><br><span class="line">data_all.head()</span><br></pre></td></tr></table></figure>
<p>上面这段是什么意思呢？我们可以将种类众多的头衔特征先进行归类，比如”Don”，”Sir”，”Jonkheer”这几个头衔出现的次数极低，大约每个出现次数只有不到十个，因此我们可以将意思相近的归为一类便于模型运行。然后我们用get_dummies将这些特征转为one-hot向量，得到的结果如下：</p>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/3.png" alt></p>
<h2 id="提取其他特征"><a href="#提取其他特征" class="headerlink" title="提取其他特征"></a>提取其他特征</h2><p>这个 Ticket特征比较麻烦懒得搞了，先把它删掉吧，然后Cabin特征应该是很有用的，你想想嘛我们在船的不同位置到安全通道的距离当然是会随着Cabin位置的不同而不同的，我们简单提取A、B、C、D这几个仓位来作为特征，而不考虑C85、C123中的数字（表示某个仓中的位置），当然由于有些船在A、B、C、D等仓位可能都有安全通道，我们可能提取后面的数字会更适合，为了方便我们先不做此讨论：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_all[<span class="string">"Cabin"</span>].fillna(<span class="string">"NA"</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">data_all[<span class="string">"Cabin"</span>] = data_all[<span class="string">"Cabin"</span>].map(<span class="keyword">lambda</span> s:s[<span class="number">0</span>])</span><br><span class="line">data_all.pop(<span class="string">"Ticket"</span>)</span><br></pre></td></tr></table></figure>
<p>前面也说了Pclass更适合作为One-hot型特征出现，我们先将之转换为字符型特征再进行归类，这里我们顺手把几个靠谱的类别标签做One-hot特征：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_all[<span class="string">"Pclass"</span>] = data_all[<span class="string">"Pclass"</span>].astype(str)</span><br><span class="line">feature_dummies = pd.get_dummies(data_all[[<span class="string">"Pclass"</span>, <span class="string">"Sex"</span>, <span class="string">"Embarked"</span>, <span class="string">"Cabin"</span>]])</span><br><span class="line"><span class="comment"># feature_dummies.head()</span></span><br><span class="line">data_all.drop([<span class="string">"Pclass"</span>, <span class="string">"Sex"</span>, <span class="string">"Embarked"</span>, <span class="string">"Cabin"</span>], inplace=<span class="literal">True</span>, axis=<span class="number">1</span>)</span><br><span class="line">data_all = pd.concat((data_all, feature_dummies), axis=<span class="number">1</span>)</span><br><span class="line">data_all.head()</span><br></pre></td></tr></table></figure>
<p>于是我们将特征集合由原来的11列扩充到了27列，噢糟糕我们前面忘了做缺失值填充，不要紧我们现在做也不晚：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mean_cols = data_all.mean()</span><br><span class="line">data_all = data_all.fillna(mean_cols)</span><br></pre></td></tr></table></figure>
<p>这里是使用了平均值对Age和Embarked两个特征进行填充，由于Age刚好是数值型特征，这种填充方式是合理的，且Embarked只有两个缺失值，因此随便填充啦~不碍事的。</p>
<h2 id="将训练集测试集重新分开"><a href="#将训练集测试集重新分开" class="headerlink" title="将训练集测试集重新分开"></a>将训练集测试集重新分开</h2><p>在模型搭建之前不要忘了之前我们拼在一起的训练集和测试集噢，还记得最开始读取数据的时候加入的index_col嘛，这里刚好派上用场啦：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_df = data_all.loc[train_data.index]</span><br><span class="line">test_df = data_all.loc[test_data.index]</span><br><span class="line">print(train_df.shape, test_df.shape)</span><br></pre></td></tr></table></figure>
<p>打印结果是(891, 27) (418, 27)，符合原训练集测试集的大小，我们的粗略数据预处理就到此为止了，下面进行模型搭建~</p>
<h1 id="模型搭建"><a href="#模型搭建" class="headerlink" title="模型搭建"></a>模型搭建</h1><h2 id="Random-Forest"><a href="#Random-Forest" class="headerlink" title="Random Forest"></a>Random Forest</h2><p>首先导入sklearn的包</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br></pre></td></tr></table></figure>
<p>然后设置不同的树最大深度进行参数调优：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line">depth_ = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]</span><br><span class="line">scores = []</span><br><span class="line"><span class="keyword">for</span> depth <span class="keyword">in</span> depth_:</span><br><span class="line">    clf = RandomForestClassifier(n_estimators=<span class="number">100</span>, max_depth=depth, random_state=<span class="number">0</span>)</span><br><span class="line">    test_score = cross_val_score(clf, train_df, y_train, cv=<span class="number">10</span>, scoring=<span class="string">"precision"</span>)</span><br><span class="line">    scores.append(np.mean(test_score))</span><br><span class="line">plt.plot(depth_, scores)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/4.png" alt></p>
<p>得到了这样一张图，这张图大致反映了模型中树的最大深度以6为最佳，此时可以达到0.84左右的验证准确率，我们当然可以继续调整其他参数获得更优的结果，但接下来我们先继续讨论其他模型。</p>
<h2 id="Gradient-Boosting-Classifier"><a href="#Gradient-Boosting-Classifier" class="headerlink" title="Gradient Boosting Classifier"></a>Gradient Boosting Classifier</h2><p>代码和上面差不多：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line">depth_ = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]</span><br><span class="line">scores = []</span><br><span class="line"><span class="keyword">for</span> depth <span class="keyword">in</span> depth_:</span><br><span class="line">    clf = GradientBoostingClassifier(n_estimators=<span class="number">100</span>, max_depth=depth, random_state=<span class="number">0</span>)</span><br><span class="line">    test_score = cross_val_score(clf, train_df, y_train, cv=<span class="number">10</span>, scoring=<span class="string">"precision"</span>)</span><br><span class="line">    scores.append(np.mean(test_score))</span><br><span class="line">plt.plot(depth_, scores)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/gb.png" alt></p>
<p>成功率最高似乎接近0.82</p>
<h2 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h2><p>Bagging把很多小分类器放在一起，每个train随机的一部分数据，然后把它们的最终结果综合起来（多数投票制）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> BaggingClassifier</span><br><span class="line">params = [<span class="number">1</span>, <span class="number">10</span>, <span class="number">15</span>, <span class="number">20</span>, <span class="number">25</span>, <span class="number">30</span>, <span class="number">40</span>]</span><br><span class="line">test_scores = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">    clf = BaggingClassifier(n_estimators=param)</span><br><span class="line">    test_score = cross_val_score(clf, train_df, y_train, cv=<span class="number">10</span>, scoring=<span class="string">"precision"</span>)</span><br><span class="line">    test_scores.append(np.mean(test_score))</span><br><span class="line">plt.plot(params, test_scores)</span><br></pre></td></tr></table></figure>
<p>结果又不稳定又不好：</p>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/bagging.png" alt></p>
<h2 id="RidgeClassifier"><a href="#RidgeClassifier" class="headerlink" title="RidgeClassifier"></a>RidgeClassifier</h2><p>下面就不说废话了，一个个试就对了：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> RidgeClassifier</span><br><span class="line">alphas = np.logspace(<span class="number">-3</span>, <span class="number">2</span>, <span class="number">50</span>)</span><br><span class="line">test_scores = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> alpha <span class="keyword">in</span> alphas:</span><br><span class="line">    clf = RidgeClassifier(alpha)</span><br><span class="line">    test_score = cross_val_score(clf, train_df, y_train, cv=<span class="number">10</span>, scoring=<span class="string">"precision"</span>)</span><br><span class="line">    test_scores.append(np.mean(test_score))</span><br><span class="line">plt.plot(alphas, test_scores)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/ridge.png" alt></p>
<h2 id="RidgeClassifier-Bagging"><a href="#RidgeClassifier-Bagging" class="headerlink" title="RidgeClassifier + Bagging"></a>RidgeClassifier + Bagging</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ridge = RidgeClassifier(alpha=<span class="number">5</span>)</span><br><span class="line">params = [<span class="number">1</span>, <span class="number">10</span>, <span class="number">15</span>, <span class="number">20</span>, <span class="number">25</span>, <span class="number">30</span>, <span class="number">40</span>]</span><br><span class="line">test_scores = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">    clf = BaggingClassifier(n_estimators=param, base_estimator=ridge)</span><br><span class="line">    test_score = cross_val_score(clf, train_df, y_train, cv=<span class="number">10</span>, scoring=<span class="string">"precision"</span>)</span><br><span class="line">    test_scores.append(np.mean(test_score))</span><br><span class="line">plt.plot(params, test_scores)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/ridge+bagging.png" alt></p>
<p>结果比使用默认模型的Bagging策略稍好一些。</p>
<h2 id="XGBClassifier"><a href="#XGBClassifier" class="headerlink" title="XGBClassifier"></a>XGBClassifier</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line">params = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">test_scores = []</span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">    clf = XGBClassifier(max_depth=param)</span><br><span class="line">    test_score = cross_val_score(clf, train_df, y_train, cv=<span class="number">10</span>, scoring=<span class="string">"precision"</span>)</span><br><span class="line">    test_scores.append(np.mean(test_score))</span><br><span class="line">plt.plot(params, test_scores)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/xgb.png" alt></p>
<h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><p>首先我们基于Keras搭建了一个简单的神经网络架构：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">tf.keras.optimizers.Adam(</span><br><span class="line">    learning_rate=<span class="number">0.003</span>, beta_1=<span class="number">0.9</span>, beta_2=<span class="number">0.999</span>, epsilon=<span class="number">1e-07</span>, amsgrad=<span class="literal">False</span>,</span><br><span class="line">    name=<span class="string">'Adam'</span>, </span><br><span class="line">)</span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">32</span>, input_dim=train_df.shape[<span class="number">1</span>],kernel_initializer = <span class="string">'uniform'</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(Dense(<span class="number">32</span>, kernel_initializer = <span class="string">'uniform'</span>, activation = <span class="string">'relu'</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.4</span>))</span><br><span class="line">model.add(Dense(<span class="number">32</span>,kernel_initializer = <span class="string">'uniform'</span>, activation = <span class="string">'relu'</span>))</span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line">    </span><br><span class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure>
<p>然后将模型放入train_df进行训练得到结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">history = model.fit(np.array(train_df), np.array(y_train), epochs=<span class="number">20</span>, batch_size=<span class="number">50</span>, validation_split = <span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>
<p>最后一轮的结果为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Epoch 20&#x2F;20</span><br><span class="line">712&#x2F;712 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 43us&#x2F;step - loss: 0.4831 - accuracy: 0.7978 - val_loss: 0.3633 - val_accuracy: 0.8715</span><br></pre></td></tr></table></figure>
<p>可以看到实验结果还是不错的，我们看一看模型的架构：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Model: &quot;sequential_1&quot;</span><br><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">dense_1 (Dense)              (None, 32)                896       </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_2 (Dense)              (None, 32)                1056      </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dropout_1 (Dropout)          (None, 32)                0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_3 (Dense)              (None, 32)                1056      </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_4 (Dense)              (None, 1)                 33        </span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">Total params: 3,041</span><br><span class="line">Trainable params: 3,041</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">_________________________________________________________________</span><br></pre></td></tr></table></figure>
<p>测试模型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scores = model.evaluate(train_df, y_train, batch_size=<span class="number">32</span>)</span><br><span class="line">print(scores)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">891&#x2F;891 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 18us&#x2F;step</span><br><span class="line">[0.4208374666645872, 0.8316498398780823]</span><br></pre></td></tr></table></figure>
<p>可以看到效果和随机森林的最佳效果差不多。</p>
<h1 id="模型优化"><a href="#模型优化" class="headerlink" title="模型优化"></a>模型优化</h1><p>后续我们可以通过对这些表现比较好的模型再进行第二层的学习获得更好的分数。</p>
<p>首先我们将之前获得的几个比较好的结果一一定好参数放上来（这里只随便调了一个参数）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> RidgeClassifier</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"></span><br><span class="line">classifier_num = <span class="number">5</span></span><br><span class="line">clf = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(classifier_num)]</span><br><span class="line">clf[<span class="number">0</span>] = RandomForestClassifier(n_estimators=<span class="number">100</span>, max_depth=<span class="number">6</span>, random_state=<span class="number">0</span>)</span><br><span class="line">clf[<span class="number">1</span>] = GradientBoostingClassifier(n_estimators=<span class="number">100</span>, max_depth=<span class="number">4</span>, random_state=<span class="number">0</span>)</span><br><span class="line">clf[<span class="number">2</span>] = RidgeClassifier(<span class="number">5</span>)</span><br><span class="line">clf[<span class="number">3</span>] = BaggingClassifier(n_estimators=<span class="number">15</span>, base_estimator=clf[<span class="number">2</span>])</span><br><span class="line">clf[<span class="number">4</span>] = XGBClassifier(max_depth=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, Y_train, Y_test = train_test_split(train_df, y_train, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">predictFrame = pd.DataFrame()</span><br><span class="line"><span class="keyword">for</span> model <span class="keyword">in</span> clf:</span><br><span class="line">    model.fit(X_train, Y_train)</span><br><span class="line">    predictFrame[str(model)[:<span class="number">13</span>]] = model.predict(X_test)</span><br><span class="line">predictFrame.head()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/model_merge.png" alt></p>
<p>名字随意啦反正只要不重复就好了~然后将这个结果放入下一个分类器中学习，我没有试其他的就直接放进了随机森林分类器：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line">depth_ = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]</span><br><span class="line">scores = []</span><br><span class="line"><span class="keyword">for</span> depth <span class="keyword">in</span> depth_:</span><br><span class="line">    clf_ = RandomForestClassifier(n_estimators=<span class="number">100</span>, max_depth=depth, random_state=<span class="number">0</span>)</span><br><span class="line">    test_score = cross_val_score(clf_, predictFrame, Y_test, cv=<span class="number">10</span>, scoring=<span class="string">"precision"</span>)</span><br><span class="line">    scores.append(np.mean(test_score))</span><br><span class="line">plt.plot(depth_, scores)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E7%94%9F%E5%AD%98%E7%8E%87%E9%A2%84%E6%B5%8B/model_2.png" alt></p>
<p>好吧就定个参数为2，然后就将整体跑个结果试试：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">finalFrame = pd.DataFrame()</span><br><span class="line">XFrame = pd.DataFrame()</span><br><span class="line"><span class="keyword">for</span> model <span class="keyword">in</span> clf:</span><br><span class="line">    model.fit(train_df, y_train)</span><br><span class="line">    XFrame[str(model)[:<span class="number">13</span>]] = model.predict(train_df)</span><br><span class="line">    finalFrame[str(model)[:<span class="number">13</span>]] = model.predict(test_df)</span><br><span class="line">final_clf = RandomForestClassifier(n_estimators=<span class="number">100</span>, max_depth=<span class="number">2</span>, random_state=<span class="number">0</span>)</span><br><span class="line">final_clf.fit(XFrame, y_train)</span><br><span class="line">result = final_clf.predict(finalFrame)</span><br></pre></td></tr></table></figure>
<p>将result和passengerId一起拼接成一个Dataframe就直接输出看结果吧，比之前没有融合直接用随机森林结果稍好一些，但还是一样菜，毕竟只是用了几个简单的机器学习算法搞来搞去也没有认真调参，这个比赛就先这样收尾啦~</p>
]]></content>
      <categories>
        <category>Match</category>
      </categories>
  </entry>
  <entry>
    <title>时间序列实战（一）</title>
    <url>/posts/d85e03b4.html</url>
    <content><![CDATA[<h1 id="Pandas-生成时间序列"><a href="#Pandas-生成时间序列" class="headerlink" title="Pandas 生成时间序列"></a>Pandas 生成时间序列</h1><p>常见时间序列分类：</p>
<ul>
<li>时间戳（timestamp）：具体到时间的某一个点，具体到秒</li>
<li>固定周期（period）</li>
<li>时间间隔（internal）</li>
</ul>
<h2 id="data-range"><a href="#data-range" class="headerlink" title="data_range"></a>data_range</h2><ul>
<li>可以指定开始时间与周期<ul>
<li>H：小时</li>
<li>D：天</li>
<li>M：月</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rng = pd.date_range(<span class="string">"2016/07/01"</span>, periods=<span class="number">10</span>, freq=<span class="string">"D"</span>)</span><br><span class="line"><span class="comment"># 输出结果为：</span></span><br><span class="line">DatetimeIndex([<span class="string">'2016-07-01'</span>, <span class="string">'2016-07-02'</span>, <span class="string">'2016-07-03'</span>, <span class="string">'2016-07-04'</span>,</span><br><span class="line">               <span class="string">'2016-07-05'</span>, <span class="string">'2016-07-06'</span>, <span class="string">'2016-07-07'</span>, <span class="string">'2016-07-08'</span>,</span><br><span class="line">               <span class="string">'2016-07-09'</span>, <span class="string">'2016-07-10'</span>],</span><br><span class="line">              dtype=<span class="string">'datetime64[ns]'</span>, freq=<span class="string">'D'</span>)</span><br></pre></td></tr></table></figure>
<p>若我们将<code>freq</code>指定为<code>M</code>，输出结果为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">DatetimeIndex([<span class="string">'2016-07-31'</span>, <span class="string">'2016-08-31'</span>, <span class="string">'2016-09-30'</span>, <span class="string">'2016-10-31'</span>,</span><br><span class="line">               <span class="string">'2016-11-30'</span>, <span class="string">'2016-12-31'</span>, <span class="string">'2017-01-31'</span>, <span class="string">'2017-02-28'</span>,</span><br><span class="line">               <span class="string">'2017-03-31'</span>, <span class="string">'2017-04-30'</span>],</span><br><span class="line">              dtype=<span class="string">'datetime64[ns]'</span>, freq=<span class="string">'M'</span>)</span><br></pre></td></tr></table></figure>
<p>将<code>freq</code>指定为<code>H</code>，则输出结果为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">DatetimeIndex([<span class="string">'2016-07-01 00:00:00'</span>, <span class="string">'2016-07-01 01:00:00'</span>,</span><br><span class="line">               <span class="string">'2016-07-01 02:00:00'</span>, <span class="string">'2016-07-01 03:00:00'</span>,</span><br><span class="line">               <span class="string">'2016-07-01 04:00:00'</span>, <span class="string">'2016-07-01 05:00:00'</span>,</span><br><span class="line">               <span class="string">'2016-07-01 06:00:00'</span>, <span class="string">'2016-07-01 07:00:00'</span>,</span><br><span class="line">               <span class="string">'2016-07-01 08:00:00'</span>, <span class="string">'2016-07-01 09:00:00'</span>],</span><br><span class="line">              dtype=<span class="string">'datetime64[ns]'</span>, freq=<span class="string">'H'</span>)</span><br></pre></td></tr></table></figure>
<p>同时我们还可以给<code>freq</code>的单位加上倍数，比如我们想以3天为周期，可以将参数改为：<code>freq=&#39;3D&#39;</code>，输出结果为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">DatetimeIndex([<span class="string">'2016-07-01'</span>, <span class="string">'2016-07-04'</span>, <span class="string">'2016-07-07'</span>, <span class="string">'2016-07-10'</span>,</span><br><span class="line">               <span class="string">'2016-07-13'</span>, <span class="string">'2016-07-16'</span>, <span class="string">'2016-07-19'</span>, <span class="string">'2016-07-22'</span>,</span><br><span class="line">               <span class="string">'2016-07-25'</span>, <span class="string">'2016-07-28'</span>],</span><br><span class="line">              dtype=<span class="string">'datetime64[ns]'</span>, freq=<span class="string">'3D'</span>)</span><br></pre></td></tr></table></figure>
<p>我们读取时间的方式还不限于斜杆划分年月日，也可以使用英文缩写：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rng = pd.date_range(<span class="string">"2016 Jul 1"</span>, periods=<span class="number">10</span>, freq=<span class="string">"4H"</span>)</span><br><span class="line"><span class="comment"># 输出结果为</span></span><br><span class="line">DatetimeIndex([<span class="string">'2016-07-01 00:00:00'</span>, <span class="string">'2016-07-01 04:00:00'</span>,</span><br><span class="line">               <span class="string">'2016-07-01 08:00:00'</span>, <span class="string">'2016-07-01 12:00:00'</span>,</span><br><span class="line">               <span class="string">'2016-07-01 16:00:00'</span>, <span class="string">'2016-07-01 20:00:00'</span>,</span><br><span class="line">               <span class="string">'2016-07-02 00:00:00'</span>, <span class="string">'2016-07-02 04:00:00'</span>,</span><br><span class="line">               <span class="string">'2016-07-02 08:00:00'</span>, <span class="string">'2016-07-02 12:00:00'</span>],</span><br><span class="line">              dtype=<span class="string">'datetime64[ns]'</span>, freq=<span class="string">'4H'</span>)</span><br></pre></td></tr></table></figure>
<p>也可以使用日/月/年的方式：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rng = pd.date_range(<span class="string">"7/1/2016"</span>, periods=<span class="number">10</span>, freq=<span class="string">"4H"</span>)</span><br></pre></td></tr></table></figure>
<p>输出结果和上面一样。</p>
<p>我们可以使用<code>date_range</code>造一个时间序列：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">time = pd.Series(np.random.randn(<span class="number">10</span>), index=pd.date_range(datetime(<span class="number">2019</span>, <span class="number">1</span>, <span class="number">1</span>), periods=<span class="number">20</span>))</span><br><span class="line">print(time)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2019-01-01   -0.832742</span><br><span class="line">2019-01-02   -0.407045</span><br><span class="line">2019-01-03   -0.242624</span><br><span class="line">2019-01-04   -0.842008</span><br><span class="line">2019-01-05    0.561354</span><br><span class="line">2019-01-06   -1.961245</span><br><span class="line">2019-01-07   -0.684918</span><br><span class="line">2019-01-08    0.262698</span><br><span class="line">2019-01-09    1.728109</span><br><span class="line">2019-01-10    1.227469</span><br><span class="line">Freq: D, dtype: float64</span><br></pre></td></tr></table></figure>
<p>指定<code>index</code>之后我们可以通过索引或切片拿出数据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(time[<span class="string">"2019-01-04"</span>])</span><br><span class="line"><span class="comment"># -0.842008</span></span><br><span class="line">print(time[<span class="string">"2019-01-03"</span>:<span class="string">"2019-01-08"</span>])</span><br><span class="line"><span class="comment"># 2019-01-03   -0.242624</span></span><br><span class="line"><span class="comment"># 2019-01-04   -0.842008</span></span><br><span class="line"><span class="comment"># 2019-01-05    0.561354</span></span><br><span class="line"><span class="comment"># 2019-01-06   -1.961245</span></span><br><span class="line"><span class="comment"># 2019-01-07   -0.684918</span></span><br><span class="line"><span class="comment"># 2019-01-08    0.262698</span></span><br><span class="line"><span class="comment"># Freq: D, dtype: float64</span></span><br></pre></td></tr></table></figure>
<p>当我们不想指定时间的间隔时，我们可以指定起始时间与终止时间，指定频率就可生成时间序列：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = pd.date_range(<span class="string">"2010-01-01"</span>, <span class="string">"2012-01-01"</span>, freq=<span class="string">"4M"</span>)</span><br><span class="line">print(data)</span><br><span class="line"><span class="comment"># DatetimeIndex(['2010-01-31', '2010-05-31', '2010-09-30', '2011-01-31',</span></span><br><span class="line"><span class="comment">#                '2011-05-31', '2011-09-30'],</span></span><br><span class="line"><span class="comment">#               dtype='datetime64[ns]', freq='4M')</span></span><br></pre></td></tr></table></figure>
<h2 id="truncate"><a href="#truncate" class="headerlink" title="truncate"></a>truncate</h2><p>Truncate的意思是过滤，我们使用原来的time数据看下面的例子</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">time.truncate(before=<span class="string">"2019-01-06"</span>)</span><br><span class="line"><span class="comment"># 2019-01-06   -1.961245</span></span><br><span class="line"><span class="comment"># 2019-01-07   -0.684918</span></span><br><span class="line"><span class="comment"># 2019-01-08    0.262698</span></span><br><span class="line"><span class="comment"># 2019-01-09    1.728109</span></span><br><span class="line"><span class="comment"># 2019-01-10    1.227469</span></span><br></pre></td></tr></table></figure>
<p>这里过滤的意思是将2019-01-06之前的数据全都不要，我们亦可以将<code>before</code>替换成<code>after</code>，含义也就正好反过来了。</p>
<h2 id="Timestamp"><a href="#Timestamp" class="headerlink" title="Timestamp"></a>Timestamp</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.Timestamp(<span class="string">"2020-02-28"</span>)</span><br><span class="line"><span class="comment"># Timestamp('2020-02-28 00:00:00')</span></span><br></pre></td></tr></table></figure>
<p>我们可以只指定天，这时时间戳会将几点几分几秒 全部指定为0，我们也可以对更具体的时间做指派：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.Timestamp(<span class="string">"2020-02-28 10"</span>)</span><br><span class="line"><span class="comment"># Timestamp('2020-02-28 10:00:00')</span></span><br><span class="line">pd.Timestamp(<span class="string">"2020-02-28 10:15:20"</span>)</span><br><span class="line"><span class="comment"># Timestamp('2020-02-28 10:15:20')</span></span><br></pre></td></tr></table></figure>
<p>你可以试试指定时间戳为<code>10:00:70</code>，看看会发生啥~</p>
<h2 id="Timedelta"><a href="#Timedelta" class="headerlink" title="Timedelta"></a>Timedelta</h2><p>Timedelta指的是偏移量：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.Timedelta(<span class="string">"1 day"</span>)</span><br><span class="line"><span class="comment"># Timedelta('1 days 00:00:00')</span></span><br><span class="line">pd.Timestamp(<span class="string">"2020-02-28 10:15:20"</span>) + pd.Timedelta(<span class="string">'15 ns'</span>)</span><br><span class="line"><span class="comment"># Timestamp('2020-02-28 10:15:20.000000015')</span></span><br></pre></td></tr></table></figure>
<h1 id="Pandas-数据重采样"><a href="#Pandas-数据重采样" class="headerlink" title="Pandas 数据重采样"></a>Pandas 数据重采样</h1><p>数据重采样的意思是将时间数据从一个频率转换到另一个频率，其中分为升采样与降采样，其中降采样比如将每天的数据转换成以月为单位的数据，将原来一年的365个时间点降采样至12个时间点，而升采样则反过来，希望由原来的12个时间点拓展至更多时间点。我们先构造一个随机生成的数据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rng = pd.date_range(<span class="string">"1/1/2020"</span>, periods=<span class="number">90</span>, freq=<span class="string">"D"</span>)</span><br><span class="line">ts = pd.Series(np.random.randn(len(rng)), index=rng)</span><br><span class="line">ts.head()</span><br></pre></td></tr></table></figure>
<p>显示前五行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2020-01-01    0.181924</span><br><span class="line">2020-01-02   -1.549470</span><br><span class="line">2020-01-03   -0.362104</span><br><span class="line">2020-01-04   -1.019910</span><br><span class="line">2020-01-05   -0.043036</span><br><span class="line">Freq: D, dtype: float64</span><br></pre></td></tr></table></figure>
<h2 id="降采样"><a href="#降采样" class="headerlink" title="降采样"></a>降采样</h2><p>这里的数据是以天为单位的，我们可以调用<code>resample</code>函数将其转换成以月为单位：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ts.resample(<span class="string">"M"</span>).sum()</span><br></pre></td></tr></table></figure>
<p>显示结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2020-01-31   -5.531674</span><br><span class="line">2020-02-29   -5.243299</span><br><span class="line">2020-03-31   -6.235872</span><br><span class="line">Freq: M, dtype: float64</span><br></pre></td></tr></table></figure>
<p>后面接的<code>sum()</code>指我们希望以什么指标去观察生成的数据，也可以是<code>mean()</code>或者其他指标</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ts.resample(<span class="string">"3D"</span>).mean()</span><br></pre></td></tr></table></figure>
<p>显示结果为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2020-01-01   -0.576550</span><br><span class="line">2020-01-04   -0.785354</span><br><span class="line">2020-01-07   -0.479583</span><br><span class="line">2020-01-10    0.251568</span><br><span class="line">2020-01-13    1.348719</span><br><span class="line">Freq: 3D, dtype: float64</span><br></pre></td></tr></table></figure>
<h2 id="升采样"><a href="#升采样" class="headerlink" title="升采样"></a>升采样</h2><p>升采样我们很容易可以想到没有获得的数据我们应该以什么方式生成呢？事实上我们可以使用插值法，我们先使用前面获得的降采样数据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">day3Ts = ts.resample(<span class="string">"3D"</span>).mean()</span><br><span class="line">day3Ts</span><br></pre></td></tr></table></figure>
<p>前几行为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2020-01-01   -0.576550</span><br><span class="line">2020-01-04   -0.785354</span><br><span class="line">2020-01-07   -0.479583</span><br><span class="line">2020-01-10    0.251568</span><br><span class="line">2020-01-13    1.348719</span><br><span class="line">2020-01-16   -0.389584</span><br><span class="line">2020-01-19   -0.200646</span><br><span class="line">2020-01-22   -0.065141</span><br><span class="line">2020-01-25   -0.357723</span><br><span class="line">2020-01-28   -0.665015</span><br><span class="line">2020-01-31   -1.023145</span><br><span class="line">2020-02-03   -0.448191</span><br></pre></td></tr></table></figure>
<p>我们可以直接将其转换为以天为单位的数据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(day3Ts.resample(<span class="string">"D"</span>).asfreq())</span><br></pre></td></tr></table></figure>
<p>显示结果为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2020-01-01   -0.576550</span><br><span class="line">2020-01-02         NaN</span><br><span class="line">2020-01-03         NaN</span><br><span class="line">2020-01-04   -0.785354</span><br><span class="line">2020-01-05         NaN</span><br><span class="line">                ...   </span><br><span class="line">2020-03-24         NaN</span><br><span class="line">2020-03-25    0.215335</span><br><span class="line">2020-03-26         NaN</span><br><span class="line">2020-03-27         NaN</span><br><span class="line">2020-03-28    0.314862</span><br><span class="line">Freq: D, Length: 88, dtype: float64</span><br></pre></td></tr></table></figure>
<p>当我们什么都不指定时未生成的数据均会显示为NaN，我们可以使用以下三种插值方法：</p>
<ul>
<li>ffill：空值取前面的值</li>
<li>bfill：空值取后面的值</li>
<li>interpolate：线性取值</li>
</ul>
<p>我们可以都试一下看看结果：</p>
<p><strong>1. ffill()</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(day3Ts.resample(<span class="string">"D"</span>).ffill(<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2020-01-01   -0.576550</span><br><span class="line">2020-01-02   -0.576550</span><br><span class="line">2020-01-03         NaN</span><br><span class="line">2020-01-04   -0.785354</span><br><span class="line">2020-01-05   -0.785354</span><br><span class="line">                ...   </span><br><span class="line">2020-03-24         NaN</span><br><span class="line">2020-03-25    0.215335</span><br><span class="line">2020-03-26    0.215335</span><br><span class="line">2020-03-27         NaN</span><br><span class="line">2020-03-28    0.314862</span><br><span class="line">Freq: D, Length: 88, dtype: float64</span><br></pre></td></tr></table></figure>
<p>我们<code>ffill()</code>函数中的参数这里指定为了1，意思就是只填充一个，我们指定为2时在这里就相当于把缺值都填充上去了，大家可以自行尝试。</p>
<p><strong>2. bfill()</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(day3Ts.resample(<span class="string">"D"</span>).bfill(<span class="number">2</span>))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2020-01-01   -0.576550</span><br><span class="line">2020-01-02   -0.785354</span><br><span class="line">2020-01-03   -0.785354</span><br><span class="line">2020-01-04   -0.785354</span><br><span class="line">2020-01-05   -0.479583</span><br><span class="line">                ...   </span><br><span class="line">2020-03-24    0.215335</span><br><span class="line">2020-03-25    0.215335</span><br><span class="line">2020-03-26    0.314862</span><br><span class="line">2020-03-27    0.314862</span><br><span class="line">2020-03-28    0.314862</span><br><span class="line">Freq: D, Length: 88, dtype: float64</span><br></pre></td></tr></table></figure>
<p><strong>3. Interpolate()</strong></p>
<p>更科学的方式往往是采用拟合，拟合时可以指定拟合曲线的形状，比如我们指定为线性：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(day3Ts.resample(<span class="string">"D"</span>).interpolate(<span class="string">"linear"</span>))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2020-01-01   -0.576550</span><br><span class="line">2020-01-02   -0.646151</span><br><span class="line">2020-01-03   -0.715753</span><br><span class="line">2020-01-04   -0.785354</span><br><span class="line">2020-01-05   -0.683430</span><br><span class="line">                ...   </span><br><span class="line">2020-03-24    0.032005</span><br><span class="line">2020-03-25    0.215335</span><br><span class="line">2020-03-26    0.248511</span><br><span class="line">2020-03-27    0.281687</span><br><span class="line">2020-03-28    0.314862</span><br><span class="line">Freq: D, Length: 88, dtype: float64</span><br></pre></td></tr></table></figure>
<p>结果比之前好看多了~我们也可以 根据时间序列的信息改变拟合的参数，大家可以自行尝试</p>
<h1 id="Pandas-滑动窗口"><a href="#Pandas-滑动窗口" class="headerlink" title="Pandas 滑动窗口"></a>Pandas 滑动窗口</h1><p>当我们有一个时间序列数据，比如2019-2020年的数据时，我们希望得知其中某一天（比如2019-03-25）的数据情况时，我们当然可以直接取出这一天的数据作为结果，但更合理的方式是通过一个滑动窗口来作为这一天的数据特征，比如我们取2019-03-21至2019-03-30的数据取平均来代表中间这一天（2019-03-25）的情况，这样做可以使得我们获得的值更平稳。</p>
<p>我们可以直接调用pandas的函数得到滑动窗口，我们先生成一系列数据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = pd.Series(np.random.randn(<span class="number">600</span>), index=pd.date_range(<span class="string">"7/1/2016"</span>, freq=<span class="string">"D"</span>, periods=<span class="number">600</span>))</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>
<p>生成的数据前5行如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2016-07-01    0.234309</span><br><span class="line">2016-07-02    0.969461</span><br><span class="line">2016-07-03   -1.291212</span><br><span class="line">2016-07-04    0.957054</span><br><span class="line">2016-07-05    0.571843</span><br><span class="line">Freq: D, dtype: float64</span><br></pre></td></tr></table></figure>
<p>我们直接调用<code>rolling</code>函数并指定<code>window</code>窗口数就可以得到一个滑动窗口</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">r = df.rolling(window=<span class="number">10</span>)</span><br><span class="line">r</span><br><span class="line"><span class="comment"># Rolling [window=10,center=False,axis=0]</span></span><br><span class="line">print(r.mean())</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2016-07-01         NaN</span><br><span class="line">2016-07-02         NaN</span><br><span class="line">2016-07-03         NaN</span><br><span class="line">2016-07-04         NaN</span><br><span class="line">2016-07-05         NaN</span><br><span class="line">                ...   </span><br><span class="line">2018-02-16   -0.209858</span><br><span class="line">2018-02-17   -0.267041</span><br><span class="line">2018-02-18   -0.120890</span><br><span class="line">2018-02-19    0.030302</span><br><span class="line">2018-02-20    0.079551</span><br><span class="line">Freq: D, Length: 600, dtype: float64</span><br></pre></td></tr></table></figure>
<p>我们可以看到前9个数据都是没有滑动窗口的，因此显示结果为NaN，现在我们把这个滑动窗口的值<code>plot</code>一下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>, <span class="number">5</span>))</span><br><span class="line">df.plot(style=<span class="string">"r--"</span>)</span><br><span class="line">df.rolling(window=<span class="number">10</span>).mean().plot(style=<span class="string">"b"</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/rolling.png" alt></p>
<p>基于这个滑动窗口我们就可以统计出很多指标了~</p>
]]></content>
      <categories>
        <category>TimeSeries</category>
      </categories>
  </entry>
  <entry>
    <title>Keras深度学习(二）深度学习用于计算机视觉</title>
    <url>/posts/c8c4a7ed.html</url>
    <content><![CDATA[<h1 id="mnist-数据集"><a href="#mnist-数据集" class="headerlink" title="mnist 数据集"></a>mnist 数据集</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br></pre></td></tr></table></figure>
<pre><code>Using TensorFlow backend.
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">"relu"</span>, input_shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">"relu"</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">"relu"</span>))</span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">"relu"</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>, activation=<span class="string">"softmax"</span>))</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_4&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_8 (Conv2D)            (None, 26, 26, 32)        320       
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 13, 13, 32)        0         
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 11, 11, 64)        18496     
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 5, 5, 64)          0         
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 3, 3, 64)          36928     
_________________________________________________________________
flatten_1 (Flatten)          (None, 576)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 64)                36928     
_________________________________________________________________
dense_2 (Dense)              (None, 10)                650       
=================================================================
Total params: 93,322
Trainable params: 93,322
Non-trainable params: 0
_________________________________________________________________
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> to_categorical</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">(train_data, train_labels), (test_data, test_labels) = mnist.load_data()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_data = train_data.reshape((<span class="number">60000</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))</span><br><span class="line">train_data = train_data.astype(<span class="string">"float32"</span>) / <span class="number">255</span></span><br><span class="line"></span><br><span class="line">test_data = test_data.reshape((<span class="number">10000</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))</span><br><span class="line">test_data = test_data.astype(<span class="string">"float32"</span>) / <span class="number">255</span></span><br><span class="line"></span><br><span class="line">train_labels = to_categorical(train_labels)</span><br><span class="line">test_labels = to_categorical(test_labels)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.compile(optimizer=<span class="string">"rmsprop"</span>,</span><br><span class="line">             loss=<span class="string">"categorical_crossentropy"</span>,</span><br><span class="line">             metrics=[<span class="string">"accuracy"</span>])</span><br><span class="line"></span><br><span class="line">model.fit(train_data, train_labels, epochs=<span class="number">5</span>, batch_size=<span class="number">64</span>)</span><br></pre></td></tr></table></figure>
<pre><code>WARNING:tensorflow:From C:\Users\16402\Anaconda3\envs\python36\lib\site-packages\keras\backend\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

Epoch 1/5
60000/60000 [==============================] - 23s 385us/step - loss: 0.1701 - accuracy: 0.9471
Epoch 2/5
60000/60000 [==============================] - 22s 366us/step - loss: 0.0471 - accuracy: 0.9857
Epoch 3/5
60000/60000 [==============================] - 22s 372us/step - loss: 0.0325 - accuracy: 0.9895
Epoch 4/5
60000/60000 [==============================] - 23s 391us/step - loss: 0.0249 - accuracy: 0.9924
Epoch 5/5
60000/60000 [==============================] - 23s 383us/step - loss: 0.0199 - accuracy: 0.9941





&lt;keras.callbacks.callbacks.History at 0x186eaf2d898&gt;
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">test_loss, test_acc = model.evaluate(test_data, test_labels)</span><br><span class="line">print(test_loss, test_acc)</span><br></pre></td></tr></table></figure>
<pre><code>10000/10000 [==============================] - 1s 99us/step
0.027024587894159596 0.991599977016449
</code></pre><h1 id="猫狗分类数据集"><a href="#猫狗分类数据集" class="headerlink" title="猫狗分类数据集"></a>猫狗分类数据集</h1><h2 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os, shutil</span><br><span class="line">original_dataset_dir = <span class="string">'data/cat_dog/train/'</span></span><br><span class="line">base_dir = <span class="string">'data/cat_dog/cats_and_dogs_small'</span></span><br><span class="line">os.mkdir(base_dir)</span><br><span class="line"></span><br><span class="line">train_dir = os.path.join(base_dir, <span class="string">'train'</span>)</span><br><span class="line">os.mkdir(train_dir)</span><br><span class="line">validation_dir = os.path.join(base_dir, <span class="string">'validation'</span>)</span><br><span class="line">os.mkdir(validation_dir)</span><br><span class="line">test_dir = os.path.join(base_dir, <span class="string">'test'</span>)</span><br><span class="line">os.mkdir(test_dir)</span><br><span class="line"></span><br><span class="line">train_cats_dir = os.path.join(train_dir, <span class="string">'cats'</span>)</span><br><span class="line">os.mkdir(train_cats_dir)</span><br><span class="line">train_dogs_dir = os.path.join(train_dir, <span class="string">'dogs'</span>)</span><br><span class="line">os.mkdir(train_dogs_dir)</span><br><span class="line"></span><br><span class="line">validation_cats_dir = os.path.join(validation_dir, <span class="string">'cats'</span>)</span><br><span class="line">os.mkdir(validation_cats_dir)</span><br><span class="line">validation_dogs_dir = os.path.join(validation_dir, <span class="string">'dogs'</span>)</span><br><span class="line">os.mkdir(validation_dogs_dir)</span><br><span class="line"></span><br><span class="line">test_cats_dir = os.path.join(test_dir, <span class="string">'cats'</span>)</span><br><span class="line">os.mkdir(test_cats_dir)</span><br><span class="line">test_dogs_dir = os.path.join(test_dir, <span class="string">'dogs'</span>)</span><br><span class="line">os.mkdir(test_dogs_dir)</span><br><span class="line"></span><br><span class="line">fnames = [<span class="string">'cat.&#123;&#125;.jpg'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">    src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">    dst = os.path.join(train_cats_dir, fname)</span><br><span class="line">    shutil.copyfile(src, dst)</span><br><span class="line">fnames = [<span class="string">'cat.&#123;&#125;.jpg'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>, <span class="number">1500</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">    src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">    dst = os.path.join(validation_cats_dir, fname)</span><br><span class="line">    shutil.copyfile(src, dst)</span><br><span class="line">fnames = [<span class="string">'cat.&#123;&#125;.jpg'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1500</span>, <span class="number">2000</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">    src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">    dst = os.path.join(test_cats_dir, fname)</span><br><span class="line">    shutil.copyfile(src, dst)</span><br><span class="line">    </span><br><span class="line">fnames = [<span class="string">'dog.&#123;&#125;.jpg'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">    src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">    dst = os.path.join(train_dogs_dir, fname)</span><br><span class="line">    shutil.copyfile(src, dst)</span><br><span class="line">fnames = [<span class="string">'dog.&#123;&#125;.jpg'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>, <span class="number">1500</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">    src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">    dst = os.path.join(validation_dogs_dir, fname)</span><br><span class="line">    shutil.copyfile(src, dst)</span><br><span class="line">fnames = [<span class="string">'dog.&#123;&#125;.jpg'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1500</span>, <span class="number">2000</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">    src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">    dst = os.path.join(test_dogs_dir, fname)</span><br><span class="line">    shutil.copyfile(src, dst)</span><br><span class="line">    </span><br><span class="line">print(<span class="string">'total training cat images:'</span>, len(os.listdir(train_cats_dir)))</span><br><span class="line">print(<span class="string">'total training dog images:'</span>, len(os.listdir(train_dogs_dir)))</span><br><span class="line">print(<span class="string">'total validation cat images:'</span>, len(os.listdir(validation_cats_dir)))</span><br><span class="line">print(<span class="string">'total validation dog images:'</span>, len(os.listdir(validation_dogs_dir)))</span><br><span class="line">print(<span class="string">'total test cat images:'</span>, len(os.listdir(test_cats_dir)))</span><br><span class="line">print(<span class="string">'total test dog images:'</span>, len(os.listdir(test_dogs_dir)))</span><br></pre></td></tr></table></figure>
<pre><code>total training cat images: 1000
total training dog images: 1000
total validation cat images: 500
total validation dog images: 500
total test cat images: 500
total test dog images: 500
</code></pre><h2 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用ImageDataGenerator做数据增强</span></span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line">datagen = ImageDataGenerator(</span><br><span class="line">    rotation_range=<span class="number">40</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    shear_range=<span class="number">0.2</span>,</span><br><span class="line">    zoom_range=<span class="number">0.2</span>,</span><br><span class="line">    horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">    fill_mode=<span class="string">'nearest'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 显示图像</span></span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"></span><br><span class="line">fnames = [os.path.join(train_cats_dir, fname) <span class="keyword">for</span> fname <span class="keyword">in</span> os.listdir(train_cats_dir)]</span><br><span class="line">img_path = fnames[<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">img = image.load_img(img_path, target_size=(<span class="number">150</span>, <span class="number">150</span>))</span><br><span class="line">x = image.img_to_array(img)</span><br><span class="line">x = x.reshape((<span class="number">1</span>, )+x.shape)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line">i = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> datagen.flow(x, batch_size=<span class="number">1</span>):</span><br><span class="line">    plt.figure(i)</span><br><span class="line">    imgplot = plt.imshow(image.array_to_img(batch[<span class="number">0</span>]))</span><br><span class="line">    i += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> i%<span class="number">4</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%94%A8%E4%BA%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/output_14_0-1596467952803.png" alt="png"></p>
<p><img src="/Pic/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%94%A8%E4%BA%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/output_14_1.png" alt="png"></p>
<p><img src="/Pic/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%94%A8%E4%BA%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/output_14_2.png" alt="png"></p>
<p><img src="/Pic/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%94%A8%E4%BA%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/output_14_3.png" alt="png"></p>
<h2 id="构建网络"><a href="#构建网络" class="headerlink" title="构建网络"></a>构建网络</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimizers</span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">"relu"</span>, input_shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>)))</span><br><span class="line">model.add(layers.MaxPooling2D(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">"relu"</span>))</span><br><span class="line">model.add(layers.MaxPooling2D(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">512</span>, activation=<span class="string">"relu"</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">"sigmoid"</span>))</span><br><span class="line"></span><br><span class="line">model.compile(loss=<span class="string">"binary_crossentropy"</span>,</span><br><span class="line">             optimizer=optimizers.RMSprop(lr=<span class="number">1e-4</span>),</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br></pre></td></tr></table></figure>
<pre><code>WARNING:tensorflow:From C:\Users\16402\Anaconda3\envs\python36\lib\site-packages\tensorflow_core\python\ops\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 利用数据增强生成器训练卷积神经网络</span></span><br><span class="line">train_datagen = ImageDataGenerator(</span><br><span class="line">    rescale=<span class="number">1.</span>/<span class="number">255</span>,</span><br><span class="line">    rotation_range=<span class="number">40</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    shear_range=<span class="number">0.2</span>,</span><br><span class="line">    zoom_range=<span class="number">0.2</span>,</span><br><span class="line">    horizontal_flip=<span class="literal">True</span>,)</span><br><span class="line">test_datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line"></span><br><span class="line">train_generator = train_datagen.flow_from_directory(</span><br><span class="line">    train_dir,</span><br><span class="line">    target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">    batch_size=<span class="number">32</span>,</span><br><span class="line">    class_mode=<span class="string">'binary'</span>)</span><br><span class="line">validation_generator = test_datagen.flow_from_directory(</span><br><span class="line">    validation_dir,</span><br><span class="line">    target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">    batch_size=<span class="number">32</span>,</span><br><span class="line">    class_mode=<span class="string">'binary'</span>)</span><br><span class="line"></span><br><span class="line">history = model.fit_generator(</span><br><span class="line">    train_generator,</span><br><span class="line">    steps_per_epoch=<span class="number">100</span>,</span><br><span class="line">    epochs=<span class="number">100</span>,</span><br><span class="line">    validation_data=validation_generator,</span><br><span class="line">    validation_steps=<span class="number">50</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Found 2000 images belonging to 2 classes.
Found 1000 images belonging to 2 classes.
Epoch 1/100
100/100 [==============================] - 74s 740ms/step - loss: 0.6927 - acc: 0.5167 - val_loss: 0.6583 - val_acc: 0.5933
Epoch 2/100
100/100 [==============================] - 68s 678ms/step - loss: 0.6757 - acc: 0.5707 - val_loss: 0.6161 - val_acc: 0.5670
Epoch 3/100
100/100 [==============================] - 65s 645ms/step - loss: 0.6539 - acc: 0.6074 - val_loss: 0.6832 - val_acc: 0.6237
Epoch 4/100
100/100 [==============================] - 66s 656ms/step - loss: 0.6368 - acc: 0.6222 - val_loss: 0.6641 - val_acc: 0.6553
Epoch 5/100
100/100 [==============================] - 66s 658ms/step - loss: 0.6161 - acc: 0.6648 - val_loss: 0.5204 - val_acc: 0.6789
Epoch 6/100
100/100 [==============================] - 69s 693ms/step - loss: 0.6063 - acc: 0.6734 - val_loss: 0.5975 - val_acc: 0.6740
Epoch 7/100
100/100 [==============================] - 70s 702ms/step - loss: 0.6009 - acc: 0.6692 - val_loss: 0.4627 - val_acc: 0.7005
Epoch 8/100
100/100 [==============================] - 77s 768ms/step - loss: 0.5921 - acc: 0.6831 - val_loss: 0.8519 - val_acc: 0.6321
Epoch 9/100
100/100 [==============================] - 88s 881ms/step - loss: 0.5940 - acc: 0.6783 - val_loss: 0.4899 - val_acc: 0.7049
Epoch 10/100
100/100 [==============================] - 83s 832ms/step - loss: 0.5801 - acc: 0.6913 - val_loss: 0.4796 - val_acc: 0.6980
Epoch 11/100
100/100 [==============================] - 70s 697ms/step - loss: 0.5684 - acc: 0.7015 - val_loss: 0.5900 - val_acc: 0.7255
Epoch 12/100
100/100 [==============================] - 70s 702ms/step - loss: 0.5599 - acc: 0.7092 - val_loss: 0.5051 - val_acc: 0.7030
Epoch 13/100
100/100 [==============================] - 70s 698ms/step - loss: 0.5526 - acc: 0.7181 - val_loss: 0.5009 - val_acc: 0.7101
Epoch 14/100
100/100 [==============================] - 71s 708ms/step - loss: 0.5602 - acc: 0.7129 - val_loss: 0.6177 - val_acc: 0.7088
Epoch 15/100
100/100 [==============================] - 74s 738ms/step - loss: 0.5401 - acc: 0.7177 - val_loss: 0.7140 - val_acc: 0.6591
Epoch 16/100
100/100 [==============================] - 72s 725ms/step - loss: 0.5472 - acc: 0.7186 - val_loss: 0.8219 - val_acc: 0.7384
Epoch 17/100
100/100 [==============================] - 70s 704ms/step - loss: 0.5407 - acc: 0.7180 - val_loss: 0.4693 - val_acc: 0.7367
Epoch 18/100
100/100 [==============================] - 70s 704ms/step - loss: 0.5300 - acc: 0.7301 - val_loss: 0.6182 - val_acc: 0.7191
Epoch 19/100
100/100 [==============================] - 71s 710ms/step - loss: 0.5297 - acc: 0.7271 - val_loss: 0.5767 - val_acc: 0.7379
Epoch 20/100
100/100 [==============================] - 70s 700ms/step - loss: 0.5320 - acc: 0.7345 - val_loss: 0.4792 - val_acc: 0.7616
Epoch 21/100
100/100 [==============================] - 70s 702ms/step - loss: 0.5228 - acc: 0.7393 - val_loss: 0.6806 - val_acc: 0.7240
Epoch 22/100
100/100 [==============================] - 69s 690ms/step - loss: 0.5190 - acc: 0.7421 - val_loss: 0.5098 - val_acc: 0.7610
Epoch 23/100
100/100 [==============================] - 68s 679ms/step - loss: 0.5184 - acc: 0.7481 - val_loss: 0.6571 - val_acc: 0.7665
Epoch 24/100
100/100 [==============================] - 68s 677ms/step - loss: 0.5054 - acc: 0.7484 - val_loss: 0.4710 - val_acc: 0.7506
Epoch 25/100
100/100 [==============================] - 69s 686ms/step - loss: 0.5080 - acc: 0.7412 - val_loss: 0.5399 - val_acc: 0.7468
Epoch 26/100
100/100 [==============================] - 68s 679ms/step - loss: 0.4945 - acc: 0.7644 - val_loss: 0.2892 - val_acc: 0.7602
Epoch 27/100
100/100 [==============================] - 67s 671ms/step - loss: 0.5005 - acc: 0.7449 - val_loss: 0.5151 - val_acc: 0.7552
Epoch 28/100
100/100 [==============================] - 68s 677ms/step - loss: 0.5062 - acc: 0.7465 - val_loss: 0.3623 - val_acc: 0.7659
Epoch 29/100
100/100 [==============================] - 68s 678ms/step - loss: 0.4914 - acc: 0.7595 - val_loss: 0.3824 - val_acc: 0.7964
Epoch 30/100
100/100 [==============================] - 81s 807ms/step - loss: 0.4937 - acc: 0.7566 - val_loss: 0.4665 - val_acc: 0.6942
Epoch 31/100
100/100 [==============================] - 80s 796ms/step - loss: 0.4852 - acc: 0.7641 - val_loss: 0.5380 - val_acc: 0.7506
Epoch 32/100
100/100 [==============================] - 78s 782ms/step - loss: 0.4774 - acc: 0.7698 - val_loss: 0.3291 - val_acc: 0.7668
Epoch 33/100
100/100 [==============================] - 75s 752ms/step - loss: 0.4834 - acc: 0.7636 - val_loss: 0.3217 - val_acc: 0.7805
Epoch 34/100
100/100 [==============================] - 72s 722ms/step - loss: 0.4784 - acc: 0.7677 - val_loss: 0.4656 - val_acc: 0.7397
Epoch 35/100
100/100 [==============================] - 77s 772ms/step - loss: 0.4717 - acc: 0.7737 - val_loss: 0.3206 - val_acc: 0.7887
Epoch 36/100
100/100 [==============================] - 70s 695ms/step - loss: 0.4781 - acc: 0.7582 - val_loss: 0.5194 - val_acc: 0.7932
Epoch 37/100
100/100 [==============================] - 69s 686ms/step - loss: 0.4530 - acc: 0.7828 - val_loss: 0.2837 - val_acc: 0.7786
Epoch 38/100
100/100 [==============================] - 68s 684ms/step - loss: 0.4778 - acc: 0.7692 - val_loss: 0.4444 - val_acc: 0.7674
Epoch 39/100
100/100 [==============================] - 78s 780ms/step - loss: 0.4629 - acc: 0.7753 - val_loss: 0.5315 - val_acc: 0.7627
Epoch 40/100
100/100 [==============================] - 83s 831ms/step - loss: 0.4606 - acc: 0.7792 - val_loss: 0.5177 - val_acc: 0.7564
Epoch 41/100
100/100 [==============================] - 84s 838ms/step - loss: 0.4597 - acc: 0.7917 - val_loss: 0.4885 - val_acc: 0.7680
Epoch 42/100
100/100 [==============================] - 76s 764ms/step - loss: 0.4475 - acc: 0.7820 - val_loss: 0.3850 - val_acc: 0.7868
Epoch 43/100
100/100 [==============================] - 85s 849ms/step - loss: 0.4532 - acc: 0.7891 - val_loss: 0.4080 - val_acc: 0.7957
Epoch 44/100
100/100 [==============================] - 73s 733ms/step - loss: 0.4655 - acc: 0.7715 - val_loss: 0.5390 - val_acc: 0.7779
Epoch 45/100
100/100 [==============================] - 68s 684ms/step - loss: 0.4479 - acc: 0.7871 - val_loss: 0.3279 - val_acc: 0.7751
Epoch 46/100
100/100 [==============================] - 68s 680ms/step - loss: 0.4452 - acc: 0.7948 - val_loss: 0.4211 - val_acc: 0.7506
Epoch 47/100
100/100 [==============================] - 69s 689ms/step - loss: 0.4403 - acc: 0.7945 - val_loss: 0.4955 - val_acc: 0.7809
Epoch 48/100
100/100 [==============================] - 82s 824ms/step - loss: 0.4535 - acc: 0.7885 - val_loss: 0.2140 - val_acc: 0.7951
Epoch 49/100
100/100 [==============================] - 86s 861ms/step - loss: 0.4466 - acc: 0.7899 - val_loss: 0.3635 - val_acc: 0.7786
Epoch 50/100
100/100 [==============================] - 84s 844ms/step - loss: 0.4287 - acc: 0.8075 - val_loss: 0.5638 - val_acc: 0.7210
Epoch 51/100
100/100 [==============================] - 92s 916ms/step - loss: 0.4411 - acc: 0.7904 - val_loss: 0.5665 - val_acc: 0.7779
Epoch 52/100
100/100 [==============================] - 91s 908ms/step - loss: 0.4360 - acc: 0.7904 - val_loss: 0.3423 - val_acc: 0.8009
Epoch 53/100
100/100 [==============================] - 72s 717ms/step - loss: 0.4210 - acc: 0.8015 - val_loss: 0.9407 - val_acc: 0.7151
Epoch 54/100
100/100 [==============================] - 70s 702ms/step - loss: 0.4283 - acc: 0.7999 - val_loss: 0.5640 - val_acc: 0.7726
Epoch 55/100
100/100 [==============================] - 71s 708ms/step - loss: 0.4223 - acc: 0.8040 - val_loss: 0.7437 - val_acc: 0.7855
Epoch 56/100
100/100 [==============================] - 75s 745ms/step - loss: 0.4262 - acc: 0.7970 - val_loss: 0.3689 - val_acc: 0.7796
Epoch 57/100
100/100 [==============================] - 93s 928ms/step - loss: 0.4006 - acc: 0.8197 - val_loss: 0.7411 - val_acc: 0.7558
Epoch 58/100
100/100 [==============================] - 85s 849ms/step - loss: 0.4284 - acc: 0.7961 - val_loss: 0.4485 - val_acc: 0.7621
Epoch 59/100
100/100 [==============================] - 84s 835ms/step - loss: 0.4225 - acc: 0.8043 - val_loss: 0.4462 - val_acc: 0.7249
Epoch 60/100
100/100 [==============================] - 96s 963ms/step - loss: 0.4270 - acc: 0.7977 - val_loss: 0.3348 - val_acc: 0.7836
Epoch 61/100
100/100 [==============================] - 86s 856ms/step - loss: 0.4080 - acc: 0.8150 - val_loss: 0.5779 - val_acc: 0.7700
Epoch 62/100
100/100 [==============================] - 83s 830ms/step - loss: 0.4228 - acc: 0.8009 - val_loss: 0.2566 - val_acc: 0.7919
Epoch 63/100
100/100 [==============================] - 83s 831ms/step - loss: 0.4020 - acc: 0.8131 - val_loss: 0.5130 - val_acc: 0.7809
Epoch 64/100
100/100 [==============================] - 73s 729ms/step - loss: 0.4190 - acc: 0.8052 - val_loss: 0.2442 - val_acc: 0.7687
Epoch 65/100
100/100 [==============================] - 76s 759ms/step - loss: 0.4110 - acc: 0.8112 - val_loss: 0.4209 - val_acc: 0.7843
Epoch 66/100
100/100 [==============================] - 73s 728ms/step - loss: 0.3941 - acc: 0.8169 - val_loss: 0.4747 - val_acc: 0.7700
Epoch 67/100
100/100 [==============================] - 70s 697ms/step - loss: 0.4040 - acc: 0.8201 - val_loss: 0.3064 - val_acc: 0.8077
Epoch 68/100
100/100 [==============================] - 73s 727ms/step - loss: 0.3913 - acc: 0.8228 - val_loss: 0.4265 - val_acc: 0.7790
Epoch 69/100
100/100 [==============================] - 72s 719ms/step - loss: 0.3935 - acc: 0.8236 - val_loss: 0.2245 - val_acc: 0.8179
Epoch 70/100
100/100 [==============================] - 73s 728ms/step - loss: 0.4004 - acc: 0.8131 - val_loss: 0.4465 - val_acc: 0.7796
Epoch 71/100
100/100 [==============================] - 71s 712ms/step - loss: 0.3935 - acc: 0.8248 - val_loss: 0.5309 - val_acc: 0.7766
Epoch 72/100
100/100 [==============================] - 73s 733ms/step - loss: 0.3998 - acc: 0.8141 - val_loss: 0.4126 - val_acc: 0.8048
Epoch 73/100
100/100 [==============================] - 71s 711ms/step - loss: 0.3866 - acc: 0.8109 - val_loss: 0.3455 - val_acc: 0.7970
Epoch 74/100
100/100 [==============================] - 74s 742ms/step - loss: 0.3847 - acc: 0.8291 - val_loss: 0.4794 - val_acc: 0.7893
Epoch 75/100
100/100 [==============================] - 72s 717ms/step - loss: 0.3831 - acc: 0.8223 - val_loss: 0.3068 - val_acc: 0.8073
Epoch 76/100
100/100 [==============================] - 73s 732ms/step - loss: 0.3780 - acc: 0.8333 - val_loss: 0.3512 - val_acc: 0.7938
Epoch 77/100
100/100 [==============================] - 71s 711ms/step - loss: 0.3803 - acc: 0.8298 - val_loss: 0.4373 - val_acc: 0.8235
Epoch 78/100
100/100 [==============================] - 73s 733ms/step - loss: 0.3746 - acc: 0.8333 - val_loss: 0.3070 - val_acc: 0.8077
Epoch 79/100
100/100 [==============================] - 69s 694ms/step - loss: 0.3815 - acc: 0.8286 - val_loss: 0.5839 - val_acc: 0.7932
Epoch 80/100
100/100 [==============================] - 74s 735ms/step - loss: 0.3700 - acc: 0.8392 - val_loss: 0.4024 - val_acc: 0.8177
Epoch 81/100
100/100 [==============================] - 90s 903ms/step - loss: 0.3702 - acc: 0.8374 - val_loss: 0.3240 - val_acc: 0.8115
Epoch 82/100
100/100 [==============================] - 90s 898ms/step - loss: 0.3768 - acc: 0.8313 - val_loss: 0.6445 - val_acc: 0.8073
Epoch 83/100
100/100 [==============================] - 90s 898ms/step - loss: 0.3578 - acc: 0.8349 - val_loss: 0.2373 - val_acc: 0.7893
Epoch 84/100
100/100 [==============================] - 72s 717ms/step - loss: 0.3692 - acc: 0.8357 - val_loss: 0.3050 - val_acc: 0.8222
Epoch 85/100
100/100 [==============================] - 70s 703ms/step - loss: 0.3587 - acc: 0.8365 - val_loss: 0.2624 - val_acc: 0.8128
Epoch 86/100
100/100 [==============================] - 70s 702ms/step - loss: 0.3559 - acc: 0.8405 - val_loss: 0.3040 - val_acc: 0.7932
Epoch 87/100
100/100 [==============================] - 68s 683ms/step - loss: 0.3672 - acc: 0.8390 - val_loss: 0.6529 - val_acc: 0.8166
Epoch 88/100
100/100 [==============================] - 69s 685ms/step - loss: 0.3653 - acc: 0.8425 - val_loss: 0.6271 - val_acc: 0.7758
Epoch 89/100
100/100 [==============================] - 68s 684ms/step - loss: 0.3461 - acc: 0.8439 - val_loss: 0.3287 - val_acc: 0.8196
Epoch 90/100
100/100 [==============================] - 68s 680ms/step - loss: 0.3671 - acc: 0.8387 - val_loss: 0.6344 - val_acc: 0.8185
Epoch 91/100
100/100 [==============================] - 68s 685ms/step - loss: 0.3509 - acc: 0.8458 - val_loss: 0.5421 - val_acc: 0.7925
Epoch 92/100
100/100 [==============================] - 68s 683ms/step - loss: 0.3430 - acc: 0.8494 - val_loss: 0.3669 - val_acc: 0.8052
Epoch 93/100
100/100 [==============================] - 68s 684ms/step - loss: 0.3536 - acc: 0.8464 - val_loss: 0.4218 - val_acc: 0.8003
Epoch 94/100
100/100 [==============================] - 68s 683ms/step - loss: 0.3424 - acc: 0.8510 - val_loss: 0.3568 - val_acc: 0.8166
Epoch 95/100
100/100 [==============================] - 68s 681ms/step - loss: 0.3368 - acc: 0.8510 - val_loss: 0.2573 - val_acc: 0.8112
Epoch 96/100
100/100 [==============================] - 68s 684ms/step - loss: 0.3384 - acc: 0.8464 - val_loss: 0.1202 - val_acc: 0.8138
Epoch 97/100
100/100 [==============================] - 68s 680ms/step - loss: 0.3614 - acc: 0.8384 - val_loss: 0.2557 - val_acc: 0.8071
Epoch 98/100
100/100 [==============================] - 69s 689ms/step - loss: 0.3374 - acc: 0.8548 - val_loss: 0.5183 - val_acc: 0.7668
Epoch 99/100
100/100 [==============================] - 69s 691ms/step - loss: 0.3432 - acc: 0.8452 - val_loss: 0.6175 - val_acc: 0.8249
Epoch 100/100
100/100 [==============================] - 69s 685ms/step - loss: 0.3448 - acc: 0.8489 - val_loss: 0.3623 - val_acc: 0.7951
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.save(<span class="string">'model/cats_and_dogs_small_2.h5'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.applications <span class="keyword">import</span> VGG16</span><br><span class="line">conv_base = VGG16(weights=<span class="string">'imagenet'</span>, include_top=<span class="literal">False</span>, input_shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>))</span><br><span class="line">conv_base.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;vgg16&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         (None, 150, 150, 3)       0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         
=================================================================
Total params: 14,714,688
Trainable params: 14,714,688
Non-trainable params: 0
_________________________________________________________________
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"></span><br><span class="line">base_dir = <span class="string">"data/cat_dog/cats_and_dogs_small"</span></span><br><span class="line">train_dir = os.path.join(base_dir, <span class="string">'train'</span>)</span><br><span class="line">validation_dir = os.path.join(base_dir, <span class="string">'validation'</span>)</span><br><span class="line">test_dir = os.path.join(base_dir, <span class="string">'test'</span>)</span><br><span class="line">datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line">batch_size = <span class="number">20</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_features</span><span class="params">(directory, sample_count)</span>:</span></span><br><span class="line">    features = np.zeros(shape=(sample_count, <span class="number">4</span>, <span class="number">4</span>, <span class="number">512</span>))</span><br><span class="line">    labels = np.zeros(shape=(sample_count))</span><br><span class="line">    generator = datagen.flow_from_directory(</span><br><span class="line">        directory,</span><br><span class="line">        target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">        batch_size=batch_size,</span><br><span class="line">        class_mode=<span class="string">'binary'</span>)</span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> inputs_batch, labels_batch <span class="keyword">in</span> generator:</span><br><span class="line">        features_batch = conv_base.predict(inputs_batch)</span><br><span class="line">        features[i * batch_size : (i + <span class="number">1</span>) * batch_size] = features_batch</span><br><span class="line">        labels[i * batch_size : (i + <span class="number">1</span>) * batch_size] = labels_batch</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> i * batch_size &gt;= sample_count:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> features, labels</span><br><span class="line"></span><br><span class="line">train_features, train_labels = extract_features(train_dir, <span class="number">2000</span>)</span><br><span class="line">validation_features, validation_labels = extract_features(validation_dir, <span class="number">1000</span>)</span><br><span class="line">test_features, test_labels = extract_features(test_dir, <span class="number">1000</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Found 2000 images belonging to 2 classes.
Found 1000 images belonging to 2 classes.
Found 1000 images belonging to 2 classes.
</code></pre><p>目前，提取的特征形状为(samples, 4, 4, 512)。我们要将其输入到密集连接分类器中，<br>所以首先必须将其形状展平为(samples, 8192)。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_features = np.reshape(train_features, (<span class="number">2000</span>, <span class="number">4</span>*<span class="number">4</span>*<span class="number">512</span>))</span><br><span class="line">validation_features = np.reshape(validation_features, (<span class="number">1000</span>, <span class="number">4</span> * <span class="number">4</span> * <span class="number">512</span>))</span><br><span class="line">test_features = np.reshape(test_features, (<span class="number">1000</span>, <span class="number">4</span> * <span class="number">4</span> * <span class="number">512</span>))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers </span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimizers</span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">256</span>, activation=<span class="string">"relu"</span>, input_dim=<span class="number">4</span>*<span class="number">4</span>*<span class="number">512</span>))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">"sigmoid"</span>))</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=optimizers.RMSprop(lr=<span class="number">2e-5</span>),</span><br><span class="line">             loss = <span class="string">"binary_crossentropy"</span>,</span><br><span class="line">             metrics=[<span class="string">"acc"</span>])</span><br><span class="line"></span><br><span class="line">history = model.fit(train_features, train_labels,</span><br><span class="line">                   epochs=<span class="number">30</span>, batch_size=<span class="number">20</span>,</span><br><span class="line">                   validation_data=(validation_features, validation_labels))</span><br></pre></td></tr></table></figure>
<pre><code>Train on 2000 samples, validate on 1000 samples
Epoch 1/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.6142 - acc: 0.6485 - val_loss: 0.4569 - val_acc: 0.8210
Epoch 2/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.4278 - acc: 0.8115 - val_loss: 0.3716 - val_acc: 0.8650
Epoch 3/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.3626 - acc: 0.8430 - val_loss: 0.3342 - val_acc: 0.8720
Epoch 4/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.3246 - acc: 0.8605 - val_loss: 0.3049 - val_acc: 0.8850
Epoch 5/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.2933 - acc: 0.8855 - val_loss: 0.2946 - val_acc: 0.8730
Epoch 6/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.2679 - acc: 0.8950 - val_loss: 0.2773 - val_acc: 0.8950
Epoch 7/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.2581 - acc: 0.8950 - val_loss: 0.2805 - val_acc: 0.8830
Epoch 8/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.2352 - acc: 0.9075 - val_loss: 0.2612 - val_acc: 0.9010
Epoch 9/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.2227 - acc: 0.9120 - val_loss: 0.2591 - val_acc: 0.8950
Epoch 10/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.2081 - acc: 0.9235 - val_loss: 0.2521 - val_acc: 0.9010
Epoch 11/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.2105 - acc: 0.9125 - val_loss: 0.2492 - val_acc: 0.8990
Epoch 12/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1917 - acc: 0.9270 - val_loss: 0.2482 - val_acc: 0.8980
Epoch 13/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1835 - acc: 0.9350 - val_loss: 0.2447 - val_acc: 0.8990
Epoch 14/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1756 - acc: 0.9345 - val_loss: 0.2462 - val_acc: 0.8980
Epoch 15/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1648 - acc: 0.9355 - val_loss: 0.2414 - val_acc: 0.9000
Epoch 16/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1600 - acc: 0.9435 - val_loss: 0.2449 - val_acc: 0.8980
Epoch 17/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1566 - acc: 0.9460 - val_loss: 0.2410 - val_acc: 0.9010
Epoch 18/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1430 - acc: 0.9510 - val_loss: 0.2404 - val_acc: 0.9020
Epoch 19/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1451 - acc: 0.9470 - val_loss: 0.2422 - val_acc: 0.9010
Epoch 20/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1368 - acc: 0.9565 - val_loss: 0.2387 - val_acc: 0.9010
Epoch 21/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1293 - acc: 0.9565 - val_loss: 0.2389 - val_acc: 0.9010
Epoch 22/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1194 - acc: 0.9610 - val_loss: 0.2390 - val_acc: 0.9010
Epoch 23/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1206 - acc: 0.9605 - val_loss: 0.2396 - val_acc: 0.8990
Epoch 24/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1176 - acc: 0.9530 - val_loss: 0.2442 - val_acc: 0.8990
Epoch 25/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1117 - acc: 0.9630 - val_loss: 0.2392 - val_acc: 0.8990
Epoch 26/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1072 - acc: 0.9650 - val_loss: 0.2480 - val_acc: 0.9040
Epoch 27/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1028 - acc: 0.9685 - val_loss: 0.2466 - val_acc: 0.9030
Epoch 28/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.0949 - acc: 0.9745 - val_loss: 0.2453 - val_acc: 0.8980
Epoch 29/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.0946 - acc: 0.9715 - val_loss: 0.2618 - val_acc: 0.8960
Epoch 30/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.0891 - acc: 0.9740 - val_loss: 0.2428 - val_acc: 0.9000
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">acc = history.history[<span class="string">'acc'</span>]</span><br><span class="line">val_acc = history.history[<span class="string">'val_acc'</span>]</span><br><span class="line">loss = history.history[<span class="string">'loss'</span>]</span><br><span class="line">val_loss = history.history[<span class="string">'val_loss'</span>]</span><br><span class="line"></span><br><span class="line">epochs = range(<span class="number">1</span>, len(acc) + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, acc, <span class="string">'bo'</span>, label=<span class="string">'Training acc'</span>)</span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">'b'</span>, label=<span class="string">'Validation acc'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation accuracy'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(epochs, loss, <span class="string">'bo'</span>, label=<span class="string">'Training loss'</span>)</span><br><span class="line">plt.plot(epochs, val_loss, <span class="string">'b'</span>, label=<span class="string">'Validation loss'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%94%A8%E4%BA%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/output_24_0.png" alt="png"></p>
<p><img src="/Pic/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%94%A8%E4%BA%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/output_24_1.png" alt="png"></p>
<h1 id="可视化中间激活"><a href="#可视化中间激活" class="headerlink" title="可视化中间激活"></a>可视化中间激活</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line">model = load_model(<span class="string">'model/cats_and_dogs_small_2.h5'</span>)</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_5&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_11 (Conv2D)           (None, 148, 148, 32)      896       
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 74, 74, 32)        0         
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 72, 72, 64)        18496     
_________________________________________________________________
max_pooling2d_8 (MaxPooling2 (None, 36, 36, 64)        0         
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 34, 34, 128)       73856     
_________________________________________________________________
max_pooling2d_9 (MaxPooling2 (None, 17, 17, 128)       0         
_________________________________________________________________
conv2d_14 (Conv2D)           (None, 15, 15, 128)       147584    
_________________________________________________________________
max_pooling2d_10 (MaxPooling (None, 7, 7, 128)         0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 6272)              0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 6272)              0         
_________________________________________________________________
dense_3 (Dense)              (None, 512)               3211776   
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 513       
=================================================================
Total params: 3,453,121
Trainable params: 3,453,121
Non-trainable params: 0
_________________________________________________________________
</code></pre><p>接下来，我们需要一张输入图像，即一张猫的图像，它不属于网络的训练图像。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">img_path = <span class="string">'data/cat_dog/train/cat.1700.jpg'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型的输入数据都用这种方法预处理</span></span><br><span class="line">img = image.load_img(img_path, target_size=(<span class="number">150</span>, <span class="number">150</span>))</span><br><span class="line">img_tensor = image.img_to_array(img)</span><br><span class="line">img_tensor = np.expand_dims(img_tensor, axis=<span class="number">0</span>)</span><br><span class="line">img_tensor /= <span class="number">255.</span></span><br><span class="line"></span><br><span class="line">print(img_tensor.shape)</span><br></pre></td></tr></table></figure>
<pre><code>(1, 150, 150, 3)
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.imshow(img_tensor[<span class="number">0</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%94%A8%E4%BA%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/output_29_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line">layer_outputs = [layer.output <span class="keyword">for</span> layer <span class="keyword">in</span> model.layers[:<span class="number">8</span>]]</span><br><span class="line">activation_model = models.Model(inputs=model.input, outputs=layer_outputs)</span><br><span class="line">activations = activation_model.predict(img_tensor)</span><br><span class="line"></span><br><span class="line">first_layer_activation = activations[<span class="number">0</span>]</span><br><span class="line">print(first_layer_activation.shape)</span><br></pre></td></tr></table></figure>
<pre><code>(1, 148, 148, 32)
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.matshow(first_layer_activation[<span class="number">0</span>, :, :, <span class="number">4</span>], cmap=<span class="string">'viridis'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.image.AxesImage at 0x18690050be0&gt;
</code></pre><p><img src="/Pic/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%94%A8%E4%BA%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/output_31_1.png" alt="png"></p>
<p>当然，还有更多的可视化方法，但不是我们关注的主线，这里就不一一阐述了。</p>
<blockquote>
<p>注：以上内容均直接搬运自个人的jupyter notebook，参考书籍为《Python深度学习》，注释未到位之处请多谅解，有需要对哪些地方补充注释的可以在下方留言</p>
</blockquote>
]]></content>
      <categories>
        <category>Keras</category>
      </categories>
  </entry>
  <entry>
    <title>Keras深度学习（一）神经网络入门</title>
    <url>/posts/990a7167.html</url>
    <content><![CDATA[<h1 id="神经网络剖析"><a href="#神经网络剖析" class="headerlink" title="神经网络剖析"></a>神经网络剖析</h1><p>训练神经网络主要分为以下四个方面：</p>
<ol>
<li>层：多个层组合成网络（或模型）</li>
<li>输入数据和相应的目标</li>
<li>损失函数：即用于学习的返回信号</li>
<li>优化器：决定学习进程如何进行</li>
</ol>
<h2 id="定义模型"><a href="#定义模型" class="headerlink" title="定义模型"></a>定义模型</h2><p>定义模型的两种不同方法：</p>
<ol>
<li>使用Sequential类（仅用于层的线性堆叠）</li>
<li>函数式API（可以构建任何形式的架构）</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br></pre></td></tr></table></figure>
<p><strong>Sequential类定义的模型</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">32</span>, activation=<span class="string">"relu"</span>, input_shape=(<span class="number">784</span>,)))</span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>, activation=<span class="string">"softmax"</span>))</span><br></pre></td></tr></table></figure>
<pre><code>WARNING:tensorflow:From C:\Users\16402\Anaconda3\envs\python36\lib\site-packages\tensorflow_core\python\ops\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
</code></pre><p><strong>函数式API定义的模型</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">input_tensor = layers.Input(shape=(<span class="number">784</span>,))</span><br><span class="line">x = layers.Dense(<span class="number">32</span>, activation=<span class="string">"relu"</span>)(input_tensor)</span><br><span class="line">output_tensor = layers.Dense(<span class="number">10</span>, activation=<span class="string">"softmax"</span>)(x)</span><br><span class="line">model = models.Model(inputs=input_tensor, outputs=output_tensor)</span><br></pre></td></tr></table></figure>
<h2 id="损失函数与优化器"><a href="#损失函数与优化器" class="headerlink" title="损失函数与优化器"></a>损失函数与优化器</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimizers</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=optimizers.RMSprop(lr=<span class="number">0.01</span>), loss=<span class="string">"mse"</span>, metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure>
<p>最后，学习过程就是通过fit() 方法将输入数据的Numpy 数组（和对应的目标数据）传入模型，这一做法与Scikit-Learn 及其他机器学习库类似。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.fit(input_tensor, target_tensor, batch_size=<span class="number">128</span>, epoches=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<h1 id="电影评论分类：二分类问题"><a href="#电影评论分类：二分类问题" class="headerlink" title="电影评论分类：二分类问题"></a>电影评论分类：二分类问题</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> imdb</span><br><span class="line">(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=<span class="number">10000</span>)</span><br></pre></td></tr></table></figure>
<pre><code>C:\Users\16402\Anaconda3\envs\python36\lib\site-packages\keras\datasets\imdb.py:101: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify &#39;dtype=object&#39; when creating the ndarray
  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])
C:\Users\16402\Anaconda3\envs\python36\lib\site-packages\keras\datasets\imdb.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify &#39;dtype=object&#39; when creating the ndarray
  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(train_data[<span class="number">0</span>])</span><br><span class="line">print(train_labels[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<pre><code>[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]
1
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">word_index = imdb.get_word_index()</span><br><span class="line">reverse_word_index = dict([(value, key) <span class="keyword">for</span> (key, value) <span class="keyword">in</span> word_index.items()])</span><br><span class="line">decoded_review = <span class="string">" "</span>.join([reverse_word_index.get(i<span class="number">-3</span>, <span class="string">"?"</span>) <span class="keyword">for</span> i <span class="keyword">in</span> train_data[<span class="number">0</span>]])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vectorize_sequences</span><span class="params">(sequences, dimension=<span class="number">10000</span>)</span>:</span></span><br><span class="line">    results = np.zeros((len(sequences), dimension))</span><br><span class="line">    <span class="keyword">for</span> i, sequence <span class="keyword">in</span> enumerate(sequences):</span><br><span class="line">        results[i, sequence] = <span class="number">1.</span></span><br><span class="line">    <span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line">x_train = vectorize_sequences(train_data)</span><br><span class="line">x_test = vectorize_sequences(test_data)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y_train = np.asarray(train_labels).astype(<span class="string">'float32'</span>)</span><br><span class="line">y_test = np.asarray(test_labels).astype(<span class="string">'float32'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 模型定义</span></span><br><span class="line"><span class="keyword">import</span> keras.models <span class="keyword">as</span> models</span><br><span class="line"><span class="keyword">import</span> keras.layers <span class="keyword">as</span> layers</span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">"relu"</span>, input_shape=(<span class="number">10000</span>,)))</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">"relu"</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">"sigmoid"</span>))</span><br></pre></td></tr></table></figure>
<pre><code>WARNING:tensorflow:From C:\Users\16402\Anaconda3\envs\python36\lib\site-packages\tensorflow_core\python\ops\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.compile(optimizer=<span class="string">"rmsprop"</span>,</span><br><span class="line">              loss=<span class="string">"binary_crossentropy"</span>,</span><br><span class="line">              metrics=[<span class="string">"accuracy"</span>])</span><br></pre></td></tr></table></figure>
<pre><code>WARNING:tensorflow:From C:\Users\16402\Anaconda3\envs\python36\lib\site-packages\tensorflow_core\python\ops\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x_val = x_train[:<span class="number">10000</span>]</span><br><span class="line">partial_x_train = x_train[<span class="number">10000</span>:]</span><br><span class="line"></span><br><span class="line">y_val = y_train[:<span class="number">10000</span>]</span><br><span class="line">partial_y_train = y_train[<span class="number">10000</span>:]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">history = model.fit(partial_x_train,</span><br><span class="line">                    partial_y_train,</span><br><span class="line">                    epochs=<span class="number">20</span>,</span><br><span class="line">                    batch_size=<span class="number">512</span>,</span><br><span class="line">                    validation_data=(x_val, y_val))</span><br></pre></td></tr></table></figure>
<pre><code>WARNING:tensorflow:From C:\Users\16402\Anaconda3\envs\python36\lib\site-packages\keras\backend\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

Train on 15000 samples, validate on 10000 samples
Epoch 1/20
15000/15000 [==============================] - 5s 304us/step - loss: 0.5254 - accuracy: 0.7822 - val_loss: 0.3898 - val_accuracy: 0.8633
Epoch 2/20
15000/15000 [==============================] - 2s 110us/step - loss: 0.3074 - accuracy: 0.9003 - val_loss: 0.3077 - val_accuracy: 0.8848
Epoch 3/20
15000/15000 [==============================] - 2s 102us/step - loss: 0.2278 - accuracy: 0.9264 - val_loss: 0.2798 - val_accuracy: 0.8914
Epoch 4/20
15000/15000 [==============================] - 1s 98us/step - loss: 0.1805 - accuracy: 0.9415 - val_loss: 0.2928 - val_accuracy: 0.8823
Epoch 5/20
15000/15000 [==============================] - 1s 98us/step - loss: 0.1486 - accuracy: 0.9529 - val_loss: 0.2839 - val_accuracy: 0.8875
Epoch 6/20
15000/15000 [==============================] - 2s 101us/step - loss: 0.1194 - accuracy: 0.9642 - val_loss: 0.2957 - val_accuracy: 0.8872
Epoch 7/20
15000/15000 [==============================] - 1s 99us/step - loss: 0.1030 - accuracy: 0.9678 - val_loss: 0.3137 - val_accuracy: 0.8836
Epoch 8/20
15000/15000 [==============================] - 1s 98us/step - loss: 0.0846 - accuracy: 0.9773 - val_loss: 0.3224 - val_accuracy: 0.8827
Epoch 9/20
15000/15000 [==============================] - 1s 98us/step - loss: 0.0735 - accuracy: 0.9803 - val_loss: 0.3628 - val_accuracy: 0.8725
Epoch 10/20
15000/15000 [==============================] - 1s 99us/step - loss: 0.0582 - accuracy: 0.9861 - val_loss: 0.3789 - val_accuracy: 0.8783
Epoch 11/20
15000/15000 [==============================] - 1s 98us/step - loss: 0.0500 - accuracy: 0.9883 - val_loss: 0.3892 - val_accuracy: 0.8786
Epoch 12/20
15000/15000 [==============================] - 1s 98us/step - loss: 0.0397 - accuracy: 0.9917 - val_loss: 0.4213 - val_accuracy: 0.8718
Epoch 13/20
15000/15000 [==============================] - 1s 98us/step - loss: 0.0338 - accuracy: 0.9931 - val_loss: 0.4453 - val_accuracy: 0.8744
Epoch 14/20
15000/15000 [==============================] - 1s 98us/step - loss: 0.0273 - accuracy: 0.9948 - val_loss: 0.4754 - val_accuracy: 0.8745
Epoch 15/20
15000/15000 [==============================] - 2s 101us/step - loss: 0.0224 - accuracy: 0.9961 - val_loss: 0.5247 - val_accuracy: 0.8717
Epoch 16/20
15000/15000 [==============================] - 1s 98us/step - loss: 0.0155 - accuracy: 0.9981 - val_loss: 0.5341 - val_accuracy: 0.8711
Epoch 17/20
15000/15000 [==============================] - 1s 98us/step - loss: 0.0139 - accuracy: 0.9983 - val_loss: 0.5686 - val_accuracy: 0.8695
Epoch 18/20
15000/15000 [==============================] - 1s 98us/step - loss: 0.0127 - accuracy: 0.9973 - val_loss: 0.6013 - val_accuracy: 0.8672
Epoch 19/20
15000/15000 [==============================] - 2s 100us/step - loss: 0.0062 - accuracy: 0.9997 - val_loss: 0.6324 - val_accuracy: 0.8652
Epoch 20/20
15000/15000 [==============================] - 1s 98us/step - loss: 0.0079 - accuracy: 0.9989 - val_loss: 0.6615 - val_accuracy: 0.8668
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">history_dict = history.history</span><br><span class="line">history_dict.keys()</span><br></pre></td></tr></table></figure>
<pre><code>dict_keys([&#39;val_loss&#39;, &#39;val_accuracy&#39;, &#39;loss&#39;, &#39;accuracy&#39;])
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">history_dict = history.history</span><br><span class="line">loss_values = history_dict[<span class="string">"loss"</span>]</span><br><span class="line">val_loss_values = history_dict[<span class="string">"val_loss"</span>]</span><br><span class="line">epochs = range(<span class="number">1</span>, len(loss_values)+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, loss_values, <span class="string">"bo"</span>, label=<span class="string">"Training loss"</span>)</span><br><span class="line">plt.plot(epochs, val_loss_values, <span class="string">"b"</span>, label=<span class="string">"Validation loss"</span>)</span><br><span class="line">plt.title(<span class="string">"Training and validation loss"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Epochs"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Loss"</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/posts/keras/output_24_2.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.clf()</span><br><span class="line">acc = history_dict[<span class="string">'accuracy'</span>]</span><br><span class="line">val_acc = history_dict[<span class="string">'val_accuracy'</span>]</span><br><span class="line">plt.plot(epochs, acc, <span class="string">'bo'</span>, label=<span class="string">'Training acc'</span>)</span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">'b'</span>, label=<span class="string">'Validation acc'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation accuracy'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Epochs'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Accuracy'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/keras/output_25_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">"relu"</span>, input_shape=(<span class="number">10000</span>,)))</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">"relu"</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">"sigmoid"</span>))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.compile(optimizer=<span class="string">"rmsprop"</span>,</span><br><span class="line">             loss=<span class="string">"binary_crossentropy"</span>,</span><br><span class="line">             metrics=[<span class="string">"acc"</span>])</span><br><span class="line">model.fit(x_train, y_train, epochs=<span class="number">4</span>, batch_size=<span class="number">512</span>)</span><br><span class="line">results = model.evaluate(x_test, y_test)</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1/4
25000/25000 [==============================] - 2s 65us/step - loss: 0.4611 - acc: 0.8215
Epoch 2/4
25000/25000 [==============================] - 2s 62us/step - loss: 0.2626 - acc: 0.9069
Epoch 3/4
25000/25000 [==============================] - 2s 65us/step - loss: 0.2007 - acc: 0.9264
Epoch 4/4
25000/25000 [==============================] - 2s 67us/step - loss: 0.1659 - acc: 0.9414
25000/25000 [==============================] - 15s 586us/step
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">results</span><br></pre></td></tr></table></figure>
<pre><code>[0.2943145182275772, 0.8847600221633911]
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.predict(x_test)</span><br></pre></td></tr></table></figure>
<pre><code>array([[0.20976487],
       [0.999882  ],
       [0.89416105],
       ...,
       [0.12636474],
       [0.05909678],
       [0.44751233]], dtype=float32)
</code></pre><h1 id="新闻分类：多分类问题"><a href="#新闻分类：多分类问题" class="headerlink" title="新闻分类：多分类问题"></a>新闻分类：多分类问题</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> reuters</span><br><span class="line">(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=<span class="number">10000</span>)</span><br></pre></td></tr></table></figure>
<pre><code>C:\Users\16402\Anaconda3\envs\python36\lib\site-packages\keras\datasets\reuters.py:85: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify &#39;dtype=object&#39; when creating the ndarray
  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])
C:\Users\16402\Anaconda3\envs\python36\lib\site-packages\keras\datasets\reuters.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify &#39;dtype=object&#39; when creating the ndarray
  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(len(train_data))</span><br><span class="line">print(len(train_labels))</span><br></pre></td></tr></table></figure>
<pre><code>8982
8982
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">word_index = reuters.get_word_index()</span><br><span class="line">reverse_word_index = dict([(value, key) <span class="keyword">for</span> (key,value) <span class="keyword">in</span> word_index.items()])</span><br><span class="line">decoded_newwire = <span class="string">" "</span>.join([reverse_word_index.get(i<span class="number">-3</span>, <span class="string">"?"</span>) <span class="keyword">for</span> i <span class="keyword">in</span> train_data[<span class="number">0</span>]])</span><br><span class="line">decoded_newwire</span><br></pre></td></tr></table></figure>
<pre><code>&#39;? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3&#39;
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vectorize_sequences</span><span class="params">(sequences, dimension=<span class="number">10000</span>)</span>:</span></span><br><span class="line">    results = np.zeros((len(sequences), dimension))</span><br><span class="line">    <span class="keyword">for</span> i, sequence <span class="keyword">in</span> enumerate(sequences):</span><br><span class="line">        results[i, sequence] = <span class="number">1.</span></span><br><span class="line">    <span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line">x_train = vectorize_sequences(train_data)</span><br><span class="line">x_test = vectorize_sequences(test_data)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">to_one_hot</span><span class="params">(labels, dimension=<span class="number">46</span>)</span>:</span></span><br><span class="line">    results = np.zeros((len(labels), dimension))</span><br><span class="line">    <span class="keyword">for</span> i, label <span class="keyword">in</span> enumerate(labels):</span><br><span class="line">        results[i, label] = <span class="number">1.</span></span><br><span class="line">    <span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line">one_hot_train_labels = to_one_hot(train_labels)</span><br><span class="line">one_hot_test_labels = to_one_hot(test_labels)</span><br></pre></td></tr></table></figure>
<p>注意，Keras 内置方法可以实现One-hot操作:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.utils.np_utils <span class="keyword">import</span> to_categorical</span><br><span class="line"></span><br><span class="line">one_hot_train_labels = to_categorical(train_labels)</span><br><span class="line">one_hot_test_labels = to_categorical(test_labels)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> keras.models <span class="keyword">as</span> models</span><br><span class="line"><span class="keyword">import</span> keras.layers <span class="keyword">as</span> layers</span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">512</span>, activation=<span class="string">"relu"</span>, input_shape=(<span class="number">10000</span>,)))</span><br><span class="line">model.add(layers.Dense(<span class="number">512</span>, activation=<span class="string">"relu"</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">46</span>, activation=<span class="string">"softmax"</span>))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.compile(optimizer=<span class="string">"rmsprop"</span>,</span><br><span class="line">             loss=<span class="string">"categorical_crossentropy"</span>,</span><br><span class="line">             metrics=[<span class="string">"accuracy"</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x_val = x_train[:<span class="number">1000</span>]</span><br><span class="line">partial_x_train = x_train[<span class="number">1000</span>:]</span><br><span class="line">y_val = one_hot_train_labels[:<span class="number">1000</span>]</span><br><span class="line">partial_y_train = one_hot_train_labels[<span class="number">1000</span>:]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">history = model.fit(partial_x_train,</span><br><span class="line">                   partial_y_train,</span><br><span class="line">                   epochs=<span class="number">20</span>,</span><br><span class="line">                   batch_size=<span class="number">512</span>,</span><br><span class="line">                   validation_data=(x_val, y_val))</span><br></pre></td></tr></table></figure>
<pre><code>Train on 7982 samples, validate on 1000 samples
Epoch 1/20
7982/7982 [==============================] - 2s 272us/step - loss: 1.8693 - accuracy: 0.5712 - val_loss: 1.2307 - val_accuracy: 0.7020
Epoch 2/20
7982/7982 [==============================] - 2s 258us/step - loss: 0.8578 - accuracy: 0.8029 - val_loss: 0.9550 - val_accuracy: 0.7770
Epoch 3/20
7982/7982 [==============================] - 2s 257us/step - loss: 0.4959 - accuracy: 0.8861 - val_loss: 0.8886 - val_accuracy: 0.8010
Epoch 4/20
7982/7982 [==============================] - 2s 269us/step - loss: 0.3254 - accuracy: 0.9247 - val_loss: 0.8109 - val_accuracy: 0.8330
Epoch 5/20
7982/7982 [==============================] - 2s 266us/step - loss: 0.2040 - accuracy: 0.9491 - val_loss: 0.8889 - val_accuracy: 0.8050
Epoch 6/20
7982/7982 [==============================] - 2s 257us/step - loss: 0.1730 - accuracy: 0.9520 - val_loss: 0.8479 - val_accuracy: 0.8200
Epoch 7/20
7982/7982 [==============================] - 2s 247us/step - loss: 0.1677 - accuracy: 0.9520 - val_loss: 0.9323 - val_accuracy: 0.8040
Epoch 8/20
7982/7982 [==============================] - 2s 245us/step - loss: 0.1376 - accuracy: 0.9546 - val_loss: 0.8941 - val_accuracy: 0.8190
Epoch 9/20
7982/7982 [==============================] - 2s 256us/step - loss: 0.1273 - accuracy: 0.9564 - val_loss: 0.9124 - val_accuracy: 0.8190
Epoch 10/20
7982/7982 [==============================] - 2s 252us/step - loss: 0.1188 - accuracy: 0.9559 - val_loss: 1.0038 - val_accuracy: 0.7970
Epoch 11/20
7982/7982 [==============================] - 2s 264us/step - loss: 0.1116 - accuracy: 0.9555 - val_loss: 0.9859 - val_accuracy: 0.8120
Epoch 12/20
7982/7982 [==============================] - 2s 256us/step - loss: 0.1014 - accuracy: 0.9578 - val_loss: 1.1145 - val_accuracy: 0.7910
Epoch 13/20
7982/7982 [==============================] - 2s 251us/step - loss: 0.1018 - accuracy: 0.9554 - val_loss: 1.0680 - val_accuracy: 0.8020
Epoch 14/20
7982/7982 [==============================] - 2s 258us/step - loss: 0.0950 - accuracy: 0.9568 - val_loss: 1.1566 - val_accuracy: 0.8000
Epoch 15/20
7982/7982 [==============================] - 2s 284us/step - loss: 0.0906 - accuracy: 0.9578 - val_loss: 1.1965 - val_accuracy: 0.8040
Epoch 16/20
7982/7982 [==============================] - 2s 289us/step - loss: 0.0843 - accuracy: 0.9562 - val_loss: 1.1994 - val_accuracy: 0.8020
Epoch 17/20
7982/7982 [==============================] - 2s 263us/step - loss: 0.0834 - accuracy: 0.9575 - val_loss: 1.2736 - val_accuracy: 0.8060
Epoch 18/20
7982/7982 [==============================] - 2s 249us/step - loss: 0.0786 - accuracy: 0.9559 - val_loss: 1.3329 - val_accuracy: 0.8050
Epoch 19/20
7982/7982 [==============================] - 2s 255us/step - loss: 0.0771 - accuracy: 0.9592 - val_loss: 1.7559 - val_accuracy: 0.7720
Epoch 20/20
7982/7982 [==============================] - 2s 253us/step - loss: 0.0768 - accuracy: 0.9569 - val_loss: 1.4354 - val_accuracy: 0.8040
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">history_dict = history.history</span><br><span class="line">loss = history_dict[<span class="string">"loss"</span>]</span><br><span class="line">val_loss = history_dict[<span class="string">"val_loss"</span>]</span><br><span class="line">epochs = range(<span class="number">1</span>, len(loss)+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, loss, <span class="string">'bo'</span>, label=<span class="string">'Training loss'</span>)</span><br><span class="line">plt.plot(epochs, val_loss, <span class="string">'b'</span>, label=<span class="string">'Validation loss'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation loss'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Epochs'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/keras/output_42_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">acc = history.history[<span class="string">'accuracy'</span>]</span><br><span class="line">val_acc = history.history[<span class="string">'val_accuracy'</span>]</span><br><span class="line">plt.plot(epochs, acc, <span class="string">'bo'</span>, label=<span class="string">'Training acc'</span>)</span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">'b'</span>, label=<span class="string">'Validation acc'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation accuracy'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Epochs'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Accuracy'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/keras/output_43_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 训练数据在第五轮左右开始过拟合</span></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">"relu"</span>, input_shape=(<span class="number">10000</span>,)))</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">"relu"</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">46</span>, activation=<span class="string">"softmax"</span>))</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="string">"rmsprop"</span>,</span><br><span class="line">             loss=<span class="string">"categorical_crossentropy"</span>,</span><br><span class="line">             metrics=[<span class="string">"accuracy"</span>])</span><br><span class="line">model.fit(x_train,</span><br><span class="line">         one_hot_train_labels,</span><br><span class="line">         epochs=<span class="number">5</span>,</span><br><span class="line">         batch_size=<span class="number">512</span>)</span><br><span class="line">results = model.evaluate(x_test, one_hot_test_labels)</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1/5
8982/8982 [==============================] - 1s 84us/step - loss: 2.4658 - accuracy: 0.5529
Epoch 2/5
8982/8982 [==============================] - 1s 77us/step - loss: 1.3174 - accuracy: 0.7286
Epoch 3/5
8982/8982 [==============================] - 1s 79us/step - loss: 0.9746 - accuracy: 0.7960
Epoch 4/5
8982/8982 [==============================] - 1s 77us/step - loss: 0.7625 - accuracy: 0.8398
Epoch 5/5
8982/8982 [==============================] - 1s 77us/step - loss: 0.6018 - accuracy: 0.8720
2246/2246 [==============================] - 0s 118us/step
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">results</span><br></pre></td></tr></table></figure>
<pre><code>[0.9859163759015865, 0.7822796106338501]
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 完全随机的分类精度</span></span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line">test_labels_copy = copy.copy(test_labels)</span><br><span class="line">np.random.shuffle(test_labels_copy)</span><br><span class="line">hits_array = np.array(test_labels) == np.array(test_labels_copy)</span><br><span class="line">print(float(np.sum(hits_array))/len(test_labels))</span><br></pre></td></tr></table></figure>
<pre><code>0.1861086375779163
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">predictions = model.predict(x_test)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">predictions[<span class="number">0</span>].shape</span><br></pre></td></tr></table></figure>
<pre><code>(46,)
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.sum(predictions[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<pre><code>0.9999999
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.argmax(predictions[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<pre><code>3
</code></pre><h2 id="处理标签的另一种方法"><a href="#处理标签的另一种方法" class="headerlink" title="处理标签的另一种方法"></a>处理标签的另一种方法</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y_train = np.array(train_labels)</span><br><span class="line">y_test = np.array(test_labels)</span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">"relu"</span>, input_shape=(<span class="number">10000</span>,)))</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">"relu"</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">46</span>, activation=<span class="string">"softmax"</span>))</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="string">"rmsprop"</span>,</span><br><span class="line">             loss=<span class="string">"sparse_categorical_crossentropy"</span>,</span><br><span class="line">             metrics=[<span class="string">"acc"</span>])</span><br><span class="line">model.fit(x_train,</span><br><span class="line">         y_train,</span><br><span class="line">         epochs=<span class="number">5</span>,</span><br><span class="line">         batch_size=<span class="number">512</span>)</span><br><span class="line">results = model.evaluate(x_test, y_test)</span><br><span class="line">print(results)</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1/5
8982/8982 [==============================] - 1s 85us/step - loss: 2.6402 - acc: 0.5324
Epoch 2/5
8982/8982 [==============================] - 1s 80us/step - loss: 1.3306 - acc: 0.7237
Epoch 3/5
8982/8982 [==============================] - 1s 75us/step - loss: 0.9743 - acc: 0.7951
Epoch 4/5
8982/8982 [==============================] - 1s 76us/step - loss: 0.7556 - acc: 0.8447
Epoch 5/5
8982/8982 [==============================] - 1s 76us/step - loss: 0.5990 - acc: 0.8785
2246/2246 [==============================] - 0s 104us/step
[0.9927649695429543, 0.7724844217300415]
</code></pre><h1 id="预测房价：回归问题"><a href="#预测房价：回归问题" class="headerlink" title="预测房价：回归问题"></a>预测房价：回归问题</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> boston_housing</span><br><span class="line">(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(train_data.shape)</span><br><span class="line">print(test_data.shape)</span><br></pre></td></tr></table></figure>
<pre><code>(404, 13)
(102, 13)
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_targets[:<span class="number">10</span>]</span><br></pre></td></tr></table></figure>
<pre><code>array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4])
</code></pre><p>将取值范围差异很大的数据输入到神经网络中，这是有问题的。网络可能会自动适应这种<br>取值范围不同的数据，但学习肯定变得更加困难。对于这种数据，普遍采用的最佳实践是对每<br>个特征做标准化，即对于输入数据的每个特征（输入数据矩阵中的列），减去特征平均值，再除<br>以标准差，这样得到的特征平均值为0，标准差为1</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mean = train_data.mean(axis=<span class="number">0</span>)</span><br><span class="line">train_data -= mean</span><br><span class="line">std = train_data.std(axis=<span class="number">0</span>)</span><br><span class="line">train_data /= std</span><br><span class="line"></span><br><span class="line">test_data -= mean</span><br><span class="line">test_data /= std</span><br></pre></td></tr></table></figure>
<p>注意，用于测试数据标准化的均值和标准差都是在训练数据上计算得到的。在工作流程中，<br>你不能使用在测试数据上计算得到的任何结果，即使是像数据标准化这么简单的事情也不行。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_model</span><span class="params">()</span>:</span></span><br><span class="line">    model = models.Sequential()</span><br><span class="line">    model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">"relu"</span>, input_shape=(train_data.shape[<span class="number">1</span>],)))</span><br><span class="line">    model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">"relu"</span>))</span><br><span class="line">    model.add(layers.Dense(<span class="number">1</span>))</span><br><span class="line">    model.compile(optimizer=<span class="string">"rmsprop"</span>, loss=<span class="string">"mse"</span>, metrics=[<span class="string">"mae"</span>])</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<h2 id="K折验证"><a href="#K折验证" class="headerlink" title="K折验证"></a>K折验证</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">k = <span class="number">4</span></span><br><span class="line">num_val_samples = len(train_data) // k</span><br><span class="line">num_epochs = <span class="number">100</span></span><br><span class="line">all_scores = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">    print(<span class="string">"Processing fold #"</span>, i)</span><br><span class="line">    val_data = train_data[i*num_val_samples: (i+<span class="number">1</span>)*num_val_samples]</span><br><span class="line">    val_targets = train_targets[i*num_val_samples:(i+<span class="number">1</span>)*num_val_samples]</span><br><span class="line">    partial_train_data = np.concatenate([train_data[:i*num_val_samples], train_data[(i+<span class="number">1</span>)*num_val_samples:]], axis=<span class="number">0</span>)</span><br><span class="line">    partial_train_targets = np.concatenate([train_targets[:i*num_val_samples], train_targets[(i+<span class="number">1</span>)*num_val_samples:]], axis=<span class="number">0</span>)</span><br><span class="line">    model = build_model()</span><br><span class="line">    model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=<span class="number">1</span>, verbose=<span class="number">0</span>)</span><br><span class="line">    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=<span class="number">0</span>)</span><br><span class="line">    all_scores.append(val_mae)</span><br><span class="line">print(all_scores)</span><br><span class="line">print(np.mean(all_scores))</span><br></pre></td></tr></table></figure>
<pre><code>Processing fold # 0
Processing fold # 1
Processing fold # 2
Processing fold # 3
[2.0739996433258057, 2.4122469425201416, 2.454885959625244, 2.5617122650146484]
2.37571120262146
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num_epochs = <span class="number">500</span></span><br><span class="line">all_mae_histories = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">    print(<span class="string">'processing fold #'</span>, i)</span><br><span class="line">    val_data = train_data[i * num_val_samples: (i + <span class="number">1</span>) * num_val_samples]</span><br><span class="line">    val_targets = train_targets[i * num_val_samples: (i + <span class="number">1</span>) * num_val_samples]</span><br><span class="line">    partial_train_data = np.concatenate(</span><br><span class="line">        [train_data[:i * num_val_samples],</span><br><span class="line">         train_data[(i + <span class="number">1</span>) * num_val_samples:]],</span><br><span class="line">         axis=<span class="number">0</span>)</span><br><span class="line">    partial_train_targets = np.concatenate(</span><br><span class="line">        [train_targets[:i * num_val_samples],</span><br><span class="line">         train_targets[(i + <span class="number">1</span>) * num_val_samples:]],</span><br><span class="line">        axis=<span class="number">0</span>)</span><br><span class="line">    model = build_model()</span><br><span class="line">    history = model.fit(partial_train_data, partial_train_targets,</span><br><span class="line">    validation_data=(val_data, val_targets),</span><br><span class="line">    epochs=num_epochs, batch_size=<span class="number">1</span>, verbose=<span class="number">0</span>)</span><br><span class="line">    mae_history = history.history[<span class="string">'mae'</span>]</span><br><span class="line">    all_mae_histories.append(mae_history)</span><br><span class="line"></span><br><span class="line">average_mae_history = [np.mean([x[i] <span class="keyword">for</span> x <span class="keyword">in</span> all_mae_histories]) <span class="keyword">for</span> i <span class="keyword">in</span> range(num_epochs)]</span><br></pre></td></tr></table></figure>
<pre><code>processing fold # 0
processing fold # 1
processing fold # 2
processing fold # 3
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.plot(range(<span class="number">1</span>, len(average_mae_history) + <span class="number">1</span>), average_mae_history)</span><br><span class="line">plt.xlabel(<span class="string">'Epochs'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Validation MAE'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%A5%E9%97%A8/output_64_0.png" alt="png"></p>
<p>因为纵轴的范围较大，且数据方差相对较大，所以难以看清这张图的规律。我们来重新绘制一张图。</p>
<ul>
<li>删除前 10 个数据点，因为它们的取值范围与曲线上的其他点不同。</li>
<li>将每个数据点替换为前面数据点的指数移动平均值，以得到光滑的曲线。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">smooth_curve</span><span class="params">(points, factor=<span class="number">0.9</span>)</span>:</span></span><br><span class="line">    smoothed_points = []</span><br><span class="line">    <span class="keyword">for</span> point <span class="keyword">in</span> points:</span><br><span class="line">        <span class="keyword">if</span> smoothed_points:</span><br><span class="line">            previous = smoothed_points[<span class="number">-1</span>]</span><br><span class="line">            smoothed_points.append(previous * factor + point * (<span class="number">1</span> - factor))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            smoothed_points.append(point)</span><br><span class="line">    <span class="keyword">return</span> smoothed_points</span><br><span class="line"></span><br><span class="line">smooth_mae_history = smooth_curve(average_mae_history[<span class="number">10</span>:])</span><br><span class="line">plt.plot(range(<span class="number">1</span>, len(smooth_mae_history) + <span class="number">1</span>), smooth_mae_history)</span><br><span class="line">plt.xlabel(<span class="string">'Epochs'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Validation MAE'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%A5%E9%97%A8/output_66_0.png" alt="png"></p>
<blockquote>
<p>注：以上内容均直接搬运自个人的jupyter notebook，参考书籍为《Python深度学习》，注释未到位之处请多谅解，有需要对哪些地方补充注释的可以在下方留言</p>
</blockquote>
]]></content>
      <categories>
        <category>Keras</category>
      </categories>
  </entry>
  <entry>
    <title>Tensorflow 神经网络搭建（一）—— 组件构建与基础使用</title>
    <url>/posts/acf1f2c0.html</url>
    <content><![CDATA[<p>这一节我们对tensorflow的一些最基本的函数进行简单调用举例，当然调用函数前大家有必要自己了解神经网络的一些基本常识，这里给大家推荐邱锡鹏老师的一本书《神经网络与深度学习》，以及Raul Rojas的《Neural Networks》，这两本书足够对神经网络与深度学习的基础知识有一个完整清晰的认识，下面直接进入tensorflow的基础语法尝试。</p>
<h1 id="第一个例子"><a href="#第一个例子" class="headerlink" title="第一个例子"></a>第一个例子</h1><p>下面看第一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x_data = np.random.rand(<span class="number">100</span>).astype(np.float32)</span><br><span class="line">y_data = x_data*<span class="number">0.1</span> + <span class="number">0.3</span></span><br><span class="line"></span><br><span class="line">Weights = tf.Variable(tf.random_uniform([<span class="number">1</span>], <span class="number">-1.0</span>, <span class="number">1.0</span>))</span><br><span class="line">biases = tf.Variable(tf.zeros([<span class="number">1</span>]))</span><br><span class="line">y = Weights*x_data + biases</span><br><span class="line"></span><br><span class="line">loss = tf.reduce_mean(tf.square(y-y_data))</span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.5</span>)</span><br><span class="line">train = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line">init = tf.initialize_all_variables()</span><br><span class="line"></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">200</span>):</span><br><span class="line">    sess.run(train)</span><br><span class="line">    <span class="keyword">if</span> step % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">        print(step, sess.run(Weights), sess.run(biases))</span><br></pre></td></tr></table></figure>
<ul>
<li>代码中第1行导入tensorflow包</li>
<li>第3行和第4行定义x和y变量，其中x变量是根据标准正态分布随机生成的100个数</li>
<li>第7、8行分别定义变量Weights和biases，分别声明为tf.Variable()</li>
<li>第9行根据这两个变量生成一个预测的y值</li>
<li>第11行至第13行分别定义损失函数形式，优化器和训练器</li>
<li>第15行的initialize_all_variables()函数十分重要，因为前面定义的所有变量都只是定义，而没有初始化（C++中的实例化）</li>
<li>第17-18行分别定义了Session()并执行初始化</li>
<li>最后四行则是打印出运行结果，每隔20轮打印出权重参数和偏置参数</li>
</ul>
<p>至此结束，我们看看打印结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0 [0.52235436] [0.0773498]</span><br><span class="line">20 [0.2182928] [0.23877653]</span><br><span class="line">40 [0.133002] [0.28291953]</span><br><span class="line">60 [0.1092071] [0.2952348]</span><br><span class="line">80 [0.10256864] [0.2986706]</span><br><span class="line">100 [0.10071664] [0.29962912]</span><br><span class="line">120 [0.10019994] [0.29989654]</span><br><span class="line">140 [0.1000558] [0.29997113]</span><br><span class="line">160 [0.10001557] [0.29999197]</span><br><span class="line">180 [0.10000437] [0.29999775]</span><br></pre></td></tr></table></figure>
<h1 id="Session的打开方式"><a href="#Session的打开方式" class="headerlink" title="Session的打开方式"></a>Session的打开方式</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">matrix1 = tf.constant([[<span class="number">3</span>,<span class="number">3</span>]])</span><br><span class="line">matrix2 = tf.constant([[<span class="number">2</span>],[<span class="number">2</span>]])</span><br><span class="line">product = tf.multiply(matrix1, matrix2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方式一</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line">result = sess.run(product)</span><br><span class="line">print(result)</span><br><span class="line">sess.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># [[6 6]</span></span><br><span class="line"><span class="comment"># [6 6]]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 方式二</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    result2 = sess.run(product)</span><br><span class="line">    print(result2)</span><br></pre></td></tr></table></figure>
<p>由于Session()打开之后就一定要关闭，和平时操作文件时使用到的with open语句类似，方式二的语句可以避免close()操作，使代码更美观。</p>
<h1 id="Variable变量"><a href="#Variable变量" class="headerlink" title="Variable变量"></a>Variable变量</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">state = tf.Variable(<span class="number">0</span>, name=<span class="string">"counter"</span>)</span><br><span class="line">print(state.name)</span><br><span class="line"></span><br><span class="line">one = tf.constant(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">new_value = tf.add(state, one)</span><br><span class="line">update = tf.assign(state, new_value)</span><br><span class="line"></span><br><span class="line">init = tf.initialize_all_variables()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">        sess.run(update)</span><br><span class="line">        print(sess.run(state))</span><br></pre></td></tr></table></figure>
<p>变量一定要initialize！</p>
<h1 id="placeholder"><a href="#placeholder" class="headerlink" title="placeholder"></a>placeholder</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">input1 = tf.placeholder(tf.float32)</span><br><span class="line">input2 = tf.placeholder(tf.float32)</span><br><span class="line"></span><br><span class="line">output = tf.multiply(input1,input2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(sess.run(output, feed_dict=&#123;input1:[<span class="number">7.</span>], input2:[<span class="number">2.4</span>]&#125;))</span><br><span class="line"><span class="comment"># [16.800001]</span></span><br></pre></td></tr></table></figure>
<p>placeholder一共有三个参数，含义分别是：</p>
<ul>
<li>dtype：数据类型。常用的是tf.float32,tf.float64等数值类型</li>
<li>shape：数据形状。默认是None，就是一维值，也可以是多维，比如[2,3], [None, 3]表示列是3，行不定</li>
<li>name：名称。</li>
</ul>
<p>在训练神经网络时需要每次提供一个批量的训练样本，如果每次迭代选取的数据要通过常量表示，那么TensorFlow 的计算图会非常大。因为每增加一个常量，TensorFlow 都会在计算图中增加一个结点，所以说拥有几百万次迭代的神经网络会拥有极其庞大的计算图，而占位符却可以解决这一点，它只会拥有占位符这一个结点，Placeholder机制的出现就是为了解决这个问题，我们在编程的时候只需要把数据通过placeholder传入tensorflow计算图即可。另外，若变量维度不确定，可以填入None。</p>
<h1 id="Activation实例"><a href="#Activation实例" class="headerlink" title="Activation实例"></a>Activation实例</h1><p>下面介绍Activation函数的使用：</p>
<h2 id="定义添加层函数"><a href="#定义添加层函数" class="headerlink" title="定义添加层函数"></a>定义添加层函数</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_layer</span><span class="params">(inputs, in_size, out_size, activation_function=None)</span>:</span></span><br><span class="line">    Weights = tf.Variable(tf.random_normal([in_size, out_size]))</span><br><span class="line">    biases = tf.Variable(tf.zeros([<span class="number">1</span>, out_size]) + <span class="number">0.1</span>)</span><br><span class="line">    Wx_plus_b = tf.matmul(inputs, Weights) + biases</span><br><span class="line">    <span class="keyword">if</span> activation_function <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        outputs = Wx_plus_b</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        outputs = activation_function(Wx_plus_b)</span><br><span class="line">    <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure>
<h2 id="建立神经网络结构"><a href="#建立神经网络结构" class="headerlink" title="建立神经网络结构"></a>建立神经网络结构</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x_data = np.linspace(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">300</span>)[:,np.newaxis]</span><br><span class="line">noise = np.random.normal(<span class="number">0</span>, <span class="number">0.05</span>, x_data.shape)</span><br><span class="line">y_data = np.square(x_data) - <span class="number">0.5</span> + noise</span><br><span class="line"></span><br><span class="line">xs = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>])</span><br><span class="line">ys = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">l1 = add_layer(xs, <span class="number">1</span>, <span class="number">10</span>, activation_function=tf.nn.relu)</span><br><span class="line">prediction = add_layer(l1, <span class="number">10</span>, <span class="number">1</span>, activation_function=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction), reduction_indices=[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.1</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line">init = tf.initialize_all_variables()</span><br><span class="line"></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    sess.run(train_step, feed_dict=&#123;xs:x_data, ys:y_data&#125;)</span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">50</span>:</span><br><span class="line">        print(sess.run(loss, feed_dict=&#123;xs:x_data, ys:y_data&#125;))</span><br></pre></td></tr></table></figure>
<p>上面这些代码代价应能看懂，与第一个例子类似，只是在这里我们定义了一个新的Activation Layer，读者自行分析总结即可。</p>
<h1 id="结果可视化"><a href="#结果可视化" class="headerlink" title="结果可视化"></a>结果可视化</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x_data = np.linspace(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">300</span>)[:,np.newaxis]</span><br><span class="line">noise = np.random.normal(<span class="number">0</span>, <span class="number">0.05</span>, x_data.shape)</span><br><span class="line">y_data = np.square(x_data) - <span class="number">0.5</span> + noise</span><br><span class="line"></span><br><span class="line">xs = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>])</span><br><span class="line">ys = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">l1 = add_layer(xs, <span class="number">1</span>, <span class="number">10</span>, activation_function=tf.nn.relu)</span><br><span class="line">prediction = add_layer(l1, <span class="number">10</span>, <span class="number">1</span>, activation_function=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction), reduction_indices=[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.1</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line">init = tf.initialize_all_variables()</span><br><span class="line"></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line">fig = plt.figure()   <span class="comment"># (*)</span></span><br><span class="line">ax = fig.add_subplot(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>)   <span class="comment"># (*)</span></span><br><span class="line">ax.scatter(x_data, y_data)   <span class="comment"># (*)</span></span><br><span class="line">plt.ion()   <span class="comment"># (*)</span></span><br><span class="line">plt.show()   <span class="comment"># (*)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    sess.run(train_step, feed_dict=&#123;xs:x_data, ys:y_data&#125;)</span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">50</span>:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            ax.lines.remove(lines[<span class="number">0</span>])   <span class="comment"># (*)</span></span><br><span class="line">        <span class="keyword">except</span> Exception:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        prediction_value = sess.run(prediction, feed_dict=&#123;xs:x_data&#125;)   <span class="comment"># (*)</span></span><br><span class="line">        lines = ax.plot(x_data, prediction_value, <span class="string">"r-"</span>, lw=<span class="number">5</span>)   <span class="comment"># (*)</span></span><br><span class="line">        plt.pause(<span class="number">0.1</span>)   <span class="comment"># (*)</span></span><br></pre></td></tr></table></figure>
<p>重点关注有(*)标记的代码，这些是新增的与画图相关的代码。这些代码能够显示神经网络一步步接近真实值的过程，代码具体含义大家应当都能看懂，其中plt.ion()表示拟合曲线可以自动变化，plt.pause()是控制拟合曲线变化时间间隔的函数，ax.lines.remove是为了使图形界面不要太杂乱，抹掉上一次的拟合曲线。</p>
<h1 id="Tensorboard可视化"><a href="#Tensorboard可视化" class="headerlink" title="Tensorboard可视化"></a>Tensorboard可视化</h1><p>我们基于前面的add_layer函数及神经网络的实现代码进行部分修改，定义一些名称与包含关系，并在终端执行 tensorboard —logdir=’logs/‘ 命令，在浏览器中输入获得的对应网址，即而已获得我们需要的Tensorboard，下面是修改后的代码，注意with tf.name_scope()的用法。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_layer</span><span class="params">(inputs, in_size, out_size, activation_function=None)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">"inputs"</span>):</span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">"weights"</span>):</span><br><span class="line">            Weights = tf.Variable(tf.random_normal([in_size, out_size]), name=<span class="string">"W"</span>)</span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">"biases"</span>):</span><br><span class="line">            biases = tf.Variable(tf.zeros([<span class="number">1</span>, out_size]) + <span class="number">0.1</span>)</span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">"Wx_plus_b"</span>):</span><br><span class="line">            Wx_plus_b = tf.matmul(inputs, Weights) + biases</span><br><span class="line">        <span class="keyword">if</span> activation_function <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            outputs = Wx_plus_b</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            outputs = activation_function(Wx_plus_b)</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line">x_data = np.linspace(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">300</span>)[:,np.newaxis]</span><br><span class="line">noise = np.random.normal(<span class="number">0</span>, <span class="number">0.05</span>, x_data.shape)</span><br><span class="line">y_data = np.square(x_data) - <span class="number">0.5</span> + noise</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"inputs"</span>):</span><br><span class="line">    xs = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>], name=<span class="string">"x_input"</span>)</span><br><span class="line">    ys = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>], name = <span class="string">"y_input"</span>)</span><br><span class="line"></span><br><span class="line">l1 = add_layer(xs, <span class="number">1</span>, <span class="number">10</span>, activation_function=tf.nn.relu)</span><br><span class="line">prediction = add_layer(l1, <span class="number">10</span>, <span class="number">1</span>, activation_function=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"loss"</span>):</span><br><span class="line">    loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction), reduction_indices=[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"train"</span>):</span><br><span class="line">    train_step = tf.train.GradientDescentOptimizer(<span class="number">0.1</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line">init = tf.initialize_all_variables()</span><br><span class="line"></span><br><span class="line">sess = tf.Session()</span><br><span class="line">writer = tf.summary.FileWriter(<span class="string">"logs/"</span>, sess.graph)</span><br><span class="line">sess.run(init)</span><br></pre></td></tr></table></figure>
<p>下面是可视化结果（输入网址后），大家如果想看更清晰的图片可以滑动鼠标滚轮查看。</p>
<p><img src="/posts/Tensorflow/tb1.png" alt></p>
<p>事实上，我们还可以定义直方图，误差折线图等有趣的Tensorboard可视化，运行以下代码，然后试试删除第一行，多运行几次，看看会有什么问题。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tf.reset_default_graph()</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_layer</span><span class="params">(inputs, in_size, out_size, n_layer, activation_function=None)</span>:</span></span><br><span class="line">    layer_name = <span class="string">'layer%s'</span> % n_layer</span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(layer_name):</span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">"weights"</span>):</span><br><span class="line">            Weights = tf.Variable(tf.random_normal([in_size, out_size]), name=<span class="string">"W"</span>)</span><br><span class="line">            tf.summary.histogram(layer_name+<span class="string">'/Weights'</span>, Weights)</span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">"biases"</span>):</span><br><span class="line">            biases = tf.Variable(tf.zeros([<span class="number">1</span>, out_size]) + <span class="number">0.1</span>, name=<span class="string">"b"</span>)</span><br><span class="line">            tf.summary.histogram(layer_name+<span class="string">'/biases'</span>, Weights)</span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">"Wx_plus_b"</span>):</span><br><span class="line">            Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases)</span><br><span class="line">        <span class="keyword">if</span> activation_function <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            outputs = Wx_plus_b</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            outputs = activation_function(Wx_plus_b)</span><br><span class="line">            tf.summary.histogram(layer_name+<span class="string">'/outputs'</span>, outputs)</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line">x_data = np.linspace(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">300</span>)[:,np.newaxis]</span><br><span class="line">noise = np.random.normal(<span class="number">0</span>, <span class="number">0.05</span>, x_data.shape)</span><br><span class="line">y_data = np.square(x_data) - <span class="number">0.5</span> + noise</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"inputs"</span>):</span><br><span class="line">    xs = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>], name=<span class="string">"x_input"</span>)</span><br><span class="line">    ys = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>], name = <span class="string">"y_input"</span>)</span><br><span class="line"></span><br><span class="line">l1 = add_layer(xs, <span class="number">1</span>, <span class="number">10</span>, n_layer=<span class="number">1</span>, activation_function=tf.nn.relu)</span><br><span class="line">prediction = add_layer(l1, <span class="number">10</span>, <span class="number">1</span>, n_layer=<span class="number">2</span>, activation_function=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"loss"</span>):</span><br><span class="line">    loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction), reduction_indices=[<span class="number">1</span>]))</span><br><span class="line">    <span class="comment"># 会在Events显示</span></span><br><span class="line">    tf.summary.scalar(<span class="string">"loss"</span>, loss)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"train"</span>):</span><br><span class="line">    train_step = tf.train.GradientDescentOptimizer(<span class="number">0.1</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line">init = tf.initialize_all_variables()</span><br><span class="line"></span><br><span class="line">sess = tf.Session()</span><br><span class="line">merged = tf.summary.merge_all()</span><br><span class="line">writer = tf.summary.FileWriter(<span class="string">"logs/"</span>, sess.graph)</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    sess.run(train_step,feed_dict=&#123;xs:x_data, ys:y_data&#125;)</span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">        result = sess.run(merged, feed_dict=&#123;xs:x_data, ys:y_data&#125;)</span><br><span class="line">        writer.add_summary(result, i)</span><br></pre></td></tr></table></figure>
<p>同样的，我们运行tensorboard —logdir=’logs/‘，进入给出的网址，我们可以在scalars栏看到下图：</p>
<p><img src="/Pic/Tensorflow/tb2.png" alt></p>
<p>这正是我们定义的tf.summary.scalar(“loss”, loss)，找到上面源代码看看是如何使用的。</p>
<p>然后我们看到Histograms栏，我们会发现前面使用tf.summary.histogram()定义的一些图都在这里体现出来了：</p>
<p><img src="/Pic/Tensorflow/tb3.png" alt></p>
<h1 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h1><p>我们看一看MNIST手写体分类的数据集实验，大家如果接触过sklearn就会有一些这个数据集的印象，大概就是从手写体的1到9中训练出能够分辨出这些手写数字的实际数字的算法，下面我们直接用tensorflow实现之：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"MNIST_data"</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_layer</span><span class="params">(inputs, in_size, out_size, activation_function=None)</span>:</span></span><br><span class="line">    Weights = tf.Variable(tf.random_normal([in_size, out_size]))</span><br><span class="line">    biases = tf.Variable(tf.zeros([<span class="number">1</span>, out_size]) + <span class="number">0.1</span>)</span><br><span class="line">    Wx_plus_b = tf.matmul(inputs, Weights) + biases</span><br><span class="line">    <span class="keyword">if</span> activation_function <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        outputs = Wx_plus_b</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        outputs = activation_function(Wx_plus_b)</span><br><span class="line">    <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_accuracy</span><span class="params">(v_xs, v_ys)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> predictions</span><br><span class="line">    y__pre = sess.run(prediction, feed_dict=&#123;xs:v_xs&#125;)</span><br><span class="line">    <span class="comment"># 对比预测和实际是否相等</span></span><br><span class="line">    correct_prediction = tf.equal(tf.argmax(y__pre, <span class="number">1</span>), tf.argmax(v_ys, <span class="number">1</span>))</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line">    <span class="comment"># result是百分比,越高越准确</span></span><br><span class="line">    result = sess.run(accuracy, feed_dict=&#123;xs:v_xs, ys:v_ys&#125;)</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">xs = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">784</span>]) <span class="comment"># 28*28</span></span><br><span class="line">ys = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line">prediction = add_layer(xs, <span class="number">784</span>, <span class="number">10</span>, activation_function=tf.nn.softmax)</span><br><span class="line"></span><br><span class="line">cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction), reduction_indices=[<span class="number">1</span>]))</span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.5</span>).minimize(cross_entropy)</span><br><span class="line"></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.initialize_all_variables())</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    batch_xs, batch_ys = mnist.train.next_batch(<span class="number">100</span>)</span><br><span class="line">    sess.run(train_step, feed_dict=&#123;xs:batch_xs, ys:batch_ys&#125;)</span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">        print(compute_accuracy(mnist.test.images, mnist.test.labels))</span><br></pre></td></tr></table></figure>
<p>运行这段程序时会下载MNIST数据集，并与前面类似定义输入、训练集测试集、损失函数等等，这里使用的loss function：cross_entropy是适用于分类算法中的常用损失函数，感兴趣的话大家可以另行查找相关资料学习。</p>
<h1 id="避免overfitting"><a href="#避免overfitting" class="headerlink" title="避免overfitting"></a>避免overfitting</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_digits</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelBinarizer</span><br><span class="line"></span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">digits = load_digits()</span><br><span class="line">X = digits.data</span><br><span class="line">y = digits.target</span><br><span class="line">y = LabelBinarizer().fit_transform(y)</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">.3</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_layer</span><span class="params">(inputs, in_size, out_size, layer_name, activation_function=None, )</span>:</span></span><br><span class="line">    <span class="comment"># add one more layer and return the output of this layer</span></span><br><span class="line">    Weights = tf.Variable(tf.random_normal([in_size, out_size]))</span><br><span class="line">    biases = tf.Variable(tf.zeros([<span class="number">1</span>, out_size]) + <span class="number">0.1</span>, )</span><br><span class="line">    Wx_plus_b = tf.matmul(inputs, Weights) + biases</span><br><span class="line">    <span class="comment"># here to dropout</span></span><br><span class="line">    Wx_plus_b = tf.nn.dropout(Wx_plus_b, keep_prob)</span><br><span class="line">    <span class="keyword">if</span> activation_function <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        outputs = Wx_plus_b</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        outputs = activation_function(Wx_plus_b, )</span><br><span class="line">    tf.summary.histogram(layer_name + <span class="string">'/outputs'</span>, outputs)</span><br><span class="line">    <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># define placeholder for inputs to network</span></span><br><span class="line">keep_prob = tf.placeholder(tf.float32)</span><br><span class="line">xs = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">64</span>])  <span class="comment"># 8x8</span></span><br><span class="line">ys = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># add output layer</span></span><br><span class="line">l1 = add_layer(xs, <span class="number">64</span>, <span class="number">50</span>, <span class="string">'l1'</span>, activation_function=tf.nn.tanh)</span><br><span class="line">prediction = add_layer(l1, <span class="number">50</span>, <span class="number">10</span>, <span class="string">'l2'</span>, activation_function=tf.nn.softmax)</span><br><span class="line"></span><br><span class="line"><span class="comment"># the loss between prediction and real data</span></span><br><span class="line">cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),</span><br><span class="line">                                              reduction_indices=[<span class="number">1</span>]))  <span class="comment"># loss</span></span><br><span class="line">tf.summary.scalar(<span class="string">'loss'</span>, cross_entropy)</span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.5</span>).minimize(cross_entropy)</span><br><span class="line"></span><br><span class="line">sess = tf.Session()</span><br><span class="line">merged = tf.summary.merge_all()</span><br><span class="line"><span class="comment"># summary writer goes in here</span></span><br><span class="line">train_writer = tf.summary.FileWriter(<span class="string">"logs/train"</span>, sess.graph)</span><br><span class="line">test_writer = tf.summary.FileWriter(<span class="string">"logs/test"</span>, sess.graph)</span><br><span class="line"></span><br><span class="line"><span class="comment"># tf.initialize_all_variables() no long valid from</span></span><br><span class="line"><span class="comment"># 2017-03-02 if using tensorflow &gt;= 0.12</span></span><br><span class="line"><span class="keyword">if</span> int((tf.__version__).split(<span class="string">'.'</span>)[<span class="number">1</span>]) &lt; <span class="number">12</span> <span class="keyword">and</span> int((tf.__version__).split(<span class="string">'.'</span>)[<span class="number">0</span>]) &lt; <span class="number">1</span>:</span><br><span class="line">    init = tf.initialize_all_variables()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    init = tf.global_variables_initializer()</span><br><span class="line">sess.run(init)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># here to determine the keeping probability</span></span><br><span class="line">    sess.run(train_step, feed_dict=&#123;xs: X_train, ys: y_train, keep_prob: <span class="number">0.5</span>&#125;)</span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># record loss</span></span><br><span class="line">        train_result = sess.run(merged, feed_dict=&#123;xs: X_train, ys: y_train, keep_prob: <span class="number">1</span>&#125;)</span><br><span class="line">        test_result = sess.run(merged, feed_dict=&#123;xs: X_test, ys: y_test, keep_prob: <span class="number">1</span>&#125;)</span><br><span class="line">        train_writer.add_summary(train_result, i)</span><br><span class="line">        test_writer.add_summary(test_result, i)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>以上部分代码参考于MovanZhou的github：<a href="https://github.com/MorvanZhou/tutorials/tree/master/tensorflowTUT" target="_blank" rel="noopener">https://github.com/MorvanZhou/tutorials/tree/master/tensorflowTUT</a></p>
</blockquote>
]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
  </entry>
  <entry>
    <title>CS224n 13_Contextual Representations</title>
    <url>/posts/f2fb8471.html</url>
    <content><![CDATA[<p>前面介绍了glove,word2vec,fasttext，这几个模型解决了词的上下文信息，但是不能解决多义词问题，基于语义环境的词嵌入模型由此被提出解决这一问题。语义环境词嵌入模型的核心在于通过具体的上下文语义环境确定词向量，“一句一词一向量”，其比较典型的代表有ELMo, GPT, Bert等，以下将分别进行介绍：</p>
<h1 id="ELMo"><a href="#ELMo" class="headerlink" title="ELMo"></a>ELMo</h1><p>ELMo(Embeddings from Language Models)利用语言模型通过上下文来确定词向量。在ELMo被提出之前，TagLM被提出了进行语音词嵌入，模型比ELMo简单。其先使用无监督数据预训练词向量和语言模型，接着将词向量和由语言模型得到的单词编码组合作为有标记的序列模型的输入，然后训练有标记的序列模型。其示意图如下：</p>
<p><img src="/posts/NLP/24.jpg" alt></p>
<p>在ELMo中，他们使用的是一个双向的LSTM语言模型，由一个前向和一个后向语言模型构成，目标函数就是取这两个方向语言模型的最大似然：</p>
<p><img src="/posts/NLP/23.jpg" alt></p>
<ul>
<li><strong>A Forward LM</strong></li>
</ul>
<script type="math/tex; mode=display">p(t_1,t_2,...,t_N) = \prod_{k=1}^N p(t_k|t_1,t_2,...,t_{k-1})</script><ul>
<li><strong>A Backward LM</strong></li>
</ul>
<script type="math/tex; mode=display">p(t_1,t_2,...,t_N) = \prod_{k=1}^N p(t_k|t_{k+1},t_{k+2},...,t_{N})</script><ul>
<li><strong>Jointly maximize the log likelihood of the forward and backward directions</strong></li>
</ul>
<script type="math/tex; mode=display">\sum_{k=1}^N (log p(t_k|t_1,t_2,...,t_{k-1};\theta_x,\theta_{LSTM}^{forward},\theta_s) + log p(t_k|t_{k+1},t_{k+2},...,t_{N};\theta_x,\theta_{LSTM}^{backward},\theta_s))</script><p>总结一下，不像传统的词向量，每一个词只对应一个词向量，ELMo利用预训练好的双向语言模型，然后根据具体输入从该语言模型中可以得到上下文依赖的当前词表示（对于不同上下文的同一个词的表示是不一样的），再当成特征加入到具体的NLP有监督模型里。</p>
<h1 id="Open-AI-GPT"><a href="#Open-AI-GPT" class="headerlink" title="Open AI GPT"></a>Open AI GPT</h1><p>他们利用了Transformer网络代替了LSTM作为语言模型来更好的捕获长距离语言结构。</p>
<p>首先我们来看一下他们无监督预训练时的语言模型。他们仍然使用的是标准的语言模型目标函数，即通过前k个词预测当前词，但是在语言模型网络上他们使用了google团队在《Attention is all your need》论文中提出的Transformer解码器作为语言模型。Transformer模型主要是利用自注意力（self-attention）机制的模型（参看我另一篇Bert介绍的博客）。</p>
<p>然后再具体NLP任务有监督微调时，与ELMo当成特征的做法不同，OpenAI GPT不需要再重新对任务构建新的模型结构，而是直接在transformer这个语言模型上的最后一层接上softmax作为任务输出层，然后再对这整个模型进行微调。他们额外发现，如果使用语言模型作为辅助任务，能够提升有监督模型的泛化能力，并且能够加速收敛。</p>
<p>由于不同NLP任务的输入有所不同，在transformer模型的输入上针对不同NLP任务也有所不同。具体如下图，对于分类任务直接讲文本输入即可；对于文本蕴涵任务，需要将前提和假设用一个Delim分割向量拼接后进行输入；对于文本相似度任务，在两个方向上都使用Delim拼接后，进行输入；对于像问答多选择的任务，就是将每个答案和上下文进行拼接进行输入。</p>
<p><img src="/posts/NLP/25.jpg" alt></p>
<h1 id="Bert"><a href="#Bert" class="headerlink" title="Bert"></a>Bert</h1><p>这篇论文中，作者们证明了使用双向的预训练效果更好。其实这篇论文方法的整体框架和GPT类似，是进一步的发展。具体的，他们BERT是使用Transformer的编码器来作为语言模型，在语言模型预训练的时候，提出了两个新的目标任务（即遮挡语言模型MLM和预测下一个句子的任务），最后在11个NLP任务上取得了SOTA。</p>
<p>在语言模型上，BERT使用的是Transformer编码器，并且设计了一个小一点Base结构和一个更大的Large网络结构。步骤大体如下：</p>
<ul>
<li><p>Pre-training Task 1#: Masked LM</p>
<ul>
<li>第一步预训练的目标就是做语言模型，即bidirectional。</li>
<li>意思就是如果使用预训练模型处理其他任务，那人们想要的肯定不止某个词左边的信息，而是左右两边的信息。而考虑到这点的模型ELMo只是将left-to-right和right-to-left分别训练拼接起来。直觉上来讲人们其实想要一个deeply bidirectional的模型，但是普通的LM又无法做到，因为在训练时可能会“穿越”。</li>
<li>在训练过程中随机mask 15%的token，而不是把像CBOW一样把每个词都预测一遍。从结构上看输入输出是长度一样的sequence，这样模型实际上在做sequence-level的LM。</li>
<li>Mask如何做也是有技巧的，如果一直用标记[MASK]代替会影响模型，所以随机mask的时候10%的单词会被替代成其他单词，10%的单词不替换，剩下80%才被替换为[MASK]。要注意的是Masked LM预训练阶段模型是不知道真正被mask的是哪个词，所以模型每个词都要关注。</li>
</ul>
</li>
<li><p>Pre-training Task 2#: Next Sentence Prediction</p>
<ul>
<li>因为涉及到QA和NLI之类的任务，增加了第二个预训练任务，目的是让模型理解两个句子之间的联系。训练的输入是句子A和B，B有一半的几率是A的下一句，输入这两个句子，模型预测B是不是A的下一句。预训练的时候可以达到97-98%的准确度。</li>
</ul>
</li>
<li><p>Fine-tunning</p>
<ul>
<li>分类：对于sequence-level的分类任务，BERT直接取第一个[CLS]token的final hidden state  ，加一层权重后softmax预测label proba： </li>
<li>其他预测任务需要进行一些调整，如图：</li>
</ul>
</li>
</ul>
<p><img src="/posts/NLP/28.jpg" alt></p>
<p>因为大部分参数都和预训练时一样，精调会快一些，所以推荐多试一些参数。</p>
<p>具体见我的另一篇博客：<a href="https://chenk.tech/posts/1424e830.html" target="_blank" rel="noopener">Bert模型解析</a></p>
<h1 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h1><p>对比一下三种语言模型结构，BERT使用的是Transformer编码器，由于self-attention机制，所以模型上下层直接全部互相连接的。而OpenAI GPT使用的是Transformer解码器，它是一个需要从左到右的受限制的Transformer，而ELMo使用的是双向LSTM，虽然是双向的，但是也只是在两个单向的LSTM的最高层进行简单的拼接。所以作者们任务只有BERT是真正在模型所有层中是双向的。</p>
<p><img src="/posts/NLP/27.jpg" alt></p>
<p>而在模型的输入方面，BERT做了更多的细节，如下图。他们使用了WordPiece embedding作为词向量，并加入了位置向量和句子切分向量。并在每一个文本输入前加入了一个CLS向量，后面会有这个向量作为具体的分类向量。</p>
<p><img src="/posts/NLP/26.jpg" alt></p>
<p>近日，百度提出知识增强的语义表示模型 ERNIE（Enhanced Representation from kNowledge IntEgration），并发布了基于 PaddlePaddle 的开源代码与模型，在语言推断、语义相似度、命名实体识别、情感分析、问答匹配等自然语言处理（NLP）各类中文任务上的验证显示，模型效果全面超越 BERT。由此可以看出，预训练模型已成为近来NLP领域的潮流。</p>
<p><em>参考链接</em>：</p>
<blockquote>
<ul>
<li><a href="https://arxiv.org/pdf/1902.06006.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1902.06006.pdf</a></li>
<li><a href="https://blog.csdn.net/skyseezhang/article/details/106951103" target="_blank" rel="noopener">https://blog.csdn.net/skyseezhang/article/details/106951103</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/152471599" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/152471599</a></li>
<li><a href="https://baike.sogou.com/historylemma?lId=177732926" target="_blank" rel="noopener">https://baike.sogou.com/historylemma?lId=177732926</a></li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title>CS224n 12_Subword Models</title>
    <url>/posts/44cf3868.html</url>
    <content><![CDATA[<h1 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h1><h2 id="语音学"><a href="#语音学" class="headerlink" title="语音学"></a>语音学</h2><p>Phonology假定了一组或多组独特的分类单元：音素（作为独特的特征存在）。声音本身在语言中没有意义，Subword是音素的下一级的形态学，是具有意义的最低级别</p>
<p><img src="/posts/NLP/15.png" alt></p>
<p>传统上，（morphemes）词素是最小的语义单位（semantic unit），长得像下面这样：</p>
<script type="math/tex; mode=display">\left[\left[\text {un}\left[[\text { fortun }(\mathrm{e})]_{\text { Root }} \text { ate }\right]_{\text { STEM }}\right]_{\text { STEM }} \text {ly}\right]_{\text { WORD }}</script><h2 id="进击的词汇处理"><a href="#进击的词汇处理" class="headerlink" title="进击的词汇处理"></a>进击的词汇处理</h2><p><strong>深度学习</strong>中的递归神经网络是一种尝试处理更大词汇量的一种方法，更大的词汇量比如一些网络词汇，或者是字符与数字的组合（火星文），例如下面这样：</p>
<p><img src="/posts/NLP/16.png" alt></p>
<p><strong>Character-Level Models</strong>：我们可以拓展词嵌入为字符嵌入，这样我们可以为未知单词生成词嵌入，相似的拼写单词将共享相似的词嵌入，同时能够解决OOV问题。也就是说：连续语言可以作为字符来处理，我们将所有的语言处理均建立在字符序列上，不考虑 word-level。上面两种方法事实上都是可行的（深度学习方法与字符嵌入方法）。</p>
<p>下面是一个简单地Character-Level Model:</p>
<p><img src="/posts/NLP/17.png" alt></p>
<p>从上图可以看出，字符级别的机器翻译效果较单词级别的效果有所提升，但是其有一个很显著的问题是随着模型层数的增大，其运行时间较单词级别的模型增长要快得多，如下图所示：</p>
<p><img src="/posts/NLP/18.png" alt></p>
<h1 id="Character-Level-model"><a href="#Character-Level-model" class="headerlink" title="Character-Level model"></a>Character-Level model</h1><p>Character-Level model大体可以分为两个趋势：<strong>一种是与word-level model完全相同，只不过是输入不同，另一种是hybrid模型，其输入主要为word，需要时再用character。</strong>下面分别介绍这两个方向：</p>
<h2 id="Byte-Pair-Encoding（BPE）"><a href="#Byte-Pair-Encoding（BPE）" class="headerlink" title="Byte Pair Encoding（BPE）"></a>Byte Pair Encoding（BPE）</h2><p>BPE可以看作是pure Character-Level model，属于上述两种趋势的第一种，其核心思想是将经常出现的Byte pair作为一个新的Byte并加入到字典中。它先将文本中所有的character加入字典，然后将经常出现的character对添加到字典中，下面是一个例子：</p>
<p><img src="/posts/NLP/19.png" alt></p>
<p>该模型事先设定好了character对的大小以及字典的大小，当字典达到数量后便停止。另外一个基于character的模型是Character-based LSTM，其整体结构如下：</p>
<p><img src="/posts/NLP/20.png" alt></p>
<p>该结构表明，基于character-level的CNNs + Highway Network能更好地提取语意和结构信息，从而帮助提升机器翻译的效果。</p>
<h2 id="Hybrid-NMT"><a href="#Hybrid-NMT" class="headerlink" title="Hybrid NMT"></a>Hybrid NMT</h2><p>第二种趋势是混合模型，其核心思想是大部分情况用word-level，只在需要时，如出现字典外的词时才使用character-level。如下面这个模型：</p>
<p><img src="/posts/NLP/21.png" alt></p>
<p>该模型当遇到OOV（out of vocabulary）词时，采用vocabulary-level的beam search，寻找最适合的结果。实验结果表明，该模型可以提高机器翻译的效果，尤其是对于一些字典之外的词或者需要音译的词。</p>
<h2 id="FastText-embeddings"><a href="#FastText-embeddings" class="headerlink" title="FastText embeddings"></a>FastText embeddings</h2><p>FastText embeddings的目的在于采用类似于word2vec的模型去生成character-level的词向量，这些词向量对于生僻词或者拥有复杂语法的语言有很好的适应能力。其思路是将一个词拆分成若干个N-grams，经过训练后将这些N-gram的词向量和这个词的词向量进行平均作为最终这个词的词向量，比如where可以拆分成：</p>
<p><img src="/posts/NLP/22.png" alt></p>
<p>最终实验表明，该模型的Word similarity效果要好于原始的word2vec，而且对于一些生僻词有更好的处理能力。</p>
<h1 id="缺点分析"><a href="#缺点分析" class="headerlink" title="缺点分析"></a>缺点分析</h1><ol>
<li>语义上理解可能没那么好</li>
<li>样本多的时候效果略微下降</li>
<li>有一些语言不太适合用形态学</li>
</ol>
<blockquote>
<p>参考链接：</p>
</blockquote>
<ul>
<li><a href="https://www.dazhuanlan.com/2020/03/09/5e65d24e1acfb/" target="_blank" rel="noopener">https://www.dazhuanlan.com/2020/03/09/5e65d24e1acfb/</a></li>
<li><a href="http://web.stanford.edu/class/cs224n/index.html#coursework" target="_blank" rel="noopener">http://web.stanford.edu/class/cs224n/index.html#coursework</a></li>
</ul>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title>CS224n 02_Word Vectors and Word Senses</title>
    <url>/posts/73ac7324.html</url>
    <content><![CDATA[<h1 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h1><h2 id="模型训练步骤"><a href="#模型训练步骤" class="headerlink" title="模型训练步骤"></a>模型训练步骤</h2><p>首先我们回顾一下前面说的Word2vec的main idea：</p>
<p><img src="/posts/NLP/11.png" alt></p>
<p>我们训练这个模型的主要方式是以下四步：</p>
<ol>
<li>给每个单词一个初始向量</li>
<li>遍历整个语料库的所有单词</li>
<li>使用中心单词预测周围的单词</li>
<li>更新单词向量以便更好地预测</li>
</ol>
<h2 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h2><p>那么我们是用什么方法来预测单词呢？我们要降低loss，也就等价于概率最大化，在这里我们利用极大似然函数求解，首先我们定义预测单词的概率：</p>
<script type="math/tex; mode=display">P(o|c) = \frac{exp(u_0^Tv_c)}{\sum_{w\in V}exp(u_w^Tv_c)}</script><p>我们的目标函数是：</p>
<script type="math/tex; mode=display">J(\theta)=\frac{1}{T} \sum_{t=1}^{T} J_{t}(\theta)</script><p>其中</p>
<script type="math/tex; mode=display">J_{t}(\theta)=\log \sigma\left(u_{o}^{T} v_{c}\right)+\sum_{i=1}^{k} \mathbb{E}_{j \sim P(w)}\left[\log \sigma\left(-u_{j}^{T} v_{c}\right)\right]</script><h2 id="想一想"><a href="#想一想" class="headerlink" title="想一想"></a>想一想</h2><p>我们思考两个问题：</p>
<ol>
<li>我们把所有单词拿出来计算预测单词的概率$P(0|c)$，会给计算机带来很大的负担。<ul>
<li>我们会采用两个方式缓解这个问题，也就是上一节课末尾提出的negative sampling和hierarchical softmax。</li>
</ul>
</li>
<li>词向量有什么局限性呢？<ul>
<li>一个单词只有唯一一种向量表征方式，无法用一个向量表征两个意思（ElMo解决）</li>
<li>滑窗体现不出语序的关系</li>
</ul>
</li>
</ol>
<p>因此我们以后会用Transformer来解决这两问题（Transformer和Word2Vec没什么关系，和RNN、LSTM一脉相承，因此以后再讲）。</p>
<p>Word2Vec模型是一种基于local context window的direct prediction预测模型，对于学习word vector，还有另一类模型是<strong>count based global matrix factorization</strong></p>
<h1 id="SVD"><a href="#SVD" class="headerlink" title="SVD"></a>SVD</h1><p>SVD主要基于count based global matrix factorization，也就是共现矩阵，因此下面首先介绍共现矩阵的概念：</p>
<h2 id="共现矩阵"><a href="#共现矩阵" class="headerlink" title="共现矩阵"></a>共现矩阵</h2><h3 id="主要内涵："><a href="#主要内涵：" class="headerlink" title="主要内涵："></a>主要内涵：</h3><p>共现矩阵主要用于<strong>发现主题，解决词向量相近关系的表示</strong>。首先将共现矩阵行(列)作为词向量</p>
<p>例如：语料库如下：</p>
<ul>
<li>I like deep learning.</li>
<li>I like NLP.</li>
<li>I enjoy flying.</li>
</ul>
<p>若使用对称的窗函数（左右window length都为1），则共现矩阵表示如下：</p>
<p><img src="/posts/NLP/12.png" alt></p>
<p>解释一下这个表：”I like”出现在第1，2句话中，一共出现2次，所以对应矩阵位置$A[0,1]=2$。对称的窗口指的是，“like I”也是2次，所以对应矩阵位置$A[1,0]=2$</p>
<p>我们将共现矩阵行(列)作为词向量表示得到上面的表后，可以知道”like”，”enjoy”都是在”I”附近且统计数目大约相等，可以认为他们意思相近。</p>
<h3 id="不足之处"><a href="#不足之处" class="headerlink" title="不足之处"></a>不足之处</h3><ul>
<li>面临稀疏性问题</li>
<li>向量维数随着词典大小线性增长</li>
</ul>
<p>解决方法：SVD、PCA降维（但是计算量大）</p>
<h2 id="降维方法"><a href="#降维方法" class="headerlink" title="降维方法"></a>降维方法</h2><h3 id="Method-1-Dimensionality-Reduction-on-X-HW1"><a href="#Method-1-Dimensionality-Reduction-on-X-HW1" class="headerlink" title="Method 1: Dimensionality Reduction on X (HW1)"></a>Method 1: Dimensionality Reduction on X (HW1)</h3><p>使用SVD方法将共现矩阵$X$分解为$U \Sigma V^{\top}, \Sigma$是对角矩阵，对角线上的值是矩阵的奇异值，$U,V$是对应于行和列的正交基。</p>
<p>为了减少尺度同时尽量保存有效信息，可保留对角矩阵的最大的$k$个值，并将矩阵$U,V$的相应的行列保留。这是经典的线性代数算法，对于大型矩阵而言，计算代价昂贵。</p>
<p><img src="/posts/NLP/13.png" alt></p>
<h3 id="Method-2-Hacks-to-X-several-used-in-Rohde-et-al-2005"><a href="#Method-2-Hacks-to-X-several-used-in-Rohde-et-al-2005" class="headerlink" title="Method 2: Hacks to X (several used in Rohde et al. 2005)"></a>Method 2: Hacks to X (several used in Rohde et al. 2005)</h3><p>有很多高频词比如the, this等是我们不太需要关注的，为了应付这些词汇，我们可以用下面的方法降维：</p>
<ul>
<li>对高频词进行缩放<ul>
<li>使用log进行缩放</li>
<li>min(X,t),t≈100</li>
</ul>
</li>
<li>直接全部忽视</li>
<li>在基于window的计数中，提高更加接近的单词的计数</li>
<li>使用Person相关系数</li>
</ul>
<h1 id="GloVe"><a href="#GloVe" class="headerlink" title="GloVe"></a>GloVe</h1><h2 id="现有方法的问题与GloVe的目标"><a href="#现有方法的问题与GloVe的目标" class="headerlink" title="现有方法的问题与GloVe的目标"></a>现有方法的问题与GloVe的目标</h2><p>比较SVD这种<strong>count based</strong>模型与Word2Vec这种<strong>direct prediction</strong>模型，它们各有优缺点：</p>
<ul>
<li><p>Count based模型优点是:</p>
<ul>
<li>训练快速</li>
<li>有效的利用了统计信息</li>
</ul>
</li>
<li><p>Count based模型缺点是：</p>
<ul>
<li>对于高频词汇较为偏向</li>
<li>仅能概括词组的相关性</li>
<li>有的时候产生的word vector对于解释词的含义如word analogy等任务效果不好</li>
</ul>
</li>
<li><p>Direct Prediction模型优点是：</p>
<ul>
<li>可以概括比相关性更为复杂的信息</li>
<li>进行word analogy等任务时效果较好</li>
</ul>
</li>
<li><p>Direct Prediction模型缺点是：</p>
<ul>
<li>对统计信息利用的不够充分</li>
</ul>
</li>
</ul>
<p>所以Manning教授他们想采取一种方法可以结合两者的优势，并将这种算法命名为GloVe（Global Vectors的缩写），表示他们可以有效的利用全局的统计信息。</p>
<p>我们理解GloVe，重点便是：<strong>GloVe利用全局统计量，以最小二乘为目标，预测单词$j$出现在单词$i$上下文中的概率。</strong></p>
<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><h3 id="计算共现矩阵"><a href="#计算共现矩阵" class="headerlink" title="计算共现矩阵"></a>计算共现矩阵</h3><p>$X$表示word-word共现矩阵，其中$X_{ij}$表示词$j$出现在词$i$的上下文的次数。令$X_{i}=\sum_{k}X_{ik}$为任意词$k$出现在词$i$的上下文的次数。最后，令$P_{ij}=P(w_{j}\mid w_{i})=\frac{X_{ij}}{X_{i}}$是词$j$出现在词$i$的上下文的概率。</p>
<p>计算这个矩阵需要遍历一次整个语料库获得统计信息。对庞大的语料库，这样的遍历会产生非常大的计算量，但是这只是一次性的前期投入成本。</p>
<h3 id="计算损失函数"><a href="#计算损失函数" class="headerlink" title="计算损失函数"></a>计算损失函数</h3><p>回想一下Skip-Gram模型，我们使用softmax来计算词$j$出现在词$i$的上下文的概率：</p>
<script type="math/tex; mode=display">Q_{ij}=\frac{exp(u_{j}^{T}v_{i})}{\sum_{w=1}^{W}exp(u_{w}^{T}v_{i})}</script><p>隐含的全局交叉熵损失可以如下计算：</p>
<script type="math/tex; mode=display">J=-\sum_{i\in corpus} \sum_{j\in context(i)}log\;Q_{ij}</script><p>或者可以写成：</p>
<script type="math/tex; mode=display">J=-\sum_{i=1}^{W}\sum_{j=1}^{W}X_{ij}log\;Q_{ij}</script><p>其中$X_{ij}$由共现矩阵相应位置的值给定。</p>
<p>交叉熵损失的一个显着缺点是要求分布$Q$被正确归一化，因为对整个词汇的求和的计算量是非常大的。因此，我们使用一个最小二乘的目标函数，其中$P$和$Q$的归一化因子被丢弃了：</p>
<script type="math/tex; mode=display">\widehat{J}=\sum_{i=1}^{W}\sum_{j=1}^{W}X_{i}(\widehat{P}_{ij}-\widehat{Q}_{ij})^{2}</script><p>其中$\hat{P}_{i j}=X_{i j}$和 $\hat{Q}_{i j}=\exp \left(\vec{u}_{j}^{T} \vec{v}_{i}\right)$是未归一化分布。这个公式带来了一个新的问题，$X_{ij}$经常会是很大的值，从而难以优化。一个有效的改变是最小化$\widehat{P}$和$\widehat{Q}$对数的平方误差：</p>
<script type="math/tex; mode=display">\begin{eqnarray}  \widehat{J} &amp;=&amp;\sum_{i=1}^{W}\sum_{j=1}^{W}X_{i}(log(\widehat{P}_{ij})-log(\widehat{Q}_{ij}))^{2} \nonumber \\ &amp;=&amp; \sum_{i=1}^{W}\sum_{j=1}^{W}X_{i}(u_{j}^{T}v_{i}-log\; X_{ij})^{2} \nonumber \end{eqnarray}</script><p>另外一个问题是权值因子$X_i$不能保证是最优的。因此，我们引入更一般化的权值函数，我们可以自由地依赖于上下文单词：</p>
<script type="math/tex; mode=display">\widehat{J}=\sum_{i=1}^{W}\sum_{j=1}^{W}f(X_{ij})(u_{j}^{T}v_{i}-log\; X_{ij})^{2}</script><p>或者我们从另一个角度来看这个损失函数公式的结果：</p>
<p><img src="/posts/NLP/14.jpg" alt></p>
<p>例如我们想区分热力学上两种不同状态ice冰与蒸汽steam，它们之间的关系可通过与不同的单词$x$的co-occurrence probability的比值来描述，例如对于solid固态，虽然$P(solid|ice)$与$P(solid|stream)$本身很小，不能透露有效的信息，但是它们的比值$\frac{P(solid|ice)}{P(solid|stream)}$却较大，因为solid更常用来描述ice的状态而不是steam的状态，所以在ice的上下文中出现几率较大，对于gas则恰恰相反，而对于water这种描述ice与steam均可或者fashion这种与两者都没什么联系的单词，则比值接近于1。所以相较于单纯的co-occurrence probability，实际上co-occurrence probability的相对比值更有意义。</p>
<p>基于对于以上概率比值的观察，我们假设模型的函数有如下形式：</p>
<script type="math/tex; mode=display">F(w_i,w_j,w_k) = \frac{P_{ik}}{P_{jk}}</script><p>其中，$w$代表了context vector，如上例中的solid，gas，water，fashion等。$w_i, w_j$则是我们要比较的两个词汇，如上例中的ice，steam。</p>
<p>$F$的可选的形式过多，我们希望有所限定。首先我们希望的是$F$能有效的在单词向量空间内表示概率比值，由于向量空间是线性空间，一个自然的假设是$F$是关于向量$w_i,w_j$的差的形式：</p>
<script type="math/tex; mode=display">F(w_i-w_j,w_k) = \frac{P_{ik}}{P_{jk}}</script><p>我们可以直接通过矢量的点乘将左边化为标量形式</p>
<script type="math/tex; mode=display">F((w_i-w_j)^T,w_k) = \frac{P_{ik}}{P_{jk}}</script><p>在此，作者又对其进行了对称性分析，即对于word-word co-occurrence，将向量划分为center word还是context word的选择是不重要的，即我们在交换 $w\leftrightarrow \bar w$ 与$X\leftrightarrow\bar X$的时候该式仍然成立。如何保证这种对称性呢？</p>
<p><img src="/posts/NLP/14.png" alt></p>
<p>作者最终尝试的比较好的权重参数是：</p>
<script type="math/tex; mode=display">f(x)=
\begin{cases}
(x/x_{max})^{\alpha}& \text{if x} \lt \text{}x_{max}\\
1& \text{otherwise}
\end{cases}</script><blockquote>
<p>部分引用自：</p>
</blockquote>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/60208480" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/60208480</a></li>
<li><a href="https://looperxx.github.io/CS224n-2019-02-Word%20Vectors%202%20and%20Word%20Senses/" target="_blank" rel="noopener">https://looperxx.github.io/CS224n-2019-02-Word%20Vectors%202%20and%20Word%20Senses/</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/59016893" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/59016893</a></li>
<li><a href="https://www.aclweb.org/anthology/Q16-1028.pdf" target="_blank" rel="noopener">https://www.aclweb.org/anthology/Q16-1028.pdf</a></li>
</ul>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title>CS224n 01_Introduction and Word Vectors</title>
    <url>/posts/fb70fd3e.html</url>
    <content><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><h2 id="语言"><a href="#语言" class="headerlink" title="语言"></a>语言</h2><p>理解意义的最普遍的语言方式(linguistic way) : 语言符号与语言符号的意义的转化</p>
<script type="math/tex; mode=display">\boxed{\text{signifier(symbol)}\Leftrightarrow \text{signified(idea or thing)}} \ = \textbf{denotational semantics}</script><p>在所有的NLP任务中，第一个也是可以说是最重要的共同点是我们如何将单词表示为任何模型的输入（编码）。</p>
<h2 id="编码方式"><a href="#编码方式" class="headerlink" title="编码方式"></a>编码方式</h2><p>我们思考一下：我们如何让计算机学习到语言的意义？</p>
<h3 id="1、WordNet"><a href="#1、WordNet" class="headerlink" title="1、WordNet"></a>1、WordNet</h3><p>Wordnet指的是一个包含同义词集和上位词列表的辞典，我们很容易通过nltk获取到这种词典：</p>
<p><img src="/posts/NLP/1.png" alt></p>
<p>这种方式的缺点：</p>
<ul>
<li>需要人工操作，主观性强</li>
<li>忽略了细微差别</li>
<li>无法计算相似度</li>
</ul>
<h3 id="2、One-hot编码"><a href="#2、One-hot编码" class="headerlink" title="2、One-hot编码"></a>2、One-hot编码</h3><blockquote>
<p>motel = [0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 1 \ 0 \ 0 \ 0 \ 0] \\ hotel = [0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 1 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0]</p>
</blockquote>
<p>这种方式的缺点：</p>
<ul>
<li>无法衡量词语相似性</li>
<li>向量维度过大，训练难</li>
</ul>
<p>解决方式：</p>
<ul>
<li>使用类似 WordNet 的工具中的列表，获得相似度，但会因不够完整而失败</li>
<li>学习在向量本身中编码相似性</li>
</ul>
<h3 id="3、Representing-words-by-their-context"><a href="#3、Representing-words-by-their-context" class="headerlink" title="3、Representing words by their context"></a>3、Representing words by their context</h3><p>这种方式的思想在于：一个单词的意思是由经常出现在它附近的单词给出的，我们可以在单词$A$出现的上下文（固定大小的窗口）附近找到一组单词$a_k$来表示$A$：</p>
<p><img src="/posts/NLP/2.png" alt></p>
<h1 id="Word2vec-introduction"><a href="#Word2vec-introduction" class="headerlink" title="Word2vec introduction"></a>Word2vec introduction</h1><p><strong>思想</strong>：我们为每个单词构建一个密集的向量，使其与出现在相似上下文中的单词向量相似</p>
<p><img src="/posts/NLP/3.png" alt></p>
<p><strong>主要思路</strong>：给定大量的文本，给定一个初始词向量（低维度），对于文本中的每个位置$t$，其中有一个中心词$c$和上下文(“外部”)单词$o$。使用$c$和$o$的词向量的相似性，来计算给定$c$的$o$的概率(反之亦然)，然后我们不断调整词向量来最大化这个概率。</p>
<p>下图为窗口大小$j=2$时的$P\left(w_{t+j} | w_{t}\right)$计算过程，center word分别为into和banking：</p>
<p><img src="/posts/NLP/4.png" alt></p>
<p><img src="/posts/NLP/5.png" alt></p>
<h2 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h2><p>对于每个位置$t=1, \ldots, T$，在大小为$m$的固定窗口内预测上下文单词，给定中心词$w_j$</p>
<script type="math/tex; mode=display">Likelihoood = L(\theta) = \prod^{T}_{t=1} \prod_{-m \leq j \leq m \atop j \neq 0} P(w_{t+j} | w_{t} ; \theta)</script><p>其中，$\theta$为所有需要优化的变量。<br>目标函数$J(\theta)$(有时被称为代价函数或损失函数) 是(平均)负对数似然</p>
<script type="math/tex; mode=display">J(\theta)=-\frac{1}{T} \log L(\theta)=-\frac{1}{T} \sum_{t=1}^{T} \sum_{-m \leq j \leq m \atop j \neq 0} \log P\left(w_{t+j} | w_{t} ; \theta\right)</script><p>其中$log$形式是方便将连乘转化为求和，负号是希望将极大化似然率转化为极小化损失函数的等价问题。</p>
<h2 id="最小化目标函数-Leftrightarrow-最大化预测精度"><a href="#最小化目标函数-Leftrightarrow-最大化预测精度" class="headerlink" title="最小化目标函数$\Leftrightarrow$最大化预测精度"></a>最小化目标函数$\Leftrightarrow$最大化预测精度</h2><p><strong>问题：如何计算$P(w_{t+j} | w_{t} ; \theta)$？</strong></p>
<p>对于每个单词$w$都是用两个向量表示：</p>
<p><em>$v_w$当$w$是中心词时
</em>$u_w$当$w$是上下文词时</p>
<p>于是对于一个中心词$c$和一个上下文词$o$，就得到了Word2vec prediction function：</p>
<script type="math/tex; mode=display">P(o | c)=\frac{\exp \left(u_{o}^{T} v_{c}\right)}{\sum_{w \in V} \exp \left(u_{w}^{T} v_{c}\right)}</script><blockquote>
<p>公式中，向量$u_o$和向量$v_c$进行点乘。向量之间越相似，点乘结果越大，从而归一化后得到的概率值也越大。模型的训练正是为了使得具有相似上下文的单词，具有相似的向量。</p>
</blockquote>
<p>在公式中分母对整个词汇表进行标准化，从而给出概率分布。</p>
<p>附注：$softmax function：\mathbb{R}^{n} \rightarrow \mathbb{R}^{1}$</p>
<script type="math/tex; mode=display">\operatorname{softmax}\left(x_{i}\right)=\frac{\exp \left(x_{i}\right)}{\sum_{j=1}^{n} \exp \left(x_{j}\right)}=p_{i}</script><p>将任意值$x_i$映射到概率分布$p_i$</p>
<h2 id="梯度下降法求解"><a href="#梯度下降法求解" class="headerlink" title="梯度下降法求解"></a>梯度下降法求解</h2><p>首先我们随机初始化$u_{w}\in\mathbb{R}^d$和$v_{w}\in\mathbb{R}^d$，而后使用梯度下降法进行更新：</p>
<script type="math/tex; mode=display">\begin{align} \frac{\partial}{\partial v_c}\log P(o|c) &=\frac{\partial}{\partial v_c}\log \frac{\exp(u_o^Tv_c)}{\sum_{w\in V}\exp(u_w^Tv_c)}\\ &=\frac{\partial}{\partial v_c}\left(\log \exp(u_o^Tv_c)-\log{\sum_{w\in V}\exp(u_w^Tv_c)}\right)\\ &=\frac{\partial}{\partial v_c}\left(u_o^Tv_c-\log{\sum_{w\in V}\exp(u_w^Tv_c)}\right)\\ &=u_o-\frac{\sum_{w\in V}\exp(u_w^Tv_c)u_w}{\sum_{w\in V}\exp(u_w^Tv_c)} \end{align}</script><p>我们可以对上述结果重新排列如下，第一项是真正的上下文单词，第二项是预测的上下文单词。使用梯度下降法，模型的预测上下文将逐步接近真正的上下文。</p>
<script type="math/tex; mode=display">\begin{align} \frac{\partial}{\partial v_c}\log P(o|c) &=u_o-\frac{\sum_{w\in V}\exp(u_w^Tv_c)u_w}{\sum_{w\in V}\exp(u_w^Tv_c)}\\ &=u_o-\sum_{w\in V}\frac{\exp(u_w^Tv_c)}{\sum_{w\in V}\exp(u_w^Tv_c)}u_w\\ &=u_o-\sum_{w\in V}P(w|c)u_w \end{align}</script><p>再对$u_o$进行偏微分计算，注意这里的$u_o$是$u_{w=o}$的简写，故可知</p>
<script type="math/tex; mode=display">\frac{\partial}{\partial u_o}\sum_{w \in V } u_w^T v_c = \frac{\partial}{\partial u_o} u_o^T v_c = \frac{\partial u_o}{\partial u_o}v_c + \frac{\partial v_c}{\partial u_o}u_o= v_c</script><p>因此有：</p>
<script type="math/tex; mode=display">\begin{align} \frac{\partial}{\partial u_o}\log P(o|c) &=\frac{\partial}{\partial u_o}\log \frac{\exp(u_o^Tv_c)}{\sum_{w\in V}\exp(u_w^Tv_c)}\\ &=\frac{\partial}{\partial u_o}\left(\log \exp(u_o^Tv_c)-\log{\sum_{w\in V}\exp(u_w^Tv_c)}\right)\\ &=\frac{\partial}{\partial u_o}\left(u_o^Tv_c-\log{\sum_{w\in V}\exp(u_w^Tv_c)}\right)\\ &=v_c-\frac{\sum\frac{\partial}{\partial u_o}\exp(u_w^Tv_c)}{\sum_{w\in V}\exp(u_w^Tv_c)}\\ &=v_c - \frac{\exp(u_o^Tv_c)v_c}{\sum_{w\in V}\exp(u_w^Tv_c)}\\ &=v_c - \frac{\exp(u_o^Tv_c)}{\sum_{w\in V}\exp(u_w^Tv_c)}v_c\\ &=v_c - P(o|c)v_c\\ &=(1-P(o|c))v_c \end{align}</script><p>可以理解，当$P(o|c) \to 1$，即通过中心词$c$我们可以正确预测上下文词$o$，此时我们不需要调整$u_o$，反之，则相应调整$u_o$。</p>
<h1 id="SVD-Based-Methods"><a href="#SVD-Based-Methods" class="headerlink" title="SVD Based Methods"></a>SVD Based Methods</h1><p>与WordVector为词向量编码不同，SVD Based Methods为词嵌入的方法，首先遍历一个很大的数据集和统计词的共现计数矩阵$X$，然后对矩阵$X$进行SVD分解得到$USV^{T}$。然后我们使用$U$的行来作为字典中所有词的词向量。我们来讨论一下矩阵$X$的几种选择。</p>
<h2 id="矩阵-X-的选择"><a href="#矩阵-X-的选择" class="headerlink" title="矩阵$X$的选择"></a>矩阵$X$的选择</h2><h3 id="Word-Document-Matrix"><a href="#Word-Document-Matrix" class="headerlink" title="Word-Document Matrix"></a>Word-Document Matrix</h3><p>我们最初的尝试，我们猜想相关连的单词在同一个文档中会经常出现。例如，“banks” “bonds” “stocks” “moneys”等等，出现在一起的概率会比较高。但是“banks” “octopus” “banana” “hockey”不大可能会连续地出现。我们根据这个情况来建立一个Word-Document矩阵，$X$是按照以下方式构建：遍历数亿的文档和当词$i$出现在文档$j$，我们对$X_{ij}$加一。这显然是一个很大的矩阵$\mathbb{R}^{|V|\times M}$，它的规模是和文档数量$M$成正比关系。因此我们可以尝试更好的方法。</p>
<h3 id="Window-based-Co-occurrence-Matrix"><a href="#Window-based-Co-occurrence-Matrix" class="headerlink" title="Window based Co-occurrence Matrix"></a>Window based Co-occurrence Matrix</h3><p>与上一个不同的是，矩阵$X$存储单词的共现，从而成为一个关联矩阵。在此方法中，我们计算每个单词在特定大小的窗口中出现的次数。我们按照这个方法对语料库中的所有单词进行统计。</p>
<ul>
<li>生成维度为$|V| \times|V|$的共现矩阵$X$</li>
<li>在$X$上应用 SVD 从而得到$X = {USV}^T$</li>
<li>选择$U$前$k$行得到$k$维的词向量<br>*$\frac{\sum_{i=1}^{k} \sigma_{i}}{\sum_{i=1}^{|V|} \sigma_{i}}$表示第一个k维捕获的方差量</li>
</ul>
<h2 id="将SVD应用于共现矩阵"><a href="#将SVD应用于共现矩阵" class="headerlink" title="将SVD应用于共现矩阵"></a>将SVD应用于共现矩阵</h2><p>我们对矩阵$X$使用SVD，观察奇异值（矩阵 S 上对角线上元素），根据期望的捕获方差百分比截断，留下前$k$个元素：</p>
<p>然后取子矩阵$U_{1:|V|, 1:k}$作为词嵌入矩阵。这就给出了词汇表中每个词的$k$维表示，如下图所示：</p>
<p><img src="/posts/NLP/6.png" alt></p>
<p>通过选择前$k$个奇异向量来降低维度：</p>
<p><img src="/posts/NLP/7.png" alt></p>
<p>这两种方法都给我们提供了足够的词向量来编码语义和句法(part of speech)信息，但也有许多其他问题：</p>
<ul>
<li>矩阵的维度会经常发生改变（经常增加新的单词和语料库的大小会改变）。</li>
<li>矩阵会非常的稀疏，因为很多词不会共现。</li>
<li>矩阵维度一般会非常高$\approx 10^{6}\times 10^{6}$</li>
<li>基于 SVD 的方法的计算复杂度很高$(m×n$矩阵的计算成本是$O({mn}^2))$，并且很难合并新单词或文档</li>
<li>需要在$X$上加入一些技巧处理来解决词频的极剧的不平衡</li>
</ul>
<p>对上述讨论中存在的问题存在以下的解决方法：</p>
<ul>
<li>忽略功能词，例如 “the”，“he”，“has” 等等，构建停用词库。</li>
<li>使用ramp window，即根据文档中单词之间的距离对共现计数进行加权</li>
<li>使用皮尔逊相关系数并将负计数设置为0，而不是只使用原始计数</li>
</ul>
<h1 id="Iteration-Based-Methods-Word2vec"><a href="#Iteration-Based-Methods-Word2vec" class="headerlink" title="Iteration Based Methods - Word2vec"></a>Iteration Based Methods - Word2vec</h1><p>为了避免上述弊端（数据集过于庞大等），我们考虑设计一个模型，该模型的参数就是词向量。然后根据一个目标函数训练模型，在每次模型的迭代计算误差，并遵循一些更新规则，该规则具有惩罚造成错误的模型参数的作用，从而可以学习到词向量，我们称这个方法为“反向传播”，模型和任务越简单，反向传播训练速度就越快。</p>
<p>Word2vec作为一个概率模型，定义了两个算法和两个训练方法：</p>
<ul>
<li>两个算法：continuous bag-of-words（CBOW）和 skip-gram。CBOW 是根据中心词周围的上下文单词来预测该词的词向量。skip-gram 则相反，是根据中心词预测周围上下文的词的概率分布。</li>
<li>两个训练方法：negative sampling 和 hierarchical softmax。Negative sampling 通过抽取负样本来定义目标，hierarchical softmax 通过使用一个有效的树结构来计算所有词的概率来定义目标。</li>
</ul>
<p>Language Models (Unigrams, Bigrams, etc.)</p>
<p>首先，我们需要创建一个模型来为一系列的单词分配概率。我们从一个例子开始：</p>
<blockquote>
<p>“The cat jumped over the puddle”</p>
</blockquote>
<p>一个好的语言模型会给这个句子很高的概率，因为在句法和语义上这是一个完全有效的句子。相似地，句子“stock boil fish is toy”会得到一个很低的概率，因为这是一个无意义的句子。在数学上，我们可以称为对给定 n 个词的序列的概率是：</p>
<script type="math/tex; mode=display">P(w_{1}, w_{2}, \ldots, w_{n})</script><p>我们可以采用一元语言模型方法(Unigram model)，假设单词的出现是完全独立的，从而分解概率</p>
<script type="math/tex; mode=display">P\left(w_{1}, w_{2}, \cdots, w_{n}\right)=\prod_{i=1}^{n} P\left(w_{i}\right)</script><p>但是我们知道这是不大合理的，因为下一个单词是高度依赖于前面的单词序列的。如果使用上述的语言模型，可能会让一个无意义的句子具有很高的概率。所以我们让序列的概率取决于序列中的单词和其旁边的单词的成对概率。我们称之为 bigram 模型：</p>
<script type="math/tex; mode=display">P\left(w_{1}, w_{2}, \cdots, w_{n}\right)=\prod_{i=2}^{n} P\left(w_{i} | w_{i-1}\right)</script><p>但是这个方法还是有点简单，因为我们只考虑了一对邻近的单词而不是整个句子，但是这个方法已经能获得不错的效果了。现在我们根据概率模型讨论两个常用模型 —— CBOW和SkipGram模型。</p>
<h2 id="两个模型"><a href="#两个模型" class="headerlink" title="两个模型"></a>两个模型</h2><h3 id="1、CBOW"><a href="#1、CBOW" class="headerlink" title="1、CBOW"></a>1、CBOW</h3><p>CBOW的原句是Continuous Bag of Words Model，目标是通过给定中心词周围的其他词来预测中心词，首先我们设定已知参数。令我们模型的已知参数是 one-hot形式的词向量表示。输入的one-hot向量或者上下文我们用$x^{(c)}$表示，输出用$y^{(c)}$表示。在CBOW模型中，因为我们只有一个输出，因此我们把$y$称为是中心词的的one-hot向量。现在让我们定义模型的未知参数。</p>
<p>$w_{i}$：词汇表$V$中的单词$i$<br>$\mathcal{V}\in \mathbb{R}^{n\times |V|}$：输入词矩阵<br>$v_{i} ： \mathcal{V}$的第$i$列，单词$w_{i}$的输入向量表示<br>$\mathcal{U}\in \mathbb{R}^{|V|\times n}$：输出词矩阵<br>$u_{i}： \mathcal{U}$的第$i$行，单词$w_{i}$的输出向量表示</p>
<p>我们创建两个矩阵，$\mathcal{V}\in \mathbb{R}^{n\times |V|}$和$\mathcal{U}\in \mathbb{R}^{|V|\times n}$。其中$n$是嵌入空间的任意维度大小。$\mathcal{V}$是输入词矩阵，使得当其为模型的输入时，$\mathcal{V}$的第$i$列是词$w_{i}$的$n$维嵌入向量。我们定义这个$n \times 1$的向量为$v_{i}$。相似地，$\mathcal{U}$是输出词矩阵。当其为模型的输入时，$\mathcal{U}$的第$j$行是词$w_{j}$的$n$维嵌入向量。我们定义$\mathcal{U}$的这行为$u_{j}$。注意实际上对每个词$w_{i}$我们需要学习两个词向量（即输入词向量$v_{i}$和输出词向量$u_{i} ）。</p>
<p>我们将这个模型的训练分解为以下步骤</p>
<ol>
<li>为大小为$m$的输入上下文生成 one-hot 词向量<script type="math/tex; mode=display">(x^{(c-m)},...,x^{(c-1)},x^{(c+1)},...,x^{(c+m)}\in \mathbb{R}^{|V|})</script></li>
<li>从上下文得到嵌入词向量<script type="math/tex; mode=display">(v_{c-m}=\mathcal{V}x^{(c-m)},v_{c-m+1}=\mathcal{V}x^{(c-m+1)},...,v_{c+m}=\mathcal{V}x^{(c+m)}\in \mathbb{R}^{n})</script></li>
<li>对上述向量求平均值<script type="math/tex; mode=display">\widehat{v}=\frac{v_{c-m}+v_{c-m+1+...+v_{c+m}}}{2m}\in \mathbb{R}^{n}</script></li>
<li>生成一个分数向量$z = \mathcal{U}\widehat{v}\in \mathbb{R}^{|V|}$。相似向量的点积越高两个词越相似，从而获得更高的分数。将分数转换为概率：<script type="math/tex; mode=display">\widehat{y}=softmax(z)\in \mathbb{R}^{|V|}</script><ul>
<li>这里 softmax 是一个常用的函数。它将一个向量转换为另外一个向量，其中转换后的向量的第$i$个元素是<script type="math/tex; mode=display">\frac{e^{\widehat{y}_i}}{\sum_{k=1}^{|V|}e^{\widehat{y}_k}}</script>因为该函数是一个指数函数，所以值一定为正数；通过除以$\sum_{k=1}^{|V|}e^{\widehat{y}_k}$来归一化向量得到概率。</li>
</ul>
</li>
<li>我们希望生成的概率$\widehat{y} \in \mathbb{R}^{|V|}$与实际的概率$y \in \mathbb{R}^{|V|}$匹配。使得其刚好是实际的词，也就是这个     one-hot 向量。</li>
</ol>
<p><img src="/posts/NLP/8.png" alt></p>
<p>为了计算损失函数，我们首先给出度量两个概率分布的距离的方法 —— <strong>交叉熵$H(\widehat{y}, y)$</strong></p>
<script type="math/tex; mode=display">H(\hat{y}, y)=-\sum_{j=1}^{|V|} y_{j} \log \left(\hat{y}_{j}\right)</script><p>上面的公式中，$y$是 one-hot 向量。因此上面的损失函数可以简化为：</p>
<script type="math/tex; mode=display">H(\widehat{y}, y)= - y_{j}\,log(\widehat{y}_{j})</script><p>c 是正确词的 one-hot 向量的索引。我们现在可以考虑我们的预测正确并且$\widehat{y}_{c}=1$的情况，可以计算得$H(\widehat{y}, y)=- log(1)=0$；若预测非常差并且$\widehat{y}_{c}=0.01$。和前面类似，我们可以计算损失$H(\widehat{y}, y)=-log(0.01)=4.605$。下面定义优化目标函数：</p>
<script type="math/tex; mode=display">\begin{aligned} \text { minimize } J &=-\log P\left(w_{c} | w_{c-m}, \ldots, w_{c-1}, w_{c+1}, \ldots, w_{c+m}\right)\\ &=-\log P\left(u_{c} | \hat{v}\right) \\ &=-\log \frac{\exp \left(u_{c}^{T} \hat{v}\right)}{\sum_{j=1}^{|V|} \exp \left(u_{j}^{T} \hat{v}\right)} \\ &=-u_{c}^{T} \hat{v}+\log \sum_{j=1}^{|V|} \exp \left(u_{j}^{T} \hat{v}\right) \end{aligned}</script><p>我们使用 SGD 来更新所有相关的词向量$u_{c} 和 v_{j}$。SGD对一个窗口计算梯度和更新参数：</p>
<script type="math/tex; mode=display">\begin{array}{l}{\mathcal{U}_{\text {new}} \leftarrow \mathcal{U}_{\text {old}}-\alpha \nabla_{\mathcal{U}} J} \\ {\mathcal{V}_{\text {old}} \leftarrow \mathcal{V}_{\text {old}}-\alpha \nabla_{\mathcal{V}} J}\end{array}</script><h3 id="2、Skip-Gram-Model"><a href="#2、Skip-Gram-Model" class="headerlink" title="2、Skip-Gram Model"></a>2、Skip-Gram Model</h3><p>在这里的预测任务和CBOW的正好相反，在CBOW中我们已知附近词预测中心词，在这里我们已知中心词预测附近词。</p>
<ul>
<li>生成中心词的one-hot向量$x\in \mathbb{R}^{|V|}$</li>
<li>我们对中心词$v_{c}=\mathcal{V}x\in \mathbb{R}^{|V|}$得到词嵌入向量</li>
<li>生成分数向量$z = \mathcal{U}v_{c}$</li>
<li>将分数向量转化为概率，$\widehat{y}=softmax(z)$，注意$\widehat{y}_{c-m},…,\widehat{y}_{c-1},\widehat{y}_{c+1},…,\widehat{y}_{c+m}$是每个上下文词观察到的概率</li>
<li>我们希望我们生成的概率向量匹配真实概率$y^{(c-m)},…,y^{(c-1)},y^{(c+1)},…,y^{(c+m)}$，实际的输出的是one-hot向量。</li>
</ul>
<p>大致如下：</p>
<p><img src="/posts/NLP/9.png" alt></p>
<p>我们要定义目标函数，首先假设给定中心词，所有输出的词是完全独立的（不甚严谨），于是可以写出目标函数：</p>
<script type="math/tex; mode=display">\begin{aligned} \text { minimize } J &=-\log P\left(w_{c-m}, \ldots, w_{c-1}, w_{c+1}, \ldots, w_{c+m} | w_{c}\right) \\ &=-\log \prod_{j=0, j \neq m}^{2 m} P\left(w_{c-m+j} | w_{c}\right) \\ &=-\log \prod_{j=0, j \neq m}^{2 m} P\left(u_{c-m+j} | v_{c}\right) \\ &=-\log \prod_{j=0, j \neq m}^{2 m} \frac{\exp \left(u_{c-m+j}^{T} v_{c}\right)}{\sum_{k=1}^{|V|} \exp \left(u_{k}^{T} v_{c}\right)} \\ &=-\sum_{j=0, j \neq m}^{2 m} u_{c-m+j}^{T} v_{c}+2 m \log \sum_{k=1}^{|V|} \exp \left(u_{k}^{T} v_{c}\right) \end{aligned}</script><p>通过这个目标函数，我们可以计算出与未知参数相关的梯度，并且在每次迭代中通过 SGD 来更新它们。另外需要注意到</p>
<script type="math/tex; mode=display">\begin{aligned} J &=-\sum_{j=0, j \neq m}^{2 m} \log P\left(u_{c-m+j} | v_{c}\right) \\ &=\sum_{j=0, j \neq m}^{2 m} H\left(\hat{y}, y_{c-m+j}\right) \end{aligned}</script><p>是向量$\widehat{y}$的概率和 one-hot 向量$y_{c-m+j}$之间的交叉熵。</p>
<p>以下为Skip-Gram的代码：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span>  pprint</span><br><span class="line">obj_path = <span class="string">r'E:\back_up\NLP\process_train.txt'</span></span><br><span class="line">stop_word_file = <span class="string">r"E:\back_up\NLP\pro1\data\stop_word.txt"</span></span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_stop_word</span><span class="params">(stop_word_file)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    加载停用词</span></span><br><span class="line"><span class="string">    :param stop_word_file: </span></span><br><span class="line"><span class="string">    :return: </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    stopwords = [x.strip() <span class="keyword">for</span> x <span class="keyword">in</span> open(stop_word_file, <span class="string">'r'</span>, encoding=<span class="string">'utf-8'</span>).readlines()]</span><br><span class="line">    <span class="keyword">return</span> stopwords + list(<span class="string">"0123456789"</span>) + [<span class="string">r'\n'</span>, <span class="string">'\n'</span>]</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_data</span><span class="params">(file_path, windows_len, lines_number)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    :param file_path:   数据的路径</span></span><br><span class="line"><span class="string">    :param windows_len:   窗口长度</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    words = set()     <span class="comment"># 保存词</span></span><br><span class="line">    sentences = []    <span class="comment"># 保存句子</span></span><br><span class="line">    stopwords = get_stop_word(stop_word_file)</span><br><span class="line">    stopwords = set(stopwords)</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> open(file_path, <span class="string">'r'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            line = fp.readline()</span><br><span class="line">            count = count + <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> line <span class="keyword">or</span> count &gt; lines_number:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="comment"># print(line)</span></span><br><span class="line">            out_str = []</span><br><span class="line">            result = jieba.cut(line, cut_all=<span class="literal">False</span>)    <span class="comment"># 精确模式</span></span><br><span class="line">            <span class="keyword">for</span> c <span class="keyword">in</span> result:</span><br><span class="line">                <span class="keyword">if</span> c <span class="keyword">not</span> <span class="keyword">in</span> stopwords <span class="keyword">and</span> len(c) &gt; <span class="number">1</span>:</span><br><span class="line">                    out_str.append(c)</span><br><span class="line">                    words.add(c)     <span class="comment"># 保存所有的词</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">            out_str.append(<span class="string">"EOS"</span>)</span><br><span class="line">            sentences.append(out_str)</span><br><span class="line">    word2id = &#123;&#125;</span><br><span class="line">    words = list(words)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(words)):</span><br><span class="line">        word2id[words[i]] = i + <span class="number">1</span></span><br><span class="line">    word2id[<span class="string">"EOS"</span>] = len(words) + <span class="number">1</span></span><br><span class="line">    <span class="comment"># 构造输入input和输出labels</span></span><br><span class="line">    input = []</span><br><span class="line">    labels = []</span><br><span class="line">    <span class="comment"># 构造训练数据和标签</span></span><br><span class="line">    <span class="keyword">for</span> sentence <span class="keyword">in</span> sentences:</span><br><span class="line">        <span class="keyword">for</span> word_index <span class="keyword">in</span> range(len(sentence)):</span><br><span class="line">            start = max(<span class="number">0</span>, word_index - windows_len)</span><br><span class="line">            end = min(word_index + windows_len + <span class="number">1</span>, len(sentence))</span><br><span class="line">            <span class="keyword">for</span> index <span class="keyword">in</span> range(start, end):</span><br><span class="line">                <span class="keyword">if</span> index == word_index:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    input_word_id = word2id.get(sentence[word_index], <span class="literal">None</span>)</span><br><span class="line">                    label_word_id = word2id.get(sentence[index], <span class="literal">None</span>)</span><br><span class="line">                    <span class="keyword">if</span> input_word_id <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> label_word_id <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                        <span class="keyword">continue</span></span><br><span class="line">                    input.append(int(input_word_id))</span><br><span class="line">                    labels.append(int(label_word_id))</span><br><span class="line">    <span class="keyword">return</span> words, word2id, sentences, input, labels, len(words)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TrainData</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, inputs, labels, words, vocab_size, batch_size)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param inputs:   输入</span></span><br><span class="line"><span class="string">        :param labels:   输出</span></span><br><span class="line"><span class="string">        :param words:    所有单词</span></span><br><span class="line"><span class="string">        :param vocab_size:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.inputs = inputs</span><br><span class="line">        self.labels = labels</span><br><span class="line">        self.words = words</span><br><span class="line">        self.vocab_size = vocab_size</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        self.input_length = len(inputs)</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_batch_data</span><span class="params">(self, batch_count)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param batch_count:  batch计数</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 确定选取的batch大小</span></span><br><span class="line">        start_position = batch_count * self.batch_size</span><br><span class="line">        end_position = min((batch_count + <span class="number">1</span>) * self.batch_size, self.input_length)</span><br><span class="line">        batch_input = self.inputs[start_position: end_position]</span><br><span class="line">        batch_labels = self.labels[start_position: end_position]</span><br><span class="line">        batch_input = np.array(batch_input, dtype=np.int32)</span><br><span class="line">        batch_labels = np.array(batch_labels, dtype=np.int32)</span><br><span class="line">        batch_labels = np.reshape(batch_labels, [len(batch_labels), <span class="number">1</span>])   <span class="comment"># 转置</span></span><br><span class="line">        <span class="keyword">return</span> batch_input, batch_labels</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_batch_nums</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        获取数据的batch数</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">return</span> self.input_length // self.batch_size + <span class="number">1</span></span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, vocab_size, embedding_size, batch_nums, num_sampled, learning_rate)</span>:</span></span><br><span class="line">        self.vocab_size = vocab_size</span><br><span class="line">        self.embedding_size = embedding_size</span><br><span class="line">        self.batch_nums = batch_nums</span><br><span class="line">        self.num_sampled = num_sampled</span><br><span class="line">        self.lr = learning_rate</span><br><span class="line">        self.batch_size = <span class="literal">None</span></span><br><span class="line">        <span class="comment"># self.graph = tf.Graph()</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment"># 创建placeholder</span></span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">"placeholders"</span>):</span><br><span class="line">            self.inputs = tf.placeholder(dtype=tf.int32, shape=[self.batch_size], name=<span class="string">"train_inputs"</span>)   <span class="comment"># 输入</span></span><br><span class="line">            self.labels = tf.placeholder(dtype=tf.int32, shape=[self.batch_size, <span class="number">1</span>], name=<span class="string">"train_labels"</span>)</span><br><span class="line">            self.test_word_id = tf.placeholder(dtype=tf.int32, shape=[<span class="literal">None</span>], name=<span class="string">"test_word_id"</span>)</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># 创建词向量</span></span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">"word_embedding"</span>):</span><br><span class="line">            self.embedding_dict = tf.get_variable(name=<span class="string">"embedding_dict"</span>, shape=[self.vocab_size, self.embedding_size],</span><br><span class="line">                                                  initializer=tf.random_uniform_initializer(<span class="number">-1</span>, <span class="number">1</span>, seed=<span class="number">1</span>)</span><br><span class="line">                                                  )</span><br><span class="line">            self.nce_weight = tf.get_variable(name=<span class="string">"nce_weight"</span>, shape=[self.vocab_size, self.embedding_size],</span><br><span class="line">                                              initializer=tf.random_uniform_initializer(<span class="number">-1</span>, <span class="number">1</span>, seed=<span class="number">1</span>)</span><br><span class="line">                                              )</span><br><span class="line">            self.nce_bias = tf.get_variable(name=<span class="string">"nce_bias"</span>, initializer=tf.zeros([self.vocab_size]))</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># 定义误差</span></span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">"creating_embedding"</span>):</span><br><span class="line">            embeded = tf.nn.embedding_lookup(self.embedding_dict, self.inputs)</span><br><span class="line">            self.embeded = tf.layers.dense(inputs=embeded, units=self.embedding_size, activation=tf.nn.relu)  <span class="comment"># 激活函数</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment"># 定义误差</span></span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">"creating_loss"</span>):</span><br><span class="line">            self.loss = tf.reduce_mean(</span><br><span class="line">                tf.nn.nce_loss(weights=self.nce_weight,</span><br><span class="line">                               biases=self.nce_bias,</span><br><span class="line">                               labels=self.labels,</span><br><span class="line">                               inputs=self.embeded,</span><br><span class="line">                               num_sampled=self.num_sampled,</span><br><span class="line">                               num_classes=self.vocab_size,</span><br><span class="line">                               <span class="comment"># remove_accidental_hits=True</span></span><br><span class="line">                               )</span><br><span class="line">             )</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># 定义测试函数</span></span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">"evaluation"</span>):</span><br><span class="line">            norm = tf.sqrt(tf.reduce_sum(tf.square(self.embedding_dict), <span class="number">1</span>, keepdims=<span class="literal">True</span>))</span><br><span class="line">            self.normed_embedding_dict = self.embedding_dict / norm</span><br><span class="line">            test_embed = tf.nn.embedding_lookup(self.normed_embedding_dict, self.test_word_id)</span><br><span class="line">            self.similarity = tf.matmul(test_embed, tf.transpose(self.normed_embedding_dict), name=<span class="string">'similarity'</span>)</span><br><span class="line"> </span><br><span class="line">        self.optimizer = tf.train.AdamOptimizer(learning_rate=self.lr).minimize(self.loss)</span><br><span class="line"> </span><br><span class="line">        <span class="comment">#  tensorboard 显示数据</span></span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">"summaries"</span>):</span><br><span class="line">            tf.summary.scalar(<span class="string">'loss'</span>, self.loss)   <span class="comment"># 在 tensorboard中显示信息</span></span><br><span class="line">            self.summary_op = tf.summary.merge_all()</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, train_data, train_steps=<span class="number">1000</span>)</span>:</span></span><br><span class="line">        <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">            <span class="comment"># 初始化变量</span></span><br><span class="line">            sess.run(tf.group(tf.local_variables_initializer(), tf.global_variables_initializer()))</span><br><span class="line">            writer = tf.summary.FileWriter(<span class="string">r'E:\back_up\NLP\graph'</span>, sess.graph)   </span><br><span class="line">            initial_step = <span class="number">0</span>                <span class="comment"># self.global_step.eval(session=sess)</span></span><br><span class="line">            step = <span class="number">0</span>   <span class="comment"># 记录总的训练次数</span></span><br><span class="line">            saver = tf.train.Saver(tf.global_variables(), max_to_keep=<span class="number">2</span>)   <span class="comment"># 保存模型</span></span><br><span class="line">            <span class="keyword">for</span> index <span class="keyword">in</span> range(initial_step, train_steps):</span><br><span class="line">                total_loss = <span class="number">0.0</span>     <span class="comment"># 总的loss</span></span><br><span class="line">                <span class="keyword">for</span> batch_count <span class="keyword">in</span> tqdm(range(self.batch_nums)):</span><br><span class="line">                    batch_inputs, batch_labels = train_data.get_batch_data(batch_count)</span><br><span class="line">                    feed_dict = &#123;self.inputs: batch_inputs,</span><br><span class="line">                                 self.labels: batch_labels&#125;</span><br><span class="line"> </span><br><span class="line">                    sess.run(self.optimizer, feed_dict=feed_dict)</span><br><span class="line">                    batch_loss = sess.run(self.loss, feed_dict=feed_dict)</span><br><span class="line">                    summary = sess.run(self.summary_op, feed_dict=feed_dict)</span><br><span class="line">                    <span class="comment"># batch_loss, summary = sess.run([self.loss, self.summary_op])</span></span><br><span class="line">                    total_loss += batch_loss</span><br><span class="line">                    step += <span class="number">1</span></span><br><span class="line">                    <span class="keyword">if</span> step % <span class="number">200</span> == <span class="number">0</span>:</span><br><span class="line">                        saver.save(sess=sess, save_path=<span class="string">r'E:\back_up\NLP\global_variables\global_variables'</span>, global_step=step)</span><br><span class="line">                        writer.add_summary(summary, global_step=step)</span><br><span class="line">                print(<span class="string">'Train Loss at step &#123;&#125;: &#123;:5.6f&#125;'</span>.format(index, total_loss/self.batch_nums))</span><br><span class="line">            word_embedding = sess.run(self.embedding_dict)</span><br><span class="line">            np.save(<span class="string">r"E:\back_up\NLP\word_embedding\word_embedding"</span>, word_embedding)   <span class="comment"># 保存词向量</span></span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(test_word, word2id, top_k=<span class="number">4</span>)</span>:</span>     <span class="comment"># 测试训练的词向量</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    :param test_word: </span></span><br><span class="line"><span class="string">    :param word2id: </span></span><br><span class="line"><span class="string">    :param top_k:   与testword最相近的k个词 </span></span><br><span class="line"><span class="string">    :return: </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    sess = tf.Session()</span><br><span class="line">    check_point_file = tf.train.latest_checkpoint(<span class="string">r'E:\back_up\NLP\global_variables'</span>)   <span class="comment"># 加载模型</span></span><br><span class="line">    saver = tf.train.import_meta_graph(<span class="string">"&#123;&#125;.meta"</span>.format(check_point_file), clear_devices=<span class="literal">True</span>)</span><br><span class="line">    saver.restore(sess, check_point_file)</span><br><span class="line">    graph = sess.graph    </span><br><span class="line">    graph_test_word_id = graph.get_operation_by_name(<span class="string">"placeholders/test_word_id"</span>).outputs[<span class="number">0</span>]</span><br><span class="line">    graph_similarity = graph.get_operation_by_name(<span class="string">"evaluation/similarity"</span>).outputs[<span class="number">0</span>]</span><br><span class="line">    test_word_id = [word2id.get(x) <span class="keyword">for</span> x <span class="keyword">in</span> test_word]</span><br><span class="line">    feed_dict = &#123;graph_test_word_id: test_word_id&#125;</span><br><span class="line">    similarity = sess.run(graph_similarity, feed_dict)</span><br><span class="line">    <span class="keyword">for</span> index <span class="keyword">in</span> range(len(test_word)):</span><br><span class="line">        nearest = (-similarity[index, :]).argsort()[<span class="number">0</span>:top_k]     <span class="comment"># argsort()默认按照从小大的顺序  最接近的词</span></span><br><span class="line">        log_info = <span class="string">"Nearest to %s: "</span> % test_word[index]</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(top_k):</span><br><span class="line">            closest_word = [x <span class="keyword">for</span> x, v <span class="keyword">in</span> word2id.items() <span class="keyword">if</span> v == nearest[k]]</span><br><span class="line">            log_info = <span class="string">'%s %s,'</span> % (log_info, closest_word)</span><br><span class="line">        print(log_info)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    batch_size = <span class="number">40</span></span><br><span class="line">    window_len = <span class="number">4</span></span><br><span class="line">    words, word2id, sentences, inputs, labels, vocab_size = get_data(obj_path, windows_len=window_len, lines_number=<span class="number">2000</span>)</span><br><span class="line">    train_data = TrainData(inputs, labels, words, vocab_size, batch_size)</span><br><span class="line">    batch_nums = train_data.get_batch_nums()</span><br><span class="line">    <span class="comment"># print(words)</span></span><br><span class="line">    print(<span class="string">"vocab_size: "</span>, vocab_size)</span><br><span class="line">    print(<span class="string">"batch_nums"</span>, batch_nums)</span><br><span class="line">    model = Model(vocab_size=vocab_size, embedding_size=<span class="number">128</span>, batch_nums=batch_nums, num_sampled=<span class="number">5</span>, learning_rate=<span class="number">0.0001</span>)</span><br><span class="line">    model.train(train_data=train_data, train_steps=<span class="number">150</span>)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    batch_size = <span class="number">200</span></span><br><span class="line">    window_len = <span class="number">4</span></span><br><span class="line">    words, word2id, sentences, inputs, labels, vocab_size = get_data(obj_path, windows_len=window_len,</span><br><span class="line">                                                                     lines_number=<span class="number">2000</span>)</span><br><span class="line">    test_word = []</span><br><span class="line">    <span class="keyword">for</span> count <span class="keyword">in</span> range(<span class="number">50</span>):</span><br><span class="line">        test_word.append(np.random.choice(words))</span><br><span class="line">    print(test_word)</span><br><span class="line">    predict(test_word, word2id)</span><br></pre></td></tr></table></figure></p>
<h2 id="两个方法"><a href="#两个方法" class="headerlink" title="两个方法"></a>两个方法</h2><h3 id="1、Negative-Sampling"><a href="#1、Negative-Sampling" class="headerlink" title="1、Negative Sampling"></a>1、Negative Sampling</h3><p>在每一个训练的时间步，我们不去遍历整个词汇表，而仅仅是抽取一些负样例。考虑一对中心词和上下文词$(w,c)$。这词对是来自训练数据集吗？我们通过$P(D=1\mid w,c)$表示$(w,c)$是来自语料库。相应地，$P(D=0\mid w,c)$表示$(w,c)$不是来自语料库。</p>
<p>现在，我们建立一个新的目标函数，如果中心词和上下文词确实在语料库中，就最大化概率$P(D=1\mid w,c)$，如果中心词和上下文词确实不在语料库中，就最大化概率$P(D=0\mid w,c)$。我们对这两个概率采用一个简单的极大似然估计的方法（这里我们把$\theta$作为模型的参数，在我们的例子是$\mathcal{V}$和$\mathcal{U}$）</p>
<script type="math/tex; mode=display">\begin{aligned} \theta &=\underset{\theta}{\operatorname{argmax}} \prod_{(w, c) \in D} P(D=1 | w, c, \theta) \prod_{(w, c) \in \widetilde{D}} P(D=0 | w, c, \theta) \\ &=\underset{\theta}{\operatorname{argmax}} \prod_{(w, c) \in D} P(D=1 | w, c, \theta) \prod_{(w, c) \in \widetilde{D}}(1-P(D=1 | w, c, \theta)) \\ &=\underset{\theta}{\operatorname{argmax}} \sum_{(w, c) \in D} \log P(D=1 | w, c, \theta)+\sum_{(w, c) \in \widetilde{D}} \log (1-P(D=1 | w, c, \theta)) \\ &=\arg \max _{\theta} \sum_{(w, c) \in D} \log \frac{1}{1+\exp \left(-u_{w}^{T} v_{c}\right)}+\sum_{(w, c) \in \widetilde{D}} \log \left(1-\frac{1}{1+\exp \left(-u_{w}^{T} v_{c}\right)}\right) \\ &=\arg \max _{\theta} \sum_{(w, c) \in D} \log \frac{1}{1+\exp \left(-u_{w}^{T} v_{c}\right)}+\sum_{(w, c) \in \widetilde{D}} \log \left(\frac{1}{1+\exp \left(u_{w}^{T} v_{c}\right)}\right) \end{aligned}</script><p>注意到最大化似然函数等同于最小化负对数似然：</p>
<script type="math/tex; mode=display">J=-\sum_{(w, c) \in D} \log \frac{1}{1+\exp \left(-u_{w}^{T} v_{c}\right)}-\sum_{(w, c) \in \widetilde{D}} \log \left(\frac{1}{1+\exp \left(u_{w}^{T} v_{c}\right)}\right)</script><p>注意$\widetilde{D}$是“假的”或者“负的”语料。例如我们有句子类似“stock boil fish is toy”，这种无意义的句子出现时会得到一个很低的概率。我们可以从语料库中随机抽样出负样例$\widetilde{D}$。</p>
<p>对于 Skip-Gram 模型，我们对给定中心词$c$来观察的上下文单词$c-m+j$的新目标函数为</p>
<script type="math/tex; mode=display">-\log \sigma\left(u_{c-m+j}^{T} \cdot v_{c}\right)-\sum_{k=1}^{K} \log \sigma\left(-\tilde{u}_{k}^{T} \cdot v_{c}\right)</script><p>对 CBOW 模型，我们对给定上下文向量$\widehat{v}=\frac{v_{c-m}+v_{c-m+1}+…+v_{c+m}}{2m}$来观察中心词$u_{c}$的新的目标函数为</p>
<script type="math/tex; mode=display">-log\,\sigma(u_{c}^{T}\cdot \widehat{v})-\sum_{k=1}^{K}log\,\sigma(-\widetilde{u}_{k}^{T}\cdot \widehat{v})</script><p>在上面的公式中，$\{\widetilde{u}_{k}\mid k=1…K\}$是从$P_{n}(w)$中抽样。有很多关于如何得到最好近似的讨论，从实际效果看来最好的是指数为 ¾ 的 Unigram 模型。那么为什么是 ¾？下面有一些例子对比可能让你有一些直观的了解：</p>
<script type="math/tex; mode=display">\begin{eqnarray} is: 0.9^{3/4} &=& 0.92 \nonumber \\ Constitution: 0.09^{3/4}&=& 0.16 \nonumber \\ bombastic:0.01^{3/4}&=& 0.032 \nonumber \end{eqnarray}</script><p>“Bombastic”当前被抽样的概率是原来的三倍，而“is”只比原来的提高了一点点。</p>
<h3 id="2、Hierarchical-Softmax"><a href="#2、Hierarchical-Softmax" class="headerlink" title="2、Hierarchical Softmax"></a>2、Hierarchical Softmax</h3><p>Mikolov 在论文《Distributed Representations of Words and Phrases and their Compositionality.》中提出了 hierarchical softmax，相比普通的 softmax 这是一种更有效的替代方法。<strong>在实际中，hierarchical softmax 对低频词往往表现得更好，负采样对高频词和较低维度向量表现得更好。</strong></p>
<p>Hierarchical softmax 使用一个二叉树来表示词表中的所有词。树中的每个叶结点都是一个单词，而且只有一条路径从根结点到叶结点。在这个模型中，没有词的输出表示。相反，图的每个节点（根节点和叶结点除外）与模型要学习的向量相关联。单词作为输出单词的概率定义为从根随机游走到单词所对应的叶的概率。计算成本变为$O(log (|V|))$而不是$O(|V|)$。</p>
<p>在这个模型中，给定一个向量$w_{i}$的下的单词$w$的概率$p(w\mid w_{i})$，等于从根结点开始到对应$w$的叶结点结束的随机漫步概率。这个方法最大的优势是计算概率的时间复杂度仅仅是$O(log(|V|))$，对应着路径的长度。</p>
<p>下图是 Hierarchical softmax 的二叉树示意图：</p>
<p><img src="/posts/NLP/10.png" alt></p>
<p>令$L(w)$为从根结点到叶结点$w$的路径中节点数目。例如，上图中的$L(w_{2})$为3。我们定义$n(w,i)$为与向量$v_{n(w,i)}$相关的路径上第$i$个结点。因此$n(w,1)$是根结点，而$n(w,L(w))$是$w$的父节点。现在对每个内部节点$n$，我们任意选取一个它的子节点，定义为$ch(n)$（一般是左节点）。然后，我们可以计算概率为</p>
<script type="math/tex; mode=display">p\left(w | w_{i}\right)=\prod_{j=1}^{L(w)-1} \sigma\left([n(w, j+1)=\operatorname{ch}(n(w, j))] \cdot v_{n(w, j)}^{T} v_{w_{i}}\right)</script><p>其中</p>
<script type="math/tex; mode=display">[x]=\left\{\begin{array}{ll}{1} & {\text { if } x \text { is true }} \\ {-1} & {\text { otherwise }}\end{array}\right.</script><p>这个公式看起来非常复杂，让我们细细梳理一下。</p>
<p>首先，我们将根据从根节点$(n(w,1))$到叶节点$(w)$的路径的形状来计算相乘的项。如果我们假设$ch(n)$一直都是$n$的左节点，然后当路径往左时$[n(w,j+1)=ch(n(w,j))]$的值返回 1，往右则返回 0。</p>
<p>此外，$[n(w,j+1)=ch(n(w,j))]$提供了归一化的作用。在节点$n$处，如果我们将去往左和右节点的概率相加，对于$v_{n}^{T}v_{w_{i}}$的任何值则可以检查，</p>
<script type="math/tex; mode=display">\sigma\left(v_{n}^{T} v_{w_{i}}\right)+\sigma\left(-v_{n}^{T} v_{w_{i}}\right)=1</script><p>归一化也保证了$\sum_{w=1}^{|V|}P(w\mid w_{i})=1$，和在普通的 softmax 是一样的。</p>
<p>最后我们计算点积来比较输入向量$v_{w_{i}}$对每个内部节点向量$v_{n(w,j)}^{T}$的相似度。下面我们给出一个例子。以上图中的$w_{2}$为例，从根节点要经过两次左边的边和一次右边的边才到达$w_{2}$，因此</p>
<script type="math/tex; mode=display">\begin{aligned} p\left(w_{2} | w_{i}\right) &=p\left(n\left(w_{2}, 1\right), \text {left}\right) \cdot p\left(n\left(w_{2}, 2\right), \text {left}\right) \cdot p\left(n\left(w_{2}, 3\right), \text { right }\right) \\ &=\sigma\left(v_{n\left(w_{2}, 1\right)}^{T} v_{w_{i}}\right) \cdot \sigma\left(v_{n\left(w_{2}, 2\right)}^{T} v_{w_{i}}\right) \cdot \sigma\left(-v_{n\left(w_{2}, 3\right)}^{T} v_{w_{i}}\right) \end{aligned}</script><p>我们训练模型的目标是最小化负的对数似然$-log\,P(w\mid w_{i})$。不是更新每个词的输出向量，而是更新更新二叉树中从根结点到叶结点的路径上的节点的向量。</p>
<p>该方法的速度由构建二叉树的方式确定，并将词分配给叶节点。Mikolov 在论文《Distributed Representations of Words and Phrases and their Compositionality.》中使用的是哈夫曼树，在树中分配高频词到较短的路径。</p>
<blockquote>
<p>参考文章：<br><a href="https://looperxx.github.io/CS224n-2019-01-Introduction%20and%20Word%20Vectors/" target="_blank" rel="noopener">https://looperxx.github.io/CS224n-2019-01-Introduction%20and%20Word%20Vectors/</a><br><a href="https://arxiv.org/abs/1310.4546" target="_blank" rel="noopener">https://arxiv.org/abs/1310.4546</a></p>
</blockquote>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title>新闻文本分类实战(二)</title>
    <url>/posts/e39af9a7.html</url>
    <content><![CDATA[<p>这里我们接着前面的<a href="https://chenk.tech/posts/eb79fc5f.html" target="_blank" rel="noopener">新闻文本实战的比赛案例</a>，在这里介绍了比赛数据以及实现了机器学习方法及fastText，Word2Vec等方法进行了文本分类，下面我们使用Bert（Transformer框架）对文本实现分类，关于Bert的具体原理在前面的博客都有涉及（<a href="https://chenk.tech/posts/1424e830.html" target="_blank" rel="noopener">传送门1</a>，<a href="https://chenk.tech/posts/aefe1ee4.html" target="_blank" rel="noopener">传送门2</a>），这里就不一一阐述了，下面直接上代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import logging</span><br><span class="line">import random</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import torch</span><br><span class="line"></span><br><span class="line">logging.basicConfig(level&#x3D;logging.INFO, format&#x3D;&#39;%(asctime)-15s %(levelname)s: %(message)s&#39;)</span><br><span class="line"></span><br><span class="line"># set seed</span><br><span class="line">seed &#x3D; 666</span><br><span class="line">random.seed(seed)</span><br><span class="line">np.random.seed(seed)</span><br><span class="line">torch.cuda.manual_seed(seed)</span><br><span class="line">torch.manual_seed(seed)</span><br><span class="line"></span><br><span class="line"># set cuda</span><br><span class="line">gpu &#x3D; 0</span><br><span class="line">use_cuda &#x3D; gpu &gt;&#x3D; 0 and torch.cuda.is_available()</span><br><span class="line">if use_cuda:</span><br><span class="line">    torch.cuda.set_device(gpu)</span><br><span class="line">    device &#x3D; torch.device(&quot;cuda&quot;, gpu)</span><br><span class="line">else:</span><br><span class="line">    device &#x3D; torch.device(&quot;cpu&quot;)</span><br><span class="line">logging.info(&quot;Use cuda: %s, gpu id: %d.&quot;, use_cuda, gpu)</span><br></pre></td></tr></table></figure>
<pre><code>2020-08-04 20:51:59,686 INFO: Use cuda: False, gpu id: 0.
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># split data to 10 fold</span></span><br><span class="line">fold_num = <span class="number">10</span></span><br><span class="line">data_file = <span class="string">'train.csv'</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">all_data2fold</span><span class="params">(fold_num, num=<span class="number">10000</span>)</span>:</span></span><br><span class="line">    fold_data = []</span><br><span class="line">    f = pd.read_csv(data_file, sep=<span class="string">'\t'</span>, encoding=<span class="string">'UTF-8'</span>)</span><br><span class="line">    texts = f[<span class="string">'text'</span>].tolist()[:num]</span><br><span class="line">    labels = f[<span class="string">'label'</span>].tolist()[:num]</span><br><span class="line"></span><br><span class="line">    total = len(labels)</span><br><span class="line"></span><br><span class="line">    index = list(range(total))</span><br><span class="line">    np.random.shuffle(index)</span><br><span class="line"></span><br><span class="line">    all_texts = []</span><br><span class="line">    all_labels = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> index:</span><br><span class="line">        all_texts.append(texts[i])</span><br><span class="line">        all_labels.append(labels[i])</span><br><span class="line"></span><br><span class="line">    label2id = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(total):</span><br><span class="line">        label = str(all_labels[i])</span><br><span class="line">        <span class="keyword">if</span> label <span class="keyword">not</span> <span class="keyword">in</span> label2id:</span><br><span class="line">            label2id[label] = [i]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            label2id[label].append(i)</span><br><span class="line"></span><br><span class="line">    all_index = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> range(fold_num)]</span><br><span class="line">    <span class="keyword">for</span> label, data <span class="keyword">in</span> label2id.items():</span><br><span class="line">        <span class="comment"># print(label, len(data))</span></span><br><span class="line">        batch_size = int(len(data) / fold_num)</span><br><span class="line">        other = len(data) - batch_size * fold_num</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(fold_num):</span><br><span class="line">            cur_batch_size = batch_size + <span class="number">1</span> <span class="keyword">if</span> i &lt; other <span class="keyword">else</span> batch_size</span><br><span class="line">            <span class="comment"># print(cur_batch_size)</span></span><br><span class="line">            batch_data = [data[i * batch_size + b] <span class="keyword">for</span> b <span class="keyword">in</span> range(cur_batch_size)]</span><br><span class="line">            all_index[i].extend(batch_data)</span><br><span class="line"></span><br><span class="line">    batch_size = int(total / fold_num)</span><br><span class="line">    other_texts = []</span><br><span class="line">    other_labels = []</span><br><span class="line">    other_num = <span class="number">0</span></span><br><span class="line">    start = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> fold <span class="keyword">in</span> range(fold_num):</span><br><span class="line">        num = len(all_index[fold])</span><br><span class="line">        texts = [all_texts[i] <span class="keyword">for</span> i <span class="keyword">in</span> all_index[fold]]</span><br><span class="line">        labels = [all_labels[i] <span class="keyword">for</span> i <span class="keyword">in</span> all_index[fold]]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> num &gt; batch_size:</span><br><span class="line">            fold_texts = texts[:batch_size]</span><br><span class="line">            other_texts.extend(texts[batch_size:])</span><br><span class="line">            fold_labels = labels[:batch_size]</span><br><span class="line">            other_labels.extend(labels[batch_size:])</span><br><span class="line">            other_num += num - batch_size</span><br><span class="line">        <span class="keyword">elif</span> num &lt; batch_size:</span><br><span class="line">            end = start + batch_size - num</span><br><span class="line">            fold_texts = texts + other_texts[start: end]</span><br><span class="line">            fold_labels = labels + other_labels[start: end]</span><br><span class="line">            start = end</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            fold_texts = texts</span><br><span class="line">            fold_labels = labels</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> batch_size == len(fold_labels)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># shuffle</span></span><br><span class="line">        index = list(range(batch_size))</span><br><span class="line">        np.random.shuffle(index)</span><br><span class="line"></span><br><span class="line">        shuffle_fold_texts = []</span><br><span class="line">        shuffle_fold_labels = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> index:</span><br><span class="line">            shuffle_fold_texts.append(fold_texts[i])</span><br><span class="line">            shuffle_fold_labels.append(fold_labels[i])</span><br><span class="line"></span><br><span class="line">        data = &#123;<span class="string">'label'</span>: shuffle_fold_labels, <span class="string">'text'</span>: shuffle_fold_texts&#125;</span><br><span class="line">        fold_data.append(data)</span><br><span class="line"></span><br><span class="line">    logging.info(<span class="string">"Fold lens %s"</span>, str([len(data[<span class="string">'label'</span>]) <span class="keyword">for</span> data <span class="keyword">in</span> fold_data]))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> fold_data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fold_data = all_data2fold(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<pre><code>2020-08-04 20:52:13,069 INFO: Fold lens [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># build train, dev, test data</span></span><br><span class="line">fold_id = <span class="number">9</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># dev</span></span><br><span class="line">dev_data = fold_data[fold_id]</span><br><span class="line"></span><br><span class="line"><span class="comment"># train</span></span><br><span class="line">train_texts = []</span><br><span class="line">train_labels = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, fold_id):</span><br><span class="line">    data = fold_data[i]</span><br><span class="line">    train_texts.extend(data[<span class="string">'text'</span>])</span><br><span class="line">    train_labels.extend(data[<span class="string">'label'</span>])</span><br><span class="line"></span><br><span class="line">train_data = &#123;<span class="string">'label'</span>: train_labels, <span class="string">'text'</span>: train_texts&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># test</span></span><br><span class="line">test_data_file = <span class="string">'test.csv'</span></span><br><span class="line">f = pd.read_csv(test_data_file, sep=<span class="string">'\t'</span>, encoding=<span class="string">'UTF-8'</span>)</span><br><span class="line">texts = f[<span class="string">'text'</span>].tolist()</span><br><span class="line">test_data = &#123;<span class="string">'label'</span>: [<span class="number">0</span>] * len(texts), <span class="string">'text'</span>: texts&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># build vocab</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BasicTokenizer</span><br><span class="line"></span><br><span class="line">basic_tokenizer = BasicTokenizer()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Vocab</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, train_data)</span>:</span></span><br><span class="line">        self.min_count = <span class="number">5</span></span><br><span class="line">        self.pad = <span class="number">0</span></span><br><span class="line">        self.unk = <span class="number">1</span></span><br><span class="line">        self._id2word = [<span class="string">'[PAD]'</span>, <span class="string">'[UNK]'</span>]</span><br><span class="line">        self._id2extword = [<span class="string">'[PAD]'</span>, <span class="string">'[UNK]'</span>]</span><br><span class="line"></span><br><span class="line">        self._id2label = []</span><br><span class="line">        self.target_names = []</span><br><span class="line"></span><br><span class="line">        self.build_vocab(train_data)</span><br><span class="line"></span><br><span class="line">        reverse = <span class="keyword">lambda</span> x: dict(zip(x, range(len(x))))</span><br><span class="line">        self._word2id = reverse(self._id2word)</span><br><span class="line">        self._label2id = reverse(self._id2label)</span><br><span class="line"></span><br><span class="line">        logging.info(<span class="string">"Build vocab: words %d, labels %d."</span> % (self.word_size, self.label_size))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_vocab</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        self.word_counter = Counter()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> text <span class="keyword">in</span> data[<span class="string">'text'</span>]:</span><br><span class="line">            words = text.split()</span><br><span class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">                self.word_counter[word] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> word, count <span class="keyword">in</span> self.word_counter.most_common():</span><br><span class="line">            <span class="keyword">if</span> count &gt;= self.min_count:</span><br><span class="line">                self._id2word.append(word)</span><br><span class="line"></span><br><span class="line">        label2name = &#123;<span class="number">0</span>: <span class="string">'科技'</span>, <span class="number">1</span>: <span class="string">'股票'</span>, <span class="number">2</span>: <span class="string">'体育'</span>, <span class="number">3</span>: <span class="string">'娱乐'</span>, <span class="number">4</span>: <span class="string">'时政'</span>, <span class="number">5</span>: <span class="string">'社会'</span>, <span class="number">6</span>: <span class="string">'教育'</span>, <span class="number">7</span>: <span class="string">'财经'</span>,</span><br><span class="line">                      <span class="number">8</span>: <span class="string">'家居'</span>, <span class="number">9</span>: <span class="string">'游戏'</span>, <span class="number">10</span>: <span class="string">'房产'</span>, <span class="number">11</span>: <span class="string">'时尚'</span>, <span class="number">12</span>: <span class="string">'彩票'</span>, <span class="number">13</span>: <span class="string">'星座'</span>&#125;</span><br><span class="line"></span><br><span class="line">        self.label_counter = Counter(data[<span class="string">'label'</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> label <span class="keyword">in</span> range(len(self.label_counter)):</span><br><span class="line">            count = self.label_counter[label]</span><br><span class="line">            self._id2label.append(label)</span><br><span class="line">            self.target_names.append(label2name[label])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load_pretrained_embs</span><span class="params">(self, embfile)</span>:</span></span><br><span class="line">        <span class="keyword">with</span> open(embfile, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            lines = f.readlines()</span><br><span class="line">            items = lines[<span class="number">0</span>].split()</span><br><span class="line">            word_count, embedding_dim = int(items[<span class="number">0</span>]), int(items[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        index = len(self._id2extword)</span><br><span class="line">        embeddings = np.zeros((word_count + index, embedding_dim))</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> lines[<span class="number">1</span>:]:</span><br><span class="line">            values = line.split()</span><br><span class="line">            self._id2extword.append(values[<span class="number">0</span>])</span><br><span class="line">            vector = np.array(values[<span class="number">1</span>:], dtype=<span class="string">'float64'</span>)</span><br><span class="line">            embeddings[self.unk] += vector</span><br><span class="line">            embeddings[index] = vector</span><br><span class="line">            index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        embeddings[self.unk] = embeddings[self.unk] / word_count</span><br><span class="line">        embeddings = embeddings / np.std(embeddings)</span><br><span class="line"></span><br><span class="line">        reverse = <span class="keyword">lambda</span> x: dict(zip(x, range(len(x))))</span><br><span class="line">        self._extword2id = reverse(self._id2extword)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> len(set(self._id2extword)) == len(self._id2extword)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> embeddings</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">word2id</span><span class="params">(self, xs)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(xs, list):</span><br><span class="line">            <span class="keyword">return</span> [self._word2id.get(x, self.unk) <span class="keyword">for</span> x <span class="keyword">in</span> xs]</span><br><span class="line">        <span class="keyword">return</span> self._word2id.get(xs, self.unk)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">extword2id</span><span class="params">(self, xs)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(xs, list):</span><br><span class="line">            <span class="keyword">return</span> [self._extword2id.get(x, self.unk) <span class="keyword">for</span> x <span class="keyword">in</span> xs]</span><br><span class="line">        <span class="keyword">return</span> self._extword2id.get(xs, self.unk)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">label2id</span><span class="params">(self, xs)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(xs, list):</span><br><span class="line">            <span class="keyword">return</span> [self._label2id.get(x, self.unk) <span class="keyword">for</span> x <span class="keyword">in</span> xs]</span><br><span class="line">        <span class="keyword">return</span> self._label2id.get(xs, self.unk)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">word_size</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self._id2word)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">extword_size</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self._id2extword)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">label_size</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self._id2label)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">vocab = Vocab(train_data)</span><br></pre></td></tr></table></figure>
<pre><code>2020-08-04 20:52:21,004 INFO: PyTorch version 1.6.0+cpu available.
2020-08-04 20:52:23,281 INFO: Build vocab: words 4337, labels 14.
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># build module</span></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Attention</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, hidden_size)</span>:</span></span><br><span class="line">        super(Attention, self).__init__()</span><br><span class="line">        self.weight = nn.Parameter(torch.Tensor(hidden_size, hidden_size))</span><br><span class="line">        self.weight.data.normal_(mean=<span class="number">0.0</span>, std=<span class="number">0.05</span>)</span><br><span class="line"></span><br><span class="line">        self.bias = nn.Parameter(torch.Tensor(hidden_size))</span><br><span class="line">        b = np.zeros(hidden_size, dtype=np.float32)</span><br><span class="line">        self.bias.data.copy_(torch.from_numpy(b))</span><br><span class="line"></span><br><span class="line">        self.query = nn.Parameter(torch.Tensor(hidden_size))</span><br><span class="line">        self.query.data.normal_(mean=<span class="number">0.0</span>, std=<span class="number">0.05</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, batch_hidden, batch_masks)</span>:</span></span><br><span class="line">        <span class="comment"># batch_hidden: b x len x hidden_size (2 * hidden_size of lstm)</span></span><br><span class="line">        <span class="comment"># batch_masks:  b x len</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># linear</span></span><br><span class="line">        key = torch.matmul(batch_hidden, self.weight) + self.bias  <span class="comment"># b x len x hidden</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute attention</span></span><br><span class="line">        outputs = torch.matmul(key, self.query)  <span class="comment"># b x len</span></span><br><span class="line"></span><br><span class="line">        masked_outputs = outputs.masked_fill((<span class="number">1</span> - batch_masks).bool(), float(<span class="number">-1e32</span>))</span><br><span class="line"></span><br><span class="line">        attn_scores = F.softmax(masked_outputs, dim=<span class="number">1</span>)  <span class="comment"># b x len</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对于全零向量，-1e32的结果为 1/len, -inf为nan, 额外补0</span></span><br><span class="line">        masked_attn_scores = attn_scores.masked_fill((<span class="number">1</span> - batch_masks).bool(), <span class="number">0.0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># sum weighted sources</span></span><br><span class="line">        batch_outputs = torch.bmm(masked_attn_scores.unsqueeze(<span class="number">1</span>), key).squeeze(<span class="number">1</span>)  <span class="comment"># b x hidden</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> batch_outputs, attn_scores</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># build word encoder</span></span><br><span class="line"><span class="comment"># bert_path = 'bert/bert-mini/'</span></span><br><span class="line">dropout = <span class="number">0.15</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertModel</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WordBertEncoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(WordBertEncoder, self).__init__()</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">        self.tokenizer = WhitespaceTokenizer()</span><br><span class="line">        self.bert = BertModel.from_pretrained(bert_path)</span><br><span class="line"></span><br><span class="line">        self.pooled = <span class="literal">False</span></span><br><span class="line">        logging.info(<span class="string">'Build Bert encoder with pooled &#123;&#125;.'</span>.format(self.pooled))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">encode</span><span class="params">(self, tokens)</span>:</span></span><br><span class="line">        tokens = self.tokenizer.tokenize(tokens)</span><br><span class="line">        <span class="keyword">return</span> tokens</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_bert_parameters</span><span class="params">(self)</span>:</span></span><br><span class="line">        no_decay = [<span class="string">'bias'</span>, <span class="string">'LayerNorm.weight'</span>]</span><br><span class="line">        optimizer_parameters = [</span><br><span class="line">            &#123;<span class="string">'params'</span>: [p <span class="keyword">for</span> n, p <span class="keyword">in</span> self.bert.named_parameters() <span class="keyword">if</span> <span class="keyword">not</span> any(nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> no_decay)],</span><br><span class="line">             <span class="string">'weight_decay'</span>: <span class="number">0.01</span>&#125;,</span><br><span class="line">            &#123;<span class="string">'params'</span>: [p <span class="keyword">for</span> n, p <span class="keyword">in</span> self.bert.named_parameters() <span class="keyword">if</span> any(nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> no_decay)],</span><br><span class="line">             <span class="string">'weight_decay'</span>: <span class="number">0.0</span>&#125;</span><br><span class="line">        ]</span><br><span class="line">        <span class="keyword">return</span> optimizer_parameters</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input_ids, token_type_ids)</span>:</span></span><br><span class="line">        <span class="comment"># input_ids: sen_num x bert_len</span></span><br><span class="line">        <span class="comment"># token_type_ids: sen_num  x bert_len</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># sen_num x bert_len x 256, sen_num x 256</span></span><br><span class="line">        sequence_output, pooled_output = self.bert(input_ids=input_ids, token_type_ids=token_type_ids)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.pooled:</span><br><span class="line">            reps = pooled_output</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            reps = sequence_output[:, <span class="number">0</span>, :]  <span class="comment"># sen_num x 256</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.training:</span><br><span class="line">            reps = self.dropout(reps)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> reps</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WhitespaceTokenizer</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""WhitespaceTokenizer with vocab."""</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        vocab_file = bert_path + <span class="string">'vocab.txt'</span></span><br><span class="line">        self._token2id = self.load_vocab(vocab_file)</span><br><span class="line">        self._id2token = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> self._token2id.items()&#125;</span><br><span class="line">        self.max_len = <span class="number">256</span></span><br><span class="line">        self.unk = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        logging.info(<span class="string">"Build Bert vocab with size %d."</span> % (self.vocab_size))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load_vocab</span><span class="params">(self, vocab_file)</span>:</span></span><br><span class="line">        f = open(vocab_file, <span class="string">'r'</span>)</span><br><span class="line">        lines = f.readlines()</span><br><span class="line">        lines = list(map(<span class="keyword">lambda</span> x: x.strip(), lines))</span><br><span class="line">        vocab = dict(zip(lines, range(len(lines))))</span><br><span class="line">        <span class="keyword">return</span> vocab</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tokenize</span><span class="params">(self, tokens)</span>:</span></span><br><span class="line">        <span class="keyword">assert</span> len(tokens) &lt;= self.max_len - <span class="number">2</span></span><br><span class="line">        tokens = [<span class="string">"[CLS]"</span>] + tokens + [<span class="string">"[SEP]"</span>]</span><br><span class="line">        output_tokens = self.token2id(tokens)</span><br><span class="line">        <span class="keyword">return</span> output_tokens</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">token2id</span><span class="params">(self, xs)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(xs, list):</span><br><span class="line">            <span class="keyword">return</span> [self._token2id.get(x, self.unk) <span class="keyword">for</span> x <span class="keyword">in</span> xs]</span><br><span class="line">        <span class="keyword">return</span> self._token2id.get(xs, self.unk)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">vocab_size</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self._id2token)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># build sent encoder</span></span><br><span class="line">sent_hidden_size = <span class="number">256</span></span><br><span class="line">sent_num_layers = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SentEncoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, sent_rep_size)</span>:</span></span><br><span class="line">        super(SentEncoder, self).__init__()</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">        self.sent_lstm = nn.LSTM(</span><br><span class="line">            input_size=sent_rep_size,</span><br><span class="line">            hidden_size=sent_hidden_size,</span><br><span class="line">            num_layers=sent_num_layers,</span><br><span class="line">            batch_first=<span class="literal">True</span>,</span><br><span class="line">            bidirectional=<span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, sent_reps, sent_masks)</span>:</span></span><br><span class="line">        <span class="comment"># sent_reps:  b x doc_len x sent_rep_size</span></span><br><span class="line">        <span class="comment"># sent_masks: b x doc_len</span></span><br><span class="line"></span><br><span class="line">        sent_hiddens, _ = self.sent_lstm(sent_reps)  <span class="comment"># b x doc_len x hidden*2</span></span><br><span class="line">        sent_hiddens = sent_hiddens * sent_masks.unsqueeze(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.training:</span><br><span class="line">            sent_hiddens = self.dropout(sent_hiddens)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> sent_hiddens</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># build model</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, vocab)</span>:</span></span><br><span class="line">        super(Model, self).__init__()</span><br><span class="line">        self.sent_rep_size = <span class="number">256</span></span><br><span class="line">        self.doc_rep_size = sent_hidden_size * <span class="number">2</span></span><br><span class="line">        self.all_parameters = &#123;&#125;</span><br><span class="line">        parameters = []</span><br><span class="line">        self.word_encoder = WordBertEncoder()</span><br><span class="line">        bert_parameters = self.word_encoder.get_bert_parameters()</span><br><span class="line"></span><br><span class="line">        self.sent_encoder = SentEncoder(self.sent_rep_size)</span><br><span class="line">        self.sent_attention = Attention(self.doc_rep_size)</span><br><span class="line">        parameters.extend(list(filter(<span class="keyword">lambda</span> p: p.requires_grad, self.sent_encoder.parameters())))</span><br><span class="line">        parameters.extend(list(filter(<span class="keyword">lambda</span> p: p.requires_grad, self.sent_attention.parameters())))</span><br><span class="line"></span><br><span class="line">        self.out = nn.Linear(self.doc_rep_size, vocab.label_size, bias=<span class="literal">True</span>)</span><br><span class="line">        parameters.extend(list(filter(<span class="keyword">lambda</span> p: p.requires_grad, self.out.parameters())))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> use_cuda:</span><br><span class="line">            self.to(device)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> len(parameters) &gt; <span class="number">0</span>:</span><br><span class="line">            self.all_parameters[<span class="string">"basic_parameters"</span>] = parameters</span><br><span class="line">        self.all_parameters[<span class="string">"bert_parameters"</span>] = bert_parameters</span><br><span class="line"></span><br><span class="line">        logging.info(<span class="string">'Build model with bert word encoder, lstm sent encoder.'</span>)</span><br><span class="line"></span><br><span class="line">        para_num = sum([np.prod(list(p.size())) <span class="keyword">for</span> p <span class="keyword">in</span> self.parameters()])</span><br><span class="line">        logging.info(<span class="string">'Model param num: %.2f M.'</span> % (para_num / <span class="number">1e6</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, batch_inputs)</span>:</span></span><br><span class="line">        <span class="comment"># batch_inputs(batch_inputs1, batch_inputs2): b x doc_len x sent_len</span></span><br><span class="line">        <span class="comment"># batch_masks : b x doc_len x sent_len</span></span><br><span class="line">        batch_inputs1, batch_inputs2, batch_masks = batch_inputs</span><br><span class="line">        batch_size, max_doc_len, max_sent_len = batch_inputs1.shape[<span class="number">0</span>], batch_inputs1.shape[<span class="number">1</span>], batch_inputs1.shape[<span class="number">2</span>]</span><br><span class="line">        batch_inputs1 = batch_inputs1.view(batch_size * max_doc_len, max_sent_len)  <span class="comment"># sen_num x sent_len</span></span><br><span class="line">        batch_inputs2 = batch_inputs2.view(batch_size * max_doc_len, max_sent_len)  <span class="comment"># sen_num x sent_len</span></span><br><span class="line">        batch_masks = batch_masks.view(batch_size * max_doc_len, max_sent_len)  <span class="comment"># sen_num x sent_len</span></span><br><span class="line"></span><br><span class="line">        sent_reps = self.word_encoder(batch_inputs1, batch_inputs2)  <span class="comment"># sen_num x sent_rep_size</span></span><br><span class="line"></span><br><span class="line">        sent_reps = sent_reps.view(batch_size, max_doc_len, self.sent_rep_size)  <span class="comment"># b x doc_len x sent_rep_size</span></span><br><span class="line">        batch_masks = batch_masks.view(batch_size, max_doc_len, max_sent_len)  <span class="comment"># b x doc_len x max_sent_len</span></span><br><span class="line">        sent_masks = batch_masks.bool().any(<span class="number">2</span>).float()  <span class="comment"># b x doc_len</span></span><br><span class="line"></span><br><span class="line">        sent_hiddens = self.sent_encoder(sent_reps, sent_masks)  <span class="comment"># b x doc_len x doc_rep_size</span></span><br><span class="line">        doc_reps, atten_scores = self.sent_attention(sent_hiddens, sent_masks)  <span class="comment"># b x doc_rep_size</span></span><br><span class="line"></span><br><span class="line">        batch_outputs = self.out(doc_reps)  <span class="comment"># b x num_labels</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> batch_outputs</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">bert_path = <span class="string">'bert/bert-mini/'</span></span><br><span class="line">model = Model(vocab)</span><br></pre></td></tr></table></figure>
<pre><code>2020-08-04 21:08:52,810 INFO: Build Bert vocab with size 5981.
2020-08-04 21:08:52,812 INFO: loading configuration file bert/bert-mini/config.json
2020-08-04 21:08:52,812 INFO: Model config BertConfig {
  &quot;attention_probs_dropout_prob&quot;: 0.1,
  &quot;gradient_checkpointing&quot;: false,
  &quot;hidden_act&quot;: &quot;gelu&quot;,
  &quot;hidden_dropout_prob&quot;: 0.1,
  &quot;hidden_size&quot;: 256,
  &quot;initializer_range&quot;: 0.02,
  &quot;intermediate_size&quot;: 1024,
  &quot;layer_norm_eps&quot;: 1e-12,
  &quot;max_position_embeddings&quot;: 256,
  &quot;model_type&quot;: &quot;bert&quot;,
  &quot;num_attention_heads&quot;: 4,
  &quot;num_hidden_layers&quot;: 4,
  &quot;pad_token_id&quot;: 0,
  &quot;type_vocab_size&quot;: 2,
  &quot;vocab_size&quot;: 5981
}

2020-08-04 21:08:52,814 INFO: loading weights file bert/bert-mini/pytorch_model.bin
2020-08-04 21:08:53,114 INFO: All model checkpoint weights were used when initializing BertModel.

2020-08-04 21:08:53,115 INFO: All the weights of BertModel were initialized from the model checkpoint at bert/bert-mini/.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertModel for predictions without further training.
2020-08-04 21:08:53,117 INFO: Build Bert encoder with pooled False.
2020-08-04 21:08:53,156 INFO: Build model with bert word encoder, lstm sent encoder.
2020-08-04 21:08:53,159 INFO: Model param num: 7.72 M.
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># build optimizer</span></span><br><span class="line">learning_rate = <span class="number">2e-4</span></span><br><span class="line">bert_lr = <span class="number">5e-5</span></span><br><span class="line">decay = <span class="number">.75</span></span><br><span class="line">decay_step = <span class="number">1000</span></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AdamW, get_linear_schedule_with_warmup</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Optimizer</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, model_parameters, steps)</span>:</span></span><br><span class="line">        self.all_params = []</span><br><span class="line">        self.optims = []</span><br><span class="line">        self.schedulers = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> name, parameters <span class="keyword">in</span> model_parameters.items():</span><br><span class="line">            <span class="keyword">if</span> name.startswith(<span class="string">"basic"</span>):</span><br><span class="line">                optim = torch.optim.Adam(parameters, lr=learning_rate)</span><br><span class="line">                self.optims.append(optim)</span><br><span class="line"></span><br><span class="line">                l = <span class="keyword">lambda</span> step: decay ** (step // decay_step)</span><br><span class="line">                scheduler = torch.optim.lr_scheduler.LambdaLR(optim, lr_lambda=l)</span><br><span class="line">                self.schedulers.append(scheduler)</span><br><span class="line">                self.all_params.extend(parameters)</span><br><span class="line">            <span class="keyword">elif</span> name.startswith(<span class="string">"bert"</span>):</span><br><span class="line">                optim_bert = AdamW(parameters, bert_lr, eps=<span class="number">1e-8</span>)</span><br><span class="line">                self.optims.append(optim_bert)</span><br><span class="line"></span><br><span class="line">                scheduler_bert = get_linear_schedule_with_warmup(optim_bert, <span class="number">0</span>, steps)</span><br><span class="line">                self.schedulers.append(scheduler_bert)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">for</span> group <span class="keyword">in</span> parameters:</span><br><span class="line">                    <span class="keyword">for</span> p <span class="keyword">in</span> group[<span class="string">'params'</span>]:</span><br><span class="line">                        self.all_params.append(p)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                Exception(<span class="string">"no nameed parameters."</span>)</span><br><span class="line"></span><br><span class="line">        self.num = len(self.optims)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">step</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> optim, scheduler <span class="keyword">in</span> zip(self.optims, self.schedulers):</span><br><span class="line">            optim.step()</span><br><span class="line">            scheduler.step()</span><br><span class="line">            optim.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">zero_grad</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> optim <span class="keyword">in</span> self.optims:</span><br><span class="line">            optim.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_lr</span><span class="params">(self)</span>:</span></span><br><span class="line">        lrs = tuple(map(<span class="keyword">lambda</span> x: x.get_lr()[<span class="number">-1</span>], self.schedulers))</span><br><span class="line">        lr = <span class="string">' %.5f'</span> * self.num</span><br><span class="line">        res = lr % lrs</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># build dataset</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sentence_split</span><span class="params">(text, vocab, max_sent_len=<span class="number">256</span>, max_segment=<span class="number">16</span>)</span>:</span></span><br><span class="line">    words = text.strip().split()</span><br><span class="line">    document_len = len(words)</span><br><span class="line"></span><br><span class="line">    index = list(range(<span class="number">0</span>, document_len, max_sent_len))</span><br><span class="line">    index.append(document_len)</span><br><span class="line"></span><br><span class="line">    segments = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(index) - <span class="number">1</span>):</span><br><span class="line">        segment = words[index[i]: index[i + <span class="number">1</span>]]</span><br><span class="line">        <span class="keyword">assert</span> len(segment) &gt; <span class="number">0</span></span><br><span class="line">        segment = [word <span class="keyword">if</span> word <span class="keyword">in</span> vocab._id2word <span class="keyword">else</span> <span class="string">'&lt;UNK&gt;'</span> <span class="keyword">for</span> word <span class="keyword">in</span> segment]</span><br><span class="line">        segments.append([len(segment), segment])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> len(segments) &gt; <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> len(segments) &gt; max_segment:</span><br><span class="line">        segment_ = int(max_segment / <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> segments[:segment_] + segments[-segment_:]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> segments</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_examples</span><span class="params">(data, word_encoder, vocab, max_sent_len=<span class="number">256</span>, max_segment=<span class="number">8</span>)</span>:</span></span><br><span class="line">    label2id = vocab.label2id</span><br><span class="line">    examples = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> text, label <span class="keyword">in</span> zip(data[<span class="string">'text'</span>], data[<span class="string">'label'</span>]):</span><br><span class="line">        <span class="comment"># label</span></span><br><span class="line">        id = label2id(label)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># words</span></span><br><span class="line">        sents_words = sentence_split(text, vocab, max_sent_len<span class="number">-2</span>, max_segment)</span><br><span class="line">        doc = []</span><br><span class="line">        <span class="keyword">for</span> sent_len, sent_words <span class="keyword">in</span> sents_words:</span><br><span class="line">            token_ids = word_encoder.encode(sent_words)</span><br><span class="line">            sent_len = len(token_ids)</span><br><span class="line">            token_type_ids = [<span class="number">0</span>] * sent_len</span><br><span class="line">            doc.append([sent_len, token_ids, token_type_ids])</span><br><span class="line">        examples.append([id, len(doc), doc])</span><br><span class="line"></span><br><span class="line">    logging.info(<span class="string">'Total %d docs.'</span> % len(examples))</span><br><span class="line">    <span class="keyword">return</span> examples</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># build loader</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batch_slice</span><span class="params">(data, batch_size)</span>:</span></span><br><span class="line">    batch_num = int(np.ceil(len(data) / float(batch_size)))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(batch_num):</span><br><span class="line">        cur_batch_size = batch_size <span class="keyword">if</span> i &lt; batch_num - <span class="number">1</span> <span class="keyword">else</span> len(data) - batch_size * i</span><br><span class="line">        docs = [data[i * batch_size + b] <span class="keyword">for</span> b <span class="keyword">in</span> range(cur_batch_size)]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> docs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_iter</span><span class="params">(data, batch_size, shuffle=True, noise=<span class="number">1.0</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    randomly permute data, then sort by source length, and partition into batches</span></span><br><span class="line"><span class="string">    ensure that the length of  sentences in each batch</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    batched_data = []</span><br><span class="line">    <span class="keyword">if</span> shuffle:</span><br><span class="line">        np.random.shuffle(data)</span><br><span class="line"></span><br><span class="line">        lengths = [example[<span class="number">1</span>] <span class="keyword">for</span> example <span class="keyword">in</span> data]</span><br><span class="line">        noisy_lengths = [- (l + np.random.uniform(- noise, noise)) <span class="keyword">for</span> l <span class="keyword">in</span> lengths]</span><br><span class="line">        sorted_indices = np.argsort(noisy_lengths).tolist()</span><br><span class="line">        sorted_data = [data[i] <span class="keyword">for</span> i <span class="keyword">in</span> sorted_indices]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        sorted_data =data</span><br><span class="line">        </span><br><span class="line">    batched_data.extend(list(batch_slice(sorted_data, batch_size)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> shuffle:</span><br><span class="line">        np.random.shuffle(batched_data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> batched_data:</span><br><span class="line">        <span class="keyword">yield</span> batch</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># some function</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score, precision_score, recall_score</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_score</span><span class="params">(y_ture, y_pred)</span>:</span></span><br><span class="line">    y_ture = np.array(y_ture)</span><br><span class="line">    y_pred = np.array(y_pred)</span><br><span class="line">    f1 = f1_score(y_ture, y_pred, average=<span class="string">'macro'</span>) * <span class="number">100</span></span><br><span class="line">    p = precision_score(y_ture, y_pred, average=<span class="string">'macro'</span>) * <span class="number">100</span></span><br><span class="line">    r = recall_score(y_ture, y_pred, average=<span class="string">'macro'</span>) * <span class="number">100</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> str((reformat(p, <span class="number">2</span>), reformat(r, <span class="number">2</span>), reformat(f1, <span class="number">2</span>))), reformat(f1, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reformat</span><span class="params">(num, n)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> float(format(num, <span class="string">'0.'</span> + str(n) + <span class="string">'f'</span>))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># build trainer</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"></span><br><span class="line">clip = <span class="number">5.0</span></span><br><span class="line">epochs = <span class="number">1</span></span><br><span class="line">early_stops = <span class="number">3</span></span><br><span class="line">log_interval = <span class="number">50</span></span><br><span class="line"></span><br><span class="line">test_batch_size = <span class="number">16</span></span><br><span class="line">train_batch_size = <span class="number">16</span></span><br><span class="line"></span><br><span class="line">save_model = <span class="string">'./bert.bin'</span></span><br><span class="line">save_test = <span class="string">'./bert.csv'</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Trainer</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, model, vocab)</span>:</span></span><br><span class="line">        self.model = model</span><br><span class="line">        self.report = <span class="literal">True</span></span><br><span class="line">        </span><br><span class="line">        self.train_data = get_examples(train_data, model.word_encoder, vocab)</span><br><span class="line">        self.batch_num = int(np.ceil(len(self.train_data) / float(train_batch_size)))</span><br><span class="line">        self.dev_data = get_examples(dev_data, model.word_encoder, vocab)</span><br><span class="line">        self.test_data = get_examples(test_data, model.word_encoder, vocab)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># criterion</span></span><br><span class="line">        self.criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># label name</span></span><br><span class="line">        self.target_names = vocab.target_names</span><br><span class="line"></span><br><span class="line">        <span class="comment"># optimizer</span></span><br><span class="line">        self.optimizer = Optimizer(model.all_parameters, steps=self.batch_num * epochs)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># count</span></span><br><span class="line">        self.step = <span class="number">0</span></span><br><span class="line">        self.early_stop = <span class="number">-1</span></span><br><span class="line">        self.best_train_f1, self.best_dev_f1 = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        self.last_epoch = epochs</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self)</span>:</span></span><br><span class="line">        logging.info(<span class="string">'Start training...'</span>)</span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>, epochs + <span class="number">1</span>):</span><br><span class="line">            train_f1 = self._train(epoch)</span><br><span class="line"></span><br><span class="line">            dev_f1 = self._eval(epoch)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> self.best_dev_f1 &lt;= dev_f1:</span><br><span class="line">                logging.info(</span><br><span class="line">                    <span class="string">"Exceed history dev = %.2f, current dev = %.2f"</span> % (self.best_dev_f1, dev_f1))</span><br><span class="line">                torch.save(self.model.state_dict(), save_model)</span><br><span class="line"></span><br><span class="line">                self.best_train_f1 = train_f1</span><br><span class="line">                self.best_dev_f1 = dev_f1</span><br><span class="line">                self.early_stop = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                self.early_stop += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> self.early_stop == early_stops:</span><br><span class="line">                    logging.info(</span><br><span class="line">                        <span class="string">"Eearly stop in epoch %d, best train: %.2f, dev: %.2f"</span> % (</span><br><span class="line">                            epoch - early_stops, self.best_train_f1, self.best_dev_f1))</span><br><span class="line">                    self.last_epoch = epoch</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.model.load_state_dict(torch.load(save_model))</span><br><span class="line">        self._eval(self.last_epoch + <span class="number">1</span>, test=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_train</span><span class="params">(self, epoch)</span>:</span></span><br><span class="line">        self.optimizer.zero_grad()</span><br><span class="line">        self.model.train()</span><br><span class="line"></span><br><span class="line">        start_time = time.time()</span><br><span class="line">        epoch_start_time = time.time()</span><br><span class="line">        overall_losses = <span class="number">0</span></span><br><span class="line">        losses = <span class="number">0</span></span><br><span class="line">        batch_idx = <span class="number">1</span></span><br><span class="line">        y_pred = []</span><br><span class="line">        y_true = []</span><br><span class="line">        <span class="keyword">for</span> batch_data <span class="keyword">in</span> data_iter(self.train_data, train_batch_size, shuffle=<span class="literal">True</span>):</span><br><span class="line">            torch.cuda.empty_cache()</span><br><span class="line">            batch_inputs, batch_labels = self.batch2tensor(batch_data)</span><br><span class="line">            batch_outputs = self.model(batch_inputs)</span><br><span class="line">            loss = self.criterion(batch_outputs, batch_labels)</span><br><span class="line">            loss.backward()</span><br><span class="line"></span><br><span class="line">            loss_value = loss.detach().cpu().item()</span><br><span class="line">            losses += loss_value</span><br><span class="line">            overall_losses += loss_value</span><br><span class="line"></span><br><span class="line">            y_pred.extend(torch.max(batch_outputs, dim=<span class="number">1</span>)[<span class="number">1</span>].cpu().numpy().tolist())</span><br><span class="line">            y_true.extend(batch_labels.cpu().numpy().tolist())</span><br><span class="line"></span><br><span class="line">            nn.utils.clip_grad_norm_(self.optimizer.all_params, max_norm=clip)</span><br><span class="line">            <span class="keyword">for</span> optimizer, scheduler <span class="keyword">in</span> zip(self.optimizer.optims, self.optimizer.schedulers):</span><br><span class="line">                optimizer.step()</span><br><span class="line">                scheduler.step()</span><br><span class="line">            self.optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">            self.step += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> batch_idx % log_interval == <span class="number">0</span>:</span><br><span class="line">                elapsed = time.time() - start_time</span><br><span class="line"></span><br><span class="line">                lrs = self.optimizer.get_lr()</span><br><span class="line">                logging.info(</span><br><span class="line">                    <span class="string">'| epoch &#123;:3d&#125; | step &#123;:3d&#125; | batch &#123;:3d&#125;/&#123;:3d&#125; | lr&#123;&#125; | loss &#123;:.4f&#125; | s/batch &#123;:.2f&#125;'</span>.format(</span><br><span class="line">                        epoch, self.step, batch_idx, self.batch_num, lrs,</span><br><span class="line">                        losses / log_interval,</span><br><span class="line">                        elapsed / log_interval))</span><br><span class="line"></span><br><span class="line">                losses = <span class="number">0</span></span><br><span class="line">                start_time = time.time()</span><br><span class="line"></span><br><span class="line">            batch_idx += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        overall_losses /= self.batch_num</span><br><span class="line">        during_time = time.time() - epoch_start_time</span><br><span class="line"></span><br><span class="line">        <span class="comment"># reformat</span></span><br><span class="line">        overall_losses = reformat(overall_losses, <span class="number">4</span>)</span><br><span class="line">        score, f1 = get_score(y_true, y_pred)</span><br><span class="line"></span><br><span class="line">        logging.info(</span><br><span class="line">            <span class="string">'| epoch &#123;:3d&#125; | score &#123;&#125; | f1 &#123;&#125; | loss &#123;:.4f&#125; | time &#123;:.2f&#125;'</span>.format(epoch, score, f1,</span><br><span class="line">                                                                                  overall_losses,</span><br><span class="line">                                                                                  during_time))</span><br><span class="line">        <span class="keyword">if</span> set(y_true) == set(y_pred) <span class="keyword">and</span> self.report:</span><br><span class="line">            report = classification_report(y_true, y_pred, digits=<span class="number">4</span>, target_names=self.target_names)</span><br><span class="line">            logging.info(<span class="string">'\n'</span> + report)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> f1</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_eval</span><span class="params">(self, epoch, test=False)</span>:</span></span><br><span class="line">        self.model.eval()</span><br><span class="line">        start_time = time.time()</span><br><span class="line">        data = self.test_data <span class="keyword">if</span> test <span class="keyword">else</span> self.dev_data</span><br><span class="line">        y_pred = []</span><br><span class="line">        y_true = []</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            <span class="keyword">for</span> batch_data <span class="keyword">in</span> data_iter(data, test_batch_size, shuffle=<span class="literal">False</span>):</span><br><span class="line">                torch.cuda.empty_cache()</span><br><span class="line">                batch_inputs, batch_labels = self.batch2tensor(batch_data)</span><br><span class="line">                batch_outputs = self.model(batch_inputs)</span><br><span class="line">                y_pred.extend(torch.max(batch_outputs, dim=<span class="number">1</span>)[<span class="number">1</span>].cpu().numpy().tolist())</span><br><span class="line">                y_true.extend(batch_labels.cpu().numpy().tolist())</span><br><span class="line"></span><br><span class="line">            score, f1 = get_score(y_true, y_pred)</span><br><span class="line"></span><br><span class="line">            during_time = time.time() - start_time</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> test:</span><br><span class="line">                df = pd.DataFrame(&#123;<span class="string">'label'</span>: y_pred&#125;)</span><br><span class="line">                df.to_csv(save_test, index=<span class="literal">False</span>, sep=<span class="string">','</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                logging.info(</span><br><span class="line">                    <span class="string">'| epoch &#123;:3d&#125; | dev | score &#123;&#125; | f1 &#123;&#125; | time &#123;:.2f&#125;'</span>.format(epoch, score, f1,</span><br><span class="line">                                                                              during_time))</span><br><span class="line">                <span class="keyword">if</span> set(y_true) == set(y_pred) <span class="keyword">and</span> self.report:</span><br><span class="line">                    report = classification_report(y_true, y_pred, digits=<span class="number">4</span>, target_names=self.target_names)</span><br><span class="line">                    logging.info(<span class="string">'\n'</span> + report)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> f1</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">batch2tensor</span><span class="params">(self, batch_data)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">            [[label, doc_len, [[sent_len, [sent_id0, ...], [sent_id1, ...]], ...]]</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        batch_size = len(batch_data)</span><br><span class="line">        doc_labels = []</span><br><span class="line">        doc_lens = []</span><br><span class="line">        doc_max_sent_len = []</span><br><span class="line">        <span class="keyword">for</span> doc_data <span class="keyword">in</span> batch_data:</span><br><span class="line">            doc_labels.append(doc_data[<span class="number">0</span>])</span><br><span class="line">            doc_lens.append(doc_data[<span class="number">1</span>])</span><br><span class="line">            sent_lens = [sent_data[<span class="number">0</span>] <span class="keyword">for</span> sent_data <span class="keyword">in</span> doc_data[<span class="number">2</span>]]</span><br><span class="line">            max_sent_len = max(sent_lens)</span><br><span class="line">            doc_max_sent_len.append(max_sent_len)</span><br><span class="line"></span><br><span class="line">        max_doc_len = max(doc_lens)</span><br><span class="line">        max_sent_len = max(doc_max_sent_len)</span><br><span class="line"></span><br><span class="line">        batch_inputs1 = torch.zeros((batch_size, max_doc_len, max_sent_len), dtype=torch.int64)</span><br><span class="line">        batch_inputs2 = torch.zeros((batch_size, max_doc_len, max_sent_len), dtype=torch.int64)</span><br><span class="line">        batch_masks = torch.zeros((batch_size, max_doc_len, max_sent_len), dtype=torch.float32)</span><br><span class="line">        batch_labels = torch.LongTensor(doc_labels)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> b <span class="keyword">in</span> range(batch_size):</span><br><span class="line">            <span class="keyword">for</span> sent_idx <span class="keyword">in</span> range(doc_lens[b]):</span><br><span class="line">                sent_data = batch_data[b][<span class="number">2</span>][sent_idx]</span><br><span class="line">                <span class="keyword">for</span> word_idx <span class="keyword">in</span> range(sent_data[<span class="number">0</span>]):</span><br><span class="line">                    batch_inputs1[b, sent_idx, word_idx] = sent_data[<span class="number">1</span>][word_idx]</span><br><span class="line">                    batch_inputs2[b, sent_idx, word_idx] = sent_data[<span class="number">2</span>][word_idx]</span><br><span class="line">                    batch_masks[b, sent_idx, word_idx] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> use_cuda:</span><br><span class="line">            batch_inputs1 = batch_inputs1.to(device)</span><br><span class="line">            batch_inputs2 = batch_inputs2.to(device)</span><br><span class="line">            batch_masks = batch_masks.to(device)</span><br><span class="line">            batch_labels = batch_labels.to(device)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> (batch_inputs1, batch_inputs2, batch_masks), batch_labels</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># train</span></span><br><span class="line">trainer = Trainer(model, vocab)</span><br><span class="line">trainer.train()</span><br></pre></td></tr></table></figure>
<pre><code>2020-08-04 21:09:42,141 INFO: Total 9000 docs.
2020-08-04 21:09:46,220 INFO: Total 1000 docs.
2020-08-04 21:13:16,817 INFO: Total 50000 docs.
2020-08-04 21:13:16,818 INFO: Start training...
C:\Users\16402\Anaconda3\envs\torch\lib\site-packages\torch\optim\lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn(&quot;To get the last learning rate computed by the scheduler, &quot;
2020-08-04 21:18:31,349 INFO: | epoch   1 | step  50 | batch  50/563 | lr 0.00020 0.00005 | loss 2.0842 | s/batch 6.29
2020-08-04 21:23:30,647 INFO: | epoch   1 | step 100 | batch 100/563 | lr 0.00020 0.00004 | loss 1.3136 | s/batch 5.99
2020-08-04 21:28:09,804 INFO: | epoch   1 | step 150 | batch 150/563 | lr 0.00020 0.00004 | loss 0.8795 | s/batch 5.58
2020-08-04 21:32:29,511 INFO: | epoch   1 | step 200 | batch 200/563 | lr 0.00020 0.00003 | loss 0.8083 | s/batch 5.19
2020-08-04 21:37:23,139 INFO: | epoch   1 | step 250 | batch 250/563 | lr 0.00020 0.00003 | loss 0.7032 | s/batch 5.87
2020-08-04 21:41:54,379 INFO: | epoch   1 | step 300 | batch 300/563 | lr 0.00020 0.00002 | loss 0.7255 | s/batch 5.42
2020-08-04 21:46:54,413 INFO: | epoch   1 | step 350 | batch 350/563 | lr 0.00020 0.00002 | loss 0.4691 | s/batch 6.00
2020-08-04 21:51:52,438 INFO: | epoch   1 | step 400 | batch 400/563 | lr 0.00020 0.00001 | loss 0.6759 | s/batch 5.96
2020-08-04 21:56:39,501 INFO: | epoch   1 | step 450 | batch 450/563 | lr 0.00020 0.00001 | loss 0.5045 | s/batch 5.74
2020-08-04 22:01:25,859 INFO: | epoch   1 | step 500 | batch 500/563 | lr 0.00020 0.00001 | loss 0.4234 | s/batch 5.73
2020-08-04 22:06:26,352 INFO: | epoch   1 | step 550 | batch 550/563 | lr 0.00020 0.00000 | loss 0.5096 | s/batch 6.01
2020-08-04 22:07:30,164 INFO: | epoch   1 | score (70.97, 58.94, 62.61) | f1 62.61 | loss 0.8152 | time 3253.28
2020-08-04 22:07:30,209 INFO: 
              precision    recall  f1-score   support

          科技     0.7663    0.8156    0.7902      1697
          股票     0.7096    0.8917    0.7903      1680
          体育     0.8803    0.9210    0.9002      1405
          娱乐     0.7736    0.8198    0.7960       971
          时政     0.7661    0.7056    0.7346       710
          社会     0.7122    0.7097    0.7110       558
          教育     0.8329    0.7231    0.7741       455
          财经     0.6778    0.3177    0.4326       384
          家居     0.6568    0.5936    0.6236       374
          游戏     0.7650    0.5018    0.6061       279
          房产     0.6987    0.5000    0.5829       218
          时尚     0.6506    0.3649    0.4675       148
          彩票     0.8788    0.3625    0.5133        80
          星座     0.1667    0.0244    0.0426        41

    accuracy                         0.7639      9000
   macro avg     0.7097    0.5894    0.6261      9000
weighted avg     0.7607    0.7639    0.7538      9000

C:\Users\16402\Anaconda3\envs\torch\lib\site-packages\sklearn\metrics\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
2020-08-04 22:11:06,013 INFO: | epoch   1 | dev | score (77.81, 73.77, 74.78) | f1 74.78 | time 215.80
2020-08-04 22:11:06,013 INFO: Exceed history dev = 0.00, current dev = 74.78
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># test</span></span><br><span class="line">trainer.test()</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title>贪心NLP刷课笔记（二）</title>
    <url>/posts/ecee2a21.html</url>
    <content><![CDATA[<h1 id="Spell-Correction实现"><a href="#Spell-Correction实现" class="headerlink" title="Spell-Correction实现"></a>Spell-Correction实现</h1><p>我们的目标函数是$\text{argmax}_{c\in \text{Candidates}}P(c)P(s|c)$，因此我们第一步需要找出Candidates，也就是围绕原始单词生成编辑距离为1的错误单词，然后我们需要再做一层过滤，过滤掉词典库过滤掉不存在于词典库中的单词，最后我们通过Noisy Channel Model选择最好的Candidates。</p>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title>NLP任务分类</title>
    <url>/posts/82d9aeed.html</url>
    <content><![CDATA[<p>本文系综合NLP领域的最新发展成果，并应对NLP处理时遇到的各类状况。</p>
<h1 id="词干提取"><a href="#词干提取" class="headerlink" title="词干提取"></a>词干提取</h1><p>词干提取是将词语去除变化或衍生形式，转换为词干或原型形式的过程。词干提取的目标是将相关词语还原为同样的词干，哪怕词干并非词典的词目。例如，英文中:</p>
<blockquote>
<p>1.beautiful和beautifully的词干同为beauti</p>
<p>2.Good,better和best 的词干分别为good,better和best。</p>
</blockquote>
<ul>
<li><p>相关论文：Martin Porter的<a href="https://tartarus.org/martin/PorterStemmer/def.txt" target="_blank" rel="noopener">波特词干算法</a></p>
</li>
<li><p>相关算法：在Python上可以使用Porter2词干算法</p>
</li>
</ul>
<p>需要注意到英语词汇由两部分构成，词干和词缀，词缀又分前缀和后缀，这里的词干提取<strong>仅指去除后缀</strong>的操作。这里给出了在<a href="https://bitbucket.org/mchaput/stemming/src/5c242aa592a6d4f0e9a0b2e1afdca4fd757b8e8a/stemming/porter2.py?at=default&amp;fileviewer=file-view-default" target="_blank" rel="noopener">python的stemming库中使用</a>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!pip install stemming</span><br><span class="line"><span class="keyword">from</span> stemming.porter2 <span class="keyword">import</span> stem</span><br><span class="line">stem(<span class="string">"casually"</span>)</span><br></pre></td></tr></table></figure>
<h1 id="词形还原"><a href="#词形还原" class="headerlink" title="词形还原"></a>词形还原</h1><p>词形还原是将一组词语还原为词源或词典的词目形式的过程。还原过程考虑到了POS问题，即词语在句中的语义，词语对相邻语句的语义等。例如，英语中：</p>
<blockquote>
<p>1.beautiful和beautifully被分别还原为beautiful和beautifully。</p>
<p>2.good, better和best被分别还原为good, good和good</p>
</blockquote>
<ul>
<li><p>相关论文1: <a href="http://www.ijrat.org/downloads/icatest2015/ICATEST-2015127.pdf" target="_blank" rel="noopener">这篇文章</a>详细讨论了<strong>词形还原的不同方法</strong>。想要了解传统词形还原的工作原理必读。</p>
</li>
<li><p>相关论文2:  <a href="https://academic.oup.com/dsh/article-abstract/doi/10.1093/llc/fqw034/2669790/Lemmatization-for-variation-rich-languages-using" target="_blank" rel="noopener">这篇论文</a>非常出色，讨论了<strong>运用深度学习对变化丰富的语种做词形还原时会遇到的问题</strong>。</p>
</li>
<li><p>数据集: <a href="https://catalog.ldc.upenn.edu/ldc99t42" target="_blank" rel="noopener">这里</a>是Treebank-3数据集的链接，你可以使用它创建一个自己的词形还原工具。</p>
</li>
</ul>
<p>下面给出了在spacy上的英语词形还原代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!pip install spacy</span><br><span class="line"><span class="comment">#python -m spacy download en</span></span><br><span class="line"><span class="keyword">import</span> spacy</span><br><span class="line">nlp=spacy.load(<span class="string">"en"</span>)</span><br><span class="line">doc=<span class="string">"good better best"</span></span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> nlp(doc):</span><br><span class="line">    print(token,token.lemma_)</span><br></pre></td></tr></table></figure>
<h1 id="词向量化"><a href="#词向量化" class="headerlink" title="词向量化"></a>词向量化</h1><p>词向量化是用一组实数构成的向量代表自然语言的叫法。这种技术非常实用，因为电脑无法处理自然语言。词向量化可以捕捉到自然语言和实数间的本质关系。通过词向量化，一个词语或者一段短语可以用一个定维的向量表示，例如向量的长度可以为100，这里维度中的每个数字代表了词语在某个特定方向上的量级。</p>
<ul>
<li>相关博文：<a href="https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/" target="_blank" rel="noopener">这篇文章</a>详细解释了词向量化。</li>
<li><p>相关论文：<a href="https://www.analyticsvidhya.com/blog/2017/10/essential-nlp-guide-data-scientists-top-10-nlp-tasks/" target="_blank" rel="noopener">这篇论文</a>解释了词向量化的细节。深入理解词向量化必读。</p>
</li>
<li><p>相关工具：<a href="https://ronxin.github.io/wevi/" target="_blank" rel="noopener">这是</a>个基于浏览器的词向量可视化工具。</p>
</li>
<li><p>预训练词向量：</p>
<ul>
<li><a href="https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md" target="_blank" rel="noopener">这里</a>有一份facebook的预训练词向量列表，包含294种语言。</li>
<li><a href="https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit" target="_blank" rel="noopener">这里</a>可以下载google news的预训练词向量。</li>
</ul>
</li>
</ul>
<p>下面是具体调用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!pip install gensim</span><br><span class="line">fromgensim.models.keyedvectors <span class="keyword">import</span> KeyedVectors</span><br><span class="line">word_vectors=KeyedVectors.load_word2vec_format(<span class="string">'GoogleNews-vectors-negative300.bin'</span>,binary=<span class="literal">True</span>)</span><br><span class="line">word_vectors[<span class="string">'human'</span>]</span><br></pre></td></tr></table></figure>
<p>这段代码可以用gensim训练你自己的词向量，具体训练往期博客已有阐述，这里是<a href="https://chenk.tech/posts/eb79fc5f.html" target="_blank" rel="noopener">传送门</a>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sentence=[[<span class="string">'first'</span>,<span class="string">'sentence'</span>],[<span class="string">'second'</span>,<span class="string">'sentence'</span>]]</span><br><span class="line">model = gensim.models.Word2Vec(sentence, min_count=<span class="number">1</span>,size=<span class="number">300</span>,workers=<span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<h1 id="词性标注"><a href="#词性标注" class="headerlink" title="词性标注"></a>词性标注</h1><p>词性标注是对句子中的词语标注为名字、动词、形容词、副词等的过程。</p>
<ul>
<li><p>论文1：choi aptly的这篇<a href="https://aclweb.org/anthology/N16-1031.pdf" target="_blank" rel="noopener">《The Last Gist to theState-of-the-Art 》</a>介绍了一种叫动态特征归纳的新方法，这是目前词性标注最先进的方法。</p>
</li>
<li><p>论文2：<a href="https://transacl.org/ojs/index.php/tacl/article/viewFile/837/192" target="_blank" rel="noopener">这篇文章</a>介绍了通过隐马尔科夫模型做无监督词性标注学习的方法。</p>
</li>
</ul>
<p>这段代码可以在spacy上做词性标注：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!pip install spacy</span><br><span class="line"><span class="comment">#!python -m spacy download en</span></span><br><span class="line">nlp=spacy.load(<span class="string">'en'</span>)</span><br><span class="line">sentence=<span class="string">"Ashok killed the snake with a stick"</span></span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> nlp(sentence):</span><br><span class="line">    print(token,token.pos_)</span><br></pre></td></tr></table></figure>
<h1 id="命名实体消岐"><a href="#命名实体消岐" class="headerlink" title="命名实体消岐"></a>命名实体消岐</h1><p>命名实体消岐是对句子中的提到的实体识别的过程。例如，对句子“Apple earned a revenue of 200 Billion  USD in  2016”，命名实体消岐会推断出句子中的Apple是苹果公司而不是指一种水果。一般来说，命名实体要求有一个实体知识库，能够将句子中提到的实体和知识库联系起来。</p>
<ul>
<li><p>论文1：Huang的<a href="https://arxiv.org/pdf/1504.07678.pdf" target="_blank" rel="noopener">这篇论文</a>运用了基于深度神经网络和知识库的深层语义关联模型，在命名实体消岐上达到了领先水平。</p>
</li>
<li><p>论文2：Ganea and Hofmann的<a href="https://arxiv.org/pdf/1704.04920.pdf" target="_blank" rel="noopener">这篇文章</a>运用了局部神经关注模型和词向量化，没有人为设置特征。</p>
</li>
</ul>
<h1 id="命名实体识别"><a href="#命名实体识别" class="headerlink" title="命名实体识别"></a>命名实体识别</h1><p>命名实体识别是识别一个句子中有特定意义的实体并将其区分为人名，机构名，日期，地名，时间等类别的任务。</p>
<ul>
<li>论文：<a href="https://arxiv.org/pdf/1603.01360.pdf" target="_blank" rel="noopener">这篇优秀</a>的论文使用双向LSTM（长短期记忆网络）神经网络结合监督学习和非监督学习方法，在4种语言领域实现了命名实体识别的最新成果。</li>
</ul>
<p>以下是如何使用spacy执行命名实体识别：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> spacy</span><br><span class="line">nlp=spacy.load(<span class="string">'en'</span>)</span><br><span class="line">sentence=<span class="string">"Ram of Apple Inc. travelled to Sydney on 5th October 2017"</span></span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> nlp(sentence):</span><br><span class="line">    print(token,  token.ent_type_)</span><br></pre></td></tr></table></figure>
<h1 id="情感分析"><a href="#情感分析" class="headerlink" title="情感分析"></a>情感分析</h1><p>情感分析是一种广泛的主观分析，它使用自然语言处理技术来识别客户评论的语义情感，语句表达的情绪正负面以及通过语音分析或书面文字判断其表达的情感等等。例如：</p>
<blockquote>
<p>“我不喜欢巧克力冰淇淋” 是对该冰淇淋的负面评价。</p>
<p>“我并不讨厌巧克力冰激凌”—可以被认为是一种中性的评价。</p>
</blockquote>
<p>从使用LSTMs和Word嵌入来计算一个句子中的正负词数开始，有很多方法都可以用来进行情感分析。</p>
<ul>
<li><p>博文1：<a href="https://www.analyticsvidhya.com/blog/2016/02/step-step-guide-building-sentiment-analysis-model-graphlab/" target="_blank" rel="noopener">本文</a>重点对电影推文进行情感分析</p>
</li>
<li><p>博文2：<a href="https://www.analyticsvidhya.com/blog/2017/01/sentiment-analysis-of-twitter-posts-on-chennai-floods-using-python/" target="_blank" rel="noopener">本文</a>重点对印度金奈洪水期间的推文进行情感分析。</p>
</li>
<li><p>论文1：<a href="https://arxiv.org/pdf/1305.6143.pdf" target="_blank" rel="noopener">本文</a>采用朴素贝叶斯的监督学习方法对IMDB评论进行分类。</p>
</li>
<li><p>论文2：<a href="http://www.cs.cmu.edu/~yohanj/research/papers/WSDM11.pdf" target="_blank" rel="noopener">本文</a>利用LDA的无监督学习方法来识别用户生成评论的观点和情感。本文在解决注释评论短缺的问题上表现突出。</p>
</li>
<li><p>资料库：<a href="https://github.com/xiamx/awesome-sentiment-analysis" target="_blank" rel="noopener">这是</a>一个很好的包含相关研究论文和各种语言情感分析程序实现的资料库。</p>
</li>
<li><p>数据集1：<a href="http://www.cs.jhu.edu/~mdredze/datasets/sentiment/" target="_blank" rel="noopener">多域情感数据集版本2.0</a></p>
</li>
<li><p>数据集2：<a href="http://www.sananalytics.com/lab/twitter-sentiment/" target="_blank" rel="noopener">Twitter情感分析数据集</a></p>
</li>
<li><p>竞赛：一个非常好的<a href="https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews" target="_blank" rel="noopener">比赛</a>，你可以检查你的模型在烂番茄电影评论的情感分析任务中的表现。</p>
</li>
</ul>
<h1 id="文本语义相似分析"><a href="#文本语义相似分析" class="headerlink" title="文本语义相似分析"></a>文本语义相似分析</h1><p>语义文本相似度分析是对两段文本的意义和本质之间的相似度进行分析的过程。注意，相似性与相关性是不同的。例如：汽车和公共汽车是相似的，但是汽车和燃料是相关的。</p>
<ul>
<li><p>论文1：<a href="https://pdfs.semanticscholar.org/5b5c/a878c534aee3882a038ef9e82f46e102131b.pdf" target="_blank" rel="noopener">本文</a>详细介绍了文本相似度测量的不同方法。是一篇可以一站式了解目前所有方法的必读文章。</p>
</li>
<li><p>论文2：<a href="http://casa.disi.unitn.it/~moschitt/since2013/2015_SIGIR_Severyn_LearningRankShort.pdf" target="_blank" rel="noopener">本文</a>介绍了用CNN神经网络去比对两个短文本。</p>
</li>
<li><p>论文3：<a href="https://nlp.stanford.edu/pubs/tai-socher-manning-acl2015.pdf" target="_blank" rel="noopener">本文</a>利用Tree-LSTMs方法得到了文本的语义相关和语义分类的最新成果。</p>
</li>
</ul>
<h1 id="语种辨识"><a href="#语种辨识" class="headerlink" title="语种辨识"></a>语种辨识</h1><p>什么是语言识别（语种辨识）？语言识别指的是将不同语言的文本区分出来。其利用语言的统计和语法属性来执行此任务。语言识别也可以被认为是文本分类的特殊情况。</p>
<ul>
<li><p>博文：在<a href="https://fasttext.cc/blog/2017/10/02/blog-post.html" target="_blank" rel="noopener">这篇</a>由fastText撰写的博文中介绍了一种新的工具，其可以在1MB的内存使用情况下识别170种语言。</p>
</li>
<li><p>论文1：<a href="http://www.ep.liu.se/ecp/131/021/ecp17131021.pdf" target="_blank" rel="noopener">本文</a>讨论了285种语言的7种语言识别方法。</p>
</li>
<li><p>论文2：<a href="https://repositorio.uam.es/bitstream/handle/10486/666848/automatic_lopez-moreno_ICASSP_2014_ps.pdf?sequence=1" target="_blank" rel="noopener">本文</a>描述了如何使用深度神经网络来实现自动语言识别的最新成果。</p>
</li>
</ul>
<h1 id="文本摘要"><a href="#文本摘要" class="headerlink" title="文本摘要"></a>文本摘要</h1><p>文本摘要是通过识别文本的重点并使用这些要点创建摘要来缩短文本的过程。文本摘要的目的是在不改变文本含义的前提下最大限度地缩短文本。</p>
<ul>
<li>论文1：<a href="https://arxiv.org/pdf/1509.00685.pdf" target="_blank" rel="noopener">本文</a>描述了基于神经注意模型的抽象语句梗概方法。</li>
<li>论文2：<a href="https://arxiv.org/pdf/1602.06023.pdf" target="_blank" rel="noopener">本文</a>描述了使用序列到序列的RNN在文本摘要中达到的最新结果。</li>
<li>资料库：Google  Brain团队的<a href="https://github.com/tensorflow/models/tree/master/research/textsum" target="_blank" rel="noopener">这个资料库</a>拥有使用为文本摘要定制的序列到序列模型的代码。该模型在Gigaword数据集上进行训练。</li>
<li>应用程序：<a href="https://www.reddit.com/r/autotldr/comments/31b9fm/faq_autotldr_bot/" target="_blank" rel="noopener">Reddit的autotldr机器人</a>使用文本摘要来梗概从文章到帖子的各种评论。这个功能在Reddit用户中非常有名。</li>
</ul>
<p>程序实现：以下是如何用gensim包快速实现文本摘要。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.summarization <span class="keyword">import</span> summarize</span><br><span class="line">sentence=<span class="string">"Automatic  summarization is the process of shortening a text document with  software, in order to create a summary with the major points of the  original document. Technologies that can make a coherent summary take  into account variables such as length, writing style and  syntax.Automatic data summarization is part of machine learning and data mining. The main idea of summarization is to find a subset of data  which contains the information of the entire set. Such techniques are  widely used in industry today. Search engines are an example; others  include summarization of documents, image collections and videos.  Document summarization tries to create a representative summary or  abstract of the entire document, by finding the most informative  sentences, while in image summarization the system finds the most  representative and important (i.e. salient) images. For surveillance  videos, one might want to extract the important events from the  uneventful context.There are two general approaches to automatic  summarization: extraction and abstraction. Extractive methods work by  selecting a subset of existing words, phrases, or sentences in the  original text to form the summary. In contrast, abstractive methods  build an internal semantic representation and then use natural language  generation techniques to create a summary that is closer to what a human might express. Such a summary might include verbal innovations.  Research to date has focused primarily on extractive methods, which are  appropriate for image collection summarization and video  summarization."</span></span><br><span class="line">summarize(sentence)</span><br></pre></td></tr></table></figure>
<p>参考链接：</p>
<ul>
<li><a href="https://www.sohu.com/a/203314063_308467" target="_blank" rel="noopener">https://www.sohu.com/a/203314063_308467</a> （本文实际上系转载该文章，由于排版问题不便日后翻阅特整理于此以便查阅）</li>
</ul>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title>新闻文本分类实战(一)</title>
    <url>/posts/eb79fc5f.html</url>
    <content><![CDATA[<h1 id="赛题理解及思考"><a href="#赛题理解及思考" class="headerlink" title="赛题理解及思考"></a>赛题理解及思考</h1><h2 id="获取数据"><a href="#获取数据" class="headerlink" title="获取数据"></a>获取数据</h2><p>我们直接打开天池大赛找到<a href="https://tianchi.aliyun.com/competition/entrance/531810/information" target="_blank" rel="noopener">零基础入门NLP比赛</a>，看到的是这样一个页面：</p>
<p><img src="/Pic/%E6%96%B0%E9%97%BB%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E5%AE%9E%E6%88%98/25.png" alt></p>
<p>接着就三步走：注册报名下载数据，查看数据前五行可以看到我们获得的数据如下：</p>
<p><img src="/Pic/%E6%96%B0%E9%97%BB%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E5%AE%9E%E6%88%98/26.png" alt></p>
<p>其中左边的label是数据集文本对应的标签，而右边的text则是编码后的文本，文本对应的标签列举如下：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">&#123;'科技': 0, '股票': 1, '体育': 2, '娱乐': 3, '时政': 4, '社会': 5, '教育': 6, '财经': 7, '家居': 8, '游戏': 9, '房产': 10, '时尚': 11, '彩票': 12, '星座': 13&#125;</span><br></pre></td></tr></table></figure>
<p>根据官方描述：赛题以匿名处理后的新闻数据为赛题数据，数据集报名后可见并可下载。赛题数据为新闻文本，并按照字符级别进行匿名处理。整合划分出14个候选分类类别：财经、彩票、房产、股票、家居、教育、科技、社会、时尚、时政、体育、星座、游戏、娱乐的文本数据。</p>
<p>赛题数据由以下几个部分构成：训练集20w条样本，测试集A包括5w条样本，测试集B包括5w条样本。为了预防选手人工标注测试集的情况，我们将比赛数据的文本按照字符级别进行了匿名处理。</p>
<p>同时我们还应该注意到官网有给出结果评价指标，我们也需要根据这个评价指标衡量我们的验证集数据误差：</p>
<p><img src="/Pic/%E6%96%B0%E9%97%BB%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E5%AE%9E%E6%88%98/27.png" alt></p>
<p>既然该拿到的我们都拿到了，我们接下来就开始构思我们都应该使用哪些思路来完成我们的预测。</p>
<h2 id="赛题构思"><a href="#赛题构思" class="headerlink" title="赛题构思"></a>赛题构思</h2><p>由于赛题给出的数据是匿名化的，因此我们无法使用分词等操作提取关键词来简单预测，我们可以使用的是对文本提取特征的分类器或者是深度学习分类器，综合我们有如下思路：</p>
<ul>
<li><p>思路1：TF-IDF + 机器学习分类器：直接使用TF-IDF对文本提取特征，并使用分类器进行分类。在分类器的选择上，可以使用SVM、LR、或者XGBoost。</p>
</li>
<li><p>思路2：FastText：FastText是入门款的词向量，利用Facebook提供的FastText工具，可以快速构建出分类器。</p>
</li>
<li><p>思路3：WordVec + 深度学习分类器：WordVec是进阶款的词向量，并通过构建深度学习分类完成分类。深度学习分类的网络结构可以选择TextCNN、TextRNN或者BiLSTM。</p>
</li>
<li><p>思路4：Bert词向量：Bert是高配款的词向量，具有强大的建模学习能力。</p>
</li>
</ul>
<p>我们后续将一一实现。</p>
<h2 id="基础数据分析"><a href="#基础数据分析" class="headerlink" title="基础数据分析"></a>基础数据分析</h2><p>虽然这里的数据都是编码的文本数据，我们很难通过简单的数据分析获得很多有价值的信息，但我们还是希望获得诸如文本长度分布，文本类别分布、文本字符分布等信息以获得一个直观的印象，下面我们完成这些操作：</p>
<p>读取数据（由于数据量较大读取前一百行便于操作）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_df = pd.read_csv(<span class="string">"train_set.csv"</span>, sep=<span class="string">"\t"</span>, nrows=<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<h3 id="统计文章词数"><a href="#统计文章词数" class="headerlink" title="统计文章词数"></a>统计文章词数</h3><p>统计每篇文章的词数并绘制直方图：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line">train_df[<span class="string">"text_len"</span>] = train_df[<span class="string">"text"</span>].apply(<span class="keyword">lambda</span> x:len(x.split(<span class="string">" "</span>)))</span><br><span class="line">print(train_df[<span class="string">"text_len"</span>].describe())</span><br><span class="line">_ = plt.hist(train_df[<span class="string">'text_len'</span>], bins=<span class="number">200</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Text char count'</span>)</span><br><span class="line">plt.title(<span class="string">"Histogram of char count"</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%96%B0%E9%97%BB%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E5%AE%9E%E6%88%98/charCount-1595154665274.jpg" alt="charCount"></p>
<h3 id="统计不同种类新闻数量"><a href="#统计不同种类新闻数量" class="headerlink" title="统计不同种类新闻数量"></a>统计不同种类新闻数量</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_df[<span class="string">"label"</span>].value_counts().plot(kind=<span class="string">"bar"</span>)</span><br><span class="line">plt.title(<span class="string">'News class count'</span>)</span><br><span class="line">plt.xlabel(<span class="string">"category"</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E6%96%B0%E9%97%BB%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E5%AE%9E%E6%88%98/classCount.jpg" alt></p>
<h3 id="统计单词频率"><a href="#统计单词频率" class="headerlink" title="统计单词频率"></a>统计单词频率</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line">all_lines = <span class="string">" "</span>.join(list(train_df[<span class="string">"text"</span>]))</span><br><span class="line">word_count = Counter(all_lines.split(<span class="string">" "</span>))</span><br><span class="line">word_count = sorted(word_count.items(), key=<span class="keyword">lambda</span> d:d[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">print(len(word_count))</span><br><span class="line">print(word_count[<span class="number">-1</span>])</span><br><span class="line">print(word_count[<span class="number">0</span>])</span><br><span class="line">print(word_count[<span class="number">1</span>])</span><br><span class="line">print(word_count[<span class="number">2</span>])</span><br></pre></td></tr></table></figure>
<p>打印结果为编码”3750”，”648”，”900”为出现次数最多的字符且每篇文章中出现率均很高，我们有理由猜测这三个（或其中一两个）字符是标点符号，由此我们可以试着统计文章句子长度(假设这三个字符为标点符号)。</p>
<h3 id="统计文章平均句子长度"><a href="#统计文章平均句子长度" class="headerlink" title="统计文章平均句子长度"></a>统计文章平均句子长度</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">sent_count = Counter(re.split(<span class="string">'3750|648|900'</span>, all_lines))</span><br><span class="line">sent_count = sorted(sent_count.items(), key=<span class="keyword">lambda</span> d:d[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">sent_count = sent_count[<span class="number">1</span>:<span class="number">-1</span>]</span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(sent_count)):</span><br><span class="line">    count += sent_count[i][<span class="number">1</span>]</span><br><span class="line">print(<span class="string">"Average amount of sentences per article:"</span>, count/<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<p>结果显示平均每篇文章有78.5个句子。当然这三个编码未必都是标点符号，猜测应该是一个逗号一个句号一个常见字（估计是“的”），因此每篇文章文章句子数应该更少（可以查看上面代码中的第一个sent count，每个分割句都比我们平时遇见的短很多），具体分析哪个编码是表示这个常见字可以对其他新闻文本数据做分析，看看排名前三的关键字是否匹配，这个特征感兴趣的可以自行研究。</p>
<h3 id="统计每类新闻最常出现的n个单词"><a href="#统计每类新闻最常出现的n个单词" class="headerlink" title="统计每类新闻最常出现的n个单词"></a>统计每类新闻最常出现的n个单词</h3><p>另外我们可以统计每类新闻出现次数最多的字符，只需要将前100个文本中每类新闻的编码文本拼接起来进行如上统计即可，因此我们可以写一个函数用于输出出现次数前n的字符，然后传入对应的文本即可，实现如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">TopWord</span><span class="params">(type_, n)</span>:</span></span><br><span class="line">    all_lines = <span class="string">" "</span>.join([train_df[<span class="string">"text"</span>][i] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(train_df[<span class="string">"text"</span>])) <span class="keyword">if</span> train_df[<span class="string">"label"</span>][i]==type_])</span><br><span class="line">    word_count = Counter(all_lines.split(<span class="string">" "</span>))</span><br><span class="line">    word_count = sorted(word_count.items(), key=<span class="keyword">lambda</span> d:d[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        print(word_count[i])</span><br><span class="line">        </span><br><span class="line">TopWord(<span class="number">2</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>其中参数type_的取值范围为[0,13]内的整数，意为对应的标签，参数n为打印出现次数前n的单词对应的编码。当然也可以对其制作不同类别的文本出现次数前n的单词的直方图，由于这里不准备对单词频率等特征做过多分析因此略过不提。</p>
<h1 id="基于机器学习的文本分类"><a href="#基于机器学习的文本分类" class="headerlink" title="基于机器学习的文本分类"></a>基于机器学习的文本分类</h1><p>在机器学习算法的训练过程中，假设给定$N$个样本，每个样本有$M$个特征，这样组成了$N×M$的样本矩阵，然后完成算法的训练和预测。同样的在计算机视觉中可以将图片的像素看作特征，每张图片看作hight×width×3的特征图，一个三维的矩阵来进入计算机进行计算。</p>
<p>但是在自然语言领域，上述方法却不可行：文本是不定长度的。文本表示成计算机能够运算的数字或向量的方法一般称为词嵌入（Word Embedding）方法。词嵌入将不定长的文本转换到定长的空间内，是文本分类的第一步。</p>
<h2 id="词袋模型"><a href="#词袋模型" class="headerlink" title="词袋模型"></a>词袋模型</h2><p>词嵌入的最简单的方法就是将每一个字转为一个onehot编码，然后对于句子或者文章直接统计每个字出现的次数（词袋模型），例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">句子1：我 爱 北 京 天 安 门</span><br><span class="line">转换为 [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]</span><br><span class="line"></span><br><span class="line">句子2：我 喜 欢 上 海</span><br><span class="line">转换为 [1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]</span><br></pre></td></tr></table></figure>
<p>在sklearn中可以直接<code>CountVectorizer</code>来实现这一步骤：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line">corpus = [</span><br><span class="line">    <span class="string">'This is the first document.'</span>,</span><br><span class="line">    <span class="string">'This document is the second document.'</span>,</span><br><span class="line">    <span class="string">'And this is the third one.'</span>,</span><br><span class="line">    <span class="string">'Is this the first document?'</span>,</span><br><span class="line">]</span><br><span class="line">vectorizer = CountVectorizer()</span><br><span class="line">vectorizer.fit_transform(corpus).toarray()</span><br></pre></td></tr></table></figure>
<p>CountVectorizer的使用及参数表如下，具体可见<a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" target="_blank" rel="noopener">官方文档</a>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">CountVectorizer(input=<span class="string">'content'</span>, encoding=<span class="string">'utf-8'</span>,  decode_error=<span class="string">'strict'</span>, strip_accents=<span class="literal">None</span>, lowercase=<span class="literal">True</span>, preprocessor=<span class="literal">None</span>, tokenizer=<span class="literal">None</span>, stop_words=<span class="literal">None</span>, </span><br><span class="line">token_pattern=<span class="string">'(?u)\b\w\w+\b'</span>, ngram_range=(<span class="number">1</span>, <span class="number">1</span>), analyzer=<span class="string">'word'</span>, max_df=<span class="number">1.0</span>, min_df=<span class="number">1</span>, max_features=<span class="literal">None</span>, vocabulary=<span class="literal">None</span>, binary=<span class="literal">False</span>, dtype=&lt;<span class="class"><span class="keyword">class</span> '<span class="title">numpy</span>.<span class="title">int64</span>'&gt;)</span></span><br></pre></td></tr></table></figure>
<div class="table-container">
<table>
<thead>
<tr>
<th>参数表</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td>input</td>
<td>一般使用默认即可，可以设置为”filename’或’file’</td>
</tr>
<tr>
<td>encodeing</td>
<td>使用默认的utf-8即可，分析器将会以utf-8解码raw document</td>
</tr>
<tr>
<td>decode_error</td>
<td>默认为strict，遇到不能解码的字符将报UnicodeDecodeError错误，设为ignore将会忽略解码错误，还可以设为replace，作用尚不明确</td>
</tr>
<tr>
<td>strip_accents</td>
<td>默认为None，可设为ascii或unicode，将使用ascii或unicode编码在预处理步骤去除raw document中的重音符号</td>
</tr>
<tr>
<td>analyzer</td>
<td>一般使用默认，可设置为string类型，如’word’, ‘char’, ‘char_wb’，还可设置为callable类型，比如函数是一个callable类型</td>
</tr>
<tr>
<td>preprocessor</td>
<td>设为None或callable类型</td>
</tr>
<tr>
<td>tokenizer</td>
<td>设为None或callable类型</td>
</tr>
<tr>
<td>ngram_range</td>
<td>词组切分的长度范围，待详解</td>
</tr>
<tr>
<td>stop_words</td>
<td>设置停用词，设为english将使用内置的英语停用词，设为一个list可自定义停用词，设为None不使用停用词，设为None且max_df∈[0.7, 1.0)将自动根据当前的语料库建立停用词表</td>
</tr>
<tr>
<td>lowercase</td>
<td>将所有字符变成小写</td>
</tr>
<tr>
<td>token_pattern</td>
<td>过滤规则，表示token的正则表达式，需要设置analyzer == ‘word’，默认的正则表达式选择2个及以上的字母或数字作为token，标点符号默认当作token分隔符，而不会被当作token</td>
</tr>
<tr>
<td>max_df</td>
<td>可以设置为范围在[0.0 1.0]的float，也可以设置为没有范围限制的int，默认为1.0。这个参数的作用是作为一个阈值，当构造语料库的关键词集的时候，如果某个词的document frequence大于max_df，这个词不会被当作关键词。如果这个参数是float，则表示词出现的次数与语料库文档数的百分比，如果是int，则表示词出现的次数。如果参数中已经给定了vocabulary，则这个参数无效</td>
</tr>
<tr>
<td>min_df</td>
<td>类似于max_df，不同之处在于如果某个词的document frequence小于min_df，则这个词不会被当作关键词</td>
</tr>
<tr>
<td>max_features</td>
<td>默认为None，可设为int，对所有关键词的term frequency进行降序排序，只取前max_features个作为关键词集</td>
</tr>
<tr>
<td>vocabulary</td>
<td>默认为None，自动从输入文档中构建关键词集，也可以是一个字典或可迭代对象</td>
</tr>
<tr>
<td>binary</td>
<td>默认为False，一个关键词在一篇文档中可能出现n次，如果binary=True，非零的n将全部置为1，这对需要布尔值输入的离散概率模型的有用的</td>
</tr>
<tr>
<td>dtype</td>
<td>使用CountVectorizer类的fit_transform()或transform()将得到一个文档词频矩阵，dtype可以设置这个矩阵的数值类型</td>
</tr>
</tbody>
</table>
</div>
<p>硬要总结一下词袋模型的话可总结为三部曲：<strong>分词（tokenizing），统计修订词特征值（counting）与标准化（normalizing）</strong>。</p>
<h2 id="tf-idf"><a href="#tf-idf" class="headerlink" title="tf-idf"></a>tf-idf</h2><p>转换的结果正是如上面我们人工转换的那样，但正如你现在想到的，有些字比如“的”，“我”等在每篇文章中出现频率很高，但不能体现更多的文章特征，因此我们会对每篇文章中出现次数较高的单词执行降权操作，想要了解的更具体可以参看我的另一篇<a href="https://chenk.tech/posts/dcf8c6f9.html" target="_blank" rel="noopener">学习笔记</a>，这篇文章提到了比较多NLP领域的基础概念，这里简单将其中关于tf-idf的介绍复制过来：</p>
<blockquote>
<p>tf-idf：核心方法论为<strong>单词并不是出现的越多就越重要，并不是出现的越少就越不重要</strong>。计算公式为$tfidf(w)=tf(d,w)*idf(w)$，其中$tf(d,w)$为文档$d$中$w$的词频，$idf(w)=\text{log}\frac{N}{N(w)}$，$N$为语料库中的文档总数，$N(w)$为词语$w$ 出现在多少个文档。 也就是一个单词如果每个文档都出现了，tfidf值会很低，相反一个单词只出现少数几个文档中，在这里个文档中这些个单词的重要性一定是比较高的。</p>
</blockquote>
<h2 id="比较词袋模型与tf-idf"><a href="#比较词袋模型与tf-idf" class="headerlink" title="比较词袋模型与tf-idf"></a>比较词袋模型与tf-idf</h2><p>接下来我们将对比不同文本表示算法的精度，通过本地构建验证集计算F1得分。</p>
<p>首先是词袋模型，部分代码旁边标有注释</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer						<span class="comment"># 构建词袋模型的库</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> RidgeClassifier								<span class="comment"># 岭回归分类器</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score											<span class="comment"># 导入计算F1值的库</span></span><br><span class="line"></span><br><span class="line">train_df = pd.read_csv(<span class="string">'train_set.csv'</span>, sep=<span class="string">'\t'</span>, nrows=<span class="number">15000</span>)					<span class="comment"># 读取前15000行数据</span></span><br><span class="line"></span><br><span class="line">vectorizer = CountVectorizer(max_features=<span class="number">3000</span>)									<span class="comment"># 取前max_features个作为关键词</span></span><br><span class="line">train_test = vectorizer.fit_transform(train_df[<span class="string">'text'</span>])							<span class="comment"># 转化为one-hot向量</span></span><br><span class="line"></span><br><span class="line">clf = RidgeClassifier()															</span><br><span class="line">clf.fit(train_test[:<span class="number">10000</span>], train_df[<span class="string">'label'</span>].values[:<span class="number">10000</span>])					<span class="comment"># 对前10000个学习，后5000个验证</span></span><br><span class="line"></span><br><span class="line">val_pred = clf.predict(train_test[<span class="number">10000</span>:])										<span class="comment"># 对验证集进行预测</span></span><br><span class="line">print(f1_score(train_df[<span class="string">'label'</span>].values[<span class="number">10000</span>:], val_pred, average=<span class="string">'macro'</span>))</span><br></pre></td></tr></table></figure>
<p>其F1得分为0.7416952793751392。</p>
<p>然后我们看tf-idf，代码与前面几乎一样：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> RidgeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score</span><br><span class="line"></span><br><span class="line">train_df = pd.read_csv(<span class="string">'../input/train_set.csv'</span>, sep=<span class="string">'\t'</span>, nrows=<span class="number">15000</span>)</span><br><span class="line"></span><br><span class="line">tfidf = TfidfVectorizer(ngram_range=(<span class="number">1</span>,<span class="number">3</span>), max_features=<span class="number">3000</span>)</span><br><span class="line">train_test = tfidf.fit_transform(train_df[<span class="string">'text'</span>])</span><br><span class="line"></span><br><span class="line">clf = RidgeClassifier()</span><br><span class="line">clf.fit(train_test[:<span class="number">10000</span>], train_df[<span class="string">'label'</span>].values[:<span class="number">10000</span>])</span><br><span class="line"></span><br><span class="line">val_pred = clf.predict(train_test[<span class="number">10000</span>:])</span><br><span class="line">print(f1_score(train_df[<span class="string">'label'</span>].values[<span class="number">10000</span>:], val_pred, average=<span class="string">'macro'</span>))</span><br></pre></td></tr></table></figure>
<p>其F1得分为0.8721598830546126，明显优于词袋模型。上面的代码需要注意的是ngram_range=(1,3)表示考虑单个编码单词组成的词语的长度，官方解释为：</p>
<blockquote>
<p><strong>ngram_range</strong>tuple (min_n, max_n), default=(1, 1)</p>
<p>The lower and upper boundary of the range of n-values for different n-grams to be extracted. All values of n such that min_n &lt;= n &lt;= max_n will be used. For example an <code>ngram_range</code> of <code>(1, 1)</code> means only unigrams, <code>(1, 2)</code> means unigrams and bigrams, and <code>(2, 2)</code> means only bigrams. Only applies if <code>analyzer is not callable</code>.</p>
</blockquote>
<p>我们还可以尝试其他<a href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text" target="_blank" rel="noopener">sklearn库中的文本分类</a>方法：</p>
<p><img src="/Pic/%E6%96%B0%E9%97%BB%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E5%AE%9E%E6%88%98/sklearn.png" alt></p>
<p>呃好像只剩下一个HashingVectorizer，这正是我们接下来要介绍的。</p>
<h2 id="用哈希技巧向量化大文本向量"><a href="#用哈希技巧向量化大文本向量" class="headerlink" title="用哈希技巧向量化大文本向量"></a>用哈希技巧向量化大文本向量</h2><p>以上的向量化情景很简单，但是，事实上这种方式从字符标记到整型特征的目录（vocabulary_属性）的映射都是在内存中进行，在处理大数据集时会出现一些问题：</p>
<ul>
<li>语料库越大，词表就会越大，因此使用的内存也越大</li>
<li>拟合（fitting）需要根据原始数据集的大小等比例分配中间数据结构的大小，构建词映射需要完整的传递数据集，因此不可能以严格在线的方式拟合文本分类器。</li>
<li>pickling和un-pickling vocabulary很大的向量器会非常慢</li>
<li>将向量化任务分隔成并行的子任务很不容易实现，因为vocabulary属性要共享状态有一个细颗粒度的同步障碍：从标记字符串中映射特征索引与每个标记的首次出现顺序是独立的，因此应该被共享，在这点上并行worker的性能收到了损害，使他们比串行更慢。</li>
</ul>
<p>通过同时使用由sklearn.feature_extraction.FeatureHasher类实施的“哈希技巧”（特征哈希）、文本预处理和CountVectorizer的标记特征有可能克服这些限制。简而言之，Hash Trick可以做特征的降维，具体的做法是：假设哈希函数$h$使第$i$个特征哈希到位置$j$即$h(i)=j$，则第$i$个原始特征的词频数值$\phi(i)$将累加到哈希后的第$j$个特征的词频数值$\bar\phi$上：</p>
<script type="math/tex; mode=display">\bar \phi(j) = \sum_{i \text{ in } \mathbb{J};h(i)=j}\phi(i)</script><p>其中$\mathbb{J}$是原始特征的维度。但是上面的方法有一个问题，有可能两个原始特征的哈希后位置在一起导致词频累加特征值突然变大，为了解决这个问题，出现了hash Trick的变种signed hash trick,此时除了哈希函数<em>h</em>,我们多了一个一个哈希函数：</p>
<script type="math/tex; mode=display">\eta:\mathbb{N}\rightarrow \pm1</script><script type="math/tex; mode=display">\bar \phi(j) = \sum_{i \text{ in } \mathbb{J};h(i)=j}\eta(i)\phi(i)</script><p>这样做的好处是，哈希后的特征仍然是一个无偏的估计，不会导致某些哈希位置的值过大。</p>
<p>当然，大家会有疑惑，这种方法来处理特征，哈希后的特征是否能够很好的代表哈希前的特征呢？从实际应用中说，由于文本特征的高稀疏性，这么做是可行的。如果大家对理论上为何这种方法有效，建议参考论文：<a href="http://alex.smola.org/papers/2009/Weinbergeretal09.pdf" target="_blank" rel="noopener">Feature hashing for large scale multitask learning</a>.这里就不多说了。</p>
<p>在scikit-learn的HashingVectorizer类中，实现了基于signed hash  trick的算法，这里我们就用HashingVectorizer来实践一下Hash  Trick，我们直接用前面的文本数据做分类看看结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> HashingVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> RidgeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score</span><br><span class="line"></span><br><span class="line">hashVec = HashingVectorizer(ngram_range=(<span class="number">1</span>,<span class="number">3</span>))</span><br><span class="line">train_test = hashVec.fit_transform(train_df[<span class="string">'text'</span>])</span><br><span class="line"></span><br><span class="line">clf = RidgeClassifier()</span><br><span class="line">clf.fit(train_test[:<span class="number">10000</span>], train_df[<span class="string">'label'</span>].values[:<span class="number">10000</span>])</span><br><span class="line"></span><br><span class="line">val_pred = clf.predict(train_test[<span class="number">10000</span>:])</span><br><span class="line">print(f1_score(train_df[<span class="string">'label'</span>].values[<span class="number">10000</span>:], val_pred, average=<span class="string">'macro'</span>))</span><br></pre></td></tr></table></figure>
<p>这里没有传入max_features参数，因为我们知道哈希技巧本身就是一个降维的算法，计算出来的F1值为0.8891893925390113，明显优于另外两个算法，经过一些调参之后算法准确度还可以提高一些。</p>
<p>这里我们看到虽然我们只用了简单地机器学习算法，但已经取得了挺不错的分类率了，接下来我们将尝试基于深度学习的分类，事实上我们的比赛也从这里才正式开始！</p>
<h1 id="基于深度学习的文本分类"><a href="#基于深度学习的文本分类" class="headerlink" title="基于深度学习的文本分类"></a>基于深度学习的文本分类</h1><h2 id="FastText"><a href="#FastText" class="headerlink" title="FastText"></a>FastText</h2><h3 id="FastText介绍"><a href="#FastText介绍" class="headerlink" title="FastText介绍"></a>FastText介绍</h3><h4 id="fastText模型架构"><a href="#fastText模型架构" class="headerlink" title="fastText模型架构"></a>fastText模型架构</h4><p>fastText是一个快速文本分类算法，与基于神经网络的分类算法相比有两大优点：</p>
<ol>
<li>fastText在保持高精度的情况下加快了训练速度和测试速度</li>
<li>fastText不需要预训练好的词向量，fastText会自己训练词向量</li>
<li>fastText两个重要的优化：<strong>Hierarchical Softmax、N-gram</strong></li>
</ol>
<p>fastText模型架构和word2vec中的CBOW很相似， 不同之处是fastText预测标签而CBOW预测的是中间词，即模型架构类似但是模型的任务不同。word2vec将上下文关系转化为多分类任务，进而训练逻辑回归模型，这里的类别数量$|V|$词库大小。通常的文本数据中，词库少则数万，多则百万，在训练中直接训练多分类逻辑回归并不现实。word2vec中提供了两种针对大规模多分类问题的优化手段， negative sampling 和hierarchical softmax。在优化中，negative sampling 只更新少量负面类，从而减轻了计算量。hierarchical softmax 将词库表示成前缀树，从树根到叶子的路径可以表示为一系列二分类器，一次多分类计算的复杂度从$|V|$降低到了树的高度</p>
<p>fastText模型架构:其中$x_1,x_2,…,x_{N−1},x_N$表示一个文本中的n-gram向量，每个特征是词向量的平均值。这和前文中提到的CBOW相似，<strong>CBOW用上下文去预测中心词，而此处用全部的n-gram去预测指定类别</strong>。</p>
<h4 id="Hierarchical-Softmax"><a href="#Hierarchical-Softmax" class="headerlink" title="Hierarchical Softmax"></a>Hierarchical Softmax</h4><p>softmax函数常在神经网络输出层充当激活函数，目的就是将输出层的值归一化到</p>
<p>$0-1$区间，将神经元输出构造成概率分布，主要就是起到将神经元输出值进行归一化的作用。在标准的softmax中，计算一个类别的softmax概率时，我们需要对所有类别概率做归一化，在这类别很大情况下非常耗时，因此提出了分层softmax(Hierarchical Softmax),思想是根据类别的频率构造霍夫曼树来代替标准softmax，通过分层softmax可以将复杂度从$N$降低到$logN$，下图给出分层softmax示例：<br><img src="/Pic/%E6%96%B0%E9%97%BB%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E5%AE%9E%E6%88%98/huffman.png"></p>
<p>在层次softmax模型中，叶子结点的词没有直接输出的向量，而非叶子节点都有响应的输在在模型的训练过程中，通过Huffman编码，构造了一颗庞大的Huffman树，同时会给非叶子结点赋予向量。我们要计算的是目标词w的概率，这个概率的具体含义，是指从root结点开始随机走，走到目标词w的概率。因此在途中路过非叶子结点（包括root）时，需要分别知道往左走和往右走的概率。例如到达非叶子节点n的时候往左边走和往右边走的概率分别是：</p>
<script type="math/tex; mode=display">p(n, left) = \delta(\theta_n^T·h)</script><script type="math/tex; mode=display">p(n, right) = 1-\sigma(\theta_n^T·h) = \sigma(-\theta_n^T·h)</script><p>以上图中的目标词$w_2$为例：</p>
<script type="math/tex; mode=display">p(w_2) = p(n(w_2, 1), left)·p(n(w_2, 2), left)·p(n(w_2, 3), right)=\sigma(\theta_{n(w_2,1)}^T·h)·\sigma(\theta_{n(w_2,2)}^T·h)·\sigma(-\theta_{n(w_2,3)}^T·h)</script><p>因此目标词为$w$的概率可以表示为：</p>
<script type="math/tex; mode=display">p(w)=\prod_{j=1}^{L(w)-1}\sigma(sign(w,j)·\theta_{n(w,j)}^Th)</script><p>其中$θ_{n(w,j)}$是非叶子结点$n(w,j)$的向量表示（即输出向量）；$h$是隐藏层的输出值，从输入词的向量中计算得来；$sign(x,j)$是一个特殊函数，定义为：</p>
<script type="math/tex; mode=display">sign(w,j)=\begin{cases}1,\text{  若}n(w,j+1)\text{是}n(w,j)\text{的左孩子}\\-1,\text{  若}n(w,j+1)\text{是}n(w,j)\text{的右孩子} \end{cases}</script><p>此外，所有词的概率和为1，即</p>
<script type="math/tex; mode=display">\sum_{i=1}^np(w_i)=1</script><p>最终得到参数更新公式为：</p>
<script type="math/tex; mode=display">\theta_i^{(new)} = \theta_j^{(old)}-\eta(\sigma(\theta_j^Th)-t_j)h</script><h4 id="N-gram特征"><a href="#N-gram特征" class="headerlink" title="N-gram特征"></a>N-gram特征</h4><p>n-gram是基于语言模型的算法，基本思想是将文本内容按照子节顺序进行大小为N的窗口滑动操作，最终形成窗口为N的字节片段序列。而且需要额外注意一点是n-gram可以根据粒度不同有不同的含义，有字粒度的n-gram和词粒度的n-gram，正如前面调参时的2-gram和3-gram。</p>
<p>对于文本句子的n-gram来说，如上面所说可以是字粒度或者是词粒度，同时n-gram也可以在字符级别工作，例如对单个单词matter来说，假设采用3-gram特征，那么matter可以表示成图中五个3-gram特征，这五个特征都有各自的词向量，五个特征的词向量和即为matter这个词的向其中“&lt;”和“&gt;”是作为边界符号被添加，来将一个单词的ngrams与单词本身区分开来：<br><img src="/Pic/%E6%96%B0%E9%97%BB%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E5%AE%9E%E6%88%98/28.png" alt></p>
<p>从上面来看，使用n-gram有如下优点<br>1、为罕见的单词生成更好的单词向量：根据上面的字符级别的n-gram来说，即是这个单词出现的次数很少，但是组成单词的字符和其他单词有共享的部分，因此这一点可以优化生成的单词向量<br>2、在词汇单词中，即使单词没有出现在训练语料库中，仍然可以从字符级n-gram中构造单词的词向量<br>3、n-gram可以让模型学习到局部单词顺序的部分信息, 如果不考虑n-gram则便是取每个单词，这样无法考虑到词序所包含的信息，即也可理解为上下文信息，因此通过n-gram的方式关联相邻的几个词，这样会让模型在训练的时候保持词序信息</p>
<h4 id="其他解决方案"><a href="#其他解决方案" class="headerlink" title="其他解决方案"></a>其他解决方案</h4><p>但正如上面提到过，随着语料库的增加，内存需求也会不断增加，严重影响模型构建速度，针对这个有以下几种解决方案：<br>1、过滤掉出现次数少的单词<br>2、使用hash存储<br>3、由采用字粒度变化为采用词粒度</p>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>我们先看看<a href="https://github.com/facebookresearch/fastText/tree/master/python" target="_blank" rel="noopener">gituhub官方文档</a>对FastText的定义 ：</p>
<blockquote>
<p><a href="https://fasttext.cc/" target="_blank" rel="noopener">fastText</a> is a library for efficient learning of word representations and sentence classification.</p>
</blockquote>
<p>我们先使用fastText，随后再对其进行详细解析，第一步我们需要安装 fastText库：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip instal fastText</span><br></pre></td></tr></table></figure>
<p>或者手动从github下载：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ git clone https:&#x2F;&#x2F;github.com&#x2F;facebookresearch&#x2F;fastText.git</span><br><span class="line">$ cd fastText</span><br><span class="line">$ sudo pip install .</span><br><span class="line">$ # or :</span><br><span class="line">$ sudo python setup.py install</span><br></pre></td></tr></table></figure>
<h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><p>我们直接使用fastText来实现我们的文本分类，代码一共只有寥寥几行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!pip install fasttext</span><br><span class="line"><span class="keyword">import</span> fasttext</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转换为FastText需要的格式</span></span><br><span class="line">train_df = pd.read_csv(<span class="string">"train_set.csv"</span>, sep=<span class="string">"\t"</span>, nrows=<span class="number">15000</span>)</span><br><span class="line">train_df[<span class="string">"label_ft"</span>] = <span class="string">"__label__"</span> + train_df[<span class="string">"label"</span>].astype(str)</span><br><span class="line">train_df[[<span class="string">"text"</span>, <span class="string">"label_ft"</span>]].iloc[:<span class="number">-5000</span>].to_csv(<span class="string">"train.csv"</span>, index=<span class="literal">None</span>, header=<span class="literal">None</span>, sep=<span class="string">"\t"</span>)</span><br><span class="line"></span><br><span class="line">model = fasttext.train_supervised(<span class="string">"train.csv"</span>, lr=<span class="number">1.0</span>, wordNgrams=<span class="number">2</span>, verbose=<span class="number">2</span>, minCount=<span class="number">1</span>, epoch=<span class="number">25</span>, loss=<span class="string">"hs"</span>)</span><br><span class="line"></span><br><span class="line">val_pred = [model.predict(x)[<span class="number">0</span>][<span class="number">0</span>].split(<span class="string">"__"</span>)[<span class="number">-1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> train_df.iloc[<span class="number">-5000</span>:][<span class="string">"text"</span>]]</span><br><span class="line">print(f1_score(train_df[<span class="string">"label"</span>].values[<span class="number">-5000</span>:].astype(str), val_pred, average=<span class="string">"macro"</span>))</span><br></pre></td></tr></table></figure>
<p>结果很快就输出出来了（比前面的机器学习模型还快），结果为0.8260812453351833，但人不可貌相，我们可以对这个结果做很多优化，比如增加训练集数量，调整参数等。下面先对上面部分参数做了个简单的循环用于查看粗略的训练效果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 粗略调参</span></span><br><span class="line"><span class="keyword">import</span> fasttext</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转换为FastText需要的格式</span></span><br><span class="line">train_df = pd.read_csv(<span class="string">"train_set.csv"</span>, sep=<span class="string">"\t"</span>, nrows=<span class="number">15000</span>)</span><br><span class="line">train_df[<span class="string">"label_ft"</span>] = <span class="string">"__label__"</span> + train_df[<span class="string">"label"</span>].astype(str)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> val_set <span class="keyword">in</span> [<span class="number">2000</span>, <span class="number">3000</span>, <span class="number">4000</span>, <span class="number">5000</span>]:</span><br><span class="line">    print(<span class="string">"The validation set is:"</span>, val_set)</span><br><span class="line">    train_df[[<span class="string">"text"</span>, <span class="string">"label_ft"</span>]].iloc[:-val_set].to_csv(<span class="string">"train.csv"</span>, index=<span class="literal">None</span>, header=<span class="literal">None</span>, sep=<span class="string">"\t"</span>)</span><br><span class="line">    <span class="keyword">for</span> lr_ <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">10</span>, <span class="number">2</span>):</span><br><span class="line">        print(<span class="string">"Learning rate is:"</span>, lr_/<span class="number">10</span>)</span><br><span class="line">        <span class="keyword">for</span> wordGram <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]:</span><br><span class="line">            print(<span class="string">"wordNgrams is:"</span>, wordGram)</span><br><span class="line">            model = fasttext.train_supervised(<span class="string">"train.csv"</span>, lr=lr_/<span class="number">10</span>, wordNgrams=wordGram, verbose=<span class="number">2</span>, minCount=<span class="number">1</span>, epoch=<span class="number">25</span>, loss=<span class="string">"hs"</span>)</span><br><span class="line">            val_pred = [model.predict(x)[<span class="number">0</span>][<span class="number">0</span>].split(<span class="string">"__"</span>)[<span class="number">-1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> train_df.iloc[-val_set:][<span class="string">"text"</span>]]</span><br><span class="line">            print(<span class="string">"f1_score is:"</span>, f1_score(train_df[<span class="string">"label"</span>].values[-val_set:].astype(str), val_pred, average=<span class="string">"macro"</span>))</span><br></pre></td></tr></table></figure>
<p>为什么说这是粗略的呢，因为验证集与测试集的划分比较随意，就取了前一部分作为训练集后一部分作为验证集，没有多次独立重复实验取平均值之类的操作，因此实验结果带有较大的偶然性，但这样粗略的实验有助于我们对整体参数有个大概的估计，我们后面的实验可以在更精细的参数范围内做调参等工作。根据上面的粗调参结果我们可以看到几个显然的结论（以下对参数的讨论均限制在上述实验所取范围）：</p>
<ul>
<li>验证集越小效果越好</li>
<li>学习率越高越好</li>
<li>学习率较高（约0.7以上）时，wordNgrams参数为3时效果较好，学习率较低时wordNgrams参数为2时效果较好</li>
<li>最最重要的是，训练数据全加进来效果当然会好很多</li>
</ul>
<p>由于学习率未达到峰值，我们往1的右边继续调高学习率进行实验，最终我们将参数的取值范围大致定在以下范围内，我们后续将对这个范围内的参数做进一步调参：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>参数名</th>
<th>learning_rate</th>
<th>wordNgrams</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>取值范围</strong></td>
<td>(1.2, 1.4)</td>
<td>3</td>
</tr>
</tbody>
</table>
</div>
<p>在精确的参数估计中，我们使用10折交叉验证，每折使用9/10的数据进行训练，剩余1/10作为验证集检验模型的效果。这里需要注意每折的划分必须保证标签的分布与整个数据集的分布一致，划分代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">label2id &#x3D; &#123;&#125;</span><br><span class="line">for i in range(total):</span><br><span class="line">    label &#x3D; str(all_labels[i])</span><br><span class="line">    if label not in label2id:</span><br><span class="line">        label2id[label] &#x3D; [i]</span><br><span class="line">    else:</span><br><span class="line">        label2id[label].append(i)</span><br></pre></td></tr></table></figure>
<p>通过10折划分，我们一共得到了10份分布一致的数据，索引分别为0到9，每次通过将一份数据作为验证集，剩余数据作为训练集，获得了所有数据的10种分割。不失一般性，我们选择最后一份完成剩余的实验，即索引为9的一份做为验证集，索引为1-8的作为训练集，然后基于验证集的结果调整超参数，使得模型性能更优。嗯想了想前面的HashingVectorizer，不用累死累活去调参就有0.889的准确率（甭跟我扯训练数据的事，两个方法的训练数据都是10000），真是心累阿，不准备接着调参了反正也不是很高，就大概0.85左右这个样，重点还是后面两个方法。</p>
<h2 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h2><h3 id="词向量训练"><a href="#词向量训练" class="headerlink" title="词向量训练"></a>词向量训练</h3><p>Word2Vec的理论我们在往期博客中已经有详细介绍了（<a href="https://chenk.tech/posts/fb70fd3e.html" target="_blank" rel="noopener">传送门</a>），这里我们将直接对其进行调用，并介绍整个实验流程：</p>
<p>首先导入必要的包，并过滤警告：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Word2Vec</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br></pre></td></tr></table></figure>
<p>然后保险起见我们再瞅一眼我们的数据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_all = pd.read_csv(<span class="string">"train.csv"</span>, sep=<span class="string">"\t"</span>, nrows=<span class="number">15000</span>)</span><br><span class="line">data_all.head()</span><br></pre></td></tr></table></figure>
<p>大概长这样，嗯没错：</p>
<p><img src="/Pic/NLP/30.png" alt></p>
<p>我们接下来就要构建我们的词表啦，由于训练时通常是所有文档合并起来一起训练，因此这里就直接将所有的编码词合并起来：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">word_list = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(data_all)):</span><br><span class="line">    word_list.append(data_all[<span class="string">"text"</span>][i].strip().split(<span class="string">" "</span>))</span><br></pre></td></tr></table></figure>
<p>下一步就将词表传入模型进行训练啦，当然也可以将训练结果进行保存：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">word2vec_model = Word2Vec(word_list, size=<span class="number">20</span>, iter=<span class="number">10</span>, min_count=<span class="number">20</span>)</span><br><span class="line">word2vec_model.save(<span class="string">'word2vec_model.w2v'</span>)</span><br></pre></td></tr></table></figure>
<p>由于我们是要对文章进行分类，而不是对某个词分类，我们最简单的表示文章的方法就是将文章中所有词向量取平均输出（后面会介绍其他方法）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getVector</span><span class="params">(text, word2vec_model)</span>:</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    article_vector = np.zeros( word2vec_model.layer1_size )</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> text:</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> word2vec_model:</span><br><span class="line">            article_vector += word2vec_model[word]</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> article_vector / count</span><br><span class="line"></span><br><span class="line">startTime = time.time()</span><br><span class="line">vector_list = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(data_all)):</span><br><span class="line">    text = data_all[<span class="string">"text"</span>][i].strip().split(<span class="string">" "</span>)</span><br><span class="line">    vector_list.append(getVector(text, word2vec_model))</span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">"前%d个文本生成词向量花费总时间%.2f秒"</span> %(i, time.time()-startTime))</span><br></pre></td></tr></table></figure>
<p>可以看到生成的结果还是蛮快的：</p>
<p><img src="/Pic/NLP/31.png" alt></p>
<p>于是我们的文本向量也就构建完成了，接下来我们可以套用我们熟知的各种机器学习模型或深度学习模型啦！</p>
<h3 id="利用词向量进行分类"><a href="#利用词向量进行分类" class="headerlink" title="利用词向量进行分类"></a>利用词向量进行分类</h3><p>首先最简单的当然是试探一下逻辑回归是否可行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">X = np.array(vector_list)</span><br><span class="line">y = np.array(data_all[<span class="string">"label"</span>])</span><br><span class="line"></span><br><span class="line">train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>)</span><br><span class="line"> </span><br><span class="line">logistic_model = LogisticRegression()</span><br><span class="line">logistic_model.fit(train_X, train_y)</span><br><span class="line">logistic_model.score(test_X, test_y)</span><br></pre></td></tr></table></figure>
<p>结果是0.7783333333333333,不好不差，至少说明了构建的词向量不算离谱hhh~我们接下来将所有能想到的分类的模型全部试一遍，然后选一个效果比较不错的再进行调参，大致是这样：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPClassifier  <span class="comment"># 多层感知机</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier  <span class="comment"># K最近邻</span></span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC  <span class="comment"># 支持向量机</span></span><br><span class="line"><span class="keyword">from</span> sklearn.gaussian_process <span class="keyword">import</span> GaussianProcessClassifier  <span class="comment"># 高斯过程</span></span><br><span class="line"><span class="keyword">from</span> sklearn.gaussian_process.kernels <span class="keyword">import</span> RBF  <span class="comment"># 高斯核函数</span></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier  <span class="comment"># 决策树</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier,\</span><br><span class="line">    ExtraTreesClassifier, BaggingClassifier  <span class="comment"># 集成方法</span></span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB  <span class="comment"># 高斯朴素贝叶斯</span></span><br><span class="line"><span class="keyword">from</span> sklearn.discriminant_analysis <span class="keyword">import</span> QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis  <span class="comment"># 判别分析</span></span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier  <span class="comment"># 极端梯度提升（eXtreme Gradient Boosting）</span></span><br><span class="line"></span><br><span class="line">classifiers = [</span><br><span class="line">    (<span class="string">'Logistic Regression'</span>, LogisticRegression()),  <span class="comment"># 逻辑回归</span></span><br><span class="line">    (<span class="string">'Nearest Neighbors'</span>, KNeighborsClassifier(<span class="number">3</span>)),  <span class="comment"># K最近邻</span></span><br><span class="line">    (<span class="string">'Linear SVM'</span>, SVC(kernel=<span class="string">'linear'</span>, C=<span class="number">0.025</span>)),  <span class="comment"># 线性的支持向量机</span></span><br><span class="line">    (<span class="string">'RBF SVM'</span>, SVC(gamma=<span class="number">2</span>, C=<span class="number">1</span>)),  <span class="comment"># 径向基函数的支持向量机</span></span><br><span class="line">    (<span class="string">'Gaussian Process'</span>, GaussianProcessClassifier(<span class="number">1.0</span> * RBF(<span class="number">1.0</span>))),  <span class="comment"># 基于拉普拉斯近似的高斯过程</span></span><br><span class="line">    (<span class="string">'Decision Tree'</span>, DecisionTreeClassifier(max_depth=<span class="number">5</span>)),  <span class="comment"># 决策树</span></span><br><span class="line">    (<span class="string">'Random Forest'</span>, RandomForestClassifier(max_depth=<span class="number">5</span>, n_estimators=<span class="number">10</span>, max_features=<span class="number">1</span>)),  <span class="comment"># 随机森林</span></span><br><span class="line">    (<span class="string">'AdaBoost'</span>, AdaBoostClassifier()),  <span class="comment"># 通过迭代弱分类器而产生最终的强分类器的算法</span></span><br><span class="line">    (<span class="string">'Extra Trees'</span>, ExtraTreesClassifier()),</span><br><span class="line">    (<span class="string">'GradientBoosting'</span>, GradientBoostingClassifier()),  <span class="comment"># 梯度提升树</span></span><br><span class="line">    (<span class="string">'Bagging'</span>, BaggingClassifier()),</span><br><span class="line">    (<span class="string">'Naive Bayes'</span>, GaussianNB()),  <span class="comment"># 朴素贝叶斯</span></span><br><span class="line">    (<span class="string">'QDA'</span>, QuadraticDiscriminantAnalysis()),  <span class="comment"># 二次判别分析</span></span><br><span class="line">    (<span class="string">'LDA'</span>, LinearDiscriminantAnalysis()),  <span class="comment"># 线性判别分析</span></span><br><span class="line">    (<span class="string">'MLP'</span>, MLPClassifier(alpha=<span class="number">1</span>)),  <span class="comment"># 多层感知机</span></span><br><span class="line">    (<span class="string">'XGB'</span>, XGBClassifier()),  <span class="comment"># 极端梯度提升</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>定义两个函数便于调参（构建词向量与训练模型）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">testWord2Vec</span><span class="params">(data_all, size_=<span class="number">100</span>, min_count_=<span class="number">5</span>)</span>:</span></span><br><span class="line">    word_list = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data_all)):</span><br><span class="line">        word_list.append(data_all[<span class="string">"text"</span>][i].strip().split(<span class="string">" "</span>))</span><br><span class="line">    word2vec_model = Word2Vec(word_list, size=size_, iter=<span class="number">10</span>, min_count=min_count_)</span><br><span class="line">    vector_list = []</span><br><span class="line">    startTime = time.time()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data_all)):</span><br><span class="line">        text = data_all[<span class="string">"text"</span>][i].strip().split(<span class="string">" "</span>)</span><br><span class="line">        vector_list.append(getVector(text, word2vec_model))</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"前%d个文本生成词向量花费总时间%.2f秒"</span> %(i, time.time()-startTime))</span><br><span class="line">    X = np.array(vector_list)</span><br><span class="line">    y = np.array(data_all[<span class="string">"label"</span>])</span><br><span class="line">    <span class="keyword">return</span> X, y</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">testModel</span><span class="params">(X, y, test_size_=<span class="number">0.2</span>, seed=<span class="number">0</span>)</span>:</span> </span><br><span class="line">    train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=test_size_, random_state=seed)</span><br><span class="line">    <span class="keyword">for</span> name, clf <span class="keyword">in</span> classifiers:</span><br><span class="line">        print(name, end=<span class="string">": "</span>)</span><br><span class="line">        clf.fit(train_X, train_y)</span><br><span class="line">        print(clf.score(test_X, test_y))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X, y = testWord2Vec(data_all)</span><br><span class="line">testModel(X, y)</span><br></pre></td></tr></table></figure>
<p>本人训练后结果比较好的是逻辑回归、K最近邻、多层感知机和极端梯度提升，没有进行调参的准确率大约0.85左右，部分结果如下。希望有更高的准确率读者自行调参即可：</p>
<p><img src="/Pic/NLP/32.png" alt></p>
<h3 id="其他方式（Doc2Vec）"><a href="#其他方式（Doc2Vec）" class="headerlink" title="其他方式（Doc2Vec）"></a>其他方式（Doc2Vec）</h3><p>事实上我们不一定要先构建词向量，再取平均得到句子向量，2013 年 Mikolov 提出了 word2vec 来学习单词的向量表示，主要有两种方法，cbow ( continuous bag of words) 和 skip-gram ， 一个是用语境来预测目标单词，另一个是用中心单词来预测语境。</p>
<p>既然可以将 word 表示成向量形式，那么句子／段落／文档是否也可以只用一个向量表示？事实上是可以的，主要有两种方式，第一种方式便是我们 前面所做的，先得到 word 的向量表示，然后用一个简单的平均来代表文档。 第二种方式就是 Mikolov 在 2014 提出的Doc2Vec，也有两种方法来实现：</p>
<p><strong>Distributed Memory Model of Paragraph Vectors(PVDM)</strong></p>
<p>它不是仅是使用一些单词来预测下一个单词,我们还添加了另一个特征向量，即<strong>文档Id</strong>。</p>
<p>因此，当训练单词向量W时，也训练文档向量D，并且在训练结束时，它包含了文档的向量化表示。</p>
<p><img src="/Pic/NLP/29.jpg" alt></p>
<p>调用gensim方式为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = gensim.models.Doc2Vec(documents,dm = <span class="number">0</span>, alpha=<span class="number">0.1</span>, size= <span class="number">20</span>, min_alpha=<span class="number">0.025</span>)</span><br></pre></td></tr></table></figure>
<p><strong>Distributed Bag of Words version of Paragraph Vector(PV-DBOW)</strong></p>
<p><img src="/Pic/NLP/30.jpg" alt></p>
<p>调用gensim方式为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = gensim.models.Doc2Vec(documents,dm = <span class="number">0</span>, alpha=<span class="number">0.1</span>, size= <span class="number">20</span>, min_alpha=<span class="number">0.025</span>)</span><br></pre></td></tr></table></figure>
<p>由上面的调用方式可见，PVDM与PV-DBOW两者在 gensim 实现时的区别是 dm = 0 还是 1。总结一下：</p>
<ul>
<li><p><strong>Doc2Vec 的目的</strong>：获得文档的一个固定长度的向量表达。</p>
</li>
<li><p><strong>数据</strong>：多个文档，以及它们的标签，可以用标题作为标签。</p>
</li>
<li><strong>影响模型准确率的因素</strong>：语料的大小，文档的数量，越多越高；文档的相似性，越相似越好。</li>
</ul>
<p>下面我们动手实现一下Doc2Vec（具体参考<a href="https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html#sphx-glr-auto-examples-tutorials-run-doc2vec-lee-py" target="_blank" rel="noopener">文档</a>）结果可能会让你大吃一惊（哭笑）：</p>
<p>首先还是一样导入相关的包：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Doc2Vec</span><br><span class="line"><span class="keyword">import</span> gensim</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br></pre></td></tr></table></figure>
<p>然后读取文件：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_all = pd.read_csv(<span class="string">"train.csv"</span>, sep=<span class="string">"\t"</span>, nrows=<span class="number">15000</span>)</span><br><span class="line">data_all.head()</span><br></pre></td></tr></table></figure>
<p>用后3000条做验证集（当然也可以搞个N折交叉验证严谨点），这里需要注意的是一定要重置索引，哎说多都是泪：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_all_train = data_all.head(<span class="number">12000</span>)</span><br><span class="line">data_all_val = data_all.tail(<span class="number">3000</span>)</span><br><span class="line">data_all_val = data_all_val.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">data_all_train.head()</span><br></pre></td></tr></table></figure>
<p>然后按格式读进数据，这里定义了一个read_corpus，是根据官方文档进行的修改，读者也可以根据自己的需要对其进行修改：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_corpus</span><span class="params">(data_all, tokens_only=False)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data_all)):</span><br><span class="line">        tokens = data_all[<span class="string">"text"</span>][i].split(<span class="string">" "</span>)</span><br><span class="line">        <span class="keyword">if</span> tokens_only:</span><br><span class="line">            <span class="keyword">yield</span> tokens</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">yield</span> gensim.models.doc2vec.TaggedDocument(tokens, [data_all[<span class="string">'label'</span>][i]])</span><br><span class="line">    </span><br><span class="line">train_corpus = list(read_corpus(data_all_train))</span><br><span class="line">val_corpus = list(read_corpus(data_all_val, tokens_only=<span class="literal">True</span>))</span><br></pre></td></tr></table></figure>
<p>随后定义模型，可以开始训练啦：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = gensim.models.doc2vec.Doc2Vec(vector_size=<span class="number">50</span>, min_count=<span class="number">2</span>, epochs=<span class="number">40</span>)</span><br><span class="line">model.build_vocab(train_corpus)</span><br><span class="line">model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)</span><br><span class="line">vector_train_1 = model.infer_vector(train_corpus[<span class="number">1</span>].words)</span><br><span class="line">print(vector_train_1)</span><br><span class="line">tag_train_1 = train_corpus[<span class="number">1</span>].tags</span><br><span class="line">print(tag_train_1)</span><br></pre></td></tr></table></figure>
<p>打印出训练得到的编码，看起来挺人模人样的：</p>
<p><img src="/Pic/NLP/33.png" alt></p>
<p>然后我们就把模型套进我们的文本中，将训练集和测试集顺便划分好：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_X = []</span><br><span class="line">train_y = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(train_corpus)):</span><br><span class="line">    train_X.append(list(model.infer_vector(train_corpus[i].words)))</span><br><span class="line">    train_y.append(train_corpus[i].tags)</span><br><span class="line">    <span class="keyword">if</span>(i%<span class="number">3000</span>==<span class="number">0</span>):</span><br><span class="line">        print(<span class="string">"Processing train set"</span>, i)</span><br><span class="line">val_X = []</span><br><span class="line">val_y = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(val_corpus)):</span><br><span class="line">    val_X.append(list(model.infer_vector(val_corpus[i])))</span><br><span class="line">    val_y.append([data_all[<span class="string">"label"</span>][i]])</span><br><span class="line">    </span><br><span class="line">train_X = np.array(train_X)</span><br><span class="line">train_y = np.array(train_y)</span><br><span class="line">val_X = np.array(val_X)</span><br><span class="line">val_y = np.array(val_y)</span><br></pre></td></tr></table></figure>
<p>好这一切准备就绪了，我们就套一个逻辑回归吧，咱也甭求多高准确度，百分之八九十就好啦再慢慢调参吧：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">logistic_model = LogisticRegression()</span><br><span class="line">logistic_model.fit(train_X, train_y)</span><br><span class="line">logistic_model.score(val_X, val_y)</span><br></pre></td></tr></table></figure>
<p>看看结果：0.12666666，雾草？？？我不信邪试了试其他的回归模型也差不多这个数，emmm网上搜了搜确实有遇到Doc2Vec效果不稳定的情况，但看原理不是和Word2Vec差不多吗，别以为我是埋伏笔，俺也不知道啊大家清楚的下面留言咯，看看是我代码的问题还是确实如此，又或者是数据集的特点决定的~</p>
<h2 id="Bert"><a href="#Bert" class="headerlink" title="Bert"></a>Bert</h2><p>参考链接：</p>
<ul>
<li><a href="https://github.com/datawhalechina/team-learning-nlp/blob/master/NewsTextClassification" target="_blank" rel="noopener">https://github.com/datawhalechina/team-learning-nlp/blob/master/NewsTextClassification</a></li>
<li><a href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text" target="_blank" rel="noopener">https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text</a></li>
<li><a href="https://www.cnblogs.com/pinard/p/6688348.html" target="_blank" rel="noopener">https://www.cnblogs.com/pinard/p/6688348.html</a></li>
<li><a href="https://blog.csdn.net/zhangbaoanhadoop/article/details/79570128" target="_blank" rel="noopener">https://blog.csdn.net/zhangbaoanhadoop/article/details/79570128</a></li>
<li><a href="https://blog.csdn.net/feilong_csdn/article/details/88655927" target="_blank" rel="noopener">https://blog.csdn.net/feilong_csdn/article/details/88655927</a></li>
<li>A. Joulin, E. Grave, P. Bojanowski, T. Mikolov, <a href="https://arxiv.org/abs/1607.01759" target="_blank" rel="noopener"><em>Bag of Tricks for Efficient Text Classification</em></a></li>
<li><a href="https://blog.csdn.net/qdhy199148/article/details/51754631" target="_blank" rel="noopener">https://blog.csdn.net/qdhy199148/article/details/51754631</a></li>
<li><a href="https://www.imooc.com/article/41650" target="_blank" rel="noopener">https://www.imooc.com/article/41650</a></li>
</ul>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title>贪心NLP刷课笔记（一）</title>
    <url>/posts/dcf8c6f9.html</url>
    <content><![CDATA[<h1 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h1><h2 id="自然语言处理技术"><a href="#自然语言处理技术" class="headerlink" title="自然语言处理技术"></a>自然语言处理技术</h2><h3 id="四个维度"><a href="#四个维度" class="headerlink" title="四个维度"></a>四个维度</h3><ul>
<li>Semantic 语义</li>
<li>Syntax 句子结构</li>
<li>Morphology 单词</li>
<li>Phonetics 声音</li>
</ul>
<p>上面四个维度是自订而底的，核心为前三类：Morphology关注的是分词，pos（词性）和NER等基础技术，我们要做到顶层的可用性，其底层至少需要达到某个阈值；Syntax关注的是句法分析（提取特征；有一个算法为CYK，是一个根据动态规划的算法）、依存分析（Dependence，分析每个词之间有什么关系，可以分析单词之间潜在的联系，可作为特征）；语义分析为最终的目标，是最上层的生态。</p>
<h3 id="基本问题"><a href="#基本问题" class="headerlink" title="基本问题"></a>基本问题</h3><p>NLP的问题可以分为三大类：第一类是基本解决的问题：Spam detection, 命名实体识别等为简单的问题，基本可以保证准确率95%以上，第二类是比较难的算法，比如：Coreference resolution, Word sense disambiguation, Parsing, Machine Translation, Information Translation，第三类是很难的且需要花费较多时间的工作，比如文本摘要与对话系统。</p>
<h2 id="4P"><a href="#4P" class="headerlink" title="4P"></a>4P</h2><p>咳这个不是多人运动，这里讲的是<strong>P, NP, NP Hard和NP Complete</strong>，我们一般来说，可以将算法复杂度分为指数级复杂度$O(p^n)$与多项式级复杂度$O(n^p)$，只要是多项式级复杂度，我们都可以将其理解为可解决的问题，而指数级复杂度我们一般认为是不可解决的问题（量级很小仍可以解决），但我们可以提出一个近似算法，其复杂度为$O(n^p)$可以得到一个近似解（不能保证得到精确解），我们仍可以认为其是近似可以解决的（当然未来也可以使用量子计算机）。</p>
<p>上面的多项式级的复杂度我们称为P问题，指数级复杂度为NP Hard或者NP Complete问题，其中NP Complete问题是NP Hard问题的子集（这两者较难区分这里不详述），NP的意思是可以在多项式复杂度内能验证的问题。</p>
<h2 id="基于搜索的问答系统"><a href="#基于搜索的问答系统" class="headerlink" title="基于搜索的问答系统"></a>基于搜索的问答系统</h2><p>首先我们有一个知识库（问题答案对），预处理环节我们对用户提出的问题先做分词处理，然后做拼写纠错，然后将所有的语态转化为相同的语态（比如went和going转为go），这是Stemming环节，然后就是停用词过滤以及无用单词的过滤（Word Filtering），最后还可以考虑同义词替换。接着我们可以将用户提出的问题转换为向量表示（boolen vector——&gt;count vector——&gt; tf-idf——&gt;Word2Vector——&gt; Seq2Seq），转换完向量后我们就需要计算相似度（可以使用欧氏距离,Cosine距离或其他距离公式），然后按照相似度距离排序，获得最终结果，排序完之后也可能再进行最后一轮的过滤。如果文本数量太多可以通过建立倒排表降低时间复杂度加速过程。</p>
<h1 id="NLP项目Pipeline"><a href="#NLP项目Pipeline" class="headerlink" title="NLP项目Pipeline"></a>NLP项目Pipeline</h1><p>下图为NLP项目的Pipeline：</p>
<p><img src="/posts/Pic\NLP\23.png" alt></p>
<p>下面介绍的前两个流程涉及的算法较多，后两个算法较少。下面分别进行介绍：</p>
<h2 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h2><h3 id="Word-Segmentation"><a href="#Word-Segmentation" class="headerlink" title="Word Segmentation"></a>Word Segmentation</h3><p>常见的分词工具有Jieba分词，SnowNLP，LTP，HanNLP，目前较常用的是Jieba分词工具，Python调用直接impor jieba即可，可以通过cut语句切分，可以通过add_word函数加入希望其识别的专有名词，此时不会对其做切分。</p>
<h4 id="前向最大匹配（forward-max-matching）"><a href="#前向最大匹配（forward-max-matching）" class="headerlink" title="前向最大匹配（forward-max matching）"></a>前向最大匹配（forward-max matching）</h4><p>首先我们举例：我们经常有意见分歧。我们第一步建立词典：[“我们”，”经常”，”有”，”有意见”，”意见”，”分歧”]，我们匹配方式是将整个句子不断剪掉后面的单词，然后匹配词典中的单词，最终得到的分词结果是：[“我们”，”经常”，”有意见”，”分歧”]，这种匹配法会尽量匹配更多的字符。这是一个贪心的算法。</p>
<p>顺便提一句，算法分为贪心算法和DP算法，其中贪心算法是寻找当前最优的，DP算法近似寻找全局最优，可以考虑全局信息。</p>
<h4 id="后向最大匹配（backward-max-matching）"><a href="#后向最大匹配（backward-max-matching）" class="headerlink" title="后向最大匹配（backward-max matching）"></a>后向最大匹配（backward-max matching）</h4><p>过程与前向最大匹配类似，首先设置max-len=5，先考虑”有意见分歧“，发现不在词典里，我们缩减单词为“意见分歧”，逐步这样炒粉得到”分歧“为词典中的单词，最终这个例子我们得到的结果与前向最大匹配得到的结果一样，当然有时候这两个匹配方式得到的结果不一样（但机率很低）。结合这两个匹配方式就得到了双向匹配，也就是结合前向最大匹配和后向最大匹配 。</p>
<p>上面的分词方法的缺点：</p>
<ol>
<li>无法对词进行细分，当我们遇到细分后单词可能为更好的单词时就不太准确；</li>
<li>考虑的是局部最优而不是全局最优；</li>
<li>效率受到Max-len影响</li>
<li>不能考虑到语义信息</li>
</ol>
<p>最大匹配算法只能看到我们前面说到的单词信息，是最简单的模型，而考虑不到语义和句子结构的信息。但我们考虑到这两个信息之后当然我们的复杂度也会随之提高。因此我们可以先试验简单地分词方法，效果还不错的话我们可以再提升为更复杂的模型（考虑到语义信息）。</p>
<h4 id="Incorporate-Semantic（考虑语义）"><a href="#Incorporate-Semantic（考虑语义）" class="headerlink" title="Incorporate Semantic（考虑语义）"></a>Incorporate Semantic（考虑语义）</h4><p>我们希望有一个工具，能够将句子传入，返回一个语义的概率（不同分词法的概率），然后选取概率高的分法即可。<strong>也就是我们输入句子，根据词典库生成所有可能的分割，在其中选择最好的。</strong></p>
<p>我们有一个工具（Language Model），最简单的算法就是根据条件概率假设（所有词出现概率不相关），将句子概率分解成单词的概率乘积，也就是：</p>
<script type="math/tex; mode=display">P(\text{经常，有，意见，分歧})=P(\text{经常})P(\text{有})P(\text{意见})P(\text{分歧}) v.s. P(\text{经常，有意见，分歧})=P(\text{经常})P(\text{有意见})P(\text{分歧})</script><p>由于上面的计算中每个概率值都很低（在一个语料库中每个单词出现的次数都比较少），我们计算乘积时一般会计算$\text{log}P(\text{经常，有，意见，分歧})$，然后将取log之后的结果累加即可。由于$\text{log}$函数时严格递增的，因此可以保证比较是等同的，有时候我们也会加平滑项，这里先不讲。上面的计算方法是Unigram方法，我们当然还可以考虑两个或更多单词的联合概率分布。</p>
<p>我们前面考虑的是先列出所有可能，然后找到其中最好的（概率最高的），我们可以将这两个步骤合并起来做优化，也就是我们常说的维特比算法（也是DP算法）。首先我们计算出每个分词的负log概率，如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>词典</th>
<th>经常</th>
<th>经</th>
<th>有</th>
<th>有意见</th>
<th>意见</th>
<th>分歧</th>
<th>见</th>
<th>意</th>
<th>见分歧</th>
<th>分</th>
</tr>
</thead>
<tbody>
<tr>
<td>概率</td>
<td>0.1</td>
<td>0.05</td>
<td>0.1</td>
<td>0.1</td>
<td>0.2</td>
<td>0.2</td>
<td>0.05</td>
<td>0.05</td>
<td>0.05</td>
<td>0.1</td>
</tr>
<tr>
<td>-log(x)</td>
<td>2.3</td>
<td>3</td>
<td>2.3</td>
<td>2.3</td>
<td>1.6</td>
<td>1.6</td>
<td>3</td>
<td>3</td>
<td>3</td>
<td>2.3</td>
</tr>
</tbody>
</table>
</div>
<p>可以转化为下图：</p>
<p><img src="/posts/Pic\NLP\24.png" alt></p>
<p>我们可以<strong>将分词目标转化为最小路径</strong>（路径为-log(x)），我们只需要找到最短的从第一个单词经过所有单词（按次序）直到最后一个单词的路径即可。我们定义$f(n)=\text{从节点1到节点n的最短路径的值}$，这个过程我们完全可以通过递归实现，但我们可以想道斐波那契数列用这种方法来计算的话会很浪费计算资源，我们可以维护一个$f(n)$数组来简化运算。其中$f(1)=0,f(2)=3,f(3)=2.3$等等得到第一个节点到最后一个节点的最短路径值，同时也可以得到其路径（需要反推 ），读者不妨自己推一下，最终我们得到最优路径为1——&gt;3——&gt;6——&gt;8（上面的概率是随意取的不代表真实概率 ）。具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">sys.setrecursionlimit(<span class="number">9000000</span>)</span><br><span class="line">    <span class="comment">## 请编写word_segment_viterbi函数来实现对输入字符串的分词</span></span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">word_segment_viterbi</span><span class="params">(input_str)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    1. 基于输入字符串，词典，以及给定的unigram概率来创建DAG(有向图）。</span></span><br><span class="line"><span class="string">    2. 编写维特比算法来寻找最优的PATH</span></span><br><span class="line"><span class="string">    3. 返回分词结果</span></span><br><span class="line"><span class="string">    """</span> </span><br><span class="line">    <span class="keyword">if</span> len(input_str) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 第一步： 构建图                 </span></span><br><span class="line">    n = len(input_str)</span><br><span class="line">    path = np.zeros([n+<span class="number">1</span>,n+<span class="number">1</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        <span class="keyword">if</span> input_str[i] <span class="keyword">in</span> word_prob:</span><br><span class="line">            path[i,i+<span class="number">1</span>] = word_prob[input_str[i]]</span><br><span class="line">        <span class="keyword">elif</span> input_str[i] <span class="keyword">in</span> dic_words:</span><br><span class="line">            path[i,i+<span class="number">1</span>] = <span class="number">0.00001</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>,n+<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> input_str[i:j] <span class="keyword">in</span> word_prob:</span><br><span class="line">                path[i,j] = word_prob[input_str[i:j]]</span><br><span class="line">            <span class="keyword">elif</span> input_str[i:j] <span class="keyword">in</span> dic_words:</span><br><span class="line">                    path[i,i+<span class="number">1</span>] = <span class="number">0.00001</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 第二步： 利用维特比算法来找出最好的PATH， 这个PATH是P(sentence)最大或者 -log P(sentence)最小的PATH。</span></span><br><span class="line">    <span class="comment"># hint: 思考为什么不用相乘: p(w1)p(w2)...而是使用negative log sum:  -log(w1)-log(w2)-...  </span></span><br><span class="line">    minPath = np.zeros(n+<span class="number">1</span>)</span><br><span class="line">    score = [sys.maxsize]*(n+<span class="number">1</span>)</span><br><span class="line">    score[<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    seg = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,n+<span class="number">1</span>):</span><br><span class="line">        p = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,n):</span><br><span class="line">            <span class="keyword">if</span> path[j,i] != <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">if</span> score[i] &gt; -np.log(path[j,i])+score[j]:</span><br><span class="line">                    score[i] = -np.log(path[j,i])+score[j]</span><br><span class="line">                    minPath[i] = j</span><br><span class="line">                     </span><br><span class="line">    <span class="comment"># 第三步： 根据最好的PATH, 返回最好的切分</span></span><br><span class="line"></span><br><span class="line">    i = n</span><br><span class="line">    <span class="keyword">while</span> i &gt; <span class="number">0</span>:</span><br><span class="line">        seg.append(input_str[int(minPath[i]):i])</span><br><span class="line">        i = int(minPath[i])</span><br><span class="line">    seg = seg[::<span class="number">-1</span>]</span><br><span class="line">    <span class="keyword">return</span> seg</span><br></pre></td></tr></table></figure>
<h3 id="Spell-Correction"><a href="#Spell-Correction" class="headerlink" title="Spell Correction"></a>Spell Correction</h3><p>由于用户输入内容可能错误，我们需要有一个算法可以将错误的输入修改为正确的，这里有一个重要的概念是编辑距离。错误的输入可能是错别字，而有些则可能是输入的词不适合，这里可以使用语言模型来纠正。</p>
<p>编辑距离是两个字符串的距离有多长（要多少个操作才能转换为目标字符串），我们以therr这个错误拼写为例求得以下编辑距离：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>目标单词</th>
<th>there</th>
<th>their</th>
<th>thesis</th>
<th>theirs</th>
<th>the</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>编辑距离</strong></td>
<td>1</td>
<td>1</td>
<td>3</td>
<td>2</td>
<td>2</td>
</tr>
</tbody>
</table>
</div>
<p>而我们具体要返回哪个词需要根据上下文（结合语义）来判断，而计算编辑距离我们会使用DP算法。</p>
<p>最笨的选择方法就是遍历词典库的所有单词，然后选择其中编辑距离最小的（实际上就是ASM近似串匹配算法），编辑距离的DP算法如下 ：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normal_leven</span><span class="params">(str1, str2)</span>:</span></span><br><span class="line">    len_str1 = len(str1) + <span class="number">1</span></span><br><span class="line">    len_str2 = len(str2) + <span class="number">1</span></span><br><span class="line">    <span class="comment"># 创建矩阵</span></span><br><span class="line">    matrix = [<span class="number">0</span> <span class="keyword">for</span> n <span class="keyword">in</span> range(len_str1 * len_str2)]</span><br><span class="line">    <span class="comment"># 矩阵的第一行</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len_str1):</span><br><span class="line">        matrix[i] = i</span><br><span class="line">    <span class="comment"># 矩阵的第一列</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>, len(matrix), len_str1):</span><br><span class="line">        <span class="keyword">if</span> j % len_str1 == <span class="number">0</span>:</span><br><span class="line">            matrix[j] = j // len_str1</span><br><span class="line">    <span class="comment"># 根据状态转移方程逐步得到编辑距离</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len_str1):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>, len_str2):</span><br><span class="line">            <span class="keyword">if</span> str1[i - <span class="number">1</span>] == str2[j - <span class="number">1</span>]:</span><br><span class="line">                cost = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                cost = <span class="number">1</span></span><br><span class="line">            matrix[j * len_str1 + i] = min(matrix[(j - <span class="number">1</span>) * len_str1 + i] + <span class="number">1</span>,</span><br><span class="line">                                           matrix[j * len_str1 + (i - <span class="number">1</span>)] + <span class="number">1</span>,</span><br><span class="line">                                           matrix[(j - <span class="number">1</span>) * len_str1 + (i - <span class="number">1</span>)] + cost)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> matrix[<span class="number">-1</span>]  <span class="comment"># 返回矩阵的最后一个值，也就是编辑距离</span></span><br><span class="line"></span><br><span class="line">str1=<span class="string">'谁是谁的谁的谁'</span></span><br><span class="line">str2=<span class="string">'你爱我们谁的是'</span></span><br><span class="line"></span><br><span class="line">a=normal_leven(str1, str2)</span><br><span class="line">print(a)</span><br></pre></td></tr></table></figure>
<p>另外一种简洁写法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">edit</span><span class="params">(str1, str2)</span>:</span></span><br><span class="line">    matrix = [[i + j <span class="keyword">for</span> j <span class="keyword">in</span> range(len(str2) + <span class="number">1</span>)] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(str1) + <span class="number">1</span>)]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len(str1) + <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>, len(str2) + <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> str1[i - <span class="number">1</span>] == str2[j - <span class="number">1</span>]:</span><br><span class="line">                d = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                d = <span class="number">1</span></span><br><span class="line">            matrix[i][j] = min(matrix[i - <span class="number">1</span>][j] + <span class="number">1</span>, matrix[i][j - <span class="number">1</span>] + <span class="number">1</span>, matrix[i - <span class="number">1</span>][j - <span class="number">1</span>] + d)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> matrix[len(str1)][len(str2)]</span><br></pre></td></tr></table></figure>
<p>a=edit(‘谁是谁的谁的谁’,’你爱我们谁的是’)<br>print(a)</p>
<p>我们可以直接调包：import Levenshtein，使用包中的distance函数计算编辑距离，</p>
<p>实际上我们不必遍历词典选择编辑距离最小的，我们可以反过来，使用用户输入字符串生成编辑距离为1或2的字符串（Replace，Add，Delete），然后过滤后返回结果（不会依赖于词典库大小）。</p>
<p>我们得到了一个备选较小编辑距离字符串集合后，可以通过计算$\hat c=argmax_{c\in condidates}p(c|s)$计算得到最可能成为正确的字符串c。上式可以通过贝叶斯定理稍作转换：</p>
<script type="math/tex; mode=display">\hat c = argmax_{c\in candidates}p(c|s) = argmax_{c\in candidates}\frac{p(s|c)*p(c)}{p(s)}= argmax_{c\in candidates}p(s|c)*p(c)</script><p>其中$p(s|c)$应理解为对于apple这个正确的单词，有多少用户将apple写程appla（或者之类的），此数据我们可以从历史数据统计得到，而第二项$p(c)$是一个Unigram的概率，可以通过直接统计apple这个单词在所有文章中出现的次数计算得到（偏向于选择更常用的单词）。</p>
<h3 id="Stop-Words-Removal"><a href="#Stop-Words-Removal" class="headerlink" title="Stop Words Removal"></a>Stop Words Removal</h3><p>对于NLP的应用，我们通常先把停用词、出现频率低的词汇过滤掉，这其实类似于特征筛选的过程。在英文里，“the“，”an“，”their“这些都可以作为停用词来处理（不绝对），<strong>需要考虑把自己的应用场景</strong>。一般做法是拿别人做好的停用词库然后做一些删改，对于很大文本的项目我们可以将出现次数低于10或20之类的词去掉。</p>
<h3 id="Stemming"><a href="#Stemming" class="headerlink" title="Stemming"></a>Stemming</h3><p>词的标准化操作（主要针对英文）有两种常用技术：Stemming和Lemmazation。Stemming不能保证转换出来的单词是正常的英文单词，需要进一步转换，而Lemmazation则比Stemming更严格，可以保证转换出来的单词是一个出现在词库的单词。目前最广泛使用的Stemming操作时Porter Stemmer，其主要分为四个模块：</p>
<ul>
<li>制定规则，可以将后缀改为我们希望的后缀形式，如sses改为ss，ies改为i，ss改为ss，s直接去掉</li>
<li>修改时态：(v)ing的ing去掉，(v)ed的ed去掉，有些需要特殊处理的，比如sing</li>
<li>for long stems：ational改为ate，izer改为ize，ator改为ate</li>
<li>for longers stems：去掉al，able，ate等</li>
</ul>
<p>此过程需要依赖语言学家的经验，由程序员实现。</p>
<h2 id="句子表示"><a href="#句子表示" class="headerlink" title="句子表示"></a>句子表示</h2><h3 id="发展"><a href="#发展" class="headerlink" title="发展"></a>发展</h3><ul>
<li>boolean：构建词典库通过one-hot表示，向量长度与词典库大小一样。</li>
<li>tf-idf：核心方法论为<strong>单词并不是出现的越多就越重要，并不是出现的越少就越不重要</strong>。计算公式为$tfidf(w)=tf(d,w)*idf(w)$，其中$tf(d,w)$为文档$d$中$w$的词频，$idf(w)=\text{log}\frac{N}{N(w)}$，$N$为语料库中的文档总数，$N(w)$为词语$w$ 出现在多少个文档。 也就是一个单词如果每个文档都出现了，tfidf值会很低，相反一个单词只出现少数几个文档中，在这里个文档中这些个单词的重要性一定是比较高的。<ul>
<li>但无论是Boolean方法还是tf-idf均无法通过欧氏距离体现单词的相似性，计算余弦相似度很多都是0，也无法体现单词相似性</li>
<li>上面两个方法的稀疏性（Sparsity）很高</li>
</ul>
</li>
<li>Word2Vec：分布式表示法，能体现单词语义，稀疏度低</li>
</ul>
<h3 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h3><p>训练时输入为一个很长的字符串，当我们有一篇文章时可以直接将其拼接起来得到一个字符串进行训练，一般需要10亿或100亿个单词的语料库，数据很少时训练出来的结果不准确。训练词向量的主要方法有Skip-Gram，Glove，CBOW，RNN，LSTM，MF，Gaussian Embedding等，训练时最重要的参数为希望训练得到词向量的维度。</p>
<p>实际上我们不需要自己训练词向量，可以直接调用。但有些垂直领域需要自己训练词向量，比如金融领域和医疗领域等等，需要根据特定的语料库进行训练。</p>
<p>词向量某种程度上代表了单词的意思，那么当我们训练得到了一个词向量，对于一个句子我们该如何得到他的意思呢？这里主要有两种方法：</p>
<ul>
<li>平均法</li>
<li>LSTM/RNN</li>
</ul>
<h2 id="加速方式（倒排表）"><a href="#加速方式（倒排表）" class="headerlink" title="加速方式（倒排表）"></a>加速方式（倒排表）</h2><p>用户输入了一个问题，我们首先要匹配到知识库中的问题集，计算其相似度，返回其中最匹配的问题，其时间复杂度为$O(n)$，计算量很大。我们先讨论解决这个问题的思路——”层次过滤思想“</p>
<p>我们不需要计算所有问题集与用户输入的问题的余弦相似度，可以通过简单的方法层层过滤，最终得到较低数量级的备选问题得到较少的新备选问题集。我们需要保证：复杂度（过滤器1）&lt;复杂度（过滤器2）&lt;…….&lt;复杂度（过滤器N）。过滤的方式我们通常会使用倒排表来做。</p>
<p>比如我们文档中有如下关键词：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>文档</th>
<th>Doc1</th>
<th>Doc2</th>
<th>Doc3</th>
<th>Doc4</th>
</tr>
</thead>
<tbody>
<tr>
<td>关键词</td>
<td>我们，今天，运动</td>
<td>我们，昨天，运动</td>
<td>你们，上，课</td>
<td>你们上什么课</td>
</tr>
</tbody>
</table>
</div>
<p>我们可以构建以下词典：[我们，今天，运动，昨天，上，课，什么]，然后给每个词标注所在的文档：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>单词</th>
<th>文档</th>
</tr>
</thead>
<tbody>
<tr>
<td>我们</td>
<td>Doc1，Doc2</td>
</tr>
<tr>
<td>今天</td>
<td>Doc1</td>
</tr>
<tr>
<td>运动</td>
<td>Doc1，Doc2</td>
</tr>
<tr>
<td>昨天</td>
<td>Doc2</td>
</tr>
<tr>
<td>上</td>
<td>Doc3，Doc4</td>
</tr>
<tr>
<td>课</td>
<td>Doc3，Doc4</td>
</tr>
<tr>
<td>什么</td>
<td>Doc4</td>
</tr>
</tbody>
</table>
</div>
<p>当我们输入我们”运动“，就可以直接返回Doc1与Doc2，我们输入“我们上课”时，由于两个单词没有交集，我们就可以采用并集操作得出结果。我们的过滤器就可以由倒排表的一系列规则组合而成，比如最低层的倒排表过滤结果可以是包含问句中所有单词中任意一个的返回结果，而层数越高则需要的规则也就越苛刻，比如需要包含更多的单词。</p>
<h1 id="语言模型"><a href="#语言模型" class="headerlink" title="语言模型"></a>语言模型</h1><h2 id="Noisy-Channel-Model"><a href="#Noisy-Channel-Model" class="headerlink" title="Noisy Channel Model"></a>Noisy Channel Model</h2><script type="math/tex; mode=display">\text{p(text|source)}\text{p(source|text)~p(text)}</script><p>上面这个公式只需要简单地应用贝叶斯公式就可以得到，这个公式看起来简单，应用场景却很多，语音识别、机器翻译、拼写纠错、OCR、密码破解等领域都用到了这个公式。其共同点都是要将一段信号转换为一个文本。</p>
<p><strong>机器翻译</strong>：$\text{P(中文|英文)}\text{~}\text{P(英文|中文)}*\text{P(中文)}$，其中$\text{P(英文|中文)}$为Translation模型，$P(\text{中文})$为语言模型</p>
<p><strong>拼写纠错</strong>：$\text{P(正确的写法|错误的写法)}\text{~}\text{P(错误的写法|正确的写法)}*\text{P(正确的写法)}$</p>
<p><strong>语音识别</strong>：输入为波形，希望将波形转为文本。$\text{P(文本|语音信息)}\text{~}\text{P(语音信息|文本)}*\text{P(文本)}$</p>
<p><strong>密码破解</strong>：输入encrypted string，转为可读的字符串。$\text{P(明文|暗文)}\text{~}\text{P(暗文|明文)}*\text{P(明文)}$</p>
<p>语言模型的作用就是保证转化后的信号是符合常理的，将<strong>判断一句话从语法上是否通顺</strong>（是否是人话）。</p>
<h2 id="Markov-Assumption"><a href="#Markov-Assumption" class="headerlink" title="Markov Assumption"></a>Markov Assumption</h2><p>我们在计算一个语言模型的时候，首先考虑到的就是使用整个句子除了最后一个单词的所有单词来预测这个句子发生的概率，举个例子我们要预测今天是春节，我们都休息这句话的概率，那么我们会计算$P(休息|今天，是，春节，我们，都)$，我们可以想到在一个语料库中出现这样句子的概率肯定是极低的，因此我们会使用到Markov假设， 将上面这个条件概率简化为$P(休息|都)$这里使用的是1st order markov assumption，我们当然也可以使用2rd order……，根据自己的需要调整即可，但需要注意到的是随着加入单词的长度越多概率会越低。再举个例子：</p>
<p>比较今天是周日与今天周日是这两个句子的概率：</p>
<script type="math/tex; mode=display">P_{LM}(今天是周日)=P(今天)P(是|今天)P(周日|是)</script><script type="math/tex; mode=display">P_{LM}(今天周日是)=P(今天)P(周日|今天)P(是|周日)</script><p>我们使用不同的order，就可以得到N-gram的语言模型，其中Unigram就是不考虑前后文信息，无法分析单词依赖性，我们最常用的还是Bigram的语言模型。</p>
<h2 id="平滑项"><a href="#平滑项" class="headerlink" title="平滑项"></a>平滑项</h2><p>往往我们的概率值某一项是0，此时会导致整个句子的概率为0，为了避免这种情况发生，我们需要在每次计算概率的时候加一个平滑项，一般来说，语言模型的平滑处理可分为以下三类：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">Discounting（折扣）：通过给概率不为0的项打折扣，来提高概率为0的项的概率；</span><br><span class="line">Interpolation（插值）：在使用N-gram模型计算某一项的概率时，同时结合低阶的模型所计算出的概率；</span><br><span class="line">Back‐off：approximate counts of unobserved N‐gram based on the proportion of back‐off events (e.g., N‐1 gram)。</span><br></pre></td></tr></table></figure>
<h4 id="Discounting"><a href="#Discounting" class="headerlink" title="Discounting"></a>Discounting</h4><p><em>Discounting 包括 Add‐One Smoothing、Add‐K Smoothing、Good-Turing Smoothing等。</em></p>
<h5 id="Add‐One-Smoothing"><a href="#Add‐One-Smoothing" class="headerlink" title="Add‐One Smoothing"></a>Add‐One Smoothing</h5><p>假设N为语料中的单词个数，V为词典中单词的个数，那么对于Unigram和Bigram模型，平滑处理后计算每一项概率的公式为：</p>
<ul>
<li>Unigram case：$P_{L}(w_i) = \frac{count(w_i)+1}{N+V}$</li>
<li>Bigram case：$P_L(w_i|w_{i-1})=\frac{count(w_iw_{i-1})+1}{count(w_{i-1})+V}$</li>
</ul>
<p>举例来说，假设使用Bigram模型，$V=20，count(我们)=3，count(我们,是)=0$。若不使用平滑处理，则$P(是|我们)=0$；若使用上述处理，则$P(是|我们)=(0+1)/(3+20)=1/23$。</p>
<h5 id="Add‐K-Smoothing-Laplace-Smoothing"><a href="#Add‐K-Smoothing-Laplace-Smoothing" class="headerlink" title="Add‐K Smoothing(Laplace Smoothing)"></a>Add‐K Smoothing(Laplace Smoothing)</h5><p>对于这种方式，有$P_L(w_i|w_{i-1})=\frac{count(w_iw_{i-1})+K}{count(w_{i-1})+KV}$。可以看出，Add‐One Smoothing就是$K=1$的情况。<br>在使用Add‐K Smoothing的时候，可以使用优化的方法来寻找最佳的$K$。具体来说，先计算文本的perplexity，由于perplexity是关于$K$的函数，因此通过优化得到最小的perplexity时也同时得到了最佳的$K$。</p>
<h5 id="Good-Turing"><a href="#Good-Turing" class="headerlink" title="Good-Turing"></a>Good-Turing</h5><p>Good-Turing技术是在1953年由古德（I.J.Good）引用图灵（Turing）的方法而提出来的，其基本思想是<strong>用观察计数较高的N元语法数重新估计概率量的大小，并把它指派给那些具有零计数或者较低计数的N元语法</strong>，具体使用公式如下：</p>
<script type="math/tex; mode=display">c^∗=(c+1)\frac{N_{c+1}}{N_c}</script><p>其中，$c$代表某个单词出现的频数，$N_c$代表出现$c$次的单词的个数，而$c^∗$是频数为$c$的单词经过Good-Turing处理后的新的频数。例如，在某个语料库中，单词“love”出现了20次，而出现20次的单词共有100个，经过处理后，这100个出现过20次单词的频数可能变成18.2。</p>
<h4 id="Interpolation："><a href="#Interpolation：" class="headerlink" title="Interpolation："></a>Interpolation：</h4><p>Interpolation 包括 Linear Interpolation等。这种方式的思路为：在使用N-gram模型计算某一项的概率时，同时结合低阶的模型所计算出的概率。 以Trigram模型来说，使用interpolation方式后，计算每一项的概率公式为：</p>
<script type="math/tex; mode=display">\hat P(w_i|w_{i-1},w_{i-2})=\lambda_1P_{ML}(w_i|w_{i-1},w_{i-2})+\lambda_2P_{ML}(w_i|w_{i-1})+\lambda_3P_{ML}(w_i)</script><p>其中$\lambda_1+\lambda_2+\lambda_3=1$，其核心思想是：<strong>现在没有出现不代表未来不会出现</strong>。</p>
<h2 id="评估语言模型"><a href="#评估语言模型" class="headerlink" title="评估语言模型"></a>评估语言模型</h2><p>评估语言模型的核心思路是做填空题，我们给定第一个单词让语言模型预测下一个单词，如此往复可以评估出语言模型的效果如何，其中的评估方法为Perplexity：Perplexity$=2^{-x},x:\text{average log likehood}$，我们训练语言模型的时候自然会希望$x$越小越好，于是Perplexity越小越好，因此我们训练出来的Perplexity应该是不断下降的，最后达到一个均衡值。Perplexity之于我们目前的训练目标就如同召回率精确率之于推荐系统，后面根据不同的任务还有不同的评估方法，但Perplexity是其中很重要的一个评估方法。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>N-gram Order</th>
<th>Unigram</th>
<th>Bigram</th>
<th>Trigram</th>
</tr>
</thead>
<tbody>
<tr>
<td>Perplexity</td>
<td>962</td>
<td>170</td>
<td>109</td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title>NLP项目Pipeline</title>
    <url>/posts/aefe1ee4.html</url>
    <content><![CDATA[<h1 id="Traditional-NLP-Pipeline"><a href="#Traditional-NLP-Pipeline" class="headerlink" title="Traditional NLP Pipeline"></a>Traditional NLP Pipeline</h1><h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><ul>
<li>繁杂的数据预处理：分词形式、是否做字符级别的切分词等等</li>
<li>基于word embedding：太大，稀疏，线上部署需要保证内存等</li>
<li>模型能力不够，拟合能力有限，RNN、CNN等很难学习更多东西</li>
<li>训练数据：需要数据集大，人工标注成本大</li>
</ul>
<p>下面我们看看训练流程。</p>
<h2 id="训练流程"><a href="#训练流程" class="headerlink" title="训练流程"></a>训练流程</h2><h3 id="基于Pytorch"><a href="#基于Pytorch" class="headerlink" title="基于Pytorch"></a>基于Pytorch</h3><h4 id="下载并处理IMDB公开数据集"><a href="#下载并处理IMDB公开数据集" class="headerlink" title="下载并处理IMDB公开数据集"></a>下载并处理IMDB公开数据集</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchtext <span class="keyword">import</span> data</span><br><span class="line"></span><br><span class="line">SEED = <span class="number">1234</span></span><br><span class="line"></span><br><span class="line">torch.manual_seed(SEED) <span class="comment">#为CPU设置随机种子</span></span><br><span class="line">torch.cuda.manual_seed(SEED)<span class="comment">#为GPU设置随机种子</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#在程序刚开始加这条语句可以提升一点训练速度，没什么额外开销。</span></span><br><span class="line">torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#用来定义字段的处理方法（文本字段，标签字段）</span></span><br><span class="line">TEXT = data.Field(tokenize=<span class="string">'spacy'</span>)<span class="comment">#torchtext.data.Field : </span></span><br><span class="line">LABEL = data.LabelField(dtype=torch.float)</span><br></pre></td></tr></table></figure>
<h4 id="切分训练集、测试集和验证集"><a href="#切分训练集、测试集和验证集" class="headerlink" title="切分训练集、测试集和验证集"></a>切分训练集、测试集和验证集</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torchtext <span class="keyword">import</span> datasets</span><br><span class="line">train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)</span><br><span class="line">print(<span class="string">f'Number of training examples: <span class="subst">&#123;len(train_data)&#125;</span>'</span>)</span><br><span class="line">print(<span class="string">f'Number of testing examples: <span class="subst">&#123;len(test_data)&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line">train_data, valid_data = train_data.split(random_state=random.seed(SEED))</span><br></pre></td></tr></table></figure>
<h4 id="读入glove词向量"><a href="#读入glove词向量" class="headerlink" title="读入glove词向量"></a>读入glove词向量</h4><p>目的是把训练集的Token转化为词向量传入模型中，若使用TEXT的api会自动下载词向量</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">TEXT.build_vocab(train_data, max_size=<span class="number">25000</span>, vectors=<span class="string">"glove.6B.100d"</span>,</span><br><span class="line">                 unk_init=torch.Tensor.normal_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建训练集字典</span></span><br><span class="line">LABEL.build_vocab(train_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Dataloader制作</span></span><br><span class="line"></span><br><span class="line">BATCH_SIZE = <span class="number">64</span></span><br><span class="line"><span class="comment"># 判断使用的是CPU还是GPU</span></span><br><span class="line">device = torch.device(<span class="string">'cuda'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 迭代器的形式会加速数据传输速度（异步读取）</span></span><br><span class="line">train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(</span><br><span class="line">    (train_data, valid_data, test_data),</span><br><span class="line">    batch_size=BATCH_SIZE,</span><br><span class="line">    device=device)</span><br></pre></td></tr></table></figure>
<h4 id="建立模型"><a href="#建立模型" class="headerlink" title="建立模型"></a>建立模型</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WordAVGModel</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, vocab_size, embedding_dim, output_dim, pad_idx)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)</span><br><span class="line">        self.fc = nn.Linear(embedding_dim, output_dim)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, text)</span>:</span></span><br><span class="line">        embedded = self.embedding(text) <span class="comment"># [sent_len, batch _size, emb_size]</span></span><br><span class="line">        embedded = embedded.permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>) <span class="comment"># [batch size, sent len, emb dim]</span></span><br><span class="line">        pooled = F.avg_pool2d(embedded, (embedded.shape[<span class="number">1</span>], <span class="number">1</span>)).squeeze(<span class="number">1</span>) <span class="comment"># [batch size, embedding_dim]</span></span><br><span class="line">        <span class="keyword">return</span> self.fc(pooled)</span><br><span class="line"></span><br><span class="line">INPUT_DIM = len(TEXT.vocab) <span class="comment">#词个数</span></span><br><span class="line">EMBEDDING_DIM = <span class="number">100</span> <span class="comment">#词嵌入维度</span></span><br><span class="line">OUTPUT_DIM = <span class="number">1</span> <span class="comment">#输出维度</span></span><br><span class="line">PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token] <span class="comment">#pad索引</span></span><br><span class="line"></span><br><span class="line">model = WordAVGModel(INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM, PAD_IDX)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count_parameters</span><span class="params">(model)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> sum(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters() <span class="keyword">if</span> p.requires_grad)</span><br><span class="line"></span><br><span class="line">print(<span class="string">f'The model has <span class="subst">&#123;count_parameters(model):,&#125;</span> trainable parameters'</span>)</span><br><span class="line"></span><br><span class="line">拿到新的词向量，换掉原有的</span><br><span class="line">pretrained_embeddings = TEXT.vocab.vectors</span><br><span class="line">model.embedding.weight.data.copy_(pretrained_embeddings)</span><br><span class="line"></span><br><span class="line">UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]</span><br><span class="line"></span><br><span class="line">model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)</span><br><span class="line">model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line">optimizer = optim.Adam(model.parameters())</span><br><span class="line">criterion = nn.BCEWithLogitsLoss()</span><br><span class="line">model = model.to(device)</span><br><span class="line">criterion = criterion.to(device)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binary_accuracy</span><span class="params">(preds, y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#round predictions to the closest integer</span></span><br><span class="line">    rounded_preds = torch.round(torch.sigmoid(preds))</span><br><span class="line">    correct = (rounded_preds == y).float() <span class="comment">#convert into float for division </span></span><br><span class="line">    acc = correct.sum()/len(correct)</span><br><span class="line">    <span class="keyword">return</span> acc</span><br></pre></td></tr></table></figure>
<h4 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(model, iterator, optimizer, criterion)</span>:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    epoch_loss = <span class="number">0</span></span><br><span class="line">    epoch_acc = <span class="number">0</span></span><br><span class="line">    total_len = <span class="number">0</span></span><br><span class="line">    model.train() <span class="comment">#model.train()代表了训练模式</span></span><br><span class="line">    <span class="comment">#这步一定要加，是为了区分model训练和测试的模式的。</span></span><br><span class="line">    <span class="comment">#有时候训练时会用到dropout、归一化等方法，但是测试的时候不能用dropout等方法。</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> iterator: <span class="comment">#iterator为train_iterator</span></span><br><span class="line">        optimizer.zero_grad() <span class="comment">#加这步防止梯度叠加</span></span><br><span class="line"></span><br><span class="line">        predictions = model(batch.text).squeeze(<span class="number">1</span>)</span><br><span class="line">        <span class="comment">#batch.text 就是上面forward函数的参数text</span></span><br><span class="line">        <span class="comment">#压缩维度，不然跟batch.label维度对不上</span></span><br><span class="line"></span><br><span class="line">        loss = criterion(predictions, batch.label)</span><br><span class="line">        acc = binary_accuracy(predictions, batch.label)</span><br><span class="line"></span><br><span class="line">        loss.backward() <span class="comment">#反向传播</span></span><br><span class="line">        optimizer.step() <span class="comment">#梯度下降</span></span><br><span class="line"></span><br><span class="line">        epoch_loss += loss.item() * len(batch.label)</span><br><span class="line">        <span class="comment">#loss.item()已经本身除以了len(batch.label)</span></span><br><span class="line">        <span class="comment">#所以得再乘一次，得到一个batch的损失，累加得到所有样本损失。</span></span><br><span class="line"></span><br><span class="line">        epoch_acc += acc.item() * len(batch.label)</span><br><span class="line">        <span class="comment">#（acc.item()：一个batch的正确率） *batch数 = 正确数</span></span><br><span class="line">        <span class="comment">#train_iterator所有batch的正确数累加。</span></span><br><span class="line"></span><br><span class="line">        total_len += len(batch.label)</span><br><span class="line">        <span class="comment">#计算train_iterator所有样本的数量，不出意外应该是17500</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> epoch_loss / total_len, epoch_acc / total_len</span><br><span class="line">    <span class="comment">#epoch_loss / total_len ：train_iterator所有batch的损失</span></span><br><span class="line">    <span class="comment">#epoch_acc / total_len ：train_iterator所有batch的正确率</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(model, iterator, criterion)</span>:</span></span><br><span class="line"></span><br><span class="line">    epoch_loss = <span class="number">0</span></span><br><span class="line">    epoch_acc = <span class="number">0</span></span><br><span class="line">    model.eval()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> iterator:</span><br><span class="line">            predictions = model(batch.text).squeeze(<span class="number">1</span>)</span><br><span class="line">            loss = criterion(predictions, batch.label)</span><br><span class="line">            acc = binary_accuracy(predictions, batch.label)</span><br><span class="line">            epoch_loss += loss.item()</span><br><span class="line">            epoch_acc += acc.item()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> epoch_loss / len(iterator), epoch_acc / len(iterator)</span><br><span class="line"></span><br><span class="line"><span class="comment">#import time</span></span><br><span class="line">N_EPOCHS = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">best_valid_loss = float(<span class="string">'inf'</span>) <span class="comment">#无穷大</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(N_EPOCHS):</span><br><span class="line"></span><br><span class="line">    <span class="comment">#start_time = time.time()</span></span><br><span class="line"></span><br><span class="line">    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)</span><br><span class="line">    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#end_time = time.time()</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#epoch_mins, epoch_secs = epoch_time(start_time, end_time)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> valid_loss &lt; best_valid_loss: <span class="comment">#只要模型效果变好，就存模型</span></span><br><span class="line">        best_valid_loss = valid_loss</span><br><span class="line">        torch.save(model.state_dict(), <span class="string">'wordavg-model.pt'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#print(f'Epoch: &#123;epoch+1:02&#125; | Epoch Time: &#123;epoch_mins&#125;m &#123;epoch_secs&#125;s')</span></span><br><span class="line">    print(<span class="string">f'\tTrain Loss: <span class="subst">&#123;train_loss:<span class="number">.3</span>f&#125;</span> | Train Acc: <span class="subst">&#123;train_acc*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>%'</span>)</span><br><span class="line">    print(<span class="string">f'\t Val. Loss: <span class="subst">&#123;valid_loss:<span class="number">.3</span>f&#125;</span> |  Val. Acc: <span class="subst">&#123;valid_acc*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>%'</span>)</span><br></pre></td></tr></table></figure>
<h3 id="基于Tensorflow2-0"><a href="#基于Tensorflow2-0" class="headerlink" title="基于Tensorflow2.0"></a>基于Tensorflow2.0</h3><h4 id="下载IMDB公开数据集，并处理"><a href="#下载IMDB公开数据集，并处理" class="headerlink" title="下载IMDB公开数据集，并处理"></a>下载IMDB公开数据集，并处理</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">imdb_dir = <span class="string">"./aclImdb"</span></span><br><span class="line">train_dir = os.path.join(imdb_dir, <span class="string">"train"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">labels = []</span><br><span class="line">texts = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> label_type <span class="keyword">in</span> [<span class="string">"neg"</span>, <span class="string">"pos"</span>]:</span><br><span class="line">    dir_name = os.path.join(train_dir, label_type)</span><br><span class="line">    <span class="keyword">for</span> fname <span class="keyword">in</span> os.listdir(dir_name):</span><br><span class="line">        <span class="keyword">if</span> fname [<span class="number">-4</span>:] == <span class="string">".txt"</span>:</span><br><span class="line">            f = open(os.path.join(dir_name, fname), encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">            texts.append(f.read())</span><br><span class="line">            f.close()</span><br><span class="line">            <span class="keyword">if</span> label_type == <span class="string">"neg"</span>:</span><br><span class="line">                labels.append(<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                labels.append(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h4 id="制作训练集和验证集"><a href="#制作训练集和验证集" class="headerlink" title="制作训练集和验证集"></a>制作训练集和验证集</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.preprocessing.text <span class="keyword">import</span> Tokenizer</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing. sequence <span class="keyword">import</span> pad_sequences</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">maxlen = <span class="number">100</span> <span class="comment"># cuts off review after 100 words</span></span><br><span class="line">training_samples = <span class="number">200</span> <span class="comment"># Trains on 200 samples</span></span><br><span class="line">validation_samples = <span class="number">10000</span> <span class="comment"># Validates o 10000 samples</span></span><br><span class="line">max_words = <span class="number">10000</span> <span class="comment"># Considers only the top 10000 words in the dataset</span></span><br><span class="line"></span><br><span class="line">tokenizer = Tokenizer(num_words=max_words)</span><br><span class="line">tokenizer.fit_on_texts(texts)</span><br><span class="line">sequences = tokenizer.texts_to_sequences(texts)</span><br><span class="line">word_index = tokenizer.word_index                   <span class="comment"># Length: 88582</span></span><br><span class="line">print(<span class="string">"Found %s unique tokens."</span> % len(word_index))</span><br><span class="line"></span><br><span class="line">data = pad_sequences(sequences, maxlen=maxlen)</span><br><span class="line"></span><br><span class="line">labels = np.asarray(labels)</span><br><span class="line">print(<span class="string">"Shape of data tensor:"</span>, data.shape)</span><br><span class="line">print(<span class="string">"Shape of label tensor:"</span>, labels.shape)</span><br><span class="line"></span><br><span class="line">indices = np.arange(data.shape[<span class="number">0</span>]) <span class="comment"># Splits data into training and validation set, but shuffles is, since samples are ordered:</span></span><br><span class="line"><span class="comment"># all negatives first, then all positive</span></span><br><span class="line">np.random.shuffle(indices)</span><br><span class="line">data = data[indices]</span><br><span class="line">labels = labels[indices]</span><br><span class="line"></span><br><span class="line">x_train = data[:training_samples] <span class="comment"># (200, 100)</span></span><br><span class="line">y_train = labels[:training_samples] <span class="comment"># shape (200,)</span></span><br><span class="line">x_val = data[training_samples:training_samples+validation_samples] <span class="comment"># shape (10000, 100)</span></span><br><span class="line">y_val = labels[training_samples:training_samples+validation_samples] <span class="comment"># shape (10000,)</span></span><br></pre></td></tr></table></figure>
<h4 id="下载glove词向量，并读入"><a href="#下载glove词向量，并读入" class="headerlink" title="下载glove词向量，并读入"></a>下载glove词向量，并读入</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">glove_dir = <span class="string">"./"</span></span><br><span class="line"></span><br><span class="line">embeddings_index = &#123;&#125;</span><br><span class="line"></span><br><span class="line">f = open(os.path.join(glove_dir, <span class="string">"glove.6B.50d.txt"</span>), encoding=<span class="string">'utf-8'</span>) <span class="comment">#added , encoding='utf-8'</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">    values = line.split()</span><br><span class="line">    word = values[<span class="number">0</span>]</span><br><span class="line">    coefs = np.asarray(values[<span class="number">1</span>:], dtype=<span class="string">"float32"</span>)</span><br><span class="line">    embeddings_index[word] = coefs</span><br><span class="line">f.close()</span><br><span class="line"></span><br><span class="line">print(<span class="string">"found %s word vectors."</span> % len (embeddings_index))</span><br></pre></td></tr></table></figure>
<h4 id="读入词向量"><a href="#读入词向量" class="headerlink" title="读入词向量"></a>读入词向量</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">embedding_dim = <span class="number">50</span> <span class="comment"># GloVe contains 50-dimensional embedding vectors for 400.000 words</span></span><br><span class="line"></span><br><span class="line">embedding_matrix = np.zeros((max_words, embedding_dim)) <span class="comment"># embedding_matrix.shape (10000, 50)</span></span><br><span class="line"><span class="keyword">for</span> word, i <span class="keyword">in</span> word_index.items():</span><br><span class="line">    <span class="keyword">if</span> i &lt; max_words:</span><br><span class="line">        embedding_vector = embeddings_index.get(word) <span class="comment"># embedding_vector.shape (100,)</span></span><br><span class="line">        <span class="keyword">if</span> embedding_vector <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            embedding_matrix[i] = embedding_vector <span class="comment"># Words not found in the mebedding index will all be zeros</span></span><br></pre></td></tr></table></figure>
<h4 id="搭建模型"><a href="#搭建模型" class="headerlink" title="搭建模型"></a>搭建模型</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = keras.models.Sequential() </span><br><span class="line">model.add(keras.layers.Embedding(max_words, embedding_dim, input_length = maxlen))</span><br><span class="line">model.add(keras.layers.Bidirectional(keras.layers.LSTM(<span class="number">64</span>, return_sequences = <span class="literal">True</span>)))</span><br><span class="line">model.add(keras.layers.GlobalMaxPool1D())</span><br><span class="line">model.add(keras.layers.Dense(<span class="number">16</span>, activation = <span class="string">"relu"</span>))</span><br><span class="line">model.add(keras.layers.Dense(<span class="number">1</span>, activation = <span class="string">"sigmoid"</span>))</span><br><span class="line">model.compile(loss = <span class="string">'binary_crossentropy'</span>, optimizer = <span class="string">'adam'</span>, metrics = [<span class="string">'accuracy'</span>])</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<h4 id="加载预训词向量"><a href="#加载预训词向量" class="headerlink" title="加载预训词向量"></a>加载预训词向量</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.layers[<span class="number">0</span>].set_weights([embedding_matrix])</span><br><span class="line">model.layers[<span class="number">0</span>].trainable = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<h4 id="训练-1"><a href="#训练-1" class="headerlink" title="训练"></a>训练</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.compile(optimizer = <span class="string">"rmsprop"</span>, </span><br><span class="line">              loss = <span class="string">"binary_crossentropy"</span>, <span class="comment"># in a multiclass problem categorical_crossentropy would be used</span></span><br><span class="line">              metrics = [<span class="string">"acc"</span>]) </span><br><span class="line">history = model.fit(x_train, y_train,</span><br><span class="line">                   epochs = <span class="number">10</span>,</span><br><span class="line">                   batch_size = <span class="number">32</span>,</span><br><span class="line">                   validation_data = (x_val, y_val))</span><br><span class="line">model.save_weights(<span class="string">"pre_trained_glove_model.h5"</span>)</span><br></pre></td></tr></table></figure>
<h1 id="New-NLP-Pipeline"><a href="#New-NLP-Pipeline" class="headerlink" title="New NLP Pipeline"></a>New NLP Pipeline</h1><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><ul>
<li>先进的Tokenizer：WordPiece，将词拆成一个一个字，减少了vocab集的大小</li>
<li>模型结构：强大的特征提取器Transformer</li>
<li>预训练任务：解决了数据问题，不需要太多的数据清洗</li>
</ul>
<p>注：生成任务不适合使用Bert</p>
<h2 id="训练流程-1"><a href="#训练流程-1" class="headerlink" title="训练流程"></a>训练流程</h2><h3 id="基于Pytorch-1"><a href="#基于Pytorch-1" class="headerlink" title="基于Pytorch"></a>基于Pytorch</h3><h4 id="导入相关的包"><a href="#导入相关的包" class="headerlink" title="导入相关的包"></a>导入相关的包</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="comment"># 使用transformers包</span></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertTokenizer, BertModel</span><br><span class="line"><span class="keyword">from</span> torchtext <span class="keyword">import</span> data, datasets</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> time</span><br></pre></td></tr></table></figure>
<h4 id="种子和参数设定"><a href="#种子和参数设定" class="headerlink" title="种子和参数设定"></a>种子和参数设定</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 参数</span></span><br><span class="line">SEED = <span class="number">1234</span></span><br><span class="line">TRAIN = <span class="literal">False</span></span><br><span class="line">BATCH_SIZE = <span class="number">128</span></span><br><span class="line">N_EPOCHS = <span class="number">5</span></span><br><span class="line">HIDDEN_DIM = <span class="number">256</span></span><br><span class="line">OUTPUT_DIM = <span class="number">1</span></span><br><span class="line">N_LAYERS = <span class="number">2</span></span><br><span class="line">BIDIRECTIONAL = <span class="literal">True</span></span><br><span class="line">DROPOUT = <span class="number">0.25</span></span><br><span class="line"></span><br><span class="line">TEXT = <span class="string">"I like you!"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 固定模型用种子，便于重复试验</span></span><br><span class="line">random.seed(SEED)</span><br><span class="line">np.random.seed(SEED)</span><br><span class="line">torch.manual_seed(SEED)</span><br><span class="line">torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<h4 id="处理Token"><a href="#处理Token" class="headerlink" title="处理Token"></a>处理Token</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 应用transformers中Tokenizer</span></span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(<span class="string">'bert-base-uncased'</span>)</span><br><span class="line">init_token_id = tokenizer.cls_token_id</span><br><span class="line">eos_token_id  = tokenizer.sep_token_id</span><br><span class="line">pad_token_id  = tokenizer.pad_token_id</span><br><span class="line">unk_token_id  = tokenizer.unk_token_id</span><br><span class="line"></span><br><span class="line">max_input_len = tokenizer.max_model_input_sizes[<span class="string">'bert-base-uncased'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将句子长度切割成510长，为了加上开头和最后一个token</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenize_and_crop</span><span class="params">(sentence)</span>:</span></span><br><span class="line">    tokens = tokenizer.tokenize(sentence)</span><br><span class="line">    tokens = tokens[:max_input_len - <span class="number">2</span>]</span><br><span class="line">    <span class="keyword">return</span> tokens</span><br></pre></td></tr></table></figure>
<h4 id="加载PyTorch提供的IMDB数据"><a href="#加载PyTorch提供的IMDB数据" class="headerlink" title="加载PyTorch提供的IMDB数据"></a>加载PyTorch提供的IMDB数据</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span><span class="params">()</span>:</span></span><br><span class="line">    text = data.Field(</span><br><span class="line">        batch_first=<span class="literal">True</span>,</span><br><span class="line">        use_vocab=<span class="literal">False</span>,</span><br><span class="line">        tokenize=tokenize_and_crop,</span><br><span class="line">        preprocessing=tokenizer.convert_tokens_to_ids,</span><br><span class="line">        init_token=init_token_id,</span><br><span class="line">        pad_token=pad_token_id,</span><br><span class="line">        unk_token=unk_token_id</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    label = data.LabelField(dtype=torch.float)</span><br><span class="line"></span><br><span class="line">    train_data, test_data  = datasets.IMDB.splits(text, label)</span><br><span class="line">    train_data, valid_data = train_data.split(random_state=random.seed(SEED))</span><br><span class="line"></span><br><span class="line">    print(<span class="string">f"training examples count: <span class="subst">&#123;len(train_data)&#125;</span>"</span>)</span><br><span class="line">    print(<span class="string">f"test examples count: <span class="subst">&#123;len(test_data)&#125;</span>"</span>)</span><br><span class="line">    print(<span class="string">f"validation examples count: <span class="subst">&#123;len(valid_data)&#125;</span>"</span>)</span><br><span class="line"></span><br><span class="line">    label.build_vocab(train_data)</span><br><span class="line"></span><br><span class="line">    train_iter, valid_iter, test_iter = data.BucketIterator.splits(</span><br><span class="line">        (train_data, valid_data, test_data),</span><br><span class="line">        batch_size=BATCH_SIZE,</span><br><span class="line">        device=device</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train_iter, valid_iter, test_iter</span><br></pre></td></tr></table></figure>
<h4 id="引入Bert预处理模型"><a href="#引入Bert预处理模型" class="headerlink" title="引入Bert预处理模型"></a>引入Bert预处理模型</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 看是否有GPU</span></span><br><span class="line">device = <span class="string">'cuda'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过transformers包，建立BERT模型</span></span><br><span class="line">bert_model = BertModel.from_pretrained(<span class="string">'bert-base-uncased'</span>)</span><br></pre></td></tr></table></figure>
<h4 id="搭建模型-1"><a href="#搭建模型-1" class="headerlink" title="搭建模型"></a>搭建模型</h4><p>在这里开始做finetune处理了</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 此处用BERT做为基础模型完成情感分析任务</span></span><br><span class="line"><span class="comment"># 在BERT之上加两层GRU</span></span><br><span class="line"><span class="comment"># 最后接一层线性层用于完成分类任务</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SentimentModel</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">        self,</span></span></span><br><span class="line"><span class="function"><span class="params">        bert,</span></span></span><br><span class="line"><span class="function"><span class="params">        hidden_dim,</span></span></span><br><span class="line"><span class="function"><span class="params">        output_dim,</span></span></span><br><span class="line"><span class="function"><span class="params">        n_layers,</span></span></span><br><span class="line"><span class="function"><span class="params">        bidirectional,</span></span></span><br><span class="line"><span class="function"><span class="params">        dropout</span></span></span><br><span class="line"><span class="function"><span class="params">    )</span>:</span></span><br><span class="line">      </span><br><span class="line">        super(SentimentModel, self).__init__()</span><br><span class="line">    </span><br><span class="line">        self.bert = bert</span><br><span class="line">        embedding_dim = bert.config.to_dict()[<span class="string">'hidden_size'</span>]</span><br><span class="line">        self.rnn = nn.GRU(</span><br><span class="line">            embedding_dim,</span><br><span class="line">            hidden_dim,</span><br><span class="line">            num_layers=n_layers,</span><br><span class="line">            bidirectional=bidirectional,</span><br><span class="line">            batch_first=<span class="literal">True</span>,</span><br><span class="line">            dropout=<span class="number">0</span> <span class="keyword">if</span> n_layers &lt; <span class="number">2</span> <span class="keyword">else</span> dropout</span><br><span class="line">            )</span><br><span class="line">        self.out = nn.Linear(hidden_dim * <span class="number">2</span> <span class="keyword">if</span> bidirectional <span class="keyword">else</span> hidden_dim, output_dim)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line">      </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, text)</span>:</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            embedded = self.bert(text)[<span class="number">0</span>]</span><br><span class="line">            </span><br><span class="line">        _, hidden = self.rnn(embedded)</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">if</span> self.rnn.bidirectional:</span><br><span class="line">            hidden = self.dropout(torch.cat((hidden[<span class="number">-2</span>,:,:], hidden[<span class="number">-1</span>,:,:]), dim = <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            hidden = self.dropout(hidden[<span class="number">-1</span>,:,:])</span><br><span class="line">    </span><br><span class="line">        output = self.out(hidden)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">model = SentimentModel(</span><br><span class="line">  bert_model,</span><br><span class="line">  HIDDEN_DIM,</span><br><span class="line">  OUTPUT_DIM,!pip list</span><br><span class="line">  N_LAYERS,</span><br><span class="line">  BIDIRECTIONAL,</span><br><span class="line">  DROPOUT</span><br><span class="line">)</span><br><span class="line">print(model)</span><br></pre></td></tr></table></figure>
<h4 id="一个epoch需要多长时间"><a href="#一个epoch需要多长时间" class="headerlink" title="一个epoch需要多长时间"></a>一个epoch需要多长时间</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">epoch_time</span><span class="params">(start_time, end_time)</span>:</span></span><br><span class="line">    elapsed_time = end_time - start_time</span><br><span class="line">    elapsed_mins = int(elapsed_time / <span class="number">60</span>)</span><br><span class="line">    elapsed_secs = int(elapsed_time - (elapsed_mins * <span class="number">60</span>))</span><br><span class="line">    <span class="keyword">return</span> elapsed_mins, elapsed_secs</span><br></pre></td></tr></table></figure>
<h4 id="二分类问题的accuracy"><a href="#二分类问题的accuracy" class="headerlink" title="二分类问题的accuracy"></a>二分类问题的accuracy</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binary_accuracy</span><span class="params">(preds, y)</span>:</span></span><br><span class="line">    rounded_preds = torch.round(torch.sigmoid(preds))</span><br><span class="line">    correct = (rounded_preds == y).float()</span><br><span class="line">    acc = correct.sum() / len(correct)</span><br><span class="line">    <span class="keyword">return</span> acc</span><br></pre></td></tr></table></figure>
<h4 id="一个训练步"><a href="#一个训练步" class="headerlink" title="一个训练步"></a>一个训练步</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(model, iterator, optimizer, criterion)</span>:</span></span><br><span class="line">    epoch_loss = <span class="number">0</span></span><br><span class="line">    epoch_acc = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    model.train()</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> iterator:</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        predictions = model(batch.text).squeeze(<span class="number">1</span>)</span><br><span class="line">        loss = criterion(predictions, batch.label)</span><br><span class="line">        acc = binary_accuracy(predictions, batch.label)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        epoch_loss += loss.item()</span><br><span class="line">        epoch_acc += acc.item()</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> epoch_loss / len(iterator), epoch_acc / len(iterator)</span><br></pre></td></tr></table></figure>
<h4 id="验证模型"><a href="#验证模型" class="headerlink" title="验证模型"></a>验证模型</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(model, iterator, criterion)</span>:</span></span><br><span class="line">    epoch_loss = <span class="number">0</span></span><br><span class="line">    epoch_acc = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    model.eval()</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> iterator:</span><br><span class="line">            predictions = model(batch.text).squeeze(<span class="number">1</span>)</span><br><span class="line">            loss = criterion(predictions, batch.label)</span><br><span class="line">            acc = binary_accuracy(predictions, batch.label)</span><br><span class="line">            epoch_loss += loss.item()</span><br><span class="line">            epoch_acc += acc.item()</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">return</span> epoch_loss / len(iterator), epoch_acc / len(iterator)</span><br></pre></td></tr></table></figure>
<h4 id="预测模型"><a href="#预测模型" class="headerlink" title="预测模型"></a>预测模型</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_sentiment</span><span class="params">(model, tokenizer, sentence)</span>:</span></span><br><span class="line">    model.eval()</span><br><span class="line">    tokens = tokenizer.tokenize(sentence)</span><br><span class="line">    tokens = tokens[:max_input_len - <span class="number">2</span>]</span><br><span class="line">    indexed = [init_token_id] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_id]</span><br><span class="line">    tensor = torch.LongTensor(indexed).to(device)</span><br><span class="line">    tensor = tensor.unsqueeze(<span class="number">0</span>)</span><br><span class="line">    prediction = torch.sigmoid(model(tensor))</span><br><span class="line">    <span class="keyword">return</span> prediction.item()</span><br><span class="line"></span><br><span class="line">train_iter, valid_iter, test_iter = load_data()</span><br><span class="line"></span><br><span class="line">optimizer = optim.Adam(model.parameters())</span><br><span class="line">criterion = nn.BCEWithLogitsLoss().to(device)</span><br><span class="line">model = model.to(device)</span><br><span class="line"></span><br><span class="line">best_val_loss = float(<span class="string">'inf'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(N_EPOCHS):</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    <span class="comment"># 训练一个epoch</span></span><br><span class="line">    train_loss, train_acc = train(model, train_iter, optimizer, criterion)</span><br><span class="line">    valid_loss, valid_acc = evaluate(model, valid_iter, criterion)</span><br><span class="line"></span><br><span class="line">    end_time = time.time()</span><br><span class="line"></span><br><span class="line">    epoch_mins, epoch_secs = epoch_time(start_time, end_time)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> valid_loss &lt; best_valid_loss:</span><br><span class="line">        best_valid_loss = valid_loss</span><br><span class="line">        torch.save(model.state_dict(), <span class="string">'model.pt'</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">f'Epoch: <span class="subst">&#123;epoch+<span class="number">1</span>:<span class="number">02</span>&#125;</span> | Epoch Time: <span class="subst">&#123;epoch_mins&#125;</span>m <span class="subst">&#123;epoch_secs&#125;</span>s'</span>)</span><br><span class="line">    print(<span class="string">f'\tTrain Loss: <span class="subst">&#123;train_loss:<span class="number">.3</span>f&#125;</span> | Train Acc: <span class="subst">&#123;train_acc*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>%'</span>)</span><br><span class="line">    print(<span class="string">f'\t Val. Loss: <span class="subst">&#123;valid_loss:<span class="number">.3</span>f&#125;</span> |  Val. Acc: <span class="subst">&#123;valid_acc*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>%'</span>)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="comment"># 开始训练</span></span><br><span class="line">    <span class="keyword">if</span> TRAIN:</span><br><span class="line">        <span class="comment"># 读取数据</span></span><br><span class="line">        train_iter, valid_iter, test_iter = load_data()</span><br><span class="line"></span><br><span class="line">        optimizer = optim.Adam(model.parameters())</span><br><span class="line">        criterion = nn.BCEWithLogitsLoss().to(device)</span><br><span class="line">        model = model.to(device)</span><br><span class="line"></span><br><span class="line">        best_val_loss = float(<span class="string">'inf'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> range(N_EPOCHS):</span><br><span class="line">            start_time = time.time()</span><br><span class="line">            <span class="comment"># 训练一个epoch</span></span><br><span class="line">            train_loss, train_acc = train(model, train_iter, optimizer, criterion)</span><br><span class="line">            valid_loss, valid_acc = evaluate(model, valid_iter, criterion)</span><br><span class="line"></span><br><span class="line">            end_time = time.time()</span><br><span class="line"></span><br><span class="line">            epoch_mins, epoch_secs = epoch_time(start_time, end_time)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> valid_loss &lt; best_valid_loss:</span><br><span class="line">                best_valid_loss = valid_loss</span><br><span class="line">                torch.save(model.state_dict(), <span class="string">'model.pt'</span>)</span><br><span class="line"></span><br><span class="line">            print(<span class="string">f'Epoch: <span class="subst">&#123;epoch+<span class="number">1</span>:<span class="number">02</span>&#125;</span> | Epoch Time: <span class="subst">&#123;epoch_mins&#125;</span>m <span class="subst">&#123;epoch_secs&#125;</span>s'</span>)</span><br><span class="line">            print(<span class="string">f'\tTrain Loss: <span class="subst">&#123;train_loss:<span class="number">.3</span>f&#125;</span> | Train Acc: <span class="subst">&#123;train_acc*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>%'</span>)</span><br><span class="line">            print(<span class="string">f'\t Val. Loss: <span class="subst">&#123;valid_loss:<span class="number">.3</span>f&#125;</span> |  Val. Acc: <span class="subst">&#123;valid_acc*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>%'</span>)</span><br><span class="line">        <span class="comment"># 测试</span></span><br><span class="line">        model.load_state_dict(torch.load(<span class="string">'model.pt'</span>))</span><br><span class="line">        test_loss, test_acc = evaluate(model, test_iter, criterion)</span><br><span class="line">        print(<span class="string">f'Test Loss: <span class="subst">&#123;test_loss:<span class="number">.3</span>f&#125;</span> | Test Acc: <span class="subst">&#123;test_acc*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>%'</span>)</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 推理结果</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        model.load_state_dict(torch.load(<span class="string">'model.pt'</span>, map_location=device))</span><br><span class="line">        sentiment = predict_sentiment(model, tokenizer, TEXT)</span><br><span class="line">        print(sentiment)</span><br></pre></td></tr></table></figure>
<h3 id="基于Tensorflow2-0-1"><a href="#基于Tensorflow2-0-1" class="headerlink" title="基于Tensorflow2.0"></a>基于Tensorflow2.0</h3><p>This is a modification of <a href="https://github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb" target="_blank" rel="noopener">https://github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb</a> using the Tensorflow 2.0 Keras implementation of BERT from <a href="https://github.com/kpe/bert-for-tf2" target="_blank" rel="noopener">kpe/bert-for-tf2</a> with the original <a href="https://github.com/google-research/bert" target="_blank" rel="noopener">google-research/bert</a> weights.</p>
<p><strong>Predicting Movie Review Sentiment with <a href="https://github.com/kpe/bert-for-tf2" target="_blank" rel="noopener">kpe/bert-for-tf2</a></strong></p>
<h4 id="First-install-some-prerequisites"><a href="#First-install-some-prerequisites" class="headerlink" title="First install some prerequisites:"></a>First install some prerequisites:</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br></pre></td></tr></table></figure>
<p>In addition to the standard libraries we imported above, we’ll need to install the <a href="https://github.com/kpe/bert-for-tf2" target="_blank" rel="noopener">bert-for-tf2</a> python package, and do the imports required for loading the pre-trained weights and tokenizing the input text. </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> bert</span><br><span class="line"><span class="keyword">from</span> bert <span class="keyword">import</span> BertModelLayer</span><br><span class="line"><span class="keyword">from</span> bert.loader <span class="keyword">import</span> StockBertConfig, map_stock_config_to_params, load_stock_weights</span><br><span class="line"><span class="keyword">from</span> bert.tokenization.bert_tokenization <span class="keyword">import</span> FullTokenizer</span><br></pre></td></tr></table></figure>
<h4 id="Download-the-dataset"><a href="#Download-the-dataset" class="headerlink" title="Download the dataset"></a>Download the dataset</h4><p>First, let’s download the dataset, hosted by Stanford. The code below, which downloads, extracts, and imports the IMDB Large Movie Review Dataset, is borrowed from <a href="https://www.tensorflow.org/hub/tutorials/text_classification_with_tf_hub" target="_blank" rel="noopener">this Tensorflow tutorial</a>.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load all files from a directory in a DataFrame.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_directory_data</span><span class="params">(directory)</span>:</span></span><br><span class="line">    data = &#123;&#125;</span><br><span class="line">    data[<span class="string">"sentence"</span>] = []</span><br><span class="line">    data[<span class="string">"sentiment"</span>] = []</span><br><span class="line">    <span class="keyword">for</span> file_path <span class="keyword">in</span> tqdm(os.listdir(directory), desc=os.path.basename(directory)):</span><br><span class="line">        <span class="keyword">with</span> tf.io.gfile.GFile(os.path.join(directory, file_path), <span class="string">"r"</span>) <span class="keyword">as</span> f:</span><br><span class="line">            data[<span class="string">"sentence"</span>].append(f.read())</span><br><span class="line">            data[<span class="string">"sentiment"</span>].append(re.match(<span class="string">"\d+_(\d+)\.txt"</span>, file_path).group(<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> pd.DataFrame.from_dict(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Merge positive and negative examples, add a polarity column and shuffle.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_dataset</span><span class="params">(directory)</span>:</span></span><br><span class="line">    pos_df = load_directory_data(os.path.join(directory, <span class="string">"pos"</span>))</span><br><span class="line">    neg_df = load_directory_data(os.path.join(directory, <span class="string">"neg"</span>))</span><br><span class="line">    pos_df[<span class="string">"polarity"</span>] = <span class="number">1</span></span><br><span class="line">    neg_df[<span class="string">"polarity"</span>] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> pd.concat([pos_df, neg_df]).sample(frac=<span class="number">1</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Download and process the dataset files.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_and_load_datasets</span><span class="params">(force_download=False)</span>:</span></span><br><span class="line"><span class="comment">#     dataset = tf.keras.utils.get_file(</span></span><br><span class="line"><span class="comment">#       fname="aclImdb.tar.gz", </span></span><br><span class="line"><span class="comment">#       origin="http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz", </span></span><br><span class="line"><span class="comment">#       extract=True)</span></span><br><span class="line">    </span><br><span class="line">    dataset = <span class="string">"./aclImdb"</span></span><br><span class="line">    train_df = load_dataset(os.path.join(os.path.dirname(dataset), </span><br><span class="line">                                       <span class="string">"aclImdb"</span>, <span class="string">"train"</span>))</span><br><span class="line">    test_df = load_dataset(os.path.join(os.path.dirname(dataset), </span><br><span class="line">                                      <span class="string">"aclImdb"</span>, <span class="string">"test"</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train_df, test_df</span><br></pre></td></tr></table></figure>
<h4 id="Prepare-Encode"><a href="#Prepare-Encode" class="headerlink" title="Prepare/Encode"></a>Prepare/Encode</h4><p>Let’s use the <code>MovieReviewData</code> class below, to prepare/encode the data for feeding into our BERT model, by:</p>
<ul>
<li>tokenizing the text</li>
<li>trim or pad it to a <code>max_seq_len</code> length</li>
<li>append the special tokens <code>[CLS]</code> and <code>[SEP]</code></li>
<li>convert the string tokens to numerical <code>ID</code>s using the original model’s token encoding from <code>vocab.txt</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> bert</span><br><span class="line"><span class="keyword">from</span> bert <span class="keyword">import</span> BertModelLayer</span><br><span class="line"><span class="keyword">from</span> bert.loader <span class="keyword">import</span> StockBertConfig, map_stock_config_to_params, load_stock_weights</span><br><span class="line"><span class="comment"># from bert.tokenization import FullTokenizer</span></span><br><span class="line"><span class="keyword">from</span> bert <span class="keyword">import</span> bert_tokenization</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MovieReviewData</span>:</span></span><br><span class="line">    DATA_COLUMN = <span class="string">"sentence"</span></span><br><span class="line">    LABEL_COLUMN = <span class="string">"polarity"</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, tokenizer: bert_tokenization.FullTokenizer, sample_size=None, max_seq_len=<span class="number">1024</span>)</span>:</span></span><br><span class="line">        self.tokenizer = tokenizer</span><br><span class="line">        self.sample_size = sample_size</span><br><span class="line">        self.max_seq_len = <span class="number">0</span></span><br><span class="line">        train, test = download_and_load_datasets()</span><br><span class="line">        </span><br><span class="line">        train, test = map(<span class="keyword">lambda</span> df: df.reindex(df[MovieReviewData.DATA_COLUMN].str.len().sort_values().index), </span><br><span class="line">                          [train, test])</span><br><span class="line">                </span><br><span class="line">        <span class="keyword">if</span> sample_size <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">assert</span> sample_size % <span class="number">128</span> == <span class="number">0</span></span><br><span class="line">            train, test = train.head(sample_size), test.head(sample_size)</span><br><span class="line">            <span class="comment"># train, test = map(lambda df: df.sample(sample_size), [train, test])</span></span><br><span class="line">        </span><br><span class="line">        ((self.train_x, self.train_y),</span><br><span class="line">         (self.test_x, self.test_y)) = map(self._prepare, [train, test])</span><br><span class="line"></span><br><span class="line">        print(<span class="string">"max seq_len"</span>, self.max_seq_len)</span><br><span class="line">        self.max_seq_len = min(self.max_seq_len, max_seq_len)</span><br><span class="line">        ((self.train_x, self.train_x_token_types),</span><br><span class="line">         (self.test_x, self.test_x_token_types)) = map(self._pad, </span><br><span class="line">                                                       [self.train_x, self.test_x])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_prepare</span><span class="params">(self, df)</span>:</span></span><br><span class="line">        x, y = [], []</span><br><span class="line">        <span class="keyword">with</span> tqdm(total=df.shape[<span class="number">0</span>], unit_scale=<span class="literal">True</span>) <span class="keyword">as</span> pbar:</span><br><span class="line">            <span class="keyword">for</span> ndx, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">                text, label = row[MovieReviewData.DATA_COLUMN], row[MovieReviewData.LABEL_COLUMN]</span><br><span class="line">                tokens = self.tokenizer.tokenize(text)</span><br><span class="line">                tokens = [<span class="string">"[CLS]"</span>] + tokens + [<span class="string">"[SEP]"</span>]</span><br><span class="line">                token_ids = self.tokenizer.convert_tokens_to_ids(tokens)</span><br><span class="line">                self.max_seq_len = max(self.max_seq_len, len(token_ids))</span><br><span class="line">                x.append(token_ids)</span><br><span class="line">                y.append(int(label))</span><br><span class="line">                pbar.update()</span><br><span class="line">        <span class="keyword">return</span> np.array(x), np.array(y)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_pad</span><span class="params">(self, ids)</span>:</span></span><br><span class="line">        x, t = [], []</span><br><span class="line">        token_type_ids = [<span class="number">0</span>] * self.max_seq_len</span><br><span class="line">        <span class="keyword">for</span> input_ids <span class="keyword">in</span> ids:</span><br><span class="line">            input_ids = input_ids[:min(len(input_ids), self.max_seq_len - <span class="number">2</span>)]</span><br><span class="line">            input_ids = input_ids + [<span class="number">0</span>] * (self.max_seq_len - len(input_ids))</span><br><span class="line">            x.append(np.array(input_ids))</span><br><span class="line">            t.append(token_type_ids)</span><br><span class="line">        <span class="keyword">return</span> np.array(x), np.array(t)</span><br></pre></td></tr></table></figure>
<h4 id="A-tweak"><a href="#A-tweak" class="headerlink" title="A tweak"></a>A tweak</h4><p>Because of a <code>tf.train.load_checkpoint</code> limitation requiring list permissions on the google storage bucket, we need to copy the pre-trained BERT weights locally.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">bert_ckpt_dir=<span class="string">"./uncased_L-12_H-768_A-12/"</span></span><br><span class="line">bert_ckpt_file = bert_ckpt_dir + <span class="string">"bert_model.ckpt"</span></span><br><span class="line">bert_config_file = bert_ckpt_dir + <span class="string">"bert_config.json"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># %%time</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># bert_model_dir="2018_10_18"</span></span><br><span class="line"><span class="comment"># bert_model_name="uncased_L-12_H-768_A-12"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># !mkdir -p .model .model/$bert_model_name</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># for fname in ["bert_config.json", "vocab.txt", "bert_model.ckpt.meta", "bert_model.ckpt.index", "bert_model.ckpt.data-00000-of-00001"]:</span></span><br><span class="line"><span class="comment">#   cmd = f"gsutil cp gs://bert_models/&#123;bert_model_dir&#125;/&#123;bert_model_name&#125;/&#123;fname&#125; .model/&#123;bert_model_name&#125;"</span></span><br><span class="line"><span class="comment">#   !$cmd</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># !ls -la .model .model/$bert_model_name</span></span><br><span class="line"></span><br><span class="line">bert_ckpt_dir    = os.path.join(<span class="string">".model/"</span>,bert_model_name)</span><br><span class="line">bert_ckpt_file   = os.path.join(bert_ckpt_dir, <span class="string">"bert_model.ckpt"</span>)</span><br><span class="line">bert_config_file = os.path.join(bert_ckpt_dir, <span class="string">"bert_config.json"</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Preparing-the-Data"><a href="#Preparing-the-Data" class="headerlink" title="Preparing the Data"></a>Preparing the Data</h4><p>Now let’s fetch and prepare the data by taking the first <code>max_seq_len</code> tokenens after tokenizing with the BERT tokenizer, und use <code>sample_size</code> examples for both training and testing.</p>
<p>To keep training fast, we’ll take a sample of about 2500 train and test examples, respectively, and use the first 128 tokens only (transformers memory and computation requirements scale quadraticly with the sequence length - so with a TPU you might use <code>max_seq_len=512</code>, but on a GPU this would be too slow, and you will have to use a very small <code>batch_size</code>s to fit the model into the GPU memory).</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%%time</span><br><span class="line"></span><br><span class="line">tokenizer = FullTokenizer(vocab_file=os.path.join(bert_ckpt_dir, <span class="string">"vocab.txt"</span>))</span><br><span class="line">data = MovieReviewData(tokenizer, </span><br><span class="line">                       sample_size=<span class="number">10</span>*<span class="number">128</span>*<span class="number">2</span>,<span class="comment">#5000, </span></span><br><span class="line">                       max_seq_len=<span class="number">128</span>)</span><br><span class="line">print(<span class="string">"            train_x"</span>, data.train_x.shape)</span><br><span class="line">print(<span class="string">"train_x_token_types"</span>, data.train_x_token_types.shape)</span><br><span class="line">print(<span class="string">"            train_y"</span>, data.train_y.shape)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"             test_x"</span>, data.test_x.shape)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"        max_seq_len"</span>, data.max_seq_len)</span><br></pre></td></tr></table></figure>
<h4 id="Adapter-BERT"><a href="#Adapter-BERT" class="headerlink" title="Adapter BERT"></a>Adapter BERT</h4><p>If we decide to use <a href="https://arxiv.org/abs/1902.00751" target="_blank" rel="noopener">adapter-BERT</a> we need some helpers for freezing the original BERT layers.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">flatten_layers</span><span class="params">(root_layer)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(root_layer, keras.layers.Layer):</span><br><span class="line">        <span class="keyword">yield</span> root_layer</span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> root_layer._layers:</span><br><span class="line">        <span class="keyword">for</span> sub_layer <span class="keyword">in</span> flatten_layers(layer):</span><br><span class="line">            <span class="keyword">yield</span> sub_layer</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">freeze_bert_layers</span><span class="params">(l_bert)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Freezes all but LayerNorm and adapter layers - see arXiv:1902.00751.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> flatten_layers(l_bert):</span><br><span class="line">        <span class="keyword">if</span> layer.name <span class="keyword">in</span> [<span class="string">"LayerNorm"</span>, <span class="string">"adapter-down"</span>, <span class="string">"adapter-up"</span>]:</span><br><span class="line">            layer.trainable = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">elif</span> len(layer._layers) == <span class="number">0</span>:</span><br><span class="line">            layer.trainable = <span class="literal">False</span></span><br><span class="line">        l_bert.embeddings_layer.trainable = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_learning_rate_scheduler</span><span class="params">(max_learn_rate=<span class="number">5e-5</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                                   end_learn_rate=<span class="number">1e-7</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                                   warmup_epoch_count=<span class="number">10</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                                   total_epoch_count=<span class="number">90</span>)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">lr_scheduler</span><span class="params">(epoch)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> epoch &lt; warmup_epoch_count:</span><br><span class="line">            res = (max_learn_rate/warmup_epoch_count) * (epoch + <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            res = max_learn_rate*math.exp(math.log(end_learn_rate/max_learn_rate)*(epoch-warmup_epoch_count+<span class="number">1</span>)/(total_epoch_count-warmup_epoch_count+<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> float(res)</span><br><span class="line">    learning_rate_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> learning_rate_scheduler</span><br></pre></td></tr></table></figure>
<h4 id="Creating-a-model"><a href="#Creating-a-model" class="headerlink" title="Creating a model"></a>Creating a model</h4><p>Now let’s create a classification model using <a href="https//arxiv.org/abs/1902.00751">adapter-BERT</a>, which is clever way of reducing the trainable parameter count, by freezing the original BERT weights, and adapting them with two FFN bottlenecks (i.e. <code>adapter_size</code> bellow) in every BERT layer.</p>
<p><strong>N.B.</strong> The commented out code below show how to feed a <code>token_type_ids</code>/<code>segment_ids</code> sequence (which is not needed in our case).</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_model</span><span class="params">(max_seq_len, adapter_size=<span class="number">64</span>)</span>:</span></span><br><span class="line">    <span class="string">"""Creates a classification model."""</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#adapter_size = 64  # see - arXiv:1902.00751</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># create the bert layer</span></span><br><span class="line">    <span class="keyword">with</span> tf.io.gfile.GFile(bert_config_file, <span class="string">"r"</span>) <span class="keyword">as</span> reader:</span><br><span class="line">        bc = StockBertConfig.from_json_string(reader.read())</span><br><span class="line">        bert_params = map_stock_config_to_params(bc)</span><br><span class="line">        bert_params.adapter_size = adapter_size</span><br><span class="line">        bert = BertModelLayer.from_params(bert_params, name=<span class="string">"bert"</span>)</span><br><span class="line"></span><br><span class="line">    input_ids      = keras.layers.Input(shape=(max_seq_len,), dtype=<span class="string">'int32'</span>, name=<span class="string">"input_ids"</span>)</span><br><span class="line">    <span class="comment"># token_type_ids = keras.layers.Input(shape=(max_seq_len,), dtype='int32', name="token_type_ids")</span></span><br><span class="line">    <span class="comment"># output         = bert([input_ids, token_type_ids])</span></span><br><span class="line">    output         = bert(input_ids)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"bert shape"</span>, output.shape)</span><br><span class="line">    cls_out = keras.layers.Lambda(<span class="keyword">lambda</span> seq: seq[:, <span class="number">0</span>, :])(output)</span><br><span class="line">    cls_out = keras.layers.Dropout(<span class="number">0.5</span>)(cls_out)</span><br><span class="line">    logits = keras.layers.Dense(units=<span class="number">768</span>, activation=<span class="string">"tanh"</span>)(cls_out)</span><br><span class="line">    logits = keras.layers.Dropout(<span class="number">0.5</span>)(logits)</span><br><span class="line">    logits = keras.layers.Dense(units=<span class="number">2</span>, activation=<span class="string">"softmax"</span>)(logits)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># model = keras.Model(inputs=[input_ids, token_type_ids], outputs=logits)</span></span><br><span class="line">    <span class="comment"># model.build(input_shape=[(None, max_seq_len), (None, max_seq_len)])</span></span><br><span class="line">    model = keras.Model(inputs=input_ids, outputs=logits)</span><br><span class="line">    model.build(input_shape=(<span class="literal">None</span>, max_seq_len))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># load the pre-trained model weights</span></span><br><span class="line">    load_stock_weights(bert, bert_ckpt_file)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># freeze weights if adapter-BERT is used</span></span><br><span class="line">    <span class="keyword">if</span> adapter_size <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        freeze_bert_layers(bert)</span><br><span class="line"></span><br><span class="line">    model.compile(optimizer=keras.optimizers.Adam(),</span><br><span class="line">                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">                metrics=[keras.metrics.SparseCategoricalAccuracy(name=<span class="string">"acc"</span>)])</span><br><span class="line"></span><br><span class="line">    model.summary()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line">adapter_size = <span class="literal">None</span> <span class="comment"># use None to fine-tune all of BERT</span></span><br><span class="line">model = create_model(data.max_seq_len, adapter_size=adapter_size)</span><br><span class="line"></span><br><span class="line">%%time</span><br><span class="line"></span><br><span class="line">log_dir = <span class="string">".log/movie_reviews/"</span> + datetime.datetime.now().strftime(<span class="string">"%Y%m%d-%H%M%s"</span>)</span><br><span class="line">tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir)</span><br><span class="line"></span><br><span class="line">total_epoch_count = <span class="number">50</span></span><br><span class="line"><span class="comment"># model.fit(x=(data.train_x, data.train_x_token_types), y=data.train_y,</span></span><br><span class="line">model.fit(x=data.train_x, y=data.train_y,</span><br><span class="line">          validation_split=<span class="number">0.1</span>,</span><br><span class="line">          batch_size=<span class="number">48</span>,</span><br><span class="line">          shuffle=<span class="literal">True</span>,</span><br><span class="line">          epochs=total_epoch_count,</span><br><span class="line">          callbacks=[create_learning_rate_scheduler(max_learn_rate=<span class="number">1e-5</span>,</span><br><span class="line">                                                    end_learn_rate=<span class="number">1e-7</span>,</span><br><span class="line">                                                    warmup_epoch_count=<span class="number">20</span>,</span><br><span class="line">                                                    total_epoch_count=total_epoch_count),</span><br><span class="line">                     keras.callbacks.EarlyStopping(patience=<span class="number">20</span>, restore_best_weights=<span class="literal">True</span>),</span><br><span class="line">                     tensorboard_callback])</span><br><span class="line"></span><br><span class="line">model.save_weights(<span class="string">'./movie_reviews.h5'</span>, overwrite=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">%%time</span><br><span class="line"></span><br><span class="line">_, train_acc = model.evaluate(data.train_x, data.train_y)</span><br><span class="line">_, test_acc = model.evaluate(data.test_x, data.test_y)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"train acc"</span>, train_acc)</span><br><span class="line">print(<span class="string">"test acc"</span>, test_acc)</span><br></pre></td></tr></table></figure>
<h4 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h4><p>To evaluate the trained model, let’s load the saved weights in a new model instance, and evaluate.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%%time </span><br><span class="line"></span><br><span class="line">model = create_model(data.max_seq_len, adapter_size=<span class="literal">None</span>)</span><br><span class="line">model.load_weights(<span class="string">"movie_reviews.h5"</span>)</span><br><span class="line"></span><br><span class="line">_, train_acc = model.evaluate(data.train_x, data.train_y)</span><br><span class="line">_, test_acc = model.evaluate(data.test_x, data.test_y)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"train acc"</span>, train_acc)</span><br><span class="line">print(<span class="string">" test acc"</span>, test_acc)</span><br></pre></td></tr></table></figure>
<h4 id="Prediction"><a href="#Prediction" class="headerlink" title="Prediction"></a>Prediction</h4><p>For prediction, we need to prepare the input text the same way as we did for training - tokenize, adding the special <code>[CLS]</code> and <code>[SEP]</code> token at begin and end of the token sequence, and pad to match the model input shape.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pred_sentences = [</span><br><span class="line">  <span class="string">"That movie was absolutely awful"</span>,</span><br><span class="line">  <span class="string">"The acting was a bit lacking"</span>,</span><br><span class="line">  <span class="string">"The film was creative and surprising"</span>,</span><br><span class="line">  <span class="string">"Absolutely fantastic!"</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">tokenizer = FullTokenizer(vocab_file=os.path.join(bert_ckpt_dir, <span class="string">"vocab.txt"</span>))</span><br><span class="line">pred_tokens    = map(tokenizer.tokenize, pred_sentences)</span><br><span class="line">pred_tokens    = map(<span class="keyword">lambda</span> tok: [<span class="string">"[CLS]"</span>] + tok + [<span class="string">"[SEP]"</span>], pred_tokens)</span><br><span class="line">pred_token_ids = list(map(tokenizer.convert_tokens_to_ids, pred_tokens))</span><br><span class="line"></span><br><span class="line">pred_token_ids = map(<span class="keyword">lambda</span> tids: tids +[<span class="number">0</span>]*(data.max_seq_len-len(tids)),pred_token_ids)</span><br><span class="line">pred_token_ids = np.array(list(pred_token_ids))</span><br><span class="line"></span><br><span class="line">print(<span class="string">'pred_token_ids'</span>, pred_token_ids.shape)</span><br><span class="line"></span><br><span class="line">res = model.predict(pred_token_ids).argmax(axis=<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> text, sentiment <span class="keyword">in</span> zip(pred_sentences, res):</span><br><span class="line">  print(<span class="string">" text:"</span>, text)</span><br><span class="line">  print(<span class="string">"  res:"</span>, [<span class="string">"negative"</span>,<span class="string">"positive"</span>][sentiment])</span><br></pre></td></tr></table></figure>
<h3 id="一些Trick"><a href="#一些Trick" class="headerlink" title="一些Trick"></a>一些Trick</h3><ul>
<li>Multi-task学习</li>
<li>对抗训练</li>
<li>Domain data再训练</li>
</ul>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title>使用Transformer完成文本分类任务</title>
    <url>/posts/a6658471.html</url>
    <content><![CDATA[<div id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <div class="hbe-input-container">
  <input type="password" id="hbePass" placeholder="" />
    <label for="hbePass">Hey, password is required here.</label>
    <div class="bottom-line"></div>
  </div>
  <script id="hbeData" type="hbeData" data-hmacdigest="7866c9f4f75a6b1862990835c1e6a7bb92ddef1abf2242cfff59a22b4bb14970">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</script>
</div>
<script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title>Bert</title>
    <url>/posts/1424e830.html</url>
    <content><![CDATA[<h1 id="自然语言处理通用解决方案"><a href="#自然语言处理通用解决方案" class="headerlink" title="自然语言处理通用解决方案"></a>自然语言处理通用解决方案</h1><ol>
<li>需要熟悉 word2vec，RNN 网络模型，了解词向量如何建模</li>
<li>重点在于 Transform 网络架构，BERT训练方法，实际应用</li>
<li>开源项目都是现成的，提供预训练模型，基本任务拿过来直接用就成</li>
</ol>
<h1 id="Bert-核心原理"><a href="#Bert-核心原理" class="headerlink" title="Bert 核心原理"></a>Bert 核心原理</h1><p>Transformer结构是谷歌大脑在2017年底发表的一篇论文 Attention is All You Need 中提出的一种语言结构，是一种 Seq2Seq 的模型，Bert 就是从 Transformer 中衍生出来的一种预训练的语言模型。</p>
<p>BERT的全称是Bidirectional Encoder Representation from Transformers，即双向Transformer的Encoder，因为Decoder是不能获要预测的信息的。模型的主要创新点都在pre-train方法上，即用了Masked LM和Next Sentence Prediction两种方法分别捕捉词语和句子级别的representation。</p>
<h2 id="1-Transformer-直观理解"><a href="#1-Transformer-直观理解" class="headerlink" title="1 Transformer 直观理解"></a>1 Transformer 直观理解</h2><hr>
<h3 id="1-1-Transformer做了啥"><a href="#1-1-Transformer做了啥" class="headerlink" title="1.1 Transformer做了啥"></a>1.1 Transformer做了啥</h3><ol>
<li>其基本组成仍是机器翻译中常见的Seq2Seq网络，也就是类似输入一串中文，输出对应的英文。</li>
<li>传统架构中，中间的网络设计就是一个RNN，但是RNN不能并行计算，比如输入$x_0,x_1,…x_n$一串字符串，RNN会处理$x_0$得到一个当前输出$h_0$和一个隐藏特征，然后$x_1$与$x_0$不是独立的，会用到前面一个隐藏特征，也就是每个下一步都会用到前面的中间结果，因此我们在计算过程中不能独立计算。这就是RNN的问题，没办法做并行计算。Transformer 能做并行计算。</li>
<li>实际任务中我们对每个词不是一视同仁的，对重要程度不够高的词随便看看就好，对重要程度较高的词需要多关注一下 —— Transformer结构中使用 <strong>Self-Attention</strong> 机制。其输出结果是同时被计算出来的，而不是RNN中一步输出一个结果。</li>
<li>传统的 word2vec表达向量时在不同语境下相同的词无法改变，也就是预训练好的向量永久不变，但实际任务中会需要用到一个词的不同语义表示。</li>
<li>Transformer使用位置嵌入(positional encoding)来理解语言的顺序</li>
</ol>
<hr>
<h3 id="1-2-Attention是啥意思呢？"><a href="#1-2-Attention是啥意思呢？" class="headerlink" title="1.2 Attention是啥意思呢？"></a>1.2 Attention是啥意思呢？</h3><p>比较两个句子：</p>
<ol>
<li>The animal didn’t cross the street because it was too tired.</li>
<li>The animal didn’t cross the street because it was too narrow.</li>
</ol>
<p>我们要让计算机识别这两个it具体指代的是animal还是street，我们考虑对it编码时，前后文各个词在该编码中所占的比例，也就是要把上下文语境融入到当前计算的词向量中，这就是self-attention。</p>
<p>大概长得像这样：</p>
<p><img src="https://img-blog.csdnimg.cn/20200601153124996.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<blockquote>
<p>Self-attention is the method the Transformer uses to bake the “understanding” of other relevant words into the one we’re currently processing.</p>
</blockquote>
<hr>
<h2 id="2-Transformer-架构分析"><a href="#2-Transformer-架构分析" class="headerlink" title="2 Transformer 架构分析"></a>2 Transformer 架构分析</h2><p>我们从整体层面来看，输入一个句子，经过Transformer处理后，输出另一个句子：</p>
<p><img src="https://img-blog.csdnimg.cn/20200601153137132.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<hr>
<p>把Transformer稍微拆开一点，我们看到了句子输入后先由Encoder处理，经过某些转换，再由Decoder输出：</p>
<p><img src="https://img-blog.csdnimg.cn/20200601153146802.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<hr>
<p>事实上，中间的Encoder-Decoder可能是由更多的Encoders-Decoders拼接起来的，看起来像这样：</p>
<p><img src="https://img-blog.csdnimg.cn/20200601153155158.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<hr>
<p>每一个Encoder都是独立的，训练的时候权重参数可能完全不同，每一个Encoder都被分为两个子模块 ——— Self-Attention和前馈神经网络。</p>
<p><img src="https://img-blog.csdnimg.cn/20200601153203901.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<hr>
<p>使用Embedding Algorithm将每个单词转化为词向量：</p>
<p><img src="https://img-blog.csdnimg.cn/20200601153212169.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<hr>
<p>然后把词向量依次流入两个组件中，输出向量作为下一个Encoder的输入向量</p>
<p><img src="https://img-blog.csdnimg.cn/20200601153240878.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200601153240708.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="3-细看Self-Attention机制"><a href="#3-细看Self-Attention机制" class="headerlink" title="3 细看Self-Attention机制"></a>3 细看Self-Attention机制</h2><p><strong>第一步</strong>：对每个单词进行计算得到Queries，Keys，Values三个向量</p>
<p><img src="https://img-blog.csdnimg.cn/20200601153310517.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<hr>
<p><strong>第二步</strong>：使用单词A的Queries与单词A、C、D……的Keys计算出单词A与单词A、B、C、D……的相关程度，这个相关程度决定了我们编码该单词时需要考虑其他单词的比例：</p>
<p><img src="https://img-blog.csdnimg.cn/20200601153325830.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<hr>
<p><strong>第三步</strong>：将上面得到的Score除以向量的维度（为了让梯度更稳定），Softmax规范化转化为概率：</p>
<p><img src="https://img-blog.csdnimg.cn/20200601153335268.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<hr>
<p><strong>第四步</strong>：将该单词对应的每个单词的Softmax值分别乘上每个单词的Value，加和得到最终结果：</p>
<p><img src="https://img-blog.csdnimg.cn/20200601153343433.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<hr>
<h2 id="4-一点说明"><a href="#4-一点说明" class="headerlink" title="4 一点说明"></a>4 一点说明</h2><p><strong>ADDITION1</strong>：事实上上面的操作我们可以向量化表示，这样我们就实现了前面说的效率更高的并行计算：</p>
<p><img src="https://img-blog.csdnimg.cn/20200601153353255.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p><strong>ADDITION2</strong>：我们可以用一个公式概括上面的步骤：</p>
<p><img src="https://img-blog.csdnimg.cn/20200601153401474.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p><strong>ADDITION3</strong>： Mulit-head attention：</p>
<p><img src="https://img-blog.csdnimg.cn/20200601153411869.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p><strong>ADDITION4</strong>：总结图</p>
<p><img src="https://img-blog.csdnimg.cn/20200601153420715.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title>资金流入流出预测比赛（四）</title>
    <url>/posts/5ed99bac.html</url>
    <content><![CDATA[<h1 id="导包与数据预处理"><a href="#导包与数据预处理" class="headerlink" title="导包与数据预处理"></a>导包与数据预处理</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span>  pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> shap</span><br><span class="line"><span class="keyword">import</span> eli5</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> mvtpy <span class="keyword">import</span> mvtest</span><br><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"><span class="keyword">from</span> eli5.sklearn <span class="keyword">import</span> PermutationImportance</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> warnings </span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 为方面后面操作，设置全局index变量</span></span><br><span class="line"></span><br><span class="line">labels = [<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>]</span><br><span class="line">date_indexs = [<span class="string">'week'</span>,<span class="string">'year'</span>,<span class="string">'month'</span>,<span class="string">'weekday'</span>,<span class="string">'day'</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Load the balance data</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span><span class="params">(path: str = <span class="string">'user_balance_table.csv'</span>)</span>-&gt;pd.DataFrame:</span></span><br><span class="line">    data_balance = pd.read_csv(path)</span><br><span class="line">    <span class="keyword">return</span> data_balance.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="comment"># add tiemstamp to dataset</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_timestamp</span><span class="params">(data: pd.DataFrame, time_index: str = <span class="string">'report_date'</span>)</span>-&gt;pd.DataFrame:</span></span><br><span class="line">    data_balance = data.copy()</span><br><span class="line">    data_balance[<span class="string">'date'</span>] = pd.to_datetime(data_balance[time_index], format= <span class="string">"%Y%m%d"</span>)</span><br><span class="line">    data_balance[<span class="string">'day'</span>] = data_balance[<span class="string">'date'</span>].dt.day</span><br><span class="line">    data_balance[<span class="string">'month'</span>] = data_balance[<span class="string">'date'</span>].dt.month</span><br><span class="line">    data_balance[<span class="string">'year'</span>] = data_balance[<span class="string">'date'</span>].dt.year</span><br><span class="line">    data_balance[<span class="string">'week'</span>] = data_balance[<span class="string">'date'</span>].dt.week</span><br><span class="line">    data_balance[<span class="string">'weekday'</span>] = data_balance[<span class="string">'date'</span>].dt.weekday</span><br><span class="line">    <span class="keyword">return</span> data_balance.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># total amount</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_total_balance</span><span class="params">(data: pd.DataFrame, date: str = <span class="string">'2014-03-31'</span>)</span>-&gt;pd.DataFrame:</span></span><br><span class="line">    df_tmp = data.copy()</span><br><span class="line">    df_tmp = df_tmp.groupby([<span class="string">'date'</span>])[<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>].sum()</span><br><span class="line">    df_tmp.reset_index(inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> df_tmp[(df_tmp[<span class="string">'date'</span>]&gt;= date)].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate the test data</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_test_data</span><span class="params">(data: pd.DataFrame)</span>-&gt;pd.DataFrame:</span></span><br><span class="line">    total_balance = data.copy()</span><br><span class="line">    start = datetime.datetime(<span class="number">2014</span>,<span class="number">9</span>,<span class="number">1</span>)</span><br><span class="line">    testdata = []</span><br><span class="line">    <span class="keyword">while</span> start != datetime.datetime(<span class="number">2014</span>,<span class="number">10</span>,<span class="number">15</span>):</span><br><span class="line">        temp = [start, np.nan, np.nan]</span><br><span class="line">        testdata.append(temp)</span><br><span class="line">        start += datetime.timedelta(days = <span class="number">1</span>)</span><br><span class="line">    testdata = pd.DataFrame(testdata)</span><br><span class="line">    testdata.columns = total_balance.columns</span><br><span class="line"></span><br><span class="line">    total_balance = pd.concat([total_balance, testdata], axis = <span class="number">0</span>)</span><br><span class="line">    total_balance = total_balance.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> total_balance.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load user's information</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_user_information</span><span class="params">(path: str = <span class="string">'user_profile_table.csv'</span>)</span>-&gt;pd.DataFrame:</span></span><br><span class="line">    <span class="keyword">return</span> pd.read_csv(path)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 读取数据集</span></span><br><span class="line"></span><br><span class="line">balance_data = load_data(<span class="string">'Dataset/user_balance_table.csv'</span>)</span><br><span class="line">balance_data = add_timestamp(balance_data, time_index=<span class="string">'report_date'</span>)</span><br><span class="line">total_balance = get_total_balance(balance_data)</span><br><span class="line">total_balance = generate_test_data(total_balance)</span><br><span class="line">total_balance = add_timestamp(total_balance, <span class="string">'date'</span>)</span><br><span class="line">user_information = load_user_information(<span class="string">'Dataset/user_profile_table.csv'</span>)</span><br></pre></td></tr></table></figure>
<h1 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h1><h2 id="一、基于日期的静态特征"><a href="#一、基于日期的静态特征" class="headerlink" title="一、基于日期的静态特征"></a>一、基于日期的静态特征</h2><h3 id="1-1-提取-is-特征"><a href="#1-1-提取-is-特征" class="headerlink" title="1.1 提取 is 特征"></a>1.1 提取 is 特征</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 获取节假日集合</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_holiday_set</span><span class="params">()</span>-&gt;Set[datetime.date]:</span></span><br><span class="line">    holiday_set = set()</span><br><span class="line">    <span class="comment"># 清明节</span></span><br><span class="line">    holiday_set = holiday_set | &#123;datetime.date(<span class="number">2014</span>,<span class="number">4</span>,<span class="number">5</span>), datetime.date(<span class="number">2014</span>,<span class="number">4</span>,<span class="number">6</span>), datetime.date(<span class="number">2014</span>,<span class="number">4</span>,<span class="number">7</span>)&#125;</span><br><span class="line">    <span class="comment"># 劳动节</span></span><br><span class="line">    holiday_set = holiday_set | &#123;datetime.date(<span class="number">2014</span>,<span class="number">5</span>,<span class="number">1</span>), datetime.date(<span class="number">2014</span>,<span class="number">5</span>,<span class="number">2</span>), datetime.date(<span class="number">2014</span>,<span class="number">5</span>,<span class="number">3</span>)&#125;</span><br><span class="line">    <span class="comment"># 端午节</span></span><br><span class="line">    holiday_set = holiday_set | &#123;datetime.date(<span class="number">2014</span>,<span class="number">5</span>,<span class="number">31</span>), datetime.date(<span class="number">2014</span>,<span class="number">6</span>,<span class="number">1</span>), datetime.date(<span class="number">2014</span>,<span class="number">6</span>,<span class="number">2</span>)&#125;</span><br><span class="line">    <span class="comment"># 中秋节</span></span><br><span class="line">    holiday_set = holiday_set | &#123;datetime.date(<span class="number">2014</span>,<span class="number">9</span>,<span class="number">6</span>), datetime.date(<span class="number">2014</span>,<span class="number">9</span>,<span class="number">7</span>), datetime.date(<span class="number">2014</span>,<span class="number">9</span>,<span class="number">8</span>)&#125;</span><br><span class="line">    <span class="comment"># 国庆节</span></span><br><span class="line">    holiday_set = holiday_set | &#123;datetime.date(<span class="number">2014</span>,<span class="number">10</span>,<span class="number">1</span>), datetime.date(<span class="number">2014</span>,<span class="number">10</span>,<span class="number">2</span>), datetime.date(<span class="number">2014</span>,<span class="number">10</span>,<span class="number">3</span>),\</span><br><span class="line">                                 datetime.date(<span class="number">2014</span>,<span class="number">10</span>,<span class="number">4</span>), datetime.date(<span class="number">2014</span>,<span class="number">10</span>,<span class="number">5</span>), datetime.date(<span class="number">2014</span>,<span class="number">10</span>,<span class="number">6</span>),\</span><br><span class="line">                                datetime.date(<span class="number">2014</span>,<span class="number">10</span>,<span class="number">7</span>)&#125;</span><br><span class="line">    <span class="comment"># 中秋节</span></span><br><span class="line">    holiday_set = holiday_set | &#123;datetime.date(<span class="number">2013</span>,<span class="number">9</span>,<span class="number">19</span>), datetime.date(<span class="number">2013</span>,<span class="number">9</span>,<span class="number">20</span>), datetime.date(<span class="number">2013</span>,<span class="number">9</span>,<span class="number">21</span>)&#125;</span><br><span class="line">    <span class="comment"># 国庆节</span></span><br><span class="line">    holiday_set = holiday_set | &#123;datetime.date(<span class="number">2013</span>,<span class="number">10</span>,<span class="number">1</span>), datetime.date(<span class="number">2013</span>,<span class="number">10</span>,<span class="number">2</span>), datetime.date(<span class="number">2013</span>,<span class="number">10</span>,<span class="number">3</span>),\</span><br><span class="line">                                 datetime.date(<span class="number">2013</span>,<span class="number">10</span>,<span class="number">4</span>), datetime.date(<span class="number">2013</span>,<span class="number">10</span>,<span class="number">5</span>), datetime.date(<span class="number">2013</span>,<span class="number">10</span>,<span class="number">6</span>),\</span><br><span class="line">                                datetime.date(<span class="number">2013</span>,<span class="number">10</span>,<span class="number">7</span>)&#125;</span><br><span class="line">    <span class="keyword">return</span> holiday_set</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 提取所有 is特征</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_is_feature</span><span class="params">(data: pd.DataFrame)</span>-&gt;pd.DataFrame:</span></span><br><span class="line">    total_balance = data.copy().reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 是否是Weekend</span></span><br><span class="line">    total_balance[<span class="string">'is_weekend'</span>] = <span class="number">0</span></span><br><span class="line">    total_balance.loc[total_balance[<span class="string">'weekday'</span>].isin((<span class="number">5</span>,<span class="number">6</span>)), <span class="string">'is_weekend'</span>] = <span class="number">1</span></span><br><span class="line">    <span class="comment"># 是否是假期</span></span><br><span class="line">    total_balance[<span class="string">'is_holiday'</span>] = <span class="number">0</span></span><br><span class="line">    total_balance.loc[total_balance[<span class="string">'date'</span>].isin(get_holiday_set()), <span class="string">'is_holiday'</span>] = <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 是否是节假日的第一天</span></span><br><span class="line">    last_day_flag = <span class="number">0</span></span><br><span class="line">    total_balance[<span class="string">'is_firstday_of_holiday'</span>] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> total_balance.iterrows():</span><br><span class="line">        <span class="keyword">if</span> last_day_flag == <span class="number">0</span> <span class="keyword">and</span> row[<span class="string">'is_holiday'</span>] == <span class="number">1</span>:</span><br><span class="line">            total_balance.loc[index, <span class="string">'is_firstday_of_holiday'</span>] = <span class="number">1</span></span><br><span class="line">        last_day_flag = row[<span class="string">'is_holiday'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 是否是节假日的最后一天</span></span><br><span class="line">    total_balance[<span class="string">'is_lastday_of_holiday'</span>] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> total_balance.iterrows():</span><br><span class="line">        <span class="keyword">if</span> row[<span class="string">'is_holiday'</span>] == <span class="number">1</span> <span class="keyword">and</span> total_balance.loc[index+<span class="number">1</span>, <span class="string">'is_holiday'</span>] == <span class="number">0</span>:</span><br><span class="line">             total_balance.loc[index, <span class="string">'is_lastday_of_holiday'</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 是否是节假日后的上班第一天</span></span><br><span class="line">    total_balance[<span class="string">'is_firstday_of_work'</span>] = <span class="number">0</span></span><br><span class="line">    last_day_flag = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> total_balance.iterrows():</span><br><span class="line">        <span class="keyword">if</span> last_day_flag == <span class="number">1</span> <span class="keyword">and</span> row[<span class="string">'is_holiday'</span>] == <span class="number">0</span>:</span><br><span class="line">            total_balance.loc[index, <span class="string">'is_firstday_of_work'</span>] = <span class="number">1</span></span><br><span class="line">        last_day_flag = row[<span class="string">'is_lastday_of_holiday'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 是否不用上班</span></span><br><span class="line">    total_balance[<span class="string">'is_work'</span>] = <span class="number">1</span></span><br><span class="line">    total_balance.loc[(total_balance[<span class="string">'is_holiday'</span>] == <span class="number">1</span>) | (total_balance[<span class="string">'is_weekend'</span>] == <span class="number">1</span>), <span class="string">'is_work'</span>] = <span class="number">0</span></span><br><span class="line">    special_work_day_set = &#123;datetime.date(<span class="number">2014</span>,<span class="number">5</span>,<span class="number">4</span>), datetime.date(<span class="number">2014</span>,<span class="number">9</span>,<span class="number">28</span>)&#125;</span><br><span class="line">    total_balance.loc[total_balance[<span class="string">'date'</span>].isin(special_work_day_set), <span class="string">'is_work'</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 是否明天要上班</span></span><br><span class="line">    total_balance[<span class="string">'is_gonna_work_tomorrow'</span>] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> total_balance.iterrows():</span><br><span class="line">        <span class="keyword">if</span> index == len(total_balance)<span class="number">-1</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">if</span> row[<span class="string">'is_work'</span>] == <span class="number">0</span> <span class="keyword">and</span> total_balance.loc[index+<span class="number">1</span>, <span class="string">'is_work'</span>] == <span class="number">1</span>:</span><br><span class="line">             total_balance.loc[index, <span class="string">'is_gonna_work_tomorrow'</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 昨天上班了吗</span></span><br><span class="line">    total_balance[<span class="string">'is_worked_yestday'</span>] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> total_balance.iterrows():</span><br><span class="line">        <span class="keyword">if</span> index &lt;= <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">if</span> total_balance.loc[index<span class="number">-1</span>, <span class="string">'is_work'</span>] == <span class="number">1</span>:</span><br><span class="line">             total_balance.loc[index, <span class="string">'is_worked_yestday'</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 是否是放假前一天</span></span><br><span class="line">    total_balance[<span class="string">'is_lastday_of_workday'</span>] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> total_balance.iterrows():</span><br><span class="line">        <span class="keyword">if</span> index == len(total_balance)<span class="number">-1</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">if</span> row[<span class="string">'is_holiday'</span>] == <span class="number">0</span> <span class="keyword">and</span> total_balance.loc[index+<span class="number">1</span>, <span class="string">'is_holiday'</span>] == <span class="number">1</span>:</span><br><span class="line">             total_balance.loc[index, <span class="string">'is_lastday_of_workday'</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 是否周日要上班</span></span><br><span class="line">    total_balance[<span class="string">'is_work_on_sunday'</span>] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> total_balance.iterrows():</span><br><span class="line">        <span class="keyword">if</span> index == len(total_balance)<span class="number">-1</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">if</span> row[<span class="string">'weekday'</span>] == <span class="number">6</span> <span class="keyword">and</span> row[<span class="string">'is_work'</span>] == <span class="number">1</span>:</span><br><span class="line">             total_balance.loc[index, <span class="string">'is_work_on_sunday'</span>] = <span class="number">1</span></span><br><span class="line">                </span><br><span class="line">    <span class="comment"># 是否是月初第一天</span></span><br><span class="line">    total_balance[<span class="string">'is_firstday_of_month'</span>] = <span class="number">0</span></span><br><span class="line">    total_balance.loc[total_balance[<span class="string">'day'</span>] == <span class="number">1</span>, <span class="string">'is_firstday_of_month'</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 是否是月初第二天</span></span><br><span class="line">    total_balance[<span class="string">'is_secday_of_month'</span>] = <span class="number">0</span></span><br><span class="line">    total_balance.loc[total_balance[<span class="string">'day'</span>] == <span class="number">2</span>, <span class="string">'is_secday_of_month'</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 是否是月初</span></span><br><span class="line">    total_balance[<span class="string">'is_premonth'</span>] = <span class="number">0</span></span><br><span class="line">    total_balance.loc[total_balance[<span class="string">'day'</span>] &lt;= <span class="number">10</span>, <span class="string">'is_premonth'</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 是否是月中</span></span><br><span class="line">    total_balance[<span class="string">'is_midmonth'</span>] = <span class="number">0</span></span><br><span class="line">    total_balance.loc[(<span class="number">10</span> &lt; total_balance[<span class="string">'day'</span>]) &amp; (total_balance[<span class="string">'day'</span>] &lt;= <span class="number">20</span>), <span class="string">'is_midmonth'</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 是否是月末</span></span><br><span class="line">    total_balance[<span class="string">'is_tailmonth'</span>] = <span class="number">0</span></span><br><span class="line">    total_balance.loc[<span class="number">20</span> &lt; total_balance[<span class="string">'day'</span>], <span class="string">'is_tailmonth'</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 是否是每个月第一个周</span></span><br><span class="line">    total_balance[<span class="string">'is_first_week'</span>] = <span class="number">0</span></span><br><span class="line">    total_balance.loc[total_balance[<span class="string">'week'</span>] % <span class="number">4</span> == <span class="number">1</span>, <span class="string">'is_first_week'</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 是否是每个月第一个周</span></span><br><span class="line">    total_balance[<span class="string">'is_second_week'</span>] = <span class="number">0</span></span><br><span class="line">    total_balance.loc[total_balance[<span class="string">'week'</span>] % <span class="number">4</span> == <span class="number">2</span>, <span class="string">'is_second_week'</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 是否是每个月第一个周</span></span><br><span class="line">    total_balance[<span class="string">'is_third_week'</span>] = <span class="number">0</span></span><br><span class="line">    total_balance.loc[total_balance[<span class="string">'week'</span>] % <span class="number">4</span> == <span class="number">3</span>, <span class="string">'is_third_week'</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 是否是每个月第四个周</span></span><br><span class="line">    total_balance[<span class="string">'is_fourth_week'</span>] = <span class="number">0</span></span><br><span class="line">    total_balance.loc[total_balance[<span class="string">'week'</span>] % <span class="number">4</span> == <span class="number">0</span>, <span class="string">'is_fourth_week'</span>] = <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> total_balance.reset_index(drop=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 提取is特征到数据集</span></span><br><span class="line"></span><br><span class="line">total_balance = extract_is_feature(total_balance)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 编码翌日特征</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">encode_data</span><span class="params">(data: pd.DataFrame, feature_name:str = <span class="string">'weekday'</span>, encoder=OneHotEncoder<span class="params">()</span>)</span>-&gt;pd.DataFrame():</span></span><br><span class="line">    total_balance = data.copy()</span><br><span class="line">    week_feature = encoder.fit_transform(np.array(total_balance[feature_name]).reshape(<span class="number">-1</span>, <span class="number">1</span>)).toarray()</span><br><span class="line">    week_feature = pd.DataFrame(week_feature,columns= [feature_name + <span class="string">'_onehot_'</span>+ str(x) <span class="keyword">for</span> x <span class="keyword">in</span> range(len(week_feature[<span class="number">0</span>]))])</span><br><span class="line">    <span class="comment">#featureWeekday = pd.concat([total_balance, week_feature], axis = 1).drop(feature_name, axis=1)</span></span><br><span class="line">    featureWeekday = pd.concat([total_balance, week_feature], axis = <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> featureWeekday</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 编码翌日特征到数据集</span></span><br><span class="line"></span><br><span class="line">total_balance = encode_data(total_balance)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生成is特征集合</span></span><br><span class="line"></span><br><span class="line">feature = total_balance[[x <span class="keyword">for</span> x <span class="keyword">in</span> total_balance.columns <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> date_indexs]]</span><br></pre></td></tr></table></figure>
<h3 id="1-2-is特征的下标签分布分析"><a href="#1-2-is特征的下标签分布分析" class="headerlink" title="1.2 is特征的下标签分布分析"></a>1.2 is特征的下标签分布分析</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 绘制箱型图</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw_boxplot</span><span class="params">(data: pd.DataFrame)</span>-&gt;<span class="keyword">None</span>:</span></span><br><span class="line">    f, axes = plt.subplots(<span class="number">7</span>, <span class="number">4</span>, figsize=(<span class="number">18</span>, <span class="number">24</span>))</span><br><span class="line">    <span class="keyword">global</span> date_indexs, labels</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> [x <span class="keyword">for</span> x <span class="keyword">in</span> data.columns <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> date_indexs + labels + [<span class="string">'date'</span>]]:</span><br><span class="line">        sns.boxenplot(x=i, y=<span class="string">'total_purchase_amt'</span>, data=data, ax=axes[count // <span class="number">4</span>][count % <span class="number">4</span>])</span><br><span class="line">        count += <span class="number">1</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">draw_boxplot(feature)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/05.%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/output_17_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 剔除看起来较差的特征</span></span><br><span class="line"></span><br><span class="line">purchase_feature_seems_useless = [</span><br><span class="line">      <span class="comment">#样本量太少，建模时无效；但若确定这是一个有用规则，可以对结果做修正</span></span><br><span class="line">      <span class="string">'is_work_on_sunday'</span>,</span><br><span class="line">      <span class="comment">#中位数差异不明显</span></span><br><span class="line">      <span class="string">'is_first_week'</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<h3 id="1-3-IS-特征的相关性分析"><a href="#1-3-IS-特征的相关性分析" class="headerlink" title="1.3 IS 特征的相关性分析"></a>1.3 IS 特征的相关性分析</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 画相关性热力图</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw_correlation_heatmap</span><span class="params">(data: pd.DataFrame, way:str = <span class="string">'pearson'</span>)</span>-&gt;<span class="keyword">None</span>:</span></span><br><span class="line">    feature = data.copy()</span><br><span class="line">    plt.figure(figsize=(<span class="number">20</span>,<span class="number">10</span>))</span><br><span class="line">    plt.title(<span class="string">'The '</span> + way +<span class="string">' coleration between total purchase and each feature'</span>)</span><br><span class="line">    sns.heatmap(feature[[x <span class="keyword">for</span> x <span class="keyword">in</span> feature.columns <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'total_redeem_amt'</span>, <span class="string">'date'</span>] ]].corr(way),linecolor=<span class="string">'white'</span>,</span><br><span class="line">        linewidths=<span class="number">0.1</span>,</span><br><span class="line">        cmap=<span class="string">"RdBu"</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">draw_correlation_heatmap(feature, <span class="string">'spearman'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/05.%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/output_21_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 剔除相关性较低的特征</span></span><br><span class="line"></span><br><span class="line">temp = np.abs(feature[[x <span class="keyword">for</span> x <span class="keyword">in</span> feature.columns </span><br><span class="line">                       <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'total_redeem_amt'</span>, <span class="string">'date'</span>] ]].corr(<span class="string">'spearman'</span>)[<span class="string">'total_purchase_amt'</span>])</span><br><span class="line">feature_low_correlation = list(set(temp[temp &lt; <span class="number">0.1</span>].index))</span><br></pre></td></tr></table></figure>
<h2 id="二、基于距离的特征"><a href="#二、基于距离的特征" class="headerlink" title="二、基于距离的特征"></a>二、基于距离的特征</h2><h3 id="2-1-距离特征提取"><a href="#2-1-距离特征提取" class="headerlink" title="2.1 距离特征提取"></a>2.1 距离特征提取</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 提取距离特征</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_distance_feature</span><span class="params">(data: pd.DataFrame)</span>-&gt;pd.DataFrame:</span></span><br><span class="line">    total_balance = data.copy()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 距离放假还有多少天</span></span><br><span class="line">    total_balance[<span class="string">'dis_to_nowork'</span>] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> total_balance.iterrows():</span><br><span class="line">        <span class="keyword">if</span> row[<span class="string">'is_work'</span>] == <span class="number">0</span>:</span><br><span class="line">            step = <span class="number">1</span></span><br><span class="line">            flag = <span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> flag:</span><br><span class="line">                <span class="keyword">if</span> index - step &gt;= <span class="number">0</span> <span class="keyword">and</span> total_balance.loc[index - step, <span class="string">'is_work'</span>] == <span class="number">1</span>:</span><br><span class="line">                    total_balance.loc[index - step, <span class="string">'dis_to_nowork'</span>] = step</span><br><span class="line">                    step += <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    flag = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    total_balance[<span class="string">'dis_from_nowork'</span>] = <span class="number">0</span></span><br><span class="line">    step = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> total_balance.iterrows():</span><br><span class="line">        step += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> row[<span class="string">'is_work'</span>] == <span class="number">1</span>:</span><br><span class="line">            total_balance.loc[index, <span class="string">'dis_from_nowork'</span>] = step</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            step = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 距离上班还有多少天</span></span><br><span class="line">    total_balance[<span class="string">'dis_to_work'</span>] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> total_balance.iterrows():</span><br><span class="line">        <span class="keyword">if</span> row[<span class="string">'is_work'</span>] == <span class="number">1</span>:</span><br><span class="line">            step = <span class="number">1</span></span><br><span class="line">            flag = <span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> flag:</span><br><span class="line">                <span class="keyword">if</span> index - step &gt;= <span class="number">0</span> <span class="keyword">and</span> total_balance.loc[index - step, <span class="string">'is_work'</span>] == <span class="number">0</span>:</span><br><span class="line">                    total_balance.loc[index - step, <span class="string">'dis_to_work'</span>] = step</span><br><span class="line">                    step += <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    flag = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    total_balance[<span class="string">'dis_from_work'</span>] = <span class="number">0</span></span><br><span class="line">    step = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> total_balance.iterrows():</span><br><span class="line">        step += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> row[<span class="string">'is_work'</span>] == <span class="number">0</span>:</span><br><span class="line">            total_balance.loc[index, <span class="string">'dis_from_work'</span>] = step</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            step = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 距离节假日还有多少天</span></span><br><span class="line">    total_balance[<span class="string">'dis_to_holiday'</span>] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> total_balance.iterrows():</span><br><span class="line">        <span class="keyword">if</span> row[<span class="string">'is_holiday'</span>] == <span class="number">1</span>:</span><br><span class="line">            step = <span class="number">1</span></span><br><span class="line">            flag = <span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> flag:</span><br><span class="line">                <span class="keyword">if</span> index - step &gt;= <span class="number">0</span> <span class="keyword">and</span> total_balance.loc[index - step, <span class="string">'is_holiday'</span>] == <span class="number">0</span>:</span><br><span class="line">                    total_balance.loc[index - step, <span class="string">'dis_to_holiday'</span>] = step</span><br><span class="line">                    step += <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    flag = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    total_balance[<span class="string">'dis_from_holiday'</span>] = <span class="number">0</span></span><br><span class="line">    step = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> total_balance.iterrows():</span><br><span class="line">        step += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> row[<span class="string">'is_holiday'</span>] == <span class="number">0</span>:</span><br><span class="line">            total_balance.loc[index, <span class="string">'dis_from_holiday'</span>] = step</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            step = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 距离节假日最后一天还有多少天</span></span><br><span class="line">    total_balance[<span class="string">'dis_to_holiendday'</span>] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> total_balance.iterrows():</span><br><span class="line">        <span class="keyword">if</span> row[<span class="string">'is_lastday_of_holiday'</span>] == <span class="number">1</span>:</span><br><span class="line">            step = <span class="number">1</span></span><br><span class="line">            flag = <span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> flag:</span><br><span class="line">                <span class="keyword">if</span> index - step &gt;= <span class="number">0</span> <span class="keyword">and</span> total_balance.loc[index - step, <span class="string">'is_lastday_of_holiday'</span>] == <span class="number">0</span>:</span><br><span class="line">                    total_balance.loc[index - step, <span class="string">'dis_to_holiendday'</span>] = step</span><br><span class="line">                    step += <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    flag = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    total_balance[<span class="string">'dis_from_holiendday'</span>] = <span class="number">0</span></span><br><span class="line">    step = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> total_balance.iterrows():</span><br><span class="line">        step += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> row[<span class="string">'is_lastday_of_holiday'</span>] == <span class="number">0</span>:</span><br><span class="line">            total_balance.loc[index, <span class="string">'dis_from_holiendday'</span>] = step</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            step = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 距离月初第几天</span></span><br><span class="line">    total_balance[<span class="string">'dis_from_startofmonth'</span>] = np.abs(total_balance[<span class="string">'day'</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 距离月的中心点有几天</span></span><br><span class="line">    total_balance[<span class="string">'dis_from_middleofmonth'</span>] = np.abs(total_balance[<span class="string">'day'</span>] - <span class="number">15</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 距离星期的中心有几天</span></span><br><span class="line">    total_balance[<span class="string">'dis_from_middleofweek'</span>] = np.abs(total_balance[<span class="string">'weekday'</span>] - <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 距离星期日有几天</span></span><br><span class="line">    total_balance[<span class="string">'dis_from_endofweek'</span>] = np.abs(total_balance[<span class="string">'weekday'</span>] - <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> total_balance</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 拼接距离特征到原数据集</span></span><br><span class="line"></span><br><span class="line">total_balance = extract_distance_feature(total_balance)</span><br></pre></td></tr></table></figure>
<h3 id="2-2-距离特征分析"><a href="#2-2-距离特征分析" class="headerlink" title="2.2 距离特征分析"></a>2.2 距离特征分析</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 获取距离特征的列名</span></span><br><span class="line"></span><br><span class="line">feature = total_balance[[x <span class="keyword">for</span> x <span class="keyword">in</span> total_balance.columns <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> date_indexs]]</span><br><span class="line">dis_feature_indexs = [x <span class="keyword">for</span> x <span class="keyword">in</span> feature.columns <span class="keyword">if</span> (x <span class="keyword">not</span> <span class="keyword">in</span> date_indexs + labels + [<span class="string">'date'</span>]) &amp; (<span class="string">'dis'</span> <span class="keyword">in</span> x)]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 画点线</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw_point_feature</span><span class="params">(data: pd.DataFrame)</span>-&gt;<span class="keyword">None</span>:</span></span><br><span class="line">    feature = data.copy()</span><br><span class="line">    f, axes = plt.subplots(data.shape[<span class="number">1</span>] // <span class="number">3</span>, <span class="number">3</span>, figsize=(<span class="number">30</span>, data.shape[<span class="number">1</span>] // <span class="number">3</span> * <span class="number">4</span>))</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> [x <span class="keyword">for</span> x <span class="keyword">in</span> feature.columns <span class="keyword">if</span> (x <span class="keyword">not</span> <span class="keyword">in</span> date_indexs + labels + [<span class="string">'date'</span>])]:</span><br><span class="line">        sns.pointplot(x=i, y=<span class="string">"total_purchase_amt"</span>,</span><br><span class="line">                markers=[<span class="string">"^"</span>, <span class="string">"o"</span>], linestyles=[<span class="string">"-"</span>, <span class="string">"--"</span>],</span><br><span class="line">                kind=<span class="string">"point"</span>, data=feature, ax=axes[count // <span class="number">3</span>][count % <span class="number">3</span>] <span class="keyword">if</span> data.shape[<span class="number">1</span>] &gt; <span class="number">3</span> <span class="keyword">else</span> axes[count])</span><br><span class="line">        count += <span class="number">1</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">draw_point_feature(feature[[<span class="string">'total_purchase_amt'</span>] + dis_feature_indexs])</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/05.%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/output_30_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 处理距离过远的时间点</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dis_change</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> x &gt; <span class="number">5</span>:</span><br><span class="line">        x = <span class="number">10</span></span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 处理特殊距离</span></span><br><span class="line"></span><br><span class="line">dis_holiday_feature = [x <span class="keyword">for</span> x <span class="keyword">in</span> total_balance.columns <span class="keyword">if</span> <span class="string">'dis'</span> <span class="keyword">in</span> x <span class="keyword">and</span> <span class="string">'holi'</span> <span class="keyword">in</span> x]</span><br><span class="line">dis_month_feature = [x <span class="keyword">for</span> x <span class="keyword">in</span> total_balance.columns <span class="keyword">if</span> <span class="string">'dis'</span> <span class="keyword">in</span> x <span class="keyword">and</span> <span class="string">'month'</span> <span class="keyword">in</span> x]</span><br><span class="line">total_balance[dis_holiday_feature] = total_balance[dis_holiday_feature].applymap(dis_change)</span><br><span class="line">total_balance[dis_month_feature] = total_balance[dis_month_feature].applymap(dis_change)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">feature = total_balance[[x <span class="keyword">for</span> x <span class="keyword">in</span> total_balance.columns <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> date_indexs]]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 画处理后的点线图</span></span><br><span class="line"></span><br><span class="line">draw_point_feature(feature[[<span class="string">'total_purchase_amt'</span>] + dis_feature_indexs])</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/05.%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/output_34_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 剔除看起来用处不大的特征</span></span><br><span class="line">purchase_feature_seems_useless += [</span><br><span class="line">                                  <span class="comment">#即使做了处理，但方差太大，不可信，规律不明显</span></span><br><span class="line">                                  <span class="string">'dis_to_holiday'</span>,</span><br><span class="line">                                  <span class="comment">#方差太大，不可信</span></span><br><span class="line">                                  <span class="string">'dis_from_startofmonth'</span>,</span><br><span class="line">                                  <span class="comment">#方差太大，不可信</span></span><br><span class="line">                                  <span class="string">'dis_from_middleofmonth'</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 画出相关性图</span></span><br><span class="line"></span><br><span class="line">draw_correlation_heatmap(feature[[<span class="string">'total_purchase_amt'</span>] + dis_feature_indexs])</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/05.%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/output_36_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 剔除相关性较差的特征</span></span><br><span class="line"></span><br><span class="line">temp = np.abs(feature[[x <span class="keyword">for</span> x <span class="keyword">in</span> feature.columns </span><br><span class="line">                       <span class="keyword">if</span> (<span class="string">'dis'</span> <span class="keyword">in</span> x) | (x <span class="keyword">in</span> [<span class="string">'total_purchase_amt'</span>]) ]].corr()[<span class="string">'total_purchase_amt'</span>])</span><br><span class="line">feature_low_correlation += list(set(temp[temp &lt; <span class="number">0.1</span>].index) )</span><br></pre></td></tr></table></figure>
<h2 id="三、波峰波谷特征"><a href="#三、波峰波谷特征" class="headerlink" title="三、波峰波谷特征"></a>三、波峰波谷特征</h2><h3 id="3-1-提取波峰特征"><a href="#3-1-提取波峰特征" class="headerlink" title="3.1 提取波峰特征"></a>3.1 提取波峰特征</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 观察波峰特点</span></span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">15</span>,<span class="number">15</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">6</span>, <span class="number">10</span>):</span><br><span class="line">    plt.subplot(<span class="number">5</span>,<span class="number">1</span>,i - <span class="number">5</span>)</span><br><span class="line">    total_balance_2 = total_balance[(total_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,<span class="number">8</span>,<span class="number">1</span>)) &amp; (total_balance[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>,<span class="number">9</span>,<span class="number">1</span>))]</span><br><span class="line">    sns.pointplot(x=total_balance_2[<span class="string">'day'</span>],y=total_balance_2[<span class="string">'total_purchase_amt'</span>])</span><br><span class="line">    plt.legend().set_title(<span class="string">'Month:'</span> + str(i))</span><br></pre></td></tr></table></figure>
<pre><code>No handles with labels found to put in legend.
No handles with labels found to put in legend.
No handles with labels found to put in legend.
No handles with labels found to put in legend.
</code></pre><p><img src="/Pic/05.%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/output_40_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Purchase</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#0401(周二)                                     0406（周日，清明节第二天）</span></span><br><span class="line"><span class="comment">#0410(周四，与周二近似)                         0412（周六，与周日近似）</span></span><br><span class="line"><span class="comment">#0415（周二）                                   0420（周日）</span></span><br><span class="line"><span class="comment">#0424（周四，与周二在近似水平）                 0427（周日）</span></span><br><span class="line"><span class="comment">#0429（周二）                                   0502（周五，劳动节第二天）</span></span><br><span class="line"><span class="comment">#0507（周三，与周二差异较大，可能受劳务节影响） 0511（周日）</span></span><br><span class="line"><span class="comment">#0512（周一，与周二有一定差距）                 0518（周日）</span></span><br><span class="line"><span class="comment">#0519（周二）                                   0525（周日）</span></span><br><span class="line"><span class="comment">#0526（周一，与周二有一定差距）                 0531（周六，月末）</span></span><br><span class="line"><span class="comment">#0605（周四，与周二差异大，可能受端午节影响）   0607（周六，可能受端午节影响）</span></span><br><span class="line"><span class="comment">#0609（周一，与周二近似）                       0615（周日）</span></span><br><span class="line"><span class="comment">#0616（周一，与周二差异大）                     0622（周日）</span></span><br><span class="line"><span class="comment">#0626（周四，与周二差异不大）                   0629（周日）</span></span><br><span class="line"><span class="comment">#0701（周二）                                   0705（周六，与周日差距不大）</span></span><br><span class="line"><span class="comment">#0707（周一，与周二有差距）                     0713（周日）</span></span><br><span class="line"><span class="comment">#0716（周三，与周二有一定差距）                 0720（周日）</span></span><br><span class="line"><span class="comment">#0721（周一，与周二有明显差距）                 0726（周六，与周日近似）</span></span><br><span class="line"><span class="comment">#0728（周一，与周二有明显差距）                 0803（周日）</span></span><br><span class="line"><span class="comment">#0805（周二）                                   0809（周六，与周日有较大差距）</span></span><br><span class="line"><span class="comment">#0811（周一，有周二有较大差距）                 0817（周日）</span></span><br><span class="line"><span class="comment">#0818（周一，与周二差距不大）                   0824（周日）</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 设定波峰日期</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_peak_feature</span><span class="params">(data: pd.DataFrame)</span>-&gt;pd.DataFrame:</span></span><br><span class="line">    total_balance = data.copy()</span><br><span class="line">    <span class="comment"># 距离purchase波峰（即周二）有几天</span></span><br><span class="line">    total_balance[<span class="string">'dis_from_purchase_peak'</span>] = np.abs(total_balance[<span class="string">'weekday'</span>] - <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 距离purchase波谷（即周日）有几天，与dis_from_endofweek相同</span></span><br><span class="line">    total_balance[<span class="string">'dis_from_purchase_valley'</span>] = np.abs(total_balance[<span class="string">'weekday'</span>] - <span class="number">6</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> total_balance</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 提取波峰特征</span></span><br><span class="line"></span><br><span class="line">total_balance = extract_peak_feature(total_balance)</span><br><span class="line">feature = total_balance[[x <span class="keyword">for</span> x <span class="keyword">in</span> total_balance.columns <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> date_indexs]]</span><br></pre></td></tr></table></figure>
<h3 id="3-2-分析波峰特征"><a href="#3-2-分析波峰特征" class="headerlink" title="3.2 分析波峰特征"></a>3.2 分析波峰特征</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">draw_point_feature(feature[[<span class="string">'total_purchase_amt'</span>] + [<span class="string">'dis_from_purchase_peak'</span>,<span class="string">'dis_from_purchase_valley'</span>]])</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/05.%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/output_45_0.png" alt="png"></p>
<h3 id="3-3-分析波峰特征相关性"><a href="#3-3-分析波峰特征相关性" class="headerlink" title="3.3 分析波峰特征相关性"></a>3.3 分析波峰特征相关性</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">temp = np.abs(feature[[x <span class="keyword">for</span> x <span class="keyword">in</span> feature.columns <span class="keyword">if</span> (<span class="string">'peak'</span> <span class="keyword">in</span> x) <span class="keyword">or</span> (<span class="string">'valley'</span> <span class="keyword">in</span> x) <span class="keyword">or</span> (x <span class="keyword">in</span> [<span class="string">'total_purchase_amt'</span>]) ]].corr()[<span class="string">'total_purchase_amt'</span>])</span><br></pre></td></tr></table></figure>
<h2 id="四、加入周期因子作为特征"><a href="#四、加入周期因子作为特征" class="headerlink" title="四、加入周期因子作为特征"></a>四、加入周期因子作为特征</h2><h3 id="4-1-提取周期因子"><a href="#4-1-提取周期因子" class="headerlink" title="4.1 提取周期因子"></a>4.1 提取周期因子</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_rate</span><span class="params">(df, month_index)</span>:</span></span><br><span class="line">    total_balance = df.copy()</span><br><span class="line">    pure_balance = total_balance[[<span class="string">'date'</span>,<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>]]</span><br><span class="line">    pure_balance = pure_balance[(pure_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,<span class="number">3</span>,<span class="number">1</span>)) &amp; (pure_balance[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>, month_index, <span class="number">1</span>))]</span><br><span class="line">    pure_balance[<span class="string">'weekday'</span>] = pure_balance[<span class="string">'date'</span>].dt.weekday</span><br><span class="line">    pure_balance[<span class="string">'day'</span>] = pure_balance[<span class="string">'date'</span>].dt.day</span><br><span class="line">    pure_balance[<span class="string">'week'</span>] = pure_balance[<span class="string">'date'</span>].dt.week</span><br><span class="line">    pure_balance[<span class="string">'month'</span>] = pure_balance[<span class="string">'date'</span>].dt.month</span><br><span class="line">    weekday_rate = pure_balance[[<span class="string">'weekday'</span>]+labels].groupby(<span class="string">'weekday'</span>,as_index=<span class="literal">False</span>).mean()</span><br><span class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> labels:</span><br><span class="line">        weekday_rate = weekday_rate.rename(columns=&#123;name: name+<span class="string">'_weekdaymean'</span>&#125;)</span><br><span class="line">    weekday_rate[<span class="string">'total_purchase_amt_weekdaymean'</span>] /= np.mean(pure_balance[<span class="string">'total_purchase_amt'</span>])</span><br><span class="line">    weekday_rate[<span class="string">'total_redeem_amt_weekdaymean'</span>] /= np.mean(pure_balance[<span class="string">'total_redeem_amt'</span>])</span><br><span class="line">    pure_balance = pd.merge(pure_balance, weekday_rate, on=<span class="string">'weekday'</span>, how=<span class="string">'left'</span>)</span><br><span class="line">    weekday_count = pure_balance[[<span class="string">'day'</span>,<span class="string">'weekday'</span>,<span class="string">'date'</span>]].groupby([<span class="string">'day'</span>,<span class="string">'weekday'</span>],as_index=<span class="literal">False</span>).count()</span><br><span class="line">    weekday_count = pd.merge(weekday_count, weekday_rate, on = <span class="string">'weekday'</span>)</span><br><span class="line">    weekday_count[<span class="string">'total_purchase_amt_weekdaymean'</span>] *= weekday_count[<span class="string">'date'</span>] / (len(set(pure_balance[<span class="string">'month'</span>])) - <span class="number">1</span>)</span><br><span class="line">    weekday_count[<span class="string">'total_redeem_amt_weekdaymean'</span>] *= weekday_count[<span class="string">'date'</span>] / (len(set(pure_balance[<span class="string">'month'</span>])) - <span class="number">1</span>)</span><br><span class="line">    day_rate = weekday_count.drop([<span class="string">'weekday'</span>,<span class="string">'date'</span>],axis=<span class="number">1</span>).groupby(<span class="string">'day'</span>,as_index=<span class="literal">False</span>).sum()</span><br><span class="line">    weekday_rate.columns = [<span class="string">'weekday'</span>,<span class="string">'purchase_weekdayrate'</span>,<span class="string">'redeem_weekdayrate'</span>]</span><br><span class="line">    day_rate.columns = [<span class="string">'day'</span>,<span class="string">'purchase_dayrate'</span>,<span class="string">'redeem_dayrate'</span>]</span><br><span class="line">    day_rate[<span class="string">'date'</span>] = datetime.datetime(<span class="number">2014</span>, month_index, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> day_rate.iterrows():</span><br><span class="line">        <span class="keyword">if</span> month_index <span class="keyword">in</span> (<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">9</span>) <span class="keyword">and</span> row[<span class="string">'day'</span>] == <span class="number">31</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        day_rate.loc[index, <span class="string">'date'</span>] = datetime.datetime(<span class="number">2014</span>, month_index, int(row[<span class="string">'day'</span>]))</span><br><span class="line">    day_rate[<span class="string">'weekday'</span>] = day_rate[<span class="string">'date'</span>].dt.weekday</span><br><span class="line">    day_rate = pd.merge(day_rate, weekday_rate, on=<span class="string">'weekday'</span>)</span><br><span class="line">    day_rate[<span class="string">'purchase_dayrate'</span>] = day_rate[<span class="string">'purchase_weekdayrate'</span>] / day_rate[<span class="string">'purchase_dayrate'</span>]</span><br><span class="line">    day_rate[<span class="string">'redeem_dayrate'</span>] = day_rate[<span class="string">'redeem_weekdayrate'</span>] / day_rate[<span class="string">'redeem_dayrate'</span>]</span><br><span class="line">    weekday_rate[<span class="string">'month'</span>] = month_index</span><br><span class="line">    day_rate[<span class="string">'month'</span>] = month_index</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> weekday_rate, day_rate[[<span class="string">'day'</span>,<span class="string">'purchase_dayrate'</span>,<span class="string">'redeem_dayrate'</span>,<span class="string">'month'</span>]].sort_values(<span class="string">'day'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生成周期因子并合并到数据集</span></span><br><span class="line"></span><br><span class="line">weekday_rate_list = []</span><br><span class="line">day_rate_list = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>, <span class="number">10</span>):</span><br><span class="line">    weekday_rate, day_rate = generate_rate(total_balance, i)</span><br><span class="line">    weekday_rate_list.append(weekday_rate.reset_index(drop=<span class="literal">True</span>))</span><br><span class="line">    day_rate_list.append(day_rate.reset_index(drop=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">weekday_rate_list = pd.concat(weekday_rate_list).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">day_rate_list = pd.concat(day_rate_list).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">total_balance = pd.merge(total_balance, weekday_rate_list, on=[<span class="string">'weekday'</span>,<span class="string">'month'</span>], how=<span class="string">'left'</span>)</span><br><span class="line">total_balance = pd.merge(total_balance, day_rate_list, on=[<span class="string">'day'</span>,<span class="string">'month'</span>], how=<span class="string">'left'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对周期因子进行特殊处理</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> [x <span class="keyword">for</span> x <span class="keyword">in</span> total_balance.columns </span><br><span class="line">          <span class="keyword">if</span> <span class="string">'rate'</span> <span class="keyword">in</span> x <span class="keyword">and</span> x <span class="keyword">not</span> <span class="keyword">in</span> labels + date_indexs]:</span><br><span class="line">    total_balance[i] = total_balance[i].fillna(np.nanmedian(total_balance[i]))</span><br></pre></td></tr></table></figure>
<h3 id="4-2-分析周期因子的相关性"><a href="#4-2-分析周期因子的相关性" class="headerlink" title="4.2 分析周期因子的相关性"></a>4.2 分析周期因子的相关性</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 画出相关性图</span></span><br><span class="line"></span><br><span class="line">draw_correlation_heatmap(total_balance[[<span class="string">'total_purchase_amt'</span>] </span><br><span class="line">                                       + [x <span class="keyword">for</span> x <span class="keyword">in</span> total_balance.columns </span><br><span class="line">                                          <span class="keyword">if</span> <span class="string">'rate'</span> <span class="keyword">in</span> x <span class="keyword">and</span> x <span class="keyword">not</span> <span class="keyword">in</span> labels + date_indexs]])</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/05.%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/output_54_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 剔除相关性低的特征</span></span><br><span class="line"></span><br><span class="line">feature = total_balance.drop(date_indexs, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h2 id="五、加入动态时序特征"><a href="#五、加入动态时序特征" class="headerlink" title="五、加入动态时序特征"></a>五、加入动态时序特征</h2><h3 id="5-1-提取动态特征"><a href="#5-1-提取动态特征" class="headerlink" title="5.1 提取动态特征"></a>5.1 提取动态特征</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 提取动态特征</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_amtfeature_with_time</span><span class="params">(data: pd.DataFrame)</span>-&gt;pd.DataFrame:</span></span><br><span class="line">    df_tmp_ = data[labels + date_indexs + [<span class="string">'date'</span>]].copy()</span><br><span class="line">    total_balance = data.copy()</span><br><span class="line">    </span><br><span class="line">    df_tmp_ = df_tmp_[(df_tmp_[<span class="string">'date'</span>]&gt;=datetime.date(<span class="number">2014</span>,<span class="number">3</span>,<span class="number">3</span>))]</span><br><span class="line">    df_tmp_[<span class="string">'weekday'</span>] = df_tmp_[<span class="string">'date'</span>].dt.weekday + <span class="number">1</span></span><br><span class="line">    df_tmp_[<span class="string">'week'</span>] = df_tmp_[<span class="string">'date'</span>].dt.week - min(df_tmp_[<span class="string">'date'</span>].dt.week) + <span class="number">1</span></span><br><span class="line">    df_tmp_[<span class="string">'day'</span>] = df_tmp_[<span class="string">'date'</span>].dt.day</span><br><span class="line">    df_tmp_[<span class="string">'month'</span>] = df_tmp_[<span class="string">'date'</span>].dt.month</span><br><span class="line">    df_tmp_.reset_index(inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">del</span> df_tmp_[<span class="string">'index'</span>]</span><br><span class="line">    df_purchase = pd.DataFrame(columns = [<span class="string">'weekday1'</span>,<span class="string">'weekday2'</span>,<span class="string">'weekday3'</span>,<span class="string">'weekday4'</span>,</span><br><span class="line">                                          <span class="string">'weekday5'</span>,<span class="string">'weekday6'</span>,<span class="string">'weekday7'</span>])</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(df_tmp_)):</span><br><span class="line">        df_purchase.loc[count,<span class="string">'weekday'</span>+str(df_tmp_.loc[i,<span class="string">'weekday'</span>])] = df_tmp_.loc[i,<span class="string">'total_purchase_amt'</span>]</span><br><span class="line">        <span class="keyword">if</span> df_tmp_.loc[i,<span class="string">'weekday'</span>] == <span class="number">7</span>:</span><br><span class="line">            count = count + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    df_tmp_[<span class="string">'purchase_weekday_median'</span>] = np.nan</span><br><span class="line">    df_tmp_[<span class="string">'purchase_weekday_mean'</span>] = np.nan</span><br><span class="line">    df_tmp_[<span class="string">'purchase_weekday_min'</span>] = np.nan</span><br><span class="line">    df_tmp_[<span class="string">'purchase_weekday_max'</span>] = np.nan</span><br><span class="line">    df_tmp_[<span class="string">'purchase_weekday_std'</span>] = np.nan</span><br><span class="line">    df_tmp_[<span class="string">'purchase_weekday_skew'</span>] = np.nan</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(df_tmp_)):</span><br><span class="line">        <span class="comment">#从2014年3月31日开始统计</span></span><br><span class="line">        <span class="keyword">if</span> i &gt; <span class="number">4</span>*<span class="number">7</span><span class="number">-1</span>:</span><br><span class="line">            df_tmp_.loc[i,<span class="string">'purchase_weekday_median'</span>] = df_purchase.loc[:df_tmp_.loc[i,<span class="string">'week'</span>]<span class="number">-2</span>,</span><br><span class="line">                                          <span class="string">'weekday'</span>+str(df_tmp_.loc[i,<span class="string">'weekday'</span>])].median()</span><br><span class="line"></span><br><span class="line">            df_tmp_.loc[i,<span class="string">'purchase_weekday_mean'</span>] = df_purchase.loc[:df_tmp_.loc[i,<span class="string">'week'</span>]<span class="number">-2</span>,</span><br><span class="line">                                          <span class="string">'weekday'</span>+str(df_tmp_.loc[i,<span class="string">'weekday'</span>])].mean()</span><br><span class="line"></span><br><span class="line">            df_tmp_.loc[i,<span class="string">'purchase_weekday_min'</span>] = df_purchase.loc[:df_tmp_.loc[i,<span class="string">'week'</span>]<span class="number">-2</span>,</span><br><span class="line">                                          <span class="string">'weekday'</span>+str(df_tmp_.loc[i,<span class="string">'weekday'</span>])].min()    </span><br><span class="line"></span><br><span class="line">            df_tmp_.loc[i,<span class="string">'purchase_weekday_max'</span>] = df_purchase.loc[:df_tmp_.loc[i,<span class="string">'week'</span>]<span class="number">-2</span>,</span><br><span class="line">                                          <span class="string">'weekday'</span>+str(df_tmp_.loc[i,<span class="string">'weekday'</span>])].max()   </span><br><span class="line"></span><br><span class="line">            df_tmp_.loc[i,<span class="string">'purchase_weekday_std'</span>] = df_purchase.loc[:df_tmp_.loc[i,<span class="string">'week'</span>]<span class="number">-2</span>,</span><br><span class="line">                                          <span class="string">'weekday'</span>+str(df_tmp_.loc[i,<span class="string">'weekday'</span>])].std() </span><br><span class="line"></span><br><span class="line">            df_tmp_.loc[i,<span class="string">'purchase_weekday_skew'</span>] = df_purchase.loc[:df_tmp_.loc[i,<span class="string">'week'</span>]<span class="number">-2</span>,</span><br><span class="line">                                          <span class="string">'weekday'</span>+str(df_tmp_.loc[i,<span class="string">'weekday'</span>])].skew() </span><br><span class="line"></span><br><span class="line">    colList = [<span class="string">'purchase_weekday_median'</span>,<span class="string">'purchase_weekday_mean'</span>,<span class="string">'purchase_weekday_min'</span>,</span><br><span class="line">               <span class="string">'purchase_weekday_max'</span>,<span class="string">'purchase_weekday_std'</span>,<span class="string">'purchase_weekday_skew'</span>]</span><br><span class="line">    total_balance = pd.merge(total_balance, df_tmp_[colList+[<span class="string">'day'</span>,<span class="string">'month'</span>]], on=[<span class="string">'day'</span>,<span class="string">'month'</span>], how=<span class="string">'left'</span>)</span><br><span class="line">    <span class="keyword">return</span> total_balance</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 合并特征到数据集</span></span><br><span class="line"></span><br><span class="line">total_balance = get_amtfeature_with_time(total_balance)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对动态特征做特殊处理</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> [x <span class="keyword">for</span> x <span class="keyword">in</span> total_balance.columns </span><br><span class="line">          <span class="keyword">if</span> <span class="string">'_weekday_'</span> <span class="keyword">in</span> x <span class="keyword">and</span> x <span class="keyword">not</span> <span class="keyword">in</span> labels + date_indexs]:</span><br><span class="line">    total_balance[i] = total_balance[i].fillna(np.nanmedian(total_balance[i]))</span><br></pre></td></tr></table></figure>
<h3 id="5-2-分析动态特征相关性"><a href="#5-2-分析动态特征相关性" class="headerlink" title="5.2 分析动态特征相关性"></a>5.2 分析动态特征相关性</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 绘制动态特征的相关性图</span></span><br><span class="line"></span><br><span class="line">draw_correlation_heatmap(total_balance[[<span class="string">'total_purchase_amt'</span>] + </span><br><span class="line">                                      [<span class="string">'purchase_weekday_median'</span>,</span><br><span class="line">                                      <span class="string">'purchase_weekday_mean'</span>,<span class="string">'purchase_weekday_min'</span>,</span><br><span class="line">                                       <span class="string">'purchase_weekday_max'</span>,<span class="string">'purchase_weekday_std'</span>,</span><br><span class="line">                                       <span class="string">'purchase_weekday_skew'</span></span><br><span class="line">                                      ]])</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/05.%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/output_62_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">feature[labels + [<span class="string">'dis_to_nowork'</span>, <span class="string">'dis_to_work'</span>, <span class="string">'dis_from_work'</span>, <span class="string">'purchase_weekdayrate'</span>,</span><br><span class="line">       <span class="string">'redeem_dayrate'</span>, <span class="string">'weekday_onehot_5'</span>, <span class="string">'weekday_onehot_6'</span>,</span><br><span class="line">       <span class="string">'dis_from_nowork'</span>, <span class="string">'is_holiday'</span>, <span class="string">'weekday_onehot_1'</span>, <span class="string">'weekday_onehot_2'</span>,</span><br><span class="line">       <span class="string">'weekday_onehot_0'</span>, <span class="string">'dis_from_middleofweek'</span>, <span class="string">'dis_from_holiendday'</span>,</span><br><span class="line">       <span class="string">'weekday_onehot_3'</span>, <span class="string">'is_lastday_of_holiday'</span>, <span class="string">'is_firstday_of_holiday'</span>,</span><br><span class="line">       <span class="string">'weekday_onehot_4'</span>, <span class="string">'is_worked_yestday'</span>, <span class="string">'is_second_week'</span>,</span><br><span class="line">       <span class="string">'is_third_week'</span>, <span class="string">'dis_from_startofmonth'</span>, <span class="string">'dis_from_holiday'</span>, <span class="string">'total_purchase_amt'</span>,</span><br><span class="line">       <span class="string">'total_redeem_amt'</span>, <span class="string">'date'</span>]].to_csv(<span class="string">'Feature/0615_residual_purchase_origined.csv'</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<h1 id="特征劣汰剔除"><a href="#特征劣汰剔除" class="headerlink" title="特征劣汰剔除"></a>特征劣汰剔除</h1><h3 id="1-1-剔除无法有效分割数据集的特征"><a href="#1-1-剔除无法有效分割数据集的特征" class="headerlink" title="1.1 剔除无法有效分割数据集的特征"></a>1.1 剔除无法有效分割数据集的特征</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 画出各个特征分割数据集的分布估计图</span></span><br><span class="line">plt.figure(figsize=(<span class="number">4</span> * <span class="number">6</span>, <span class="number">6</span> * len(feature.columns) / <span class="number">6</span>))</span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> [x <span class="keyword">for</span> x <span class="keyword">in</span> feature.columns </span><br><span class="line">          <span class="keyword">if</span> (x <span class="keyword">not</span> <span class="keyword">in</span> labels + date_indexs + [<span class="string">'date'</span>]) </span><br><span class="line">          &amp; (<span class="string">'amt'</span> <span class="keyword">not</span> <span class="keyword">in</span> x) &amp; (<span class="string">'dis'</span> <span class="keyword">not</span> <span class="keyword">in</span> x) &amp; (<span class="string">'rate'</span> <span class="keyword">not</span> <span class="keyword">in</span> x)]:</span><br><span class="line">    count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> feature[feature[i] == <span class="number">0</span>].empty:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    plt.subplot(len(feature.columns) / <span class="number">4</span>, <span class="number">4</span>, count)</span><br><span class="line">    </span><br><span class="line">    ax = sns.kdeplot(feature[feature[i] == <span class="number">0</span>][<span class="string">'total_purchase_amt'</span>], label= str(i) + <span class="string">' == 0, purchase'</span>)</span><br><span class="line">    ax = sns.kdeplot(feature[feature[i] == <span class="number">1</span>][<span class="string">'total_purchase_amt'</span>], label= str(i) + <span class="string">' == 1, purchase'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/05.%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/output_66_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 剔除对数据集划分不明显的特征</span></span><br><span class="line"></span><br><span class="line">purchase_feature_seems_useless += [<span class="string">'is_gonna_work_tomorrow'</span>,<span class="string">'is_fourth_week'</span>,<span class="string">'weekday_onehot_4'</span>]</span><br></pre></td></tr></table></figure>
<h3 id="1-2-使用MVTest挽回一些有依赖性但是不相关的特征"><a href="#1-2-使用MVTest挽回一些有依赖性但是不相关的特征" class="headerlink" title="1.2 使用MVTest挽回一些有依赖性但是不相关的特征"></a>1.2 使用MVTest挽回一些有依赖性但是不相关的特征</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">feature_low_correlation</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[<span class="string">'is_firstday_of_work'</span>, <span class="string">'is_midmonth'</span>, <span class="string">'is_first_week'</span>, <span class="string">'is_lastday_of_workday'</span>, <span class="string">'weekday_onehot_3'</span>, <span class="string">'is_work_on_sunday'</span>, <span class="string">'is_gonna_work_tomorrow'</span>, <span class="string">'is_second_week'</span>, <span class="string">'is_secday_of_month'</span>, <span class="string">'is_worked_yestday'</span>, <span class="string">'weekday_onehot_1'</span>, <span class="string">'is_firstday_of_month'</span>, <span class="string">'weekday_onehot_2'</span>, <span class="string">'weekday_onehot_4'</span>, <span class="string">'weekday_onehot_5'</span>, <span class="string">'weekday_onehot_0'</span>, <span class="string">'weekday_onehot_6'</span>, <span class="string">'is_weekend'</span>, <span class="string">'dis_from_endofweek'</span>, <span class="string">'dis_from_middleofmonth'</span>, <span class="string">'dis_to_nowork'</span>, <span class="string">'dis_from_middleofweek'</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># MVtest Ref: https://github.com/ChuanyuXue/MVTest</span></span><br><span class="line"></span><br><span class="line">l = mvtest.mvtest()</span><br><span class="line"></span><br><span class="line">name_list = []</span><br><span class="line">Tn_list = []</span><br><span class="line">p_list = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> [i <span class="keyword">for</span> i <span class="keyword">in</span> feature_low_correlation <span class="keyword">if</span> <span class="string">'is'</span> <span class="keyword">in</span> i <span class="keyword">or</span> <span class="string">'discret'</span> <span class="keyword">in</span> i]:</span><br><span class="line">    pair = l.test(feature[<span class="string">'total_purchase_amt'</span>], feature[i])</span><br><span class="line">    name_list.append(str(i))</span><br><span class="line">    Tn_list.append(pair[<span class="string">'Tn'</span>])</span><br><span class="line">    p_list.append(pair[<span class="string">'p-value'</span>][<span class="number">0</span>])</span><br><span class="line">temp = pd.DataFrame([name_list,Tn_list]).T.sort_values(<span class="number">1</span>)</span><br><span class="line">temp[<span class="number">1</span>] = np.abs(temp[<span class="number">1</span>])</span><br><span class="line">feature_saved_from_mv_purchase = list(temp.sort_values(<span class="number">1</span>, ascending=<span class="literal">False</span>)[temp[<span class="number">1</span>] &gt; <span class="number">0.5984</span>][<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<h3 id="1-3-剔除复共线特征"><a href="#1-3-剔除复共线特征" class="headerlink" title="1.3 剔除复共线特征"></a>1.3 剔除复共线特征</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">feature = feature[[x <span class="keyword">for</span> x <span class="keyword">in</span> feature.columns </span><br><span class="line">                   <span class="keyword">if</span> (x <span class="keyword">not</span> <span class="keyword">in</span> feature_low_correlation + purchase_feature_seems_useless) <span class="keyword">or</span>\</span><br><span class="line">                   (x <span class="keyword">in</span> feature_saved_from_mv_purchase )]]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">purchase_cors = feature.corr()</span><br><span class="line">purchase_cors[<span class="string">'total_purchase_amt'</span>] = np.abs(purchase_cors[<span class="string">'total_purchase_amt'</span>])</span><br><span class="line">feature_lists = list(purchase_cors.sort_values(by=<span class="string">'total_purchase_amt'</span>,ascending=<span class="literal">False</span>).index)[<span class="number">2</span>:]</span><br><span class="line">feature_temp = feature.dropna()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 这里要注意 保留的时候按照相关性降序排序 剔除按照相关性升序排序的顺序</span></span><br><span class="line">thershold = <span class="number">0.8</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(feature_lists)):</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(len(feature_lists)<span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>):</span><br><span class="line">        <span class="keyword">if</span> i &gt;= len(feature_lists) <span class="keyword">or</span> k &gt;= len(feature_lists) <span class="keyword">or</span> i == k:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">if</span> np.abs(np.corrcoef(feature_temp[feature_lists[i]], feature_temp[feature_lists[k]])[<span class="number">0</span>][<span class="number">1</span>]) &gt; thershold:</span><br><span class="line">            higher_feature_temp = feature_temp[feature_lists[i]] * feature_temp[feature_lists[k]]</span><br><span class="line">            <span class="keyword">if</span> np.abs(np.corrcoef(feature_temp[feature_lists[i]], higher_feature_temp)[<span class="number">0</span>][<span class="number">1</span>]) &lt;= thershold:</span><br><span class="line">                name = str(feature_lists[i]) + <span class="string">'%%%%'</span> + str(feature_lists[k])</span><br><span class="line">                feature_temp[name] = higher_feature_temp</span><br><span class="line">                feature[name] = feature[feature_lists[i]] * feature[feature_lists[k]]</span><br><span class="line">                feature_lists.append(name)</span><br><span class="line">            feature_temp = feature_temp.drop(feature_lists[k], axis=<span class="number">1</span>)</span><br><span class="line">            feature_lists.remove(feature_lists[k])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">feature = feature[[x <span class="keyword">for</span> x <span class="keyword">in</span> feature_lists <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> labels] + labels + [<span class="string">'date'</span>]]</span><br><span class="line">feature_lists</span><br><span class="line"><span class="comment"># ['dis_from_holiday', 'is_holiday', 'dis_to_work', 'dis_from_work', 'dis_from_holiendday', #'dis_from_nowork', 'is_firstday_of_holiday', 'is_tailmonth', 'is_premonth', 'is_lastday_of_holiday', #'is_third_week', 'is_work', 'dis_to_nowork', 'redeem_weekdayrate', 'redeem_dayrate', #'dis_from_purchase_peak', 'purchase_dayrate', 'purchase_weekdayrate', 'is_holiday%%%%dis_to_holiendday']</span></span><br><span class="line">feature.to_csv(<span class="string">'Feature/purchase_feature_droped_0614.csv'</span>,index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<h1 id="选出优胜特征"><a href="#选出优胜特征" class="headerlink" title="选出优胜特征"></a>选出优胜特征</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 分割数据集</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_data_underline</span><span class="params">(data)</span>:</span></span><br><span class="line">    trainset = data[(datetime.date(<span class="number">2014</span>,<span class="number">4</span>,<span class="number">1</span>) &lt;= data[<span class="string">'date'</span>]) &amp; (data[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>,<span class="number">8</span>,<span class="number">1</span>))]</span><br><span class="line">    testset = data[(datetime.date(<span class="number">2014</span>,<span class="number">8</span>,<span class="number">1</span>) &lt;= data[<span class="string">'date'</span>]) &amp; (data[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>,<span class="number">9</span>,<span class="number">1</span>))]</span><br><span class="line">    <span class="keyword">return</span> trainset, testset</span><br></pre></td></tr></table></figure>
<h3 id="1-1-使用SHAP包获取优胜特征"><a href="#1-1-使用SHAP包获取优胜特征" class="headerlink" title="1.1 使用SHAP包获取优胜特征"></a>1.1 使用SHAP包获取优胜特征</h3><blockquote>
<p>SHAP testues represent the fair score of features depending on their contribution towards the total score in the set of features.</p>
<p>SHAP also can visualize how the score changes when the feature testue is low/high on each data.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">shap.initjs()</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line">model = tree.DecisionTreeRegressor()</span><br><span class="line">train, test = split_data_underline(feature.dropna())</span><br><span class="line">features = [x <span class="keyword">for</span> x <span class="keyword">in</span> train.columns <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> date_indexs]</span><br><span class="line">model.fit(train[features].drop(labels+[<span class="string">'date'</span>], axis=<span class="number">1</span>), train[<span class="string">'total_purchase_amt'</span>])</span><br><span class="line"></span><br><span class="line">explainer = shap.TreeExplainer(model)</span><br><span class="line">shap_testues = explainer.shap_values(test[features].drop(labels+[<span class="string">'date'</span>], axis=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">shap.summary_plot(shap_testues, test[features].drop(labels+[<span class="string">'date'</span>], axis=<span class="number">1</span>), plot_type=<span class="string">'bar'</span>)</span><br><span class="line"></span><br><span class="line">shap.summary_plot(shap_testues, test[features].drop(labels+[<span class="string">'date'</span>], axis=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">tree_important_purchase = pd.DataFrame(np.mean(np.abs(shap_testues), axis=<span class="number">0</span>),[x <span class="keyword">for</span> x <span class="keyword">in</span> features <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> labels + date_indexs + [<span class="string">'date'</span>]]).reset_index()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/05.%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/output_81_1.png" alt="png"></p>
<p><img src="/Pic/05.%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/output_81_2.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tree_important_purchase = tree_important_purchase.sort_values(<span class="number">0</span>, ascending=<span class="literal">False</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">tree_important_purchase = list(tree_important_purchase[:<span class="number">20</span>][<span class="string">'index'</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tree_important_purchase</span><br><span class="line"></span><br><span class="line">[<span class="string">'redeem_weekdayrate'</span>, <span class="string">'is_tailmonth'</span>, <span class="string">'dis_to_nowork'</span>, <span class="string">'redeem_dayrate'</span>, <span class="string">'is_holiday'</span>, <span class="string">'is_third_week'</span>, <span class="string">'dis_from_nowork'</span>, <span class="string">'is_premonth'</span>, <span class="string">'purchase_weekdayrate'</span>, <span class="string">'dis_from_holiendday'</span>, <span class="string">'purchase_dayrate'</span>, <span class="string">'dis_from_purchase_peak'</span>, <span class="string">'dis_from_holiday'</span>, <span class="string">'dis_to_work'</span>, <span class="string">'dis_from_work'</span>, <span class="string">'is_firstday_of_holiday'</span>, <span class="string">'is_work'</span>, <span class="string">'is_lastday_of_holiday'</span>, <span class="string">'is_holiday%%%%dis_to_holiendday'</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 输出选择的特征</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw_cloud</span><span class="params">(feature_index: List[str])</span>-&gt;<span class="keyword">None</span>:</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">20</span>,<span class="number">10</span>))</span><br><span class="line">    plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">    ciyun = WordCloud(background_color=<span class="string">'white'</span>, max_font_size=<span class="number">40</span>)</span><br><span class="line">    ciyun.generate(text=<span class="string">''</span>.join([x+<span class="string">' '</span> <span class="keyword">for</span> x <span class="keyword">in</span> feature_index <span class="keyword">if</span> x != <span class="string">'total_purchase_amt'</span>]))</span><br><span class="line">    plt.imshow(ciyun, interpolation=<span class="string">'bilinear'</span>)</span><br><span class="line">    plt.axis(<span class="string">"off"</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">draw_cloud(tree_important_purchase)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/05.%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/output_85_0.png" alt="png"></p>
<h3 id="1-2-使用Permutation-importance包获取优胜特征"><a href="#1-2-使用Permutation-importance包获取优胜特征" class="headerlink" title="1.2 使用Permutation importance包获取优胜特征"></a>1.2 使用Permutation importance包获取优胜特征</h3><blockquote>
<p>SHAP testues represent the fair score of features depending on their contribution towards the total score in the set of features.</p>
<p>SHAP also can visualize how the score changes when the feature testue is low/high on each data.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = LinearRegression()</span><br><span class="line">train, test = split_data_underline(feature.dropna())</span><br><span class="line">model.fit(train[features].drop(labels+[<span class="string">'date'</span>], axis=<span class="number">1</span>), train[<span class="string">'total_purchase_amt'</span>])</span><br><span class="line">perm = PermutationImportance(model, random_state=<span class="number">42</span>).fit(test[features].drop(labels+[<span class="string">'date'</span>], axis=<span class="number">1</span>), test[<span class="string">'total_purchase_amt'</span>])</span><br><span class="line">liner_important_purchase = pd.DataFrame(np.abs(perm.feature_importances_), [x <span class="keyword">for</span> x <span class="keyword">in</span> features <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> labels + date_indexs + [<span class="string">'date'</span>]]).reset_index()</span><br><span class="line">eli5.show_weights(perm, feature_names=list(str(x) <span class="keyword">for</span> x <span class="keyword">in</span> features <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> labels + [<span class="string">'date'</span>]))</span><br></pre></td></tr></table></figure>
<div class="table-container">
<table>
<thead>
<tr>
<th>Weight</th>
<th>Feature</th>
</tr>
</thead>
<tbody>
<tr>
<td>0.6421 ± 0.4380</td>
<td>dis_from_purchase_peak</td>
</tr>
<tr>
<td>0.1845 ± 0.1237</td>
<td>dis_from_work</td>
</tr>
<tr>
<td>0.1060 ± 0.0879</td>
<td>is_third_week</td>
</tr>
<tr>
<td>0.0883 ± 0.1364</td>
<td>is_tailmonth</td>
</tr>
<tr>
<td>0.0276 ± 0.1358</td>
<td>dis_to_nowork</td>
</tr>
<tr>
<td>0.0230 ± 0.0970</td>
<td>purchase_dayrate</td>
</tr>
<tr>
<td>0.0063 ± 0.0503</td>
<td>dis_from_nowork</td>
</tr>
<tr>
<td>0.0051 ± 0.0319</td>
<td>redeem_weekdayrate</td>
</tr>
<tr>
<td>0.0033 ± 0.0108</td>
<td>is_work</td>
</tr>
<tr>
<td>0 ± 0.0000</td>
<td>is_holiday dis_to_holiendday</td>
</tr>
<tr>
<td>0 ± 0.0000</td>
<td>is_holiday</td>
</tr>
<tr>
<td>0 ± 0.0000</td>
<td>dis_from_holiendday</td>
</tr>
<tr>
<td>0 ± 0.0000</td>
<td>is_lastday_of_holiday</td>
</tr>
<tr>
<td>0 ± 0.0000</td>
<td>is_firstday_of_holiday</td>
</tr>
<tr>
<td>0 ± 0.0000</td>
<td>dis_from_holiday</td>
</tr>
<tr>
<td>-0.0002 ± 0.0078</td>
<td>is_premonth</td>
</tr>
<tr>
<td>-0.0164 ± 0.0222</td>
<td>dis_to_work</td>
</tr>
<tr>
<td>-0.0323 ± 0.0480</td>
<td>redeem_dayrate</td>
</tr>
<tr>
<td>-0.0325 ± 0.0732</td>
<td>purchase_weekdayrate</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">liner_important_purchase = liner_important_purchase.sort_values(<span class="number">0</span>, ascending=<span class="literal">False</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">liner_important_purchase = list(liner_important_purchase[:<span class="number">20</span>][<span class="string">'index'</span>])</span><br><span class="line">draw_cloud(liner_important_purchase)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/05.%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/output_89_0.png" alt="png"></p>
<h3 id="1-3-量特征集合取交集选出最终优胜特征"><a href="#1-3-量特征集合取交集选出最终优胜特征" class="headerlink" title="1.3 量特征集合取交集选出最终优胜特征"></a>1.3 量特征集合取交集选出最终优胜特征</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">winer_features_purchase = list(set(tree_important_purchase)\</span><br><span class="line">                     &amp; set(liner_important_purchase))</span><br><span class="line">draw_cloud(winer_features_purchase)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/05.%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/output_92_0.png" alt="png"></p>
]]></content>
      <categories>
        <category>Match</category>
      </categories>
  </entry>
  <entry>
    <title>资金流入流出预测比赛（三）</title>
    <url>/posts/d75642fc.html</url>
    <content><![CDATA[<p>本文涉及内容为时间序列规则，参考链接为<a href="https://github.com/datawhalechina/team-learning-data-mining/tree/master/PurchaseAndRedemptionForecast" target="_blank" rel="noopener">Datawhale 资金流入流出学习内容</a></p>
<p>首先导入相应的包：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> sklearn <span class="keyword">as</span> skr</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> dateutil.relativedelta <span class="keyword">import</span> relativedelta</span><br></pre></td></tr></table></figure>
<p>然后我们将前面做的时间特征提取打包成函数，这个函数可以将时间信息提取出day、month等更方便使用的信息：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_timestamp</span><span class="params">(data: pd.DataFrame, time_index: str = <span class="string">'report_date'</span>)</span>-&gt;pd.DataFrame:</span></span><br><span class="line">    data_balance = data.copy()</span><br><span class="line">    data_balance[<span class="string">'date'</span>] = pd.to_datetime(data_balance[time_index], format= <span class="string">"%Y%m%d"</span>)</span><br><span class="line">    data_balance[<span class="string">'day'</span>] = data_balance[<span class="string">'date'</span>].dt.day</span><br><span class="line">    data_balance[<span class="string">'month'</span>] = data_balance[<span class="string">'date'</span>].dt.month</span><br><span class="line">    data_balance[<span class="string">'year'</span>] = data_balance[<span class="string">'date'</span>].dt.year</span><br><span class="line">    data_balance[<span class="string">'week'</span>] = data_balance[<span class="string">'date'</span>].dt.week</span><br><span class="line">    data_balance[<span class="string">'weekday'</span>] = data_balance[<span class="string">'date'</span>].dt.weekday</span><br><span class="line">    <span class="keyword">return</span> data_balance.reset_index(drop=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>定义一个load_data函数，在读取文件的同时会将时间信息传入上面的函数得到提取过时间特征之后的DataFrame：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span><span class="params">(path: str = <span class="string">'user_balance_table.csv'</span>)</span>-&gt;pd.DataFrame:</span></span><br><span class="line">    data_balance = pd.read_csv(path)</span><br><span class="line">    data_balance = add_timestamp(data_balance)</span><br><span class="line">    <span class="keyword">return</span> data_balance.reset_index(drop=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>将前面使用到的提取的total_purchase_amt和total_redeem_amt信息也封装成函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_total_balance</span><span class="params">(data: pd.DataFrame, date: str = <span class="string">'2014-03-31'</span>)</span>-&gt;pd.DataFrame:</span></span><br><span class="line">    df_tmp = data.copy()</span><br><span class="line">    df_tmp = df_tmp.groupby([<span class="string">'date'</span>])[<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>].sum()</span><br><span class="line">    df_tmp.reset_index(inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> df_tmp[(df_tmp[<span class="string">'date'</span>]&gt;= date)].reset_index(drop=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>将生成测试集封装成函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_test_data</span><span class="params">(data: pd.DataFrame)</span>-&gt;pd.DataFrame:</span></span><br><span class="line">    total_balance = data.copy()</span><br><span class="line">    start = datetime.datetime(<span class="number">2014</span>,<span class="number">9</span>,<span class="number">1</span>)</span><br><span class="line">    testdata = []</span><br><span class="line">    <span class="keyword">while</span> start != datetime.datetime(<span class="number">2014</span>,<span class="number">10</span>,<span class="number">15</span>):</span><br><span class="line">        temp = [start, np.nan, np.nan]</span><br><span class="line">        testdata.append(temp)</span><br><span class="line">        start += datetime.timedelta(days = <span class="number">1</span>)</span><br><span class="line">    testdata = pd.DataFrame(testdata)</span><br><span class="line">    testdata.columns = total_balance.columns</span><br><span class="line"></span><br><span class="line">    total_balance = pd.concat([total_balance, testdata], axis = <span class="number">0</span>)</span><br><span class="line">    total_balance = total_balance.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> total_balance.reset_index(drop=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>最后定义一个导入用户信息的函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_user_information</span><span class="params">(path: str = <span class="string">'user_profile_table.csv'</span>)</span>-&gt;pd.DataFrame:</span></span><br><span class="line">    <span class="keyword">return</span> pd.read_csv(path)</span><br></pre></td></tr></table></figure>
<p>下面可以使用前面封装好的函数对数据进行如<a href="https://chenk.tech/posts/94fccd43.html" target="_blank" rel="noopener">资金流入流出预测比赛（一）</a>中进行的载入数据以及数据预处理：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">balance_data = load_data(<span class="string">'Dataset/user_balance_table.csv'</span>)</span><br><span class="line">balance_data = add_timestamp(balance_data)</span><br><span class="line">total_balance = get_total_balance(balance_data, date = <span class="string">'2014-03-01'</span>)</span><br><span class="line">total_balance = generate_test_data(total_balance)</span><br><span class="line">total_balance = add_timestamp(total_balance, <span class="string">'date'</span>)</span><br></pre></td></tr></table></figure>
<p>创建数据的深层拷贝：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = total_balance.copy()</span><br></pre></td></tr></table></figure>
<p>下面是比较重要的一步，定义生成时间序列规则预测结果的方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_base</span><span class="params">(df: pd.DataFrame, month_index: int)</span>-&gt;pd.DataFrame:</span></span><br><span class="line">    <span class="comment"># 选中固定时间段的数据集</span></span><br><span class="line">    total_balance = df.copy()</span><br><span class="line">    total_balance = total_balance[[<span class="string">'date'</span>,<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>]]</span><br><span class="line">    total_balance = total_balance[(total_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,<span class="number">3</span>,<span class="number">1</span>)) &amp; (total_balance[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>, month_index, <span class="number">1</span>))]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加入时间戳</span></span><br><span class="line">    total_balance[<span class="string">'weekday'</span>] = total_balance[<span class="string">'date'</span>].dt.weekday</span><br><span class="line">    total_balance[<span class="string">'day'</span>] = total_balance[<span class="string">'date'</span>].dt.day</span><br><span class="line">    total_balance[<span class="string">'week'</span>] = total_balance[<span class="string">'date'</span>].dt.week</span><br><span class="line">    total_balance[<span class="string">'month'</span>] = total_balance[<span class="string">'date'</span>].dt.month</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 统计翌日因子</span></span><br><span class="line">    mean_of_each_weekday = total_balance[[<span class="string">'weekday'</span>]+[<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>]].groupby(<span class="string">'weekday'</span>,as_index=<span class="literal">False</span>).mean()</span><br><span class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> [<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>]:</span><br><span class="line">        mean_of_each_weekday = mean_of_each_weekday.rename(columns=&#123;name: name+<span class="string">'_weekdaymean'</span>&#125;)</span><br><span class="line">    mean_of_each_weekday[<span class="string">'total_purchase_amt_weekdaymean'</span>] /= np.mean(total_balance[<span class="string">'total_purchase_amt'</span>])</span><br><span class="line">    mean_of_each_weekday[<span class="string">'total_redeem_amt_weekdaymean'</span>] /= np.mean(total_balance[<span class="string">'total_redeem_amt'</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 合并统计结果到原数据集</span></span><br><span class="line">    total_balance = pd.merge(total_balance, mean_of_each_weekday, on=<span class="string">'weekday'</span>, how=<span class="string">'left'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 分别统计翌日在(1~31)号出现的频次</span></span><br><span class="line">    weekday_count = total_balance[[<span class="string">'day'</span>,<span class="string">'weekday'</span>,<span class="string">'date'</span>]].groupby([<span class="string">'day'</span>,<span class="string">'weekday'</span>],as_index=<span class="literal">False</span>).count()</span><br><span class="line">    weekday_count = pd.merge(weekday_count, mean_of_each_weekday, on=<span class="string">'weekday'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 依据频次对翌日因子进行加权，获得日期因子</span></span><br><span class="line">    weekday_count[<span class="string">'total_purchase_amt_weekdaymean'</span>] *= weekday_count[<span class="string">'date'</span>]   / len(np.unique(total_balance[<span class="string">'month'</span>]))</span><br><span class="line">    weekday_count[<span class="string">'total_redeem_amt_weekdaymean'</span>] *= weekday_count[<span class="string">'date'</span>]  / len(np.unique(total_balance[<span class="string">'month'</span>]))</span><br><span class="line">    day_rate = weekday_count.drop([<span class="string">'weekday'</span>,<span class="string">'date'</span>],axis=<span class="number">1</span>).groupby(<span class="string">'day'</span>,as_index=<span class="literal">False</span>).sum()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将训练集中所有日期的均值剔除日期残差得到base</span></span><br><span class="line">    day_mean = total_balance[[<span class="string">'day'</span>] + [<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>]].groupby(<span class="string">'day'</span>,as_index=<span class="literal">False</span>).mean()</span><br><span class="line">    day_pre = pd.merge(day_mean, day_rate, on=<span class="string">'day'</span>, how=<span class="string">'left'</span>)</span><br><span class="line">    day_pre[<span class="string">'total_purchase_amt'</span>] /= day_pre[<span class="string">'total_purchase_amt_weekdaymean'</span>]</span><br><span class="line">    day_pre[<span class="string">'total_redeem_amt'</span>] /= day_pre[<span class="string">'total_redeem_amt_weekdaymean'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 生成测试集数据</span></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> day_pre.iterrows():</span><br><span class="line">        <span class="keyword">if</span> month_index <span class="keyword">in</span> (<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">9</span>) <span class="keyword">and</span> row[<span class="string">'day'</span>] == <span class="number">31</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        day_pre.loc[index, <span class="string">'date'</span>] = datetime.datetime(<span class="number">2014</span>, month_index, int(row[<span class="string">'day'</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 基于base与翌日因子获得最后的预测结果</span></span><br><span class="line">    day_pre[<span class="string">'weekday'</span>] = day_pre.date.dt.weekday</span><br><span class="line">    day_pre = day_pre[[<span class="string">'date'</span>,<span class="string">'weekday'</span>]+[<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>]]</span><br><span class="line">    day_pre = pd.merge(day_pre, mean_of_each_weekday,on=<span class="string">'weekday'</span>)</span><br><span class="line">    day_pre[<span class="string">'total_purchase_amt'</span>] *= day_pre[<span class="string">'total_purchase_amt_weekdaymean'</span>]</span><br><span class="line">    day_pre[<span class="string">'total_redeem_amt'</span>] *= day_pre[<span class="string">'total_redeem_amt_weekdaymean'</span>]</span><br><span class="line"></span><br><span class="line">    day_pre = day_pre.sort_values(<span class="string">'date'</span>)[[<span class="string">'date'</span>]+[<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>]]</span><br><span class="line">    <span class="keyword">return</span> day_pre</span><br></pre></td></tr></table></figure>
<p>结果是菜了点，后续我们将做进一步优化：</p>
<p><img src="/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B%EF%BC%88%E4%B8%89%EF%BC%89/output.png" alt></p>
]]></content>
      <categories>
        <category>Match</category>
      </categories>
  </entry>
  <entry>
    <title>资金流入流出预测比赛（二）</title>
    <url>/posts/cf4d8977.html</url>
    <content><![CDATA[<p><strong>This script is used for the online course “资金流入流出” in Tianchi platform</strong></p>
<p>注，此处所有的金额单位都是分，例如用户某日买入100万，代表其购买了1万</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span>  pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> warnings </span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Load the balance data</span></span><br><span class="line">data_balance = pd.read_csv(<span class="string">'Dataset/user_balance_table.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># add tiemstamp to dataset</span></span><br><span class="line">data_balance[<span class="string">'date'</span>] = pd.to_datetime(data_balance[<span class="string">'report_date'</span>], format= <span class="string">"%Y%m%d"</span>)</span><br><span class="line">data_balance[<span class="string">'day'</span>] = data_balance[<span class="string">'date'</span>].dt.day</span><br><span class="line">data_balance[<span class="string">'month'</span>] = data_balance[<span class="string">'date'</span>].dt.month</span><br><span class="line">data_balance[<span class="string">'year'</span>] = data_balance[<span class="string">'date'</span>].dt.year</span><br><span class="line">data_balance[<span class="string">'week'</span>] = data_balance[<span class="string">'date'</span>].dt.week</span><br><span class="line">data_balance[<span class="string">'weekday'</span>] = data_balance[<span class="string">'date'</span>].dt.weekday</span><br><span class="line"></span><br><span class="line"><span class="comment"># total amount</span></span><br><span class="line">total_balance = data_balance.groupby([<span class="string">'date'</span>])[<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>].sum()</span><br><span class="line">total_balance.reset_index(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add time stamp</span></span><br><span class="line">total_balance[<span class="string">'day'</span>] = total_balance[<span class="string">'date'</span>].dt.day</span><br><span class="line">total_balance[<span class="string">'month'</span>] = total_balance[<span class="string">'date'</span>].dt.month</span><br><span class="line">total_balance[<span class="string">'year'</span>] = total_balance[<span class="string">'date'</span>].dt.year</span><br><span class="line">total_balance[<span class="string">'week'</span>] = total_balance[<span class="string">'date'</span>].dt.week</span><br><span class="line">total_balance[<span class="string">'weekday'</span>] = total_balance[<span class="string">'date'</span>].dt.weekday</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load user's information</span></span><br><span class="line">users = pd.read_csv(<span class="string">'Dataset/user_profile_table.csv'</span>)</span><br></pre></td></tr></table></figure>
<h1 id="一、分析大小额用户"><a href="#一、分析大小额用户" class="headerlink" title="一、分析大小额用户"></a>一、分析大小额用户</h1><p>前面的分析可以看出，某些用户的交易额很大，对于日交易量很明显，这里统计四月份后依旧活跃的大额用户(大于100万)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 获得大额用户的集合</span></span><br><span class="line"></span><br><span class="line">temp = data_balance[(data_balance[<span class="string">'total_purchase_amt'</span>] &gt;= <span class="number">1000000</span>) | (data_balance[<span class="string">'total_redeem_amt'</span>] &gt;= <span class="number">1000000</span>)]</span><br><span class="line">big_users_set = set(temp[temp[<span class="string">'date'</span>] &gt;= datetime.datetime(<span class="number">2014</span>,<span class="number">4</span>,<span class="number">1</span>)][<span class="string">'user_id'</span>])</span><br></pre></td></tr></table></figure>
<p>可以计算得出大额用户占3903个，占总数的13%</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 标记大额用户</span></span><br><span class="line">data_balance[<span class="string">'big_user'</span>] = <span class="number">0</span></span><br><span class="line">data_balance.loc[data_balance[<span class="string">'user_id'</span>].isin(big_users_set), <span class="string">'big_user'</span>] = <span class="number">1</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 统计大额用户与小额用户的日总交易额的区别</span></span><br><span class="line">total_balance_bigNsmall = data_balance.groupby([<span class="string">'date'</span>,<span class="string">'big_user'</span>], as_index=<span class="literal">False</span>)[<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>].sum()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 画出大额用户与小额用户交易的日总交易量图</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">8</span>))</span><br><span class="line">plt.plot(total_balance_bigNsmall[total_balance_bigNsmall[<span class="string">'big_user'</span>] == <span class="number">1</span>][<span class="string">'date'</span>], total_balance_bigNsmall[total_balance_bigNsmall[<span class="string">'big_user'</span>] == <span class="number">1</span>][<span class="string">'total_purchase_amt'</span>],label=<span class="string">'big_purchase'</span>)</span><br><span class="line">plt.plot(total_balance_bigNsmall[total_balance_bigNsmall[<span class="string">'big_user'</span>] == <span class="number">1</span>][<span class="string">'date'</span>], total_balance_bigNsmall[total_balance_bigNsmall[<span class="string">'big_user'</span>] == <span class="number">1</span>][<span class="string">'total_redeem_amt'</span>],label=<span class="string">'big_redeem'</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(total_balance_bigNsmall[total_balance_bigNsmall[<span class="string">'big_user'</span>] == <span class="number">0</span>][<span class="string">'date'</span>], total_balance_bigNsmall[total_balance_bigNsmall[<span class="string">'big_user'</span>] == <span class="number">0</span>][<span class="string">'total_purchase_amt'</span>],label=<span class="string">'small_purchase'</span>)</span><br><span class="line">plt.plot(total_balance_bigNsmall[total_balance_bigNsmall[<span class="string">'big_user'</span>] == <span class="number">0</span>][<span class="string">'date'</span>], total_balance_bigNsmall[total_balance_bigNsmall[<span class="string">'big_user'</span>] == <span class="number">0</span>][<span class="string">'total_redeem_amt'</span>],label=<span class="string">'small_redeem'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">plt.title(<span class="string">"The time series of big and small user of Purchase and Redeem"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Amount"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B%EF%BC%88%E4%BA%8C%EF%BC%89/output_13_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 统计大额小额用户购买量占比</span></span><br><span class="line">np.sum(total_balance_bigNsmall[total_balance_bigNsmall[<span class="string">'big_user'</span>] == <span class="number">1</span>][<span class="string">'total_purchase_amt'</span>]) / np.sum(total_balance_bigNsmall[total_balance_bigNsmall[<span class="string">'big_user'</span>] == <span class="number">0</span>][<span class="string">'total_purchase_amt'</span>])</span><br><span class="line"><span class="comment"># 5.1456178397775805</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 统计大额小额用户赎回量占比</span></span><br><span class="line">np.sum(total_balance_bigNsmall[total_balance_bigNsmall[<span class="string">'big_user'</span>] == <span class="number">1</span>][<span class="string">'total_redeem_amt'</span>]) / np.sum(total_balance_bigNsmall[total_balance_bigNsmall[<span class="string">'big_user'</span>] == <span class="number">0</span>][<span class="string">'total_redeem_amt'</span>])</span><br><span class="line"><span class="comment"># 5.422141272341089</span></span><br></pre></td></tr></table></figure>
<h1 id="二、分析用户的交易频次"><a href="#二、分析用户的交易频次" class="headerlink" title="二、分析用户的交易频次"></a>二、分析用户的交易频次</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 画出非0交易的分布图</span></span><br><span class="line">frequency = data_balance[(data_balance[<span class="string">'direct_purchase_amt'</span>] != <span class="number">0</span>) | (data_balance[<span class="string">'total_redeem_amt'</span>] != <span class="number">0</span>)][[<span class="string">'user_id'</span>,<span class="string">'tBalance'</span>]].groupby(<span class="string">'user_id'</span>, as_index=<span class="literal">False</span>).count()</span><br><span class="line">sns.distplot(frequency[<span class="string">'tBalance'</span>])</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%EF%BC%88%E4%BA%8C%EF%BC%89/output_17_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 获取频繁交易用户集合</span></span><br><span class="line">hot_users_set = set(frequency[frequency[<span class="string">'tBalance'</span>] &gt; <span class="number">30</span>][<span class="string">'user_id'</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 获取频繁用户的交易纪录</span></span><br><span class="line">data_balance[<span class="string">'is_hot_users'</span>] = <span class="number">0</span></span><br><span class="line">data_balance.loc[data_balance[<span class="string">'user_id'</span>].isin(hot_users_set) , <span class="string">'is_hot_users'</span>] = <span class="number">1</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 统计频繁用户与非频繁用户的日总交易额的区别</span></span><br><span class="line">total_balance_hotNcold = data_balance.groupby([<span class="string">'date'</span>,<span class="string">'is_hot_users'</span>], as_index=<span class="literal">False</span>)[<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>].sum()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 绘制频繁用户与非频繁用户总购买赎回量的时序图</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">8</span>))</span><br><span class="line">plt.plot(total_balance_hotNcold[total_balance_hotNcold[<span class="string">'is_hot_users'</span>] == <span class="number">1</span>][<span class="string">'date'</span>], total_balance_hotNcold[total_balance_hotNcold[<span class="string">'is_hot_users'</span>] == <span class="number">1</span>][<span class="string">'total_purchase_amt'</span>],label=<span class="string">'hot_purchase'</span>)</span><br><span class="line">plt.plot(total_balance_hotNcold[total_balance_hotNcold[<span class="string">'is_hot_users'</span>] == <span class="number">1</span>][<span class="string">'date'</span>], total_balance_hotNcold[total_balance_hotNcold[<span class="string">'is_hot_users'</span>] == <span class="number">1</span>][<span class="string">'total_redeem_amt'</span>],label=<span class="string">'hot_redeem'</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(total_balance_hotNcold[total_balance_hotNcold[<span class="string">'is_hot_users'</span>] == <span class="number">0</span>][<span class="string">'date'</span>], total_balance_hotNcold[total_balance_hotNcold[<span class="string">'is_hot_users'</span>] == <span class="number">0</span>][<span class="string">'total_purchase_amt'</span>],label=<span class="string">'cold_purchase'</span>)</span><br><span class="line">plt.plot(total_balance_hotNcold[total_balance_hotNcold[<span class="string">'is_hot_users'</span>] == <span class="number">0</span>][<span class="string">'date'</span>], total_balance_hotNcold[total_balance_hotNcold[<span class="string">'is_hot_users'</span>] == <span class="number">0</span>][<span class="string">'total_redeem_amt'</span>],label=<span class="string">'cold_redeem'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">plt.title(<span class="string">"The time series of big and small user of Purchase and Redeem"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Amount"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%EF%BC%88%E4%BA%8C%EF%BC%89/output_21_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 画出冷启动用户与老用户交易的箱型图</span></span><br><span class="line">temp = data_balance[[<span class="string">'year'</span>,<span class="string">'month'</span>,<span class="string">'user_id'</span>,<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>]].groupby([<span class="string">'year'</span>,<span class="string">'month'</span>,<span class="string">'user_id'</span>], as_index=<span class="literal">False</span>).sum()</span><br><span class="line">user_old_set = set()</span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">30</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">9</span>):</span><br><span class="line">    newset = set(temp[(temp[<span class="string">'year'</span>] == <span class="number">2014</span>) &amp; (temp[<span class="string">'month'</span>] == i)][<span class="string">'user_id'</span>])</span><br><span class="line">    this_month = data_balance[(data_balance[<span class="string">'year'</span>] == <span class="number">2014</span>) &amp; (data_balance[<span class="string">'month'</span>] == i)]</span><br><span class="line">    this_month[<span class="string">'cold'</span>] = <span class="number">0</span></span><br><span class="line">    this_month.loc[this_month[<span class="string">'user_id'</span>].isin(newset - user_old_set), <span class="string">'cold'</span>] = <span class="number">1</span></span><br><span class="line">    plt.subplot(<span class="number">4</span>,<span class="number">2</span>,i)</span><br><span class="line">    plt.title(<span class="string">'This month : '</span> + str(i))</span><br><span class="line">    sns.boxplot(x=<span class="string">"cold"</span>, y=<span class="string">"total_purchase_amt"</span> , data=this_month[(this_month[<span class="string">'direct_purchase_amt'</span>] != <span class="number">0</span>) | (this_month[<span class="string">'total_redeem_amt'</span>] != <span class="number">0</span>)])</span><br><span class="line">    user_old_set = user_old_set | newset</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%EF%BC%88%E4%BA%8C%EF%BC%89/output_22_0.png" alt="png"></p>
<h1 id="三、分析用户的其他属性"><a href="#三、分析用户的其他属性" class="headerlink" title="三、分析用户的其他属性"></a>三、分析用户的其他属性</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 用户的其他属性</span></span><br><span class="line">users.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_id</th>
      <th>sex</th>
      <th>city</th>
      <th>constellation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>1</td>
      <td>6411949</td>
      <td>狮子座</td>
    </tr>
    <tr>
      <th>1</th>
      <td>12</td>
      <td>1</td>
      <td>6412149</td>
      <td>摩羯座</td>
    </tr>
    <tr>
      <th>2</th>
      <td>22</td>
      <td>1</td>
      <td>6411949</td>
      <td>双子座</td>
    </tr>
    <tr>
      <th>3</th>
      <td>23</td>
      <td>1</td>
      <td>6411949</td>
      <td>双鱼座</td>
    </tr>
    <tr>
      <th>4</th>
      <td>25</td>
      <td>1</td>
      <td>6481949</td>
      <td>双鱼座</td>
    </tr>
  </tbody>
</table>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 添加城市、星座、性别</span></span><br><span class="line">data_balance = pd.merge(data_balance, users, on=<span class="string">'user_id'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 统计每个城市用户的日总交易额的区别并绘制分布估计图</span></span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">10</span>,<span class="number">5</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> np.unique(data_balance[<span class="string">'city'</span>]):</span><br><span class="line">    temp = data_balance.groupby([<span class="string">'date'</span>,<span class="string">'city'</span>], as_index=<span class="literal">False</span>)[<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>].sum()</span><br><span class="line">    ax = sns.kdeplot( temp[temp[<span class="string">'city'</span>] == i][<span class="string">'total_purchase_amt'</span>],label=i)</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">plt.title(<span class="string">"The time series of different city of Purchase and Redeem"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Amount"</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">10</span>,<span class="number">5</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> np.unique(data_balance[<span class="string">'city'</span>]):</span><br><span class="line">    temp = data_balance.groupby([<span class="string">'date'</span>,<span class="string">'city'</span>], as_index=<span class="literal">False</span>)[<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>].sum()</span><br><span class="line">    ax = sns.kdeplot( temp[temp[<span class="string">'city'</span>] == i][<span class="string">'total_redeem_amt'</span>],label=i)</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">plt.title(<span class="string">"The time series of different city of Purchase and Redeem"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Amount"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%EF%BC%88%E4%BA%8C%EF%BC%89/output_26_0.png" alt="png"></p>
<p><img src="/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%EF%BC%88%E4%BA%8C%EF%BC%89/output_26_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 统计每个性别用户的日总交易额的区别，并绘制时序图</span></span><br><span class="line"></span><br><span class="line">temp = data_balance.groupby([<span class="string">'date'</span>,<span class="string">'sex'</span>], as_index=<span class="literal">False</span>)[<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>].sum()</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">6</span>))</span><br><span class="line">plt.plot(temp[temp[<span class="string">'sex'</span>] == <span class="number">1</span>][<span class="string">'date'</span>], temp[temp[<span class="string">'sex'</span>] == <span class="number">1</span>][<span class="string">'total_purchase_amt'</span>],label=<span class="string">'Male'</span>)</span><br><span class="line">plt.plot(temp[temp[<span class="string">'sex'</span>] == <span class="number">0</span>][<span class="string">'date'</span>], temp[temp[<span class="string">'sex'</span>] == <span class="number">0</span>][<span class="string">'total_purchase_amt'</span>],label=<span class="string">'Female'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">plt.title(<span class="string">"The time series of two gender user of Purchase"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Amount"</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">6</span>))</span><br><span class="line">plt.plot(temp[temp[<span class="string">'sex'</span>] == <span class="number">1</span>][<span class="string">'date'</span>], temp[temp[<span class="string">'sex'</span>] == <span class="number">1</span>][<span class="string">'total_purchase_amt'</span>],label=<span class="string">'Male'</span>)</span><br><span class="line">plt.plot(temp[temp[<span class="string">'sex'</span>] == <span class="number">0</span>][<span class="string">'date'</span>], temp[temp[<span class="string">'sex'</span>] == <span class="number">0</span>][<span class="string">'total_redeem_amt'</span>],label=<span class="string">'Female'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">plt.title(<span class="string">"The time series of two gender user of Redeem"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Amount"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%EF%BC%88%E4%BA%8C%EF%BC%89/output_27_0.png" alt="png"></p>
<p><img src="/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%EF%BC%88%E4%BA%8C%EF%BC%89/output_27_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 统计每个星座用户的日总交易额的区别 并绘制分布估计图</span></span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">10</span>,<span class="number">5</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> np.unique(data_balance[<span class="string">'constellation'</span>]):</span><br><span class="line">    temp = data_balance.groupby([<span class="string">'date'</span>,<span class="string">'constellation'</span>], as_index=<span class="literal">False</span>)[<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>].sum()</span><br><span class="line">    ax = sns.kdeplot( temp[temp[<span class="string">'constellation'</span>] == i][<span class="string">'total_purchase_amt'</span>],label=i)</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">plt.title(<span class="string">"The time series of small deal of Purchase and Redeem"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Amount"</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">10</span>,<span class="number">5</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> np.unique(data_balance[<span class="string">'constellation'</span>]):</span><br><span class="line">    temp = data_balance.groupby([<span class="string">'date'</span>,<span class="string">'constellation'</span>], as_index=<span class="literal">False</span>)[<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>].sum()</span><br><span class="line">    ax = sns.kdeplot( temp[temp[<span class="string">'constellation'</span>] == i][<span class="string">'total_redeem_amt'</span>],label=i)</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">plt.title(<span class="string">"The time series of small deal of Purchase and Redeem"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Amount"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%EF%BC%88%E4%BA%8C%EF%BC%89/output_28_0.png" alt="png"></p>
<p><img src="/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%EF%BC%88%E4%BA%8C%EF%BC%89/output_28_1.png" alt="png"></p>
<h1 id="四、其他分析"><a href="#四、其他分析" class="headerlink" title="四、其他分析"></a>四、其他分析</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 统计每个性别用户的日总交易额的区别</span></span><br><span class="line">temp = data_balance.groupby([<span class="string">'date'</span>], as_index=<span class="literal">False</span>)[<span class="string">'direct_purchase_amt'</span>,<span class="string">'share_amt'</span>].sum()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 画出每日利息的增长/直接购买量的时序图</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">6</span>))</span><br><span class="line">plt.plot(temp[<span class="string">'date'</span>],  temp[<span class="string">'share_amt'</span>] / temp[<span class="string">'direct_purchase_amt'</span>] ,label=<span class="string">'Rate'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">plt.title(<span class="string">"The rate of Share / Purchase"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Amount"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%EF%BC%88%E4%BA%8C%EF%BC%89/output_31_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 加载支付宝利率数据</span></span><br><span class="line">share = pd.read_csv(<span class="string">'Dataset/mfd_day_share_interest.csv'</span>)</span><br><span class="line">share = share.rename(columns = &#123;<span class="string">'mfd_date'</span>: <span class="string">'date'</span>&#125;)</span><br><span class="line">share_features = [x <span class="keyword">for</span> x <span class="keyword">in</span> share.columns <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'date'</span>]]</span><br><span class="line">share[<span class="string">'date'</span>] = pd.to_datetime(share[<span class="string">'date'</span>], format= <span class="string">"%Y%m%d"</span>)</span><br><span class="line">share[<span class="string">'day'</span>] = share[<span class="string">'date'</span>].dt.day</span><br><span class="line">share[<span class="string">'month'</span>] = share[<span class="string">'date'</span>].dt.month</span><br><span class="line">share[<span class="string">'year'</span>] = share[<span class="string">'date'</span>].dt.year</span><br><span class="line">share[<span class="string">'week'</span>] = share[<span class="string">'date'</span>].dt.week</span><br><span class="line">share[<span class="string">'weekday'</span>] = share[<span class="string">'date'</span>].dt.weekday</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 绘制支付宝利率与交易额的时序图</span></span><br><span class="line">fig,ax1 = plt.subplots(figsize=(<span class="number">15</span>,<span class="number">5</span>))</span><br><span class="line">plt.plot(temp[<span class="string">'date'</span>], temp[<span class="string">'share_amt'</span>],<span class="string">'b'</span>,label=<span class="string">"Share_amt"</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">ax2=ax1.twinx()</span><br><span class="line">plt.plot(share[<span class="string">'date'</span>], share[<span class="string">'mfd_daily_yield'</span>],<span class="string">'g'</span>,label=<span class="string">"Share rate"</span>)</span><br><span class="line"></span><br><span class="line">plt.legend(loc=<span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">"The correlation between share rate and share amount"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Rate &amp; Amount"</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%EF%BC%88%E4%BA%8C%EF%BC%89/output_33_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 支付宝利率与每日利息的增长/直接购买量的时序图</span></span><br><span class="line">fig,ax1 = plt.subplots(figsize=(<span class="number">15</span>,<span class="number">5</span>))</span><br><span class="line">plt.plot(temp[<span class="string">'date'</span>], temp[<span class="string">'share_amt'</span>] / temp[<span class="string">'direct_purchase_amt'</span>],<span class="string">'b'</span>,label=<span class="string">"Share_amt / Direct_amt"</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">ax2=ax1.twinx()</span><br><span class="line">plt.plot(share[<span class="string">'date'</span>], share[<span class="string">'mfd_daily_yield'</span>],<span class="string">'g'</span>,label=<span class="string">"Share rate"</span>)</span><br><span class="line"></span><br><span class="line">plt.legend(loc=<span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">"The correlation between share rate and Share/Purchase"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Rate &amp; Amount"</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%EF%BC%88%E4%BA%8C%EF%BC%89/output_34_0.png" alt="png"></p>
<p>直接购买里面有两种</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 聚合两种不同购买方式</span></span><br><span class="line">temp = data_balance.groupby([<span class="string">'date'</span>], as_index=<span class="literal">False</span>)[<span class="string">'purchase_bal_amt'</span>,<span class="string">'purchase_bank_amt'</span>].sum()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 画出不同购买方式日购买量的时序图</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">6</span>))</span><br><span class="line">plt.plot(temp[<span class="string">'date'</span>], temp[<span class="string">'purchase_bal_amt'</span>],label=<span class="string">'Bal'</span>)</span><br><span class="line">plt.plot(temp[<span class="string">'date'</span>], temp[<span class="string">'purchase_bank_amt'</span>],label=<span class="string">'Bank'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">plt.title(<span class="string">"The purchase of bal and bank"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Amount"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%EF%BC%88%E4%BA%8C%EF%BC%89/output_37_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 画出不同赎回方式日赎回量的时序图</span></span><br><span class="line">temp = data_balance.groupby([<span class="string">'date'</span>], as_index=<span class="literal">False</span>)[<span class="string">'tftobal_amt'</span>,<span class="string">'tftocard_amt'</span>].sum()</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">6</span>))</span><br><span class="line">plt.plot(temp[<span class="string">'date'</span>], temp[<span class="string">'tftobal_amt'</span>],label=<span class="string">'Bal'</span>)</span><br><span class="line">plt.plot(temp[<span class="string">'date'</span>], temp[<span class="string">'tftocard_amt'</span>],label=<span class="string">'Bank'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">plt.title(<span class="string">"The redeem of bal and bank"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Amount"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%EF%BC%88%E4%BA%8C%EF%BC%89/output_38_0.png" alt="png"></p>
<p>虽然支付宝或者银行卡买入区别不大，但是redeem上的差异性相当明显。</p>
]]></content>
      <categories>
        <category>Match</category>
      </categories>
  </entry>
  <entry>
    <title>资金流入流出预测比赛（一）</title>
    <url>/posts/94fccd43.html</url>
    <content><![CDATA[<h1 id="赛题理解"><a href="#赛题理解" class="headerlink" title="赛题理解"></a>赛题理解</h1><p>本博客是参加datawhale组队学习记的笔记，其中大部分内容来自<a href="https://github.com/datawhalechina/team-learning-data-mining/tree/master/PurchaseAndRedemptionForecast" target="_blank" rel="noopener">本次数据挖掘比赛学习文档</a>。本次比赛为<a href="https://tianchi.aliyun.com/competition/entrance/231573/information" target="_blank" rel="noopener">阿里天池资金流入流出预测-挑战Baseline</a>，研究问题为<strong>蚂蚁金服资金管理下预测未来每日的资金流入流出情况</strong>（Redeem/Purchase），总结可得以下信息：</p>
<ul>
<li>场景：蚂蚁金服每天需要处理大量的资金流入和流出</li>
<li>条件：为了资金流动的风险达到最低，同时保证每天的正常业务运转</li>
<li>目标：精准预测未来每日的资金流入流出情况</li>
<li>数据：用户基本信息数据、用户申购赎回数据、收益率表、银行间拆借利率表</li>
</ul>
<h2 id="数据可视化方式"><a href="#数据可视化方式" class="headerlink" title="数据可视化方式"></a>数据可视化方式</h2><p>下面的时间序列可视化将用到以下函数：</p>
<ul>
<li><p>直方图</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.distplot()</span><br><span class="line">sns.barplot()</span><br></pre></td></tr></table></figure>
</li>
<li><p>箱形图</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.boxplot()</span><br></pre></td></tr></table></figure>
<p>异常值 Q1-IQR, Q3+IQR, IQR=Q3-Q1</p>
</li>
<li><p>小提琴图</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.violin()</span><br></pre></td></tr></table></figure>
<p>粗黑条：四分位；细黑条：置信区间；白点：中位数</p>
</li>
<li><p>频率图</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.distplot()</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="变量相关性分析与独立性分析"><a href="#变量相关性分析与独立性分析" class="headerlink" title="变量相关性分析与独立性分析"></a>变量相关性分析与独立性分析</h2><ul>
<li><p>相关性分析</p>
<ul>
<li>定类 定序 定距</li>
<li>定类-定类/定序——-&gt;卡方检验</li>
<li>定类- 定距——-&gt;eta系数</li>
<li>定序-定序——-&gt;spearman系数/同异序测量</li>
<li>定序-定距——-&gt;spearman系数</li>
<li>定距-定距———&gt;peason相关系数</li>
</ul>
</li>
<li><p>独立性分析</p>
<ul>
<li>若变量之间无线性相关性，还可能存在非线性关联</li>
<li>mv test</li>
</ul>
</li>
</ul>
<h1 id="全局设置"><a href="#全局设置" class="headerlink" title="全局设置"></a>全局设置</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span>  pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> warnings </span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> datetime </span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 设置数据集路径</span></span><br><span class="line">dataset_path = <span class="string">'Dataset/'</span></span><br><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line">data_balance = pd.read_csv(dataset_path+<span class="string">'user_balance_table.csv'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_balance[<span class="string">'date'</span>] = pd.to_datetime(data_balance[<span class="string">'report_date'</span>], format= <span class="string">"%Y%m%d"</span>)</span><br><span class="line">data_balance[<span class="string">'day'</span>] = data_balance[<span class="string">'date'</span>].dt.day</span><br><span class="line">data_balance[<span class="string">'month'</span>] = data_balance[<span class="string">'date'</span>].dt.month</span><br><span class="line">data_balance[<span class="string">'year'</span>] = data_balance[<span class="string">'date'</span>].dt.year</span><br><span class="line">data_balance[<span class="string">'week'</span>] = data_balance[<span class="string">'date'</span>].dt.week</span><br><span class="line">data_balance[<span class="string">'weekday'</span>] = data_balance[<span class="string">'date'</span>].dt.weekday</span><br></pre></td></tr></table></figure>
<h1 id="一、时间序列分析"><a href="#一、时间序列分析" class="headerlink" title="一、时间序列分析"></a>一、时间序列分析</h1><h2 id="1-1-聚合时间数据"><a href="#1-1-聚合时间数据" class="headerlink" title="1.1 聚合时间数据"></a>1.1 聚合时间数据</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">total_balance = data_balance.groupby([<span class="string">'date'</span>])[<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>].sum().reset_index()</span><br></pre></td></tr></table></figure>
<h2 id="1-2-生成测试集区段数据，拼接数据"><a href="#1-2-生成测试集区段数据，拼接数据" class="headerlink" title="1.2 生成测试集区段数据，拼接数据"></a>1.2 生成测试集区段数据，拼接数据</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">start = datetime.datetime(<span class="number">2014</span>,<span class="number">9</span>,<span class="number">1</span>)</span><br><span class="line">testdata = []</span><br><span class="line"><span class="keyword">while</span> start != datetime.datetime(<span class="number">2014</span>,<span class="number">10</span>,<span class="number">1</span>):</span><br><span class="line">    temp = [start, np.nan, np.nan]</span><br><span class="line">    testdata.append(temp)</span><br><span class="line">    start += datetime.timedelta(days = <span class="number">1</span>)</span><br><span class="line">testdata = pd.DataFrame(testdata)</span><br><span class="line">testdata.columns = total_balance.columns</span><br><span class="line"></span><br><span class="line">total_balance = pd.concat([total_balance, testdata], axis = <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h2 id="1-3-为数据集添加时间戳"><a href="#1-3-为数据集添加时间戳" class="headerlink" title="1.3 为数据集添加时间戳"></a>1.3 为数据集添加时间戳</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">total_balance[<span class="string">'day'</span>] = total_balance[<span class="string">'date'</span>].dt.day</span><br><span class="line">total_balance[<span class="string">'month'</span>] = total_balance[<span class="string">'date'</span>].dt.month</span><br><span class="line">total_balance[<span class="string">'year'</span>] = total_balance[<span class="string">'date'</span>].dt.year</span><br><span class="line">total_balance[<span class="string">'week'</span>] = total_balance[<span class="string">'date'</span>].dt.week</span><br><span class="line">total_balance[<span class="string">'weekday'</span>] = total_balance[<span class="string">'date'</span>].dt.weekday</span><br></pre></td></tr></table></figure>
<h2 id="1-4-画出每日总购买与赎回量的时间序列图"><a href="#1-4-画出每日总购买与赎回量的时间序列图" class="headerlink" title="1.4 画出每日总购买与赎回量的时间序列图"></a>1.4 画出每日总购买与赎回量的时间序列图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">6</span>))</span><br><span class="line">plt.plot(total_balance[<span class="string">'date'</span>], total_balance[<span class="string">'total_purchase_amt'</span>],label=<span class="string">'purchase'</span>)</span><br><span class="line">plt.plot(total_balance[<span class="string">'date'</span>], total_balance[<span class="string">'total_redeem_amt'</span>],label=<span class="string">'redeem'</span>)</span><br><span class="line"></span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">plt.title(<span class="string">"The lineplot of total amount of Purchase and Redeem from July.13 to Sep.14"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Amount"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_12_0.png" alt="png"></p>
<h2 id="1-5-画出4月份以后的时间序列图"><a href="#1-5-画出4月份以后的时间序列图" class="headerlink" title="1.5 画出4月份以后的时间序列图"></a>1.5 画出4月份以后的时间序列图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">total_balance_1 = total_balance[total_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,<span class="number">4</span>,<span class="number">1</span>)]</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">6</span>))</span><br><span class="line">plt.plot(total_balance_1[<span class="string">'date'</span>], total_balance_1[<span class="string">'total_purchase_amt'</span>])</span><br><span class="line">plt.plot(total_balance_1[<span class="string">'date'</span>], total_balance_1[<span class="string">'total_redeem_amt'</span>])</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">"The lineplot of total amount of Purchase and Redeem from April.14 to Sep.14"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Amount"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_13_0.png" alt="png"></p>
<h2 id="1-6-分别画出每个月中每天购买赎回量的时间序列图"><a href="#1-6-分别画出每个月中每天购买赎回量的时间序列图" class="headerlink" title="1.6 分别画出每个月中每天购买赎回量的时间序列图"></a>1.6 分别画出每个月中每天购买赎回量的时间序列图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig = plt.figure(figsize=(<span class="number">15</span>,<span class="number">15</span>))</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">4</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">"The time series of total amount of Purchase and Redeem for August, July, June, May respectively"</span>)</span><br><span class="line"></span><br><span class="line">total_balance_2 = total_balance[total_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,<span class="number">8</span>,<span class="number">1</span>)]</span><br><span class="line">plt.plot(total_balance_2[<span class="string">'date'</span>], total_balance_2[<span class="string">'total_purchase_amt'</span>])</span><br><span class="line">plt.plot(total_balance_2[<span class="string">'date'</span>], total_balance_2[<span class="string">'total_redeem_amt'</span>])</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">total_balance_3 = total_balance[(total_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,<span class="number">7</span>,<span class="number">1</span>)) &amp; (total_balance[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>,<span class="number">8</span>,<span class="number">1</span>))]</span><br><span class="line">plt.subplot(<span class="number">4</span>,<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">plt.plot(total_balance_3[<span class="string">'date'</span>], total_balance_3[<span class="string">'total_purchase_amt'</span>])</span><br><span class="line">plt.plot(total_balance_3[<span class="string">'date'</span>], total_balance_3[<span class="string">'total_redeem_amt'</span>])</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">total_balance_4 = total_balance[(total_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,<span class="number">6</span>,<span class="number">1</span>)) &amp; (total_balance[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>,<span class="number">7</span>,<span class="number">1</span>))]</span><br><span class="line">plt.subplot(<span class="number">4</span>,<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">plt.plot(total_balance_4[<span class="string">'date'</span>], total_balance_4[<span class="string">'total_purchase_amt'</span>])</span><br><span class="line">plt.plot(total_balance_4[<span class="string">'date'</span>], total_balance_4[<span class="string">'total_redeem_amt'</span>])</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">total_balance_5 = total_balance[(total_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,<span class="number">5</span>,<span class="number">1</span>)) &amp; (total_balance[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>,<span class="number">6</span>,<span class="number">1</span>))]</span><br><span class="line">plt.subplot(<span class="number">4</span>,<span class="number">1</span>,<span class="number">4</span>)</span><br><span class="line">plt.plot(total_balance_5[<span class="string">'date'</span>], total_balance_5[<span class="string">'total_purchase_amt'</span>])</span><br><span class="line">plt.plot(total_balance_5[<span class="string">'date'</span>], total_balance_5[<span class="string">'total_redeem_amt'</span>])</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Amount"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_14_0.png" alt="png"></p>
<h2 id="1-7-分别画出13年8月与9月每日购买赎回量的时序图"><a href="#1-7-分别画出13年8月与9月每日购买赎回量的时序图" class="headerlink" title="1.7 分别画出13年8月与9月每日购买赎回量的时序图"></a>1.7 分别画出13年8月与9月每日购买赎回量的时序图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig = plt.figure(figsize=(<span class="number">15</span>,<span class="number">9</span>))</span><br><span class="line"></span><br><span class="line">total_balance_last8 = total_balance[(total_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2013</span>,<span class="number">8</span>,<span class="number">1</span>)) &amp; (total_balance[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2013</span>,<span class="number">9</span>,<span class="number">1</span>))]</span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">plt.plot(total_balance_last8[<span class="string">'date'</span>], total_balance_last8[<span class="string">'total_purchase_amt'</span>])</span><br><span class="line">plt.plot(total_balance_last8[<span class="string">'date'</span>], total_balance_last8[<span class="string">'total_redeem_amt'</span>])</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">total_balance_last9 = total_balance[(total_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2013</span>,<span class="number">9</span>,<span class="number">1</span>)) &amp; (total_balance[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2013</span>,<span class="number">10</span>,<span class="number">1</span>))]</span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">plt.plot(total_balance_last9[<span class="string">'date'</span>], total_balance_last9[<span class="string">'total_purchase_amt'</span>])</span><br><span class="line">plt.plot(total_balance_last9[<span class="string">'date'</span>], total_balance_last9[<span class="string">'total_redeem_amt'</span>])</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Amount"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_15_0.png" alt="png"></p>
<h1 id="二、翌日特征分析"><a href="#二、翌日特征分析" class="headerlink" title="二、翌日特征分析"></a>二、翌日特征分析</h1><h2 id="2-1-画出每个翌日的数据分布于整体数据的分布图"><a href="#2-1-画出每个翌日的数据分布于整体数据的分布图" class="headerlink" title="2.1 画出每个翌日的数据分布于整体数据的分布图"></a>2.1 画出每个翌日的数据分布于整体数据的分布图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = plt.figure(figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line">scatter_para = &#123;<span class="string">'marker'</span>:<span class="string">'.'</span>, <span class="string">'s'</span>:<span class="number">3</span>, <span class="string">'alpha'</span>:<span class="number">0.3</span>&#125;</span><br><span class="line">line_kws = &#123;<span class="string">'color'</span>:<span class="string">'k'</span>&#125;</span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">'The distrubution of total purchase'</span>)</span><br><span class="line">sns.violinplot(x=<span class="string">'weekday'</span>, y=<span class="string">'total_purchase_amt'</span>, data = total_balance_1, scatter_kws=scatter_para, line_kws=line_kws)</span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">'The distrubution of total purchase'</span>)</span><br><span class="line">sns.distplot(total_balance_1[<span class="string">'total_purchase_amt'</span>].dropna())</span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">plt.title(<span class="string">'The distrubution of total redeem'</span>)</span><br><span class="line">sns.violinplot(x=<span class="string">'weekday'</span>, y=<span class="string">'total_redeem_amt'</span>, data = total_balance_1, scatter_kws=scatter_para, line_kws=line_kws)</span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line">plt.title(<span class="string">'The distrubution of total redeem'</span>)</span><br><span class="line">sns.distplot(total_balance_1[<span class="string">'total_redeem_amt'</span>].dropna())</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_17_1.png" alt="png"></p>
<h2 id="2-2-按翌日对数据聚合后取均值"><a href="#2-2-按翌日对数据聚合后取均值" class="headerlink" title="2.2 按翌日对数据聚合后取均值"></a>2.2 按翌日对数据聚合后取均值</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">week_sta = total_balance_1[[<span class="string">'total_purchase_amt'</span>, <span class="string">'total_redeem_amt'</span>, <span class="string">'weekday'</span>]].groupby(<span class="string">'weekday'</span>, as_index=<span class="literal">False</span>).mean()</span><br></pre></td></tr></table></figure>
<h2 id="2-3-分析翌日的中位数特征"><a href="#2-3-分析翌日的中位数特征" class="headerlink" title="2.3 分析翌日的中位数特征"></a>2.3 分析翌日的中位数特征</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">5</span>))</span><br><span class="line">ax = plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">'The barplot of average total purchase with each weekday'</span>)</span><br><span class="line">ax = sns.barplot(x=<span class="string">"weekday"</span>, y=<span class="string">"total_purchase_amt"</span>, data=week_sta, label=<span class="string">'Purchase'</span>)</span><br><span class="line">ax.legend()</span><br><span class="line">ax = plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">'The barplot of average total redeem with each weekday'</span>)</span><br><span class="line">ax = sns.barplot(x=<span class="string">"weekday"</span>, y=<span class="string">"total_redeem_amt"</span>, data=week_sta, label=<span class="string">'Redeem'</span>)</span><br><span class="line">ax.legend()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_19_1.png" alt="png"></p>
<h2 id="2-4-画出翌日的箱型图"><a href="#2-4-画出翌日的箱型图" class="headerlink" title="2.4 画出翌日的箱型图"></a>2.4 画出翌日的箱型图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">5</span>))</span><br><span class="line">ax = plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">'The boxplot of total purchase with each weekday'</span>)</span><br><span class="line">ax = sns.boxplot(x=<span class="string">"weekday"</span>, y=<span class="string">"total_purchase_amt"</span>, data=total_balance_1)</span><br><span class="line">ax = plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">'The boxplot of total redeem with each weekday'</span>)</span><br><span class="line">ax = sns.boxplot(x=<span class="string">"weekday"</span>, y=<span class="string">"total_redeem_amt"</span>, data=total_balance_1)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_20_0.png" alt="png"></p>
<h2 id="2-5-使用OneHot方法将翌日特征划分，获取划分后特征"><a href="#2-5-使用OneHot方法将翌日特征划分，获取划分后特征" class="headerlink" title="2.5  使用OneHot方法将翌日特征划分，获取划分后特征"></a>2.5  使用OneHot方法将翌日特征划分，获取划分后特征</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line">encoder = OneHotEncoder()</span><br><span class="line">total_balance = total_balance.reset_index()</span><br><span class="line">week_feature = encoder.fit_transform(np.array(total_balance[<span class="string">'weekday'</span>]).reshape(<span class="number">-1</span>, <span class="number">1</span>)).toarray()</span><br><span class="line">week_feature = pd.DataFrame(week_feature,columns=[<span class="string">'weekday_onehot'</span>]*len(week_feature[<span class="number">0</span>]))</span><br><span class="line">feature = pd.concat([total_balance, week_feature], axis = <span class="number">1</span>)[[<span class="string">'total_purchase_amt'</span>, <span class="string">'total_redeem_amt'</span>,<span class="string">'weekday_onehot'</span>,<span class="string">'date'</span>]]</span><br><span class="line">feature.columns = list(feature.columns[<span class="number">0</span>:<span class="number">2</span>]) + [x+str(i) <span class="keyword">for</span> i,x <span class="keyword">in</span> enumerate(feature.columns[<span class="number">2</span>:<span class="number">-1</span>])] + [<span class="string">'date'</span>]</span><br></pre></td></tr></table></figure>
<h2 id="2-6-画出划分后翌日特征与标签的斯皮尔曼相关性"><a href="#2-6-画出划分后翌日特征与标签的斯皮尔曼相关性" class="headerlink" title="2.6 画出划分后翌日特征与标签的斯皮尔曼相关性"></a>2.6 画出划分后翌日特征与标签的斯皮尔曼相关性</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">f, ax = plt.subplots(figsize = (<span class="number">15</span>, <span class="number">8</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">'The spearman coleration between total purchase and each weekday'</span>)</span><br><span class="line">sns.heatmap(feature[[x <span class="keyword">for</span> x <span class="keyword">in</span> feature.columns <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'total_redeem_amt'</span>, <span class="string">'date'</span>] ]].corr(<span class="string">'spearman'</span>),linewidths = <span class="number">0.1</span>, vmax = <span class="number">0.2</span>, vmin=<span class="number">-0.2</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">'The spearman coleration between total redeem and each weekday'</span>)</span><br><span class="line">sns.heatmap(feature[[x <span class="keyword">for</span> x <span class="keyword">in</span> feature.columns <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'total_purchase_amt'</span>, <span class="string">'date'</span>] ]].corr(<span class="string">'spearman'</span>),linewidths = <span class="number">0.1</span>,  vmax = <span class="number">0.2</span>, vmin=<span class="number">-0.2</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_22_1.png" alt="png"></p>
<h2 id="2-7-测试翌日特征与标签的独立性"><a href="#2-7-测试翌日特征与标签的独立性" class="headerlink" title="2.7 测试翌日特征与标签的独立性"></a>2.7 测试翌日特征与标签的独立性</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> mvtpy.mvtest <span class="keyword">import</span> mvtest</span><br><span class="line">mv = mvtest()</span><br><span class="line">mv.test(total_balance_1[<span class="string">'total_purchase_amt'</span>], total_balance_1[<span class="string">'weekday'</span>])</span><br></pre></td></tr></table></figure>
<pre><code>{&#39;Tn&#39;: 6.75, &#39;p-value&#39;: [0, 0.01]}
</code></pre><h1 id="三、月份特征分析"><a href="#三、月份特征分析" class="headerlink" title="三、月份特征分析"></a>三、月份特征分析</h1><h2 id="3-1-画出每个月的购买总量分布估计图-kdeplot"><a href="#3-1-画出每个月的购买总量分布估计图-kdeplot" class="headerlink" title="3.1 画出每个月的购买总量分布估计图(kdeplot)"></a>3.1 画出每个月的购买总量分布估计图(kdeplot)</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">10</span>))</span><br><span class="line">plt.title(<span class="string">'The Probability Density of total purchase amount in Each Month'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Probability'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Amount'</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">7</span>, <span class="number">12</span>):</span><br><span class="line">    sns.kdeplot(total_balance[(total_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2013</span>,i,<span class="number">1</span>)) &amp; (total_balance[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2013</span>,i+<span class="number">1</span>,<span class="number">1</span>))][<span class="string">'total_purchase_amt'</span>],label=<span class="string">'13Y,'</span>+str(i)+<span class="string">'M'</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">9</span>):</span><br><span class="line">    sns.kdeplot(total_balance[(total_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,i,<span class="number">1</span>)) &amp; (total_balance[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>,i+<span class="number">1</span>,<span class="number">1</span>))][<span class="string">'total_purchase_amt'</span>],label=<span class="string">'14Y,'</span>+str(i)+<span class="string">'M'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_25_0.png" alt="png"></p>
<h2 id="3-2-画出每个月的赎回总量分布估计图-kdeplot"><a href="#3-2-画出每个月的赎回总量分布估计图-kdeplot" class="headerlink" title="3.2 画出每个月的赎回总量分布估计图(kdeplot)"></a>3.2 画出每个月的赎回总量分布估计图(kdeplot)</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">10</span>))</span><br><span class="line">plt.title(<span class="string">'The Probability Density of total redeem amount in Each Month'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Probability'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Amount'</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">7</span>, <span class="number">12</span>):</span><br><span class="line">    sns.kdeplot(total_balance[(total_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2013</span>,i,<span class="number">1</span>)) &amp; (total_balance[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2013</span>,i+<span class="number">1</span>,<span class="number">1</span>))][<span class="string">'total_redeem_amt'</span>],label=<span class="string">'13Y,'</span>+str(i)+<span class="string">'M'</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">9</span>):</span><br><span class="line">    sns.kdeplot(total_balance[(total_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,i,<span class="number">1</span>)) &amp; (total_balance[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>,i+<span class="number">1</span>,<span class="number">1</span>))][<span class="string">'total_redeem_amt'</span>],label=<span class="string">'14Y,'</span>+str(i)+<span class="string">'M'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_26_0.png" alt="png"></p>
<h2 id="3-3-画出14年五六七八月份的分布估计图"><a href="#3-3-画出14年五六七八月份的分布估计图" class="headerlink" title="3.3 画出14年五六七八月份的分布估计图"></a>3.3 画出14年五六七八月份的分布估计图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">10</span>))</span><br><span class="line">ax = plt.subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">'The Probability Density of total purchase and redeem amount from May.14 to August.14'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Probability'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Amount'</span>)</span><br><span class="line">ax = sns.kdeplot(total_balance_2[<span class="string">'total_purchase_amt'</span>],label=<span class="string">'August'</span>)</span><br><span class="line">ax = sns.kdeplot(total_balance_3[<span class="string">'total_purchase_amt'</span>],label=<span class="string">'July'</span>)</span><br><span class="line">ax = sns.kdeplot(total_balance_4[<span class="string">'total_purchase_amt'</span>],label=<span class="string">'June'</span>)</span><br><span class="line">ax = sns.kdeplot(total_balance_5[<span class="string">'total_purchase_amt'</span>],color=<span class="string">'Black'</span>,label=<span class="string">'May'</span>)</span><br><span class="line">ax = plt.subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Probability'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Amount'</span>)</span><br><span class="line">ax = sns.kdeplot(total_balance_2[<span class="string">'total_redeem_amt'</span>],label=<span class="string">'August'</span>)</span><br><span class="line">ax = sns.kdeplot(total_balance_3[<span class="string">'total_redeem_amt'</span>],label=<span class="string">'July'</span>)</span><br><span class="line">ax = sns.kdeplot(total_balance_4[<span class="string">'total_redeem_amt'</span>],label=<span class="string">'June'</span>)</span><br><span class="line">ax = sns.kdeplot(total_balance_5[<span class="string">'total_redeem_amt'</span>],color=<span class="string">'Black'</span>,label=<span class="string">'May'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_27_0.png" alt="png"></p>
<h2 id="3-4-画出13年八月到九月份的分布估计图"><a href="#3-4-画出13年八月到九月份的分布估计图" class="headerlink" title="3.4  画出13年八月到九月份的分布估计图"></a>3.4  画出13年八月到九月份的分布估计图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">total_balance_last_7 = total_balance[(total_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2013</span>,<span class="number">7</span>,<span class="number">1</span>)) &amp; (total_balance[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2013</span>,<span class="number">8</span>,<span class="number">1</span>))]</span><br><span class="line">total_balance_last_8 = total_balance[(total_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2013</span>,<span class="number">8</span>,<span class="number">1</span>)) &amp; (total_balance[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2013</span>,<span class="number">9</span>,<span class="number">1</span>))]</span><br><span class="line">total_balance_last_9 = total_balance[(total_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2013</span>,<span class="number">9</span>,<span class="number">1</span>)) &amp; (total_balance[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2013</span>,<span class="number">10</span>,<span class="number">1</span>))]</span><br><span class="line">total_balance_last_10 = total_balance[(total_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2013</span>,<span class="number">10</span>,<span class="number">1</span>)) &amp; (total_balance[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2013</span>,<span class="number">11</span>,<span class="number">1</span>))]</span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">10</span>))</span><br><span class="line">ax = plt.subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">'The Probability Density of total purchase and redeem amount from Aug.13 to Sep.13'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Probability'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Amount'</span>)</span><br><span class="line">ax = sns.kdeplot(total_balance_last_8[<span class="string">'total_purchase_amt'</span>],label=<span class="string">'August'</span>)</span><br><span class="line">ax = sns.kdeplot(total_balance_last_7[<span class="string">'total_purchase_amt'</span>],label=<span class="string">'July'</span>)</span><br><span class="line">ax = sns.kdeplot(total_balance_last_9[<span class="string">'total_purchase_amt'</span>],color=<span class="string">'Red'</span>,label=<span class="string">'September'</span>)</span><br><span class="line"></span><br><span class="line">ax = plt.subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Probability'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Amount'</span>)</span><br><span class="line">ax = sns.kdeplot(total_balance_last_8[<span class="string">'total_redeem_amt'</span>],label=<span class="string">'August'</span>)</span><br><span class="line">ax = sns.kdeplot(total_balance_last_7[<span class="string">'total_redeem_amt'</span>],label=<span class="string">'July'</span>)</span><br><span class="line">ax = sns.kdeplot(total_balance_last_9[<span class="string">'total_redeem_amt'</span>],color=<span class="string">'Red'</span>,label=<span class="string">'September'</span>)</span><br><span class="line">ax = sns.kdeplot(total_balance_last_10[<span class="string">'total_redeem_amt'</span>],color=<span class="string">'Black'</span>,label=<span class="string">'Novermber'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_28_0.png" alt="png"></p>
<h1 id="四、日期特征分析"><a href="#四、日期特征分析" class="headerlink" title="四、日期特征分析"></a>四、日期特征分析</h1><h2 id="4-1-按照每天聚合数据集"><a href="#4-1-按照每天聚合数据集" class="headerlink" title="4.1 按照每天聚合数据集"></a>4.1 按照每天聚合数据集</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">day_sta = total_balance_2[[<span class="string">'total_purchase_amt'</span>, <span class="string">'total_redeem_amt'</span>, <span class="string">'day'</span>]].groupby(<span class="string">'day'</span>, as_index=<span class="literal">False</span>).mean()</span><br></pre></td></tr></table></figure>
<h2 id="4-2-获取聚合后每月购买分布的柱状图"><a href="#4-2-获取聚合后每月购买分布的柱状图" class="headerlink" title="4.2 获取聚合后每月购买分布的柱状图"></a>4.2 获取聚合后每月购买分布的柱状图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax = sns.barplot(x=<span class="string">"day"</span>, y=<span class="string">"total_purchase_amt"</span>, data=day_sta, label=<span class="string">'Purchase'</span>)</span><br><span class="line">ax = sns.lineplot(x=<span class="string">"day"</span>, y=<span class="string">"total_purchase_amt"</span>, data=day_sta, label=<span class="string">'Purchase'</span>)</span><br><span class="line">ax.legend()</span><br><span class="line">plt.title(<span class="string">"The total Purchase in Aug.14"</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Text(0.5, 1.0, &#39;The total Purchase in Aug.14&#39;)
</code></pre><p><img src="/Pic/Untitled/output_31_1.png" alt="png"></p>
<h2 id="4-3-获取聚合后每月赎回分布的柱状图"><a href="#4-3-获取聚合后每月赎回分布的柱状图" class="headerlink" title="4.3 获取聚合后每月赎回分布的柱状图"></a>4.3 获取聚合后每月赎回分布的柱状图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax = sns.barplot(x=<span class="string">"day"</span>, y=<span class="string">"total_redeem_amt"</span>, data=day_sta, label=<span class="string">'Redeem'</span>)</span><br><span class="line">ax = sns.lineplot(x=<span class="string">"day"</span>, y=<span class="string">"total_redeem_amt"</span>, data=day_sta, label=<span class="string">'Redeem'</span>)</span><br><span class="line">ax.legend()</span><br><span class="line">plt.title(<span class="string">"The total Redeem in Aug.14"</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Text(0.5, 1.0, &#39;The total Redeem in Aug.14&#39;)
</code></pre><p><img src="/Pic/Untitled/output_32_1.png" alt="png"></p>
<h2 id="4-4-画出13年九月份的分布图"><a href="#4-4-画出13年九月份的分布图" class="headerlink" title="4.4 画出13年九月份的分布图"></a>4.4 画出13年九月份的分布图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">5</span>))</span><br><span class="line">day_sta = total_balance_last_9[[<span class="string">'total_purchase_amt'</span>, <span class="string">'total_redeem_amt'</span>, <span class="string">'day'</span>]].groupby(<span class="string">'day'</span>, as_index=<span class="literal">False</span>).mean()</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">"The total Purchase in Sep.13"</span>)</span><br><span class="line">ax = sns.barplot(x=<span class="string">"day"</span>, y=<span class="string">"total_purchase_amt"</span>, data=day_sta, label=<span class="string">'Purchase'</span>)</span><br><span class="line">ax = sns.lineplot(x=<span class="string">"day"</span>, y=<span class="string">"total_purchase_amt"</span>, data=day_sta, label=<span class="string">'Purchase'</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">"The total Redeem in Sep.13"</span>)</span><br><span class="line">bx = sns.barplot(x=<span class="string">"day"</span>, y=<span class="string">"total_redeem_amt"</span>, data=day_sta, label=<span class="string">'Redeem'</span>)</span><br><span class="line">bx = sns.lineplot(x=<span class="string">"day"</span>, y=<span class="string">"total_redeem_amt"</span>, data=day_sta, label=<span class="string">'Redeem'</span>)</span><br><span class="line">bx.legend()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_33_1.png" alt="png"></p>
<p><strong>We find that the data from last year in Sep has very limited week feature</strong></p>
<p>There are some strange day in Sep:</p>
<ol>
<li>1st day</li>
<li>2nd day</li>
<li>16th day(Purchase a lot)—-Monday &amp; 3days before MidAutumn Festirval</li>
<li>11th day and 25th day(Redeem a lot)—-Both of Wednesday</li>
<li>18 19 20(Both Purchase and Redeem is very low)</li>
</ol>
<h2 id="4-5-画出历史所有天的热力图"><a href="#4-5-画出历史所有天的热力图" class="headerlink" title="4.5 画出历史所有天的热力图"></a>4.5 画出历史所有天的热力图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">test = np.zeros((max(total_balance_1[<span class="string">'week'</span>]) - min(total_balance_1[<span class="string">'week'</span>]) + <span class="number">1</span>, <span class="number">7</span>))</span><br><span class="line">test[total_balance_1[<span class="string">'week'</span>] - min(total_balance_1[<span class="string">'week'</span>]), total_balance_1[<span class="string">'weekday'</span>]] = total_balance_1[<span class="string">'total_purchase_amt'</span>]</span><br><span class="line"></span><br><span class="line">f, ax = plt.subplots(figsize = (<span class="number">10</span>, <span class="number">4</span>))</span><br><span class="line">sns.heatmap(test,linewidths = <span class="number">0.1</span>, ax=ax)</span><br><span class="line">ax.set_title(<span class="string">"Purchase"</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">'weekday'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'week'</span>)</span><br><span class="line"></span><br><span class="line">test = np.zeros((max(total_balance_1[<span class="string">'week'</span>]) - min(total_balance_1[<span class="string">'week'</span>]) + <span class="number">1</span>, <span class="number">7</span>))</span><br><span class="line">test[total_balance_1[<span class="string">'week'</span>] - min(total_balance_1[<span class="string">'week'</span>]), total_balance_1[<span class="string">'weekday'</span>]] = total_balance_1[<span class="string">'total_redeem_amt'</span>]</span><br><span class="line"></span><br><span class="line">f, ax = plt.subplots(figsize = (<span class="number">10</span>, <span class="number">4</span>))</span><br><span class="line">sns.heatmap(test,linewidths = <span class="number">0.1</span>, ax=ax)</span><br><span class="line">ax.set_title(<span class="string">"Redeem"</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">'weekday'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'week'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Text(69.0, 0.5, &#39;week&#39;)
</code></pre><p><img src="/Pic/Untitled/output_36_1.png" alt="png"></p>
<p><img src="/Pic/Untitled/output_36_2.png" alt="png"></p>
<p>From the heat map we find that the data of week 4 and weekday 6 is very strange, and week 12 weekday 2 either</p>
<h3 id="异常点分析-1"><a href="#异常点分析-1" class="headerlink" title="异常点分析(1)"></a>异常点分析(1)</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">total_balance_1[(total_balance_1[<span class="string">'week'</span>] == <span class="number">4</span> + min(total_balance_1[<span class="string">'week'</span>])) &amp; (total_balance_1[<span class="string">'weekday'</span>] == <span class="number">6</span>)]</span><br></pre></td></tr></table></figure>
<p><strong>2014-5-4 is a special day in China, It is the first workday after the Labour day!</strong></p>
<h3 id="异常点分析-2"><a href="#异常点分析-2" class="headerlink" title="异常点分析(2)"></a>异常点分析(2)</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">total_balance_1[(total_balance_1[<span class="string">'week'</span>] == <span class="number">12</span> + min(total_balance_1[<span class="string">'week'</span>])) &amp; (total_balance_1[<span class="string">'weekday'</span>] == <span class="number">2</span>)]</span><br></pre></td></tr></table></figure>
<h1 id="五、对于节假期的分析"><a href="#五、对于节假期的分析" class="headerlink" title="五、对于节假期的分析"></a>五、对于节假期的分析</h1><ol>
<li>The QingMing festerval (April.5 - April.7)</li>
<li>The Labour day      (May.1 - May.5)</li>
<li>The DuanWu festeval (May.31 - June.2)</li>
<li>The MidAutumn festeval (Sep.6 - Sep.8)</li>
<li>Mother day(May.13)</li>
<li>Father day(June. 17)</li>
<li>TianMao 618 sales(June 10 - June 20)</li>
<li>Teachers’ day(Sep 9)</li>
</ol>
<h2 id="5-1-获取节假日的数据"><a href="#5-1-获取节假日的数据" class="headerlink" title="5.1 获取节假日的数据"></a>5.1 获取节假日的数据</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">qingming = total_balance[(total_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,<span class="number">4</span>,<span class="number">5</span>)) &amp; (total_balance[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>,<span class="number">4</span>,<span class="number">8</span>))]</span><br><span class="line">labour = total_balance[(total_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,<span class="number">5</span>,<span class="number">1</span>)) &amp; (total_balance[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>,<span class="number">5</span>,<span class="number">4</span>))]</span><br><span class="line">duanwu = total_balance[(total_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,<span class="number">5</span>,<span class="number">31</span>)) &amp; (total_balance[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>,<span class="number">6</span>,<span class="number">3</span>))]</span><br><span class="line">data618 = total_balance[(total_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,<span class="number">6</span>,<span class="number">10</span>)) &amp; (total_balance[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>,<span class="number">6</span>,<span class="number">20</span>))]</span><br></pre></td></tr></table></figure>
<h2 id="5-2-画出节假日与平时的均值"><a href="#5-2-画出节假日与平时的均值" class="headerlink" title="5.2 画出节假日与平时的均值"></a>5.2 画出节假日与平时的均值</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">index_list = [<span class="string">'QM'</span>,<span class="string">'Labour'</span>,<span class="string">'DW'</span>,<span class="string">'618'</span>,<span class="string">'Mean'</span>]</span><br><span class="line">label_list = [np.mean(qingming[<span class="string">'total_purchase_amt'</span>]), np.mean(labour[<span class="string">'total_purchase_amt'</span>]),np.mean(duanwu[<span class="string">'total_purchase_amt'</span>]),np.mean(data618[<span class="string">'total_purchase_amt'</span>]),np.mean(total_balance_1[<span class="string">'total_purchase_amt'</span>])]</span><br><span class="line">plt.bar(index_list, label_list, label=<span class="string">"Purchase"</span>)</span><br><span class="line"></span><br><span class="line">index_list = [<span class="string">'QM.'</span>,<span class="string">'Labour.'</span>,<span class="string">'DW.'</span>,<span class="string">'618.'</span>,<span class="string">'Mean.'</span>]</span><br><span class="line">label_list = [np.mean(qingming[<span class="string">'total_redeem_amt'</span>]), np.mean(labour[<span class="string">'total_redeem_amt'</span>]),np.mean(duanwu[<span class="string">'total_redeem_amt'</span>]),np.mean(data618[<span class="string">'total_redeem_amt'</span>]),np.mean(total_balance_1[<span class="string">'total_redeem_amt'</span>])]</span><br><span class="line">plt.bar(index_list, label_list, label=<span class="string">"Redeem"</span>)</span><br><span class="line">plt.title(<span class="string">"The average of different holiday"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Amount"</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_45_0.png" alt="png"></p>
<p><img src="/Pic/Untitled/output_46_0-1597931424436.png" alt="output_46_0"></p>
<h2 id="5-3-画出节假日购买量与其所处翌日的对比"><a href="#5-3-画出节假日购买量与其所处翌日的对比" class="headerlink" title="5.3 画出节假日购买量与其所处翌日的对比"></a>5.3 画出节假日购买量与其所处翌日的对比</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">size = <span class="number">4</span></span><br><span class="line">x = np.arange(size)</span><br><span class="line"></span><br><span class="line">total_width, n = <span class="number">0.8</span>, <span class="number">2</span>    </span><br><span class="line">width = total_width / n</span><br><span class="line">x = x - (total_width - width) / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">a = [<span class="number">176250006</span>, <span class="number">167825284</span>, <span class="number">162844282</span>,<span class="number">321591063</span>]</span><br><span class="line">b = [<span class="number">225337516</span>, <span class="number">241859315</span>, <span class="number">225337516</span>,<span class="number">307635449</span>]</span><br><span class="line"></span><br><span class="line">plt.bar(x, a,  width=width, label=<span class="string">'Holiday_Purchase'</span>)</span><br><span class="line">plt.bar(x + width, b, width=width, label=<span class="string">'Normal_Purchase'</span>)</span><br><span class="line">plt.xticks(x + width / <span class="number">2</span>, (<span class="string">'QingMing'</span>, <span class="string">'Labour'</span>, <span class="string">'DuanWu'</span>, <span class="string">'618'</span>))</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_46_0.png" alt="png"></p>
<h2 id="5-4-画出节假日赎回量与其所处翌日的对比"><a href="#5-4-画出节假日赎回量与其所处翌日的对比" class="headerlink" title="5.4 画出节假日赎回量与其所处翌日的对比"></a>5.4 画出节假日赎回量与其所处翌日的对比</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">size = <span class="number">4</span></span><br><span class="line">x = np.arange(size)</span><br><span class="line"></span><br><span class="line">total_width, n = <span class="number">0.8</span>, <span class="number">2</span>     </span><br><span class="line">width = total_width / n</span><br><span class="line">x = x - (total_width - width) / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">a = [<span class="number">159914308</span>, <span class="number">154717620</span>, <span class="number">154366940</span>,<span class="number">291016763</span>]</span><br><span class="line">b = [<span class="number">235439685</span>, <span class="number">240364238</span>, <span class="number">235439685</span>,<span class="number">313310347</span>]</span><br><span class="line"></span><br><span class="line">plt.bar(x, a,  width=width, label=<span class="string">'Holiday_Redeem'</span>)</span><br><span class="line">plt.bar(x + width, b, width=width, label=<span class="string">'Normal_Redeem'</span>)</span><br><span class="line">plt.xticks(x + width / <span class="number">2</span>, (<span class="string">'QingMing'</span>, <span class="string">'Labour'</span>, <span class="string">'DuanWu'</span>, <span class="string">'618'</span>))</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_47_0.png" alt="png"></p>
<h1 id="六、对于节假日周边日期的分析"><a href="#六、对于节假日周边日期的分析" class="headerlink" title="六、对于节假日周边日期的分析"></a>六、对于节假日周边日期的分析</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 画出清明节与周边日期的时序图</span></span><br><span class="line"></span><br><span class="line">qingming_around = total_balance[(total_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,<span class="number">4</span>,<span class="number">1</span>)) &amp; (total_balance[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>,<span class="number">4</span>,<span class="number">13</span>))]</span><br><span class="line">ax = sns.lineplot(x=<span class="string">"date"</span>, y=<span class="string">"total_purchase_amt"</span>, data=qingming_around, label=<span class="string">'Purchase'</span>)</span><br><span class="line">ax = sns.lineplot(x=<span class="string">"date"</span>, y=<span class="string">"total_redeem_amt"</span>, data=qingming_around, label=<span class="string">'Redeem'</span>, ax=ax)</span><br><span class="line">ax = sns.scatterplot(x=<span class="string">"date"</span>, y=<span class="string">"total_purchase_amt"</span>, data=qingming, ax=ax)</span><br><span class="line">ax = sns.scatterplot(x=<span class="string">"date"</span>, y=<span class="string">"total_redeem_amt"</span>, data=qingming, ax=ax)</span><br><span class="line">plt.title(<span class="string">"The data around Qingming Holiday"</span>)</span><br><span class="line">ax.legend()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_49_1.png" alt="png"></p>
<h2 id="6-1-画出劳动节与周边日期的时序图"><a href="#6-1-画出劳动节与周边日期的时序图" class="headerlink" title="6.1 画出劳动节与周边日期的时序图"></a>6.1 画出劳动节与周边日期的时序图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">labour_around = total_balance[(total_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,<span class="number">4</span>,<span class="number">25</span>)) &amp; (total_balance[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>,<span class="number">5</span>,<span class="number">10</span>))]</span><br><span class="line">ax = sns.lineplot(x=<span class="string">"date"</span>, y=<span class="string">"total_purchase_amt"</span>, data=labour_around, label=<span class="string">'Purchase'</span>)</span><br><span class="line">ax = sns.lineplot(x=<span class="string">"date"</span>, y=<span class="string">"total_redeem_amt"</span>, data=labour_around, label=<span class="string">'Redeem'</span>, ax=ax)</span><br><span class="line">ax = sns.scatterplot(x=<span class="string">"date"</span>, y=<span class="string">"total_purchase_amt"</span>, data=labour, ax=ax)</span><br><span class="line">ax = sns.scatterplot(x=<span class="string">"date"</span>, y=<span class="string">"total_redeem_amt"</span>, data=labour, ax=ax)</span><br><span class="line">plt.title(<span class="string">"The data around Labour holiday"</span>)</span><br><span class="line">ax.legend()</span><br></pre></td></tr></table></figure>
<p><img src="/posts/Untitled/output_50_1.png" alt="png"></p>
<h2 id="6-2-画出端午节与周边日期的时序图"><a href="#6-2-画出端午节与周边日期的时序图" class="headerlink" title="6.2 画出端午节与周边日期的时序图"></a>6.2 画出端午节与周边日期的时序图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">duanwu_around = total_balance[(total_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,<span class="number">5</span>,<span class="number">25</span>)) &amp; (total_balance[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>,<span class="number">6</span>,<span class="number">7</span>))]</span><br><span class="line">ax = sns.lineplot(x=<span class="string">"date"</span>, y=<span class="string">"total_purchase_amt"</span>, data=duanwu_around, label=<span class="string">'Purchase'</span>)</span><br><span class="line">ax = sns.lineplot(x=<span class="string">"date"</span>, y=<span class="string">"total_redeem_amt"</span>, data=duanwu_around, label=<span class="string">'Redeem'</span>, ax=ax)</span><br><span class="line">ax = sns.scatterplot(x=<span class="string">"date"</span>, y=<span class="string">"total_purchase_amt"</span>, data=duanwu, ax=ax)</span><br><span class="line">ax = sns.scatterplot(x=<span class="string">"date"</span>, y=<span class="string">"total_redeem_amt"</span>, data=duanwu, ax=ax)</span><br><span class="line">plt.title(<span class="string">"The data around Duanwu Holiday"</span>)</span><br><span class="line">ax.legend()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_51_1.png" alt="png"></p>
<h2 id="6-3-画出中秋与周边日期的时序图"><a href="#6-3-画出中秋与周边日期的时序图" class="headerlink" title="6.3 画出中秋与周边日期的时序图"></a>6.3 画出中秋与周边日期的时序图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">zhongqiu = total_balance[(total_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2013</span>,<span class="number">9</span>,<span class="number">19</span>)) &amp; (total_balance[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2013</span>,<span class="number">9</span>,<span class="number">22</span>))]</span><br><span class="line">zhongqiu_around = total_balance[(total_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2013</span>,<span class="number">9</span>,<span class="number">14</span>)) &amp; (total_balance[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2013</span>,<span class="number">9</span>,<span class="number">28</span>))]</span><br><span class="line">ax = sns.lineplot(x=<span class="string">"date"</span>, y=<span class="string">"total_purchase_amt"</span>, data=zhongqiu_around, label=<span class="string">'Purchase'</span>)</span><br><span class="line">ax = sns.lineplot(x=<span class="string">"date"</span>, y=<span class="string">"total_redeem_amt"</span>, data=zhongqiu_around, label=<span class="string">'Redeem'</span>, ax=ax)</span><br><span class="line">ax = sns.scatterplot(x=<span class="string">"date"</span>, y=<span class="string">"total_purchase_amt"</span>, data=zhongqiu, ax=ax)</span><br><span class="line">ax = sns.scatterplot(x=<span class="string">"date"</span>, y=<span class="string">"total_redeem_amt"</span>, data=zhongqiu, ax=ax)</span><br><span class="line">plt.title(<span class="string">"The data around MiddleAutumn Holiday(in 2013)"</span>)</span><br><span class="line">ax.legend()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_52_1-1597929863470.png" alt="png"></p>
<h1 id="七、对于异常值的分析"><a href="#七、对于异常值的分析" class="headerlink" title="七、对于异常值的分析"></a>七、对于异常值的分析</h1><h2 id="7-1-画出用户交易纪录的箱型图"><a href="#7-1-画出用户交易纪录的箱型图" class="headerlink" title="7.1 画出用户交易纪录的箱型图"></a>7.1 画出用户交易纪录的箱型图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.boxplot(data_balance[<span class="string">'total_purchase_amt'</span>])</span><br><span class="line">plt.title(<span class="string">"The abnormal value of total purchase"</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_54_1-1597929867211.png" alt="png"></p>
<h2 id="7-2-对于购买2e8的用户的交易行为分析"><a href="#7-2-对于购买2e8的用户的交易行为分析" class="headerlink" title="7.2 对于购买2e8的用户的交易行为分析"></a>7.2 对于购买2e8的用户的交易行为分析</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_balance[data_balance[<span class="string">'user_id'</span>] == <span class="number">14592</span>].sort_values(by = <span class="string">'total_redeem_amt'</span>,axis = <span class="number">0</span>,ascending = <span class="literal">False</span>).head()</span><br></pre></td></tr></table></figure>
<h2 id="7-3-画出单笔交易为2e8的那天的总交易量及附近几天的交易量"><a href="#7-3-画出单笔交易为2e8的那天的总交易量及附近几天的交易量" class="headerlink" title="7.3 画出单笔交易为2e8的那天的总交易量及附近几天的交易量"></a>7.3 画出单笔交易为2e8的那天的总交易量及附近几天的交易量</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">e2 = total_balance[(total_balance[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2013</span>,<span class="number">11</span>,<span class="number">1</span>)) &amp; (total_balance[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2013</span>,<span class="number">11</span>,<span class="number">10</span>))]</span><br><span class="line">ax = sns.barplot(x=<span class="string">"day"</span>, y=<span class="string">"total_purchase_amt"</span>, data=e2, label=<span class="string">'2E'</span>)</span><br><span class="line">ax = sns.lineplot(x=<span class="string">"day"</span>, y=<span class="string">"total_purchase_amt"</span>, data=e2, label=<span class="string">'2E'</span>)</span><br><span class="line">plt.title(<span class="string">"The influence of the big deal with 200 million purchasing(Red Bar)"</span>)</span><br><span class="line">ax.legend()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_57_1-1597929889358.png" alt="png"></p>
<h2 id="7-4-画出每日单笔最大交易的时序图"><a href="#7-4-画出每日单笔最大交易的时序图" class="headerlink" title="7.4 画出每日单笔最大交易的时序图"></a>7.4 画出每日单笔最大交易的时序图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">6</span>))</span><br><span class="line">ax = sns.lineplot(x=<span class="string">"date"</span>, y=<span class="string">"total_purchase_amt"</span>, data=data_balance[[<span class="string">'total_purchase_amt'</span>, <span class="string">'date'</span>]].groupby(<span class="string">'date'</span>, as_index=<span class="literal">False</span>).max(), label=<span class="string">'MAX_PURCHASE'</span>)</span><br><span class="line">ax = sns.lineplot(x=<span class="string">"date"</span>, y=<span class="string">"total_redeem_amt"</span>, data=data_balance[[<span class="string">'total_redeem_amt'</span>, <span class="string">'date'</span>]].groupby(<span class="string">'date'</span>, as_index=<span class="literal">False</span>).max(), label=<span class="string">'MAX_REDEEM'</span>)</span><br><span class="line">plt.title(<span class="string">"The Biggest deal happend in each day"</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_58_1-1597929896511.png" alt="png"></p>
<h2 id="7-5-画出每日单笔最大交易以及总交易额的时序图"><a href="#7-5-画出每日单笔最大交易以及总交易额的时序图" class="headerlink" title="7.5 画出每日单笔最大交易以及总交易额的时序图"></a>7.5 画出每日单笔最大交易以及总交易额的时序图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">6</span>))</span><br><span class="line">ax = sns.lineplot(x=<span class="string">"date"</span>, y=<span class="string">"total_purchase_amt"</span>, data=data_balance[[<span class="string">'total_purchase_amt'</span>, <span class="string">'date'</span>]].groupby(<span class="string">'date'</span>, as_index=<span class="literal">False</span>).max(), label=<span class="string">'MAX_PURCHASE'</span>)</span><br><span class="line">ax = sns.lineplot(x=<span class="string">"date"</span>, y=<span class="string">"total_redeem_amt"</span>, data=data_balance[[<span class="string">'total_redeem_amt'</span>, <span class="string">'date'</span>]].groupby(<span class="string">'date'</span>, as_index=<span class="literal">False</span>).max(), label=<span class="string">'MAX_REDEEM'</span>)</span><br><span class="line">ax = sns.lineplot(x=<span class="string">"date"</span>, y=<span class="string">"total_purchase_amt"</span>, data=data_balance[[<span class="string">'total_purchase_amt'</span>, <span class="string">'date'</span>]].groupby(<span class="string">'date'</span>, as_index=<span class="literal">False</span>).sum(), label=<span class="string">'TOTAL_PURCHASE'</span>)</span><br><span class="line">ax = sns.lineplot(x=<span class="string">"date"</span>, y=<span class="string">"total_redeem_amt"</span>, data=data_balance[[<span class="string">'total_redeem_amt'</span>, <span class="string">'date'</span>]].groupby(<span class="string">'date'</span>, as_index=<span class="literal">False</span>).sum(), label=<span class="string">'TOTAL_REDEEM'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_59_0-1597929899546.png" alt="png"></p>
<h2 id="7-6-画出每个月大额交易的频次直方图"><a href="#7-6-画出每个月大额交易的频次直方图" class="headerlink" title="7.6 画出每个月大额交易的频次直方图"></a>7.6 画出每个月大额交易的频次直方图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">big_frequancy = data_balance[(data_balance[<span class="string">'total_purchase_amt'</span>] &gt; <span class="number">10000000</span>) | (data_balance[<span class="string">'total_redeem_amt'</span>] &gt; <span class="number">10000000</span>)][[<span class="string">'month'</span>,<span class="string">'year'</span>,<span class="string">'user_id'</span>]].groupby([<span class="string">'year'</span>,<span class="string">'month'</span>], as_index=<span class="literal">False</span>).count()</span><br><span class="line">big_frequancy[<span class="string">'i'</span>] = big_frequancy[<span class="string">'year'</span>]  + big_frequancy[<span class="string">'month'</span>] / <span class="number">100</span></span><br><span class="line">ax = sns.barplot(x=<span class="string">"i"</span>, y=<span class="string">"user_id"</span>, data=big_frequancy)</span><br><span class="line">plt.title(<span class="string">"The frequency of super big deal(larger than 100million) in each month"</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_60_1-1597929902176.png" alt="png"></p>
<h2 id="7-7-获取大额交易的数据集"><a href="#7-7-获取大额交易的数据集" class="headerlink" title="7.7 获取大额交易的数据集"></a>7.7 获取大额交易的数据集</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_balance[<span class="string">'big_purchase'</span>] = <span class="number">0</span></span><br><span class="line">data_balance.loc[data_balance[<span class="string">'total_purchase_amt'</span>] &gt; <span class="number">1000000</span>, <span class="string">'big_purchase'</span>] = <span class="number">1</span></span><br><span class="line">data_balance[<span class="string">'big_redeem'</span>] = <span class="number">0</span></span><br><span class="line">data_balance.loc[data_balance[<span class="string">'total_redeem_amt'</span>] &gt; <span class="number">1000000</span>, <span class="string">'big_redeem'</span>] = <span class="number">1</span></span><br></pre></td></tr></table></figure>
<h2 id="7-8-对大额交易按每天做聚合操作"><a href="#7-8-对大额交易按每天做聚合操作" class="headerlink" title="7.8 对大额交易按每天做聚合操作"></a>7.8 对大额交易按每天做聚合操作</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">big_purchase = data_balance[data_balance[<span class="string">'big_purchase'</span>] == <span class="number">1</span>].groupby([<span class="string">'date'</span>], as_index=<span class="literal">False</span>)[<span class="string">'total_purchase_amt'</span>].sum()</span><br><span class="line">small_purchase = data_balance[data_balance[<span class="string">'big_purchase'</span>] == <span class="number">0</span>].groupby([<span class="string">'date'</span>], as_index=<span class="literal">False</span>)[<span class="string">'total_purchase_amt'</span>].sum()</span><br><span class="line">big_redeem = data_balance[data_balance[<span class="string">'big_redeem'</span>] == <span class="number">1</span>].groupby([<span class="string">'date'</span>], as_index=<span class="literal">False</span>)[<span class="string">'total_redeem_amt'</span>].sum()</span><br><span class="line">small_redeem = data_balance[data_balance[<span class="string">'big_redeem'</span>] == <span class="number">0</span>].groupby([<span class="string">'date'</span>], as_index=<span class="literal">False</span>)[<span class="string">'total_redeem_amt'</span>].sum()</span><br></pre></td></tr></table></figure>
<h2 id="7-9-画出大额交易与小额交易的时序分布图"><a href="#7-9-画出大额交易与小额交易的时序分布图" class="headerlink" title="7.9 画出大额交易与小额交易的时序分布图"></a>7.9 画出大额交易与小额交易的时序分布图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">6</span>))</span><br><span class="line">plt.plot(big_purchase[<span class="string">'date'</span>], big_purchase[<span class="string">'total_purchase_amt'</span>],label=<span class="string">'big_purchase'</span>)</span><br><span class="line">plt.plot(big_redeem[<span class="string">'date'</span>], big_redeem[<span class="string">'total_redeem_amt'</span>],label=<span class="string">'big_redeem'</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(small_purchase[<span class="string">'date'</span>], small_purchase[<span class="string">'total_purchase_amt'</span>],label=<span class="string">'small_purchase'</span>)</span><br><span class="line">plt.plot(small_redeem[<span class="string">'date'</span>], small_redeem[<span class="string">'total_redeem_amt'</span>],label=<span class="string">'small_redeem'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">plt.title(<span class="string">"The time series of big deal of Purchase and Redeem from July.13 to Sep.14"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Amount"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_63_0-1597929905444.png" alt="png"></p>
<h2 id="7-10-画出大额交易与小额交易的分布估计图"><a href="#7-10-画出大额交易与小额交易的分布估计图" class="headerlink" title="7.10 画出大额交易与小额交易的分布估计图"></a>7.10 画出大额交易与小额交易的分布估计图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>, <span class="number">9</span>):</span><br><span class="line">    sns.kdeplot(big_purchase[(big_purchase[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,i,<span class="number">1</span>)) &amp; (big_purchase[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>,i+<span class="number">1</span>,<span class="number">1</span>))][<span class="string">'total_purchase_amt'</span>],label=<span class="string">'14Y,'</span>+str(i)+<span class="string">'M'</span>)</span><br><span class="line">plt.title(<span class="string">'BIG PURCHASE'</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>, <span class="number">9</span>):</span><br><span class="line">    sns.kdeplot(small_purchase[(small_purchase[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,i,<span class="number">1</span>)) &amp; (small_purchase[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>,i+<span class="number">1</span>,<span class="number">1</span>))][<span class="string">'total_purchase_amt'</span>],label=<span class="string">'14Y,'</span>+str(i)+<span class="string">'M'</span>)</span><br><span class="line">plt.title(<span class="string">'SMALL PURCHASE'</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>, <span class="number">9</span>):</span><br><span class="line">    sns.kdeplot(big_redeem[(big_redeem[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,i,<span class="number">1</span>)) &amp; (big_redeem[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>,i+<span class="number">1</span>,<span class="number">1</span>))][<span class="string">'total_redeem_amt'</span>],label=<span class="string">'14Y,'</span>+str(i)+<span class="string">'M'</span>)</span><br><span class="line">plt.title(<span class="string">'BIG REDEEM'</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>, <span class="number">9</span>):</span><br><span class="line">    sns.kdeplot(small_redeem[(small_redeem[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,i,<span class="number">1</span>)) &amp; (small_redeem[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>,i+<span class="number">1</span>,<span class="number">1</span>))][<span class="string">'total_redeem_amt'</span>],label=<span class="string">'14Y,'</span>+str(i)+<span class="string">'M'</span>)</span><br><span class="line">plt.title(<span class="string">'SMALL REDEEM'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_64_1-1597929908939.png" alt="png"></p>
<h2 id="7-11-添加时间戳"><a href="#7-11-添加时间戳" class="headerlink" title="7.11 添加时间戳"></a>7.11 添加时间戳</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">big_purchase[<span class="string">'weekday'</span>] = big_purchase[<span class="string">'date'</span>].dt.weekday</span><br><span class="line">small_purchase[<span class="string">'weekday'</span>] = small_purchase[<span class="string">'date'</span>].dt.weekday</span><br><span class="line">big_redeem[<span class="string">'weekday'</span>] = big_redeem[<span class="string">'date'</span>].dt.weekday</span><br><span class="line">small_redeem[<span class="string">'weekday'</span>] = small_redeem[<span class="string">'date'</span>].dt.weekday</span><br></pre></td></tr></table></figure>
<h2 id="7-12-分析大额小额的翌日分布"><a href="#7-12-分析大额小额的翌日分布" class="headerlink" title="7.12 分析大额小额的翌日分布"></a>7.12 分析大额小额的翌日分布</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">ax = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">ax = sns.boxplot(x=<span class="string">"weekday"</span>, y=<span class="string">"total_purchase_amt"</span>, data=big_purchase[big_purchase[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,<span class="number">4</span>,<span class="number">1</span>)])</span><br><span class="line">plt.title(<span class="string">'BIG PURCHASE'</span>)</span><br><span class="line"></span><br><span class="line">ax = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">ax = sns.boxplot(x=<span class="string">"weekday"</span>, y=<span class="string">"total_redeem_amt"</span>, data=big_redeem[big_redeem[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,<span class="number">4</span>,<span class="number">1</span>)])</span><br><span class="line">plt.title(<span class="string">'BIG REDEEM'</span>)</span><br><span class="line"></span><br><span class="line">ax = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">ax = sns.boxplot(x=<span class="string">"weekday"</span>, y=<span class="string">"total_purchase_amt"</span>, data=small_purchase[small_purchase[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,<span class="number">4</span>,<span class="number">1</span>)])</span><br><span class="line">plt.title(<span class="string">'SMALL PURCHASE'</span>)</span><br><span class="line"></span><br><span class="line">ax = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line">ax = sns.boxplot(x=<span class="string">"weekday"</span>, y=<span class="string">"total_redeem_amt"</span>, data=small_redeem[small_redeem[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,<span class="number">4</span>,<span class="number">1</span>)])</span><br><span class="line">plt.title(<span class="string">'SMALL REDEEM'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_66_1-1597929912400.png" alt="png"></p>
<h1 id="八、分析用户交易纪录表中其他变量"><a href="#八、分析用户交易纪录表中其他变量" class="headerlink" title="八、分析用户交易纪录表中其他变量"></a>八、分析用户交易纪录表中其他变量</h1><h2 id="8-1-截断数据集"><a href="#8-1-截断数据集" class="headerlink" title="8.1 截断数据集"></a>8.1 截断数据集</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_balance_1 = data_balance[data_balance[<span class="string">'date'</span>] &gt; datetime.datetime(<span class="number">2014</span>,<span class="number">4</span>,<span class="number">1</span>)]</span><br></pre></td></tr></table></figure>
<h2 id="8-2-画出用户交易纪录表中其他变量与标签的相关性图"><a href="#8-2-画出用户交易纪录表中其他变量与标签的相关性图" class="headerlink" title="8.2 画出用户交易纪录表中其他变量与标签的相关性图"></a>8.2 画出用户交易纪录表中其他变量与标签的相关性图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">feature = [<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>, <span class="string">'report_date'</span>, <span class="string">'tBalance'</span>, <span class="string">'yBalance'</span>, </span><br><span class="line">       <span class="string">'direct_purchase_amt'</span>, <span class="string">'purchase_bal_amt'</span>, <span class="string">'purchase_bank_amt'</span>,</span><br><span class="line">        <span class="string">'consume_amt'</span>, <span class="string">'transfer_amt'</span>, <span class="string">'tftobal_amt'</span>,</span><br><span class="line">       <span class="string">'tftocard_amt'</span>, <span class="string">'share_amt'</span>]</span><br><span class="line"></span><br><span class="line">sns.heatmap(data_balance_1[feature].corr(), linewidths = <span class="number">0.05</span>)   </span><br><span class="line">plt.title(<span class="string">"The coleration between each feature in User_Balance_Table"</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_69_1-1597929915541.png" alt="png"></p>
<h1 id="九、对于银行及支付宝利率的分析"><a href="#九、对于银行及支付宝利率的分析" class="headerlink" title="九、对于银行及支付宝利率的分析"></a>九、对于银行及支付宝利率的分析</h1><h2 id="9-1-读取银行利率并添加时间戳"><a href="#9-1-读取银行利率并添加时间戳" class="headerlink" title="9.1 读取银行利率并添加时间戳"></a>9.1 读取银行利率并添加时间戳</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">bank = pd.read_csv(dataset_path + <span class="string">"mfd_bank_shibor.csv"</span>)</span><br><span class="line">bank = bank.rename(columns = &#123;<span class="string">'mfd_date'</span>: <span class="string">'date'</span>&#125;)</span><br><span class="line">bank_features = [x <span class="keyword">for</span> x <span class="keyword">in</span> bank.columns <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'date'</span>]]</span><br><span class="line">bank[<span class="string">'date'</span>] = pd.to_datetime(bank[<span class="string">'date'</span>], format= <span class="string">"%Y%m%d"</span>)</span><br><span class="line">bank[<span class="string">'day'</span>] = bank[<span class="string">'date'</span>].dt.day</span><br><span class="line">bank[<span class="string">'month'</span>] = bank[<span class="string">'date'</span>].dt.month</span><br><span class="line">bank[<span class="string">'year'</span>] = bank[<span class="string">'date'</span>].dt.year</span><br><span class="line">bank[<span class="string">'week'</span>] = bank[<span class="string">'date'</span>].dt.week</span><br><span class="line">bank[<span class="string">'weekday'</span>] = bank[<span class="string">'date'</span>].dt.weekday</span><br></pre></td></tr></table></figure>
<h2 id="9-2-读取支付宝利率并添加时间戳"><a href="#9-2-读取支付宝利率并添加时间戳" class="headerlink" title="9.2 读取支付宝利率并添加时间戳"></a>9.2 读取支付宝利率并添加时间戳</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">share = pd.read_csv(dataset_path + <span class="string">'mfd_day_share_interest.csv'</span>)</span><br><span class="line">share = share.rename(columns = &#123;<span class="string">'mfd_date'</span>: <span class="string">'date'</span>&#125;)</span><br><span class="line">share_features = [x <span class="keyword">for</span> x <span class="keyword">in</span> share.columns <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'date'</span>]]</span><br><span class="line">share[<span class="string">'date'</span>] = pd.to_datetime(share[<span class="string">'date'</span>], format= <span class="string">"%Y%m%d"</span>)</span><br><span class="line">share[<span class="string">'day'</span>] = share[<span class="string">'date'</span>].dt.day</span><br><span class="line">share[<span class="string">'month'</span>] = share[<span class="string">'date'</span>].dt.month</span><br><span class="line">share[<span class="string">'year'</span>] = share[<span class="string">'date'</span>].dt.year</span><br><span class="line">share[<span class="string">'week'</span>] = share[<span class="string">'date'</span>].dt.week</span><br><span class="line">share[<span class="string">'weekday'</span>] = share[<span class="string">'date'</span>].dt.weekday</span><br></pre></td></tr></table></figure>
<h2 id="9-3-画出上一天银行及支付宝利率与标签的相关性图"><a href="#9-3-画出上一天银行及支付宝利率与标签的相关性图" class="headerlink" title="9.3 画出上一天银行及支付宝利率与标签的相关性图"></a>9.3 画出上一天银行及支付宝利率与标签的相关性图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">bank[<span class="string">'last_date'</span>] = bank[<span class="string">'date'</span>] + datetime.timedelta(days=<span class="number">1</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">4</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">"The coleration between each lastday bank rate and total purchase"</span>)</span><br><span class="line">temp = pd.merge(bank[[<span class="string">'last_date'</span>]+bank_features], total_balance, left_on=<span class="string">'last_date'</span>, right_on=<span class="string">'date'</span>)[[<span class="string">'total_purchase_amt'</span>]+bank_features]</span><br><span class="line">sns.heatmap(temp.corr(), linewidths = <span class="number">0.05</span>)  </span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">plt.title(<span class="string">"The coleration between each lastday bank rate and total redeem"</span>)</span><br><span class="line">temp = pd.merge(bank[[<span class="string">'last_date'</span>]+bank_features], total_balance, left_on=<span class="string">'last_date'</span>, right_on=<span class="string">'date'</span>)[[<span class="string">'total_redeem_amt'</span>]+bank_features]</span><br><span class="line">sns.heatmap(temp.corr(), linewidths = <span class="number">0.05</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_73_1-1597929918927.png" alt="png"></p>
<h2 id="9-4-画出上一星期银行及支付宝利率与标签的相关性图"><a href="#9-4-画出上一星期银行及支付宝利率与标签的相关性图" class="headerlink" title="9.4  画出上一星期银行及支付宝利率与标签的相关性图"></a>9.4  画出上一星期银行及支付宝利率与标签的相关性图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">bank[<span class="string">'last_week'</span>] = bank[<span class="string">'week'</span>] + <span class="number">1</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">4</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">"The coleration between each last week bank rate and total purchase"</span>)</span><br><span class="line">temp = pd.merge(bank[[<span class="string">'last_week'</span>,<span class="string">'weekday'</span>]+bank_features], total_balance, left_on=[<span class="string">'last_week'</span>,<span class="string">'weekday'</span>], right_on=[<span class="string">'week'</span>,<span class="string">'weekday'</span>])[[<span class="string">'total_purchase_amt'</span>]+bank_features]</span><br><span class="line">sns.heatmap(temp.corr(), linewidths = <span class="number">0.05</span>)  </span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">plt.title(<span class="string">"The coleration between each last week bank rate and total redeem"</span>)</span><br><span class="line">temp = pd.merge(bank[[<span class="string">'last_week'</span>,<span class="string">'weekday'</span>]+bank_features], total_balance, left_on=[<span class="string">'last_week'</span>,<span class="string">'weekday'</span>], right_on=[<span class="string">'week'</span>,<span class="string">'weekday'</span>])[[<span class="string">'total_redeem_amt'</span>]+bank_features]</span><br><span class="line">sns.heatmap(temp.corr(), linewidths = <span class="number">0.05</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_74_1-1597929921628.png" alt="png"></p>
<h2 id="9-5-分别画出上一星期银行及支付宝利率与大额小额数据的相关性图"><a href="#9-5-分别画出上一星期银行及支付宝利率与大额小额数据的相关性图" class="headerlink" title="9.5 分别画出上一星期银行及支付宝利率与大额小额数据的相关性图"></a>9.5 分别画出上一星期银行及支付宝利率与大额小额数据的相关性图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">bank[<span class="string">'last_date'</span>] = bank[<span class="string">'date'</span>] + datetime.timedelta(days=<span class="number">1</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">4</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">"The coleration of Small Rate purchase"</span>)</span><br><span class="line">temp = pd.merge(bank[[<span class="string">'last_date'</span>]+bank_features], small_purchase, left_on=<span class="string">'last_date'</span>, right_on=<span class="string">'date'</span>)[[<span class="string">'total_purchase_amt'</span>]+bank_features]</span><br><span class="line">sns.heatmap(temp.corr(), linewidths = <span class="number">0.05</span>)  </span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">plt.title(<span class="string">"The coleration of Small Rate redeem"</span>)</span><br><span class="line">temp = pd.merge(bank[[<span class="string">'last_date'</span>]+bank_features], small_redeem, left_on=<span class="string">'last_date'</span>, right_on=<span class="string">'date'</span>)[[<span class="string">'total_redeem_amt'</span>]+bank_features]</span><br><span class="line">sns.heatmap(temp.corr(), linewidths = <span class="number">0.05</span>)  </span><br><span class="line"></span><br><span class="line">bank[<span class="string">'last_date'</span>] = bank[<span class="string">'date'</span>] + datetime.timedelta(days=<span class="number">1</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">4</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">"The coleration of Big Rate purchase"</span>)</span><br><span class="line">temp = pd.merge(bank[[<span class="string">'last_date'</span>]+bank_features], big_purchase, left_on=<span class="string">'last_date'</span>, right_on=<span class="string">'date'</span>)[[<span class="string">'total_purchase_amt'</span>]+bank_features]</span><br><span class="line">sns.heatmap(temp.corr(), linewidths = <span class="number">0.05</span>)  </span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">plt.title(<span class="string">"The coleration of Big Rate redeem"</span>)</span><br><span class="line">temp = pd.merge(bank[[<span class="string">'last_date'</span>]+bank_features], big_redeem, left_on=<span class="string">'last_date'</span>, right_on=<span class="string">'date'</span>)[[<span class="string">'total_redeem_amt'</span>]+bank_features]</span><br><span class="line">sns.heatmap(temp.corr(), linewidths = <span class="number">0.05</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_75_1-1597929924624.png" alt="png"></p>
<p><img src="/Pic/Untitled/output_75_2-1597929926856.png" alt="png"></p>
<h2 id="9-6-画出银行利率的时序图"><a href="#9-6-画出银行利率的时序图" class="headerlink" title="9.6 画出银行利率的时序图"></a>9.6 画出银行利率的时序图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">5</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> bank_features:</span><br><span class="line">    plt.plot(bank[<span class="string">'date'</span>], bank[[i]] ,label=i)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">"The time series of bank rate"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Rate"</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_76_1-1597929929446.png" alt="png"></p>
<h2 id="9-7-画出部分银行利率与购买量的时序图"><a href="#9-7-画出部分银行利率与购买量的时序图" class="headerlink" title="9.7 画出部分银行利率与购买量的时序图"></a>9.7 画出部分银行利率与购买量的时序图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig,ax1 = plt.subplots(figsize=(<span class="number">15</span>,<span class="number">5</span>))</span><br><span class="line">plt.plot(bank[<span class="string">'date'</span>], bank[<span class="string">'Interest_3_M'</span>],<span class="string">'b'</span>,label=<span class="string">"Interest_3_M"</span>)</span><br><span class="line">plt.plot(bank[<span class="string">'date'</span>], bank[<span class="string">'Interest_6_M'</span>],<span class="string">'cyan'</span>,label=<span class="string">"Interest_6_M"</span>)</span><br><span class="line">plt.plot(bank[<span class="string">'date'</span>], bank[<span class="string">'Interest_9_M'</span>],<span class="string">'skyblue'</span>,label=<span class="string">"Interest_9_M"</span>)</span><br><span class="line"></span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">ax2=ax1.twinx()</span><br><span class="line">plt.plot(total_balance[<span class="string">'date'</span>], total_balance[<span class="string">'total_purchase_amt'</span>],<span class="string">'g'</span>,label=<span class="string">"Total purchase"</span>)</span><br><span class="line"></span><br><span class="line">plt.legend(loc=<span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">"The time series of bank rate and purchase"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Rate &amp; Amount"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_77_0-1597929932751.png" alt="png"></p>
<h2 id="9-8-画出部分银行利率与赎回量的时序图"><a href="#9-8-画出部分银行利率与赎回量的时序图" class="headerlink" title="9.8 画出部分银行利率与赎回量的时序图"></a>9.8 画出部分银行利率与赎回量的时序图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig,ax1 = plt.subplots(figsize=(<span class="number">15</span>,<span class="number">5</span>))</span><br><span class="line">plt.plot(bank[<span class="string">'date'</span>], bank[<span class="string">'Interest_3_M'</span>],<span class="string">'b'</span>,label=<span class="string">"Interest_3_M"</span>)</span><br><span class="line">plt.plot(bank[<span class="string">'date'</span>], bank[<span class="string">'Interest_6_M'</span>],<span class="string">'cyan'</span>,label=<span class="string">"Interest_6_M"</span>)</span><br><span class="line">plt.plot(bank[<span class="string">'date'</span>], bank[<span class="string">'Interest_9_M'</span>],<span class="string">'skyblue'</span>,label=<span class="string">"Interest_9_M"</span>)</span><br><span class="line"></span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">ax2=ax1.twinx()</span><br><span class="line">plt.plot(total_balance[<span class="string">'date'</span>], total_balance[<span class="string">'total_redeem_amt'</span>],<span class="string">'g'</span>,label=<span class="string">"Total redeem"</span>)</span><br><span class="line"></span><br><span class="line">plt.legend(loc=<span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">"The time series of bank rate and redeem"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Rate &amp; Amount"</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_78_0-1597929936293.png" alt="png"></p>
<h2 id="9-9-画出支付宝利率与标签的相关性图"><a href="#9-9-画出支付宝利率与标签的相关性图" class="headerlink" title="9.9 画出支付宝利率与标签的相关性图"></a>9.9 画出支付宝利率与标签的相关性图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">share[<span class="string">'last_date'</span>] = share[<span class="string">'date'</span>] + datetime.timedelta(days=<span class="number">1</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">4</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">temp = pd.merge(share[[<span class="string">'last_date'</span>]+share_features], total_balance, left_on=<span class="string">'last_date'</span>, right_on=<span class="string">'date'</span>)[[<span class="string">'total_purchase_amt'</span>]+share_features]</span><br><span class="line">sns.heatmap(temp.corr(), linewidths = <span class="number">0.05</span>, vmin = <span class="number">0</span>)  </span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">temp = pd.merge(share[[<span class="string">'last_date'</span>]+share_features], total_balance, left_on=<span class="string">'last_date'</span>, right_on=<span class="string">'date'</span>)[[<span class="string">'total_redeem_amt'</span>]+share_features]</span><br><span class="line">sns.heatmap(temp.corr(), linewidths = <span class="number">0.05</span>, vmin = <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_80_1-1597929939181.png" alt="png"></p>
<h2 id="9-10-画出银行利率与标签的相关性图"><a href="#9-10-画出银行利率与标签的相关性图" class="headerlink" title="9.10 画出银行利率与标签的相关性图"></a>9.10 画出银行利率与标签的相关性图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">share[<span class="string">'last_week'</span>] = share[<span class="string">'week'</span>] + <span class="number">1</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">4</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">temp = pd.merge(share[[<span class="string">'last_week'</span>,<span class="string">'weekday'</span>]+share_features], total_balance, left_on=[<span class="string">'last_week'</span>,<span class="string">'weekday'</span>], right_on=[<span class="string">'week'</span>,<span class="string">'weekday'</span>])[[<span class="string">'total_purchase_amt'</span>]+share_features]</span><br><span class="line">sns.heatmap(temp.corr(), linewidths = <span class="number">0.05</span>, vmin = <span class="number">0</span>)  </span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">temp = pd.merge(share[[<span class="string">'last_week'</span>,<span class="string">'weekday'</span>]+share_features], total_balance, left_on=[<span class="string">'last_week'</span>,<span class="string">'weekday'</span>], right_on=[<span class="string">'week'</span>,<span class="string">'weekday'</span>])[[<span class="string">'total_redeem_amt'</span>]+share_features]</span><br><span class="line">sns.heatmap(temp.corr(), linewidths = <span class="number">0.05</span>, vmin = <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_81_1-1597929941873.png" alt="png"></p>
<h2 id="9-11-画出支付宝利率与购买量的时序图"><a href="#9-11-画出支付宝利率与购买量的时序图" class="headerlink" title="9.11 画出支付宝利率与购买量的时序图"></a>9.11 画出支付宝利率与购买量的时序图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig,ax1 = plt.subplots(figsize=(<span class="number">15</span>,<span class="number">5</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> share_features:</span><br><span class="line">    plt.plot(share[<span class="string">'date'</span>], share[i],<span class="string">'b'</span>,label=i)</span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line">plt.legend()</span><br><span class="line">ax2=ax1.twinx()</span><br><span class="line">plt.plot(total_balance[<span class="string">'date'</span>], total_balance[<span class="string">'total_purchase_amt'</span>],<span class="string">'g'</span>,label=<span class="string">"Total purchase"</span>)</span><br><span class="line">plt.legend(loc=<span class="number">2</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_82_0-1597929944660.png" alt="png"></p>
<h2 id="9-12-画出支付宝利率与赎回量的时序图"><a href="#9-12-画出支付宝利率与赎回量的时序图" class="headerlink" title="9.12 画出支付宝利率与赎回量的时序图"></a>9.12 画出支付宝利率与赎回量的时序图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig,ax1 = plt.subplots(figsize=(<span class="number">15</span>,<span class="number">5</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> share_features:</span><br><span class="line">    plt.plot(share[<span class="string">'date'</span>], share[i],<span class="string">'b'</span>,label=i)</span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line">plt.legend()</span><br><span class="line">ax2=ax1.twinx()</span><br><span class="line">plt.plot(total_balance[<span class="string">'date'</span>], total_balance[<span class="string">'total_redeem_amt'</span>],<span class="string">'g'</span>,label=<span class="string">"Total redeem"</span>)</span><br><span class="line">plt.legend(loc=<span class="number">2</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_83_0-1597929948139.png" alt="png"></p>
<h2 id="9-13-画出大额小额数据与支付宝利率的相关性图"><a href="#9-13-画出大额小额数据与支付宝利率的相关性图" class="headerlink" title="9.13 画出大额小额数据与支付宝利率的相关性图"></a>9.13 画出大额小额数据与支付宝利率的相关性图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">share[<span class="string">'last_date'</span>] = share[<span class="string">'date'</span>] + datetime.timedelta(days=<span class="number">1</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">4</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">temp = pd.merge(share[[<span class="string">'last_date'</span>]+share_features], small_purchase, left_on=<span class="string">'last_date'</span>, right_on=<span class="string">'date'</span>)[[<span class="string">'total_purchase_amt'</span>]+share_features]</span><br><span class="line">sns.heatmap(temp.corr(), linewidths = <span class="number">0.05</span>, vmin=<span class="number">0</span>)  </span><br><span class="line">plt.title(<span class="string">"SMALL PURCHASE"</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">plt.title(<span class="string">"SMALL REDEEM"</span>)</span><br><span class="line">temp = pd.merge(share[[<span class="string">'last_date'</span>]+share_features], small_redeem, left_on=<span class="string">'last_date'</span>, right_on=<span class="string">'date'</span>)[[<span class="string">'total_redeem_amt'</span>]+share_features]</span><br><span class="line">sns.heatmap(temp.corr(), linewidths = <span class="number">0.05</span>, vmin=<span class="number">0</span>)  </span><br><span class="line"></span><br><span class="line">share[<span class="string">'last_date'</span>] = share[<span class="string">'date'</span>] + datetime.timedelta(days=<span class="number">1</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">4</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">"BIG PURCHASE"</span>)</span><br><span class="line">temp = pd.merge(share[[<span class="string">'last_date'</span>]+share_features], big_purchase, left_on=<span class="string">'last_date'</span>, right_on=<span class="string">'date'</span>)[[<span class="string">'total_purchase_amt'</span>]+share_features]</span><br><span class="line">sns.heatmap(temp.corr(), linewidths = <span class="number">0.05</span>, vmin=<span class="number">0</span>)  </span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">plt.title(<span class="string">"BIG REDEEM"</span>)</span><br><span class="line">temp = pd.merge(share[[<span class="string">'last_date'</span>]+share_features], big_redeem, left_on=<span class="string">'last_date'</span>, right_on=<span class="string">'date'</span>)[[<span class="string">'total_redeem_amt'</span>]+share_features]</span><br><span class="line">sns.heatmap(temp.corr(), linewidths = <span class="number">0.05</span>, vmin=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_84_1-1597929956760.png" alt="png"></p>
<p><img src="/Pic/Untitled/output_84_2-1597929959426.png" alt="png"></p>
<h2 id="9-14-画出银行利率与支付宝利率的时序图"><a href="#9-14-画出银行利率与支付宝利率的时序图" class="headerlink" title="9.14 画出银行利率与支付宝利率的时序图"></a>9.14 画出银行利率与支付宝利率的时序图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig,ax1 = plt.subplots(figsize=(<span class="number">15</span>,<span class="number">5</span>))</span><br><span class="line">plt.plot(bank[<span class="string">'date'</span>], bank[<span class="string">'Interest_3_M'</span>],c=<span class="string">'g'</span>,label= <span class="string">'BANK'</span>)</span><br><span class="line"></span><br><span class="line">plt.legend()</span><br><span class="line">ax2=ax1.twinx()</span><br><span class="line">plt.plot(share[<span class="string">'date'</span>], share[<span class="string">'mfd_daily_yield'</span>],label=<span class="string">'SHARE'</span>)</span><br><span class="line">plt.legend(loc=<span class="number">2</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/Untitled/output_85_0-1597929962321.png" alt="png"></p>
<p>It seems that:</p>
<ol>
<li>The influence of share is more likely to act on Purchase</li>
<li>The influence of bank rate is more likely to act on Redeem</li>
<li>The influence of share rate is for short</li>
<li>The influence of bank rate is for long</li>
</ol>
<p><strong>based on above analysis, we can simply find three features:</strong></p>
<ol>
<li><strong>the weekday</strong></li>
<li><strong>is it weekend</strong></li>
<li><strong>is it holidy</strong></li>
<li><strong>the distance from the start of week(monday)</strong></li>
<li><strong>the distance from the end of week(sunday)</strong></li>
<li><strong>the distance from the holiday centre(centre of QingMing DuanWu Labour ZhongQiu)</strong></li>
<li><strong>the distance from the start of month</strong></li>
<li><strong>the distance from the end of month</strong></li>
<li><strong>the mean/max/min value of the same week in last month</strong></li>
<li><strong>the value in last day of last month</strong></li>
</ol>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ul>
<li>金融数据的时序分析主要还是看风险、用户手头紧否(比如月初就容易赎回，月末)、市场利率</li>
<li>异常点分析：现实中不容忽视，是个关键问题，需要好好分析并给出一个合理的解释。</li>
</ul>
<h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><ul>
<li><a href="https://github.com/datawhalechina/team-learning-data-mining/tree/master/PurchaseAndRedemptionForecast" target="_blank" rel="noopener">https://github.com/datawhalechina/team-learning-data-mining/tree/master/PurchaseAndRedemptionForecast</a></li>
<li><a href="https://shimo.im/docs/CtrTpTgKh8phwqCW/read" target="_blank" rel="noopener">https://shimo.im/docs/CtrTpTgKh8phwqCW/read</a></li>
</ul>
]]></content>
      <categories>
        <category>Match</category>
      </categories>
  </entry>
  <entry>
    <title>JAVA基础（二）—— HashMap（更新中）</title>
    <url>/posts/ece897f8.html</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
  </entry>
  <entry>
    <title>JAVA基础（一）—— String</title>
    <url>/posts/3b6698e9.html</url>
    <content><![CDATA[<p>几乎所有JAVA面试都是以String开始的，因此掌握String知识点是至关重要的，下面我们以问题的形式与大家一起逐步解析String源码。</p>
<h1 id="String是如何实现的，它有哪些重要的方法？"><a href="#String是如何实现的，它有哪些重要的方法？" class="headerlink" title="String是如何实现的，它有哪些重要的方法？"></a>String是如何实现的，它有哪些重要的方法？</h1><h2 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h2><p>以主流的JDK版本1.8来说，String内部实际存储结构为参数组，源码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">String</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="keyword">implements</span> <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span>, <span class="title">Comparable</span>&lt;<span class="title">String</span>&gt;, <span class="title">CharSequence</span></span>&#123;</span><br><span class="line">    <span class="comment">// 用于存储字符串的值</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">char</span> value[];</span><br><span class="line">    <span class="comment">// 缓存字符串的hash code</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> hash; <span class="comment">//Default to 0</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="重要方法"><a href="#重要方法" class="headerlink" title="重要方法"></a>重要方法</h2><h3 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h3><p>String的构造方法有以下四种，其中最容易被忽略的是后两种：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// String 为参数的构造方法</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">String</span><span class="params">(String original)</span></span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.value = original.value;</span><br><span class="line">    <span class="keyword">this</span>.hash = original.hash;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// char[] 为参数的构造方法</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">String</span><span class="params">(<span class="keyword">char</span> value)</span></span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.value = Array.copyOf(value, value.length);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// StringBuffer 为参数的构造方法</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">String</span><span class="params">(StringBuffer buffer)</span></span>&#123;</span><br><span class="line">    <span class="keyword">synchronized</span>(buffer)&#123;</span><br><span class="line">        <span class="keyword">this</span>.value = Arrays.copyOf(buffer.getValue(), buffer.length());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// StringBuilder 为参数的构造方法</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">String</span><span class="params">(StringBuilder builder)</span></span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.value = Arrays.copyOf(builder.getValue(),builder.length());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="equals比较字符串是否相等"><a href="#equals比较字符串是否相等" class="headerlink" title="equals比较字符串是否相等"></a>equals比较字符串是否相等</h3><p>源码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object anObject)</span></span>&#123;</span><br><span class="line">    <span class="comment">// 对象引用相同时直接返回true</span></span><br><span class="line">    <span class="keyword">if</span>(<span class="keyword">this</span> == anObject)&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 判断需要对比的值是否为String类型，如果不是直接返回false</span></span><br><span class="line">    <span class="keyword">if</span>(anObject <span class="keyword">instanceof</span> String)&#123;</span><br><span class="line">        String anotherString = (String)anObject;</span><br><span class="line">        <span class="keyword">int</span> n = value.length;</span><br><span class="line">        <span class="keyword">if</span>(n == anotherString.value.length)&#123;</span><br><span class="line">            <span class="keyword">char</span> v1[] = value;</span><br><span class="line">            <span class="keyword">char</span> v2[] = anotherString value;</span><br><span class="line">            <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">while</span>(n != <span class="number">0</span>)&#123;</span><br><span class="line">                <span class="keyword">if</span>(v1[i]!=v2[i])&#123;</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                i++;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="instanceof判断类型"><a href="#instanceof判断类型" class="headerlink" title="instanceof判断类型"></a>instanceof判断类型</h2><p>instanceof 的使用如下：<br>当判断参数为String类型后，会循环对比两个字符串中的每一个字符，当所有字符都相等时返回true,否则返回false</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Object oString = <span class="string">"123"</span></span><br><span class="line">Object oint = <span class="number">123</span>;</span><br><span class="line">System.out.println(oString <span class="keyword">instanceof</span> String); <span class="comment">// 返回true</span></span><br><span class="line">System.out.println(oint <span class="keyword">instanceof</span> String); <span class="comment">//返回false</span></span><br></pre></td></tr></table></figure>
<h2 id="compareto-比较两个字符串"><a href="#compareto-比较两个字符串" class="headerlink" title="compareto() 比较两个字符串"></a>compareto() 比较两个字符串</h2><p>返回值为int类型，正数，负数或0，compareTo()会循环对比所有字符，当两个字符串有一个字符不相等时，返回char1-char2。源码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(String anotherString)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> len1 = value.length;</span><br><span class="line">    <span class="keyword">int</span> len2 = anotherString.value.length;</span><br><span class="line">    <span class="comment">// 获取到连个字符串长度最短的那个int值</span></span><br><span class="line">    <span class="keyword">int</span> lim = Math.min(len1, len2);</span><br><span class="line">    <span class="keyword">char</span> v1[] = value;</span><br><span class="line">    <span class="keyword">char</span> v2[] = anotherString.value;</span><br><span class="line">    <span class="keyword">int</span>  k = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(k&lt;lim)&#123;</span><br><span class="line">        <span class="keyword">char</span> c1 = v1[k];</span><br><span class="line">        <span class="keyword">char</span> c2 = v2[k];</span><br><span class="line">        <span class="keyword">if</span>(c1 != c2)&#123;</span><br><span class="line">            <span class="comment">// 有字符串不相等则返回差值</span></span><br><span class="line">            <span class="keyword">return</span> c1 - c2;</span><br><span class="line">        &#125;</span><br><span class="line">        k++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> len1-len2;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>compareTo和Equal两个方法都可以使用ignoreCase忽略大小写,这两个方法都是用于比较两个字符串的，但他们有两点不同：</p>
<ul>
<li>equals()可以接收一个Object类型的参数，但compareTo()只能接收一个String类型的参数</li>
<li>equals()返回之为Boolean，而compareTo返回值则为int</li>
</ul>
<p>当euqals()方法返回true时，或是compareTo()方法返回0时，则表示两个字符串完全相同</p>
<h2 id="其他常用方法"><a href="#其他常用方法" class="headerlink" title="其他常用方法"></a>其他常用方法</h2><ul>
<li>indexOf()：查询字符串首次出现 的下标位置</li>
<li>lastIndexOf()：查询字符串最后出现的下标位置</li>
<li>contains()：查询字符串中是否包含另一字符串</li>
<li>toLowerCase()：把字符串全部转换成小写</li>
<li>toUpperCase()：把字符串全部转化成大写</li>
<li>length()：查询字符串的长度</li>
<li>trim()：去掉字符串首尾空格 </li>
<li>repplace()：替换字符串中某些字符</li>
<li>split()：把字符串分割并返回字符串类型</li>
<li>join()：把字符串数组转为字符串</li>
</ul>
<h1 id="String关联的其他问题："><a href="#String关联的其他问题：" class="headerlink" title="String关联的其他问题："></a>String关联的其他问题：</h1><h2 id="为什么String类型要用final修饰？"><a href="#为什么String类型要用final修饰？" class="headerlink" title="为什么String类型要用final修饰？"></a>为什么String类型要用final修饰？</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">String</span></span></span><br></pre></td></tr></table></figure>
<p>为什么这里要使用final类呢？<br>Java语言之父的回答是：他更倾向使用final，因为它能够缓存结果，当你在传参时不需要考虑谁会修改它的值。如果是可变类的话，则更有可能 要重新拷贝出一个新值进行传参，这样在 性能上 就有一些损失。迫使String类设计成不可变的另一个原因是安全，如果是可变类，有可能在校验之后类型就改变了，有可能 会引起严重的系统崩溃问题。<br>总结来说：<strong>安全+高效</strong>是使String类设置为不可变的一个重要原因</p>
<h2 id="和equal的区别是什么？"><a href="#和equal的区别是什么？" class="headerlink" title="$==$和equal的区别是什么？"></a>$==$和equal的区别是什么？</h2><p>$==$对于基本数据类型来说，是用于比较”值“是否相等的，而对于引用类型来说，是用于比较引用地址是否相同的，查看源码可以发现equal方法是源于Object的，对于Object类型来说，equal的内部实现就是$==$：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object obj)</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> (<span class="keyword">this</span>==obj);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>而String重写了Object类型的equal方法，用于比较两个字符串的值是否相等，源码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object anObject)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(<span class="keyword">this</span>==anObject)&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(anObject <span class="keyword">instanceof</span> String)&#123;</span><br><span class="line">        String anotherString = (String)anObject;</span><br><span class="line">        <span class="keyword">int</span> n=value.length;</span><br><span class="line">        <span class="keyword">if</span>(n == anotherString.value.length)&#123;</span><br><span class="line">            <span class="keyword">char</span> v1[] = value;</span><br><span class="line">            <span class="keyword">char</span> v2[] = anotherString.value;</span><br><span class="line">            <span class="keyword">int</span> i=<span class="number">0</span>;</span><br><span class="line">            <span class="comment">// 循环比对两个字符串的每一个字符</span></span><br><span class="line">            <span class="keyword">while</span>(n--!= <span class="number">0</span>)&#123;</span><br><span class="line">                <span class="comment">// 如果其中有一个字符不相等就return false，否则继续比对</span></span><br><span class="line">                <span class="keyword">if</span>(v1[i]!=v2[i])&#123;</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                i++;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="String和StringBuffer、StringBuilder有什么区别？"><a href="#String和StringBuffer、StringBuilder有什么区别？" class="headerlink" title="String和StringBuffer、StringBuilder有什么区别？"></a>String和StringBuffer、StringBuilder有什么区别？</h2><p>String类型是不可变的，因此在字符串拼接时使用String的话性能 会降低，因此需要使用另一个数据类型 StringBuffer，它提供了append和insert用于字符串的拼接，它使用synchronized来保证线程安全，如下源码所示：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> StringBuffer <span class="title">append</span><span class="params">(Object obj)</span></span>&#123;</span><br><span class="line">    toStringCache = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">super</span>.append(String.valueOf(obj));</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> StringBuffer <span class="title">append</span><span class="params">(String str)</span></span>&#123;</span><br><span class="line">    toStringCache = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">super</span>.append(str);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>但又因为使用了synchroniized，导致性能不是很高，因此在JDK1.5时有了StringBuilder，它未使用synchroniized来修饰，因此性能上优于StringBuffer，因此在非并发情况下 可以使用StringBuilder来进行 字符串的拼接</p>
<h2 id="String的intern-方法有什么含义？String在JVM中是如何存储的？"><a href="#String的intern-方法有什么含义？String在JVM中是如何存储的？" class="headerlink" title="String的intern()方法有什么含义？String在JVM中是如何存储的？"></a>String的intern()方法有什么含义？String在JVM中是如何存储的？</h2><p>String常见的常见方式有以下两种：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String s1 = <span class="string">"java"</span>;</span><br><span class="line">String s2 = <span class="keyword">new</span> String(<span class="string">"java"</span>);</span><br></pre></td></tr></table></figure>
<p>这两者在JVM的存储区域截然不同，在JDK1.8中，变量s1会先去字符串常量池中找字符串”java”，如果有相同的字符，则直接返回常量句柄，如果没有该字符串，则会在常量池中创建该字符串，然后再返回常量句柄。而变量s2直接在堆上创建一个变量，如果调用intern方法，才会把字符串保存在常量池中，如下代码所示：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String s1 = <span class="string">"java"</span>;</span><br><span class="line">String s2 = <span class="keyword">new</span> String(<span class="string">"java"</span>);</span><br><span class="line">String s3 = s2.intern();</span><br><span class="line">System.out.println(s2==s3);</span><br><span class="line">System.out.println(s1==s3);</span><br></pre></td></tr></table></figure>
<p>从JDK1.7后把永生代换成元空间，把字符串常量池从方法区移到了Java堆上</p>
]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
  </entry>
  <entry>
    <title>逆波兰表达式</title>
    <url>/posts/93bfc68e.html</url>
    <content><![CDATA[<h1 id="运算表达式"><a href="#运算表达式" class="headerlink" title="运算表达式"></a>运算表达式</h1><p>一个表达式由操作数、操作符和分界符组成，算术表达式：</p>
<ul>
<li>中缀表达式(infix)：A+B</li>
<li>前缀表达式(prefix)：+AB</li>
<li>后缀表达示(postfix)：AB＋</li>
</ul>
<p><strong>表达式中相邻两个操作符的计算次序为</strong>：</p>
<ul>
<li>优先级高的先计算</li>
<li>优先级相同的自左向右计算</li>
<li>当使用括号时从最内层括号开始计算</li>
</ul>
<h2 id="中缀表达式"><a href="#中缀表达式" class="headerlink" title="中缀表达式"></a>中缀表达式</h2><p>中缀表达式需使用括号表示优先级，而后缀表达式不用，本身已含有优先级的信息。考虑下面例子：</p>
<blockquote>
<p>a b c d - * + e f / -</p>
</blockquote>
<p>从左向右，a，b，c，d分别压入堆栈，看到 “-“，将c与d提取出来做减法运算，得到rst1压入堆栈，看到”*“，将rst1与b做乘法运算，得到rst2压入堆栈，看到”+”，将rst2与a提取出来做加法，得到rst3压入堆栈，再将e与f分别压入堆栈，看到”/“，将e与f做除法，得到rst4压入堆栈，看到”-“，将rst3与rst4提取出来做减法，得到rst5压入堆栈，结束。</p>
<p>总结一下中缀表达式的计算顺序：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span>(is number)&#123;</span><br><span class="line">	push(number)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span>&#123;</span><br><span class="line">	pop(top element)</span><br><span class="line">    calculate(top element, number)</span><br><span class="line">    push(result)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="中缀表达式转后缀表达式"><a href="#中缀表达式转后缀表达式" class="headerlink" title="中缀表达式转后缀表达式"></a>中缀表达式转后缀表达式</h2><p>由于后缀表达式计算方便，我们需要考虑将中缀表达式转为后缀表达式，具体方式为：</p>
<ul>
<li>操作符栈初始化，将结束符”；“进栈，然后读入中缀表达式字符流 的首字符ch。</li>
<li>重复执行以下步骤，直到ch=”；”，同时栈顶的操作符也是”；”，停止循环。<ul>
<li>若ch是操作符直接输出，读入下一个字符ch；</li>
<li>若ch是操作符，判断ch的优先级icp和位于栈顶的操作符op的优先级isp：<ul>
<li>若icp(ch) &gt; isp(op)，令ch进栈，读入下一个字符ch；</li>
<li>若ip(ch) &lt; isp(op)，退栈并输出;</li>
<li>若icp(ch) == isp(op)，退栈但不输出，若输出的是左括号则读入下一个字符ch。</li>
</ul>
</li>
<li>算法结束，输出序列即为所需的后缀表达式。</li>
</ul>
</li>
</ul>
<p>转换时的操作符的优先级如下：</p>
<p><img src="/posts/Cpp/stack1.png" alt></p>
<p>看一个具体的例子：</p>
<p><img src="/posts/Cpp/stack2.png" alt></p>
<p><img src="/posts/Cpp/stack3.png" alt></p>
<h1 id="具体代码实现"><a href="#具体代码实现" class="headerlink" title="具体代码实现"></a>具体代码实现</h1><h2 id="中缀表达式直接求值"><a href="#中缀表达式直接求值" class="headerlink" title="中缀表达式直接求值"></a>中缀表达式直接求值</h2><p>下面是中缀表达式直接求值的C++实现（在定义了栈的相关操作的基础上实现）：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">Judge</span><span class="params">(<span class="keyword">char</span> c1,<span class="keyword">char</span> c2)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> a1,a2;</span><br><span class="line">	<span class="keyword">if</span>(<span class="string">'+'</span>==c1||<span class="string">'-'</span>==c1) a1 = <span class="number">3</span>;</span><br><span class="line">	<span class="keyword">if</span>(<span class="string">'*'</span>==c1||<span class="string">'/'</span>==c1)a1 = <span class="number">5</span>;</span><br><span class="line">	<span class="keyword">if</span>(<span class="string">'('</span>==c1) a1 = <span class="number">1</span>;</span><br><span class="line">	<span class="keyword">if</span>(<span class="string">')'</span>==c1) a1 = <span class="number">7</span>;</span><br><span class="line">	<span class="keyword">if</span>(<span class="string">'#'</span>==c1) a1 = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span>(<span class="string">'+'</span>==c2||<span class="string">'-'</span>==c2)a2 = <span class="number">2</span>;</span><br><span class="line">	<span class="keyword">if</span>(<span class="string">'*'</span>==c2||<span class="string">'/'</span>==c2)a2 = <span class="number">4</span>;</span><br><span class="line">	<span class="keyword">if</span>(<span class="string">'('</span>==c2) a2 = <span class="number">6</span>;</span><br><span class="line">	<span class="keyword">if</span>(<span class="string">')'</span>==c2) a2 = <span class="number">1</span>;</span><br><span class="line">	<span class="keyword">if</span>(<span class="string">'#'</span>==c2) a2 = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">if</span>(a1&gt;a2) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">	<span class="keyword">if</span>(a1==a2) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">if</span>(a1&lt;a2) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">	<span class="keyword">return</span> <span class="number">2</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">double</span> <span class="title">run</span><span class="params">(<span class="keyword">char</span> c ,<span class="keyword">double</span> d1,<span class="keyword">double</span> d2)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">switch</span> (c)</span><br><span class="line">	&#123;</span><br><span class="line">	<span class="keyword">case</span> <span class="string">'+'</span>:</span><br><span class="line">		<span class="keyword">return</span> d1+d2;</span><br><span class="line">		<span class="keyword">break</span>;</span><br><span class="line">	<span class="keyword">case</span> <span class="string">'-'</span>:</span><br><span class="line">		<span class="keyword">return</span> d1-d2;</span><br><span class="line">		<span class="keyword">break</span>;</span><br><span class="line">	<span class="keyword">case</span> <span class="string">'*'</span> :</span><br><span class="line">		<span class="keyword">return</span> d1*d2;</span><br><span class="line">		<span class="keyword">break</span>;</span><br><span class="line">	<span class="keyword">case</span> <span class="string">'/'</span>:</span><br><span class="line">		<span class="keyword">return</span> d1/d2;</span><br><span class="line">		<span class="keyword">break</span>;</span><br><span class="line">	<span class="keyword">default</span>:</span><br><span class="line">		<span class="keyword">return</span> <span class="number">0.0</span>;</span><br><span class="line">		<span class="keyword">break</span>;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">infix</span><span class="params">(<span class="built_in">string</span> str)</span></span>&#123;</span><br><span class="line">    <span class="keyword">char</span> * op = (<span class="keyword">char</span>*)<span class="string">"+-*/()#"</span>;</span><br><span class="line">    str.append(<span class="number">1</span>, <span class="string">'#'</span>);</span><br><span class="line">    SeqStack&lt;<span class="keyword">char</span>&gt; oper;</span><br><span class="line">    SeqStack&lt;<span class="keyword">double</span>&gt; num;</span><br><span class="line">    <span class="keyword">int</span> a=<span class="number">-1</span>;</span><br><span class="line">    oper.Push(<span class="string">'#'</span>);</span><br><span class="line">    <span class="keyword">while</span>(<span class="literal">true</span>)&#123;</span><br><span class="line">		<span class="keyword">int</span> b = a+<span class="number">1</span>;</span><br><span class="line">		a = str.find_first_of(op, a+<span class="number">1</span>);</span><br><span class="line">		<span class="keyword">if</span>(a==<span class="built_in">string</span>::npos) <span class="keyword">break</span>;</span><br><span class="line">		<span class="keyword">if</span>(a!=b)&#123;</span><br><span class="line">			<span class="function"><span class="built_in">string</span> <span class="title">ss</span><span class="params">(str,b,a-b)</span></span>;</span><br><span class="line">			<span class="keyword">double</span> d=atof(ss.c_str());</span><br><span class="line">			<span class="comment">//数据先入栈</span></span><br><span class="line">			num.Push(d);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">int</span> ju = Judge(oper.GetTop(),str[a]);</span><br><span class="line">		<span class="keyword">if</span>(<span class="number">-1</span>==ju)&#123;</span><br><span class="line">			oper.Push(str[a]);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span>(<span class="number">0</span>==ju)&#123;</span><br><span class="line">			oper.Pop();</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span>(<span class="number">1</span>==ju)&#123;</span><br><span class="line">			<span class="keyword">double</span> d1 = num.GetTop();</span><br><span class="line">			num.Pop();</span><br><span class="line">			<span class="keyword">double</span> d2 = num.GetTop();</span><br><span class="line">			num.Pop();</span><br><span class="line">			d1 = run(oper.GetTop(),d2,d1);</span><br><span class="line">			num.Push(d1);</span><br><span class="line">			oper.Pop();</span><br><span class="line">			a--;</span><br><span class="line">	 	&#125;</span><br><span class="line">    &#125;</span><br><span class="line">	str.erase(str.length()<span class="number">-1</span>,<span class="number">1</span>);</span><br><span class="line">	<span class="built_in">cout</span>&lt;&lt;str&lt;&lt;<span class="string">" = "</span>&lt;&lt;num.GetTop()&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>程序设计思路如下：</p>
<ol>
<li>首先定义了Judge函数，用于判断运算符的优先级次序</li>
<li>定义run函数，统一运算符的操作模式，避免写整段的运算符判断语句</li>
<li>定义infix中缀表达式主函数，具体实现步骤为<ul>
<li>定义运算符，目的是方便后续找到表达式字符串中的运算符，另外在运算符栈中先插入“#“终止字符。</li>
<li>循环，使用表达式：a = str.find_first_of(op, a+1)不断找到下一个位置的运算符，将两个运算符（或最开始）的连续的数字字符串通过atof函数转化为一个数字，然后将数字压入num栈中，并根据Judge函数比较得到的下一个运算符与运算符栈顶元素的优先级，分别采取压入栈、弹出栈及取数运算操作，取数运算通过将数字栈中弹出的两个数字以及对应的运算符通过run函数实现。需要注意的是，由于此时数字栈顶被压入了新的元素，需在最后使用a—。</li>
</ul>
</li>
</ol>
<h2 id="中缀表达式转后缀表达式求值"><a href="#中缀表达式转后缀表达式求值" class="headerlink" title="中缀表达式转后缀表达式求值"></a>中缀表达式转后缀表达式求值</h2><p>这里采用与中缀表达式直接求值不同的实现方式，在程序函数的调用方面有些许区别，事实上也可以直接通过中缀表达式定义好的函数实现这一步骤，读者可以自行完成。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">IsOperator</span><span class="params">(<span class="keyword">char</span> ch)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">char</span> ops[] = <span class="string">"+-*/"</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="keyword">sizeof</span>(ops) / <span class="keyword">sizeof</span>(<span class="keyword">char</span>); i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (ch == ops[i])</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">Precedence</span><span class="params">(<span class="keyword">char</span> op1, <span class="keyword">char</span> op2)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (op1 == <span class="string">'('</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (op1 == <span class="string">'+'</span> || op1 == <span class="string">'-'</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (op2 == <span class="string">'*'</span> || op2 == <span class="string">'/'</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (op1 == <span class="string">'*'</span> || op1 == <span class="string">'/'</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (op2 == <span class="string">'+'</span> || op2 == <span class="string">'-'</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="number">2</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="built_in">string</span> <span class="title">in2postfix</span><span class="params">(<span class="built_in">string</span> s)</span></span>&#123;</span><br><span class="line">	<span class="built_in">string</span> postFix;</span><br><span class="line">	<span class="keyword">int</span> j = <span class="number">0</span>, len;</span><br><span class="line">    <span class="keyword">char</span> c;</span><br><span class="line">    SeqStack&lt;<span class="keyword">char</span>&gt; st;</span><br><span class="line">    len = s.length();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; len; i++)&#123;</span><br><span class="line">        c = s[i];</span><br><span class="line">        <span class="keyword">if</span> (c == <span class="string">'('</span>)&#123;</span><br><span class="line">			st.Push(c);</span><br><span class="line">		&#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (c == <span class="string">')'</span>)&#123;</span><br><span class="line">            <span class="keyword">while</span> (st.GetTop() != <span class="string">'('</span>)&#123;</span><br><span class="line">                postFix[j++] = st.GetTop();</span><br><span class="line">                st.Pop();</span><br><span class="line">            &#125;</span><br><span class="line">            st.Pop();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (!IsOperator(c))&#123;</span><br><span class="line">				st.Push(c);</span><br><span class="line">			&#125; </span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="keyword">while</span> (st.Empty() == <span class="literal">false</span> &amp;&amp; Precedence(st.GetTop(), c) &gt;= <span class="number">0</span>)&#123;</span><br><span class="line">                    postFix[j++] = st.GetTop();</span><br><span class="line">                    st.Pop();</span><br><span class="line">                &#125;</span><br><span class="line">                st.Push(c);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (st.Empty() == <span class="number">0</span>)&#123;</span><br><span class="line">        postFix[j++] = st.GetTop();</span><br><span class="line">        st.Pop();</span><br><span class="line">    &#125;</span><br><span class="line">    postFix[j] = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">return</span> postFix;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">double</span> <span class="title">postFixEval</span><span class="params">(<span class="keyword">char</span>* postFix)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    SeqStack&lt;<span class="keyword">char</span>&gt; st;</span><br><span class="line">    <span class="keyword">int</span> len = <span class="built_in">strlen</span>(postFix);</span><br><span class="line">    <span class="keyword">char</span> c;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; len; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        c = postFix[i];</span><br><span class="line">        <span class="keyword">if</span> (IsOperator(c) == <span class="literal">false</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            st.Push(c - <span class="string">'0'</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">char</span> op1, op2;</span><br><span class="line">            <span class="keyword">int</span> val;</span><br><span class="line"></span><br><span class="line">            op1 = st.GetTop();</span><br><span class="line">            st.Pop();</span><br><span class="line">            op2 = st.GetTop();</span><br><span class="line">            st.Pop();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">switch</span> (c)</span><br><span class="line">            &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">'+'</span>:</span><br><span class="line">                val = op1 + op2;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">'-'</span>:</span><br><span class="line">                val = op2 - op1;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">'*'</span>:</span><br><span class="line">                val = op1 * op2;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">'/'</span>:</span><br><span class="line">                val = op2 / op1;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            st.Push(val);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> st.GetTop();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="栈的定义与实现代码"><a href="#栈的定义与实现代码" class="headerlink" title="栈的定义与实现代码"></a>栈的定义与实现代码</h2><p>最后附上上述代码中需使用到的栈结构的定义：</p>
<p>这是头函数SeqStack.h文件：<br><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> SEQSTACK_H</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SEQSTACK_H</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="class"><span class="keyword">class</span> <span class="title">DataType</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">struct</span> <span class="title">Node</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    DataType data;</span><br><span class="line">    Node&lt;DataType&gt; *next;  <span class="comment">//此处&lt;T&gt;也可以省略</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="class"><span class="keyword">class</span> <span class="title">DataType</span>&gt;       //定义模板类<span class="title">SeqStack</span></span></span><br><span class="line"><span class="class"><span class="title">class</span> <span class="title">LinkStack</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    LinkStack() ;            <span class="comment">//构造函数，栈的初始化</span></span><br><span class="line">	~LinkStack();            <span class="comment">//析构函数</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">Push</span><span class="params">(DataType x)</span></span>;          <span class="comment">//将元素x入栈</span></span><br><span class="line">    <span class="function">DataType <span class="title">Pop</span><span class="params">()</span></span>;                <span class="comment">//将栈顶元素弹出</span></span><br><span class="line">    <span class="function">DataType <span class="title">GetTop</span><span class="params">()</span></span>;	         <span class="comment">//取栈顶元素（并不删除）</span></span><br><span class="line">	<span class="function"><span class="keyword">int</span> <span class="title">Empty</span><span class="params">()</span></span>;           <span class="comment">//判断栈是否为空</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    Node&lt;DataType&gt; *top;                <span class="comment">//栈顶指针，指示栈顶元素在数组中的下标</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure></p>
<p>这是stack.cpp文件：<br><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"SeqStack.h"</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="class"><span class="keyword">class</span> <span class="title">DataType</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">SeqStack</span>&lt;DataType&gt;:</span>:SeqStack()&#123;</span><br><span class="line">	top=<span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="class"><span class="keyword">class</span> <span class="title">DataType</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">SeqStack</span>&lt;DataType&gt;:</span>:~SeqStack()&#123;</span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="class"><span class="keyword">class</span> <span class="title">DataType</span>&gt; </span></span><br><span class="line"><span class="class"><span class="title">void</span> <span class="title">SeqStack</span>&lt;DataType&gt;:</span>:Push(DataType x)&#123;</span><br><span class="line">    <span class="keyword">if</span> (top==StackSize<span class="number">-1</span>) <span class="keyword">throw</span> <span class="string">"error"</span>;</span><br><span class="line">    top++;</span><br><span class="line">    data[top]=x;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="class"><span class="keyword">class</span> <span class="title">DataType</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">DataType</span> <span class="title">SeqStack</span>&lt;DataType&gt;:</span>:Pop()&#123; </span><br><span class="line">    DataType x;</span><br><span class="line">    <span class="keyword">if</span> (top==<span class="number">-1</span>) <span class="keyword">throw</span> <span class="string">"error"</span>;</span><br><span class="line">    x=data[top--];</span><br><span class="line">    <span class="keyword">return</span> x;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="class"><span class="keyword">class</span> <span class="title">DataType</span>&gt; </span></span><br><span class="line"><span class="class"><span class="title">DataType</span> <span class="title">SeqStack</span>&lt;DataType&gt;:</span>:GetTop()&#123;</span><br><span class="line">	<span class="keyword">if</span> (top!=<span class="number">-1</span>)&#123;</span><br><span class="line">        <span class="keyword">return</span> data[top];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="class"><span class="keyword">class</span> <span class="title">DataType</span>&gt; </span></span><br><span class="line"><span class="class"><span class="title">int</span> <span class="title">SeqStack</span>&lt;DataType&gt;:</span>:Empty()&#123;</span><br><span class="line">	<span class="keyword">if</span>(top==<span class="number">-1</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">	<span class="keyword">else</span> <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="class"><span class="keyword">class</span> <span class="title">DataType</span>&gt; </span></span><br><span class="line"><span class="class"><span class="title">int</span> <span class="title">SeqStack</span>&lt;DataType&gt;:</span>:NotEmpty()&#123;</span><br><span class="line">	<span class="keyword">if</span>(top==<span class="number">-1</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">else</span> <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">to_Xhex</span><span class="params">(<span class="keyword">int</span> data, <span class="keyword">int</span> tohex)</span></span>&#123;</span><br><span class="line">    SeqStack&lt;<span class="keyword">int</span>&gt; S;</span><br><span class="line">    <span class="keyword">int</span> count = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">int</span> t = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span>(data&gt;=tohex)&#123;</span><br><span class="line">        S.Push(data%tohex);</span><br><span class="line">        data/=tohex;</span><br><span class="line">    &#125;</span><br><span class="line">    S.Push(data);</span><br><span class="line">    <span class="keyword">while</span>(S.NotEmpty())&#123;</span><br><span class="line">        count += t * S.GetTop();</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;S.Pop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
  </entry>
  <entry>
    <title>C++指针详解</title>
    <url>/posts/2df51814.html</url>
    <content><![CDATA[<p>C++指针大概是许多初学者最不愿意接触的 东西，但是通过指针，可以简化一些 C++ 编程任务的执行，还有一些任务，如动态内存分配，没有指针是无法执行的，因此指针始终是学习C++无法绕过的一个弯，那么什么是指针？指针是一个变量，其值为另一个变量的地址，即，内存位置的直接地址。就像其他变量或常量一样，您必须在使用指针存储其他变量地址之前，对其进行声明。</p>
<h1 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h1><p>这一个例子是作为备忘，以防啥时候忘了咋使用指针或引用便于随时翻看。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i = <span class="number">1</span>;</span><br><span class="line">	<span class="keyword">int</span> j = <span class="number">2</span>;</span><br><span class="line">	<span class="keyword">int</span>* ip = &amp;i;</span><br><span class="line">	<span class="keyword">int</span>* jp = &amp;j;</span><br><span class="line">	<span class="keyword">int</span>** ipp = &amp;ip;</span><br><span class="line"></span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"address of i:%p\r\n"</span>, &amp;i);</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"==========================\r\n"</span>);</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"value of ip:%p\r\n"</span>, ip);</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"address of ip:%p\r\n"</span>, &amp;ip);</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"content of ip:%d\r\n"</span>, *ip);</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"==========================\r\n"</span>);</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"value of ipp:%p\r\n"</span>, ipp);</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"address of ipp:%p\r\n"</span>, &amp;ipp);</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"content of ip:%p\r\n"</span>, *ipp);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"==========================\r\n"</span>);</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"value of i:%d\r\n"</span>, **ipp);</span><br><span class="line">	*ipp = &amp;j;</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"value of j:%d\r\n"</span>, **ipp);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码运行结果是：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">address of i:000000000061fe14</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">value of ip:000000000061fe14</span><br><span class="line">address of ip:000000000061fe08</span><br><span class="line">content of ip:1</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">value of ipp:000000000061fe08</span><br><span class="line">address of ipp:000000000061fe00</span><br><span class="line">content of ip:000000000061fe14</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">value of i:1</span><br><span class="line">value of j:2</span><br></pre></td></tr></table></figure>
<p>In brief，在变量前（可以是指针变量）加一个&amp;，就可以找到该变量的地址！对指针加一个*，就可以找到该（指针对应的）地址对应的值，下面我们开始深入理解指针~</p>
<h1 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h1><p>我们先给出一个断言：物理内存的单位是字节,一个字节8个位，一个字节的表示范围为0000 0000~1111 1111(oxff)，实际上往往还会多出一个位用于校验。<br>由下图可见，我们每个（不同类型）变量占的字节大小不同</p>
<p><img src="/posts/Cpp/memory.png" alt></p>
<p>首先我们定义两个变量：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> i;</span><br><span class="line"><span class="keyword">char</span> a;</span><br></pre></td></tr></table></figure>
<p>创建两个变量后，变量的空间占用如下（以下所有的地址都只是简化版本，实际上为8个位的字节）</p>
<p><img src="/posts/Cpp/memory2.PNG" alt></p>
<p>当我们对变量进行赋值操作：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">i = <span class="number">30</span>;</span><br><span class="line">a = ’t’;</span><br></pre></td></tr></table></figure>
<p>这时可以理解为：</p>
<p><img src="/posts/Cpp/memory3.PNG" alt></p>
<p>下面我们定义一个指针：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> *pi;</span><br></pre></td></tr></table></figure>
<p>它会在内存中体现为：</p>
<p><img src="/posts/Cpp/memory4.PNG" alt></p>
<p>那么给这个变量赋值，赋的值是变量i的地址：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">pi = &amp;i;</span><br></pre></td></tr></table></figure>
<p><img src="/posts/Cpp/memory5.PNG" alt></p>
<p>注意看这个变量值为6，而变量i的内存地址也为6，也就是说将i的内存地址保存为pi变量的值，这是不是有点静态链表的内味了。</p>
<p>总而言之：指针变量所存的内容就是内存的地址编号。</p>
]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
  </entry>
  <entry>
    <title>抽象代数（一）</title>
    <url>/posts/d21e0656.html</url>
    <content><![CDATA[<h1 id="映射"><a href="#映射" class="headerlink" title="映射"></a>映射</h1><p><strong>定义一</strong>：</p>
<blockquote>
<p>设$f:A\rightarrow B$为映射，如果存在$g:B\rightarrow A$使$gf=id_A$，则称$f$左可逆，$g$称为$f$的左逆，如果存在映射$g:B\rightarrow A$使$fg=id_B$，则称$f$右可逆，$g$称为$f$的右逆，若既左可逆（$g_1$）又右可逆($g_2$)，则称$f$可逆。</p>
</blockquote>
<p><strong>命题一</strong>：</p>
<blockquote>
<p>若$f$可逆则$g_1=g_2$，反之也成立</p>
</blockquote>
<p>证明：若$f$可逆，即$g_1f=id_A,fg_2=id_B$，则</p>
<script type="math/tex; mode=display">g_1 = g_1id_B = g_1fg_2 = id_A g_2 = g_2</script><p>因此$f$可逆等价于存在映射$g:B\rightarrow A$使得$gf=id_A, fg=id_B$</p>
<p>此时$g$唯一，记为$f^{-1}$</p>
<p>反之，若$g_1=g_2$，则显然$f$可逆</p>
<p><strong>命题二</strong>：</p>
<blockquote>
<ul>
<li>$f$为单射等价于$f$左可逆</li>
<li>$f$为满射等价于$f$右可逆</li>
<li>$f$为双射等价于$f$可逆</li>
</ul>
</blockquote>
<p>证明：</p>
<p>① 若$f$左可逆，则存在映射$g:B\rightarrow A$使得$gf=id_A$</p>
<p>设$a、b\in A$使得$f(a) = f(b)$，则</p>
<script type="math/tex; mode=display">gf(a) = gf(b)</script><p>因此有</p>
<script type="math/tex; mode=display">id_A(a) = id_A(b)</script><p>也即$a = b$，因此$f$为单射</p>
<p>反之，若$f:A\rightarrow B$为单射，定义$g:B\rightarrow A$如下：</p>
<p>$\forall b\in B$，若有$a\in A$使得$f(a)=b$</p>
<p>由于$f$是单射，因此$a$唯一，定义$g(b)=a$，如果不存在$a\in A$使得$f(a)=b$</p>
<p>如果不存在$a\in A$使得$f(a)=b$，则令$g(b) = a_0$，其中$a_0$为$A$中指定的元素，则$g$是$B$到$A$的映射且$gf=id_A$，因此$f$左可逆</p>
<p>② 若$f$为满射，则$\forall b\in B, f^{-1}(b) = \{a\in A:f(a)=b\}$非空</p>
<p>令$a\in f^{-1}(b)$，定义$g(b)=a$</p>
<p>则$g$是$B$到$A$的映射且$fg=id_B$，即$f$右可逆</p>
<p>反之若有$g$使得$fg = id_B$，则</p>
<script type="math/tex; mode=display">\forall b\in B, f(g(b)) = id_Bg(b) = b</script><p>且$g(b) \in A$，因此$f$满射</p>
<p>③ 由①②综合可得</p>
<p><strong>命题三</strong>：</p>
<blockquote>
<p>设$f: A\rightarrow B, g:B\rightarrow C$为映射，则</p>
<ul>
<li>若$f$与$g$都是单射，则$gf$也是</li>
<li>若$f$与$g$都是满射，则$gf$也是</li>
<li>若$f$与$g$都是双射，则$gf$也是</li>
</ul>
</blockquote>
<p>证明：（只证前两条）</p>
<p>若$f$与$g$都是单射，则由命题二有</p>
<script type="math/tex; mode=display">f^`f = id_A, g^`g=id_B</script><p>故</p>
<script type="math/tex; mode=display">f^`g^`gf = f^`id_B f = f^`f = id_A</script><p>因此$gf$是单射</p>
<p>若$f$与$g$都是满射，则任意$c\in C$，由于$g$是到上（满射）的，存在$b\in B$使得$g(b)=c$，同理存在$a\in A$使得$f(a)=b$，由此：</p>
<script type="math/tex; mode=display">(gf)(a) = g(f(a)) = g(b) = c</script>]]></content>
      <categories>
        <category>Mathematics</category>
      </categories>
  </entry>
  <entry>
    <title>k8s 核心技术</title>
    <url>/posts/44e24bf5.html</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer">

<h1 id="认识-kubernetes-架构及应用场景"><a href="#认识-kubernetes-架构及应用场景" class="headerlink" title="认识 kubernetes 架构及应用场景"></a>认识 kubernetes 架构及应用场景</h1><h2 id="kubernetes（k8s-在企业中的应用场景"><a href="#kubernetes（k8s-在企业中的应用场景" class="headerlink" title="kubernetes（k8s) 在企业中的应用场景"></a>kubernetes（k8s) 在企业中的应用场景</h2><h3 id="构建自动化运维平台"><a href="#构建自动化运维平台" class="headerlink" title="构建自动化运维平台"></a>构建自动化运维平台</h3><p>（1） 中小型企业，使用 k8s 构建一套自动化运维平台（降本增效）<br>（2） 大型互联网公司更要使用，实现更高效的运作方式</p>
<h3 id="充分利用服务器资源"><a href="#充分利用服务器资源" class="headerlink" title="充分利用服务器资源"></a>充分利用服务器资源</h3><p>怎么理解充分利用服务器资源这一条呢，我们举个例子：假设并发量200请求，服务器是两核心CPU，4G内存，其中静态请求150个，比如访问CDN、nginx、缓存等，动态请求50个，主要是访问数据库，把数据读入内存，我们来估算服务器资源（只考虑内存，不考虑程序员RT与CPU切换时间）：</p>
<p>静态+动态 = 150*2M + 50 *10M = 800M<br>也就是说200个请求占用了800M内存</p>
<p>我们可以估算这台服务器的并发能力QPS为 200*4 = 8000，但实际上 800 QPS 是无法达到的，我们需要考虑 response time，cpu切换时间，内存等等，因此实际上我们会给它安排 300 QPS，此时先然无法充分利用服务器资源，有很多资源被浪费掉了。而 k8s 使用类似 Docker 的容器化方式，也就是我们在其中部署多个容器，将服务器资源做隔离，容器中部署的就是 web 服务。</p>
<h3 id="服务无缝衔接"><a href="#服务无缝衔接" class="headerlink" title="服务无缝衔接"></a>服务无缝衔接</h3><p>那么服务的无缝迁移又该怎么理解呢？首先我们开发时应该有三种环境，分别是是开发环境、测试环境和生产环境。在开发 web 项目时有许多配套服务，在测试环境中这些环境也必须存在，测试完之后产品就可以上线，但这时会出现一个问题：项目在测试时没有毛病，但一旦上市生产就出现了很大的问题，这经常是环境的不一致性造成的，这时候往往就会花费大量精力去调试环境，非常麻烦，而容器化方式可以做到服务无缝迁移。也就是说我们可以把 JDK、MQ、ES、MySQL 等做成一个个镜像，这些镜像可以脱离我们的依赖环境，因此这些镜像可以做到无缝迁移。</p>
<h2 id="服务部署模式变迁-amp-服务部署模式变化的思考"><a href="#服务部署模式变迁-amp-服务部署模式变化的思考" class="headerlink" title="服务部署模式变迁&amp;服务部署模式变化的思考"></a>服务部署模式变迁&amp;服务部署模式变化的思考</h2><p>我们考虑下面几个问题：</p>
<h3 id="服务部署模式是怎么变迁的。"><a href="#服务部署模式是怎么变迁的。" class="headerlink" title="服务部署模式是怎么变迁的。"></a>服务部署模式是怎么变迁的。</h3><ol>
<li>物理机部署：就是直接把服务部署到物理机上（不能充分利用物理机资源）</li>
<li>虚拟化（虚拟机）方式，也就是通过虚拟机将物理资源进行隔离部署服务，将服务部署到虚拟机上，但虚拟机本身就非常占用资源，因此我们寻求一种更好的方式</li>
<li>使用容器化方式进行部署（容器更轻量级，运行更快）</li>
</ol>
<h3 id="服务部署模式变化，带来哪些问题？"><a href="#服务部署模式变化，带来哪些问题？" class="headerlink" title="服务部署模式变化，带来哪些问题？"></a>服务部署模式变化，带来哪些问题？</h3><ol>
<li><p>前提条件：SOA架构，微服务架构的模式下，项目拆分越来越多，服务越来越多，这么多服务我们是怎么管理？</p>
<ul>
<li><p>虚拟机服务部署方式（openstack）</p>
</li>
<li><p>容器化部署模式（k8s）</p>
<p>容器我们可以认为是一个更轻量级的虚拟机，使用了与虚拟机不同的技术，因此与openstack用于管理虚拟机类似， k8s 就是用来管理容器的。</p>
</li>
</ul>
</li>
<li><p>面临问题：</p>
<ul>
<li><p>如何对服务进行横向扩展（不能 简单地加机器，会影响服务）</p>
</li>
<li><p>容器宕机如何解决，数据怎么恢复</p>
</li>
<li><p>重新发布新的版本如何在线上快速更新，更新后不影响业务（k8s可以做滚动更新）</p>
</li>
<li><p>如何监控容器（容器出现问题怎么办）</p>
</li>
<li><p>容器如何调度创建</p>
</li>
<li><p>数据安全性如何保证</p>
</li>
</ul>
</li>
</ol>
<h2 id="云架构-amp-云原生"><a href="#云架构-amp-云原生" class="headerlink" title="云架构 &amp; 云原生"></a>云架构 &amp; 云原生</h2><h3 id="云和-k8s-是什么关系"><a href="#云和-k8s-是什么关系" class="headerlink" title="云和 k8s 是什么关系"></a>云和 k8s 是什么关系</h3><ul>
<li>云就是使用容器构建的一套服务集群网络，云由大量容器构成，不同容器有不同功能</li>
<li>k8s 就是用来管理云中的容器</li>
</ul>
<h3 id="云架构"><a href="#云架构" class="headerlink" title="云架构"></a>云架构</h3><h4 id="iaas-基础设施即服务"><a href="#iaas-基础设施即服务" class="headerlink" title="iaas 基础设施即服务"></a>iaas 基础设施即服务</h4><pre><code>用户：可以租用（购买|分配权限）云主机，用户就不需要考虑网络，DNS，硬件环境方面的问题。
运营商：（私有云或公有云平台）提供网络，存储，DNS（基础设施服务）
</code></pre><h4 id="paas-平台即服务"><a href="#paas-平台即服务" class="headerlink" title="paas 平台即服务"></a>paas 平台即服务</h4><pre><code>MYSQL\ES\R等服务都由平台提供了
</code></pre><h4 id="saas-软件即服务（目前很多系统都是该系统）"><a href="#saas-软件即服务（目前很多系统都是该系统）" class="headerlink" title="saas 软件即服务（目前很多系统都是该系统）"></a>saas 软件即服务（目前很多系统都是该系统）</h4><pre><code>钉钉：给每个公司提供一个系统，每个公司使用独立一套功能
财务管理软件：维护交给运营商维护，用户只需要使用其中的功能即可
</code></pre><h4 id="serverless-无服务"><a href="#serverless-无服务" class="headerlink" title="serverless 无服务"></a>serverless 无服务</h4><pre><code> 站在用户角度：不需要服务器，用户只需要使用云服务器即可，在云服务器所有基础环境 ，软件环境都不需要 用户自己安装
 未来：服务开发都是 serverless，企业都构建了自己的私有云环境，或者使用公有云环境（阿里云）
     阿里将所有服务部署到云端之后，效率提升了60%
</code></pre><h3 id="云原生"><a href="#云原生" class="headerlink" title="云原生"></a>云原生</h3><p>就是为了让应用程序（项目、服务软件）都 运行在云上的解决方案，这样的方案叫做云原生。<br><strong>特点</strong>：<br>（1）容器化 —— 所有服务部署都必须部署在容器中<br>（2）微服务 —— web 服务架构、微服务架构<br>（3）CI、CD —— 可持续交互与可持续部署<br>（4）DevOps —— 开发与运维密不可分</p>
<h2 id="kubernetes-架构原理"><a href="#kubernetes-架构原理" class="headerlink" title="kubernetes 架构原理"></a>kubernetes 架构原理</h2><p>1）kubernetes 是 Google 使用 go 语言开发，原来的系统是 borg 系统（也是云平台管理工具），Docker后来自己开发了容器管理平台 Docker Swarm，Google 表示不服，因此参照 borg 架构开发了 k8s 架构</p>
<p>2）k8s 架构</p>
<p><img src="/posts/k8s/arch1.jpg" alt></p>
<p>关系：一个 master 对应多个 node 节点</p>
<p><strong>master 节点</strong></p>
<ol>
<li>api server：k8s 网关，所有指令请求都必须经过 api server</li>
<li>scheduler：调度器，使用调度算法，将请求资源调度给某一个 node 节点</li>
<li>controller 控制器：维护 k8s 资源对象（添加、删除、更新、修改）</li>
<li>etcd：存储资源对象，服务的注册与发现</li>
</ol>
<p><strong>node 节点</strong></p>
<ol>
<li>docker：运行容器的基础环境，容器引擎</li>
<li>kuberlet：在每个 node 节点都存在一份，在 node 节点上的资源操作指令由其执行</li>
<li>kube-proxy：代理服务，负载均衡</li>
<li>fluentd：日志收集服务</li>
<li>pod：是 k8s 管理的基本单位，内部是容器，也即是 k8s 不直接管理容器，而是管理 pod</li>
</ol>
<h1 id="深入认识-kubernetes-核心组件原理"><a href="#深入认识-kubernetes-核心组件原理" class="headerlink" title="深入认识 kubernetes 核心组件原理"></a>深入认识 kubernetes 核心组件原理</h1><h2 id="pod的核心原理"><a href="#pod的核心原理" class="headerlink" title="pod的核心原理"></a>pod的核心原理</h2><p><strong>k8s的作用</strong>：k8s是用来管理容器的，但不直接操作容器，最小操作单元是pod（间接地管理容器）<br><strong>k8s的特点</strong>：</p>
<ol>
<li>一个master有一群node节点与之对应</li>
<li>master节点不存储容器，只负责调度、网关、控制器、资源对象存储</li>
<li>容器是存储在node节点（容器是存储在pod内部）</li>
<li>pod内部都可以有一个容器，或者是多个容器</li>
<li>kubelet负责本地的pod维护</li>
<li>kube-proxy负责在多个pod之间做负载均衡</li>
</ol>
<p><strong>pod是什么呢</strong>:pod也是一个容器，但这个容器中装的是docker创建的容器，也就是pod是用来封装容器的容器，pod是一个虚拟化分组（pod有自己的地址，主机名），相当于一台独立的沙箱环境（主机），可以封装一个容器或多个容器</p>
<p><strong>pod用来干什么</strong>：通常情况下，在服务部署时使用pod来管理一组相关服务（一个pod要么部署一个服务，要么部署一组相关的服务），所谓的一组相关的服务，即为链式调用的调用链路上的服务。</p>
<p><img src="/posts/k8s/pod1.png" alt></p>
<p><strong>web服务集群如何实现</strong>：只需要复制多方pod的副本即可，这也是k8s管理的先进之处，k8s如果继续扩容、缩容，只需要控制pod的数量即可</p>
<p><strong>pod底层网络，数据存储是如何进行的</strong>：pod内部容器创建之前必须先创建pause容器，服务容器之间的访问使用localhost访问，性能非常高，实际就像访问本地服务一样</p>
<p><img src="/posts/k8s/pod2.png" alt></p>
<h2 id="ReplicaSet副本控制器"><a href="#ReplicaSet副本控制器" class="headerlink" title="ReplicaSet副本控制器"></a>ReplicaSet副本控制器</h2><p><strong>什么叫做副本控制器</strong>：<strong>用于控制pod副本的数量</strong>，使副本数量与预期数量保持一致。例如，我们提前设置replicas=3（有三个副本），因此创建三个pod。当有一个pod宕机之后，k8s会立刻创建一个新的，保证副本数量等于三个，这就是副本控制器的作用——永远保证副本数量为设定值。</p>
<p>副本控制器能通过<strong>标签选择器</strong>选择维护一组相关的服务（它自己的服务），那么它要怎么判断是自己的服务呢？这里就通过标签选择，比如</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">selector:</span><br><span class="line">	app &#x3D; web</span><br><span class="line">    release &#x3D; stable</span><br></pre></td></tr></table></figure>
<p><strong>ReplicationController和ReplicaSet两个副本控制器有什么区别</strong>：</p>
<ol>
<li>ReplicaSet<ul>
<li>单选</li>
<li>复合选择</li>
</ul>
</li>
<li>ReplicationController<ul>
<li>单选</li>
</ul>
</li>
</ol>
<p>在新版的k8s中，推荐使用Replicaset作为副本控制器（功能更强大），ReplicationController不再使用</p>
<h2 id="Deployment资源部署对象"><a href="#Deployment资源部署对象" class="headerlink" title="Deployment资源部署对象"></a>Deployment资源部署对象</h2><ul>
<li>服务部署结构模型</li>
<li>滚动更新</li>
</ul>
<p>虽然在企业中我们采用ReplicaSet作为副本控制器，但在实际中项目不断更新，项目的版本将会不停的发版，版本的变化如何做到服务的更新呢？我们做的是滚动更新，如下图，每当发布一个新的版本，每更新一个POD，就要干掉原有的POD。</p>
<p><img src="/posts/k8s/Deployment.png" alt></p>
<p>那么滚动更新是由谁实现的呢？这就涉及到部署模型：因为事实上ReplicaSet是不支持滚动更新的，滚动更新是由Deployment支持的，通常两者一起使用，因此部署模型为如下结构：</p>
<p><img src="/posts/k8s/dep2.png" alt></p>
<p>如果后一个版本出现问题，k8s也可以支持向前滚动。</p>
<h2 id="StatefulSet部署有状态服务"><a href="#StatefulSet部署有状态服务" class="headerlink" title="StatefulSet部署有状态服务"></a>StatefulSet部署有状态服务</h2><p>StatefulSet和Deployment类似，区别就是StatefulSet是为了解决有状态服务容器化部署问题而产生的。</p>
<p>思考：MySQL使用容器化部署，存在怎样的问题？</p>
<ul>
<li>容器是有生命周期的，一旦宕机，数据丢失</li>
<li>pod部署：pod有生命周期，但重启pod集群副本时数据可能丢失</li>
</ul>
<p>因此容器是不太适合部署数据这样的有状态服务的，对于k8s而言，不能使用Deployment模型来部署有状态服务，通常情况下Deployment用于部署无状态服务，对于有状态服务的部署使用StatefulSet。</p>
<p>什么是有状态什么是无状态呢？</p>
<ul>
<li>有状态服务<ul>
<li>有实时的的数据需要存储</li>
<li>有状态服务集群中，把某一个服务抽离出去，一段时间后再加入机器网络，如果集群网络无法使用就被称为有状态服务</li>
</ul>
</li>
<li>无状态服务<ul>
<li>无实时的的数据需要存储</li>
<li>有状态服务集群中，把某一个服务抽离出去，一段时间后再加入机器网络，对集群网络没有影响</li>
</ul>
</li>
</ul>
<p>底层的数据存储借助PVC文件系统，而StatefulSet会保证POD重新建立后，hostname不会发生变化，POD就可以通过hostname来关联数据</p>
<h1 id="kubernetes-的服务的注册与发现（核心）"><a href="#kubernetes-的服务的注册与发现（核心）" class="headerlink" title="kubernetes 的服务的注册与发现（核心）"></a>kubernetes 的服务的注册与发现（核心）</h1><h2 id="pod在生产环境中的访问流程"><a href="#pod在生产环境中的访问流程" class="headerlink" title="pod在生产环境中的访问流程"></a>pod在生产环境中的访问流程</h2><p><strong>pod的结构</strong>：根据前面所说，pod相当于一个容器，有独立的ip地址，也有自己的hostname，利用namespace进行资源隔离，独立沙箱环境。同时pod内部封装的是容器，可以封装一个，也可以封装一组相关的容器。</p>
<p><strong>pod网络</strong>：有自己独立的ip地址，pod内部容器之间访问采用localhost访问。</p>
<h3 id="pod如何对外网提供服务"><a href="#pod如何对外网提供服务" class="headerlink" title="pod如何对外网提供服务"></a>pod如何对外网提供服务</h3><ul>
<li>前提思考：pod有PODID和hostname，pod是虚拟的资源对象（进程），没有对应的实体（物理机，物理网卡），单独的POD不能直接对外提供访问，对外提供访问一定要有物理机，通过端口访问</li>
<li>解决方案：POD如果想要对外提供访问，必须绑定物理机的端口，（在物理及上开启端口，让这个端口和POD的端口建立映射），这样就可以通过物理机进行数据包的转发</li>
<li>总结为步骤：①先通过物理机IP+port进行访问NODE节点；②数据包转发</li>
</ul>
<h3 id="pod如何实现负载均衡访问"><a href="#pod如何实现负载均衡访问" class="headerlink" title="pod如何实现负载均衡访问"></a>pod如何实现负载均衡访问</h3><p>一组相同的副本直接POD如何实现负载均衡访问，思考nginx能否做负载均衡：事实上pod是一个进程，是有生命周期的（宕机，版本更新），都会创建新的pod（ip地址发生变化，hostname发生变化）,nginx做负载均衡不太合适，因为nginx不能识别出hostname的变化，因此在pod动态变化的前提下（且由于经常做滚动更新，变化速度比较快），nginx不能发现我们的服务。因此我们使用service VIP实现负载均衡。</p>
<h4 id="利用service来实现负载均衡"><a href="#利用service来实现负载均衡" class="headerlink" title="利用service来实现负载均衡"></a>利用service来实现负载均衡</h4><ul>
<li>POD IP：pod的ip地址</li>
<li>NODE IP：物理机的IP地址</li>
<li>cluster IP：虚拟化IP，是由k8s抽象出的service对象，这个service对象是一个VIP的资源对象</li>
</ul>
<p>Kubernetes 这样定义Service ：逻辑上的一组 Pod，一种可以访问Pod的策略，通常称之为微服务。 这一组 Pod 能够被 Service 访问到，通常是通过selector实现的。当我们调用某个服务时并不关心调用了哪个Pod，对外提供服务一组的 Pod 实际上可能会发生变化(是否能提供服务，或者在销毁中，或者在创建中)，而Service 能够解耦这种关联。</p>
<p>在 Kubernetes 集群中，每个Node运行一个 kube-proxy代理进程。kube-proxy 负责为 Service实现了一种VIP(虚拟 IP)。</p>
<p>以下为Service资源对象:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-svc</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx</span><br><span class="line">spec:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  ports:</span><br><span class="line">    - port: 80</span><br><span class="line">       targetPort: 80</span><br><span class="line">  selector:</span><br><span class="line">    app: nginx</span><br></pre></td></tr></table></figure>
<h4 id="Service如何实现负载均衡"><a href="#Service如何实现负载均衡" class="headerlink" title="Service如何实现负载均衡"></a>Service如何实现负载均衡</h4><p>我们知道了一组相关的port做负载均衡会使用虚拟IP来做数据包转发，但service是节点（资源对象）是怎么实现数据包的转发呢？</p>
<p><strong>我们已知的</strong>：</p>
<ol>
<li>service和pod都是一个进行，因此service也不能对外网提供服务</li>
<li>service和pod之间可以直接进行通信，它们的通信属于局域网通信</li>
<li>把请求交给service后，service使用(ipstables,ipvs)来做数据包分发</li>
</ol>
<p><strong>访问步骤</strong>：</p>
<ol>
<li>在物理机上绑定端口</li>
<li>通过ip:port访问</li>
<li>访问完成之后将请求转交给service</li>
<li>service将数据包分发给相应的pod</li>
</ol>
<p><strong>service对象是如何与pod建立关联的？</strong></p>
<p>每一组相同的pod（副本）会有相同的标签，通过标签选择器（selector），service对一组相同的副本提供服务，如果是需要访问另一组，则需在创建一个service。因此不同的业务会有不同的service。然后service将对应的POD的IP地址存储到endpoints中，由此将service和相应的pod关联起来了。</p>
<p><strong>当pod宕机或者发布了新的版本，service怎么发现pod发生了变化？</strong></p>
<p>主要是依靠kube-proxy组件，k8s安装后每个节点都运行着这个组件。kube-proxy进程将监听所有的pod，一旦发现pod有变化，就会更新service中endpoint中的映射关系。</p>
]]></content>
      <categories>
        <category>Structure</category>
      </categories>
  </entry>
  <entry>
    <title>Go语言（一）环境搭建与简要介绍</title>
    <url>/posts/503970b4.html</url>
    <content><![CDATA[<p>现在，让我以一个经典的例子“Hello World”来带你入门 <code>Go</code> 语言，了解它是如何运行起来的。</p>
<h1 id="Hello-World"><a href="#Hello-World" class="headerlink" title="Hello, World"></a>Hello, World</h1><h2 id="1-最简单的程序"><a href="#1-最简单的程序" class="headerlink" title="1. 最简单的程序"></a>1. 最简单的程序</h2><p>如果你学过 C 语言，对这个经典的例子应该不会陌生。通过它，我先带你大概了解一下 <code>Go</code> 语言的一些核心理念，让你对 <code>Go</code> 语言代码有个整体的印象。如下所示：</p>
<p><code>ch01/main.go</code></p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"><span class="keyword">import</span> <span class="string">"fmt"</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    fmt.Println(<span class="string">"Hello, World"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这五行代码就构成了一个完整的 <code>Go</code> 程序，是不是非常简单？现在我运行这段代码，看看输出的结果，方法是打开终端输入以下命令，然后回车。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ go run ch01&#x2F;main.go</span><br><span class="line">Hello, World</span><br></pre></td></tr></table></figure>
<p>其中 <code>go run ch01/main.go</code> 是我输入的命令，回车后看到的“Hello, World”是 <code>Go</code> 程序输出的结果。</p>
<p>代码中的 <code>go</code> 是一个 <code>Go</code> 语言开发工具包提供的命令，它和你平时常用的 <code>ls</code> 命令一样都是可执行的命令。它可以帮助你运行 <code>Go</code> 语言代码，并进行编译，生成可执行的二进制文件等。</p>
<p>run 在这里是 <code>go</code> 命令的子命令，表示要运行 <code>Go</code> 语言代码的意思。最后的 <code>ch01/main.go</code> 就是我写的 <code>Go</code> 语言代码文件了。也就是说，整个 <code>go run ch01/main.go</code> 表示要运行 <code>ch01/main.go</code> 里的 <code>Go</code> 语言代码。</p>
<h2 id="2-程序结构分析"><a href="#2-程序结构分析" class="headerlink" title="2. 程序结构分析"></a>2. 程序结构分析</h2><p>要让一个 <code>Go</code> 语言程序成功运行起来，只需要 <code>package main</code> 和 <code>main</code> 函数这两个核心部分， <code>package main</code> 代表的是一个可运行的应用程序，而 <code>main</code> 函数则是这个应用程序的主入口。</p>
<p>在“Hello, World”这个简单的示例中，包含了一个 <code>Go</code> 语言程序运行的最基本的核心结构。我们以此为例，来逐一介绍程序的结构，了解 <code>Go</code> 语言的核心概念。</p>
<ul>
<li>第一行的 <code>package main</code> 代表当前的 <code>ch01/main.go</code> 文件属于哪个包，其中 <code>package</code> 是 <code>Go</code> 语言声明包的关键字，main 是要声明的包名。在 <code>Go</code> 语言中 <code>main</code> 包是一个特殊的包，代表你的 <code>Go</code> 语言项目是一个可运行的应用程序，而不是一个被其他项目引用的库。</li>
<li>第二行的 <code>import &quot;fmt&quot;</code> 是导入一个 <code>fmt</code> 包，其中 <code>import</code> 是 <code>Go</code> 语言的关键字，表示导入包的意思，这里我导入的是<code>fmt</code>包，导入的目的是要使用它，下面会继续讲到。</li>
<li>第三行的 <code>func main()</code> 是定义了一个函数，其中 <code>func</code> 是 <code>Go</code> 语言的关键字，表示要定义一个函数或者方法的意思，<code>main</code> 是函数名，<code>()</code> 空括号表示这个 <code>main</code> 函数不接受任何参数。在 <code>Go</code> 语言中 <code>main</code> 函数是一个特殊的函数，它代表整个程序的入口，也就是程序在运行的时候，会先调用 <code>main</code> 函数，然后通过 <code>main</code> 函数再调用其他函数，达到实现项目业务需求的目的。</li>
<li>第四行的 <code>fmt.Println(&quot;Hello, World&quot;)</code> 是通过<code>fmt</code>包的 <code>Println</code> 函数打印“Hello, World”这段文本。其中<code>fmt</code>是刚刚导入的包，要想使用一个包，必须先导入。<code>Println</code> 函数是属于包<code>fmt</code>的函数，这里我需要它打印输出一段文本，也就是“Hello, World”。</li>
<li>第五行的大括号 <code>}</code> 表示 <code>main</code> 函数体的结束。现在整个代码片段已经分析完了，运行就可以看到“Hello, World”结果的输出。</li>
</ul>
<p>从以上分析来看，<strong><code>Go</code> 语言的代码是非常简洁、完整的核心程序</strong>，只需要 <code>package</code>、<code>import</code>、<code>func main</code> 这些核心概念就可以实现。 在后面的课时中，我还会讲如何使用变量，如何自定义函数等，这里先略过不讲，我们先来看看 <code>Go</code> 语言的开发环境是如何搭建的，这样才能运行上面的 <code>Go</code> 语言代码，让整个程序跑起来。</p>
<h1 id="Go-语言环境搭建"><a href="#Go-语言环境搭建" class="headerlink" title="Go 语言环境搭建"></a><code>Go</code> 语言环境搭建</h1><p>要想搭建 <code>Go</code> 语言开发环境，需要先下载 <code>Go</code> 语言开发包。你可以从官网 <a href="https://golang.org/dl/" target="_blank" rel="noopener">https://golang.org/dl/</a> 和 <a href="https://golang.google.cn/dl/" target="_blank" rel="noopener">https://golang.google.cn/dl/</a> 下载（第一个链接是国外的官网，第二个是国内的官网，如果第一个访问不了，可以从第二个下载）。</p>
<p>下载时可以根据自己的操作系统选择相应的开发包，比如 Window、MacOS 或是 Linux 等，如下图所示：</p>
<p><img src="/../Pic/Spider/go_1.jpg" alt></p>
<h2 id="1-Windows-MSI-下安装"><a href="#1-Windows-MSI-下安装" class="headerlink" title="1. Windows MSI 下安装"></a>1. Windows MSI 下安装</h2><p>MSI 安装的方式比较简单，在 Windows 系统上推荐使用这种方式。现在的操作系统基本上都是 64 位的，所以选择 64 位的 go1.15.windows-amd64.msi 下载即可，如果操作系统是 32 位的，选择 go1.15.windows-386.msi 进行下载。</p>
<p>下载后双击该 MSI 安装文件，按照提示一步步地安装即可。在默认情况下，Go 语言开发工具包会被安装到 c:\Go 目录，你也可以在安装过程中选择自己想要安装的目录。</p>
<p>假设安装到 c:\Go 目录，安装程序会自动把 c:\Go\bin 添加到你的 PATH 环境变量中，如果没有的话，你可以通过系统 -&gt; 控制面板 -&gt; 高级 -&gt; 环境变量选项来手动添加。</p>
<h2 id="2-Linux-下安装"><a href="#2-Linux-下安装" class="headerlink" title="2. Linux 下安装"></a>2. Linux 下安装</h2><p>Linux 系统同样有 32 位和 64 位，你可以根据你的 Linux 操作系统选择相应的压缩包，它们分别是 <code>go1.15.linux-386.tar.gz</code> 和 <code>go1.15.linux-amd64.tar.gz</code>。</p>
<p>下载成功后，需要先进行解压，假设你下载的是 <code>go1.15.linux-amd64.tar.gz</code>，在终端通过如下命令即可解压：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo tar -C &#x2F;usr&#x2F;local -xzf go1.15.linux-amd64.tar.gz</span><br></pre></td></tr></table></figure>
<p>输入后回车，然后输入你的电脑密码，即可解压到 <code>/usr/local</code> 目录，然后把 <code>/usr/local/go/bin</code> 添加到 PATH 环境变量中，就可以使用 <code>Go</code> 语言开发工具包了。</p>
<p>把下面这段添加到 <code>/etc/profile</code> 或者 <code>$HOME/.profile</code> 文件中，保存后退出即可成功添加环境变量。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export PATH&#x3D;$PATH:&#x2F;usr&#x2F;local&#x2F;go&#x2F;bin</span><br></pre></td></tr></table></figure>
<h2 id="3-macOS-下安装"><a href="#3-macOS-下安装" class="headerlink" title="3. macOS 下安装"></a>3. macOS 下安装</h2><p>如果你的操作系统是 macOS，可以采用 PKG 安装包。下载 <code>go1.15.darwin-amd64.pkg</code> 后，双击按照提示安装即可。安装成功后，路径 <code>/usr/local/go/bin</code> 应该已经被添加到了 PATH 环境变量中，如果没有的话，你可以手动添加，和上面 Linux 的方式一样，把如下内容添加到<code>/etc/profile</code> 或者 <code>$HOME/.profile</code> 文件保存即可。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export PATH&#x3D;$PATH:&#x2F;usr&#x2F;local&#x2F;go&#x2F;bin</span><br></pre></td></tr></table></figure>
<h2 id="4-安装测试"><a href="#4-安装测试" class="headerlink" title="4. 安装测试"></a>4. 安装测试</h2><p>以上都安装成功后，你可以打开终端或者命令提示符，输入 <code>go version</code> 来验证 <code>Go</code> 语言开发工具包是否安装成功。如果成功的话，会打印出 <code>Go</code> 语言的版本和系统信息，如下所示：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ go version</span><br><span class="line">go version go1.15 darwin&#x2F;amd64</span><br></pre></td></tr></table></figure>
<h2 id="5-环境变量设置"><a href="#5-环境变量设置" class="headerlink" title="5. 环境变量设置"></a>5. 环境变量设置</h2><p><code>Go</code> 语言开发工具包安装好之后，它的开发环境还没有完全搭建完成，因为还有两个重要的环境变量没有设置，它们分别是 <code>GOPATH</code> 和 <code>GOBIN</code>。</p>
<ul>
<li><code>GOPATH</code>：代表 <code>Go</code> 语言项目的工作目录，在 <code>Go Module</code> 模式之前非常重要，现在基本上用来存放使用 <code>go get</code> 命令获取的项目。</li>
<li><code>GOBIN</code>：代表 <code>Go</code> 编译生成的程序的安装目录，比如通过 <code>go install</code> 命令，会把生成的 <code>Go</code> 程序安装到 <code>GOBIN</code> 目录下，以供你在终端使用。</li>
</ul>
<p>假设工作目录为 <code>/Users/flysnow/go</code>，你需要把 <code>GOPATH</code> 环境变量设置为 <code>/Users/flysnow/go</code>，把 <code>GOBIN</code> 环境变量设置为 <code>$GOPATH/bin</code>。</p>
<p>在 Linux 和 macOS 下，把以下内容添加到 <code>/etc/profile</code> 或者 <code>$HOME/.profile</code> 文件保存即可。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export GOPATH&#x3D;&#x2F;Users&#x2F;flysnow&#x2F;go</span><br><span class="line">export GOBIN&#x3D;$GOPATH&#x2F;bin</span><br></pre></td></tr></table></figure>
<p>在 Windows 操作系统中，则通过控制面板 -&gt; 高级 -&gt; 环境变量选项添加这两个环境变量即可。</p>
<h2 id="6-项目结构"><a href="#6-项目结构" class="headerlink" title="6. 项目结构"></a>6. 项目结构</h2><p>采用 <code>Go Module</code> 的方式，可以在任何位置创建你的 <code>Go</code> 语言项目。后面我们都将会使用这种方式演示 <code>Go</code> 语言示例，现在你先对 <code>Go Module</code> 项目结构有一个大概了解，后面的课时我会详细地介绍 <code>Go Module</code>。</p>
<p>假设你的项目位置是 <code>/Users/flysnow/git/gotour</code>，打开终端，输入如下命令切换到该目录下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ cd &#x2F;Users&#x2F;flysnow&#x2F;git&#x2F;gotour</span><br></pre></td></tr></table></figure>
<p>然后再执行如下命令创建一个 <code>Go Module</code> 项目：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ go mod init</span><br></pre></td></tr></table></figure>
<p>执行成功后，会生成一个 <code>go.mod</code> 文件。然后在当前目录下创建一个 <code>main.go</code> 文件，这样整个项目目录结构是：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">gotour</span><br><span class="line">├── go.mod</span><br><span class="line">├── lib</span><br><span class="line">└── main.go</span><br></pre></td></tr></table></figure>
<p>其中 <code>main.go</code> 是整个项目的入口文件，里面有 <code>main</code> 函数。<code>lib</code> 目录是项目的子模块，根据项目需求可以新建很多个目录作为子模块，也可以继续嵌套为子模块的子模块。</p>
<h2 id="7-编译发布"><a href="#7-编译发布" class="headerlink" title="7. 编译发布"></a>7. 编译发布</h2><p>完成了你的项目后，可以编译生成可执行文件，也可以把它发布到 <code>$GOBIN</code> 目录，以供在终端使用。以“Hello, World”为例，在项目根目录输入以下命令，即可编译一个可执行文件。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ go build .&#x2F;ch01&#x2F;main.go</span><br></pre></td></tr></table></figure>
<p>回车执行后会在当前目录生成 <code>main</code> 可执行文件，现在，我们来测试下它是否可用。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ .&#x2F;main </span><br><span class="line">Hello, World</span><br></pre></td></tr></table></figure>
<p>如果成功打印出“Hello, World”，证明程序成功生成。</p>
<p>以上生成的可执行文件在当前目录，也可以把它安装到 $GOBIN 目录或者任意位置，如下所示：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">$ <span class="keyword">go</span> install ./ch01/main.<span class="keyword">go</span></span><br></pre></td></tr></table></figure>
<p>使用 <code>go install</code> 命令即可，现在你在任意时刻打开终端，输入 <code>main</code> 回车，都会打印出“Hello, World”，是不是很方便！</p>
<h2 id="8-跨平台编译"><a href="#8-跨平台编译" class="headerlink" title="8. 跨平台编译"></a>8. 跨平台编译</h2><p><strong>Go 语言开发工具包的另一强大功能就是可以跨平台编译</strong>。什么是跨平台编译呢？就是你在 macOS 开发，可以编译 Linux、Window 等平台上的可执行程序，这样你开发的程序，就可以在这些平台上运行。也就是说，你可以选择喜欢的操作系统做开发，并跨平台编译成需要发布平台的可执行程序即可。</p>
<p>Go 语言通过两个环境变量来控制跨平台编译，它们分别是 <code>GOOS</code> 和 <code>GOARCH</code> 。</p>
<ul>
<li><p><strong>GOOS</strong>：代表要编译的目标操作系统，常见的有 Linux、Windows、Darwin 等。</p>
</li>
<li><p><strong>GOARCH</strong>：代表要编译的目标处理器架构，常见的有 386、AMD64、ARM64 等。</p>
</li>
</ul>
<p>这样通过组合不同的 <code>GOOS</code> 和 <code>GOARCH</code>，就可以编译出不同的可执行程序。比如我现在的操作系统是 macOS AMD64 的，我想编译出 Linux AMD64 的可执行程序，只需要执行 <code>go build</code>命令即可，如以下代码所示：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ GOOS&#x3D;linux GOARCH&#x3D;amd64 &#96;go&#96; build .&#x2F;ch01&#x2F;main.go</span><br></pre></td></tr></table></figure>
<p>关于 <code>GOOS</code>和 <code>GOARCH</code> 更多的组合，参考官方文档的 <code>$GOOS and $GOARCH</code> 这一节即可。</p>
<h1 id="Go-编辑器推荐"><a href="#Go-编辑器推荐" class="headerlink" title="Go 编辑器推荐"></a>Go 编辑器推荐</h1><p>好的编辑器可以提高开发的效率，这里我推荐两款目前最流行的编辑器。</p>
<ul>
<li><p>第一款是 Visual Studio Code + <code>Go</code> 扩展插件，可以让你非常高效地开发，通过官方网站 <a href="https://code.visualstudio.com/" target="_blank" rel="noopener">https://code.visualstudio.com/</a> 下载使用。</p>
</li>
<li><p>第二款是老牌 IDE 公司 JetBrains 推出的 Goland，所有插件已经全部集成，更容易上手，并且功能强大，新手老手都适合，你可以通过官方网站 <a href="https://www.jetbrains.com/go/" target="_blank" rel="noopener">https://www.jetbrains.com/go/</a> 下载使用。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Spider</category>
      </categories>
  </entry>
  <entry>
    <title>Python爬虫（九）爬虫解析利器 PyQuery 的使用</title>
    <url>/posts/fdc592bf.html</url>
    <content><![CDATA[<p>每个网页，都有一定的特殊结构和层级关系，而且很多节点都有 id 或<code>class</code>作为区分，我们可以借助它们的结构和属性来提取信息吗？</p>
<p>这的确可行。这个课时我会为你介绍一个更加强大的<code>HTML</code>解析库：pyquery。利用它，我们可以直接解析 DOM 节点的结构，并通过 DOM 节点的一些属性快速进行内容提取。</p>
<p>接下来，我们就来感受一下<code>pyquery</code>的强大之处。</p>
<h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><p><code>pyquery</code> 是 <code>Python</code> 的第三方库，我们可以借助于 <code>pip3</code> 来安装，安装命令如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip3 install pyquery</span><br></pre></td></tr></table></figure>
<p>更详细的安装方法可以参考：<a href="https://cuiqingcai.com/5186.html。" target="_blank" rel="noopener">https://cuiqingcai.com/5186.html。</a></p>
<h1 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h1><p>我们在解析<code>HTML</code>文本的时候，首先需要将其初始化为一个<code>pyquery</code>对象。它的初始化方式有多种，比如直接传入字符串、传入<code>URL</code>、传入文件名，等等。</p>
<p>下面我们来详细介绍一下。</p>
<h2 id="字符串初始化"><a href="#字符串初始化" class="headerlink" title="字符串初始化"></a>字符串初始化</h2><p>我们可以直接把<code>HTML</code>的内容当作参数来初始化<code>pyquery</code>对象。我们用一个实例来感受一下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">html = '''</span><br><span class="line"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">ul</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span>first item<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link2.html"</span>&gt;</span>second item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link4.html"</span>&gt;</span>fourth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link5.html"</span>&gt;</span>fifth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">'''</span><br><span class="line">from pyquery import PyQuery as pq</span><br><span class="line">doc = pq(html)</span><br><span class="line">print(doc('li'))</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span>first item<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link2.html"</span>&gt;</span>second item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link4.html"</span>&gt;</span>fourth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link5.html"</span>&gt;</span>fifth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>这里首先引入<code>pyquery</code>这个对象，取别名为 pq，然后声明了一个长<code>HTML</code>字符串，并将其当作参数传递给<code>pyquery</code>类，这样就成功完成了初始化。</p>
<p>接下来，将初始化的对象传入<code>CSS</code>选择器。在这个实例中，我们传入<code>li</code>节点，这样就可以选择所有的<code>li</code>节点。</p>
<h2 id="URL初始化"><a href="#URL初始化" class="headerlink" title="URL初始化"></a><code>URL</code>初始化</h2><p>初始化的参数不仅可以以字符串的形式传递，还可以传入网页的<code>URL</code>，此时只需要指定参数为<code>url</code>即可：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery <span class="keyword">as</span> pq</span><br><span class="line">doc = pq(url=<span class="string">'https://cuiqingcai.com'</span>)</span><br><span class="line">print(doc(<span class="string">'title'</span>))</span><br></pre></td></tr></table></figure>
<p>运行结果：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">title</span>&gt;</span>静觅丨崔庆才的个人博客<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>这样的话，<code>pyquery</code>对象会首先请求这个<code>URL</code>，然后用得到的<code>HTML</code>内容完成初始化。这就相当于将网页的源代码以字符串的形式传递给<code>pyquery</code>类来初始化。</p>
<p>它与下面的功能是相同的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery <span class="keyword">as</span> pq</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">doc = pq(requests.get(<span class="string">'https://cuiqingcai.com'</span>).text)</span><br><span class="line">print(doc(<span class="string">'title'</span>))</span><br></pre></td></tr></table></figure>
<h2 id="文件初始化"><a href="#文件初始化" class="headerlink" title="文件初始化"></a>文件初始化</h2><p>当然除了传递一个<code>URL</code>，我们还可以传递本地的文件名，参数指定为<code>filename</code>即可：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery <span class="keyword">as</span> pq</span><br><span class="line">doc = pq(filename=<span class="string">'demo.html'</span>)</span><br><span class="line">print(doc(<span class="string">'li'</span>))</span><br></pre></td></tr></table></figure>
<p>当然，这里需要有一个本地<code>HTML</code>文件 <code>demo.html</code>，其内容是待解析的<code>HTML</code>字符串。这样它会先读取本地的文件内容，然后将文件内容以字符串的形式传递给<code>pyquery</code>类来初始化。</p>
<p>以上 3 种方式均可初始化，当然最常用的初始化方式还是以字符串形式传递。</p>
<h1 id="基本CSS选择器"><a href="#基本CSS选择器" class="headerlink" title="基本CSS选择器"></a>基本<code>CSS</code>选择器</h1><p>我们先用一个实例来感受一下<code>pyquery</code>的<code>CSS</code>选择器的用法：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">html = '''</span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"container"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">ul</span> <span class="attr">class</span>=<span class="string">"list"</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span>first item<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link2.html"</span>&gt;</span>second item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link4.html"</span>&gt;</span>fourth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link5.html"</span>&gt;</span>fifth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">'''</span><br><span class="line">from`pyquery`import pyquery as pq</span><br><span class="line">doc = pq(html)</span><br><span class="line">print(doc('#container .list li'))</span><br><span class="line">print(type(doc('#container .list li')))</span><br></pre></td></tr></table></figure>
<p>运行结果：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span>first item<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link2.html"</span>&gt;</span>second item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link4.html"</span>&gt;</span>fourth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link5.html"</span>&gt;</span>fifth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">class</span> '<span class="attr">pyquery.pyquery.PyQuery</span>'&gt;</span></span><br></pre></td></tr></table></figure>
<p>在上面的例子中，我们初始化<code>pyquery</code>对象之后，传入<code>CSS</code>选择器 #container .list li，它的意思是先选取 id 为 container 的节点，然后再选取其内部<code>class</code>为<code>list</code>的所有<code>li</code>节点，最后打印输出。</p>
<p>可以看到，我们成功获取到了符合条件的节点。我们将它的类型打印输出后发现，它的类型依然是<code>pyquery</code>类型。</p>
<p>下面，我们直接遍历这些节点，然后调用<code>text</code>方法，就可以获取节点的文本内容，代码示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> doc(<span class="string">'#container .list li'</span>).items():</span><br><span class="line">    print(item.text())</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">first item</span><br><span class="line">second item</span><br><span class="line">third item</span><br><span class="line">fourth item</span><br><span class="line">fifth item</span><br></pre></td></tr></table></figure>
<p>怎么样？我们没有再写正则表达式，而是直接通过选择器和<code>text</code>方法，就得到了我们想要提取的文本信息，是不是方便多了？</p>
<p>下面我们再来详细了解一下<code>pyquery</code>的用法吧，我将为你讲解如何用它查找节点、遍历节点、获取各种信息等操作方法。掌握了这些，我们就能更高效地完成数据提取。</p>
<h1 id="查找节点"><a href="#查找节点" class="headerlink" title="查找节点"></a>查找节点</h1><p>下面我们介绍一些常用的查询方法。</p>
<h2 id="子节点"><a href="#子节点" class="headerlink" title="子节点"></a>子节点</h2><p>查找子节点需要用到<code>find</code>方法，传入的参数是<code>CSS</code>选择器，我们还是以上面的<code>HTML</code>为例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery <span class="keyword">as</span> pq</span><br><span class="line">doc = pq(html)</span><br><span class="line">items = doc(<span class="string">'.list'</span>)</span><br><span class="line">print(type(items))</span><br><span class="line">print(items)</span><br><span class="line">lis = items.find(<span class="string">'li'</span>)</span><br><span class="line">print(type(lis))</span><br><span class="line">print(lis)</span><br></pre></td></tr></table></figure>
<p>运行结果：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">class</span> '<span class="attr">pyquery.pyquery.PyQuery</span>'&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">ul</span> <span class="attr">class</span>=<span class="string">"list"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span>first item<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link2.html"</span>&gt;</span>second item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link4.html"</span>&gt;</span>fourth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link5.html"</span>&gt;</span>fifth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">class</span> '<span class="attr">pyquery.pyquery.PyQuery</span>'&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span>first item<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link2.html"</span>&gt;</span>second item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link4.html"</span>&gt;</span>fourth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link5.html"</span>&gt;</span>fifth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>首先，我们通过 .list  参数选取<code>class</code>为<code>list</code>的节点，然后调用<code>find</code>方法，传入<code>CSS</code>选择器，选取其内部的<code>li</code>节点，最后打印输出。可以发现，find 方法会将符合条件的所有节点选择出来，结果的类型是<code>pyquery</code>类型。</p>
<p>find 的查找范围是节点的所有子孙节点，而如果我们只想查找子节点，那可以用 children 方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lis = items.children()</span><br><span class="line">print(type(lis))</span><br><span class="line">print(lis)</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">class</span> '<span class="attr">pyquery.pyquery.PyQuery</span>'&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span>first item<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link2.html"</span>&gt;</span>second item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link4.html"</span>&gt;</span>fourth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link5.html"</span>&gt;</span>fifth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>如果要筛选所有子节点中符合条件的节点，比如想筛选出子节点中<code>class</code>为<code>active</code>的节点，可以向 children 方法传入<code>CSS</code>选择器 .active，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lis = items.children(<span class="string">'.active'</span>)</span><br><span class="line">print(lis)</span><br></pre></td></tr></table></figure>
<p>运行结果：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link4.html"</span>&gt;</span>fourth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>我们看到输出的结果已经做了筛选，留下了<code>class</code>为<code>active</code>的节点。</p>
<h2 id="父节点"><a href="#父节点" class="headerlink" title="父节点"></a>父节点</h2><p>我们可以用 parent 方法来获取某个节点的父节点，下面用一个实例来感受一下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">html = '''</span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"wrap"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"container"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">ul</span> <span class="attr">class</span>=<span class="string">"list"</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span>first item<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link2.html"</span>&gt;</span>second item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link4.html"</span>&gt;</span>fourth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link5.html"</span>&gt;</span>fifth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">'''</span><br><span class="line">from pyquery import PyQuery as pq</span><br><span class="line">doc = pq(html)</span><br><span class="line">items = doc('.list')</span><br><span class="line">container = items.parent()</span><br><span class="line">print(type(container))</span><br><span class="line">print(container)</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">class</span> '<span class="attr">pyquery.pyquery.PyQuery</span>'&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"container"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">ul</span> <span class="attr">class</span>=<span class="string">"list"</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span>first item<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link2.html"</span>&gt;</span>second item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link4.html"</span>&gt;</span>fourth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link5.html"</span>&gt;</span>fifth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>在上面的例子中我们首先用 .list 选取<code>class</code>为<code>list</code>的节点，然后调用 parent 方法得到其父节点，其类型依然是<code>pyquery</code>类型。</p>
<p>这里的父节点是该节点的直接父节点，也就是说，它不会再去查找父节点的父节点，即祖先节点。</p>
<p>但是如果你想获取某个祖先节点，该怎么办呢？我们可以用<code>parents</code>方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery <span class="keyword">as</span> pq</span><br><span class="line">doc = pq(html)</span><br><span class="line">items = doc(<span class="string">'.list'</span>)</span><br><span class="line">parents = items.parents()</span><br><span class="line">print(type(parents))</span><br><span class="line">print(parents)</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">class</span> '<span class="attr">pyquery.pyquery.PyQuery</span>'&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"wrap"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"container"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">ul</span> <span class="attr">class</span>=<span class="string">"list"</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span>first item<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link2.html"</span>&gt;</span>second item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link4.html"</span>&gt;</span>fourth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link5.html"</span>&gt;</span>fifth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"container"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">ul</span> <span class="attr">class</span>=<span class="string">"list"</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span>first item<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link2.html"</span>&gt;</span>second item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link4.html"</span>&gt;</span>fourth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link5.html"</span>&gt;</span>fifth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>可以看到，这个例子的输出结果有两个：一个是<code>class</code>为<code>wrap</code>的节点，一个是 id 为 container 的节点。也就是说，使用<code>parents</code>方法会返回所有的祖先节点。</p>
<p>如果你想要筛选某个祖先节点的话，可以向<code>parents</code>方法传入<code>CSS</code>选择器，这样就会返回祖先节点中符合<code>CSS</code>选择器的节点：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">parent = items.parents(<span class="string">'.wrap'</span>)</span><br><span class="line">print(parent)</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"wrap"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"container"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">ul</span> <span class="attr">class</span>=<span class="string">"list"</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span>first item<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link2.html"</span>&gt;</span>second item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link4.html"</span>&gt;</span>fourth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link5.html"</span>&gt;</span>fifth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>可以看到，输出结果少了一个节点，只保留了<code>class</code>为<code>wrap</code>的节点。</p>
<h2 id="兄弟节点"><a href="#兄弟节点" class="headerlink" title="兄弟节点"></a>兄弟节点</h2><p>前面我们说明了子节点和父节点的用法，还有一种节点叫作兄弟节点。如果要获取兄弟节点，可以使用<code>siblings</code>方法。这里还是以上面的<code>HTML</code>代码为例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery <span class="keyword">as</span> pq</span><br><span class="line">doc = pq(html)</span><br><span class="line">li = doc(<span class="string">'.list .item-0.active'</span>)</span><br><span class="line">print(li.siblings())</span><br></pre></td></tr></table></figure>
<p>在这个例子中我们首先选择<code>class</code>为<code>list</code>的节点，内部<code>class</code>为 <code>item-0</code> 和<code>active</code>的节点，也就是第 3 个<code>li</code>节点。很明显，它的兄弟节点有 4 个，那就是第 1、2、4、5 个<code>li</code>节点。</p>
<p>我们来运行一下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link2.html"</span>&gt;</span>second item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span>first item<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link4.html"</span>&gt;</span>fourth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link5.html"</span>&gt;</span>fifth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>可以看到，结果显示的正是我们刚才所说的 4 个兄弟节点。</p>
<p>如果要筛选某个兄弟节点，我们依然可以用<code>siblings</code>方法传入<code>CSS</code>选择器，这样就会从所有兄弟节点中挑选出符合条件的节点了：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery <span class="keyword">as</span> pq</span><br><span class="line">doc = pq(html)</span><br><span class="line">li = doc(<span class="string">'.list .item-0.active'</span>)</span><br><span class="line">print(li.siblings(<span class="string">'.active'</span>))</span><br></pre></td></tr></table></figure>
<p>在这个例子中我们筛选<code>class</code>为<code>active</code>的节点，从刚才的结果中可以观察到，class 为<code>active</code>兄弟节点的是第 4 个<code>li</code>节点，所以结果应该是1个。</p>
<p>我们再看一下运行结果：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link4.html"</span>&gt;</span>fourth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h1 id="遍历"><a href="#遍历" class="headerlink" title="遍历"></a>遍历</h1><p>通过刚才的例子我们可以观察到，<code>pyquery</code>的选择结果既可能是多个节点，也可能是单个节点，类型都是<code>pyquery</code>类型，并没有返回列表。</p>
<p>对于单个节点来说，可以直接打印输出，也可以直接转成字符串：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery <span class="keyword">as</span> pq</span><br><span class="line">doc = pq(html)</span><br><span class="line">li = doc(<span class="string">'.item-0.active'</span>)</span><br><span class="line">print(li)</span><br><span class="line">print(str(li))</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>对于有多个节点的结果，我们就需要用遍历来获取了。例如，如果要把每一个<code>li</code>节点进行遍历，需要调用<code>items</code>方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery <span class="keyword">as</span> pq</span><br><span class="line">doc = pq(html)</span><br><span class="line">lis = doc(<span class="string">'li'</span>).items()</span><br><span class="line">print(type(lis))</span><br><span class="line"><span class="keyword">for</span>`li`<span class="keyword">in</span> lis:</span><br><span class="line">    print(li, type(li))</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">class</span> '<span class="attr">generator</span>'&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span>first item<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">class</span> '<span class="attr">pyquery.pyquery.PyQuery</span>'&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link2.html"</span>&gt;</span>second item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">class</span> '<span class="attr">pyquery.pyquery.PyQuery</span>'&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">class</span> '<span class="attr">pyquery.pyquery.PyQuery</span>'&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link4.html"</span>&gt;</span>fourth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">class</span> '<span class="attr">pyquery.pyquery.PyQuery</span>'&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link5.html"</span>&gt;</span>fifth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">class</span> '<span class="attr">pyquery.pyquery.PyQuery</span>'&gt;</span></span><br></pre></td></tr></table></figure>
<p>可以发现，调用<code>items</code>方法后，会得到一个生成器，遍历一下，就可以逐个得到<code>li</code>节点对象了，它的类型也是<code>pyquery</code>类型。每个<code>li</code>节点还可以调用前面所说的方法进行选择，比如继续查询子节点，寻找某个祖先节点等，非常灵活。</p>
<h2 id="获取信息"><a href="#获取信息" class="headerlink" title="获取信息"></a>获取信息</h2><p>提取到节点之后，我们的最终目的当然是提取节点所包含的信息了。比较重要的信息有两类，一是获取属性，二是获取文本，下面分别进行说明。</p>
<p><strong>获取属性</strong></p>
<p>提取到某个<code>pyquery</code>类型的节点后，就可以调用 attr 方法来获取属性：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">html = '''</span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"wrap"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"container"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">ul</span> <span class="attr">class</span>=<span class="string">"list"</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span>first item<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link2.html"</span>&gt;</span>second item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link4.html"</span>&gt;</span>fourth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link5.html"</span>&gt;</span>fifth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">'''</span><br><span class="line">from pyquery import PyQuery as pq</span><br><span class="line">doc = pq(html)</span><br><span class="line">a = doc('.item-0.active a')</span><br><span class="line">print(a, type(a))</span><br><span class="line">print(a.attr('href'))</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span> <span class="tag">&lt;<span class="name">class</span> '<span class="attr">pyquery.pyquery.PyQuery</span>'&gt;</span></span><br><span class="line">link3.html</span><br></pre></td></tr></table></figure>
<p>在这个例子中我们首先选中<code>class</code>为 item-0 和<code>active</code>的<code>li</code>节点内的 a 节点，它的类型是<code>pyquery</code>类型。</p>
<p>然后调用 attr 方法。在这个方法中传入属性的名称，就可以得到属性值了。</p>
<p>此外，也可以通过调用 attr 属性来获取属性值，用法如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(a.attr.href)</span><br></pre></td></tr></table></figure>
<p>结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">link3.html</span><br></pre></td></tr></table></figure>
<p>这两种方法的结果完全一样。</p>
<p>如果选中的是多个元素，然后调用 attr 方法，会出现怎样的结果呢？我们用实例来测试一下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = doc(<span class="string">'a'</span>)</span><br><span class="line">print(a, type(a))</span><br><span class="line">print(a.attr(<span class="string">'href'</span>))</span><br><span class="line">print(a.attr.href)</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link2.html"</span>&gt;</span>second item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link4.html"</span>&gt;</span>fourth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link5.html"</span>&gt;</span>fifth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span> <span class="tag">&lt;<span class="name">class</span> '<span class="attr">pyquery.pyquery.PyQuery</span>'&gt;</span></span><br><span class="line">link2.html</span><br><span class="line">link2.html</span><br></pre></td></tr></table></figure>
<p>照理来说，我们选中的 a 节点应该有 4 个，打印结果也应该是 4 个，但是当我们调用 attr 方法时，返回结果却只有第 1 个。这是因为，当返回结果包含多个节点时，调用 attr 方法，只会得到第 1 个节点的属性。</p>
<p>那么，遇到这种情况时，如果想获取所有的 a 节点的属性，就要用到前面所说的遍历了：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery <span class="keyword">as</span> pq</span><br><span class="line">doc = pq(html)</span><br><span class="line">a = doc(<span class="string">'a'</span>)</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> a.items():</span><br><span class="line">    print(item.attr(<span class="string">'href'</span>))</span><br></pre></td></tr></table></figure>
<p>运行结果：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">link2.html</span><br><span class="line">link3.html</span><br><span class="line">link4.html</span><br><span class="line">link5.html</span><br></pre></td></tr></table></figure>
<p>因此，在进行属性获取时，先要观察返回节点是一个还是多个，如果是多个，则需要遍历才能依次获取每个节点的属性。</p>
<p><strong>获取文本</strong></p>
<p>获取节点之后的另一个主要操作就是获取其内部文本了，此时可以调用<code>text</code>方法来实现：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">html = '''</span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"wrap"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"container"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">ul</span> <span class="attr">class</span>=<span class="string">"list"</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span>first item<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link2.html"</span>&gt;</span>second item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link4.html"</span>&gt;</span>fourth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link5.html"</span>&gt;</span>fifth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">'''</span><br><span class="line">from pyquery import PyQuery as pq</span><br><span class="line">doc = pq(html)</span><br><span class="line">a = doc('.item-0.active a')</span><br><span class="line">print(a)</span><br><span class="line">print(a.text())</span><br></pre></td></tr></table></figure>
<p>运行结果：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">third item</span><br></pre></td></tr></table></figure>
<p>这里我们首先选中一个 <code>a</code> 节点，然后调用<code>text</code>方法，就可以获取其内部的文本信息了。<code>text</code> 会忽略节点内部包含的所有 HTML，只返回纯文字内容。</p>
<p>但如果你想要获取这个节点内部的<code>HTML</code>文本，就要用<code>HTML</code>方法了：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery <span class="keyword">as</span> pq</span><br><span class="line">doc = pq(html)</span><br><span class="line">li = doc(<span class="string">'.item-0.active'</span>)</span><br><span class="line">print(li)</span><br><span class="line">print(li.html())</span><br></pre></td></tr></table></figure>
<p>这里我们选中第 3 个<code>li</code>节点，然后调用<code>HTML</code>方法，它返回的结果应该是<code>li</code>节点内的所有<code>HTML</code>文本。</p>
<p>运行结果：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>这里同样有一个问题，如果我们选中的结果是多个节点，text 或<code>HTML</code>方法会返回什么内容？我们用实例来看一下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">html = '''</span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"wrap"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"container"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">ul</span> <span class="attr">class</span>=<span class="string">"list"</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link2.html"</span>&gt;</span>second item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link4.html"</span>&gt;</span>fourth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link5.html"</span>&gt;</span>fifth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">'''</span><br><span class="line">from pyquery import PyQuery as pq</span><br><span class="line">doc = pq(html)</span><br><span class="line">li = doc('li')</span><br><span class="line">print(li.html())</span><br><span class="line">print(li.text())</span><br><span class="line">print(type(li.text())</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link2.html"</span>&gt;</span>second item<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">second item third item fourth item fifth item</span><br><span class="line"><span class="tag">&lt;<span class="name">class'str'</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>结果比较出乎意料，html 方法返回的是第 1 个<code>li</code>节点的内部<code>HTML</code>文本，而<code>text</code>则返回了所有的<code>li</code>节点内部的纯文本，中间用一个空格分割开，即返回结果是一个字符串。</p>
<p>这个地方值得注意，如果你想要得到的结果是多个节点，并且需要获取每个节点的内部<code>HTML</code>文本，则需要遍历每个节点。而<code>text</code>方法不需要遍历就可以获取，它将所有节点取文本之后合并成一个字符串。</p>
<h1 id="节点操作"><a href="#节点操作" class="headerlink" title="节点操作"></a>节点操作</h1><p>pyquery 提供了一系列方法来对节点进行动态修改，比如为某个节点添加一个 class，移除某个节点等，这些操作有时会为提取信息带来极大的便利。</p>
<p>由于节点操作的方法太多，下面举几个典型的例子来说明它的用法。</p>
<h2 id="addClass-和-removeClass"><a href="#addClass-和-removeClass" class="headerlink" title="addClass 和 removeClass"></a>addClass 和 removeClass</h2><p>我们先用一个实例来感受一下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">html = '''</span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"wrap"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"container"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">ul</span> <span class="attr">class</span>=<span class="string">"list"</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span>first item<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link2.html"</span>&gt;</span>second item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link4.html"</span>&gt;</span>fourth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link5.html"</span>&gt;</span>fifth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">'''</span><br><span class="line">from pyquery import PyQuery as pq</span><br><span class="line">doc = pq(html)</span><br><span class="line">li = doc('.item-0.active')</span><br><span class="line">print(li)</span><br><span class="line">li.removeClass('active')</span><br><span class="line">print(li)</span><br><span class="line">li.addClass('active')</span><br><span class="line">print(li)</span><br></pre></td></tr></table></figure>
<p>首先选中第 3 个<code>li</code>节点，然后调用 removeClass 方法，将<code>li</code>节点的<code>active</code>这个<code>class</code>移除，第 2 步调用 addClass 方法，将<code>class</code>添加回来。每执行一次操作，就打印输出当前<code>li</code>节点的内容。</p>
<p>运行结果如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>可以看到，一共输出了 3 次。第 2 次输出时，li 节点的<code>active</code>这个<code>class</code>被移除了，第 3 次<code>class</code>又添加回来了。</p>
<p>所以说，<code>addClass</code> 和 <code>removeClass</code> 方法可以动态改变节点的<code>class</code>属性。</p>
<h2 id="attr、text、html"><a href="#attr、text、html" class="headerlink" title="attr、text、html"></a>attr、text、html</h2><p>当然，除了操作<code>class</code>这个属性外，也可以用 attr 方法对属性进行操作。此外，我们还可以用<code>text</code>和<code>HTML</code>方法来改变节点内部的内容。示例如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">html = '''</span><br><span class="line"><span class="tag">&lt;<span class="name">ul</span> <span class="attr">class</span>=<span class="string">"list"</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line">'''</span><br><span class="line">from pyquery import PyQuery as pq</span><br><span class="line">doc = pq(html)</span><br><span class="line">li = doc('.item-0.active')</span><br><span class="line">print(li)</span><br><span class="line">li.attr('name', 'link')</span><br><span class="line">print(li)</span><br><span class="line">li.text('changed item')</span><br><span class="line">print(li)</span><br><span class="line">li.html('<span class="tag">&lt;<span class="name">span</span>&gt;</span>changed item<span class="tag">&lt;/<span class="name">span</span>&gt;</span>')</span><br><span class="line">print(li)</span><br></pre></td></tr></table></figure>
<p>这里我们首先选中<code>li</code>节点，然后调用 attr 方法来修改属性。该方法的第 1 个参数为属性名，第 2 个参数为属性值。最后调用<code>text</code>和<code>HTML</code>方法来改变节点内部的内容。3 次操作后，分别打印输出当前的<code>li</code>节点。</p>
<p>运行结果如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span> <span class="attr">name</span>=<span class="string">"link"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span> <span class="attr">name</span>=<span class="string">"link"</span>&gt;</span>changed item<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span> <span class="attr">name</span>=<span class="string">"link"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span>&gt;</span>changed item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>我们发现，调用 attr 方法后，li 节点多了一个原本不存在的属性 name，其值为 link。接着调用<code>text</code>方法传入文本，li 节点内部的文本全被改为传入的字符串文本。最后，调用<code>HTML</code>方法传入<code>HTML</code>文本，li 节点内部又变为传入的<code>HTML</code>文本了。</p>
<p>所以说，使用 attr 方法时如果只传入第 1 个参数的属性名，则是获取这个属性值；如果传入第 2 个参数，可以用来修改属性值。使用<code>text</code>和<code>HTML</code>方法时如果不传参数，则是获取节点内纯文本和<code>HTML</code>文本，如果传入参数，则进行赋值。</p>
<h2 id="remove"><a href="#remove" class="headerlink" title="remove"></a>remove</h2><p>顾名思义，<code>remove</code> 方法就是移除，它有时会为信息的提取带来非常大的便利。下面有一段<code>HTML</code>文本：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">html = '''</span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"wrap"</span>&gt;</span></span><br><span class="line">    Hello, World</span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>This is a paragraph.<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">'''</span><br><span class="line">from pyquery import PyQuery as pq</span><br><span class="line">doc = pq(html)</span><br><span class="line">wrap = doc('.wrap')</span><br><span class="line">print(wrap.text())</span><br></pre></td></tr></table></figure>
<p>现在我们想提取“Hello, World”这个字符串，该怎样操作呢？</p>
<p>这里先直接尝试提取<code>class</code>为<code>wrap</code>的节点的内容，看看是不是我们想要的。</p>
<p>运行结果如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Hello, World This <span class="keyword">is</span> a paragraph.</span><br></pre></td></tr></table></figure>
<p>这个结果还包含了内部的 <code>p</code> 节点的内容，也就是说<code>text</code>把所有的纯文本全提取出来了。</p>
<p>如果我们想去掉 <code>p</code> 节点内部的文本，可以选择再把 p 节点内的文本提取一遍，然后从整个结果中移除这个子串，但这个做法明显比较烦琐。</p>
<p>这时 <code>remove</code> 方法就可以派上用场了，我们可以接着这么做：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">wrap.find(<span class="string">'p'</span>).remove()</span><br><span class="line">print(wrap.text())</span><br></pre></td></tr></table></figure>
<p>首先选中 p 节点，然后调用 remove 方法将其移除，这时<code>wrap</code>内部就只剩下“Hello, World”这句话了，最后利用<code>text</code>方法提取即可。</p>
<p>其实还有很多其他节点操作的方法，比如 append、empty 和 prepend 等方法，详细的用法可以参考官方文档：<a href="http://pyquery.readthedocs.io/en/latest/api.html。" target="_blank" rel="noopener">http://pyquery.readthedocs.io/en/latest/api.html。</a></p>
<h1 id="伪类选择器"><a href="#伪类选择器" class="headerlink" title="伪类选择器"></a>伪类选择器</h1><p>CSS 选择器之所以强大，还有一个很重要的原因，那就是它支持多种多样的伪类选择器，例如选择第一个节点、最后一个节点、奇偶数节点、包含某一文本的节点等。示例如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">html = '''</span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"wrap"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"container"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">ul</span> <span class="attr">class</span>=<span class="string">"list"</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span>first item<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link2.html"</span>&gt;</span>second item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1 active"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link4.html"</span>&gt;</span>fourth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link5.html"</span>&gt;</span>fifth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">'''</span><br><span class="line">from pyquery import PyQuery as pq</span><br><span class="line">doc = pq(html)</span><br><span class="line">li = doc('li:first-child')</span><br><span class="line">print(li)</span><br><span class="line">li = doc('li:last-child')</span><br><span class="line">print(li)</span><br><span class="line">li = doc('li:nth-child(2)')</span><br><span class="line">print(li)</span><br><span class="line">li = doc('li:gt(2)')</span><br><span class="line">print(li)</span><br><span class="line">li = doc('li:nth-child(2n)')</span><br><span class="line">print(li)</span><br><span class="line">li = doc('li:contains(second)')</span><br><span class="line">print(li)</span><br></pre></td></tr></table></figure>
<p>在这个例子中我们使用了 CSS3 的伪类选择器，依次选择了第 1 个<code>li</code>节点、最后一个<code>li</code>节点、第 2 个<code>li</code>节点、第 3 个<code>li</code>之后的<code>li</code>节点、偶数位置的<code>li</code>节点、包含 second 文本的<code>li</code>节点。</p>
<p>关于<code>CSS</code>选择器的更多用法，可以参考 <a href="http://www.w3school.com.cn/css/index.asp。" target="_blank" rel="noopener">http://www.w3school.com.cn/css/index.asp。</a></p>
<p>到此为止，<code>pyquery</code>的常用用法就介绍完了。如果想查看更多的内容，可以参考<code>pyquery</code>的官方文档：<a href="http://pyquery.readthedocs.io/" target="_blank" rel="noopener">http://pyquery.readthedocs.io</a>。相信一旦你拥有了它，解析网页将不再是难事。</p>
]]></content>
      <categories>
        <category>Spider</category>
      </categories>
  </entry>
  <entry>
    <title>Python爬虫（八）正则表达式</title>
    <url>/posts/7c424d25.html</url>
    <content><![CDATA[<p>正则表达式，即 RE，是 regular expression 的简称，是用来简洁表达一组字符串的表达式。前面我们学会了如何用 Requests 来获取网页的源代码，得到 <code>HTML</code> 代码。但我们如何从 <code>HTML</code> 代码中获取真正想要的数据呢？正则表达式就是一个有效的方法。</p>
<p>本节我们将学习正则表达式的相关用法。正则表达式是处理字符串的强大工具，它有自己特定的语法结构。有了它，我们就能实现字符串的检索、替换、匹配验证。当然，对于爬虫来说，有了它，要从<code>HTML</code>里提取想要的信息就非常方便了。</p>
<h1 id="实例引入"><a href="#实例引入" class="headerlink" title="实例引入"></a>实例引入</h1><p>说了这么多，可能我们对正则表达式的概念还是比较模糊，下面就用几个实例来看一下正则表达式的用法。</p>
<p>打开开源中国提供的正则表达式测试工具 <a href="http://tool.oschina.net/regex/，输入待匹配的文本，然后选择常用的正则表达式，就可以得出相应的匹配结果了。" target="_blank" rel="noopener">http://tool.oschina.net/regex/，输入待匹配的文本，然后选择常用的正则表达式，就可以得出相应的匹配结果了。</a></p>
<p>例如，输入下面这段待匹配的文本：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Hello, my phone number is 010-86432100 and email is cqc@cuiqingcai.com, and my website is https:&#x2F;&#x2F;cuiqingcai.com.</span><br></pre></td></tr></table></figure>
<p>这段字符串中包含了一个电话号码和一个电子邮件，接下来就尝试用正则表达式提取出来，如图所示</p>
<p><img src="/../Pic/Spider/re_.png" style="zoom:67%;"></p>
<h1 id="正则表达式的语法"><a href="#正则表达式的语法" class="headerlink" title="正则表达式的语法"></a>正则表达式的语法</h1><div class="table-container">
<table>
<thead>
<tr>
<th>操 作 符</th>
<th>说 明</th>
<th>正 则 表 达 式 样 例</th>
</tr>
</thead>
<tbody>
<tr>
<td>.</td>
<td>匹配任何字符（换行符除外）</td>
<td>b.b</td>
</tr>
<tr>
<td>[…]</td>
<td>匹配字符组里出现的任意一个字符</td>
<td>[abcd]</td>
</tr>
<tr>
<td>*</td>
<td>匹配前面出现的正则表达式零次或多次</td>
<td>abc*</td>
</tr>
<tr>
<td>+</td>
<td>匹配前面出现的正则表达式一次或多次</td>
<td>abc+</td>
</tr>
<tr>
<td>？</td>
<td>匹配前面出现的正则表达式零次或一次</td>
<td>abc?</td>
</tr>
<tr>
<td>\</td>
<td></td>
<td>匹配左或右任意一个正则表达式</td>
<td>re1</td>
</tr>
<tr>
<td>{A}</td>
<td>匹配前面出现的正则表达式A次</td>
<td>[0-9]{5}</td>
</tr>
<tr>
<td>{A, B}</td>
<td>匹配前面出现的正则表达式A-B次（含B）</td>
<td>[0-9]{1, 5}</td>
</tr>
<tr>
<td>^</td>
<td>匹配字符串的开始</td>
<td>^abc</td>
</tr>
<tr>
<td>$</td>
<td>匹配字符串的结束</td>
<td>abc$</td>
</tr>
<tr>
<td>[…a-b…]</td>
<td>匹配从字符a-b中的任意一个字符</td>
<td>[0-9],[A-Za-z]</td>
</tr>
<tr>
<td><sup><a href="#fn_..." id="reffn_...">...</a></sup></td>
<td>不匹配此字符集中出现的任何一个字符， 包括某一范围的字符</td>
<td><sup><a href="#fn_abc" id="reffn_abc">abc</a></sup>, <sup><a href="#fn_a-z" id="reffn_a-z">a-z</a></sup></td>
</tr>
<tr>
<td>(…)</td>
<td>匹配封闭括号中的正则表达式，并保存为子组</td>
<td>（[1-3]{2})</td>
</tr>
<tr>
<td>\d</td>
<td>匹配任何数字</td>
<td>\d.txt</td>
</tr>
<tr>
<td>\w</td>
<td>匹配任何数字字母字符（包括_),\W与\w作用相反</td>
<td>\w?</td>
</tr>
<tr>
<td>\s</td>
<td>匹配任何空白符，等价于[\n\s\r\v\f]，\S与\s作用相反</td>
<td>\s?</td>
</tr>
<tr>
<td>\b</td>
<td>匹配单词边界，\B与\b作用相反</td>
<td>\bMonkey\b</td>
</tr>
<tr>
<td>\nn</td>
<td>匹配已保存的子组</td>
<td></td>
</tr>
<tr>
<td>\c</td>
<td>逐一匹配特殊字符c</td>
<td></td>
</tr>
<tr>
<td>\A(\Z)</td>
<td>匹配字符串的起始（结束）</td>
<td>\ATest</td>
</tr>
</tbody>
</table>
</div>
<p>我们可以举一些其他常用例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">^[A - Z a - z]+$ 表示由26个字母组成的字符串</span><br><span class="line">^[A - Z a - z 0 - 9]+$ 表示由26个字母和数字组成的字符串</span><br><span class="line">^-?\d+$ 表示整数形式的字符串（有正负）</span><br><span class="line">[1-9]\d&#123;5&#125; 表示中国境内邮政编码，6位</span><br><span class="line">[\u4e00 - \u9fa5] 匹配中文字符</span><br><span class="line">\d&#123;3&#125; - \d&#123;8&#125; | \d&#123;4&#125; - \d&#123;7&#125; 匹配国外电话号码</span><br></pre></td></tr></table></figure>
<p>我们思考一下，我们应该怎么匹配 IP 地址呢？<br>我们知道，IP 地址分为4段，每段取值范围是 0-255，那么我们会考虑到根据这256个数字的特殊性进行划分，比如：<br>1、当取值为 0-99 时，我们可以记为 [1-9] ? \d<br>2、当取值为 100-199 时，我们可以记为 1\d{2}<br>3、当取值为 200-249 时，我们可以记为 2[0-4]\d<br>4、当取值为 250-255 时，我们可以记为 25[0-5]<br>我们只需要将每个区间按 | 预算符进行划分即可获得每段 IP 地址的正确表达式。</p>
<h1 id="Re-库的基本使用"><a href="#Re-库的基本使用" class="headerlink" title="Re 库的基本使用"></a>Re 库的基本使用</h1><p>我们先介绍 Re 库的主要功能函数：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>函数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>re.search()</td>
<td>在一个字符串中搜索匹配正则表达式的第一个位置，返回 match 对象</td>
</tr>
<tr>
<td>re.match()</td>
<td>从一个字符串的开始位置起匹配正则表达式，返回 match 对象</td>
</tr>
<tr>
<td>re.findall()</td>
<td>搜索字符串，以列表类型返回全部能匹配的子串</td>
</tr>
<tr>
<td>re.split()</td>
<td>将一个字符串按照正则表达式匹配结果进行分割，返回列表类型</td>
</tr>
<tr>
<td>re.finditer()</td>
<td>搜索字符串，返回一个匹配结果的迭代类型，每个迭代元素是 match 对象</td>
</tr>
<tr>
<td>re.sub()</td>
<td>在一个字符串中替换所有匹配正则表达式的子串，返回替换后的字符串</td>
</tr>
</tbody>
</table>
</div>
<p>下面一一介绍这六个函数：</p>
<h3 id="re-search-pattern-string-flags-0"><a href="#re-search-pattern-string-flags-0" class="headerlink" title="re.search(pattern, string, flags=0)"></a>re.search(pattern, string, flags=0)</h3><p>其中 pattern 是正则表达式的字符串或原生字符串表示，string 是待匹配字符串，flags 是正则表达式使用时的控制标记。<br>flags 的控制常用标记如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>常用标记</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>re.I re.IGNORECASE</td>
<td>忽略正则表达式的大小写，[A-Z] 能够匹配小写字符</td>
</tr>
<tr>
<td>re.M re.MULTILINE</td>
<td>正则表达式中的 ^ 操作符能够将给定字符串的每行当作匹配开始</td>
</tr>
<tr>
<td>re.S re.DOTAIL</td>
<td>正则表达式中的 . 操作能够匹配所有字符，默认匹配除换行外的所有字符</td>
</tr>
</tbody>
</table>
</div>
<p>下面是一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>match = re.search(<span class="string">r'[1-9]\d&#123;5&#125;'</span>,<span class="string">'BIT 100081'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">if</span> match:</span><br><span class="line">		print(match.group(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line"><span class="number">100081</span></span><br></pre></td></tr></table></figure>
<h3 id="re-match-pattern-string-flags-0"><a href="#re-match-pattern-string-flags-0" class="headerlink" title="re.match(pattern, string, flags=0)"></a>re.match(pattern, string, flags=0)</h3><p>match 对象的三个参数和标记都与 search 对象相同，我们直接看一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>match = re.match(<span class="string">r'[0-9]\d&#123;5&#125;'</span>, <span class="string">'BIT 100081'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">if</span> match:</span><br><span class="line">	match.group(<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 无结果</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>match.group(<span class="number">0</span>)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"&lt;pyshell#15&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    match.group(<span class="number">0</span>)</span><br><span class="line">AttributeError: <span class="string">'NoneType'</span> object has no attribute <span class="string">'group'</span></span><br></pre></td></tr></table></figure>
<p>我们发现上述代码的 match 对象并没有任何结果返回，也就是说这个对象是空的，因为我们知道 match 是从头开始匹配，而字符串的头为 ‘BIT’，自然匹配错误。我们换一下字符串的表示，看看是否能匹配出相关结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>match = re.match(<span class="string">r'[1-9]\d&#123;5&#125;'</span>,<span class="string">'100081 BIT'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">if</span> match:</span><br><span class="line">	match.group(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">'100081'</span></span><br></pre></td></tr></table></figure>
<p>这印证了我们上面的讨论</p>
<h3 id="re-findall-pattern-string-flags-0"><a href="#re-findall-pattern-string-flags-0" class="headerlink" title="re.findall(pattern, string, flags=0)"></a>re.findall(pattern, string, flags=0)</h3><p>我们直接看例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ls = re.findall(<span class="string">r'[1-9]\d&#123;5&#125;'</span>, <span class="string">'BIT100081 TSU100084'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ls</span><br><span class="line">[<span class="string">'100081'</span>, <span class="string">'100084'</span>]</span><br></pre></td></tr></table></figure>
<h3 id="re-split-pattern-string-maxsplit-0-flags-0"><a href="#re-split-pattern-string-maxsplit-0-flags-0" class="headerlink" title="re.split(pattern, string, maxsplit=0, flags=0)"></a>re.split(pattern, string, maxsplit=0, flags=0)</h3><p>split 函数的三个参数我们都已经熟知，中间新增加的参数 maxsplit 表示最大分割数，剩余部分作为最后一个元素输出，下面看看例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ls = re.findall(<span class="string">r'[1-9]\d&#123;5&#125;'</span>, <span class="string">'BIT100081 TSU100084'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ls</span><br><span class="line">[<span class="string">'100081'</span>, <span class="string">'100084'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>re.split(<span class="string">r'[1-9]\d&#123;5&#125;'</span>, <span class="string">'BIT100081 TSU100084'</span>)</span><br><span class="line">[<span class="string">'BIT'</span>, <span class="string">' TSU'</span>, <span class="string">''</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>re.split(<span class="string">r'[1-9]\d&#123;5&#125;'</span>, <span class="string">'BIT100081 TSU100084'</span>, maxsplit=<span class="number">1</span>)</span><br><span class="line">[<span class="string">'BIT'</span>, <span class="string">' TSU100084'</span>]</span><br></pre></td></tr></table></figure>
<h3 id="re-finditer-pattern-string-flags-0"><a href="#re-finditer-pattern-string-flags-0" class="headerlink" title="re.finditer(pattern, string, flags=0)"></a>re.finditer(pattern, string, flags=0)</h3><p>我们直接看代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> m <span class="keyword">in</span> re.finditer(<span class="string">r'[1-9]\d&#123;5&#125;'</span>, <span class="string">'BIT100081 TSU100084'</span>):</span><br><span class="line">	<span class="keyword">if</span> m:</span><br><span class="line">		print(m.group(<span class="number">0</span>))</span><br><span class="line"><span class="number">100081</span></span><br><span class="line"><span class="number">100084</span></span><br></pre></td></tr></table></figure>
<h3 id="re-sub-pattern-repl-string-count-0-flags-0"><a href="#re-sub-pattern-repl-string-count-0-flags-0" class="headerlink" title="re.sub(pattern, repl, string, count=0, flags=0)"></a>re.sub(pattern, repl, string, count=0, flags=0)</h3><p>我们可以看到所有参数中新增了两个参数，repl 是指替换匹配字符串的字符串，而 count 是匹配的最大替换次数，下面我们看一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>re.sub(<span class="string">r'[1-9]\d&#123;5&#125;'</span>, <span class="string">'zipcode'</span>, <span class="string">'BIT100081 TSU100084'</span>)</span><br><span class="line"><span class="string">'BITzipcode TSUzipcode'</span></span><br></pre></td></tr></table></figure>
<h3 id="Re-库的另一种等价用法"><a href="#Re-库的另一种等价用法" class="headerlink" title="Re 库的另一种等价用法"></a>Re 库的另一种等价用法</h3><p>我们上面给出的函数例子都是函数使用法，也就是仅支持一次性操作的用法，这是什么意思呢，我们对比一下下面的面向对象用法就知道了：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pat = re.compile(<span class="string">r'[1-9]\d&#123;5&#125;'</span>)</span><br><span class="line">rst = pat.search(<span class="string">'BIT 100081'</span>)</span><br></pre></td></tr></table></figure>
<p>re.compile 函数的完整形式是：re.compile(pattern, flags=0)，该函数将正则表达式的字符串形式编译成正则表达式对象。编译后才是一个正则表达式，表示一组字符串。</p>
<h1 id="Re-库的-Match-对象"><a href="#Re-库的-Match-对象" class="headerlink" title="Re 库的 Match 对象"></a>Re 库的 Match 对象</h1><p>Match 就是一次匹配的结果，它返回了匹配的相关信息，我们直接看前面的一个代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>match = re.match(<span class="string">r'[1-9]\d&#123;5&#125;'</span>,<span class="string">'100081 BIT'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">if</span> match:</span><br><span class="line">	match.group(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">'100081'</span></span><br></pre></td></tr></table></figure>
<p>在这里我们想看一下 match 的类型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>type(match)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">re</span>.<span class="title">Match</span>'&gt;</span></span><br></pre></td></tr></table></figure>
<p>Match 对象有很多属性，下面我们重点介绍4个属性：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>属性</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>.string</td>
<td>待匹配的文本</td>
</tr>
<tr>
<td>.re</td>
<td>匹配时使用的 pattern 对象（正则表达式）</td>
</tr>
<tr>
<td>.pos</td>
<td>正则表达式搜索文本的开始位置</td>
</tr>
<tr>
<td>.endpos</td>
<td>正则表达式搜索文本的结束位置</td>
</tr>
</tbody>
</table>
</div>
<p>Match 对象有很多方法，下面列举4个常用对象：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>方法</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>.group(0)</td>
<td>获得匹配后的字符串</td>
</tr>
<tr>
<td>.start()</td>
<td>匹配字符串在原始字符串的开始位置</td>
</tr>
<tr>
<td>.end()</td>
<td>匹配字符串在原始字符串的结束位置</td>
</tr>
<tr>
<td>.span()</td>
<td>返回 (.start(), .end())</td>
</tr>
</tbody>
</table>
</div>
<p>我们看一下相关例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = re.search(<span class="string">r'[1-9]\d&#123;5&#125;'</span>, <span class="string">'BIT100081 TSU100084'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.string</span><br><span class="line"><span class="string">'BIT100081 TSU100084'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.re</span><br><span class="line">re.compile(<span class="string">'[1-9]\\d&#123;5&#125;'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.pos</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.endpos</span><br><span class="line"><span class="number">19</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.group(<span class="number">0</span>)</span><br><span class="line"><span class="string">'100081'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.start()</span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.end()</span><br><span class="line"><span class="number">9</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.span()</span><br><span class="line">(<span class="number">3</span>, <span class="number">9</span>)</span><br></pre></td></tr></table></figure>
<h1 id="Re-库的贪婪匹配和最小匹配"><a href="#Re-库的贪婪匹配和最小匹配" class="headerlink" title="Re 库的贪婪匹配和最小匹配"></a>Re 库的贪婪匹配和最小匹配</h1><p>首先我们看一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>match = re.search(<span class="string">r'PY.*N'</span>, <span class="string">'PYANBNCNDN'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>match.group(<span class="number">0</span>)</span><br><span class="line"><span class="string">'PYANBNCNDN'</span></span><br></pre></td></tr></table></figure>
<p>其中的 ‘.*‘ 表示匹配任意字符串，这里我们应该留意到， Re 库默认采用贪婪匹配，即输出匹配最长的子串。那么我们应该如何实现输出最短的子串呢？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>match = re.search(<span class="string">r'PY.*?N'</span>, <span class="string">'PYANBNCNDN'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>match.group(<span class="number">0</span>)</span><br><span class="line"><span class="string">'PYAN'</span></span><br></pre></td></tr></table></figure>
<p>最小匹配操作符有下面四种：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>操作符</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>*?</td>
<td>前一个字符0次或无限次扩展</td>
</tr>
<tr>
<td>+?</td>
<td>前一个字符1次或无限次扩展</td>
</tr>
<tr>
<td>??</td>
<td>前一个字符0次或1次扩展</td>
</tr>
<tr>
<td>{m,n}?</td>
<td>扩展前一个字符 m 至 n 次（含 n）</td>
</tr>
</tbody>
</table>
</div>
<p>所以，在做匹配的时候，字符串中间尽量使用非贪婪匹配，也就是用 <code>.*?</code> 来代替 <code>.*</code>，以免出现匹配结果缺失的情况。</p>
<p>但需要注意的是，如果匹配的结果在字符串结尾，<code>.*?</code> 就有可能匹配不到任何内容了，因为它会匹配尽可能少的字符。例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">content = <span class="string">'http://weibo.com/comment/kEraCN'</span></span><br><span class="line">result1 = re.match(<span class="string">'http.*?comment/(.*?)'</span>, content)</span><br><span class="line">result2 = re.match(<span class="string">'http.*?comment/(.*)'</span>, content)</span><br><span class="line">print(<span class="string">'result1'</span>, result1.group(<span class="number">1</span>))</span><br><span class="line">print(<span class="string">'result2'</span>, result2.group(<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">result1 </span><br><span class="line">result2 kEraCN</span><br></pre></td></tr></table></figure>
<h1 id="修饰符"><a href="#修饰符" class="headerlink" title="修饰符"></a>修饰符</h1><p>正则表达式可以包含一些可选标志修饰符来控制匹配的模式。修饰符被指定为一个可选的标志。</p>
<p>我们用实例来看一下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">content = <span class="string">'''Hello 1234567 World_This</span></span><br><span class="line"><span class="string">is a Regex Demo</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">result = re.match(<span class="string">'^He.*?(\d+).*?Demo$'</span>, content)</span><br><span class="line">print(result.group(<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>和上面的例子相仿，我们在字符串中加了换行符，正则表达式还是一样的，用来匹配其中的数字。看一下运行结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">AttributeError Traceback (most recent call last)</span><br><span class="line">&lt;ipython-input-18-c7d232b39645&gt; in &lt;module&gt;()</span><br><span class="line">      5 &#39;&#39;&#39;</span><br><span class="line">      6 result &#x3D; re.match(&#39;^He.*?(\d+).*?Demo$&#39;, content)</span><br><span class="line">----&gt; 7 print(result.group(1))</span><br><span class="line"></span><br><span class="line">AttributeError: &#39;NoneType&#39; object has no attribute &#39;group&#39;</span><br></pre></td></tr></table></figure>
<p>运行直接报错，也就是说正则表达式没有匹配到这个字符串，返回结果为 <code>None</code>，而我们又调用了 <code>group</code> 方法导致 <code>AttributeError</code>。</p>
<p>为什么加了一个换行符，就匹配不到了呢？</p>
<p>这是因为我们匹配的是除换行符之外的任意字符，当遇到换行符时，<code>.*?</code> 就不能匹配了，导致匹配失败。</p>
<p>这里只需加一个修饰符 <code>re.S</code>，即可修正这个错误：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result = re.match(<span class="string">'^He.*?(\d+).*?Demo$'</span>, content, re.S)</span><br></pre></td></tr></table></figure>
<p><strong>这个修饰符的作用是匹配包括换行符在内的所有字符</strong>。此时运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1234567</span><br></pre></td></tr></table></figure>
<p>这个 re.S 在网页匹配中经常用到。因为 <code>HTML</code> 节点经常会有换行，加上它，就可以匹配节点与节点之间的换行了。</p>
<p>另外，还有一些修饰符，在必要的情况下也可以使用，如表所示：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>修饰符</th>
<th>描　　述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>re.I</code></td>
<td>使匹配对大小写不敏感</td>
</tr>
<tr>
<td><code>re.L</code></td>
<td>做本地化识别（locale-aware）匹配</td>
</tr>
<tr>
<td><code>re.M</code></td>
<td>多行匹配，影响 ^ 和 $</td>
</tr>
<tr>
<td><code>re.S</code></td>
<td>使匹配包括换行在内的所有字符</td>
</tr>
<tr>
<td><code>re.U</code></td>
<td>根据 Unicode 字符集解析字符。这个标志影响 <code>\w</code>、<code>\W</code>、<code>\b</code> 和 <code>\B</code></td>
</tr>
<tr>
<td><code>re.X</code></td>
<td>该标志通过给予你更灵活的格式以便你将正则表达式写得更易于理解</td>
</tr>
</tbody>
</table>
</div>
<p>在网页匹配中，较为常用的修饰符有 <code>re.S</code> 和 <code>re.I</code>。</p>
<h1 id="实例结束"><a href="#实例结束" class="headerlink" title="实例结束"></a>实例结束</h1><p>这里有一段待匹配的<code>HTML</code>文本，接下来我们写几个正则表达式实例来实现相应信息的提取：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">html = '''<span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"songs-list"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h2</span> <span class="attr">class</span>=<span class="string">"title"</span>&gt;</span>经典老歌<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"introduction"</span>&gt;</span></span><br><span class="line">经典老歌列表</span><br><span class="line"><span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">ul</span> <span class="attr">id</span>=<span class="string">"list"</span> <span class="attr">class</span>=<span class="string">"list-group"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">data-view</span>=<span class="string">"2"</span>&gt;</span>一路上有你<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">data-view</span>=<span class="string">"7"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"/2.mp3"</span> <span class="attr">singer</span>=<span class="string">"任贤齐"</span>&gt;</span>沧海一声笑<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">data-view</span>=<span class="string">"4"</span> <span class="attr">class</span>=<span class="string">"active"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"/3.mp3"</span> <span class="attr">singer</span>=<span class="string">"齐秦"</span>&gt;</span>往事随风<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">data-view</span>=<span class="string">"6"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"/4.mp3"</span> <span class="attr">singer</span>=<span class="string">"beyond"</span>&gt;</span>光辉岁月<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">data-view</span>=<span class="string">"5"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"/5.mp3"</span> <span class="attr">singer</span>=<span class="string">"陈慧琳"</span>&gt;</span>记事本<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">data-view</span>=<span class="string">"5"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"/6.mp3"</span> <span class="attr">singer</span>=<span class="string">"邓丽君"</span>&gt;</span>但愿人长久<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span>'''</span><br></pre></td></tr></table></figure>
<p>可以观察到，<code>ul</code> 节点里有许多 <code>li</code> 节点，其中 <code>li</code> 节点中有的包含 <code>a</code> 节点，有的不包含 <code>a</code> 节点，<code>a</code> 节点还有一些相应的属性 —— 超链接和歌手名。</p>
<h2 id="search"><a href="#search" class="headerlink" title="search"></a><code>search</code></h2><p>首先，我们尝试提取 <code>class</code>为 <code>active</code> 的 <code>li</code> 节点内部超链接包含的歌手名和歌名，此时需要提取第三个 <code>li</code>节点下 <code>a</code> 节点的 <code>singer</code> 属性和文本。</p>
<p>此时，正则表达式可以用 <code>li</code> 开头，然后寻找一个标志符 <code>active</code>，中间的部分可以用 <code>.*?</code> 来匹配。</p>
<p>接下来，要提取 <code>singer</code> 这个属性值，所以还需要写入 <code>singer=&quot;(.*?)&quot;</code>，这里需要提取的部分用小括号括起来，以便用 <code>group</code> 方法提取出来，它的两侧边界是双引号。</p>
<p>然后还需要匹配 <code>a</code> 节点的文本，其中它的左边界是 <code>&gt;</code>，右边界是 <code>&lt;/a&gt;</code>。目标内容依然用 <code>(.*?)</code> 来匹配，所以最后的正则表达式就变成了：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;li.*?active.*?singer&#x3D;&quot;(.*?)&quot;&gt;(.*?)&lt;&#x2F;a&gt;</span><br></pre></td></tr></table></figure>
<p>然后再调用 <code>search</code> 方法，它会搜索整个 <code>HTML</code>文本，找到符合正则表达式的第一个内容返回。</p>
<p>另外，由于代码有换行，所以这里第三个参数需要传入 <code>re.S</code>。整个匹配代码如下：</p>
<p>复制代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result = re.search(<span class="string">'&lt;li.*?active.*?singer="(.*?)"&gt;(.*?)&lt;/a&gt;'</span>, html, re.S) </span><br><span class="line"><span class="keyword">if</span> result:</span><br><span class="line">    print(result.group(<span class="number">1</span>), result.group(<span class="number">2</span>))</span><br></pre></td></tr></table></figure>
<p>由于需要获取的歌手和歌名都已经用小括号包围，所以可以用 <code>group</code> 方法获取。</p>
<p>运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">齐秦 往事随风</span><br></pre></td></tr></table></figure>
<p>可以看到，这正是 <code>class</code> 为 <code>active</code> 的 <code>li</code> 节点内部的超链接包含的歌手名和歌名。</p>
<p>如果正则表达式不加 <code>active</code>（也就是匹配不带 <code>class</code> 为 <code>active</code> 的节点内容），那会怎样呢？我们将正则表达式中的 <code>active</code> 去掉。</p>
<p>代码改写如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result = re.search(<span class="string">'&lt;li.*?singer="(.*?)"&gt;(.*?)&lt;/a&gt;'</span>, html, re.S)</span><br><span class="line"><span class="keyword">if</span> result:</span><br><span class="line">    print(result.group(<span class="number">1</span>), result.group(<span class="number">2</span>))</span><br></pre></td></tr></table></figure>
<p>由于 <code>search</code> 方法会返回第一个符合条件的匹配目标，这里结果就变了：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">任贤齐 沧海一声笑</span><br></pre></td></tr></table></figure>
<p>把 <code>active</code> 标签去掉后，从字符串开头开始搜索，此时符合条件的节点就变成了第二个 <code>li</code> 节点，后面的不再匹配，所以运行结果变成第二个 <code>li</code> 节点中的内容。</p>
<p>注意，在上面的两次匹配中，<code>search</code> 方法的第三个参数都加了 <code>re.S</code>，这使得<code>.*?</code>可以匹配换行，所以含有换行的 <code>li</code> 节点被匹配到了。如果我们将其去掉，结果会是什么？</p>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result = re.search(<span class="string">'&lt;li.*?singer="(.*?)"&gt;(.*?)&lt;/a&gt;'</span>, html)</span><br><span class="line"><span class="keyword">if</span> result:</span><br><span class="line">    print(result.group(<span class="number">1</span>), result.group(<span class="number">2</span>))</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<p>复制代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">beyond 光辉岁月</span><br></pre></td></tr></table></figure>
<p>可以看到，结果变成了第四个<code>li</code>节点的内容。这是因为第二个和第三个<code>li</code>节点都包含了换行符，去掉 <code>re.S</code> 之后，<code>.*?</code> 已经不能匹配换行符，所以正则表达式不会匹配到第二个和第三个<code>li</code>节点，而第四个<code>li</code>节点中不包含换行符，所以成功匹配。</p>
<p>由于绝大部分的<code>HTML</code>文本都包含了换行符，所以尽量都需要加上 <code>re.S</code> 修饰符，以免出现匹配不到的问题。</p>
<h2 id="findall"><a href="#findall" class="headerlink" title="findall"></a><code>findall</code></h2><p><code>search</code> 方法可以返回匹配正则表达式的第一个内容，但是如果想要获取匹配正则表达式的所有内容，那该怎么办呢？这时就要借助 <code>findall</code> 方法了。</p>
<p>该方法会搜索整个字符串，然后返回匹配正则表达式的所有内容。</p>
<p>还是上面的 <code>HTML</code> 文本，如果想获取所有 <code>a</code> 节点的超链接、歌手和歌名，就可以将 <code>search</code> 方法换成 <code>findall</code> 方法。如果有返回结果的话，就是列表类型，所以需要遍历一下来依次获取每组内容。</p>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">results = re.findall(<span class="string">'&lt;li.*?href="(.*?)".*?singer="(.*?)"&gt;(.*?)&lt;/a&gt;'</span>, html, re.S)</span><br><span class="line">print(results)</span><br><span class="line">print(type(results))</span><br><span class="line"><span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">    print(result)</span><br><span class="line">    print(result[<span class="number">0</span>], result[<span class="number">1</span>], result[<span class="number">2</span>])</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[(&#39;&#x2F;2.mp3&#39;, &#39; 任贤齐 &#39;, &#39; 沧海一声笑 &#39;), (&#39;&#x2F;3.mp3&#39;, &#39; 齐秦 &#39;, &#39; 往事随风 &#39;), (&#39;&#x2F;4.mp3&#39;, &#39;beyond&#39;, &#39; 光辉岁月 &#39;), (&#39;&#x2F;5.mp3&#39;, &#39; 陈慧琳 &#39;, &#39; 记事本 &#39;), (&#39;&#x2F;6.mp3&#39;, &#39; 邓丽君 &#39;, &#39; 但愿人长久 &#39;)]</span><br><span class="line">&lt;class &#39;list&#39;&gt;</span><br><span class="line">(&#39;&#x2F;2.mp3&#39;, &#39; 任贤齐 &#39;, &#39; 沧海一声笑 &#39;)</span><br><span class="line">&#x2F;2.mp3 任贤齐 沧海一声笑</span><br><span class="line">(&#39;&#x2F;3.mp3&#39;, &#39; 齐秦 &#39;, &#39; 往事随风 &#39;)</span><br><span class="line">&#x2F;3.mp3 齐秦 往事随风</span><br><span class="line">(&#39;&#x2F;4.mp3&#39;, &#39;beyond&#39;, &#39; 光辉岁月 &#39;)</span><br><span class="line">&#x2F;4.mp3 beyond 光辉岁月</span><br><span class="line">(&#39;&#x2F;5.mp3&#39;, &#39; 陈慧琳 &#39;, &#39; 记事本 &#39;)</span><br><span class="line">&#x2F;5.mp3 陈慧琳 记事本</span><br><span class="line">(&#39;&#x2F;6.mp3&#39;, &#39; 邓丽君 &#39;, &#39; 但愿人长久 &#39;)</span><br><span class="line">&#x2F;6.mp3 邓丽君 但愿人长久</span><br></pre></td></tr></table></figure>
<p>可以看到，返回的列表中的每个元素都是元组类型，我们用对应的索引依次取出即可。</p>
<p>如果只是获取第一个内容，可以用 <code>search</code> 方法。当需要提取多个内容时，可以用 <code>findall</code>方法。</p>
]]></content>
      <categories>
        <category>Spider</category>
      </categories>
  </entry>
  <entry>
    <title>Python爬虫（七）requests库基本使用</title>
    <url>/posts/c6945e46.html</url>
    <content><![CDATA[<p>从本节开始，我们正式步入Python 爬虫的大门。</p>
<p>学习爬虫，最基础的便是模拟浏览器向服务器发出请求，那么我们需要从什么地方做起呢？请求需要我们自己来构造吗？需要关心请求这个数据结构的实现吗？需要了解 HTTP、TCP、IP 层的网络传输通信吗？需要知道服务器的响应和应答原理吗？</p>
<p>可能你无从下手，不过不用担心，Python 的强大之处就是提供了功能齐全的类库来帮助我们完成这些请求。利用<code>Python</code>现有的库我们可以非常方便地实现网络请求的模拟，常见的库有 <code>urllib</code>、<code>requests</code> 等。</p>
<p>拿<code>requests</code>这个库来说，有了它，我们只需要关心请求的链接是什么，需要传的参数是什么，以及如何设置可选的参数就好了，不用深入到底层去了解它到底是怎样传输和通信的。有了它，两行代码就可以完成一个请求和响应的处理过程，非常方便地得到网页内容。</p>
<p>接下来，就让我们用<code>Python</code>的<code>requests</code>库开始我们的爬虫之旅吧。</p>
<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>首先，<code>requests</code>库是<code>Python</code>的一个第三方库，不是自带的。所以我们需要额外安装。</p>
<p>在这之前需要你先安装好<code>Python3</code> 环境，如<code>Python</code>3.6 版本，如若没有安装可以参考：<a href="https://cuiqingcai.com/5059.html。" target="_blank" rel="noopener">https://cuiqingcai.com/5059.html。</a></p>
<p>安装好<code>Python3</code> 之后，我们使用 pip3 即可轻松地安装好<code>requests</code>库：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install requests</span><br></pre></td></tr></table></figure>
<p>更详细的安装方式可以参考：<a href="https://cuiqingcai.com/5132.html。" target="_blank" rel="noopener">https://cuiqingcai.com/5132.html。</a></p>
<p>安装完成之后，我们就可以开始我们的网络爬虫之旅了。</p>
<h1 id="实例引入"><a href="#实例引入" class="headerlink" title="实例引入"></a>实例引入</h1><p>用<code>Python</code>写爬虫的第一步就是模拟发起一个请求，把网页的源代码获取下来。</p>
<p>当我们在浏览器中输入一个<code>URL</code>并回车，实际上就是让浏览器帮我们发起一个<code>GET</code>类型的<code>HTTP</code>请求，浏览器得到源代码后，把它渲染出来就可以看到网页内容了。</p>
<p>那如果我们想用<code>requests</code>来获取源代码，应该怎么办呢？很简单，<code>requests</code>这个库提供了一个<code>GET</code>方法，我们调用这个方法，并传入对应的<code>URL</code>就能得到网页的源代码。</p>
<p>比如这里有一个示例网站：<a href="https://static1.scrape.center/，其内容如下：" target="_blank" rel="noopener">https://static1.scrape.center/，其内容如下：</a></p>
<p><img src="/posts/Pic/Spider/scrape.png" style="zoom:50%;"></p>
<p>这个网站展示了一些电影数据，如果我们想要把这个网页里面的数据爬下来，比如获取各个电影的名称、上映时间等信息，然后把它存下来的话，该怎么做呢？</p>
<p>第一步当然就是获取它的网页源代码了。</p>
<p>我们可以用<code>requests</code>这个库轻松地完成这个过程，代码的写法是这样的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">r = requests.get(<span class="string">'https://static1.scrape.center/'</span>)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">"en"</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"utf-8"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">meta</span> <span class="attr">http-equiv</span>=<span class="string">"X-UA-Compatible"</span> <span class="attr">content</span>=<span class="string">"IE=edge"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">meta</span> <span class="attr">name</span>=<span class="string">"viewport"</span> <span class="attr">content</span>=<span class="string">"width=device-width,initial-scale=1"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">"icon"</span> <span class="attr">href</span>=<span class="string">"/static/img/favicon.ico"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">title</span>&gt;</span>Scrape | Movie<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">link</span> <span class="attr">href</span>=<span class="string">"/static/css/app.css"</span> <span class="attr">type</span>=<span class="string">"text/css"</span> <span class="attr">rel</span>=<span class="string">"stylesheet"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">link</span> <span class="attr">href</span>=<span class="string">"/static/css/index.css"</span> <span class="attr">type</span>=<span class="string">"text/css"</span> <span class="attr">rel</span>=<span class="string">"stylesheet"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"app"</span>&gt;</span></span><br><span class="line">...</span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">data-v-7f856186</span>=<span class="string">""</span> <span class="attr">id</span>=<span class="string">"index"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span> <span class="attr">data-v-7f856186</span>=<span class="string">""</span> <span class="attr">class</span>=<span class="string">"el-row"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">data-v-7f856186</span>=<span class="string">""</span> <span class="attr">class</span>=<span class="string">"el-col el-col-18 el-col-offset-3"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">div</span> <span class="attr">data-v-7f856186</span>=<span class="string">""</span> <span class="attr">class</span>=<span class="string">"el-card item m-t is-hover-shadow"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"el-card__body"</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">div</span> <span class="attr">data-v-7f856186</span>=<span class="string">""</span> <span class="attr">class</span>=<span class="string">"el-row"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">data-v-7f856186</span>=<span class="string">""</span> <span class="attr">class</span>=<span class="string">"el-col el-col-24 el-col-xs-8 el-col-sm-6 el-col-md-4"</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;<span class="name">a</span> <span class="attr">data-v-7f856186</span>=<span class="string">""</span></span></span><br><span class="line"><span class="tag">                 <span class="attr">href</span>=<span class="string">"/detail/1"</span></span></span><br><span class="line"><span class="tag">                 <span class="attr">class</span>=<span class="string">""</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">img</span></span></span><br><span class="line"><span class="tag">                    <span class="attr">data-v-7f856186</span>=<span class="string">""</span> <span class="attr">src</span>=<span class="string">"https://p0.meituan.net/movie/283292171619cdfd5b240c8fd093f1eb255670.jpg@464w_644h_1e_1c"</span></span></span><br><span class="line"><span class="tag">                    <span class="attr">class</span>=<span class="string">"cover"</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">data-v-7f856186</span>=<span class="string">""</span> <span class="attr">class</span>=<span class="string">"p-h el-col el-col-24 el-col-xs-9 el-col-sm-13 el-col-md-16"</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;<span class="name">a</span> <span class="attr">data-v-7f856186</span>=<span class="string">""</span> <span class="attr">href</span>=<span class="string">"/detail/1"</span> <span class="attr">class</span>=<span class="string">""</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">h2</span> <span class="attr">data-v-7f856186</span>=<span class="string">""</span> <span class="attr">class</span>=<span class="string">"m-b-sm"</span>&gt;</span>肖申克的救赎 - The Shawshank Redemption<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;<span class="name">div</span> <span class="attr">data-v-7f856186</span>=<span class="string">""</span> <span class="attr">class</span>=<span class="string">"categories"</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">button</span> <span class="attr">data-v-7f856186</span>=<span class="string">""</span> <span class="attr">type</span>=<span class="string">"button"</span></span></span><br><span class="line"><span class="tag">                        <span class="attr">class</span>=<span class="string">"el-button category el-button--primary el-button--mini"</span>&gt;</span></span><br><span class="line">                  <span class="tag">&lt;<span class="name">span</span>&gt;</span>剧情<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">button</span> <span class="attr">data-v-7f856186</span>=<span class="string">""</span> <span class="attr">type</span>=<span class="string">"button"</span></span></span><br><span class="line"><span class="tag">                        <span class="attr">class</span>=<span class="string">"el-button category el-button--primary el-button--mini"</span>&gt;</span></span><br><span class="line">                  <span class="tag">&lt;<span class="name">span</span>&gt;</span>犯罪<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;<span class="name">div</span> <span class="attr">data-v-7f856186</span>=<span class="string">""</span> <span class="attr">class</span>=<span class="string">"m-v-sm info"</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">span</span> <span class="attr">data-v-7f856186</span>=<span class="string">""</span>&gt;</span>美国<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">span</span> <span class="attr">data-v-7f856186</span>=<span class="string">""</span>&gt;</span> / <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">span</span> <span class="attr">data-v-7f856186</span>=<span class="string">""</span>&gt;</span>142 分钟<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;<span class="name">div</span> <span class="attr">data-v-7f856186</span>=<span class="string">""</span> <span class="attr">class</span>=<span class="string">"m-v-sm info"</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">span</span> <span class="attr">data-v-7f856186</span>=<span class="string">""</span>&gt;</span>1994-09-10 上映<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">  ...</span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>由于网页内容比较多，这里省略了大部分内容。</p>
<p>不过看运行结果，我们已经成功获取网页的<code>HTML</code>源代码，里面包含了电影的标题、类型、上映时间，等等。把网页源代码获取下来之后，下一步我们把想要的数据提取出来，数据的爬取就完成了。</p>
<p>这个实例的目的是让你体会一下<code>requests</code>这个库能帮我们实现什么功能。我们仅仅用<code>requests</code>的<code>GET</code>方法就成功发起了一个<code>GET</code>请求，把网页源代码获取下来了，是不是很方便呢？</p>
<h1 id="请求"><a href="#请求" class="headerlink" title="请求"></a>请求</h1><p><code>HTTP</code> 中最常见的请求之一就是<code>GET</code>请求，下面我们来详细了解利用<code>requests</code>库构建<code>GET</code>请求的方法。</p>
<h2 id="GET-请求"><a href="#GET-请求" class="headerlink" title="GET 请求"></a><code>GET</code> 请求</h2><p>我们换一个示例网站，其<code>URL</code>为 <a href="http://httpbin.org/get，如果客户端发起的是`GET`请求的话，该网站会判断并返回相应的请求信息，包括" target="_blank" rel="noopener">http://httpbin.org/get，如果客户端发起的是`GET`请求的话，该网站会判断并返回相应的请求信息，包括</a> <code>Headers</code>、<code>IP</code> 等。</p>
<p>我们还是用相同的方法来发起一个<code>GET</code>请求，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">'http://httpbin.org/get'</span>)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">&#123;"args": &#123;&#125;,</span><br><span class="line">  "headers": &#123;</span><br><span class="line">    "Accept": "*/*",</span><br><span class="line">    "Accept-Encoding": "gzip, deflate",</span><br><span class="line">    "Host": "httpbin.org",</span><br><span class="line">    "User-Agent": "python-requests/2.10.0"</span><br><span class="line">  &#125;,</span><br><span class="line">  "origin": "122.4.215.33",</span><br><span class="line">  "url": "http://httpbin.org/get"</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以发现，我们成功发起了<code>GET</code>请求，也通过这个网站的返回结果得到了请求所携带的信息，包括 <code>Headers</code>、<code>URL</code>、<code>IP</code>，等等。</p>
<p>对于<code>GET</code>请求，我们知道<code>URL</code>后面是可以跟上一些参数的，如果我们现在想添加两个参数，其中 <code>name</code> 是 <code>germey</code>，<code>age</code> 是 25，<code>URL</code>就可以写成如下内容：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">http://httpbin.org/get?name=germey&amp;age=25</span><br></pre></td></tr></table></figure>
<p>要构造这个请求链接，是不是要直接写成这样呢？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">r = requests.get(<span class="string">'http://httpbin.org/get?name=germey&amp;age=25'</span>)</span><br></pre></td></tr></table></figure>
<p>这样也可以，但如果这些参数还需要我们手动拼接，未免有点不人性化。</p>
<p>一般情况下，这种信息我们利用 <code>params</code> 这个参数就可以直接传递了，示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">'name'</span>: <span class="string">'germey'</span>,</span><br><span class="line">    <span class="string">'age'</span>: <span class="number">25</span></span><br><span class="line">&#125;</span><br><span class="line">r = requests.get(<span class="string">'http://httpbin.org/get'</span>, params=data)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">"args"</span>: &#123;</span><br><span class="line">    <span class="string">"age"</span>: <span class="string">"25"</span>,</span><br><span class="line">    <span class="string">"name"</span>: <span class="string">"germey"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"headers"</span>: &#123;</span><br><span class="line">    <span class="string">"Accept"</span>: <span class="string">"*/*"</span>,</span><br><span class="line">    <span class="string">"Accept-Encoding"</span>: <span class="string">"gzip, deflate"</span>,</span><br><span class="line">    <span class="string">"Host"</span>: <span class="string">"httpbin.org"</span>,</span><br><span class="line">    <span class="string">"User-Agent"</span>: <span class="string">"python-requests/2.10.0"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"origin"</span>: <span class="string">"122.4.215.33"</span>,</span><br><span class="line">  <span class="string">"url"</span>: <span class="string">"http://httpbin.org/get?age=22&amp;name=germey"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在这里我们把<code>URL</code>参数通过字典的形式传给<code>GET</code>方法的<code>params</code>参数，通过返回信息我们可以判断，请求的链接自动被构造成了：<a href="http://httpbin.org/get?age=22&amp;name=germey，这样我们就不用再去自己构造`URL`了，非常方便。" target="_blank" rel="noopener">http://httpbin.org/get?age=22&amp;name=germey，这样我们就不用再去自己构造`URL`了，非常方便。</a></p>
<p>另外，网页的返回类型实际上是<code>str</code> 类型，但是它很特殊，是<code>json</code> 格式的。所以，如果想直接解析返回结果，得到一个<code>json</code> 格式的数据的话，可以直接调用<code>json</code> 方法。</p>
<p>示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">'http://httpbin.org/get'</span>)</span><br><span class="line">print(type(r.text))</span><br><span class="line">print(r.json())</span><br><span class="line">print(type(r.json()))</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">class'str'</span>&gt;</span></span><br><span class="line">&#123;'headers': &#123;'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Host': 'httpbin.org', 'User-Agent': 'python-requests/2.10.0'&#125;, 'url': 'http://httpbin.org/get', 'args': &#123;&#125;, 'origin': '182.33.248.131'&#125;</span><br><span class="line"><span class="tag">&lt;<span class="name">class</span> '<span class="attr">dict</span>'&gt;</span></span><br></pre></td></tr></table></figure>
<p>可以发现，调用 <code>json</code> 方法，就可以将返回结果是<code>json</code> 格式的字符串转化为字典。</p>
<p>但需要注意的是，如果返回结果不是<code>json</code> 格式，便会出现解析错误，抛出 <code>json.decoder.JSONDecodeError</code> 异常。</p>
<h3 id="1-抓取网页"><a href="#1-抓取网页" class="headerlink" title="1. 抓取网页"></a>1. 抓取网页</h3><p>上面的请求链接返回的是<code>json</code> 形式的字符串，那么如果请求普通的网页，则肯定能获得相应的内容了。下面以最初的实例页面为例，我们再加上一点提取信息的逻辑，将代码完善成如下的样子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">'https://static1.scrape.center/'</span>)</span><br><span class="line">pattern = re.compile(<span class="string">'&lt;h2.*?&gt;(.*?)&lt;/h2&gt;'</span>, re.S)</span><br><span class="line">titles = re.findall(pattern, r.text)</span><br><span class="line">print(titles)</span><br></pre></td></tr></table></figure>
<p>在这个例子中我们用到了最基础的正则表达式来匹配出所有的标题。关于正则表达式的相关内容，我们会在后面详细介绍，这里作为实例来配合讲解。</p>
<p>运行结果如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">['肖申克的救赎 - The Shawshank Redemption', '霸王别姬 - Farewell My Concubine', '泰坦尼克号 - Titanic', '罗马假日 - Roman Holiday', '这个杀手不太冷 - Léon', '魂断蓝桥 - Waterloo Bridge', '唐伯虎点秋香 - Flirting Scholar', '喜剧之王 - The King of Comedy', '楚门的世界 - The Truman Show', '活着 - To Live']</span><br></pre></td></tr></table></figure>
<p>我们发现，这里成功提取出了所有的电影标题。一个最基本的抓取和提取流程就完成了。</p>
<h3 id="2-抓取二进制数据"><a href="#2-抓取二进制数据" class="headerlink" title="2. 抓取二进制数据"></a>2. 抓取二进制数据</h3><p>在上面的例子中，我们抓取的是网站的一个页面，实际上它返回的是一个<code>HTML</code>文档。如果想抓取图片、音频、视频等文件，应该怎么办呢？</p>
<p>图片、音频、视频这些文件本质上都是由二进制码组成的，由于有特定的保存格式和对应的解析方式，我们才可以看到这些形形色色的多媒体。所以，想要抓取它们，就要拿到它们的二进制数据。</p>
<p>下面以<code>GitHub</code>的站点图标为例来看一下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">'https://github.com/favicon.ico'</span>)</span><br><span class="line">print(r.text)</span><br><span class="line">print(r.content)</span><br></pre></td></tr></table></figure>
<p>这里抓取的内容是站点图标，也就是在浏览器每一个标签上显示的小图标，如图所示：</p>
<p><img src="/posts/Pic/Spider/github.png" alt></p>
<p>这里打印了 <code>Response</code> 对象的两个属性，一个是 <code>text</code>，另一个是 <code>content</code>。</p>
<p>运行结果如图所示，其中前两行是 <code>r.text</code>的结果，最后一行是 <code>r.content</code> 的结果。</p>
<p><img src="/posts/Pic/Spider/ico.png" alt="image-20210503214522111"></p>
<p>可以注意到，前者出现了乱码，后者结果前带有一个 <code>b</code>，这代表是 <code>bytes</code> 类型的数据。</p>
<p>由于图片是二进制数据，所以前者在打印时转化为<code>str</code> 类型，也就是图片直接转化为字符串，这当然会出现乱码。</p>
<p>上面返回的结果我们并不能看懂，它实际上是图片的二进制数据，没关系，我们将刚才提取到的信息保存下来就好了，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">'https://github.com/favicon.ico'</span>)</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'favicon.ico'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(r.content)</span><br></pre></td></tr></table></figure>
<p>这里用了 <code>open</code> 方法，它的第一个参数是文件名称，第二个参数代表以二进制的形式打开，可以向文件里写入二进制数据。</p>
<p>运行结束之后，可以发现在文件夹中出现了名为 <code>favicon.ico</code>的图标。这样，我们就把二进制数据成功保存成一张图片了，这个小图标就被我们成功爬取下来了。同样地，音频和视频文件我们也可以用这种方法获取。</p>
<h3 id="3-添加-headers"><a href="#3-添加-headers" class="headerlink" title="3. 添加 headers"></a>3. 添加 <code>headers</code></h3><p>我们知道，在发起一个<code>HTTP</code>请求的时候，会有一个请求头 <code>Request Headers</code>，那么这个怎么来设置呢？</p>
<p>很简单，我们使用 <code>headers</code> 参数就可以完成了。</p>
<p>在刚才的实例中，实际上我们是没有设置 <code>Request Headers</code> 信息的，如果不设置，某些网站会发现这不是一个正常的浏览器发起的请求，网站可能会返回异常的结果，导致网页抓取失败。</p>
<p>要添加 <code>Headers</code> 信息，比如我们这里想添加一个 <code>User-Agent</code> 字段，我们可以这么来写：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36'</span></span><br><span class="line">&#125;</span><br><span class="line">r = requests.get(<span class="string">'https://static1.scrape.center/'</span>, headers=headers)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>
<p>当然，我们可以在 <code>headers</code> 这个参数中任意添加其他的字段信息。</p>
<h2 id="POST-请求"><a href="#POST-请求" class="headerlink" title="POST 请求"></a><code>POST</code> 请求</h2><p>前面我们了解了最基本的<code>GET</code>请求，另外一种比较常见的请求方式是 POST。使用<code>requests</code>实现<code>POST</code> 请求同样非常简单，示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">data = &#123;<span class="string">'name'</span>: <span class="string">'germey'</span>, <span class="string">'age'</span>: <span class="string">'25'</span>&#125;</span><br><span class="line">r = requests.post(<span class="string">"http://httpbin.org/post"</span>, data=data)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>
<p>这里还是请求 <a href="http://httpbin.org/post，该网站可以判断如果请求是`POST`" target="_blank" rel="noopener">http://httpbin.org/post，该网站可以判断如果请求是`POST`</a> 方式，就把相关请求信息返回。</p>
<p>运行结果如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">"args"</span>: &#123;&#125;, </span><br><span class="line">  <span class="string">"data"</span>: <span class="string">""</span>, </span><br><span class="line">  <span class="string">"files"</span>: &#123;&#125;, </span><br><span class="line">  <span class="string">"form"</span>: &#123;</span><br><span class="line">    <span class="string">"age"</span>: <span class="string">"25"</span>, </span><br><span class="line">    <span class="string">"name"</span>: <span class="string">"germey"</span></span><br><span class="line">  &#125;, </span><br><span class="line">  <span class="string">"headers"</span>: &#123;</span><br><span class="line">    <span class="string">"Accept"</span>: <span class="string">"*/*"</span>, </span><br><span class="line">    <span class="string">"Accept-Encoding"</span>: <span class="string">"gzip, deflate"</span>, </span><br><span class="line">    <span class="string">"Content-Length"</span>: <span class="string">"18"</span>, </span><br><span class="line">    <span class="string">"Content-Type"</span>: <span class="string">"application/x-www-form-urlencoded"</span>, </span><br><span class="line">    <span class="string">"Host"</span>: <span class="string">"httpbin.org"</span>, </span><br><span class="line">    <span class="string">"User-Agent"</span>: <span class="string">"python-requests/2.22.0"</span>, </span><br><span class="line">    <span class="string">"X-Amzn-Trace-Id"</span>: <span class="string">"Root=1-5e5bdc26-b40d7e9862e3715f689cb5e6"</span></span><br><span class="line">  &#125;, </span><br><span class="line">  <span class="string">"json"</span>: null, </span><br><span class="line">  <span class="string">"origin"</span>: <span class="string">"167.220.232.237"</span>, </span><br><span class="line">  <span class="string">"url"</span>: <span class="string">"http://httpbin.org/post"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以发现，我们成功获得了返回结果，其中 <code>form</code> 部分就是提交的数据，这就证明<code>POST</code> 请求成功发送了。</p>
<h2 id="响应"><a href="#响应" class="headerlink" title="响应"></a>响应</h2><p>发送请求后，得到的自然就是响应，即 <code>Response</code>。</p>
<p>在上面的实例中，我们使用<code>text</code> 和<code>content</code> 获取了响应的内容。此外，还有很多属性和方法可以用来获取其他信息，比如状态码、响应头、<code>Cookies</code> 等。示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">r = requests.get(<span class="string">'https://static1.scrape.center/'</span>)</span><br><span class="line">print(type(r.status_code), r.status_code)</span><br><span class="line">print(type(r.headers), r.headers)</span><br><span class="line">print(type(r.cookies), r.cookies)</span><br><span class="line">print(type(r.url), r.url)</span><br><span class="line">print(type(r.history), r.history)</span><br></pre></td></tr></table></figure>
<p>这里分别打印输出<code>status_code</code> 属性得到状态码，输出<code>headers</code> 属性得到响应头，输出<code>cookies</code> 属性得到 <code>Cookies</code>，输出<code>URL</code>属性得到 <code>URL</code>，输出<code>history</code> 属性得到请求历史。</p>
<p>运行结果如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">class</span> '<span class="attr">int</span>'&gt;</span> 200</span><br><span class="line"><span class="tag">&lt;<span class="name">class</span> '<span class="attr">requests.structures.CaseInsensitiveDict</span>'&gt;</span> &#123;'Server': 'nginx/1.17.8', 'Date': 'Sun, 01 Mar 2020 13:31:54 GMT', 'Content-Type': 'text/html; charset=utf-8', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Vary': 'Accept-Encoding', 'X-Frame-Options': 'SAMEORIGIN', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains', 'Content-Encoding': 'gzip'&#125;</span><br><span class="line"><span class="tag">&lt;<span class="name">class</span> '<span class="attr">requests.cookies.RequestsCookieJar</span>'&gt;</span> <span class="tag">&lt;<span class="name">RequestsCookieJar[]</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">class</span> '<span class="attr">str</span>'&gt;</span> https://static1.scrape.center/</span><br><span class="line"><span class="tag">&lt;<span class="name">class</span> '<span class="attr">list</span>'&gt;</span> []</span><br></pre></td></tr></table></figure>
<p>可以看到，<code>headers</code> 和<code>cookies</code> 这两个属性得到的结果分别是 <code>CaseInsensitiveDict</code> 和 <code>RequestsCookieJar</code>类型。</p>
<p>前面的学习我们知道，状态码是用来表示响应状态的，比如返回 200 代表我们得到的响应是没问题的，上面的例子正好输出的结果也是 200，所以我们可以通过判断<code>Response</code> 的状态码来确认是否爬取成功。</p>
<p><code>requests</code> 还提供了一个内置的状态码查询对象 <code>requests.codes</code>，用法示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">r = requests.get(<span class="string">'https://static1.scrape.center/'</span>)</span><br><span class="line">exit() <span class="keyword">if</span> <span class="keyword">not</span> r.status_code == requests.codes.ok <span class="keyword">else</span> print(<span class="string">'Request Successfully'</span>)</span><br></pre></td></tr></table></figure>
<p>这里通过比较返回码和内置的成功的返回码，来保证请求得到了正常响应，输出成功请求的消息，否则程序终止，这里我们用 <code>requests.codes.ok</code> 得到的是成功的状态码 200。</p>
<p>这样的话，我们就不用再在程序里面写状态码对应的数字了，用字符串表示状态码会显得更加直观。当然，肯定不能只有 <code>ok</code> 这个条件码。下面列出了返回码和相应的查询条件：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 信息性状态码</span></span><br><span class="line"></span><br><span class="line"><span class="number">100</span>: (<span class="string">'continue'</span>,),</span><br><span class="line"><span class="number">101</span>: (<span class="string">'switching_protocols'</span>,),</span><br><span class="line"><span class="number">102</span>: (<span class="string">'processing'</span>,),</span><br><span class="line"><span class="number">103</span>: (<span class="string">'checkpoint'</span>,),</span><br><span class="line"><span class="number">122</span>: (<span class="string">'uri_too_long'</span>, <span class="string">'request_uri_too_long'</span>),</span><br><span class="line"></span><br><span class="line"><span class="comment"># 成功状态码</span></span><br><span class="line"></span><br><span class="line"><span class="number">200</span>: (<span class="string">'ok'</span>, <span class="string">'okay'</span>, <span class="string">'all_ok'</span>, <span class="string">'all_okay'</span>, <span class="string">'all_good'</span>, <span class="string">'\\o/'</span>, <span class="string">'✓'</span>),</span><br><span class="line"><span class="number">201</span>: (<span class="string">'created'</span>,),</span><br><span class="line"><span class="number">202</span>: (<span class="string">'accepted'</span>,),</span><br><span class="line"><span class="number">203</span>: (<span class="string">'non_authoritative_info'</span>, <span class="string">'non_authoritative_information'</span>),</span><br><span class="line"><span class="number">204</span>: (<span class="string">'no_content'</span>,),</span><br><span class="line"><span class="number">205</span>: (<span class="string">'reset_content'</span>, <span class="string">'reset'</span>),</span><br><span class="line"><span class="number">206</span>: (<span class="string">'partial_content'</span>, <span class="string">'partial'</span>),</span><br><span class="line"><span class="number">207</span>: (<span class="string">'multi_status'</span>, <span class="string">'multiple_status'</span>, <span class="string">'multi_stati'</span>, <span class="string">'multiple_stati'</span>),</span><br><span class="line"><span class="number">208</span>: (<span class="string">'already_reported'</span>,),</span><br><span class="line"><span class="number">226</span>: (<span class="string">'im_used'</span>,),</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重定向状态码</span></span><br><span class="line"></span><br><span class="line"><span class="number">300</span>: (<span class="string">'multiple_choices'</span>,),</span><br><span class="line"><span class="number">301</span>: (<span class="string">'moved_permanently'</span>, <span class="string">'moved'</span>, <span class="string">'\\o-'</span>),</span><br><span class="line"><span class="number">302</span>: (<span class="string">'found'</span>,),</span><br><span class="line"><span class="number">303</span>: (<span class="string">'see_other'</span>, <span class="string">'other'</span>),</span><br><span class="line"><span class="number">304</span>: (<span class="string">'not_modified'</span>,),</span><br><span class="line"><span class="number">305</span>: (<span class="string">'use_proxy'</span>,),</span><br><span class="line"><span class="number">306</span>: (<span class="string">'switch_proxy'</span>,),</span><br><span class="line"><span class="number">307</span>: (<span class="string">'temporary_redirect'</span>, <span class="string">'temporary_moved'</span>, <span class="string">'temporary'</span>),</span><br><span class="line"><span class="number">308</span>: (<span class="string">'permanent_redirect'</span>,</span><br><span class="line">      <span class="string">'resume_incomplete'</span>, <span class="string">'resume'</span>,), <span class="comment"># These 2 to be removed in 3.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 客户端错误状态码</span></span><br><span class="line"></span><br><span class="line"><span class="number">400</span>: (<span class="string">'bad_request'</span>, <span class="string">'bad'</span>),</span><br><span class="line"><span class="number">401</span>: (<span class="string">'unauthorized'</span>,),</span><br><span class="line"><span class="number">402</span>: (<span class="string">'payment_required'</span>, <span class="string">'payment'</span>),</span><br><span class="line"><span class="number">403</span>: (<span class="string">'forbidden'</span>,),</span><br><span class="line"><span class="number">404</span>: (<span class="string">'not_found'</span>, <span class="string">'-o-'</span>),</span><br><span class="line"><span class="number">405</span>: (<span class="string">'method_not_allowed'</span>, <span class="string">'not_allowed'</span>),</span><br><span class="line"><span class="number">406</span>: (<span class="string">'not_acceptable'</span>,),</span><br><span class="line"><span class="number">407</span>: (<span class="string">'proxy_authentication_required'</span>, <span class="string">'proxy_auth'</span>, <span class="string">'proxy_authentication'</span>),</span><br><span class="line"><span class="number">408</span>: (<span class="string">'request_timeout'</span>, <span class="string">'timeout'</span>),</span><br><span class="line"><span class="number">409</span>: (<span class="string">'conflict'</span>,),</span><br><span class="line"><span class="number">410</span>: (<span class="string">'gone'</span>,),</span><br><span class="line"><span class="number">411</span>: (<span class="string">'length_required'</span>,),</span><br><span class="line"><span class="number">412</span>: (<span class="string">'precondition_failed'</span>, <span class="string">'precondition'</span>),</span><br><span class="line"><span class="number">413</span>: (<span class="string">'request_entity_too_large'</span>,),</span><br><span class="line"><span class="number">414</span>: (<span class="string">'request_uri_too_large'</span>,),</span><br><span class="line"><span class="number">415</span>: (<span class="string">'unsupported_media_type'</span>, <span class="string">'unsupported_media'</span>, <span class="string">'media_type'</span>),</span><br><span class="line"><span class="number">416</span>: (<span class="string">'requested_range_not_satisfiable'</span>, <span class="string">'requested_range'</span>, <span class="string">'range_not_satisfiable'</span>),</span><br><span class="line"><span class="number">417</span>: (<span class="string">'expectation_failed'</span>,),</span><br><span class="line"><span class="number">418</span>: (<span class="string">'im_a_teapot'</span>, <span class="string">'teapot'</span>, <span class="string">'i_am_a_teapot'</span>),</span><br><span class="line"><span class="number">421</span>: (<span class="string">'misdirected_request'</span>,),</span><br><span class="line"><span class="number">422</span>: (<span class="string">'unprocessable_entity'</span>, <span class="string">'unprocessable'</span>),</span><br><span class="line"><span class="number">423</span>: (<span class="string">'locked'</span>,),</span><br><span class="line"><span class="number">424</span>: (<span class="string">'failed_dependency'</span>, <span class="string">'dependency'</span>),</span><br><span class="line"><span class="number">425</span>: (<span class="string">'unordered_collection'</span>, <span class="string">'unordered'</span>),</span><br><span class="line"><span class="number">426</span>: (<span class="string">'upgrade_required'</span>, <span class="string">'upgrade'</span>),</span><br><span class="line"><span class="number">428</span>: (<span class="string">'precondition_required'</span>, <span class="string">'precondition'</span>),</span><br><span class="line"><span class="number">429</span>: (<span class="string">'too_many_requests'</span>, <span class="string">'too_many'</span>),</span><br><span class="line"><span class="number">431</span>: (<span class="string">'header_fields_too_large'</span>, <span class="string">'fields_too_large'</span>),</span><br><span class="line"><span class="number">444</span>: (<span class="string">'no_response'</span>, <span class="string">'none'</span>),</span><br><span class="line"><span class="number">449</span>: (<span class="string">'retry_with'</span>, <span class="string">'retry'</span>),</span><br><span class="line"><span class="number">450</span>: (<span class="string">'blocked_by_windows_parental_controls'</span>, <span class="string">'parental_controls'</span>),</span><br><span class="line"><span class="number">451</span>: (<span class="string">'unavailable_for_legal_reasons'</span>, <span class="string">'legal_reasons'</span>),</span><br><span class="line"><span class="number">499</span>: (<span class="string">'client_closed_request'</span>,),</span><br><span class="line"></span><br><span class="line"><span class="comment"># 服务端错误状态码</span></span><br><span class="line"></span><br><span class="line"><span class="number">500</span>: (<span class="string">'internal_server_error'</span>, <span class="string">'server_error'</span>, <span class="string">'/o\\'</span>, <span class="string">'✗'</span>),</span><br><span class="line"><span class="number">501</span>: (<span class="string">'not_implemented'</span>,),</span><br><span class="line"><span class="number">502</span>: (<span class="string">'bad_gateway'</span>,),</span><br><span class="line"><span class="number">503</span>: (<span class="string">'service_unavailable'</span>, <span class="string">'unavailable'</span>),</span><br><span class="line"><span class="number">504</span>: (<span class="string">'gateway_timeout'</span>,),</span><br><span class="line"><span class="number">505</span>: (<span class="string">'http_version_not_supported'</span>, <span class="string">'http_version'</span>),</span><br><span class="line"><span class="number">506</span>: (<span class="string">'variant_also_negotiates'</span>,),</span><br><span class="line"><span class="number">507</span>: (<span class="string">'insufficient_storage'</span>,),</span><br><span class="line"><span class="number">509</span>: (<span class="string">'bandwidth_limit_exceeded'</span>, <span class="string">'bandwidth'</span>),</span><br><span class="line"><span class="number">510</span>: (<span class="string">'not_extended'</span>,),</span><br><span class="line"><span class="number">511</span>: (<span class="string">'network_authentication_required'</span>, <span class="string">'network_auth'</span>, <span class="string">'network_authentication'</span>)</span><br></pre></td></tr></table></figure>
<p>比如，如果想判断结果是不是 404 状态，可以用 <code>requests.codes.not_found</code> 来比对。</p>
<h1 id="高级用法"><a href="#高级用法" class="headerlink" title="高级用法"></a>高级用法</h1><p>刚才，我们了解了<code>requests</code>的基本用法，如基本的 <code>GET</code>、<code>POST</code> 请求以及<code>Response</code> 对象。当然<code>requests</code>能做到的不仅这些，它几乎可以帮我们完成<code>HTTP</code>的所有操作。</p>
<p>下面我们再来了解下<code>requests</code>的一些高级用法，如文件上传、<code>Cookies</code> 设置、代理设置等。</p>
<h2 id="文件上传"><a href="#文件上传" class="headerlink" title="文件上传"></a>文件上传</h2><p>我们知道<code>requests</code>可以模拟提交一些数据。假如有的网站需要上传文件，我们也可以用它来实现，示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">files = &#123;<span class="string">'file'</span>: open(<span class="string">'favicon.ico'</span>, <span class="string">'rb'</span>)&#125;</span><br><span class="line">r = requests.post(<span class="string">'http://httpbin.org/post'</span>, files=files)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>
<p>在前面我们保存了一个文件 <code>favicon.ico</code>，这次用它来模拟文件上传的过程。需要注意的是，<code>favicon.ico</code> 需要和当前脚本在同一目录下。如果有其他文件，当然也可以使用其他文件来上传，更改下代码即可。</p>
<p>运行结果如下：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;<span class="attr">"args"</span>: &#123;&#125;, </span><br><span class="line"><span class="attr">"data"</span>: <span class="string">""</span>,<span class="attr">"files"</span>: &#123;<span class="attr">"file"</span>:<span class="string">"data:application/octet-stream;base64,AAAAAA...="</span>&#125;,<span class="attr">"form"</span>: &#123;&#125;,<span class="attr">"headers"</span>: &#123;<span class="attr">"Accept"</span>:<span class="string">"*/*"</span>,<span class="attr">"Accept-Encoding"</span>:<span class="string">"gzip, deflate"</span>,<span class="attr">"Content-Length"</span>:<span class="string">"6665"</span>,<span class="attr">"Content-Type"</span>:<span class="string">"multipart/form-data; boundary=809f80b1a2974132b133ade1a8e8e058"</span>,<span class="attr">"Host"</span>:<span class="string">"httpbin.org"</span>,<span class="attr">"User-Agent"</span>:<span class="string">"python-requests/2.10.0"</span>&#125;,<span class="attr">"json"</span>: <span class="literal">null</span>,<span class="attr">"origin"</span>:<span class="string">"60.207.237.16"</span>,<span class="attr">"url"</span>:<span class="string">"http://httpbin.org/post"</span>&#125;</span><br></pre></td></tr></table></figure>
<p>以上省略部分内容，这个网站会返回响应，里面包含 <code>files</code> 这个字段，而 <code>form</code> 字段是空的，这证明文件上传部分会单独有一个 <code>files</code>字段来标识。</p>
<h2 id="Cookies"><a href="#Cookies" class="headerlink" title="Cookies"></a><code>Cookies</code></h2><p>我们如果想用<code>requests</code>获取和设置<code>cookies</code> 也非常方便，只需一步即可完成。</p>
<p>我们先用一个实例看一下获取<code>cookies</code> 的过程：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">r = requests.get(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line">print(r.cookies)</span><br><span class="line"><span class="keyword">for</span> key, value <span class="keyword">in</span> r.cookies.items():</span><br><span class="line">    print(key + <span class="string">'='</span> + value)</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;RequestsCookieJar[&lt;Cookie BDORZ&#x3D;27315 for .baidu.com&#x2F;&gt;]&gt;</span><br><span class="line">BDORZ&#x3D;27315</span><br></pre></td></tr></table></figure>
<p>这里我们首先调用<code>cookies</code> 属性即可成功得到 <code>Cookies</code>，可以发现它是 <code>RequestCookieJar</code> 类型。然后用 <code>items</code> 方法将其转化为元组组成的列表，遍历输出每一个<code>Cookie</code> 的名称和值，实现<code>Cookie</code> 的遍历解析。</p>
<p>当然，我们也可以直接用<code>Cookie</code> 来维持登录状态，下面我们以<code>GitHub</code>为例来说明一下，首先我们登录 <code>GitHub</code>，然后将<code>headers</code> 中的<code>Cookie</code> 内容复制下来，如图所示：</p>
<p>这里可以替换成你自己的 <code>Cookie</code>，将其设置到<code>headers</code> 里面，然后发送请求，示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'Cookie'</span>: <span class="string">'_octo=GH1.1.1849343058.1576602081; _ga=GA1.2.90460451.1576602111; __Host-user_session_same_site=nbDv62kHNjp4N5KyQNYZ208waeqsmNgxFnFC88rnV7gTYQw_; _device_id=a7ca73be0e8f1a81d1e2ebb5349f9075; user_session=nbDv62kHNjp4N5KyQNYZ208waeqsmNgxFnFC88rnV7gTYQw_; logged_in=yes; dotcom_user=Germey; tz=Asia%2FShanghai; has_recent_activity=1; _gat=1; _gh_sess=your_session_info'</span>,</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36'</span>,</span><br><span class="line">&#125;</span><br><span class="line">r = requests.get(<span class="string">'https://github.com/'</span>, headers=headers)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>
<p>我们发现，结果中包含了登录后才能显示的结果，如图所示：</p>
<p>可以看到这里包含了我的<code>GitHub</code>用户名信息，你如果尝试同样可以得到你的用户信息。</p>
<p>得到这样类似的结果，说明我们用<code>cookies</code> 成功模拟了登录状态，这样我们就能爬取登录之后才能看到的页面了。</p>
<p>当然，我们也可以通过<code>cookies</code> 参数来设置<code>cookies</code> 的信息，这里我们可以构造一个 <code>RequestsCookieJar</code> 对象，然后把刚才复制的<code>Cookie</code> 处理下并赋值，示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">cookies = <span class="string">'_octo=GH1.1.1849343058.1576602081; _ga=GA1.2.90460451.1576602111; __Host-user_session_same_site=nbDv62kHNjp4N5KyQNYZ208waeqsmNgxFnFC88rnV7gTYQw_; _device_id=a7ca73be0e8f1a81d1e2ebb5349f9075; user_session=nbDv62kHNjp4N5KyQNYZ208waeqsmNgxFnFC88rnV7gTYQw_; logged_in=yes; dotcom_user=Germey; tz=Asia%2FShanghai; has_recent_activity=1; _gat=1; _gh_sess=your_session_info'</span></span><br><span class="line">jar = requests.cookies.RequestsCookieJar()</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36'</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span>`Cookie` <span class="keyword">in</span> cookies.split(<span class="string">';'</span>):</span><br><span class="line">    key, value = cookie.split(<span class="string">'='</span>, <span class="number">1</span>)</span><br><span class="line">    jar.set(key, value)</span><br><span class="line">r = requests.get(<span class="string">'https://github.com/'</span>, cookies=jar, headers=headers)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>
<p>这里我们首先新建一个 <code>RequestCookieJar</code> 对象，然后将复制下来的<code>cookies</code> 利用 <code>split</code> 方法分割，接着利用 <code>set</code> 方法设置好每个<code>Cookie</code> 的 <code>key</code> 和 <code>value</code>，最后通过调用<code>requests</code>的<code>GET</code>方法并传递给<code>cookies</code> 参数即可。</p>
<p>测试后，发现同样可以正常登录。</p>
<h2 id="Session-维持"><a href="#Session-维持" class="headerlink" title="Session 维持"></a><code>Session</code> 维持</h2><p>在<code>requests</code>中，如果直接利用<code>GET</code>或<code>POST</code> 等方法的确可以做到模拟网页的请求，但是这实际上是相当于不同的 <code>Session</code>，相当于你用两个浏览器打开了不同的页面。</p>
<p>设想这样一个场景，第一个请求利用<code>POST</code> 方法登录了某个网站，第二次想获取成功登录后的自己的个人信息，你又用了一次<code>GET</code>方法去请求个人信息页面。实际上，这相当于打开了两个浏览器，是两个完全不相关的 <code>Session</code>，能成功获取个人信息吗？当然不能。</p>
<p>有人会问，我在两次请求时设置一样的<code>cookies</code> 不就行了？可以，但这样做起来很烦琐，我们有更简单的解决方法。</p>
<p>解决这个问题的主要方法就是维持同一个 <code>Session</code>，相当于打开一个新的浏览器选项卡而不是新开一个浏览器。但我又不想每次设置 <code>Cookies</code>，那该怎么办呢？这时候就有了新的利器 ——<code>Session</code> 对象。</p>
<p>利用它，我们可以方便地维护一个 <code>Session</code>，而且不用担心<code>cookies</code> 的问题，它会帮我们自动处理好。示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">requests.get(<span class="string">'http://httpbin.org/cookies/set/number/123456789'</span>)</span><br><span class="line">r = requests.get(<span class="string">'http://httpbin.org/cookies'</span>)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>
<p>这里我们请求了一个测试网址 <a href="http://httpbin.org/cookies/set/number/123456789。请求这个网址时，可以设置一个" target="_blank" rel="noopener">http://httpbin.org/cookies/set/number/123456789。请求这个网址时，可以设置一个</a> <code>cookie</code>，名称叫作 <code>number</code>，内容是 123456789，随后又请求了 <a href="http://httpbin.org/cookies，此网址可以获取当前的" target="_blank" rel="noopener">http://httpbin.org/cookies，此网址可以获取当前的</a> <code>Cookies</code>。</p>
<p>这样能成功获取到设置的<code>cookies</code> 吗？试试看。</p>
<p>运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;cookies&quot;: &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这并不行。我们再用 <code>Session</code> 试试看：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">s = requests.Session()</span><br><span class="line">s.get(<span class="string">'http://httpbin.org/cookies/set/number/123456789'</span>)</span><br><span class="line">r = s.get(<span class="string">'http://httpbin.org/cookies'</span>)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>
<p>再看下运行结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;cookies&quot;: &#123;&quot;number&quot;: &quot;123456789&quot;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>成功获取！这下能体会到同一个<code>Session</code>和不同<code>Session</code>的区别了吧！</p>
<p>所以，利用 <code>Session</code>，可以做到模拟同一个 <code>Session</code> 而不用担心<code>cookies</code> 的问题。它通常用于模拟登录成功之后再进行下一步的操作。</p>
<h2 id="SSL-证书验证"><a href="#SSL-证书验证" class="headerlink" title="SSL 证书验证"></a><code>SSL</code> 证书验证</h2><p>现在很多网站都要求使用 <code>HTTPS</code> 协议，但是有些网站可能并没有设置好 <code>HTTPS</code> 证书，或者网站的 <code>HTTPS</code> 证书不被 <code>CA</code> 机构认可，这时候，这些网站可能就会出现 <code>SSL</code> 证书错误的提示。</p>
<p>比如这个示例网站：<a href="https://static2.scrape.center/。" target="_blank" rel="noopener">https://static2.scrape.center/。</a></p>
<p>如果我们用 Chrome 浏览器打开这个 <code>URL</code>，则会提示「您的连接不是私密连接」这样的错误，如图所示：</p>
<p><img src="../Pic/Spider/https.png" style="zoom:70%;"></p>
<p>我们可以在浏览器中通过一些设置来忽略证书的验证。</p>
<p>但是如果我们想用<code>requests</code>来请求这类网站，会遇到什么问题呢？我们用代码来试一下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">response = requests.get(<span class="string">'https://static2.scrape.center/'</span>)</span><br><span class="line">print(response.status_code)</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">requests.exceptions.SSLError: HTTPSConnectionPool(host&#x3D;&#39;static2.scrape.center&#39;, port&#x3D;443): Max retries exceeded with url: &#x2F; (Caused by SSLError(SSLError(&quot;bad handshake: Error([(&#39;SSL routines&#39;, &#39;tls_process_server_certificate&#39;, &#39;certificate verify failed&#39;)])&quot;)))</span><br></pre></td></tr></table></figure>
<p>可以看到，这里直接抛出了 <code>SSLError</code> 错误，原因就是因为我们请求的<code>URL</code>的证书是无效的。</p>
<p>那如果我们一定要爬取这个网站怎么办呢？我们可以使用 <code>verify</code> 参数控制是否验证证书，如果将其设置为 <code>False</code>，在请求时就不会再验证证书是否有效。如果不加 <code>verify</code> 参数的话，默认值是 <code>True</code>，会自动验证。</p>
<p>我们改写代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">response = requests.get(<span class="string">'https://static2.scrape.center/'</span>, verify=<span class="literal">False</span>)</span><br><span class="line">print(response.status_code)</span><br></pre></td></tr></table></figure>
<p>这样就会打印出请求成功的状态码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.7&#x2F;site-packages&#x2F;urllib3&#x2F;connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https:&#x2F;&#x2F;urllib3.readthedocs.io&#x2F;en&#x2F;latest&#x2F;advanced-usage.html#ssl-warnings</span><br><span class="line">  InsecureRequestWarning)</span><br><span class="line">200</span><br></pre></td></tr></table></figure>
<p>不过我们发现报了一个警告，它建议我们给它指定证书。我们可以通过设置忽略警告的方式来屏蔽这个警告：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> requests.packages <span class="keyword">import</span> urllib3</span><br><span class="line">urllib3.disable_warnings()</span><br><span class="line">response = requests.get(<span class="string">'https://static2.scrape.center'</span>, verify=<span class="literal">False</span>)</span><br><span class="line">print(response.status_code)</span><br></pre></td></tr></table></figure>
<p>或者通过捕获警告到日志的方式忽略警告：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">logging.captureWarnings(<span class="literal">True</span>)</span><br><span class="line">response = requests.get(<span class="string">'https://static2.scrape.center/'</span>, verify=<span class="literal">False</span>)</span><br><span class="line">print(response.status_code)</span><br></pre></td></tr></table></figure>
<p>当然，我们也可以指定一个本地证书用作客户端证书，这可以是单个文件（包含密钥和证书）或一个包含两个文件路径的元组：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">response = requests.get(<span class="string">'https://static2.scrape.center/'</span>, cert=(<span class="string">'/path/server.crt'</span>, <span class="string">'/path/server.key'</span>))</span><br><span class="line">print(response.status_code)</span><br></pre></td></tr></table></figure>
<p>当然，上面的代码是演示实例，我们需要有 <code>crt</code> 和 <code>key</code> 文件，并且指定它们的路径。另外注意，本地私有证书的 <code>key</code> 必须是解密状态，加密状态的 <code>key</code> 是不支持的。</p>
<h2 id="超时设置"><a href="#超时设置" class="headerlink" title="超时设置"></a>超时设置</h2><p>在本机网络状况不好或者服务器网络响应延迟甚至无响应时，我们可能会等待很久才能收到响应，甚至到最后收不到响应而报错。为了防止服务器不能及时响应，应该设置一个超时时间，即超过了这个时间还没有得到响应，那就报错。这需要用到 <code>timeout</code> 参数。这个时间的计算是发出请求到服务器返回响应的时间。示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">r = requests.get(<span class="string">'https://httpbin.org/get'</span>, timeout=<span class="number">1</span>)</span><br><span class="line">print(r.status_code)</span><br></pre></td></tr></table></figure>
<p>通过这样的方式，我们可以将超时时间设置为 1 秒，如果 1 秒内没有响应，那就抛出异常。</p>
<p>实际上，请求分为两个阶段，即连接（connect）和读取（read）。上面设置的 <code>timeout</code> 将用作连接和读取这二者的 <code>timeout</code> 总和。</p>
<p>如果要分别指定，就可以传入一个元组：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">r = requests.get(<span class="string">'https://httpbin.org/get'</span>, timeout=(<span class="number">5</span>, <span class="number">30</span>))</span><br></pre></td></tr></table></figure>
<p>如果想永久等待，可以直接将 <code>timeout</code> 设置为 None，或者不设置直接留空，因为默认是 <code>None</code>。这样的话，如果服务器还在运行，但是响应特别慢，那就慢慢等吧，它永远不会返回超时错误的。其用法如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">r = requests.get(<span class="string">'https://httpbin.org/get'</span>, timeout=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>或直接不加参数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">r = requests.get(<span class="string">'https://httpbin.org/get'</span>)</span><br></pre></td></tr></table></figure>
<h2 id="身份认证"><a href="#身份认证" class="headerlink" title="身份认证"></a>身份认证</h2><p>在访问某些设置了身份认证的网站时，例如：<a href="https://static3.scrape.center/，我们可能会遇到这样的认证窗口，如图所示：" target="_blank" rel="noopener">https://static3.scrape.center/，我们可能会遇到这样的认证窗口，如图所示：</a></p>
<p><img src="/posts/Pic/Spider/identifier.png" style="zoom:80%;"></p>
<p>如果遇到了这种情况，那就是这个网站启用了基本身份认证，英文叫作<code>HTTP Basic Access Authentication</code>，它是一种用来允许网页浏览器或其他客户端程序在请求时提供用户名和口令形式的身份凭证的一种登录验证方式。</p>
<p>如果遇到了这种情况，怎么用 <code>reqeusts</code> 来爬取呢，当然也有办法。</p>
<p>我们可以使用<code>requests</code>自带的身份认证功能，通过 <code>auth</code> 参数即可设置，示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> requests.auth <span class="keyword">import</span> HTTPBasicAuth</span><br><span class="line">r = requests.get(<span class="string">'https://static3.scrape.center/'</span>, auth=HTTPBasicAuth(<span class="string">'admin'</span>, <span class="string">'admin'</span>))</span><br><span class="line">print(r.status_code)</span><br></pre></td></tr></table></figure>
<p>这个示例网站的用户名和密码都是 <code>admin</code>，在这里我们可以直接设置。</p>
<p>如果用户名和密码正确的话，请求时会自动认证成功，返回 200 状态码；如果认证失败，则返回 401 状态码。</p>
<p>当然，如果参数都传一个 <code>HTTPBasicAuth</code> 类，就显得有点烦琐了，所以<code>requests</code>提供了一个更简单的写法，可以直接传一个元组，它会默认使用 <code>HTTPBasicAuth</code> 这个类来认证。</p>
<p>所以上面的代码可以直接简写如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">r = requests.get(<span class="string">'https://static3.scrape.center/'</span>, auth=(<span class="string">'admin'</span>, <span class="string">'admin'</span>))</span><br><span class="line">print(r.status_code)</span><br></pre></td></tr></table></figure>
<p>此外，<code>requests</code>还提供了其他认证方式，如 <code>OAuth</code> 认证，不过此时需要安装 <code>oauth</code> 包，安装命令如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip3 install requests_oauthlib</span><br></pre></td></tr></table></figure>
<p>使用 <code>OAuth1</code> 认证的方法如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> requests_oauthlib <span class="keyword">import</span> OAuth1</span><br><span class="line">url = <span class="string">'https://api.twitter.com/1.1/account/verify_credentials.json'</span></span><br><span class="line">auth = OAuth1(<span class="string">'YOUR_APP_KEY'</span>, <span class="string">'YOUR_APP_SECRET'</span>,</span><br><span class="line">              <span class="string">'USER_OAUTH_TOKEN'</span>, <span class="string">'USER_OAUTH_TOKEN_SECRET'</span>)</span><br><span class="line">requests.get(url, auth=auth)</span><br></pre></td></tr></table></figure>
<p>更多详细的功能就可以参考 <code>requests_oauthlib</code> 的官方文档：<a href="https://requests-oauthlib.readthedocs.org/，在此就不再赘述了。" target="_blank" rel="noopener">https://requests-oauthlib.readthedocs.org/，在此就不再赘述了。</a></p>
<p>代理设置<br>某些网站在测试的时候请求几次，能正常获取内容。但是对于大规模且频繁的请求，网站可能会弹出验证码，或者跳转到登录认证页面，更甚者可能会直接封禁客户端的 IP，导致一定时间段内无法访问。</p>
<p>为了防止这种情况发生，我们需要设置代理来解决这个问题，这就需要用到 <code>proxies</code> 参数。可以用这样的方式设置：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">proxies = &#123;</span><br><span class="line">  <span class="string">'http'</span>: <span class="string">'http://10.10.10.10:1080'</span>,</span><br><span class="line">  <span class="string">'https'</span>: <span class="string">'http://10.10.10.10:1080'</span>,</span><br><span class="line">&#125;</span><br><span class="line">requests.get(<span class="string">'https://httpbin.org/get'</span>, proxies=proxies)</span><br></pre></td></tr></table></figure>
<p>当然，直接运行这个实例或许行不通，因为这个代理可能是无效的，可以直接搜索寻找有效的代理并替换试验一下。</p>
<p>若代理需要使用上文所述的身份认证，可以使用类似 <a href="http://user:password@host:port">http://user:password@host:port</a> 这样的语法来设置代理，示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">proxies = &#123;<span class="string">'https'</span>: <span class="string">'http://user:password@10.10.10.10:1080/'</span>,&#125;</span><br><span class="line">requests.get(<span class="string">'https://httpbin.org/get'</span>, proxies=proxies)</span><br></pre></td></tr></table></figure>
<p>除了基本的<code>HTTP</code>代理外，<code>requests</code>还支持 <code>SOCKS</code> 协议的代理。</p>
<p>首先，需要安装 <code>socks</code> 这个库：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip3 install <span class="string">"requests[socks]"</span></span><br></pre></td></tr></table></figure>
<p>然后就可以使用 <code>SOCKS</code> 协议代理了，示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">proxies = &#123;</span><br><span class="line">    <span class="string">'http'</span>: <span class="string">'socks5://user:password@host:port'</span>,</span><br><span class="line">    <span class="string">'https'</span>: <span class="string">'socks5://user:password@host:port'</span></span><br><span class="line">&#125;</span><br><span class="line">requests.get(<span class="string">'https://httpbin.org/get'</span>, proxies=proxies)</span><br></pre></td></tr></table></figure>
<h2 id="Prepared-Request"><a href="#Prepared-Request" class="headerlink" title="Prepared Request"></a><code>Prepared Request</code></h2><p>我们使用<code>requests</code>库的<code>GET</code>和<code>POST</code> 方法可以直接发送请求，但你有没有想过，这个请求在<code>requests</code>内部是怎么实现的呢？</p>
<p>实际上，<code>requests</code>在发送请求的时候在内部构造了一个 <code>Request</code> 对象，并给这个对象赋予了各种参数，包括 url、headers、data ，等等。然后直接把这个 Request 对象发送出去，请求成功后会再得到一个<code>Response</code> 对象，再解析即可。</p>
<p>那么这个 <code>Request</code> 是什么类型呢？实际上它就是 <code>Prepared Request</code>。</p>
<p>我们深入一下，不用<code>GET</code>方法，直接构造一个 <code>Prepared Request</code> 对象来试试，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> requests <span class="keyword">import</span> Request, Session</span><br><span class="line">url = <span class="string">'http://httpbin.org/post'</span></span><br><span class="line">data = &#123;<span class="string">'name'</span>: <span class="string">'germey'</span>&#125;</span><br><span class="line">headers = &#123;<span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36'</span></span><br><span class="line">&#125;</span><br><span class="line">s = Session()</span><br><span class="line">req = Request(<span class="string">'POST'</span>, url, data=data, headers=headers)</span><br><span class="line">prepped = s.prepare_request(req)</span><br><span class="line">r = s.send(prepped)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>
<p>这里我们引入了 <code>Request</code>，然后用 <code>url</code>、<code>data</code> 和<code>headers</code> 参数构造了一个 <code>Request</code> 对象，这时需要再调用 <code>Session</code> 的 <code>prepare_request</code> 方法将其转换为一个 <code>Prepared Request</code> 对象，然后调用 <code>send</code> 方法发送，运行结果如下：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"args"</span>: &#123;&#125;, </span><br><span class="line">  <span class="attr">"data"</span>: <span class="string">""</span>, </span><br><span class="line">  <span class="attr">"files"</span>: &#123;&#125;, </span><br><span class="line">  <span class="attr">"form"</span>: &#123;</span><br><span class="line">    <span class="attr">"name"</span>: <span class="string">"germey"</span></span><br><span class="line">  &#125;, </span><br><span class="line">  <span class="attr">"headers"</span>: &#123;</span><br><span class="line">    <span class="attr">"Accept"</span>: <span class="string">"*/*"</span>, </span><br><span class="line">    <span class="attr">"Accept-Encoding"</span>: <span class="string">"gzip, deflate"</span>, </span><br><span class="line">    <span class="attr">"Content-Length"</span>: <span class="string">"11"</span>, </span><br><span class="line">    <span class="attr">"Content-Type"</span>: <span class="string">"application/x-www-form-urlencoded"</span>, </span><br><span class="line">    <span class="attr">"Host"</span>: <span class="string">"httpbin.org"</span>, </span><br><span class="line">    <span class="attr">"User-Agent"</span>: <span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36"</span>, </span><br><span class="line">    <span class="attr">"X-Amzn-Trace-Id"</span>: <span class="string">"Root=1-5e5bd6a9-6513c838f35b06a0751606d8"</span></span><br><span class="line">  &#125;, </span><br><span class="line">  <span class="attr">"json"</span>: <span class="literal">null</span>, </span><br><span class="line">  <span class="attr">"origin"</span>: <span class="string">"167.220.232.237"</span>, </span><br><span class="line">  <span class="attr">"url"</span>: <span class="string">"http://httpbin.org/post"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到，我们达到了同样的<code>POST</code> 请求效果。</p>
<p>有了 <code>Request</code> 这个对象，就可以将请求当作独立的对象来看待，这样在一些场景中我们可以直接操作这个 <code>Request</code> 对象，更灵活地实现请求的调度和各种操作。</p>
<p>更多的用法可以参考<code>requests</code>的官方文档：<a href="http://docs.python-requests.org/。" target="_blank" rel="noopener">http://docs.python-requests.org/。</a></p>
]]></content>
      <categories>
        <category>Spider</category>
      </categories>
  </entry>
  <entry>
    <title>Python爬虫（六）多进程基本原理</title>
    <url>/posts/2a78ce87.html</url>
    <content><![CDATA[<p>前面我们说到Python 中的多线程是不能很好发挥多核优势的，如果想要发挥多核优势，最好还是使用多进程。那么现在我们就来了解下多进程的基本概念和用 Python 实现多进程的方法。</p>
<h1 id="多进程的含义"><a href="#多进程的含义" class="headerlink" title="多进程的含义"></a>多进程的含义</h1><p>进程（Process）是具有一定独立功能的程序关于某个数据集合上的一次运行活动，是系统进行资源分配和调度的一个独立单位。</p>
<p>顾名思义，多进程就是启用多个进程同时运行。由于进程是线程的集合，而且进程是由一个或多个线程构成的，所以多进程的运行意味着有大于或等于进程数量的线程在运行。</p>
<h1 id="Python-多进程的优势"><a href="#Python-多进程的优势" class="headerlink" title="Python 多进程的优势"></a>Python 多进程的优势</h1><p>前面我们说到由于进程中 GIL 的存在，Python 中的多线程并不能很好地发挥多核优势，一个进程中的多个线程，在同一时刻只能有一个线程运行。</p>
<p>而对于多进程来说，<strong>每个进程都有属于自己的 GIL</strong>，所以，在多核处理器下，多进程的运行是不会受 GIL 的影响的。因此，多进程能更好地发挥多核的优势。</p>
<p>当然，对于爬虫这种 IO 密集型任务来说，多线程和多进程影响差别并不大。对于计算密集型任务来说，Python 的多进程相比多线程，其多核运行效率会有成倍的提升。</p>
<p>总的来说，Python 的多进程整体来看是比多线程更有优势的。所以，在条件允许的情况下，<strong>能用多进程就尽量用多进程</strong>。</p>
<p>不过值得注意的是，由于进程是系统进行资源分配和调度的一个独立单位，所以<strong>各个进程之间的数据是无法共享的</strong>，如多个进程无法共享一个全局变量，进程之间的数据共享需要有单独的机制来实现，这在后面也会讲到。</p>
<h1 id="多进程的实现"><a href="#多进程的实现" class="headerlink" title="多进程的实现"></a>多进程的实现</h1><p>在 Python 中也有内置的库来实现多进程，它就是 <code>multiprocessing</code>。</p>
<p><code>multiprocessing</code>提供了一系列的组件，如<code>Process</code>（进程）、<code>Queue</code>（队列）、<code>Semaphore</code>（信号量）、<code>Pipe</code>（管道）、Lock（锁）、Pool（进程池）等，接下来让我们来了解下它们的使用方法。</p>
<h2 id="直接使用Process类"><a href="#直接使用Process类" class="headerlink" title="直接使用Process类"></a>直接使用<code>Process</code>类</h2><p>在<code>multiprocessing</code>中，每一个进程都用一个<code>Process</code>类来表示。它的 API 调用如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Process([group [,`target`[, name [, `args`[, kwargs]]]]])</span><br></pre></td></tr></table></figure>
<ul>
<li><code>target</code> 表示调用对象，你可以传入方法的名字。</li>
<li><code>args</code> 表示被调用对象的位置参数元组，比如 <code>target</code> 是函数 <code>func</code>，他有两个参数 <code>m</code>，<code>n</code>，那么 <code>args</code> 就传入 <code>[m, n]</code> 即可。</li>
<li><code>kwargs</code> 表示调用对象的字典。</li>
<li><code>name</code> 是别名，相当于给这个进程取一个名字。</li>
<li><code>group</code> 分组。</li>
</ul>
<p>我们先用一个实例来感受一下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process</span><span class="params">(index)</span>:</span></span><br><span class="line">    print(<span class="string">f'Process: <span class="subst">&#123;index&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">        p = multiprocessing.Process(target=process, args=(i,))</span><br><span class="line">        p.start()</span><br></pre></td></tr></table></figure>
<p>这是一个实现多进程最基础的方式：通过创建<code>process</code>来新建一个子进程，其中<code>target</code>参数传入方法名，<code>args</code>是方法的参数，是以元组的形式传入，其和被调用的方法<code>process</code>的参数是一一对应的。</p>
<blockquote>
<p>注意：这里 <code>args</code>必须要是一个元组，如果只有一个参数，那也要在元组第一个元素后面加一个逗号，如果没有逗号则和单个元素本身没有区别，无法构成元组，导致参数传递出现问题。</p>
</blockquote>
<p>创建完进程之后，我们通过调用<code>start</code>方法即可启动进程了。运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Process: 0</span><br><span class="line">Process: 1</span><br><span class="line">Process: 2</span><br><span class="line">Process: 3</span><br><span class="line">Process: 4</span><br></pre></td></tr></table></figure>
<p>可以看到，我们运行了 5 个子进程，每个进程都调用了<code>process</code>方法。process 方法的 index 参数通过<code>process</code>的 <code>args</code>传入，分别是 0~4 这 5 个序号，最后打印出来，5 个子进程运行结束。</p>
<p>由于进程是 <code>Python</code> 中最小的资源分配单元，因此这些进程和线程不同，各个进程之间的数据是不会共享的，每启动一个进程，都会独立分配资源。</p>
<p>另外，在当前 <code>CPU</code> 核数足够的情况下，这些不同的进程会分配给不同的 <code>CPU</code> 核来运行，实现真正的并行执行。</p>
<p><code>multiprocessing</code> 还提供了几个比较有用的方法，如我们可以通过 <code>cpu_count</code> 的方法来获取当前机器 <code>CPU</code> 的核心数量，通过 <code>active_children</code> 方法获取当前还在运行的所有进程。</p>
<p>下面通过一个实例来看一下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process</span><span class="params">(index)</span>:</span></span><br><span class="line">    time.sleep(index)</span><br><span class="line">    print(<span class="string">f'Process: <span class="subst">&#123;index&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">        p = multiprocessing.Process(target=process, args=[i])</span><br><span class="line">        p.start()</span><br><span class="line">    print(<span class="string">f'CPU number: <span class="subst">&#123;multiprocessing.cpu_count()&#125;</span>'</span>)</span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> multiprocessing.active_children():</span><br><span class="line">        print(<span class="string">f'Child process name: <span class="subst">&#123;p.name&#125;</span> id: <span class="subst">&#123;p.pid&#125;</span>'</span>)</span><br><span class="line">    print(<span class="string">'Process Ended'</span>)</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Process: 0</span><br><span class="line">CPU number: 8</span><br><span class="line">Child process name: Process-5 id: 73595</span><br><span class="line">Child process name: Process-2 id: 73592</span><br><span class="line">Child process name: Process-3 id: 73593</span><br><span class="line">Child process name: Process-4 id: 73594</span><br><span class="line">Process Ended</span><br><span class="line">Process: 1</span><br><span class="line">Process: 2</span><br><span class="line">Process: 3</span><br><span class="line">Process: 4</span><br></pre></td></tr></table></figure>
<p>在上面的例子中我们通过 <code>cpu_count</code> 成功获取了 CPU 核心的数量：8 个，当然不同的机器结果可能不同。</p>
<p>另外我们还通过 <code>active_children</code> 获取到了当前正在活跃运行的进程列表。然后我们遍历了每个进程，并将它们的名称和进程号打印出来了，这里进程号直接使用 <code>pid</code> 属性即可获取，进程名称直接通过 <code>name</code> 属性即可获取。</p>
<p>以上我们就完成了多进程的创建和一些基本信息的获取。</p>
<h2 id="继承process类"><a href="#继承process类" class="headerlink" title="继承process类"></a>继承<code>process</code>类</h2><p>在上面的例子中，我们创建进程是直接使用<code>process</code>这个类来创建的，这是一种创建进程的方式。不过，创建进程的方式不止这一种，同样，我们也可以像线程<code>Thread</code>一样来通过继承的方式创建一个进程类，进程的基本操作我们在子类的 run 方法中实现即可。</p>
<p>通过一个实例来看一下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span>`multiprocessing`<span class="keyword">import</span> Process</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyProcess</span><span class="params">(Process)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, loop)</span>:</span></span><br><span class="line">        Process.__init__(self)</span><br><span class="line">        self.loop = loop</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> count <span class="keyword">in</span> range(self.loop):</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">            print(<span class="string">f'Pid: <span class="subst">&#123;self.pid&#125;</span> LoopCount: <span class="subst">&#123;count&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>, <span class="number">5</span>):</span><br><span class="line">        p = MyProcess(i)</span><br><span class="line">        p.start()</span><br></pre></td></tr></table></figure>
<p>我们首先声明了一个构造方法，这个方法接收一个 <code>loop</code> 参数，代表循环次数，并将其设置为全局变量。在 <code>run</code> 方法中，又使用这个 <code>loop</code> 变量循环了 <code>loop</code> 次并打印了当前的进程号和循环次数。</p>
<p>在调用时，我们用 <code>range</code> 方法得到了 2、3、4 三个数字，并把它们分别初始化了 <code>MyProcess</code> 进程，然后调用<code>start</code>方法将进程启动起来。</p>
<blockquote>
<p>注意：这里进程的执行逻辑需要在 <code>run</code> 方法中实现，启动进程需要调用<code>start</code>方法，调用之后 <code>run</code> 方法便会执行。</p>
</blockquote>
<p>运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Pid: 73667 LoopCount: 0</span><br><span class="line">Pid: 73668 LoopCount: 0</span><br><span class="line">Pid: 73669 LoopCount: 0</span><br><span class="line">Pid: 73667 LoopCount: 1</span><br><span class="line">Pid: 73668 LoopCount: 1</span><br><span class="line">Pid: 73669 LoopCount: 1</span><br><span class="line">Pid: 73668 LoopCount: 2</span><br><span class="line">Pid: 73669 LoopCount: 2</span><br><span class="line">Pid: 73669 LoopCount: 3</span><br></pre></td></tr></table></figure>
<p>可以看到，三个进程分别打印出了 2、3、4 条结果，即进程 73667 打印了 2 次 结果，进程 73668 打印了 3 次结果，进程 73669 打印了 4 次结果。</p>
<blockquote>
<p>注意，这里的进程 <code>pid</code> 代表进程号，不同机器、不同时刻运行结果可能不同。</p>
</blockquote>
<p>通过上面的方式，我们也非常方便地实现了一个进程的定义。为了复用方便，我们可以把一些方法写在每个进程类里封装好，在使用时直接初始化一个进程类运行即可。</p>
<h2 id="守护进程"><a href="#守护进程" class="headerlink" title="守护进程"></a>守护进程</h2><p>在多进程中，同样存在守护进程的概念，如果一个进程被设置为守护进程，当父进程结束后，子进程会自动被终止，我们可以通过设置 <code>daemon</code> 属性来控制是否为守护进程。</p>
<p>还是原来的例子，增加了 <code>deamon</code> 属性的设置：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span>`multiprocessing`<span class="keyword">import</span> Process</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyProcess</span><span class="params">(Process)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, loop)</span>:</span></span><br><span class="line">        Process.__init__(self)</span><br><span class="line">        self.loop = loop</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> count <span class="keyword">in</span> range(self.loop):</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">            print(<span class="string">f'Pid: <span class="subst">&#123;self.pid&#125;</span> LoopCount: <span class="subst">&#123;count&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>, <span class="number">5</span>):</span><br><span class="line">        p = MyProcess(i)</span><br><span class="line">        p.daemon = <span class="literal">True</span></span><br><span class="line">        p.start()</span><br><span class="line">print(<span class="string">'Main`process`ended'</span>)</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Main process ended</span><br></pre></td></tr></table></figure>
<p>结果很简单，因为主进程没有做任何事情，直接输出一句话结束，所以在这时也直接终止了子进程的运行。</p>
<p>这样可以有效防止无控制地生成子进程。这样的写法可以让我们在主进程运行结束后无需额外担心子进程是否关闭，避免了独立子进程的运行。</p>
<h2 id="进程等待"><a href="#进程等待" class="headerlink" title="进程等待"></a>进程等待</h2><p>上面的运行效果其实不太符合我们预期：主进程运行结束时，子进程（守护进程）也都退出了，子进程什么都没来得及执行。</p>
<p>能不能让所有子进程都执行完了然后再结束呢？当然是可以的，只需要加入 <code>join</code> 方法即可，我们可以将代码改写如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">processes = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>, <span class="number">5</span>):</span><br><span class="line">    p = MyProcess(i)</span><br><span class="line">    processes.append(p)</span><br><span class="line">    p.daemon = <span class="literal">True</span></span><br><span class="line">    p.start()</span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> processes:</span><br><span class="line">    p.join()</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Pid: 40866 LoopCount: 0</span><br><span class="line">Pid: 40867 LoopCount: 0</span><br><span class="line">Pid: 40868 LoopCount: 0</span><br><span class="line">Pid: 40866 LoopCount: 1</span><br><span class="line">Pid: 40867 LoopCount: 1</span><br><span class="line">Pid: 40868 LoopCount: 1</span><br><span class="line">Pid: 40867 LoopCount: 2</span><br><span class="line">Pid: 40868 LoopCount: 2</span><br><span class="line">Pid: 40868 LoopCount: 3</span><br><span class="line">Main&#96;process&#96;ended</span><br></pre></td></tr></table></figure>
<p>在调用<code>start</code>和 <code>join</code> 方法后，父进程就可以等待所有子进程都执行完毕后，再打印出结束的结果。</p>
<p>默认情况下，<code>join</code> 是无限期的。也就是说，如果有子进程没有运行完毕，主进程会一直等待。这种情况下，如果子进程出现问题陷入了死循环，主进程也会无限等待下去。怎么解决这个问题呢？可以给<code>join</code>方法传递一个超时参数，代表最长等待秒数。如果子进程没有在这个指定秒数之内完成，会被强制返回，主进程不再会等待。也就是说这个参数设置了主进程等待该子进程的最长时间。</p>
<p>例如这里我们传入 1，代表最长等待 1 秒，代码改写如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">processes = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>, <span class="number">5</span>):</span><br><span class="line">    p = MyProcess(i)</span><br><span class="line">    processes.append(p)</span><br><span class="line">    p.daemon = <span class="literal">True</span></span><br><span class="line">    p.start()</span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> processes:</span><br><span class="line">    p.join(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Pid: 40970 LoopCount: 0</span><br><span class="line">Pid: 40971 LoopCount: 0</span><br><span class="line">Pid: 40970 LoopCount: 1</span><br><span class="line">Pid: 40971 LoopCount: 1</span><br><span class="line">Main&#96;process&#96;ended</span><br></pre></td></tr></table></figure>
<p>可以看到，有的子进程本来要运行 3 秒，结果运行 1 秒就被强制返回了，由于是守护进程，该子进程被终止了。</p>
<p>到这里，我们就了解了守护进程、进程等待和超时设置的用法。</p>
<h2 id="终止进程"><a href="#终止进程" class="headerlink" title="终止进程"></a>终止进程</h2><p>当然，终止进程不止有守护进程这一种做法，我们也可以通过<code>terminate</code>方法来终止某个子进程，另外我们还可以通过 is_alive 方法判断进程是否还在运行。</p>
<p>下面我们来看一个实例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process</span><span class="params">()</span>:</span></span><br><span class="line">    print(<span class="string">'Starting'</span>)</span><br><span class="line">    time.sleep(<span class="number">5</span>)</span><br><span class="line">    print(<span class="string">'Finished'</span>)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    p = multiprocessing.Process(target=process)</span><br><span class="line">    print(<span class="string">'Before:'</span>, p, p.is_alive())</span><br><span class="line">    p.start()</span><br><span class="line">    print(<span class="string">'During:'</span>, p, p.is_alive())</span><br><span class="line">    p.terminate()</span><br><span class="line">    print(<span class="string">'Terminate:'</span>, p, p.is_alive())</span><br><span class="line">    p.join()</span><br><span class="line">    print(<span class="string">'Joined:'</span>, p, p.is_alive())</span><br></pre></td></tr></table></figure>
<p>在上面的例子中，我们用<code>process</code>创建了一个进程，接着调用<code>start</code>方法启动这个进程，然后调用<code>terminate</code>方法将进程终止，最后调用<code>join</code>方法。</p>
<p>另外，在进程运行不同的阶段，我们还通过 is_alive 方法判断当前进程是否还在运行。</p>
<p>运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Before: &lt;Process(Process-1, initial)&gt; False</span><br><span class="line">During: &lt;Process(Process-1, started)&gt; True</span><br><span class="line">Terminate: &lt;Process(Process-1, started)&gt; True</span><br><span class="line">Joined: &lt;Process(Process-1, stopped[SIGTERM])&gt; False</span><br></pre></td></tr></table></figure>
<p>这里有一个值得注意的地方，在调用<code>terminate</code>方法之后，我们用 is_alive 方法获取进程的状态发现依然还是运行状态。在调用<code>join</code>方法之后，is_alive 方法获取进程的运行状态才变为终止状态。</p>
<p>所以，在调用<code>terminate</code>方法之后，记得要调用一下<code>join</code>方法，这里调用<code>join</code>方法可以为进程提供时间来更新对象状态，用来反映出最终的进程终止效果。</p>
<h2 id="进程互斥锁"><a href="#进程互斥锁" class="headerlink" title="进程互斥锁"></a>进程互斥锁</h2><p>在上面的一些实例中，我们可能会遇到如下的运行结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Pid: 73993 LoopCount: 0</span><br><span class="line">Pid: 73993 LoopCount: 1</span><br><span class="line">Pid: 73994 LoopCount: 0Pid: 73994 LoopCount: 1</span><br><span class="line"></span><br><span class="line">Pid: 73994 LoopCount: 2</span><br><span class="line">Pid: 73995 LoopCount: 0</span><br><span class="line">Pid: 73995 LoopCount: 1</span><br><span class="line">Pid: 73995 LoopCount: 2</span><br><span class="line">Pid: 73995 LoopCount: 3</span><br><span class="line">Main&#96;process&#96;ended</span><br></pre></td></tr></table></figure>
<p>我们发现，有的输出结果没有换行。这是什么原因造成的呢？</p>
<p>这种情况是由多个进程并行执行导致的，两个进程同时进行了输出，结果第一个进程的换行没有来得及输出，第二个进程就输出了结果，导致最终输出没有换行。</p>
<p>那如何来避免这种问题？如果我们能保证，多个进程运行期间的任一时间，只能一个进程输出，其他进程等待，等刚才那个进程输出完毕之后，另一个进程再进行输出，这样就不会出现输出没有换行的现象了。</p>
<p>这种解决方案实际上就是实现了进程互斥，避免了多个进程同时抢占临界区（输出）资源。我们可以通过<code>multiprocessing</code>中的 Lock 来实现。Lock，即锁，在一个进程输出时，加锁，其他进程等待。等此进程执行结束后，释放锁，其他进程可以进行输出。</p>
<p>我们首先实现一个不加锁的实例，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span>`multiprocessing`<span class="keyword">import</span> Process, Lock</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyProcess</span><span class="params">(Process)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, loop, lock)</span>:</span></span><br><span class="line">        Process.__init__(self)</span><br><span class="line">        self.loop = loop</span><br><span class="line">        self.lock = lock</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> count <span class="keyword">in</span> range(self.loop):</span><br><span class="line">            time.sleep(<span class="number">0.1</span>)</span><br><span class="line">            <span class="comment"># self.lock.acquire()</span></span><br><span class="line">            print(<span class="string">f'Pid: <span class="subst">&#123;self.pid&#125;</span> LoopCount: <span class="subst">&#123;count&#125;</span>'</span>)</span><br><span class="line">            <span class="comment"># self.lock.release()</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    lock = Lock()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>, <span class="number">15</span>):</span><br><span class="line">        p = MyProcess(i, lock)</span><br><span class="line">        p.start()</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Pid: 74030 LoopCount: 0</span><br><span class="line">Pid: 74031 LoopCount: 0</span><br><span class="line">Pid: 74032 LoopCount: 0</span><br><span class="line">Pid: 74033 LoopCount: 0</span><br><span class="line">Pid: 74034 LoopCount: 0</span><br><span class="line">Pid: 74030 LoopCount: 1</span><br><span class="line">Pid: 74031 LoopCount: 1</span><br><span class="line">Pid: 74032 LoopCount: 1Pid: 74033 LoopCount: 1</span><br><span class="line"></span><br><span class="line">Pid: 74034 LoopCount: 1</span><br><span class="line">Pid: 74030 LoopCount: 2</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>可以看到运行结果中有些输出已经出现了不换行的问题。</p>
<p>我们对其加锁，取消掉刚才代码中的两行注释，重新运行，运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Pid: 74061 LoopCount: 0</span><br><span class="line">Pid: 74062 LoopCount: 0</span><br><span class="line">Pid: 74063 LoopCount: 0</span><br><span class="line">Pid: 74064 LoopCount: 0</span><br><span class="line">Pid: 74065 LoopCount: 0</span><br><span class="line">Pid: 74061 LoopCount: 1</span><br><span class="line">Pid: 74062 LoopCount: 1</span><br><span class="line">Pid: 74063 LoopCount: 1</span><br><span class="line">Pid: 74064 LoopCount: 1</span><br><span class="line">Pid: 74065 LoopCount: 1</span><br><span class="line">Pid: 74061 LoopCount: 2</span><br><span class="line">Pid: 74062 LoopCount: 2</span><br><span class="line">Pid: 74064 LoopCount: 2</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>这时输出效果就正常了。</p>
<p>所以，在访问一些临界区资源时，使用 Lock 可以有效避免进程同时占用资源而导致的一些问题。</p>
<h2 id="信号量"><a href="#信号量" class="headerlink" title="信号量"></a>信号量</h2><p>进程互斥锁可以使同一时刻只有一个进程能访问共享资源，如上面的例子所展示的那样，在同一时刻只能有一个进程输出结果。但有时候我们需要允许多个进程来访问共享资源，同时还需要限制能访问共享资源的进程的数量。</p>
<p>这种需求该如何实现呢？可以用信号量，信号量是进程同步过程中一个比较重要的角色。它可以控制临界资源的数量，实现多个进程同时访问共享资源，限制进程的并发量。</p>
<p>如果你学过操作系统，那么一定对这方面非常了解，如果你还不了解信号量是什么，可以先熟悉一下这个概念。</p>
<p>我们可以用<code>multiprocessing</code>库中的 Semaphore 来实现信号量。</p>
<p>那么接下来我们就用一个实例来演示一下进程之间利用 Semaphore 做到多个进程共享资源，同时又限制同时可访问的进程数量，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span>`multiprocessing`<span class="keyword">import</span> Process, Semaphore, Lock, Queue</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">buffer = Queue(<span class="number">10</span>)</span><br><span class="line">empty = Semaphore(<span class="number">2</span>)</span><br><span class="line">full = Semaphore(<span class="number">0</span>)</span><br><span class="line">lock = Lock()</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Consumer</span><span class="params">(Process)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">global</span> buffer, empty, full, lock</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            full.acquire()</span><br><span class="line">            lock.acquire()</span><br><span class="line">            buffer.get()</span><br><span class="line">            print(<span class="string">'Consumer pop an element'</span>)</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">            lock.release()</span><br><span class="line">            empty.release()</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Producer</span><span class="params">(Process)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">global</span> buffer, empty, full, lock</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            empty.acquire()</span><br><span class="line">            lock.acquire()</span><br><span class="line">            buffer.put(<span class="number">1</span>)</span><br><span class="line">            print(<span class="string">'Producer append an element'</span>)</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">            lock.release()</span><br><span class="line">            full.release()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    p = Producer()</span><br><span class="line">    c = Consumer()</span><br><span class="line">    p.daemon = c.daemon = <span class="literal">True</span></span><br><span class="line">    p.start()</span><br><span class="line">    c.start()</span><br><span class="line">    p.join()</span><br><span class="line">    c.join()</span><br><span class="line">    print(<span class="string">'Main`process`Ended'</span>)</span><br></pre></td></tr></table></figure>
<p>如上代码实现了经典的生产者和消费者问题。它定义了两个进程类，一个是消费者，一个是生产者。</p>
<p>另外，这里使用<code>multiprocessing</code>中的 Queue 定义了一个共享队列，然后定义了两个信号量 Semaphore，一个代表缓冲区空余数，一个表示缓冲区占用数。</p>
<p>生产者 Producer 使用 acquire 方法来占用一个缓冲区位置，缓冲区空闲区大小减 1，接下来进行加锁，对缓冲区进行操作，然后释放锁，最后让代表占用的缓冲区位置数量加 1，消费者则相反。</p>
<p>运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Producer append an element</span><br><span class="line">Producer append an element</span><br><span class="line">Consumer pop an element</span><br><span class="line">Consumer pop an element</span><br><span class="line">Producer append an element</span><br><span class="line">Producer append an element</span><br><span class="line">Consumer pop an element</span><br><span class="line">Consumer pop an element</span><br><span class="line">Producer append an element</span><br><span class="line">Producer append an element</span><br><span class="line">Consumer pop an element</span><br><span class="line">Consumer pop an element</span><br><span class="line">Producer append an element</span><br><span class="line">Producer append an element</span><br></pre></td></tr></table></figure>
<p>我们发现两个进程在交替运行，生产者先放入缓冲区物品，然后消费者取出，不停地进行循环。 你可以通过上面的例子来体会信号量 Semaphore 的用法，通过 Semaphore 我们很好地控制了进程对资源的并发访问数量。</p>
<h2 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h2><p>在上面的例子中我们使用 Queue 作为进程通信的共享队列使用。</p>
<p>而如果我们把上面程序中的 Queue 换成普通的 list，是完全起不到效果的，因为进程和进程之间的资源是不共享的。即使在一个进程中改变了这个 list，在另一个进程也不能获取到这个 list 的状态，所以声明全局变量对多进程是没有用处的。</p>
<p>那进程如何共享数据呢？可以用 Queue，即队列。当然这里的队列指的是<code>multiprocessing</code>里面的 Queue。</p>
<p>依然用上面的例子，我们一个进程向队列中放入随机数据，然后另一个进程取出数据。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span>`multiprocessing`<span class="keyword">import</span> Process, Semaphore, Lock, Queue</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">buffer = Queue(<span class="number">10</span>)</span><br><span class="line">empty = Semaphore(<span class="number">2</span>)</span><br><span class="line">full = Semaphore(<span class="number">0</span>)</span><br><span class="line">lock = Lock()</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Consumer</span><span class="params">(Process)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">global</span> buffer, empty, full, lock</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            full.acquire()</span><br><span class="line">            lock.acquire()</span><br><span class="line">            print(<span class="string">f'Consumer get <span class="subst">&#123;buffer.get()&#125;</span>'</span>)</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">            lock.release()</span><br><span class="line">            empty.release()</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Producer</span><span class="params">(Process)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">global</span> buffer, empty, full, lock</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            empty.acquire()</span><br><span class="line">            lock.acquire()</span><br><span class="line">            num = random()</span><br><span class="line">            print(<span class="string">f'Producer put <span class="subst">&#123;num&#125;</span>'</span>)</span><br><span class="line">            buffer.put(num)</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">            lock.release()</span><br><span class="line">            full.release()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    p = Producer()</span><br><span class="line">    c = Consumer()</span><br><span class="line">    p.daemon = c.daemon = <span class="literal">True</span></span><br><span class="line">    p.start()</span><br><span class="line">    c.start()</span><br><span class="line">    p.join()</span><br><span class="line">    c.join()</span><br><span class="line">    print(<span class="string">'Main`process`Ended'</span>)</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Producer put  0.719213647437</span><br><span class="line">Producer put  0.44287326683</span><br><span class="line">Consumer get 0.719213647437</span><br><span class="line">Consumer get 0.44287326683</span><br><span class="line">Producer put  0.722859424381</span><br><span class="line">Producer put  0.525321338921</span><br><span class="line">Consumer get 0.722859424381</span><br><span class="line">Consumer get 0.525321338921</span><br></pre></td></tr></table></figure>
<p>在上面的例子中我们声明了两个进程，一个进程为生产者 Producer，另一个为消费者 Consumer，生产者不断向 Queue 里面添加随机数，消费者不断从队列里面取随机数。</p>
<p>生产者在放数据的时候调用了 Queue 的 put 方法，消费者在取的时候使用了 get 方法，这样我们就通过 Queue 实现两个进程的数据共享了。</p>
<h2 id="管道"><a href="#管道" class="headerlink" title="管道"></a>管道</h2><p>刚才我们使用 Queue 实现了进程间的数据共享，那么进程之间直接通信，如收发信息，用什么比较好呢？可以用 Pipe，管道。</p>
<p>管道，我们可以把它理解为两个进程之间通信的通道。管道可以是单向的，即 half-duplex：一个进程负责发消息，另一个进程负责收消息；也可以是双向的 duplex，即互相收发消息。</p>
<p>默认声明 Pipe 对象是双向管道，如果要创建单向管道，可以在初始化的时候传入 deplex 参数为 False。</p>
<p>我们用一个实例来感受一下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span>`multiprocessing`<span class="keyword">import</span> Process, Pipe</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Consumer</span><span class="params">(Process)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, pipe)</span>:</span></span><br><span class="line">        Process.__init__(self)</span><br><span class="line">        self.pipe = pipe</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.pipe.send(<span class="string">'Consumer Words'</span>)</span><br><span class="line">        print(<span class="string">f'Consumer Received: <span class="subst">&#123;self.pipe.recv()&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Producer</span><span class="params">(Process)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, pipe)</span>:</span></span><br><span class="line">        Process.__init__(self)</span><br><span class="line">        self.pipe = pipe</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">f'Producer Received: <span class="subst">&#123;self.pipe.recv()&#125;</span>'</span>)</span><br><span class="line">        self.pipe.send(<span class="string">'Producer Words'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    pipe = Pipe()</span><br><span class="line">    p = Producer(pipe[<span class="number">0</span>])</span><br><span class="line">    c = Consumer(pipe[<span class="number">1</span>])</span><br><span class="line">    p.daemon = c.daemon = <span class="literal">True</span></span><br><span class="line">    p.start()</span><br><span class="line">    c.start()</span><br><span class="line">    p.join()</span><br><span class="line">    c.join()</span><br><span class="line">    print(<span class="string">'Main`process`Ended'</span>)</span><br></pre></td></tr></table></figure>
<p>在这个例子里我们声明了一个默认为双向的管道，然后将管道的两端分别传给两个进程。两个进程互相收发。观察一下结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Producer Received: Consumer Words</span><br><span class="line">Consumer Received: Producer Words</span><br><span class="line">Main&#96;process&#96;Ended</span><br></pre></td></tr></table></figure>
<p>管道 Pipe 就像进程之间搭建的桥梁，利用它我们就可以很方便地实现进程间通信了。</p>
<h2 id="进程池"><a href="#进程池" class="headerlink" title="进程池"></a>进程池</h2><p>在前面，我们讲了可以使用<code>process</code>来创建进程，同时也讲了如何用 Semaphore 来控制进程的并发执行数量。</p>
<p>假如现在我们遇到这么一个问题，我有 10000 个任务，每个任务需要启动一个进程来执行，并且一个进程运行完毕之后要紧接着启动下一个进程，同时我还需要控制进程的并发数量，不能并发太高，不然 CPU 处理不过来（如果同时运行的进程能维持在一个最高恒定值当然利用率是最高的）。</p>
<p>那么我们该如何来实现这个需求呢？</p>
<p>用<code>process</code>和 Semaphore 可以实现，但是实现起来比较我们可以用<code>process</code>和 Semaphore 解决问题，但是实现起来比较烦琐。而这种需求在平时又是非常常见的。此时，我们就可以派上进程池了，即<code>multiprocessing</code>中的 Pool。</p>
<p>Pool 可以提供指定数量的进程，供用户调用，当有新的请求提交到 pool 中时，如果池还没有满，就会创建一个新的进程用来执行该请求；但如果池中的进程数已经达到规定最大值，那么该请求就会等待，直到池中有进程结束，才会创建新的进程来执行它。</p>
<p>我们用一个实例来实现一下，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span>`multiprocessing`<span class="keyword">import</span> Pool</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">function</span><span class="params">(index)</span>:</span></span><br><span class="line">    print(<span class="string">f'Start process: <span class="subst">&#123;index&#125;</span>'</span>)</span><br><span class="line">    time.sleep(<span class="number">3</span>)</span><br><span class="line">    print(<span class="string">f'End`process`<span class="subst">&#123;index&#125;</span>'</span>, )</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    pool = Pool(processes=<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">        pool.apply_async(function, args=(i,))</span><br><span class="line">    print(<span class="string">'Main`process`started'</span>)</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br><span class="line">    print(<span class="string">'Main`process`ended'</span>)</span><br></pre></td></tr></table></figure>
<p>在这个例子中我们声明了一个大小为 3 的进程池，通过 processes 参数来指定，如果不指定，那么会自动根据处理器内核来分配进程数。接着我们使用 apply_async 方法将进程添加进去，<code>args</code>可以用来传递参数。</p>
<p>运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Main&#96;process&#96;started</span><br><span class="line">Start process: 0</span><br><span class="line">Start process: 1</span><br><span class="line">Start process: 2</span><br><span class="line">End&#96;process&#96;0</span><br><span class="line">End&#96;process&#96;1</span><br><span class="line">End&#96;process&#96;2</span><br><span class="line">Start process: 3</span><br><span class="line">End&#96;process&#96;3</span><br><span class="line">Main&#96;process&#96;ended</span><br></pre></td></tr></table></figure>
<p>进程池大小为 3，所以最初可以看到有 3 个进程同时执行，第4个进程在等待，在有进程运行完毕之后，第4个进程马上跟着运行，出现了如上的运行效果。</p>
<p>最后，我们要记得调用 close 方法来关闭进程池，使其不再接受新的任务，然后调用<code>join</code>方法让主进程等待子进程的退出，等子进程运行完毕之后，主进程接着运行并结束。</p>
<p>不过上面的写法多少有些烦琐，这里再介绍进程池一个更好用的 map 方法，可以将上述写法简化很多。</p>
<p>map 方法是怎么用的呢？第一个参数就是要启动的进程对应的执行方法，第 2 个参数是一个可迭代对象，其中的每个元素会被传递给这个执行方法。</p>
<p>举个例子：现在我们有一个 list，里面包含了很多 URL，另外我们也定义了一个方法用来抓取每个 URL 内容并解析，那么我们可以直接在 map 的第一个参数传入方法名，第 2 个参数传入 URL 数组。</p>
<p>我们用一个实例来感受一下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span>`multiprocessing`<span class="keyword">import</span> Pool</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.error</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scrape</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        urllib.request.urlopen(url)</span><br><span class="line">        print(<span class="string">f'URL <span class="subst">&#123;url&#125;</span> Scraped'</span>)</span><br><span class="line">    <span class="keyword">except</span> (urllib.error.HTTPError, urllib.error.URLError):</span><br><span class="line">        print(<span class="string">f'URL <span class="subst">&#123;url&#125;</span> not Scraped'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    pool = Pool(processes=<span class="number">3</span>)</span><br><span class="line">    urls = [</span><br><span class="line">        <span class="string">'https://www.baidu.com'</span>,</span><br><span class="line">        <span class="string">'http://www.meituan.com/'</span>,</span><br><span class="line">        <span class="string">'http://blog.csdn.net/'</span>,</span><br><span class="line">        <span class="string">'http://xxxyxxx.net'</span></span><br><span class="line">    ]</span><br><span class="line">    pool.map(scrape, urls)</span><br><span class="line">    pool.close()</span><br></pre></td></tr></table></figure>
<p>这个例子中我们先定义了一个 scrape 方法，它接收一个参数 url，这里就是请求了一下这个链接，然后输出爬取成功的信息，如果发生错误，则会输出爬取失败的信息。</p>
<p>首先我们要初始化一个 Pool，指定进程数为 3。然后我们声明一个 urls 列表，接着我们调用了 map 方法，第 1 个参数就是进程对应的执行方法，第 2 个参数就是 urls 列表，map 方法会依次将 urls 的每个元素作为 scrape 的参数传递并启动一个新的进程，加到进程池中执行。</p>
<p>运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">URL https:&#x2F;&#x2F;www.baidu.com Scraped</span><br><span class="line">URL http:&#x2F;&#x2F;xxxyxxx.net not Scraped</span><br><span class="line">URL http:&#x2F;&#x2F;blog.csdn.net&#x2F; Scraped</span><br><span class="line">URL http:&#x2F;&#x2F;www.meituan.com&#x2F; Scraped</span><br></pre></td></tr></table></figure>
<p>这样，我们就可以实现 3 个进程并行运行。不同的进程相互独立地输出了对应的爬取结果。</p>
<p>可以看到，我们利用 Pool 的 map 方法非常方便地实现了多进程的执行。后面我们也会在实战案例中结合进程池来实现数据的爬取。</p>
<p>以上便是 Python 中多进程的基本用法，本节内容比较多，后面的实战案例也会用到这些内容，需要好好掌握。</p>
]]></content>
      <categories>
        <category>Spider</category>
      </categories>
  </entry>
  <entry>
    <title>Python爬虫（五）多线程基本原理</title>
    <url>/posts/4cff7d80.html</url>
    <content><![CDATA[<p>我们知道，在一台计算机中，我们可以同时打开许多软件，比如同时浏览网页、听音乐、打字等等，看似非常正常。但仔细想想，为什么计算机可以做到这么多软件同时运行呢？这就涉及到计算机中的两个重要概念：多进程和多线程了。</p>
<p>同样，在编写爬虫程序的时候，为了提高爬取效率，我们可能想同时运行多个爬虫任务。这里同样需要涉及多进程和多线程的知识。</p>
<p>本课时，我们就先来了解一下多线程的基本原理，以及在 Python 中如何实现多线程。</p>
<h1 id="多线程的含义"><a href="#多线程的含义" class="headerlink" title="多线程的含义"></a>多线程的含义</h1><p>说起多线程，就不得不先说什么是线程。然而想要弄明白什么是线程，又不得不先说什么是进程。</p>
<p>进程我们可以理解为是一个<strong>可以独立运行的程序单位</strong>，比如打开一个浏览器，这就开启了一个浏览器进程；打开一个文本编辑器，这就开启了一个文本编辑器进程。但一个进程中是可以同时处理很多事情的，比如在浏览器中，我们可以在多个选项卡中打开多个页面，有的页面在播放音乐，有的页面在播放视频，有的网页在播放动画，它们可以同时运行，互不干扰。为什么能同时做到同时运行这么多的任务呢？这里就需要引出线程的概念了，其实这一个个任务，实际上就对应着一个个线程的执行。</p>
<p>而进程呢？它就是<strong>线程的集合</strong>，进程就是由一个或多个线程构成的，<strong>线程是操作系统进行运算调度的最小单位</strong>，是进程中的一个最小运行单元。比如上面所说的浏览器进程，其中的播放音乐就是一个线程，播放视频也是一个线程，当然其中还有很多其他的线程在同时运行，这些线程的并发或并行执行最后使得整个浏览器可以同时运行这么多的任务。</p>
<p>了解了线程的概念，多线程就很容易理解了，<strong>多线程就是一个进程中同时执行多个线程</strong>，前面所说的浏览器的情景就是典型的多线程执行。</p>
<h1 id="并发和并行"><a href="#并发和并行" class="headerlink" title="并发和并行"></a>并发和并行</h1><p>说到多进程和多线程，这里就需要再讲解两个概念，那就是并发和并行。我们知道，一个程序在计算机中运行，其底层是处理器通过运行一条条的指令来实现的。</p>
<p><strong>并发</strong>，英文叫作 concurrency。它是指同一时刻只能有一条指令执行，但是多个线程的对应的指令被快速轮换地执行。比如一个处理器，它先执行线程 A 的指令一段时间，再执行线程 B 的指令一段时间，再切回到线程 A 执行一段时间。</p>
<p>由于处理器执行指令的速度和切换的速度非常非常快，人完全感知不到计算机在这个过程中有多个线程切换上下文执行的操作，这就使得宏观上看起来多个线程在同时运行。但<strong>微观上只是这个处理器在连续不断地在多个线程之间切换和执行</strong>，每个线程的执行一定会占用这个处理器一个时间片段，<strong>同一时刻，其实只有一个线程在执行</strong>。</p>
<p><strong>并行</strong>，英文叫作 parallel。它是指<strong>同一时刻，有多条指令在多个处理器上同时执行，并行必须要依赖于多个处理器</strong>。不论是从宏观上还是微观上，多个线程都是在同一时刻一起执行的。</p>
<p>并行只能在多处理器系统中存在，<strong>如果我们的计算机处理器只有一个核，那就不可能实现并行</strong>。而并发在单处理器和多处理器系统中都是可以存在的，因为仅靠一个核，就可以实现并发。</p>
<p>举个例子，比如系统处理器需要同时运行多个线程。如果系统处理器只有一个核，那它只能通过并发的方式来运行这些线程。如果系统处理器有多个核，当一个核在执行一个线程时，另一个核可以执行另一个线程，这样这两个线程就实现了并行执行，当然其他的线程也可能和另外的线程处在同一个核上执行，它们之间就是并发执行。具体的执行方式，就取决于操作系统的调度了。</p>
<h1 id="多线程适用场景"><a href="#多线程适用场景" class="headerlink" title="多线程适用场景"></a>多线程适用场景</h1><p>在一个程序进程中，有一些操作是比较耗时或者需要等待的，比如等待数据库的查询结果的返回，等待网页结果的响应。如果使用单线程，处理器必须要等到这些操作完成之后才能继续往下执行其他操作，而这个线程在等待的过程中，处理器明显是可以来执行其他的操作的。<strong>如果使用多线程，处理器就可以在某个线程等待的时候，去执行其他的线程，从而从整体上提高执行效率</strong>。</p>
<p>像上述场景，线程在执行过程中很多情况下是需要等待的。比如网络爬虫就是一个非常典型的例子，爬虫在向服务器发起请求之后，<strong>有一段时间必须要等待服务器的响应返回</strong>，这种任务就属于 IO 密集型任务。对于这种任务，如果我们启用多线程，处理器就可以在某个线程等待的过程中去处理其他的任务，从而提高整体的爬取效率。</p>
<p>但并不是所有的任务都是 IO 密集型任务，还有一种任务叫作<strong>计算密集型任务</strong>，也可以称之为 CPU 密集型任务。顾名思义，就是任务的运行一直需要处理器的参与。此时如果我们开启了多线程，一个处理器从一个计算密集型任务切换到切换到另一个计算密集型任务上去，处理器依然不会停下来，始终会忙于计算，这样并不会节省总体的时间，因为需要处理的任务的计算总量是不变的。如果线程数目过多，反而还会在线程切换的过程中多耗费一些时间，整体效率会变低。</p>
<p>所以，<strong>如果任务不全是计算密集型任务，我们可以使用多线程来提高程序整体的执行效率</strong>。尤其对于网络爬虫这种 IO 密集型任务来说，使用多线程会大大提高程序整体的爬取效率。</p>
<h1 id="Python-实现多线程"><a href="#Python-实现多线程" class="headerlink" title="Python 实现多线程"></a>Python 实现多线程</h1><p>在 Python 中，实现多线程的模块叫作 <code>threading</code>，是 Python 自带的模块。下面我们来了解下使用 <code>threading</code> 实现多线程的方法。</p>
<h2 id="Thread-直接创建子线程"><a href="#Thread-直接创建子线程" class="headerlink" title="Thread 直接创建子线程"></a>Thread 直接创建子线程</h2><p>首先，我们可以使用 <code>Thread</code> 类来创建一个线程，创建时需要指定 target 参数为运行的方法名称，如果被调用的方法需要传入额外的参数，则可以通过 <code>Thread</code> 的 <code>args</code> 参数来指定。示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">target</span><span class="params">(second)</span>:</span></span><br><span class="line">    print(<span class="string">f'Threading <span class="subst">&#123;threading.current_thread().name&#125;</span> is running'</span>)</span><br><span class="line">    print(<span class="string">f'Threading <span class="subst">&#123;threading.current_thread().name&#125;</span> sleep <span class="subst">&#123;second&#125;</span>s'</span>)</span><br><span class="line">    time.sleep(second)</span><br><span class="line">    print(<span class="string">f'Threading <span class="subst">&#123;threading.current_thread().name&#125;</span> is ended'</span>)</span><br><span class="line">print(<span class="string">f'Threading <span class="subst">&#123;threading.current_thread().name&#125;</span> is running'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">5</span>]:</span><br><span class="line">    thread = threading.Thread(target=target, args=[i])</span><br><span class="line">    thread.start()</span><br><span class="line">print(<span class="string">f'Threading <span class="subst">&#123;threading.current_thread().name&#125;</span> is ended'</span>)</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Threading MainThread is running</span><br><span class="line">Threading Thread-1 is running</span><br><span class="line">Threading Thread-1 sleep 1s</span><br><span class="line">Threading Thread-2 is running</span><br><span class="line">Threading Thread-2 sleep 5s</span><br><span class="line">Threading MainThread is ended</span><br><span class="line">Threading Thread-1 is ended</span><br><span class="line">Threading Thread-2 is ended</span><br></pre></td></tr></table></figure>
<p>在这里我们首先声明了一个方法，叫作 <code>target</code>，它接收一个参数为 <code>second</code>，通过方法的实现可以发现，这个方法其实就是执行了一个 <code>time.sleep</code> 休眠操作，<code>second</code> 参数就是休眠秒数，其前后都 <code>print</code> 了一些内容，其中线程的名字我们通过 <code>threading.current_thread().name</code> 来获取出来，如果是主线程的话，其值就是 <code>MainThread</code>，如果是子线程的话，其值就是 <code>Thread-*</code>。</p>
<p>然后我们通过 <code>Thead</code> 类新建了两个线程，<code>target</code> 参数就是刚才我们所定义的方法名，<code>args</code> 以列表的形式传递。两次循环中，这里 i 分别就是 1 和 5，这样两个线程就分别休眠 1 秒和 5 秒，声明完成之后，我们调用 <code>start</code> 方法即可开始线程的运行。</p>
<p>观察结果我们可以发现，这里一共产生了三个线程，分别是主线程 <code>MainThread</code> 和两个子线程 <code>Thread-1</code>、<code>Thread-2</code>。另外我们观察到，主线程首先运行结束，紧接着 <code>Thread-1</code>、<code>Thread-2</code>才接连运行结束，分别间隔了 1 秒和 4 秒。这说明主线程并没有等待子线程运行完毕才结束运行，而是直接退出了，有点不符合常理。</p>
<p>如果我们想要主线程等待子线程运行完毕之后才退出，可以让每个子线程对象都调用下 <code>join</code> 方法，实现如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">threads = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">5</span>]:</span><br><span class="line">    thread = threading.Thread(target=target, args=[i])</span><br><span class="line">    threads.append(thread)</span><br><span class="line">    thread.start()</span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> thread <span class="keyword">in</span> threads:</span><br><span class="line">    thread.join()</span><br></pre></td></tr></table></figure>
<p>这样，主线程必须等待子线程都运行结束，主线程才继续运行并结束。</p>
<h2 id="继承-Thread-类创建子线程"><a href="#继承-Thread-类创建子线程" class="headerlink" title="继承 Thread 类创建子线程"></a>继承 Thread 类创建子线程</h2><p>另外，我们也可以通过继承 <code>Thread</code> 类的方式创建一个线程，该线程需要执行的方法写在类的 <code>run</code> 方法里面即可。上面的例子的等价改写为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyThread</span><span class="params">(threading.Thread)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, second)</span>:</span></span><br><span class="line">        threading.Thread.__init__(self)</span><br><span class="line">        self.second = second</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">f'Threading <span class="subst">&#123;threading.current_thread().name&#125;</span> is running'</span>)</span><br><span class="line">        print(<span class="string">f'Threading <span class="subst">&#123;threading.current_thread().name&#125;</span> sleep <span class="subst">&#123;self.second&#125;</span>s'</span>)</span><br><span class="line">        time.sleep(self.second)</span><br><span class="line">        print(<span class="string">f'Threading <span class="subst">&#123;threading.current_thread().name&#125;</span> is ended'</span>)</span><br><span class="line">        </span><br><span class="line">print(<span class="string">f'Threading <span class="subst">&#123;threading.current_thread().name&#125;</span> is running'</span>)</span><br><span class="line">threads = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">5</span>]:</span><br><span class="line">    thread = MyThread(i)</span><br><span class="line">    threads.append(thread)</span><br><span class="line">    thread.start()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> thread <span class="keyword">in</span> threads:</span><br><span class="line">    thread.join()</span><br><span class="line">print(<span class="string">f'Threading <span class="subst">&#123;threading.current_thread().name&#125;</span> is ended'</span>)</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Threading MainThread <span class="keyword">is</span> running </span><br><span class="line">Threading Thread<span class="number">-1</span> <span class="keyword">is</span> running </span><br><span class="line">Threading Thread<span class="number">-1</span> sleep <span class="number">1</span>s </span><br><span class="line">Threading Thread<span class="number">-2</span> <span class="keyword">is</span> running </span><br><span class="line">Threading Thread<span class="number">-2</span> sleep <span class="number">5</span>s </span><br><span class="line">Threading Thread<span class="number">-1</span> <span class="keyword">is</span> ended </span><br><span class="line">Threading Thread<span class="number">-2</span> <span class="keyword">is</span> ended </span><br><span class="line">Threading MainThread <span class="keyword">is</span> ended</span><br></pre></td></tr></table></figure>
<p>可以看到，两种实现方式，其运行效果是相同的。</p>
<h2 id="守护线程"><a href="#守护线程" class="headerlink" title="守护线程"></a>守护线程</h2><p>在线程中有一个叫作守护线程的概念，如果一个线程被设置为守护线程，那么意味着这个线程是“不重要”的，这意味着，如果主线程结束了而该守护线程还没有运行完，那么它将会被强制结束。在 Python 中我们可以通过 <code>setDaemon</code> 方法来将某个线程设置为守护线程。</p>
<p>示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">target</span><span class="params">(second)</span>:</span></span><br><span class="line">    print(<span class="string">f'Threading <span class="subst">&#123;threading.current_thread().name&#125;</span> is running'</span>)</span><br><span class="line">    print(<span class="string">f'Threading <span class="subst">&#123;threading.current_thread().name&#125;</span> sleep <span class="subst">&#123;second&#125;</span>s'</span>)</span><br><span class="line">    time.sleep(second)</span><br><span class="line">    print(<span class="string">f'Threading <span class="subst">&#123;threading.current_thread().name&#125;</span> is ended'</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">f'Threading <span class="subst">&#123;threading.current_thread().name&#125;</span> is running'</span>)</span><br><span class="line">t1 = threading.Thread(target=target, args=[<span class="number">2</span>])</span><br><span class="line">t1.start()</span><br><span class="line">t2 = threading.Thread(target=target, args=[<span class="number">5</span>])</span><br><span class="line">t2.setDaemon(<span class="literal">True</span>)</span><br><span class="line">t2.start()</span><br><span class="line">print(<span class="string">f'Threading <span class="subst">&#123;threading.current_thread().name&#125;</span> is ended'</span>)</span><br></pre></td></tr></table></figure>
<p>在这里我们通过 <code>setDaemon</code> 方法将 <code>t2</code> 设置为了守护线程，这样主线程在运行完毕时，<code>t2</code> 线程会随着线程的结束而结束。</p>
<p>运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Threading MainThread is running </span><br><span class="line">Threading Thread-1 is running </span><br><span class="line">Threading Thread-1 sleep 2s </span><br><span class="line">Threading Thread-2 is running </span><br><span class="line">Threading Thread-2 sleep 5s </span><br><span class="line">Threading MainThread is ended </span><br><span class="line">Threading Thread-1 is ended</span><br></pre></td></tr></table></figure>
<p>可以看到，我们没有看到 <code>Thread-2</code> 打印退出的消息，<code>Thread-2</code> 随着主线程的退出而退出了。</p>
<p>不过细心的你可能会发现，这里并没有调用 <code>join</code> 方法，如果我们让 <code>t1</code> 和 <code>t2</code> 都调用<code>join</code>方法，主线程就会仍然等待各个子线程执行完毕再退出，不论其是否是守护线程。</p>
<h1 id="互斥锁"><a href="#互斥锁" class="headerlink" title="互斥锁"></a>互斥锁</h1><p>在一个进程中的多个线程是共享资源的，比如在一个进程中，有一个全局变量 <code>count</code> 用来计数，现在我们声明多个线程，每个线程运行时都给 <code>count</code> 加 1，让我们来看看效果如何，代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyThread</span><span class="params">(threading.Thread)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        threading.Thread.__init__(self)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">global</span> count</span><br><span class="line">        temp = count + <span class="number">1</span></span><br><span class="line">        time.sleep(<span class="number">0.001</span>)</span><br><span class="line">        count = temp</span><br><span class="line"></span><br><span class="line">threads = []</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    thread = MyThread()</span><br><span class="line">    thread.start()</span><br><span class="line">    threads.append(thread)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> thread <span class="keyword">in</span> threads:</span><br><span class="line">    thread.join()</span><br><span class="line">print(<span class="string">f'Final count: <span class="subst">&#123;count&#125;</span>'</span>)</span><br></pre></td></tr></table></figure>
<p>在这里，我们声明了 1000 个线程，每个线程都是现取到当前的全局变量 <code>count</code> 值，然后休眠一小段时间，然后对 <code>count</code> 赋予新的值。</p>
<p>那这样，按照常理来说，最终的 <code>count</code>值应该为 1000。但其实不然，我们来运行一下看看。</p>
<p>运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Final count: 69</span><br></pre></td></tr></table></figure>
<p>最后的结果居然只有 69，而且多次运行或者换个环境运行结果是不同的。</p>
<p>这是为什么呢？因为 <code>count</code> 这个值是共享的，每个线程都可以在执行 temp = count 这行代码时拿到当前 count 的值，但是这些线程中的一些线程可能是并发或者并行执行的，这就导致不同的线程拿到的可能是同一个 <code>count</code> 值，最后导致有些线程的 <code>count</code> 的加 1 操作并没有生效，导致最后的结果偏小。</p>
<p>所以，如果多个线程同时对某个数据进行读取或修改，就会出现不可预料的结果。为了避免这种情况，我们需要对多个线程进行同步，要实现同步，我们可以对需要操作的数据进行加锁保护，这里就需要用到 <code>threading.Lock</code> 了。</p>
<p>加锁保护是什么意思呢？就是说，某个线程在对数据进行操作前，需要先加锁，这样其他的线程发现被加锁了之后，就无法继续向下执行，会一直等待锁被释放，只有加锁的线程把锁释放了，其他的线程才能继续加锁并对数据做修改，修改完了再释放锁。这样可以确保同一时间只有一个线程操作数据，多个线程不会再同时读取和修改同一个数据，这样最后的运行结果就是对的了。</p>
<p>我们可以将代码修改为如下内容：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyThread</span><span class="params">(threading.Thread)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        threading.Thread.__init__(self)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">global</span> count</span><br><span class="line">        lock.acquire()</span><br><span class="line">        temp = count + <span class="number">1</span></span><br><span class="line">        time.sleep(<span class="number">0.001</span>)</span><br><span class="line">        count = temp</span><br><span class="line">        lock.release()</span><br><span class="line"></span><br><span class="line">lock = threading.Lock()</span><br><span class="line">threads = []</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    thread = MyThread()</span><br><span class="line">    thread.start()</span><br><span class="line">    threads.append(thread)</span><br><span class="line"><span class="keyword">for</span> thread <span class="keyword">in</span> threads:</span><br><span class="line">    thread.join()</span><br><span class="line">print(<span class="string">f'Final count: <span class="subst">&#123;count&#125;</span>'</span>)</span><br></pre></td></tr></table></figure>
<p>在这里我们声明了一个 <code>lock</code> 对象，其实就是 <code>threading.Lock</code> 的一个实例，然后在 <code>run</code> 方法里面，获取 <code>count</code> 前先加锁，修改完 <code>count</code> 之后再释放锁，这样多个线程就不会同时获取和修改 <code>count</code> 的值了。</p>
<p>运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Final count: 1000</span><br></pre></td></tr></table></figure>
<p>这样运行结果就正常了。</p>
<p>关于 Python 多线程的内容，这里暂且先介绍这些，关于 <code>theading</code> 更多的使用方法，如信号量、队列等，可以参考官方文档：<a href="https://docs.python.org/zh-cn/3.7/library/threading.html#module-threading。" target="_blank" rel="noopener">https://docs.python.org/zh-cn/3.7/library/threading.html#module-threading。</a></p>
<h1 id="Python-多线程的问题"><a href="#Python-多线程的问题" class="headerlink" title="Python 多线程的问题"></a>Python 多线程的问题</h1><p>由于 Python 中 GIL 的限制，导致不论是在单核还是多核条件下，在同一时刻只能运行一个线程，导致 Python 多线程无法发挥多核并行的优势。</p>
<p>GIL 全称为 Global Interpreter Lock，中文翻译为全局解释器锁，其最初设计是出于数据安全而考虑的。</p>
<p>在 Python 多线程下，每个线程的执行方式如下：</p>
<ul>
<li>获取 <code>GIL</code></li>
<li>执行对应线程的代码</li>
<li>释放 <code>GIL</code></li>
</ul>
<p>可见，某个线程想要执行，必须先拿到 GIL，我们可以把 GIL 看作是通行证，并且在一个 Python 进程中，GIL 只有一个。拿不到通行证的线程，就不允许执行。这样就会导致，即使是多核条件下，一个 Python 进程下的多个线程，同一时刻也只能执行一个线程。</p>
<p>不过对于爬虫这种 IO 密集型任务来说，这个问题影响并不大。而对于计算密集型任务来说，由于 GIL 的存在，多线程总体的运行效率相比可能反而比单线程更低。</p>
]]></content>
      <categories>
        <category>Spider</category>
      </categories>
  </entry>
  <entry>
    <title>Python爬虫（四）Session 与 Cookies</title>
    <url>/posts/8c4e03b4.html</url>
    <content><![CDATA[<p>我们在浏览网站的过程中，经常会遇到需要登录的情况，而有些网页只有登录之后才可以访问，而且登录之后可以连续访问很多次网站，但是有时候过一段时间就需要重新登录。</p>
<p>还有一些网站，在打开浏览器时就自动登录了，而且很长时间都不会失效，这种情况又是为什么？其实这里面涉及 <code>Session</code> 和 <code>Cookies</code> 的相关知识，本节就来揭开它们的神秘面纱。</p>
<h1 id="静态网页和动态网页"><a href="#静态网页和动态网页" class="headerlink" title="静态网页和动态网页"></a>静态网页和动态网页</h1><p>在开始介绍它们之前，我们需要先了解一下静态网页和动态网页的概念。这里还是前面的示例代码，内容如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">title</span>&gt;</span>This is a Demo<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"container"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"wrapper"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h2</span> <span class="attr">class</span>=<span class="string">"title"</span>&gt;</span>Hello World<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"text"</span>&gt;</span>Hello, this is a paragraph.<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>这是最基本的 <code>HTML</code> 代码，我们将其保存为一个 .html 文件，然后把它放在某台具有固定公网 IP 的主机上，主机上装上 Apache 或 Nginx 等服务器，这样这台主机就可以作为服务器了，其他人便可以通过访问服务器看到这个页面，这就搭建了一个最简单的网站。</p>
<p>这种网页的内容是 <code>HTML</code> 代码编写的，文字、图片等内容均通过写好的 <code>HTML</code> 代码来指定，这种页面叫作静态网页。它加载速度快，编写简单，但是存在很大的缺陷，如可维护性差，不能根据 <code>URL</code> 灵活多变地显示内容等。例如，我们想要给这个网页的 <code>URL</code> 传入一个 <code>name</code> 参数，让其在网页中显示出来，是无法做到的。</p>
<p>因此，动态网页应运而生，它可以动态解析 <code>URL</code> 中参数的变化，<strong>关联数据库并动态呈现不同的页面内容</strong>，非常灵活多变。我们现在遇到的大多数网站都是动态网站，它们不再是一个简单的 HTML，而是可能由 JSP、PHP、Python 等语言编写的，其功能比静态网页强大和丰富太多了。</p>
<p>此外，<strong>动态网站还可以实现用户登录和注册的功能</strong>。再回到开头来看提到的问题，很多页面是需要登录之后才可以查看的。按照一般的逻辑来说，输入用户名和密码登录之后，肯定是拿到了一种类似凭证的东西，有了它，我们才能保持登录状态，才能访问登录之后才能看到的页面。</p>
<p>那么，这种神秘的凭证到底是什么呢？其实它就是 <code>Session</code> 和 <code>Cookies</code> 共同产生的结果，下面我们来一探究竟。</p>
<h1 id="无状态-HTTP"><a href="#无状态-HTTP" class="headerlink" title="无状态 HTTP"></a>无状态 HTTP</h1><p>在了解<code>Session</code> 和 <code>Cookies</code>之前，我们还需要了解 HTTP 的一个特点，叫作无状态。</p>
<p>HTTP 的无状态是指 HTTP 协议对事务处理是没有记忆能力的，也就是说服务器不知道客户端是什么状态。</p>
<p>当我们向服务器发送请求后，服务器解析此请求，然后返回对应的响应，服务器负责完成这个过程，而且这个过程是完全独立的，服务器不会记录前后状态的变化，也就是缺少状态记录。</p>
<p>这意味着如果后续需要处理前面的信息，则必须重传，这也导致需要额外传递一些前面的重复请求，才能获取后续响应，然而这种效果显然不是我们想要的。为了保持前后状态，我们肯定不能将前面的请求全部重传一次，这太浪费资源了，对于这种需要用户登录的页面来说，更是棘手。</p>
<p>这时两个用于保持 HTTP 连接状态的技术就出现了，它们分别是 <code>Session</code> 和 <code>Cookies</code>。<strong><code>Session</code> 在服务端，也就是网站的服务器，用来保存用户的 <code>Session</code> 信息；<code>Cookies</code> 在客户端，也可以理解为浏览器端</strong>，有了 Cookies，浏览器在下次访问网页时会自动附带上它发送给服务器，服务器通过识别 <code>Cookies</code> 并鉴定出是哪个用户，然后再判断用户是否是登录状态，进而返回对应的响应。</p>
<p>我们可以理解为 <code>Cookies</code> 里面保存了登录的凭证，有了它，只需要在下次请求携带 <code>Cookies</code> 发送请求而不必重新输入用户名、密码等信息重新登录了。</p>
<p>因此在爬虫中，有时候处理需要登录才能访问的页面时，我们一般会直接将登录成功后获取的 <code>Cookies</code> 放在请求头里面直接请求，而不必重新模拟登录。</p>
<p>好了，了解 <code>Session</code> 和 <code>Cookies</code> 的概念之后，我们在来详细剖析它们的原理。</p>
<h1 id="Session"><a href="#Session" class="headerlink" title="Session"></a><code>Session</code></h1><p><code>Session</code>，中文称之为会话，其本身的含义是指有始有终的一系列动作 / 消息。比如，打电话时，从拿起电话拨号到挂断电话这中间的一系列过程可以称为一个 <code>Session</code>。</p>
<p>而在 Web 中，<code>Session</code> 对象用来存储特定用户 <code>Session</code> 所需的属性及配置信息。这样，当用户在应用程序的 Web 页之间跳转时，存储在 <code>Session</code> 对象中的变量将不会丢失，而是在整个用户 <code>Session</code> 中一直存在下去。当用户请求来自应用程序的 Web 页时，如果该用户还没有 <code>Session</code>，则 Web 服务器将自动创建一个 <code>Session</code> 对象。当 <code>Session</code> 过期或被放弃后，服务器将终止该 <code>Session</code>。</p>
<h1 id="Cookies"><a href="#Cookies" class="headerlink" title="Cookies"></a><code>Cookies</code></h1><p><code>Cookies</code> 指某些网站为了辨别用户身份、进行 <code>Session</code> 跟踪而存储在用户本地终端上的数据。</p>
<h2 id="Session-维持"><a href="#Session-维持" class="headerlink" title="Session 维持"></a>Session 维持</h2><p>那么，我们怎样利用 <code>Cookies</code>  保持状态呢？当客户端第一次请求服务器时，服务器会返回一个响应头中带有 Set-Cookie 字段的响应给客户端，用来标记是哪一个用户，客户端浏览器会把 <code>Cookies</code> 保存起来。当浏览器下一次再请求该网站时，浏览器会把此 <code>Cookies</code> 放到请求头一起提交给服务器，<code>Cookies</code>  携带了 <code>Session</code> ID 信息，服务器检查该 <code>Cookies</code> 即可找到对应的 <code>Session</code> 是什么，然后再判断 <code>Session</code> 来以此来辨认用户状态。</p>
<p>在成功登录某个网站时，服务器会告诉客户端设置哪些 <code>Cookies</code> 信息，在后续访问页面时客户端会把 <code>Cookies</code> 发送给服务器，服务器再找到对应的 <code>Session</code> 加以判断。如果 <code>Session</code> 中的某些设置登录状态的变量是有效的，那就证明用户处于登录状态，此时返回登录之后才可以查看的网页内容，浏览器再进行解析便可以看到了。</p>
<p>反之，如果传给服务器的 <code>Cookies</code> 是无效的，或者 <code>Session</code> 已经过期了，我们将不能继续访问页面，此时可能会收到错误的响应或者跳转到登录页面重新登录。</p>
<p>所以，<code>Cookies</code>和 <code>Session</code> 需要配合，一个处于客户端，一个处于服务端，二者共同协作，就实现了登录 <code>Session</code> 控制。</p>
<p><img src="/../Pic/Spider/cookie.jpg" style="zoom:57%;"></p>
<h2 id="属性结构"><a href="#属性结构" class="headerlink" title="属性结构"></a>属性结构</h2><p>接下来，我们来看看 <code>Cookies</code> 都有哪些内容。这里以知乎为例，在浏览器开发者工具中打开 <code>Application</code> 选项卡，然后在左侧会有一个<code>Storage</code> 部分，最后一项即为 <code>Cookies</code>，将其点开，如图所示，这些就是 <code>Cookies</code>。</p>
<p><img src="/../Pic/Spider/storage.jpg" style="zoom:80%;"></p>
<p>可以看到，这里有很多条目，其中每个条目可以称为 <code>Cookie</code>。它有如下几个属性。</p>
<ul>
<li><code>Name</code>，即该<code>Cookie</code>的名称。Cookie 一旦创建，名称便不可更改。</li>
<li><code>Value</code>，即该<code>Cookie</code>的值。如果值为 Unicode 字符，需要为字符编码。如果值为二进制数据，则需要使用 BASE64 编码。</li>
<li><code>Max Age</code>，即该<code>Cookie</code>失效的时间，单位秒，也常和 Expires 一起使用，通过它可以计算出其有效时间。Max Age 如果为正数，则该<code>Cookie</code>在 Max Age 秒之后失效。如果为负数，则关闭浏览器时<code>Cookie</code>即失效，浏览器也不会以任何形式保存该 <code>Cookie</code>。</li>
<li><code>Path</code>，即该<code>Cookie</code>的使用路径。如果设置为 /path/，则只有路径为 /path/ 的页面可以访问该 <code>Cookie</code>。如果设置为 /，则本域名下的所有页面都可以访问该 <code>Cookie</code>。</li>
<li><code>Domain</code>，即可以访问该<code>Cookie</code>的域名。例如如果设置为 .zhihu.com，则所有以 zhihu.com，结尾的域名都可以访问该 <code>Cookie</code>。</li>
<li><code>Size</code> 字段，即此<code>Cookie</code>的大小。</li>
<li><code>Http</code> 字段，即<code>Cookie</code>的 <code>httponly</code> 属性。若此属性为 true，则只有在 HTTP Headers 中会带有此<code>Cookie</code>的信息，而不能通过 <code>document.cookie</code> 来访问此 <code>Cookie</code>。</li>
<li><code>Secure</code>，即该<code>Cookie</code>是否仅被使用安全协议传输。安全协议。安全协议有 HTTPS、SSL 等，在网络上传输数据之前先将数据加密。默认为 <code>false</code>。</li>
</ul>
<h2 id="会话Cookie和持久-Cookie"><a href="#会话Cookie和持久-Cookie" class="headerlink" title="会话Cookie和持久 Cookie"></a>会话<code>Cookie</code>和持久 Cookie</h2><p>从表面意思来说，会话<code>Cookie</code>就是把<code>Cookie</code>放在浏览器内存里，浏览器在关闭之后该<code>Cookie</code>即失效；持久<code>Cookie</code>则会保存到客户端的硬盘中，下次还可以继续使用，用于长久保持用户登录状态。</p>
<p>其实严格来说，没有会话<code>Cookie</code>和持久<code>Cookie</code>之 分，只是由<code>Cookie</code>的 <code>Max Age</code> 或 <code>Expires</code> 字段决定了过期的时间。</p>
<p>因此，一些持久化登录的网站其实就是把<code>Cookie</code>的有效时间和<code>Session</code>有效期设置得比较长，下次我们再访问页面时仍然携带之前的 <code>Cookie</code>，就可以直接保持登录状态。</p>
<h1 id="常见误区"><a href="#常见误区" class="headerlink" title="常见误区"></a>常见误区</h1><p>在谈论<code>Session</code>机制的时候，常常听到这样一种误解 ——“只要关闭浏览器，<code>Session</code> 就消失了”。可以想象一下会员卡的例子，除非顾客主动对店家提出销卡，否则店家绝对不会轻易删除顾客的资料。对<code>Session</code>来说，也是一样，除非程序通知服务器删除一个 <code>Session</code>，否则服务器会一直保留。比如，程序一般都是在我们做注销操作时才去删除 <code>Session</code>。</p>
<p>但是当我们关闭浏览器时，浏览器不会主动在关闭之前通知服务器它将要关闭，所以服务器根本不会有机会知道浏览器已经关闭。之所以会有这种错觉，是因为大部分网站都使用会话<code>Cookie</code>来保存<code>Session ID</code> 信息，而关闭浏览器后 <code>Cookies</code> 就消失了，再次连接服务器时，也就无法找到原来的<code>Session</code>了。如果服务器设置的 <code>Cookies</code> 保存到硬盘上，或者使用某种手段改写浏览器发出的 <code>HTTP</code> 请求头，把原来的 <code>Cookies</code> 发送给服务器，则再次打开浏览器，仍然能够找到原来的<code>Session ID</code>，依旧还是可以保持登录状态的。</p>
<p>而且恰恰是由于关闭浏览器不会导致<code>Session</code>被删除，这就需要服务器为<code>Session</code>设置一个失效时间，当距离客户端上一次使用<code>Session</code>的时间超过这个失效时间时，服务器就可以认为客户端已经停止了活动，才会把<code>Session</code>删除以节省存储空间。</p>
]]></content>
      <categories>
        <category>Spider</category>
      </categories>
  </entry>
  <entry>
    <title>Python爬虫（三）爬虫的基本原理</title>
    <url>/posts/22139870.html</url>
    <content><![CDATA[<p>我们可以把互联网比作一张大网，而爬虫（即网络爬虫）便是在网上爬行的蜘蛛。如果把网的节点比作一个个网页，爬虫爬到这就相当于访问了该页面，获取了其信息。可以把节点间的连线比作网页与网页之间的链接关系，这样蜘蛛通过一个节点后，可以顺着节点连线继续爬行到达下一个节点，即通过一个网页继续获取后续的网页，这样整个网的节点便可以被蜘蛛全部爬行到，网站的数据就可以被抓取下来了。</p>
<h1 id="爬虫概述"><a href="#爬虫概述" class="headerlink" title="爬虫概述"></a>爬虫概述</h1><p>简单来说，爬虫就是获取网页并提取和保存信息的自动化程序，下面概要介绍一下。</p>
<h2 id="获取网页"><a href="#获取网页" class="headerlink" title="获取网页"></a>获取网页</h2><p>爬虫首先要做的工作就是获取网页，这里就是获取网页的源代码。</p>
<p>源代码里包含了网页的部分有用信息，所以只要把源代码获取下来，就可以从中提取想要的信息了。</p>
<p>前面讲了请求和响应的概念，向网站的服务器发送一个请求，返回的响应体便是网页源代码。所以，最关键的部分就是构造一个请求并发送给服务器，然后接收到响应并将其解析出来，那么这个流程怎样实现呢？总不能手工去截取网页源码吧？</p>
<p>不用担心，Python 提供了许多库来帮助我们实现这个操作，如 <code>urllib</code>、<code>requests</code> 等。我们可以用这些库来帮助我们实现 HTTP 请求操作，请求和响应都可以用类库提供的数据结构来表示，得到响应之后只需要解析数据结构中的 <code>Body</code> 部分即可，即得到网页的源代码，这样我们可以用程序来实现获取网页的过程了。</p>
<h2 id="提取信息"><a href="#提取信息" class="headerlink" title="提取信息"></a>提取信息</h2><p>获取网页源代码后，接下来就是分析网页源代码，从中提取我们想要的数据。首先，最通用的方法便是采用正则表达式提取，这是一个万能的方法，但是在构造正则表达式时比较复杂且容易出错。</p>
<p>另外，由于网页的结构有一定的规则，所以还有一些根据网页节点属性、CSS 选择器或 XPath 来提取网页信息的库，如 <code>Beautiful Soup</code>、<code>pyquery</code>、<code>lxml</code> 等。使用这些库，我们可以高效快速地从中提取网页信息，如节点的属性、文本值等。</p>
<p>提取信息是爬虫非常重要的部分，它可以使杂乱的数据变得条理清晰，以便我们后续处理和分析数据。</p>
<h2 id="保存数据"><a href="#保存数据" class="headerlink" title="保存数据"></a>保存数据</h2><p>提取信息后，我们一般会将提取到的数据保存到某处以便后续使用。这里保存形式有多种多样，如可以简单保存为 TXT 文本或 JSON 文本，也可以保存到数据库，如 MySQL 和 MongoDB 等，还可保存至远程服务器，如借助<code>SFTP</code> 进行操作等。</p>
<h2 id="自动化程序"><a href="#自动化程序" class="headerlink" title="自动化程序"></a>自动化程序</h2><p>说到自动化程序，意思是说爬虫可以代替人来完成这些操作。首先，我们手工当然可以提取这些信息，但是当量特别大或者想快速获取大量数据的话，肯定还是要借助程序。爬虫就是代替我们来完成这份爬取工作的自动化程序，它可以在抓取过程中进行各种异常处理、错误重试等操作，确保爬取持续高效地运行。</p>
<h1 id="能抓怎样的数据"><a href="#能抓怎样的数据" class="headerlink" title="能抓怎样的数据"></a>能抓怎样的数据</h1><p>在网页中我们能看到各种各样的信息，最常见的便是常规网页，它们对应着 HTML 代码，而最常抓取的便是 HTML 源代码。</p>
<p>另外，可能有些网页返回的不是 HTML 代码，而是一个 JSON 字符串（其中 API 接口大多采用这样的形式），这种格式的数据方便传输和解析，它们同样可以抓取，而且数据提取更加方便。</p>
<p>此外，我们还可以看到各种二进制数据，如图片、视频和音频等。利用爬虫，我们可以将这些二进制数据抓取下来，然后保存成对应的文件名。</p>
<p>另外，还可以看到各种扩展名的文件，如 CSS、JavaScript 和配置文件等，这些其实也是最普通的文件，只要在浏览器里面可以访问到，就可以将其抓取下来。</p>
<p>上述内容其实都对应各自的 URL，是基于 HTTP 或 HTTPS 协议的，只要是这种数据，爬虫都可以抓取。</p>
<h2 id="JavaScript-渲染页面"><a href="#JavaScript-渲染页面" class="headerlink" title="JavaScript 渲染页面"></a>JavaScript 渲染页面</h2><p>有时候，我们在用 urllib 或 requests 抓取网页时，得到的源代码实际和浏览器中看到的不一样。</p>
<p>这是一个非常常见的问题。现在网页越来越多地采用 Ajax、前端模块化工具来构建，整个网页可能都是由 JavaScript 渲染出来的，也就是说原始的 HTML 代码就是一个空壳，例如：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">title</span>&gt;</span>This is a Demo<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"container"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"app.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>在浏览器中打开这个页面时，首先会加载这个 HTML 内容，接着浏览器会发现其中引入了一个 <code>app.js</code> 文件，然后便会接着去请求这个文件，获取到该文件后，便会执行其中的 JavaScript 代码，而 JavaScript 则会改变 HTML 中的节点，向其添加内容，最后得到完整的页面。</p>
<p>但是在用 <code>urllib</code> 或 <code>requests</code> 等库请求当前页面时，我们得到的只是这个 HTML 代码，它不会帮助我们去继续加载这个 JavaScript 文件，这样也就看不到浏览器中的内容了。</p>
<p>这也解释了为什么有时我们得到的源代码和浏览器中看到的不一样。</p>
<p>因此，使用基本 HTTP 请求库得到的源代码可能跟浏览器中的页面源代码不太一样。对于这样的情况，我们可以分析其后台 <code>Ajax</code> 接口，也可使用 <code>Selenium</code>、<code>Splash</code> 这样的库来实现模拟 JavaScript 渲染。</p>
<p>后面，我们会详细介绍如何采集 JavaScript 渲染的网页。本节介绍了爬虫的一些基本原理，这可以帮助我们在后面编写爬虫时更加得心应手。</p>
]]></content>
      <categories>
        <category>Spider</category>
      </categories>
  </entry>
  <entry>
    <title>Python爬虫（二）Web网页基础</title>
    <url>/posts/503970b4.html</url>
    <content><![CDATA[<h1 id="网页的组成"><a href="#网页的组成" class="headerlink" title="网页的组成"></a>网页的组成</h1><p>首先，我们来了解网页的基本组成，网页可以分为三大部分：HTML、CSS 和 JavaScript。</p>
<p>如果把网页比作一个人的话，HTML 相当于骨架，JavaScript 相当于肌肉，CSS 相当于皮肤，三者结合起来才能形成一个完整的网页。下面我们来分别介绍一下这三部分的功能。</p>
<h2 id="HTML"><a href="#HTML" class="headerlink" title="HTML"></a>HTML</h2><p>HTML 是用来描述网页的一种语言，其全称叫作 Hyper Text Markup Language，即超文本标记语言。</p>
<p>我们浏览的网页包括文字、按钮、图片和视频等各种复杂的元素，其基础架构就是 HTML。不同类型的元素通过不同类型的标签来表示，如图片用 <code>img</code> 标签表示，视频用 <code>video</code> 标签表示，段落用 <code>p</code> 标签表示，它们之间的布局又常通过布局标签 div 嵌套组合而成，各种标签通过不同的排列和嵌套就可以形成网页的框架。</p>
<p>我们在 Chrome 浏览器中打开百度，右击并选择 “检查” 项（或按 F12 键），打开开发者模式，这时在 Elements 选项卡中即可看到网页的源代码，如图所示。</p>
<p><img src="/../Pic/Spider/baidu_2.png" style="zoom:67%;"></p>
<p>这就是 HTML，整个网页就是由各种标签嵌套组合而成的。这些标签定义的节点元素相互嵌套和组合形成了复杂的层次关系，就形成了网页的架构。</p>
<h2 id="CSS"><a href="#CSS" class="headerlink" title="CSS"></a>CSS</h2><p>虽然 HTML 定义了网页的结构，但是只有 HTML 页面的布局并不美观，可能只是简单的节点元素的排列，为了让网页看起来更好看一些，这里就需要借助 CSS 了。</p>
<p>CSS，全称叫作 Cascading Style Sheets，即层叠样式表。“层叠” 是指当在 HTML 中引用了数个样式文件，并且样式发生冲突时，浏览器能依据层叠顺序处理。“样式” 指网页中文字大小、颜色、元素间距、排列等格式。</p>
<p>CSS 是目前唯一的网页页面排版样式标准，有了它的帮助，页面才会变得更为美观。</p>
<p>图的右侧即为 CSS，例如：</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-id">#head_wrapper</span><span class="selector-class">.s-ps-islite</span> <span class="selector-class">.s-p-top</span> &#123;</span><br><span class="line"></span><br><span class="line">   <span class="attribute">position</span>: absolute;</span><br><span class="line"></span><br><span class="line">   <span class="attribute">bottom</span>: <span class="number">40px</span>;</span><br><span class="line"></span><br><span class="line">   <span class="attribute">width</span>: <span class="number">100%</span>;</span><br><span class="line"></span><br><span class="line">   <span class="attribute">height</span>: <span class="number">181px</span>;</span><br></pre></td></tr></table></figure>
<p>这就是一个 CSS 样式。大括号前面是一个 CSS 选择器。此选择器的作用是首先选中 <code>id</code> 为 <code>head_wrapper</code> 且 <code>class</code> 为 <code>s-ps-islite</code> 的节点，然后再选中其内部的 <code>class</code> 为 <code>s-p-top</code> 的节点。</p>
<p>大括号内部写的就是一条条样式规则，例如 <code>position</code> 指定了这个元素的布局方式为绝对布局，<code>bottom</code> 指定元素的下边距为 40 像素，<code>width</code> 指定了宽度为 100% 占满父元素，<code>height</code> 则指定了元素的高度。</p>
<p>也就是说，我们将位置、宽度、高度等样式配置统一写成这样的形式，然后用大括号括起来，接着在开头再加上 CSS 选择器，这就代表这个样式对 CSS 选择器选中的元素生效，元素就会根据此样式来展示了。</p>
<p>在网页中，一般会统一定义整个网页的样式规则，并写入 CSS 文件中（其后缀为 <code>css</code>）。在 HTML 中，只需要用 <code>link</code> 标签即可引入写好的 CSS 文件，这样整个页面就会变得美观、优雅。</p>
<h2 id="JavaScript"><a href="#JavaScript" class="headerlink" title="JavaScript"></a>JavaScript</h2><p>JavaScript，简称 JS，是一种脚本语言。HTML 和 CSS 配合使用，提供给用户的只是一种静态信息，缺乏交互性。我们在网页里可能会看到一些交互和动画效果，如下载进度条、提示框、轮播图等，这通常就是 JavaScript 的功劳。它的出现使得用户与信息之间不只是一种浏览与显示的关系，而是实现了一种实时、动态、交互的页面功能。</p>
<p>JavaScript 通常也是以单独的文件形式加载的，后缀为 js，在 HTML 中通过 script 标签即可引入，例如：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&lt;script src=<span class="string">"jquery-2.1.0.js"</span>&gt;&lt;<span class="regexp">/script&gt;</span></span><br></pre></td></tr></table></figure>
<p>综上所述，HTML 定义了网页的内容和结构，CSS 描述了网页的布局，JavaScript 定义了网页的行为。</p>
<h1 id="网页的结构"><a href="#网页的结构" class="headerlink" title="网页的结构"></a>网页的结构</h1><p>了解了网页的基本组成，我们再用一个例子来感受下 HTML 的基本结构。新建一个文本文件，名称可以自取，后缀为 <code>html</code>，内容如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">title</span>&gt;</span>This is a Demo<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"container"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"wrapper"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h2</span> <span class="attr">class</span>=<span class="string">"title"</span>&gt;</span>Hello World<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"text"</span>&gt;</span>Hello, this is a paragraph.<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br><span class="line">这就是一个最简单的 HTML 实例。开头用 DOCTYPE 定义了文档类型，其次最外层是 html 标签，最后还有对应的结束标签来表示闭合，其内部是 head 标签和 body 标签，分别代表网页头和网页体，它们也需要结束标签。</span><br></pre></td></tr></table></figure>
<p><code>head</code> 标签内定义了一些页面的配置和引用，如：<code>&lt;meta charset=&quot;UTF-8&quot;&gt;</code>，它指定了网页的编码为 UTF-8。<code>title</code> 标签则定义了网页的标题，会显示在网页的选项卡中，不会显示在正文中。body 标签内则是在网页正文中显示的内容。</p>
<p><code>div</code> 标签定义了网页中的区块，它的 <code>id</code> 是 <code>container</code>，这是一个非常常用的属性，且 <code>id</code> 的内容在网页中是唯一的，我们可以通过它来获取这个区块。然后在此区块内又有一个 <code>div</code> 标签，它的 <code>class</code> 为 <code>wrapper</code>，这也是一个非常常用的属性，经常与 CSS 配合使用来设定样式。</p>
<p>然后此区块内部又有一个 <code>h2</code> 标签，这代表一个二级标题。另外，还有一个 <code>p</code> 标签，这代表一个段落。在这两者中直接写入相应的内容即可在网页中呈现出来，它们也有各自的 <code>class</code> 属性。</p>
<p>将代码保存后，在浏览器中打开该文件，可以看到如图所示的内容。</p>
<p><img src="/../Pic/Spider/demo.png" alt></p>
<p>可以看到，在选项卡上显示了 <code>This is a Demo</code> 字样，这是我们在 <code>head</code> 中的 <code>title</code> 里定义的文字。而网页正文是 <code>body</code> 标签内部定义的各个元素生成的，可以看到这里显示了二级标题和段落。</p>
<p>这个实例便是网页的一般结构。一个网页的标准形式是 <code>html</code> 标签内嵌套 <code>head</code> 和 <code>body</code> 标签，<code>head</code> 内定义网页的配置和引用，<code>body</code> 内定义网页的正文。</p>
<h1 id="节点树及节点间的关系"><a href="#节点树及节点间的关系" class="headerlink" title="节点树及节点间的关系"></a>节点树及节点间的关系</h1><p>在 HTML 中，所有标签定义的内容都是节点，它们构成了一个 <code>HTML DOM</code> 树。</p>
<p>我们先看下什么是 DOM。<code>DOM</code> 是 W3C（万维网联盟）的标准，其英文全称 Document Object Model，即文档对象模型。它定义了访问 HTML 和 XML 文档的标准：</p>
<p>W3C 文档对象模型（<code>DOM</code>）是中立于平台和语言的接口，它允许程序和脚本动态地访问和更新文档的内容、结构和样式。</p>
<p><code>W3C DOM</code> 标准被分为 3 个不同的部分：</p>
<ul>
<li>核心 <code>DOM</code> - 针对任何结构化文档的标准模型</li>
<li><code>XML DOM</code> - 针对 XML 文档的标准模型</li>
<li><code>HTML DOM</code> - 针对 HTML 文档的标准模型</li>
</ul>
<p>根据 W3C 的 <code>HTML DOM</code> 标准，HTML 文档中的所有内容都是节点：</p>
<ul>
<li>整个文档是一个文档节点</li>
<li>每个 HTML 元素是元素节点</li>
<li>HTML 元素内的文本是文本节点</li>
<li>每个 HTML 属性是属性节点</li>
<li>注释是注释节点</li>
</ul>
<p><code>HTML DOM</code> 将 HTML 文档视作树结构，这种结构被称为节点树，如图所示。</p>
<p><img src="/../Pic/Spider/tree.jpg" style="zoom:90%;"></p>
<p>通过 <code>HTML DOM</code>，树中的所有节点均可通过 <code>JavaScript</code> 访问，所有 <code>HTML</code> 节点元素均可被修改，也可以被创建或删除。</p>
<p>节点树中的节点彼此拥有层级关系。我们常用父（<code>parent</code>）、子（<code>child</code>）和兄弟（<code>sibling</code>）等术语描述这些关系。父节点拥有子节点，同级的子节点被称为兄弟节点。</p>
<p>在节点树中，顶端节点称为根（<code>root</code>）。除了根节点之外，每个节点都有父节点，同时可拥有任意数量的子节点或兄弟节点。图中展示了节点树以及节点之间的关系。</p>
<p>本段参考 W3SCHOOL，链接：<a href="http://www.w3school.com.cn/htmldom/dom_nodes.asp。" target="_blank" rel="noopener">http://www.w3school.com.cn/htmldom/dom_nodes.asp。</a></p>
<h1 id="选择器"><a href="#选择器" class="headerlink" title="选择器"></a>选择器</h1><p>我们知道网页由一个个节点组成，CSS 选择器会根据不同的节点设置不同的样式规则，那么怎样来定位节点呢？</p>
<p>在 CSS 中，我们使用 CSS 选择器来定位节点。例如，上例中 <code>div</code> 节点的 <code>id</code> 为 <code>container</code>，那么就可以表示为 <code>#container</code>，其中 <code>#</code> 开头代表选择 <code>id</code>，其后紧跟 <code>id</code> 的名称。</p>
<p>另外，如果我们想选择 <code>class</code>为 <code>wrapper</code> 的节点，便可以使用 <code>.wrapper</code>，这里以点“<code>.</code>”开头代表选择 <code>class</code>，其后紧跟 <code>class</code> 的名称。另外，还有一种选择方式，那就是根据标签名筛选，例如想选择二级标题，直接用 <code>h2</code> 即可。这是最常用的 3 种表示，分别是根据 <code>id</code>、<code>class</code>、标签名筛选，请牢记它们的写法。</p>
<p>另外，CSS 选择器还支持嵌套选择，各个选择器之间加上空格分隔开便可以代表嵌套关系，如 <code>#container .wrapper p</code> 则代表先选择 id 为 <code>container</code> 的节点，然后选中其内部的 <code>class</code> 为 <code>wrapper</code> 的节点，然后再进一步选中其内部的 <code>p</code> 节点。</p>
<p>另外，如果不加空格，则代表并列关系，如 <code>div#container .wrapper p.text</code> 代表先选择 <code>id</code> 为 <code>container</code> 的 <code>div</code> 节点，然后选中其内部的 <code>class</code>为 <code>wrapper</code> 的节点，再进一步选中其内部的 <code>class</code> 为 <code>text</code> 的 <code>p</code>节点。这就是 CSS 选择器，其筛选功能还是非常强大的。</p>
<p>另外，CSS 选择器还有一些其他语法规则，具体如表所示。</p>
<p><img src="/../Pic/Spider/select1.png" style="zoom:67%;"></p>
<p><img src="/../Pic/Spider/select2.png" style="zoom:67%;"></p>
<p><img src="/../Pic/Spider/select3.png" style="zoom:67%;"></p>
<p>另外，还有一种比较常用的选择器是 XPath，这种选择方式后面会详细介绍。</p>
]]></content>
      <categories>
        <category>Spider</category>
      </categories>
  </entry>
  <entry>
    <title>Python爬虫（一）掌握HTTP基本原理</title>
    <url>/posts/8c9d019c.html</url>
    <content><![CDATA[<h1 id="URL和URI"><a href="#URL和URI" class="headerlink" title="URL和URI"></a>URL和URI</h1><ul>
<li>URL（Uniform Resource Identifier）：统一资源定位符</li>
<li>URI（Uniform Resource Locator）：统一资源标识符</li>
</ul>
<p>举例来说，<a href="https://github.com/favicon.ico" target="_blank" rel="noopener">https://github.com/favicon.ico</a> ，它是一个 URL，也是一个 URI。即有这样的一个图标资源，我们用 URL/URI 来唯一指定了它的访问方式，这其中包括了访问协议 HTTPS、访问路径（即根目录）和资源名称 <code>favicon.ico</code>。通过这样一个链接，我们便可以从互联网上找到这个资源，这就是 URL/URI。</p>
<p>URL 是 URI 的子集，也就是说每个 URL 都是 URI，但不是每个 URI 都是 URL。那么，什么样的 URI 不是 URL 呢？URI 还包括一个子类叫作 URN，它的全称为 Universal Resource Name，即统一资源名称。</p>
<p>URN 只命名资源而不指定如何定位资源，比如 <code>urn:isbn:0451450523</code> 指定了一本书的 ISBN，可以唯一标识这本书，但是没有指定到哪里定位这本书，这就是 URN。URL、URN 和 URI 的关系可以用图表示。</p>
<p><img src="/../Pic/Spider/url.jpg" style="zoom:33%;"></p>
<p>但是在目前的互联网，URN 的使用非常少，几乎所有的 URI 都是 URL，所以一般的网页链接我们可以称之为 URL，也可以称之为 URI。</p>
<h1 id="超文本"><a href="#超文本" class="headerlink" title="超文本"></a>超文本</h1><p>接下来，我们再了解一个概念 —— 超文本，其英文名称叫作 Hypertext，我们在浏览器里看到的网页就是超文本解析而成的，其网页源代码是一系列 HTML 代码，里面包含了一系列标签，比如 <code>img</code> 显示图片，<code>p</code> 指定显示段落等。浏览器解析这些标签后，便形成了我们平常看到的网页，而网页的源代码 HTML 就可以称作超文本。</p>
<p>例如，我们在 Chrome 浏览器里面打开任意一个页面，如淘宝首页，右击任一地方并选择 “检查” 项（或者直接按快捷键 F12），即可打开浏览器的开发者工具，这时在 Elements 选项卡即可看到当前网页的源代码，这些源代码都是超文本，如图所示。</p>
<p><img src="/../Pic/Spider/taobao.png" alt></p>
<h1 id="HTTP-和-HTTPS"><a href="#HTTP-和-HTTPS" class="headerlink" title="HTTP 和 HTTPS"></a>HTTP 和 HTTPS</h1><p>在淘宝的首页 <a href="https://www.taobao.com/中，URL" target="_blank" rel="noopener">https://www.taobao.com/中，URL</a> 的开头会有 <code>http</code> 或 <code>https</code>，这个就是访问资源需要的协议类型，有时我们还会看到 <code>ftp</code>、<code>sftp</code>、<code>smb</code> 开头的 URL，那么这里的 <code>ftp</code>、<code>sftp</code>、<code>smb</code> 都是指的协议类型。在爬虫中，我们抓取的页面通常就是 <code>http</code> 或 <code>https</code> 协议的，我们在这里首先来了解一下这两个协议的含义。</p>
<p>HTTP 的全称是 Hyper Text Transfer Protocol，中文名叫作<strong>超文本传输协议</strong>，HTTP 协议是用于从网络传输超文本数据到本地浏览器的传送协议，它能保证高效而准确地传送超文本文档。HTTP 由万维网协会（World Wide Web Consortium）和 Internet 工作小组 IETF（Internet Engineering Task Force）共同合作制定的规范，目前广泛使用的是 HTTP 1.1 版本。</p>
<p>HTTPS 的全称是 Hyper Text Transfer Protocol over Secure Socket Layer，是以安全为目标的 HTTP 通道，简单讲是 HTTP 的安全版，即 HTTP 下加入 SSL 层，简称为 HTTPS。</p>
<p><strong>HTTPS 的安全基础是 SSL</strong>，因此通过它传输的内容都是经过 SSL 加密的，它的主要作用可以分为两种：</p>
<ul>
<li>建立一个信息安全通道，来保证数据传输的安全。</li>
<li>确认网站的真实性，凡是使用了 HTTPS 的网站，都可以通过点击浏览器地址栏的锁头标志来查看网站认证之后的真实信息，也可以通过 CA 机构颁发的安全签章来查询。</li>
</ul>
<p>现在越来越多的网站和 App 都已经向 HTTPS 方向发展。例如：</p>
<ul>
<li>苹果公司强制所有 iOS App 在 2017 年 1 月 1 日 前全部改为使用 HTTPS 加密，否则 App 就无法在应用商店上架。<br>谷歌从 2017 年 1 月推出的 Chrome 56 开始，对未进行 HTTPS 加密的网址链接亮出风险提示，即在地址栏的显著位置提醒用户 “此网页不安全”。</li>
<li>腾讯微信小程序的官方需求文档要求后台使用 HTTPS 请求进行网络通信，不满足条件的域名和协议无法请求。</li>
</ul>
<p>因此，HTTPS 已经已经是大势所趋。</p>
<h1 id="HTTP-请求过程"><a href="#HTTP-请求过程" class="headerlink" title="HTTP 请求过程"></a>HTTP 请求过程</h1><p>我们在浏览器中输入一个 URL，回车之后便可以在浏览器中观察到页面内容。实际上，<strong>这个过程是浏览器向网站所在的服务器发送了一个请求，网站服务器接收到这个请求后进行处理和解析，然后返回对应的响应，接着传回给浏览器</strong>。响应里包含了页面的源代码等内容，浏览器再对其进行解析，便将网页呈现了出来，传输模型如图所示。</p>
<p><img src="/../Pic/Spider/requests1.jpg" style="zoom: 33%;"></p>
<p>此处客户端即代表我们自己的 PC 或手机浏览器，服务器即要访问的网站所在的服务器。</p>
<p>为了更直观地说明这个过程，这里用 Chrome 浏览器的开发者模式下的 Network 监听组件来做下演示，它可以显示访问当前请求网页时发生的所有网络请求和响应。</p>
<p>打开 Chrome 浏览器，右击并选择 “检查” 项，即可打开浏览器的开发者工具。这里访问百度 <a href="http://www.baidu.com/" target="_blank" rel="noopener">http://www.baidu.com/</a> ，输入该 URL 后回车，观察这个过程中发生了怎样的网络请求。可以看到，在 <code>Network</code> 页面下方出现了一个个的条目，其中一个条目就代表一次发送请求和接收响应的过程，如图所示。</p>
<p><img src="/../Pic/Spider/baidu.png" style="zoom:33%;"></p>
<ul>
<li>第一列 <code>Name</code>：请求的名称，一般会将 URL 的最后一部分内容当作名称。</li>
<li>第二列 <code>Status</code>：响应的状态码，这里显示为 200，代表响应是正常的。通过状态码，我们可以判断发送了请求之后是否得到了正常的响应。</li>
<li>第三列 <code>Type</code>：请求的文档类型。这里为 <code>document</code>，代表我们这次请求的是一个<code>HTML</code> 文档，内容就是一些 HTML 代码。</li>
<li>第四列<code>Initiator</code>：请求源。用来标记请求是由哪个对象或进程发起的。</li>
<li>第五列 <code>Size</code>：从服务器下载的文件和请求的资源大小。如果是从缓存中取得的资源，则该列会显示 from cache。</li>
<li>第六列 <code>Time</code>：发起请求到获取响应所用的总时间。</li>
<li>第七列 <code>Waterfall</code>：网络请求的可视化瀑布流。<br>我们点击这个条目即可看到其更详细的信息，如图所示。</li>
</ul>
<p><img src="/../Pic/Spider/network1.jpg" style="zoom:90%;"></p>
<p>首先是 General 部分，Request URL 为请求的 URL，Request Method 为请求的方法，Status Code 为响应状态码，Remote Address 为远程服务器的地址和端口，Referrer Policy 为 Referrer 判别策略。</p>
<p>再继续往下，可以看到，有 Response Headers 和 Request Headers，这分别代表响应头和请求头。请求头里带有许多请求信息，例如浏览器标识、Cookies、Host 等信息，这是请求的一部分，服务器会根据请求头内的信息判断请求是否合法，进而作出对应的响应。图中看到的 Response Headers 就是响应的一部分，例如其中包含了服务器的类型、文档类型、日期等信息，浏览器接受到响应后，会解析响应内容，进而呈现网页内容。</p>
<p>下面我们分别来介绍一下请求和响应都包含哪些内容。</p>
<h1 id="请求"><a href="#请求" class="headerlink" title="请求"></a>请求</h1><p>请求，由客户端向服务端发出，可以分为 4 部分内容：请求方法（Request Method）、请求的网址（Request URL）、请求头（Request Headers）、请求体（Request Body）。</p>
<h2 id="请求方法"><a href="#请求方法" class="headerlink" title="请求方法"></a>请求方法</h2><p>常见的请求方法有两种：<code>GET</code> 和 <code>POST</code>。</p>
<p>在浏览器中直接输入 URL 并回车，这便发起了一个 <code>GET</code> 请求，请求的参数会直接包含到 URL 里。例如，在百度中搜索 Python，这就是一个 GET 请求，链接为 <a href="https://www.baidu.com/s?wd=Python" target="_blank" rel="noopener">https://www.baidu.com/s?wd=Python</a> ，其中 URL 中包含了请求的参数信息，这里参数 <code>wd</code> 表示要搜寻的关键字。POST 请求大多在表单提交时发起。比如，对于一个登录表单，输入用户名和密码后，点击 “登录” 按钮，这通常会发起一个 POST 请求，其数据通常以表单的形式传输，而不会体现在 URL 中。</p>
<p><strong>GET 和 POST 请求方法有如下区别。</strong></p>
<ul>
<li>GET 请求中的参数包含在 URL 里面，数据可以在 URL 中看到，而 POST 请求的 URL 不会包含这些数据，数据都是通过表单形式传输的，会包含在请求体中。</li>
<li>GET 请求提交的数据最多只有 1024 字节，而 POST 请求没有限制。</li>
</ul>
<p>一般来说，登录时，需要提交用户名和密码，其中包含了敏感信息，使用 GET 方式请求的话，密码就会暴露在 URL 里面，造成密码泄露，所以这里最好以 POST 方式发送。上传文件时，由于文件内容比较大，也会选用 POST 方式。</p>
<p>我们平常遇到的绝大部分请求都是 GET 或 POST 请求，另外还有一些请求方法，如 <code>HEAD</code>、<code>PUT</code>、<code>DELETE</code>、<code>OPTIONS</code>、<code>CONNECT</code>、<code>TRACE</code> 等，我们简单将其总结为下表。</p>
<p><img src="/../Pic/Spider/post1.png" style="zoom:80%;"></p>
<p>请求的网址，即统一资源定位符 URL，它可以唯一确定我们想请求的资源。</p>
<h2 id="请求头"><a href="#请求头" class="headerlink" title="请求头"></a>请求头</h2><p>请求头，用来说明服务器要使用的附加信息，比较重要的信息有 <code>Cookie</code>、<code>Referer</code>、<code>User-Agent</code> 等。下面简要说明一些常用的头信息。</p>
<ul>
<li><code>Accept</code>：请求报头域，用于指定客户端可接受哪些类型的信息。</li>
<li><code>Accept-Language</code>：指定客户端可接受的语言类型。</li>
<li><code>Accept-Encoding</code>：指定客户端可接受的内容编码。</li>
<li><code>Host</code>：用于指定请求资源的主机 IP 和端口号，其内容为请求 URL 的原始服务器或网关的位置。从 HTTP 1.1 版本开始，请求必须包含此内容。</li>
<li><code>Cookie</code>：也常用复数形式 Cookies，这是网站为了辨别用户进行会话跟踪而存储在用户本地的数据。它的主要功能是维持当前访问会话。例如，我们输入用户名和密码成功登录某个网站后，服务器会用会话保存登录状态信息，后面我们每次刷新或请求该站点的其他页面时，会发现都是登录状态，这就是 Cookies 的功劳。Cookies 里有信息标识了我们所对应的服务器的会话，每次浏览器在请求该站点的页面时，都会在请求头中加上 Cookies 并将其发送给服务器，服务器通过 Cookies 识别出是我们自己，并且查出当前状态是登录状态，所以返回结果就是登录之后才能看到的网页内容。</li>
<li><code>Referer</code>：此内容用来标识这个请求是从哪个页面发过来的，服务器可以拿到这一信息并做相应的处理，如做来源统计、防盗链处理等。</li>
<li><code>User-Agent</code>：简称 UA，它是一个特殊的字符串头，可以使服务器识别客户使用的操作系统及版本、浏览器及版本等信息。在做爬虫时加上此信息，可以伪装为浏览器；如果不加，很可能会被识别出为爬虫。</li>
<li><code>Content-Type</code>：也叫互联网媒体类型（Internet Media Type）或者 MIME 类型，在 HTTP 协议消息头中，它用来表示具体请求中的媒体类型信息。例如，text/html 代表 HTML 格式，image/gif 代表 GIF 图片，application/json 代表 JSON 类型，更多对应关系可以查看此对照表：<a href="http://tool.oschina.net/commons。" target="_blank" rel="noopener">http://tool.oschina.net/commons。</a></li>
</ul>
<p>因此，请求头是请求的重要组成部分，在写爬虫时，大部分情况下都需要设定请求头。</p>
<h2 id="请求体"><a href="#请求体" class="headerlink" title="请求体"></a>请求体</h2><p>请求体一般承载的内容是 <code>POST</code> 请求中的表单数据，而对于<code>GET</code> 请求，请求体则为空。</p>
<p>例如，这里我登录 GitHub 时捕获到的请求和响应如图所示。</p>
<p><img src="/../Pic/Spider/github.jpg" style="zoom:67%;"></p>
<p>登录之前，我们填写了用户名和密码信息，提交时这些内容就会以表单数据的形式提交给服务器，此时需要注意 Request Headers 中指定 <code>Content-Type</code> 为 application/x-www-form-urlencoded。只有设置 Content-Type 为 application/x-www-form-urlencoded，才会以表单数据的形式提交。另外，我们也可以将 Content-Type 设置为 application/json 来提交 JSON 数据，或者设置为 multipart/form-data 来上传文件。</p>
<p>表格中列出了 <code>Content-Type</code> 和 <code>POST</code> 提交数据方式的关系。</p>
<p><img src="/../Pic/Spider/content.png" style="zoom:80%;"></p>
<p>在爬虫中，如果要构造 POST 请求，需要使用正确的 <code>Content-Type</code>，并了解各种请求库的各个参数设置时使用的是哪种 Content-Type，不然可能会导致 POST 提交后无法正常响应。</p>
<h1 id="响应"><a href="#响应" class="headerlink" title="响应"></a>响应</h1><p>响应，由服务端返回给客户端，可以分为三部分：响应状态码（Response Status Code）、响应头（Response Headers）和响应体（Response Body）。</p>
<h2 id="响应状态码"><a href="#响应状态码" class="headerlink" title="响应状态码"></a>响应状态码</h2><p>响应状态码表示服务器的响应状态，如 200 代表服务器正常响应，404 代表页面未找到，500 代表服务器内部发生错误。在爬虫中，我们可以根据状态码来判断服务器响应状态，如状态码为 200，则证明成功返回数据，再进行进一步的处理，否则直接忽略。下表列出了常见的错误代码及错误原因。</p>
<p><img src="/../Pic/Spider/response.png" style="zoom:67%;"></p>
<p>响应头包含了服务器对请求的应答信息，如 Content-Type、Server、Set-Cookie 等。下面简要说明一些常用的响应头信息。</p>
<ul>
<li><code>Date</code>：标识响应产生的时间。</li>
<li><code>Last-Modified</code>：指定资源的最后修改时间。</li>
<li><code>Content-Encoding</code>：指定响应内容的编码。</li>
<li><code>Server</code>：包含服务器的信息，比如名称、版本号等。</li>
<li><code>Content-Type</code>：文档类型，指定返回的数据类型是什么，如 <code>text/html</code> 代表返回 <code>HTML</code> 文档，<code>application/x-javascript</code> 则代表返回 <code>JavaScript</code>文件，<code>image/jpeg</code> 则代表返回图片。</li>
<li><code>Set-Cookie</code>：设置 <code>Cookies</code>。响应头中的 <code>Set-Cookie</code> 告诉浏览器需要将此内容放在 <code>Cookies</code> 中，下次请求携带 <code>Cookies</code> 请求。</li>
<li><code>Expires</code>：指定响应的过期时间，可以使代理服务器或浏览器将加载的内容更新到缓存中。如果再次访问时，就可以直接从缓存中加载，降低服务器负载，缩短加载时间。</li>
</ul>
<h2 id="响应体"><a href="#响应体" class="headerlink" title="响应体"></a>响应体</h2><p>最重要的当属响应体的内容了。响应的正文数据都在响应体中，比如请求网页时，它的响应体就是网页的 <code>HTML</code> 代码；请求一张图片时，它的响应体就是图片的二进制数据。我们做爬虫请求网页后，要解析的内容就是响应体，如图所示。</p>
<p><img src="/../Pic/Spider/response_body.jpg" style="zoom:67%;"></p>
<p>在浏览器开发者工具中点击 Preview，就可以看到网页的源代码，也就是响应体的内容，它是解析的目标。</p>
<p>在做爬虫时，我们主要通过响应体得到网页的源代码、JSON 数据等，然后从中做相应内容的提取。</p>
]]></content>
      <categories>
        <category>Spider</category>
      </categories>
  </entry>
  <entry>
    <title>数据结构之排序技术（五）—— 分配排序</title>
    <url>/posts/b57883cc.html</url>
    <content><![CDATA[<p>分配排序与我们前面的所有其他排序都不一样，无论是选择排序还是插入排序，都需要比较关键码然后再进行排序，而分配排序只需要先<strong>将数据分配到不同的桶中，再将桶中的数据收集到一起</strong>，其时间复杂度可以达到线性阶。分配排序主要有两种方法：桶式排序和链式基数排序，其中 桶式排序主要是对单关键字进行排序，而链式基数排序则是对多关键字进行排序，下面分别进行介绍</p>
<h1 id="桶式排序"><a href="#桶式排序" class="headerlink" title="桶式排序"></a>桶式排序</h1><h2 id="箱排序"><a href="#箱排序" class="headerlink" title="箱排序"></a>箱排序</h2><p>主要流程：假设待排序的记录的值在0到m-1之间，设置m个桶，依次扫描待排序的记录，R[1]，…，R[n-1]，把关键字等于k的记录全都装入到第k个箱子里(分配)，然后按序号依次将各非空的箱子首尾连接起来(收集)。例如要将一副混洗的52张扑克牌按点数A&lt;2&lt;…&lt;J&lt;Q&lt;K排序，需设置13个”箱子”，排序时依次将每张牌按点数放入相应的箱子里，然后依次将这些箱子首尾相接，就得到了按点数递增序排列的一副牌。</p>
<p>有几个需要注意的点：</p>
<ul>
<li><p>由于一般情况下每个箱子中存放多少个关键字相同的记录是无法预料的，故箱子的类型应设计成链表为宜。</p>
</li>
<li><p>为保证排序是稳定的，分配过程中装箱及收集过程中的连接必须按先进先出原则进行。有两个实现方法：</p>
<ul>
<li>每个箱子设为一个链队列。当一记录装入某箱子时，应做入队操作将其插入该箱子尾部；而收集过程则是对箱子做出队操作，依次将出队的记录放到输出序列中。</li>
<li>若输入的待排序记录是以链表形式给出时，出队操作可简化为是将整个箱子链表链接到输出链表的尾部。这只需要修改输出链表的尾结点中的指针域，令其指向箱子链表的头，然后修改输出链表的尾指针，令其指向箱子链表的尾即可。</li>
</ul>
</li>
<li>时间复杂度：分配过程的时间是O(n)；收集过程的时间为O(m) （采用链表来存储输入的待排序记录）或O(m+n)。因此，箱排序的时间为O(m+n)。若箱子个数m的数量级为O(n)，则箱排序的时间是线性的，即O(n)。</li>
</ul>
<h2 id="桶排序"><a href="#桶排序" class="headerlink" title="桶排序"></a>桶排序</h2><p>桶排序的思想是把[0，1)划分为n个大小相同的子区间，每一子区间是一个桶。然后将n个记录分配到各个桶中。因为关键字序列是均匀分布在[0，1)上的，所以一般不会有很多个记录落入同一个桶中。由于同一桶中的记录其关键字不尽相同，所以必须采用关键字比较的排序方法(通常用插入排序)对各个桶进行排序，然后依次将各非空桶中的记录连接(收集)起来即可。</p>
<p>这种排序思想基于以下假设：<strong>假设输入的n个关键字序列是随机分布在区间[0，1)之上</strong>。若关键字序列的取值范围不是该区间，只要其取值均非负，我们总能将所有关键字除以某一合适的数，将关键字映射到该区间上。但要保证映射后的关键字是均匀分布在[0，1)上的。</p>
<p>伪代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">BucketSon</span><span class="params">(R)</span></span></span><br><span class="line"><span class="function">    </span>&#123; <span class="comment">//对R[0..n-1]做桶排序，其中0≤R[i].key&lt;1(0≤i&lt;n)</span></span><br><span class="line">      <span class="keyword">for</span>(i=<span class="number">0</span>，i&lt;n;i++) <span class="comment">//分配过程．</span></span><br><span class="line">        将R[i]插入到桶B[「n(R[i].key)」]中； <span class="comment">//可插入表头上</span></span><br><span class="line">      <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;n;i++) <span class="comment">//排序过程</span></span><br><span class="line">        当B[i]非空时用插人排序将B[i]中的记录排序；</span><br><span class="line">      <span class="keyword">for</span>(i=<span class="number">0</span>，i&lt;n；i++) <span class="comment">//收集过程</span></span><br><span class="line">        若B[i]非空，则将B[i]中的记录依次输出到R中；</span><br><span class="line">     &#125;</span><br></pre></td></tr></table></figure>
<p>注：有些数据结构书对上面两者不做区分，事实上也差不多，下面直接默认桶排序为箱排序。</p>
<p>桶排序的存储结构为，其中QueueNode为桶的存储结构：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Node</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> key;</span><br><span class="line">    <span class="keyword">int</span> next;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">QueueNode</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> front;</span><br><span class="line">    <span class="keyword">int</span> rear;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>分配操作与收集操作的实现：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Distribute</span><span class="params">(Node r[], <span class="keyword">int</span> n, QueueNode q[], <span class="keyword">int</span> m, <span class="keyword">int</span> first)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i = first;</span><br><span class="line">    <span class="keyword">while</span>(r[i].next!=<span class="number">-1</span>)&#123;</span><br><span class="line">        <span class="keyword">int</span> k = r[i].key;</span><br><span class="line">        <span class="keyword">if</span>(q[k].front != <span class="number">-1</span>)&#123;</span><br><span class="line">            q[k].front = i;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span>&#123;</span><br><span class="line">            r[q[k].rear].next = i;</span><br><span class="line">        &#125;</span><br><span class="line">        q[k].rear = i;</span><br><span class="line">        i = r[i].next;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Collect</span><span class="params">(Node r[], <span class="keyword">int</span> n, QueueNode q[], <span class="keyword">int</span> m, <span class="keyword">int</span> first)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> k = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(q[k].front!=<span class="number">-1</span>)&#123;</span><br><span class="line">        k++;</span><br><span class="line">    &#125;</span><br><span class="line">    first = q[k].front;</span><br><span class="line">    <span class="keyword">int</span> last = q[k].rear;</span><br><span class="line">    <span class="keyword">while</span>(k&lt;m)&#123;</span><br><span class="line">        k++;</span><br><span class="line">        <span class="keyword">if</span>(q[k].front!=<span class="number">-1</span>)&#123;</span><br><span class="line">            r[last].next = q[k].front;</span><br><span class="line">            last = q[k].rear;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    r[last].next = <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>桶式排序代码：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">BucketSort</span><span class="params">(Node r[], <span class="keyword">int</span> n, <span class="keyword">int</span> m)</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">        r[i].next = i+<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    r[n<span class="number">-1</span>].next = <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">int</span> first = <span class="number">0</span>;</span><br><span class="line">    QueueNode q[<span class="number">100</span>];</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">-0</span>;i&lt;m;i++)&#123;</span><br><span class="line">        q[i].front = q[i].rear = <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    Distribute(r,n,q,m,first);</span><br><span class="line">    Collect(r,n,q,m,first);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="基数排序"><a href="#基数排序" class="headerlink" title="基数排序"></a>基数排序</h1><p>基数排序是借助多关键码进行桶式排序的思想对单关键码进行排序</p>
<p>参考链接：</p>
<ul>
<li><a href="https://www.cnblogs.com/ziyiFly/archive/2008/09/10/1288508.html" target="_blank" rel="noopener">https://www.cnblogs.com/ziyiFly/archive/2008/09/10/1288508.html</a></li>
<li>数据结构（第2版 王红梅）</li>
</ul>
]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
  </entry>
  <entry>
    <title>动态规划（一）</title>
    <url>/posts/aa65faec.html</url>
    <content><![CDATA[<p>我们拿到一个动态规划问题，一定要考虑三个方面：</p>
<ul>
<li>问题目标</li>
<li>状态的定义：$opt[n]$</li>
<li>状态转移方程：$opt[n] = \text{best_of}(opt[n-1], opt[n-2])$</li>
</ul>
<p>下面我们举几个例子（Leetcode上的题目）：</p>
<h1 id="最大子序和"><a href="#最大子序和" class="headerlink" title="最大子序和"></a>最大子序和</h1><p><strong>目标</strong>：求得数组中和最大的一个子序列</p>
<p><strong>思路</strong>：</p>
<ul>
<li>首先对数组进行遍历，当前最大连续子序列和为sum，结果为results</li>
<li>如果sum &gt; 0，则说明sum对结果有增益效果，则sum保留并加上当前遍历数字</li>
<li>如果sum &lt;= 0，则说明sum对结果无增益效果，需要舍弃，则sum直接更新为当前遍历数字</li>
<li>每次比较sum 和 results的大小，将最大值置为results，遍历结束后返回结果results</li>
<li>时间复杂度为O（n）</li>
</ul>
<p>我们可以用数学符号表示为：</p>
<p>目标：</p>
<script type="math/tex; mode=display">\text{Max}\sum_{l=i}^jA[l]</script><p>子问题：</p>
<script type="math/tex; mode=display">M[j] = \text{max sum over all windows ending at j} = \max\{M[j-1]+A[j],A[j]\}</script><p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maxSubArray</span><span class="params">(self, nums)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(nums)==<span class="number">1</span>:</span><br><span class="line">    	<span class="keyword">return</span> nums[<span class="number">0</span>]</span><br><span class="line">    max_ret = nums[<span class="number">0</span>]</span><br><span class="line">    cur_max = last_max = nums[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len(nums)):</span><br><span class="line">        <span class="keyword">if</span> last_max+nums[i]&lt;nums[i]:</span><br><span class="line">            cur_max = nums[i]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            cur_max = last_max+nums[i]</span><br><span class="line">        <span class="keyword">if</span> cur_max &gt; max_ret:</span><br><span class="line">            max_ret = cur_max</span><br><span class="line">        last_max = cur_max</span><br><span class="line">    <span class="keyword">return</span> max_ret</span><br></pre></td></tr></table></figure>
<h1 id="最长上升子序列"><a href="#最长上升子序列" class="headerlink" title="最长上升子序列"></a>最长上升子序列</h1><p>目标是求一个数列$\{A_1,A_2,…A_n\}$中最长的子串，同时需要满足这个子串是递增的。同样我们可以定义$L(j)$为$j$位置结尾处最长的上升子序列，由此有$L(j)=max_{i&lt;j\text{ and }A[i]&lt;A[j]}\{L(i)\}+1$。下面我们看代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lengthOfLIS</span><span class="params">(self, nums)</span>:</span></span><br><span class="line">    <span class="keyword">if</span>(len(nums)&lt;=<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">return</span> len(nums)</span><br><span class="line">    mem = [<span class="number">1</span> <span class="keyword">for</span> _ <span class="keyword">in</span> range(len(nums))]</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>, len(nums)):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, j):</span><br><span class="line">            <span class="keyword">if</span> nums[i] &lt; nums[j]:</span><br><span class="line">                mem[j] = max(mem[j], mem[i]+<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> max(mem)</span><br></pre></td></tr></table></figure>
<h1 id="零钱兑换"><a href="#零钱兑换" class="headerlink" title="零钱兑换"></a>零钱兑换</h1><p><strong>问题描述</strong>：给定不同面额的硬币 coins 和一个总金额 amount。编写一个函数来计算可以凑成总金额所需的最少的硬币个数。</p>
<p>如果这个题我们使用贪心算法有时候会失效，比如我们的目标是凑6元零钱，而有1元、3元、4元三种货币，如果用贪心算法最后组合为1个4元2个1元，共 3枚银币，而我们全局最优的解是两个3元硬币。</p>
<p>为了求解这个问题，我们依然设计一个数组$M[j]$来维护需要凑够$j$元的零钱所需的最小硬币数量，我们有如下递推式：</p>
<script type="math/tex; mode=display">M[j]=\min_i\{M[j-v_i]\}+1</script><p>其中$v_i$为硬币种类。代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">coinChange</span><span class="params">(self, coins, amount)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> amount == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> len(coins) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line">    <span class="keyword">if</span> len(coins) == <span class="number">1</span> <span class="keyword">and</span> coins[<span class="number">0</span>] &gt; amount:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line">    mem = [<span class="number">-1</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(amount+<span class="number">1</span>)]</span><br><span class="line">    mem[<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, amount + <span class="number">1</span>):</span><br><span class="line">        cur_min = amount + <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> coins:</span><br><span class="line">            <span class="keyword">if</span> c &lt;= i:</span><br><span class="line">                cur_min = mem[i-c] <span class="keyword">if</span> mem[i-c] &lt; cur_min <span class="keyword">else</span> cur_min</span><br><span class="line">        mem[i] = cur_min + <span class="number">1</span> <span class="keyword">if</span> cur_min&lt;amount+<span class="number">1</span> <span class="keyword">else</span> amount+<span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> mem[<span class="number">-1</span>] == amount + <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> mem[<span class="number">-1</span>]</span><br></pre></td></tr></table></figure>
<h1 id="0-1背包问题"><a href="#0-1背包问题" class="headerlink" title="0-1背包问题"></a>0-1背包问题</h1><p>你只有一个容量有限的背包，总容量为c，有n个可待选择的物品，每个物品只有一件，它们都有各自的重量和价值，你需要从中选择合适的组合来使得你背包中的物品总价值最大。例如下图的对应关系：</p>
<p><img src="/posts/Alg/1.png" alt></p>
<p>我们定义$M[i,j]$为可选物品为前$i$件时且背包容量为$j$时的物品最大价值。由此我们可以导出状态转移方程：</p>
<script type="math/tex; mode=display">M[i, j] = \max\{M[i-1,j], M[i-1,j-S_i]+V_i\}</script><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">knapsack</span><span class="params">(w, v, c)</span>:</span></span><br><span class="line">    mem = np.zeros((len(w)+<span class="number">1</span>, c+<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len(w)+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>, c+<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> w[i<span class="number">-1</span>]&lt;=j:</span><br><span class="line">                mem[i,j] = max(mem[i, j], mem[i<span class="number">-1</span>,j], mem[i<span class="number">-1</span>,j-w[i<span class="number">-1</span>]]+v[i<span class="number">-1</span>])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                mem[i,j] = mem[i<span class="number">-1</span>,j]</span><br><span class="line">    <span class="keyword">return</span> mem</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
  </entry>
  <entry>
    <title>算法复现（九）—— KMP算法</title>
    <url>/posts/700f7e13.html</url>
    <content><![CDATA[<h1 id="KMP算法详解"><a href="#KMP算法详解" class="headerlink" title="KMP算法详解"></a>KMP算法详解</h1><p>KMP算法解决的是字符串间匹配的问题，我们以Leetcode上第28题为例来理解具体的KMP算法的实现过程与原理，原题如下：</p>
<p><img src="/posts/Alg/28.png" alt></p>
<p>字符串匹配问题的暴力解法自然很容易想到，也就是逐字搜索，当发现搜索的主串无法匹配子串时，返回搜索的初始位置的下一位继续匹配，具体C++实现如下：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">BF</span><span class="params">(<span class="keyword">char</span> *s1, <span class="keyword">char</span>*s2)</span></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> len = <span class="built_in">strlen</span>(s1);</span><br><span class="line">	<span class="keyword">int</span> i=<span class="number">0</span>;<span class="keyword">int</span> j=<span class="number">0</span>;</span><br><span class="line">	<span class="keyword">while</span>(s1[i]!=<span class="string">'\0'</span> &amp;&amp; s2[j]!=<span class="string">'\0'</span>)&#123;</span><br><span class="line">		<span class="keyword">if</span>(s1[i]==s2[j])&#123;</span><br><span class="line">			i++;</span><br><span class="line">			j++;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span>&#123;</span><br><span class="line">			i=i-j+<span class="number">1</span>;</span><br><span class="line">			j=<span class="number">0</span>;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span>(s2[j]==<span class="string">'\0'</span>) <span class="keyword">return</span>(i-j+<span class="number">1</span>);</span><br><span class="line">	<span class="keyword">else</span> <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>用这个方法自然也可以把这个题做出来，但这个算法的复杂度比较高，原因是每一轮匹配（失败）结束之后，主串又返回当前匹配位置的下一位开始匹配，于是损失了前面主串与字串匹配的所有信息，KMP算法的核心就是如何利用这些信息，是一个用空间换取时间的算法，它将要利用的信息存储在部分匹配表（PMT）中，也就是说将模式串的起始位置相对于主串直接向右滑动一段距离。那么问题的关键就是这段距离的长度怎么确定？就是要使用PMT表，下面具体解释这个表。</p>
<h2 id="PMT表"><a href="#PMT表" class="headerlink" title="PMT表"></a>PMT表</h2><p><strong>PMT中的值是字符串的前缀集合与后缀集合的交集中最长元素的长度</strong>：首先介绍前缀集合与后缀集合：例如，对于”aba”，它的前缀集合为{”a”, ”ab”}，后缀 集合为{”ba”, ”a”}。两个集合的交集为{”a”}，那么长度最长的元素就是字符串”a”了，长度为1，所以对于”aba”而言，它在PMT表中对应的值就是1。再比如，对于字符串”ababa”，它的前缀集合为{”a”, ”ab”, ”aba”, ”abab”}，它的后缀集合为{”baba”, ”aba”, ”ba”, ”a”}， 两个集合的交集为{”a”, ”aba”}，其中最长的元素为”aba”，长度为3。因此PMT的值即为<strong>前缀集与后缀集交集中最长的元素</strong></p>
<p>得到的表大概长这样：</p>
<p><img src="/posts/Alg/28_1.png" alt></p>
<p>那么我们应该怎么用这个表呢？如图你所示，要在主字符串”ababababca”中查找模式字符串”abababca”。如果在 j 处字符不匹配，那么由于前边所说的模式字符串 PMT 的性质，主字符串中 i 指针之前的 PMT[j −1] 位就一定与模式字符串的第 0 位至第 PMT[j−1] 位是相同的。这是因为主字符串在 i 位失配，也就意味着主字符串从 i−j 到 i 这一段是与模式字符串的 0 到 j 这一段是完全相同的。而我们上面也解释了，模式字符串从 0 到 j−1 ，在这个例子中就是”ababab”，其前缀集合与后缀集合的交集的最长元素为”abab”， 长度为4。所以就可以断言，主字符串中i指针之前的 4 位一定与模式字符串的第0位至第 4 位是相同的，即长度为 4 的后缀与前缀相同。这样一来，我们就可以将这些字符段的比较省略掉。具体的做法是，保持i指针不动，然后将j指针指向模式字符串的PMT[j −1]位即可。总结：PMT系数帮助我们快速定位J，避免i回指，同时减小J回指的长度。</p>
<p><strong>注意：PMT表是根据子串建立的</strong></p>
<p>有了上面的思路，我们就可以使用PMT加速字符串的查找了。我们看到如果是在 j 位 失配，那么影响 j 指针回溯的位置的其实是第 j −1 位的 PMT 值，所以为了编程的方便， 我们不直接使用PMT数组，而是将PMT数组向后偏移一位。我们把新得到的这个数组称为next数组。下面给出根据next数组进行字符串匹配加速的字符串匹配程序。其中要注意的一个技巧是，在把PMT进行向右偏移时，第0位的值，我们将其设成了-1，这只是为了编程的方便，并没有其他的意义。在本节的例子中，next数组如下表所示。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>char</th>
<th>a</th>
<th>b</th>
<th>a</th>
<th>b</th>
<th>a</th>
<th>b</th>
<th>c</th>
<th>a</th>
</tr>
</thead>
<tbody>
<tr>
<td>index</td>
<td>0</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>5</td>
<td>6</td>
<td>7</td>
</tr>
<tr>
<td>pmt</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>next</td>
<td>-1</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>0</td>
</tr>
</tbody>
</table>
</div>
<h2 id="next数组求法"><a href="#next数组求法" class="headerlink" title="next数组求法"></a>next数组求法</h2><p>现在，我们再看一下如何编程快速求得next数组。其实，求next数组的过程完全可以看成字符串匹配的过程，即以模式（就是target）字符串为主字符串，以模式字符串（就是target）的前缀为目标字符串，一旦字符串匹配成功，那么当前的next值就是匹配成功的字符串的长度。</p>
<p>具体来说，就是从模式字符串的第一位(注意，不包括第0位)开始对自身进行匹配运算（因为i=0时，pmt系数为0）。 在任一位置，能匹配的最长长度就是当前位置的next值。如下图所示。</p>
<p><img src="/posts/Alg/28_2.png" alt></p>
<p><img src="/posts/Alg/28_3.png" alt></p>
<p><img src="/posts/Alg/28_4.png" alt></p>
<p><img src="/posts/Alg/28_5.png" alt></p>
<p><img src="/posts/Alg/28_6.png" alt></p>
<h1 id="完整代码-cpp"><a href="#完整代码-cpp" class="headerlink" title="完整代码(cpp)"></a>完整代码(cpp)</h1><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">KMP</span><span class="params">(<span class="keyword">char</span> * t, <span class="keyword">char</span> * p)</span></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> next[<span class="built_in">strlen</span>(p)];</span><br><span class="line">	getNext(p, next);</span><br><span class="line">	<span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">int</span> j = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">while</span> (i &lt; <span class="built_in">strlen</span>(t) &amp;&amp; j &lt; <span class="built_in">strlen</span>(p))</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">if</span> (j == <span class="number">-1</span> || t[i] == p[j])</span><br><span class="line">		&#123;</span><br><span class="line">			i++;</span><br><span class="line">			j++;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span></span><br><span class="line">			j = next[j];</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (j == <span class="built_in">strlen</span>(p))</span><br><span class="line">		<span class="keyword">return</span> i - j;</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">		<span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">getNext</span><span class="params">(<span class="keyword">char</span> *p, <span class="keyword">int</span> *next)</span></span>&#123;</span><br><span class="line">	next[<span class="number">0</span>] = <span class="number">-1</span>;</span><br><span class="line">	<span class="keyword">int</span> i = <span class="number">0</span>, j = <span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">while</span>(i &lt; <span class="built_in">strlen</span>(p))&#123;</span><br><span class="line">		<span class="keyword">if</span>(j == <span class="number">-1</span> || p[i] == p[j])&#123;</span><br><span class="line">			++i;</span><br><span class="line">			++j;</span><br><span class="line">			next[i] = j;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span>&#123;</span><br><span class="line">			j = next[j];</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>部分引用自知乎: <a href="https://www.zhihu.com/question/21923021/answer/281346746" target="_blank" rel="noopener">https://www.zhihu.com/question/21923021/answer/281346746</a></p>
</blockquote>
]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
  </entry>
  <entry>
    <title>算法复现（七）—— 手推SVM</title>
    <url>/posts/d0757ece.html</url>
    <content><![CDATA[<p>SVM有三宝：<strong>间隔，对偶，核技巧</strong>，下面一一阐述：</p>
<h1 id="间隔"><a href="#间隔" class="headerlink" title="间隔"></a>间隔</h1><h2 id="什么是线性可分"><a href="#什么是线性可分" class="headerlink" title="什么是线性可分"></a>什么是线性可分</h2><p><img src="/posts/Alg/svm_1.jpg" alt></p>
<p>上面的二维界面上，两类点被一条直线完全分开，叫做线性可分。</p>
<p>严格的数学定义是：$D_0$和$D_1$是$n$维欧氏空间中的两个点集。如果存在$n$维向量$w$和实数$b$，使得所有属于$D_0$的点$x_i$都有$wx_i+b\gt0$，而对于所有属于$D_1$的点$X_i$则有$wx_j+b\lt0$。则我们称$D_0$和$D_1$线性可分。</p>
<h2 id="什么是超平面"><a href="#什么是超平面" class="headerlink" title="什么是超平面"></a>什么是超平面</h2><p>上面提到的，将$D_0$和$D_1$完全正确地划分开的$wx+b=0$，就是一个超平面。以最大间隔把两类样本分开的超平面是最佳超平面，也称之为最大间隔超平面。<br>特征：</p>
<ul>
<li>两类样本分别分隔在该超平面的两侧</li>
<li>两侧距离超平面最近的样本点到超平面的距离被最大化了</li>
</ul>
<h2 id="什么是支持向量"><a href="#什么是支持向量" class="headerlink" title="什么是支持向量"></a>什么是支持向量</h2><p><img src="/posts/Alg/svm_2.jpg" alt></p>
<p>在蓝色样本中存在一些距离我们的超平面最近的一些点，这些点叫做支撑向量。</p>
<h2 id="svm的最优化问题是什么"><a href="#svm的最优化问题是什么" class="headerlink" title="svm的最优化问题是什么"></a>svm的最优化问题是什么</h2><p>首先我们想要最优化的是各类样本点到超平面的距离最远（其实也就是找到最大间隔超平面），任意一个超平面可以用下面这个线性方程来描述：</p>
<script type="math/tex; mode=display">w^Tx+b = 0</script><p><strong>n维空间距离又是怎么算的呢？</strong></p>
<p>我们看二维空间点$(x,y)$到直线$Ax+By+C=0$的的距离计算公式是：</p>
<script type="math/tex; mode=display">\frac{|Ax+By+C|}{\sqrt{A^2+B^2}}</script><p>拓展到$n$维也是同样的，点$x$到直线$w^Tx+b=0$的距离为：</p>
<script type="math/tex; mode=display">\frac{|w^Tx+b|}{||w||}</script><p>其中$||w||=\sqrt{w_i^2+…+w_d^2}$</p>
<p><img src="/posts/Alg/svm_3.jpg" alt></p>
<p>支撑向量是样本中离超平面最近的点，所以所有的其他的红色点距离超平面的距离一定大于$d$，那么我们有这样一个公式：</p>
<script type="math/tex; mode=display">\left\{\begin{array}{ll}
\frac{w^{T} x_{i}+b}{\|w\|} \geq d & y_{i}=1 \\
\frac{w^{T} x_{i}+b}{\|w\|} \leq-d & y_{i}=-1
\end{array}\right.</script><p>稍作转化可以得到：</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{ll}
\frac{w^{T} x_{i}+b}{\|w\| d} \geq 1 & y_{i}=1 \\
\frac{w^{T} x_{i}+b}{\|w\| d} \leq-1 & y_{i}=-1
\end{array}\right.</script><p>由于$||w_i||d$为常数，可在所有系数上同时消去之，然后有（仍以原变量名命名）：</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{ll}
w^{T} x_{i}+b \geq 1 & y_{i}=1 \\
w^{T} x_{i}+b \leq-1 & y_{i}=-1
\end{array}\right.</script><p>对于上面这个方程我们还能简写一下：</p>
<script type="math/tex; mode=display">
y_{i}\left(w^{T} x_{i}+b\right) \geq 1</script><p>超平面方程为：</p>
<script type="math/tex; mode=display">
w^{T} x_{i}+b = \pm1</script><p>有下图：<br><img src="/posts/Alg/svm_4.jpg" alt></p>
<p>并且每个支撑向量到超平面的距离可以写为：</p>
<script type="math/tex; mode=display">d=\frac{|w^Tx_i+b|}{||w||}</script><p>我们要最大化这个距离，也就是</p>
<script type="math/tex; mode=display">max\frac{|w^Tx_i+b|}{||w||}</script><p>在样本点确定以后，$|w^Tx_i+b|$是一个常数，所以这个式子就变成了：</p>
<script type="math/tex; mode=display">max\frac{1}{||w||}</script><p>也就是：</p>
<script type="math/tex; mode=display">min||w||</script><p>为了方便，我们取</p>
<script type="math/tex; mode=display">min\frac12||w||^2</script><p>所以得到最后的优化问题是：</p>
<script type="math/tex; mode=display">min\frac12||w||^2</script><script type="math/tex; mode=display">s.t. y_i(w^Tx_i+b)\ge1</script><h1 id="对偶问题"><a href="#对偶问题" class="headerlink" title="对偶问题"></a>对偶问题</h1><h2 id="约束条件下的目标函数如何求解最优化问题"><a href="#约束条件下的目标函数如何求解最优化问题" class="headerlink" title="约束条件下的目标函数如何求解最优化问题"></a>约束条件下的目标函数如何求解最优化问题</h2><p>可以使用拉格朗日乘子法进行求解，将原本有约束的优化问题转化为对拉格朗日函数的无约束优化问题。<br>拉格朗日乘子法的定义（以三维空间为例）：</p>
<script type="math/tex; mode=display">L(x,y,\lambda)=f(x,y)+\lambda g(x,y)</script><p>其中$\lambda$是拉格朗日乘子</p>
<p>拉格朗日函数把原本的目标函数和其限制条件整合成了一个函数，这样子约束问题就不存在了，我<br>们可以直接对该目标函数求解其极值。</p>
<h2 id="怎么理解对偶问题"><a href="#怎么理解对偶问题" class="headerlink" title="怎么理解对偶问题"></a>怎么理解对偶问题</h2><p>首先，原问题是：</p>
<script type="math/tex; mode=display">min_{w,b}\frac12||w||^2</script><script type="math/tex; mode=display">s.t. g_i(w,b)=1-y_i(wx_i+b)\le0,i=1,2,...,m</script><p>拉格朗日乘子法转化后，变成了：</p>
<script type="math/tex; mode=display">L(w,b,\lambda)=\frac12||w||^2+\sum_{i=1}^m\lambda_i[1-y_i(wx_i+b)]</script><p>于是原问题变成：</p>
<script type="math/tex; mode=display">min_{w,b}max_\lambda L(w,b,\lambda)</script><script type="math/tex; mode=display">s.t. \lambda_i\ge0</script><p>我们首先直观的看一下，为什么转化后的下面的式子，可以替代上面的式子。<br>由于$\lambda_i\ge 0$<br>当$1-y_i(wx_i+b)\gt0$时，$max_\lambda L(w,b,\lambda)$是无穷，无意义<br>当$1-y_i(wx_i+b)\le0$时，$max_\lambda L(w,b,\lambda)$是$\frac12||w||^2$<br>所以$min(\infty,\frac12 ||w||^2) = \frac12||w||^2$</p>
<p>所以转化后的式子实际上和原来想表达的是的一样的。</p>
<h2 id="什么是对偶问题"><a href="#什么是对偶问题" class="headerlink" title="什么是对偶问题"></a>什么是对偶问题</h2><p>对偶问题实际上就是将</p>
<script type="math/tex; mode=display">min_{w,b}max_\lambda L(w,b,\lambda)</script><script type="math/tex; mode=display">s.t. \lambda_i \ge 0</script><p>变成了</p>
<script type="math/tex; mode=display">min_\lambda max_{w,b} L(w,b,\lambda)</script><script type="math/tex; mode=display">s.t. \lambda_i \ge 0</script><p>我们假设有一个函数$f$，则一定有：</p>
<script type="math/tex; mode=display">min maxf\ge max minf</script><p>也就是说，最大的里面挑出来的最小的，也要比最小的里面挑出来的最大的要大。这个关系实际上就是弱对偶关系，那什么是强对偶关系呢？</p>
<script type="math/tex; mode=display">min maxf =  max minf</script><p>此即为强对偶的关系。</p>
<p>至于为什么我们这里可以使用强对偶关系，是由于：</p>
<p>如果主问题是凸优化问题，也就是说当：</p>
<ol>
<li>拉格朗日函数中的$f(x)$和$g_i(x)$都是凸函数；</li>
<li>$h_i(x)$是仿射函数；</li>
<li>主问题可行域中至少有一点使得不等式约束严格成立。即存在$x$，对所有$j$，均有$g_i(x)\lt 0$。</li>
</ol>
<p>当1、2、3同时成立时，强对偶性成立。</p>
<h2 id="KKT条件"><a href="#KKT条件" class="headerlink" title="KKT条件"></a>KKT条件</h2>]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
  </entry>
  <entry>
    <title>算法复现（六）—— 决策树</title>
    <url>/posts/16501e9e.html</url>
    <content><![CDATA[<h1 id="决策树的直观理解"><a href="#决策树的直观理解" class="headerlink" title="决策树的直观理解"></a>决策树的直观理解</h1><p>顾名思义，决策树就是用一棵树来表示我们的整个决策过程。这棵树可以是二叉树（比如CART只能是二叉树），也可以是多叉树（比如ID3、C4.5可以是多叉树或二叉树）。根节点包含整个样本集，每个叶节点都对应一个决策结果（注意，不同的叶节点可能对应同一个决策结果），每一个内部节点都对应一次决策过程或者说是一次属性测试。从根节点到每个叶节点的路径对应一个判定测试序列。</p>
<p><img src="/posts/Alg/jcs.jpg" alt></p>
<p>就像上面这个例子，训练集由三个特征：outlook(天气)，humidity（湿度），windy（是否有风）。那么我们该如何选择特征对训练集进行划分那？连续型特征（比如湿度）划分的阈值又是如何确定的呢？决策树的生成就是不断的选择最优的特征对训练集进行划分，是一个递归的过程。递归返回的条件有三种：</p>
<ol>
<li>当前节点包含的样本属于同一类别，无需划分</li>
<li>当前属性集为空，或所有样本在属性集上取值相同，无法划分</li>
<li>当前节点包含样本集合为空，无法划分</li>
</ol>
<h1 id="ID3、C4-5、CART"><a href="#ID3、C4-5、CART" class="headerlink" title="ID3、C4.5、CART"></a>ID3、C4.5、CART</h1><p>这三个是非常著名的决策树算法。简单粗暴来说，ID3使用<strong>信息增益</strong>作为选择特征的准则；C4.5使用<strong>信息增益比</strong>作为选择特征的准则；CART使用<strong>Gini指数</strong>作为选择特征的准则。</p>
<h2 id="ID3"><a href="#ID3" class="headerlink" title="ID3"></a>ID3</h2><p>熵表示的是数据中包含的信息量大小。熵越小，数据的纯度越高，也就是说数据越趋于一致，这是我们希望的划分之后每个子节点的样子。</p>
<p>信息增益 = 划分前熵 - 划分后熵。信息增益越大，则意味着使用属性a来进行划分所获得的“纯度提升”越大。也就是说，用属性a来划分训练集，得到的结果中纯度比较高。</p>
<p>注意：<strong>ID3仅仅能够处理离散属性。</strong></p>
<p>信息熵：</p>
<script type="math/tex; mode=display">H(D) = -\sum_{k=1}^K\frac{|C_k|}{|D|}log_2\frac{C_k}{D}</script><p>条件熵</p>
<script type="math/tex; mode=display">H(D|A) = \sum_{i=1}^n\frac{|D_i|}{|D|}H(D_i) = \sum_{i=1}^n\frac{|D_i|}{|D|}(-\sum_{k=1}^K\frac{|D_{ik}|}{|D_i|}log_2\frac{|D_{ik}|}{|D_i|})</script><p><img src="/posts/Alg/jcs_2.jpg" alt></p>
<p>在上面的问题中</p>
<script type="math/tex; mode=display">H(D) = -\frac35log_2\frac35-\frac25log_2\frac25 = 0.97</script><p>根据年龄进行划分：</p>
<script type="math/tex; mode=display">H(D|年龄) = \frac15(-0)+\frac45(-\frac24log_2\frac24-\frac24log_2\frac24)=0.8</script><h2 id="C4-5"><a href="#C4-5" class="headerlink" title="C4.5"></a>C4.5</h2><p>C4.5克服了ID3仅仅能够处理离散属性的问题，以及信息增益偏向选择取值较多特征的问题，使用信息增益比来选择特征。信息增益比 = 信息增益 /划分前熵 选择信息增益比最大的作为最优特征。</p>
<p>C4.5处理连续特征是先将特征取值排序，以连续两个值中间值作为划分标准。尝试每一种划分，并计算修正后的信息增益，选择信息增益最大的分裂点作为该属性的分裂点。（事实上ID3也可以，不过最开始设计者提出来的时候并没有提出这个Idea，于是就认为没有）C4.5更主要还是能够对冲掉特征较多的问题，也就是ID3会更倾向于划分子类更多的特征，而C4.5解决了这个问题（增加惩罚项——取值熵）。</p>
<p>信息增益比：</p>
<script type="math/tex; mode=display">g_R(D,A)=\frac{g(D,A)}{H_A(D)}</script><p>其中分母是取值熵：</p>
<script type="math/tex; mode=display">H_A(D)=-\sum_{i=1}^n\frac{|D_i|}{|D|}log_2\frac{|D_i|}{|D|}</script><p>我们计算长相的取值熵：</p>
<script type="math/tex; mode=display">H_{长相}(D)=\frac15log_215-\frac35log_2\frac35-\frac15log_2\frac15=1.371</script><p>那么，特征长相的信息增益比是：</p>
<script type="math/tex; mode=display">g_R(D,长相) = \frac{0.42}{1.371} = 0.306</script><h2 id="CART"><a href="#CART" class="headerlink" title="CART"></a>CART</h2><p>CART与ID3，C4.5不同之处在于CART生成的树必须是二叉树。也就是说，无论是回归还是分类问题，无论特征是离散的还是连续的，无论属性取值有多个还是两个，内部节点只能根据属性值进行二分。CART的全称是分类与回归树。从这个名字中就应该知道，CART既可以用于分类问题，也可以用于回归问题。</p>
<p>回归树中，使用平方误差最小化准则来选择特征并进行划分。每一个叶子节点给出的预测值，是划分到该叶子节点的所有样本目标值的均值，这样只是在给定划分的情况下最小化了平方误差。要确定最优化分，还需要遍历所有属性，以及其所有的取值来分别尝试划分并计算在此种划分情况下的最小平方误差，选取最小的作为此次划分的依据。由于回归树生成使用平方误差最小化准则，所以又叫做最小二乘回归树。<br>分类树中使用Gini指数最小化准则来选择特征并进行划分；Gini指数表示集合的不确定性，或者是不纯度。基尼指数越大，集合不确定性越高，不纯度也越大。这一点和熵类似。另一种理解基尼指数的思路是，基尼指数是为了最小化误分类的概率。</p>
<p>我们通过百面书上的例子来说明一下Gini系数的计算过程：</p>
<p><strong>Gini纯度公式</strong>：</p>
<script type="math/tex; mode=display">Gini(D)=1-\sum_{k=1}^n(\frac{|C_k|}{|D|})^2</script><p>按特征A切成两份后的Gini指数公式：</p>
<script type="math/tex; mode=display">Gini(D|A) = \sum_{i=1}^n\frac{|D_i|}{|D|}Gini(D_i)</script><p>大家可以根据上面的例子自己做尝试，可以参考西瓜书这一节内容。</p>
<p><strong>Gini系数相比起熵不需要对数运算，更加高效，并且Gini指数更偏向于连续属性，熵更偏向于离散属性</strong></p>
<h1 id="剪枝"><a href="#剪枝" class="headerlink" title="剪枝"></a>剪枝</h1><p>决策树算法很容易过拟合（overfitting），剪枝算法就是用来防止决策树过拟合，提高泛化性能的方法。剪枝分为预剪枝与后剪枝。</p>
<ul>
<li>预剪枝是指在决策树的生成过程中，对每个节点在划分前先进行评估，若当前的划分不能带来泛化性能的提升，则停止划分，并将当前节点标记为叶节点。</li>
<li>后剪枝是指先从训练集生成一颗完整的决策树，然后自底向上对非叶节点进行考察，若将该节点对应的子树替换为叶节点，能带来泛化性能的提升，则将该子树替换为叶节点。</li>
</ul>
<p>那么怎么来判断是否带来泛化性能的提升呢？最简单的就是留出法，即预留一部分数据作为验证集来进行性能评估。</p>
<p>我们讲述一下百面书上的代价复杂剪枝：<br>女孩需要对80个人进行见或不见的分类。假设根据某种规则，已经得到了一棵CART决策树$T_0$：</p>
<p>从$T_0$开始，裁剪$T_i$中关于训练数据集合误差增加最小的分支以得到$T_{i+1}$。具体地，当一棵树$T$在结点$t$处剪枝时，它的误差增加可以用$R(t)-R(T_t)$表示，其中表示，其中$R(t)$进行剪枝之后的该结点误差，$R(T_t)$表示未进行剪枝时子树$T_t$的误差。考虑到树的复杂性因素，我们用$|L(T_t)|$表示子树$T_t$的叶子结点个数，则树在结点$t$处剪枝后的误差增加率为：</p>
<script type="math/tex; mode=display">\alpha = \frac{R(t)-R(T_t)}{|L(T_t)|-1}</script><p><img src="/posts/Alg/jcs_3.jpg" alt></p>
<p>在$t_3$处剪枝，剪枝之前误差是1+2（类别中较少的样本数），剪枝之后误差是4。子树叶节点个数为2。误差增加率为$\alpha(t_3)=\frac{4-(1+2)}{2-1}=1$</p>
<p>其他的误差增加率依次计算。</p>
<p><strong>问</strong>：决策树中连续值和缺失值特征是如何处理的？<br><strong>答</strong>：决策树中，对于连续属性，假设有n个样本，那么首先按照取值从小到大进行排序。取每两个值的中值作为候选<br>的划分点进行划分。n个样本，对应有n-1个区间，也就是n-1个候选划分点。尝试所有划分点之后，分别计算信息增<br>益，选取信息增益最大的划分点即可。对于属性有缺失值的情况，划分过程中计算属性信息增益的时候，只使用属性<br>没有缺失值的样本进行信息增益的计算。确定好分类之后，对于在该属性值有缺失的样本，将被归入所有的分支节<br>点。</p>
]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
  </entry>
  <entry>
    <title>算法复现（五）—— 线性回归与逻辑回归</title>
    <url>/posts/46dadf6.html</url>
    <content><![CDATA[<h1 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h1><p>我们常说的变量关系有两种——函数关系和变量关系。线性回归是回归分析中的一个特例，回归分析研究的是变量间的相互关系，我们下面简要说明线性回归的推导。</p>
<p>首先设$Y$与$X$的关系为：$Y=\theta^{T} X+\epsilon$，上式中，$\epsilon$是$m×1$维向量，代表$m$个样本相对于线性回归方程的上下浮动程度。$\epsilon$是独立同分布的，由中心极限定理，$\epsilon$分布服从均值为0，方差为$\sigma^2$的正态分布。</p>
<p>结合上面的公式，对每个样本来说，有：$\varepsilon^{(j)}=y^{(j)}-\theta^{T} x^{(j)}$<br>上式中， $j \in(1,2, \cdots, m)$，$\varepsilon$分布服从均值为0，方差为$\sigma^{2}$的正态分布，所以:</p>
<script type="math/tex; mode=display">f\left(\varepsilon^{(j)}\right)=\frac{1}{\sqrt{2 \pi} \sigma} e^{-\frac{\left(\epsilon^{(j)})^{2}\right.}{2 \sigma^{2}}}</script><p>将 $\varepsilon^{(j)}=y^{(j)}-\theta^{T} x^{(j)}$ 代入上式, 有:</p>
<script type="math/tex; mode=display">f(y^{(j)} | x^{(j)} ; \theta)=\frac{1}{\sqrt{2 \pi \sigma}} e^{-\frac{(y^{(j)}-\theta^Tx^{(j)})^2}{2 \sigma^{2}}}</script><p>下面的公式推导用到了如下对数转换公式：</p>
<script type="math/tex; mode=display">\log a+\log b=\log a b</script><script type="math/tex; mode=display">\log a b=\log a+\log b</script><p>似然函数：</p>
<script type="math/tex; mode=display">L(\theta)=\prod_{j=1}^{m} f\left(y^{(j)} | x^{(j)} ; \theta\right)=\prod_{j=1}^{m} \frac{1}{\sqrt{2 \pi} \sigma} e^{-\frac{(y^{(j)}-\theta^Tx^{(j)})}{2 \sigma^{2}}^2}</script><p>两边取对数, $\Leftrightarrow l(\theta)=\log L(\theta)$</p>
<script type="math/tex; mode=display">\begin{array}{l}
l(\theta)=\log \prod_{j=1}^{m} \frac{1}{\sqrt{2 \pi} \sigma} e^{-\frac{\left(y^{(j)}-g^{T} r^{(1)}\right)^{2}}{2 \sigma^{2}}} =\sum_{j=1}^{m} \log \frac{1}{\sqrt{2 \pi \sigma}} e^{-\frac{\left(y^{(j)}-b^{T} z^{(j)}\right)^{2}}{2 \sigma^{2}}} \\
l_{\theta}(\theta)=m \log \frac{1}{\sqrt{2 \pi} \sigma}-\frac{1}{\sigma^{2}} \cdot \frac{1}{2} \sum_{j=1}^{m}\left(y^{(j)}-\theta^{T} x^{(j)}\right)^{2}
\end{array}</script><p>上式中，去掉常数项, 去掉负号，貝将求极大似然函数最大值转换为求成本函数最小值：</p>
<script type="math/tex; mode=display">J(\theta)=\frac{1}{2} \sum_{j=1}^{m}\left(y^{(j)}-\theta^{T} x^{(j)}\right)^{2}</script><p>即：</p>
<script type="math/tex; mode=display">J(\theta)=\frac{1}{2} \sum_{j=1}^{m}\left(y^{(j)}-h_{\theta}\left(x^{(j)}\right)\right)^{2}</script><p>这不就是最小二乘法吗~要解之获得最小值，即求导置0即可，当数据量大时需采用梯度下降法等算法以解之：</p>
<script type="math/tex; mode=display">
\begin{array}{l}
J(\theta)=\frac{1}{2}(X \theta-Y)^{T}(X \theta-Y) \\
J(\theta)=\frac{1}{2}\left(\theta^{T} X^{T}-Y^{T}\right)(X \theta-Y) \\
J(\theta)=\frac{1}{2}\left(\theta^{T} X^{T} X \theta-\left(\theta^{T} X^{T} Y-Y^{T} X \theta+Y^{T} Y\right)\right.
\end{array}</script><p>对上式求导数：</p>
<script type="math/tex; mode=display">
\nabla J(\theta)=\frac{1}{2}\left(2 X^{T} X \theta-X^{T} Y-\left(Y^{T} X\right)^{T}\right)</script><script type="math/tex; mode=display">
\begin{array}{l}
\nabla J(\theta)=\frac{1}{2}\left(2 X^{T} X \theta-X^{T} Y-X^{T} Y\right) \\
\nabla J(\theta)=\frac{1}{2}\left(2 X^{T} X \theta-2 X^{T} Y\right) \\
\nabla J(\theta)=X^{T} X \theta-X^{T} Y
\end{array}</script><p>令上式 $=0$，即：</p>
<script type="math/tex; mode=display">\nabla J(\theta)=X^{T} X \theta-X^{T} Y=0</script><p>可求得：</p>
<script type="math/tex; mode=display">\theta=\left(X^{T} X\right)^{-1} X^{T} Y</script><p>以上就是线性回归，下面我们介绍逻辑回归。</p>
<h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><p>逻辑回归虽然名字有回归二字，但其重点是在解决二分类问题，即找一条决策边界来完成分类的决策，我们熟知的线性回归的决策函数是：</p>
<script type="math/tex; mode=display">h_\theta(x) = \theta^Tx</script><p>而逻辑回归则是把线性回归的决策函数做一个softmax输出：</p>
<script type="math/tex; mode=display">h_\theta(x)=\frac{1}{1+e^{-\theta^Tx}}</script><p>这个决策函数可以将$(-\infty,+\infty)$的数映射到$(0,1)$之间，成为一个概率输出。</p>
<p>除了这一点（决策函数）和线性回归不一样，逻辑回归的本质还是线性回归。</p>
<p>逻辑回归自然是能实现多分类的，实现方式分为一对一和一对多两种：</p>
<p>其中一对一分类是每两个类之间构建一个分类器，共需要$\frac{N(N-1)}{2}$个分类器；一对多顾名思义需要$N$个分类器</p>
<p>逻辑回归的优点：可解释性高，工业中可控度高。</p>
]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
  </entry>
  <entry>
    <title>算法复现（四）—— 滑动窗口</title>
    <url>/posts/465ba12d.html</url>
    <content><![CDATA[<p>我们首先看LeetCode中的一道题：</p>
<p><img src="/posts/Alg/209.png" alt></p>
<p>我们很容易想到这个算法的暴力解法，有$O(n^3)$的时间复杂度。我们可以先试着优化之使之称为具有$O(n^2)$时间复杂度的算法：我们首先维护一个数组，这个数组中记录了该位置之前所有数之和，当我们需要计算滑动窗口时，我们只需要将两个数相减即可，此时具有$O(n^2)$的时间复杂度。我们再思考一下原来暴力解的问题出在哪，其实我们在计算出i到j所有元素之和后，要继续计算i到j+1所有元素之和，是只需要利用前一个结果加上第j+1个元素即可的。因此这些个子数组之间是存在大量重复计算的。我们可以设计一个滑动窗口的思路.</p>
<p>首先我们定义两个指针left和right，两者通过分别向右滑动，前者能够使滑动窗口的和减小，后者能使和增大，开始时两者重合，窗口的和就是重合点所在的数。</p>
<p>下面我们分三个步骤：</p>
<ol>
<li>right向右滑动，使和变大，当恰好 大于等于s时，记录滑窗所包括的子数组长度ans，若ans已有数值，需判断新值是否小于旧值，若是，更新ans。</li>
<li>left向右滑动，判断是否仍大于等于s</li>
<li>若是，重复步骤2，若否，更新ans并转步骤1，直到有边框达到最右边</li>
</ol>
<p>下面我们看代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">minSubArrayLen</span><span class="params">(self, s, nums)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type s: int</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        i, j, r = <span class="number">0</span>, <span class="number">0</span>, len(nums)+<span class="number">1</span></span><br><span class="line">        sums = []</span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> nums:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> sums:</span><br><span class="line">                sums.append(num)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                sums.append(sums[<span class="number">-1</span>]+num)</span><br><span class="line">        <span class="keyword">while</span> i &lt; len(nums) <span class="keyword">and</span> j &lt; len(nums):</span><br><span class="line">            <span class="keyword">if</span> sums[j] - sums[i] + nums[i] &lt; s:</span><br><span class="line">                j += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> j + <span class="number">1</span> - i &lt; r:</span><br><span class="line">                    r = j + <span class="number">1</span> - i</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> r != len(nums) + <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> r</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>结果如下：</p>
<p><img src="/posts/Alg/209_sol.png" alt></p>
]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
  </entry>
  <entry>
    <title>算法复现（三）—— 双指针</title>
    <url>/posts/3defe89c.html</url>
    <content><![CDATA[<p>双指针算法是数组问题中常常用到的算法，主要分为对撞指针和快慢指针两种.</p>
<h1 id="对撞指针"><a href="#对撞指针" class="headerlink" title="对撞指针"></a>对撞指针</h1><p>我们先看Leetcode的第167题：</p>
<p><img src="/posts/Alg/167.png" alt></p>
<p>最直接的思考：暴力解法，双层遍历，令i和j同时遍历，看nums[i]+nums[j]是否等于target，此时时间复杂度是$O(n^2)$，事实上我们提交此算法到Leetcode，会提示Time Exceed，因此我们必须想出更高效的思路。</p>
<p>事实上，我们很容易看出，这个暴力解法忽略了这个数组一个很重要的特征——这个数组是有序的。当我们想到这一点，我们就知道在搜索时我们可以使用二分搜索的方法，时间复杂度就降为了$O(nlogn)$，此时算法比前面的暴力解法自然高效多了。</p>
<p>对这个问题，实际上存在一种时间复杂度为$O(n)$的解答：</p>
<p>初始情况下，我们将左指针放在数组的最左边，右指针放在数组的最右边，计算nums[i]+nums[j]是否等于target。如果是则返回之，若小于target，左边指针向右移动（增大数值），若大于target，则右指针向左移动（减小数值），好了，那我们直接来实现吧~</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">twoSum</span><span class="params">(self, numbers: List[int], target: int)</span> -&gt; List[int]:</span></span><br><span class="line">        i, j = <span class="number">0</span>, len(numbers)<span class="number">-1</span></span><br><span class="line">        <span class="keyword">while</span>((numbers[i]+numbers[j])!=target <span class="keyword">and</span> i&lt;j):</span><br><span class="line">            <span class="keyword">if</span> numbers[i]+numbers[j]&lt;target:</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                j -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> [i+<span class="number">1</span>,j+<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<p>结果为：</p>
<p><img src="/posts/Alg/167_sol1.png" alt></p>
<p>其他用到对撞指针的问题：</p>
<blockquote>
<p>125 Valid Palindrome<br>344 Reverse String<br>345 Reverse Vowels of a String<br>11  Container With Most Water(难度较高)</p>
</blockquote>
<h1 id="快慢指针"><a href="#快慢指针" class="headerlink" title="快慢指针"></a>快慢指针</h1><p>我们看到Leetcode第142题：</p>
<p><img src="/posts/Alg/142.png" alt></p>
<p>如果我们用一个Set保存已经访问过的节点，我们可以遍历整个列表并返回第一个出现重复的节点。这可以很好地解决这道题，但若我们增加一个条件：空间复杂度为$)(1)$，那么我们就不能使用这种算法，接下来我们介绍快慢指针的思想：</p>
<p>当一个跑的快的人与一个跑的慢的人在一条赛道上赛跑（无止尽），在某一个时刻，跑的快的人一定会从后面赶上跑得慢的人。类比之，我们定义快指针fast一次走两步，慢指针slow一次走一步，最终他们会在环中的某个位置相遇（最小公倍数）。</p>
<p><strong>快慢指针的步骤</strong>：</p>
<ol>
<li>fast走到链表末，返回null</li>
<li>fast=slow，两只真第一次相遇，slow指针同时从相遇的位置和最开始的位置出发，相遇的位置即为环入口。</li>
</ol>
<p>证明：</p>
<ul>
<li>a = 从开始位置到环入口的步数</li>
<li>b = 一环步数</li>
<li>fast = 2 * slow</li>
<li>fast = slow + n*b</li>
<li>=&gt; slow = n*b</li>
</ul>
<p>下面我们来看代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def detectCycle(self, head: ListNode) -&gt; ListNode:</span><br><span class="line">        fast, slow &#x3D; head, head</span><br><span class="line">        while fast !&#x3D; None:</span><br><span class="line">            fast &#x3D; fast.next</span><br><span class="line">            if fast &#x3D;&#x3D; None:</span><br><span class="line">                break</span><br><span class="line">            fast &#x3D; fast.next</span><br><span class="line">            slow &#x3D; slow.next</span><br><span class="line">            if slow &#x3D;&#x3D; fast:</span><br><span class="line">                break</span><br><span class="line">        if fast &#x3D;&#x3D; None:</span><br><span class="line">            return None</span><br><span class="line">        p1, p2&#x3D; slow, head</span><br><span class="line">        while p1 !&#x3D; p2:</span><br><span class="line">            p1 &#x3D; p1.next</span><br><span class="line">            p2 &#x3D; p2.next</span><br><span class="line">        return p1</span><br></pre></td></tr></table></figure>
<p>结果为</p>
<p><img src="/posts/Alg/142_sol.png" alt></p>
]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
  </entry>
  <entry>
    <title>Python深度学习（三）深度学习用于文本和序列</title>
    <url>/posts/a98b7769.html</url>
    <content><![CDATA[<p>本节将介绍使用深度学习模型处理文本（可以将其理解为单词序列或字符序列）、时间序列和一般的序列数据。用于处理序列的两种基本的深度学习算法分别是循环神经网络（recurrent neural network）和一维卷积神经网络（1D convnet），后者是二维卷积神经网络的一维版本。下面将讨论这两种方法。<br>这些算法的应用包括：</p>
<ul>
<li>文档分类和时间序列分类，比如识别文章的主题或书的作者；</li>
<li>时间序列对比，比如估测两个文档或两支股票行情的相关程度；</li>
<li>序列到序列的学习，比如将英语翻译成法语；</li>
<li>情感分析，比如将推文或电影评论的情感划分为正面或负面；</li>
<li>时间序列预测，比如根据某地最近的天气数据来预测未来天气。</li>
</ul>
<p>本节的示例重点讨论两个小任务：一个是IMDB数据集的情感分析，这个任务前面介绍过；另一个是温度预测。但这两个任务中所使用的技术可以应用于上面列出来的所有应用。</p>
<h1 id="一、处理文本数据"><a href="#一、处理文本数据" class="headerlink" title="一、处理文本数据"></a>一、处理文本数据</h1><p>文本是最常用的序列数据之一，可以理解为字符序列或单词序列，但最常见的是单词级处理。后面几节介绍的深度学习序列处理模型都可以根据文本生成基本形式的自然语言理解，并可用于文档分类、情感分析、作者识别甚至问答（QA，在有限的语境下）等应用。当然，请记住，这些深度学习模型都没有像人类一样真正地理解文本，而只是映射出书面语言的统计结构，但这足以解决许多简单的文本任务。深度学习用于自然语言处理是将模式识别应用于单词、句子和段落，这与计算机视觉是将模式识别应用于像素大致相同。</p>
<p>与其他所有神经网络一样，深度学习模型不会接收原始文本作为输入，它只能处理数值张量。文本<strong>向量化</strong>（vectorize）是指将文本转换为数值张量的过程。它有多种实现方法。</p>
<ul>
<li>将文本分割为单词，并将每个单词转换为一个向量。</li>
<li>将文本分割为字符，并将每个字符转换为一个向量。</li>
<li>提取单词或字符的<code>n-gram</code>，并将每个<code>n-gram</code>转换为一个向量。<code>n-gram</code>是多个连续单词或字符的集合（<code>n-gram</code>之间可重叠）。</li>
</ul>
<p>将文本分解而成的单元（单词、字符或<code>n-gram</code>）叫作标记（token），将文本分解成标记的过程叫作分词（tokenization）。所有文本向量化过程都是应用某种分词方案，然后将数值向量与生成的标记相关联。这些向量组合成序列张量，被输入到深度神经网络中。将向量与标记相关联的方法有很多种。本节将介绍两种主要方法：对标记做<code>one-hot</code>编码（one-hot encoding）与标记嵌入［token embedding，通常只用于单词，叫作词嵌入（word embedding）］。<br>本节剩余内容将解释这些方法，并介绍如何使用这些方法，将原始文本转换为可以输入到<code>Keras</code>网络中的<code>Numpy</code>张量。</p>
<center>
    <img src="\Pic\DeepLearning_Pic\从文本到标记再到向量.png" width="500" height="500" alt="从文本到标记再到向量" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">从文本到标记再到向量</div>
</center>

<h2 id="1-单词和字符的one-hot-编码"><a href="#1-单词和字符的one-hot-编码" class="headerlink" title="1. 单词和字符的one-hot 编码"></a>1. 单词和字符的one-hot 编码</h2><p>one-hot编码是将标记转换为向量的最常用、最基本的方法。在IMDB和路透社两个例子中，你已经用过这种方法（都是处理单词）。它将每个单词与一个唯一的整数索引相关联，然后将这个整数索引 $i$ 转换为长度为 $N$ 的二进制向量（$N$ 是词表大小），这个向量只有第 $i$ 个元素是1，其余元素都为0。<br>当然，也可以进行字符级的one-hot编码。为了让你完全理解什么是<code>one-hot</code>编码以及如何实现<code>one-hot</code>编码，下面给出了两个简单示例，一个是单词级的<code>one-hot</code>编码，另一个是字符级的<code>one-hot</code>编码。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 单词级的one-hot 编码（简单示例）</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">samples = [<span class="string">'The cat sat on the mat.'</span>, <span class="string">'The dog ate my homework.'</span>]</span><br><span class="line">token_index = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> sample <span class="keyword">in</span> samples:</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> sample.split():</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> token_index:</span><br><span class="line">            token_index[word] = len(token_index) + <span class="number">1</span></span><br><span class="line">max_length = <span class="number">10</span></span><br><span class="line">results = np.zeros(shape=(len(samples),max_length,max(token_index.values()) + <span class="number">1</span>))</span><br><span class="line"><span class="keyword">for</span> i, sample <span class="keyword">in</span> enumerate(samples):</span><br><span class="line">    <span class="keyword">for</span> j, word <span class="keyword">in</span> list(enumerate(sample.split()))[:max_length]:</span><br><span class="line">        index = token_index.get(word)</span><br><span class="line">        results[i, j, index] = <span class="number">1.</span></span><br></pre></td></tr></table></figure>
<pre><code>array([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],

       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 字符级的one-hot 编码（简单示例）</span></span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line">samples = [<span class="string">'The cat sat on the mat.'</span>, <span class="string">'The dog ate my homework.'</span>]</span><br><span class="line">characters = string.printable</span><br><span class="line">token_index = dict(zip(range(<span class="number">1</span>, len(characters) + <span class="number">1</span>), characters))</span><br><span class="line">max_length = <span class="number">50</span></span><br><span class="line">results = np.zeros((len(samples), max_length, max(token_index.keys()) + <span class="number">1</span>))</span><br><span class="line"><span class="keyword">for</span> i, sample <span class="keyword">in</span> enumerate(samples):</span><br><span class="line">    <span class="keyword">for</span> j, character <span class="keyword">in</span> enumerate(sample):</span><br><span class="line">        index = token_index.get(character)</span><br><span class="line">        results[i, j, index] = <span class="number">1.</span></span><br></pre></td></tr></table></figure>
<pre><code>array([[[1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., 1.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., 1.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]]])
</code></pre><p>注意，Keras 的内置函数可以对原始文本数据进行单词级或字符级的<code>one-hot</code>编码。你应该使用这些函数，因为它们实现了许多重要的特性，比如从字符串中去除特殊字符、只考虑数据集中前 $N$ 个最常见的单词（这是一种常用的限制，以避免处理非常大的输入向量空间）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 用Keras实现单词级的one-hot编码</span></span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.text <span class="keyword">import</span> Tokenizer</span><br><span class="line">samples = [<span class="string">'The cat sat on the mat.'</span>, <span class="string">'The dog ate my homework.'</span>]</span><br><span class="line">tokenizer = Tokenizer(num_words=<span class="number">1000</span>)</span><br><span class="line">tokenizer.fit_on_texts(samples)</span><br><span class="line">sequences = tokenizer.texts_to_sequences(samples)</span><br><span class="line">one_hot_results = tokenizer.texts_to_matrix(samples, mode=<span class="string">'binary'</span>)</span><br><span class="line">word_index = tokenizer.word_index</span><br><span class="line">print(<span class="string">'Found %s unique tokens.'</span> % len(word_index))</span><br></pre></td></tr></table></figure>
<p>one-hot 编码的一种变体是所谓的one-hot散列技巧（one-hot hashing trick），如果词表中唯一标记的数量太大而无法直接处理，就可以使用这种技巧。这种方法没有为每个单词显式分配一个索引并将这些索引保存在一个字典中，而是将单词散列编码为固定长度的向量，通常用一个非常简单的散列函数来实现。这种方法的主要优点在于，它避免了维护一个显式的单词索引，从而节省内存并允许数据的在线编码（在读取完所有数据之前，你就可以立刻生成标记向量）。</p>
<p>这种方法有一个缺点，就是可能会出现散列冲突（hash collision），即两个不同的单词可能具有相同的散列值，随后任何机器学习模型观察这些散列值，都无法区分它们所对应的单词。如果散列空间的维度远大于需要散列的唯一标记的个数，散列冲突的可能性会减小。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用散列技巧的单词级的one-hot编码（简单示例）</span></span><br><span class="line">samples = [<span class="string">'The cat sat on the mat.'</span>, <span class="string">'The dog ate my homework.'</span>]</span><br><span class="line">dimensionality = <span class="number">1000</span></span><br><span class="line">max_length = <span class="number">10</span></span><br><span class="line">results = np.zeros((len(samples), max_length, dimensionality))</span><br><span class="line"><span class="keyword">for</span> i, sample <span class="keyword">in</span> enumerate(samples):</span><br><span class="line">    <span class="keyword">for</span> j, word <span class="keyword">in</span> list(enumerate(sample.split()))[:max_length]:</span><br><span class="line">        index = abs(hash(word)) % dimensionality</span><br><span class="line">        results[i, j, index] = <span class="number">1.</span></span><br></pre></td></tr></table></figure>
<pre><code>array([[[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]]])
</code></pre><h2 id="2-使用词嵌入"><a href="#2-使用词嵌入" class="headerlink" title="2. 使用词嵌入"></a>2. 使用词嵌入</h2><p>将单词与向量相关联还有另一种常用的强大方法，就是使用密集的词向量（word vector），也叫词嵌入（word embedding）。one-hot 编码得到的向量是二进制的、稀疏的（绝大部分元素都是0）、维度很高的（维度大小等于词表中的单词个数），而词嵌入是低维的浮点数向量（即密集向量，与稀疏向量相对）。与one-hot 编码得到的词向量不同，词嵌入是从数据中学习得到的。常见的词向量维度是256、512 或1024（处理非常大的词表时）。与此相对，onehot编码的词向量维度通常为20 000 或更高（对应包含20 000 个标记的词表）。因此，词向量可以将更多的信息塞入更低的维度中。</p>
<center>
    <img src="\Pic\DeepLearning_Pic\encoding_1.png" width="300" height="300" alt="one-hot 编码或one-hot 散列得到的词表示是稀疏的、高维的、硬编码的，
而词嵌入是密集的、相对低维的，而且是从数据中学习得到的" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">one-hot 编码或one-hot 散列得到的词表示是稀疏的、高维的、硬编码的，
而词嵌入是密集的、相对低维的，而且是从数据中学习得到的</div>
</center>

<p>获取词嵌入有两种方法。</p>
<ul>
<li>在完成主任务（比如文档分类或情感预测）的同时学习词嵌入。在这种情况下，一开始是随机的词向量，然后对这些词向量进行学习，其学习方式与学习神经网络的权重相同</li>
<li>在不同于待解决问题的机器学习任务上预计算好词嵌入，然后将其加载到模型中。这些词嵌入叫作预训练词嵌入（pretrained word embedding）</li>
</ul>
<p><strong>1. 利用Embedding 层学习词嵌入</strong></p>
<p>要将一个词与一个密集向量相关联，最简单的方法就是随机选择向量。这种方法的问题在于，得到的嵌入空间没有任何结构。例如，accurate 和exact 两个词的嵌入可能完全不同，尽管它们在大多数句子里都是可以互换的。深度神经网络很难对这种杂乱的、非结构化的嵌入空间进行学习。</p>
<p>说得更抽象一点，词向量之间的几何关系应该表示这些词之间的语义关系。词嵌入的作用应该是将人类的语言映射到几何空间中。例如，在一个合理的嵌入空间中，同义词应该被嵌入到相似的词向量中，一般来说，任意两个词向量之间的几何距离（比如L2 距离）应该和这两个词的语义距离有关（表示不同事物的词被嵌入到相隔很远的点，而相关的词则更加靠近）。除了距离，你可能还希望嵌入空间中的特定方向也是有意义的。为了更清楚地说明这一点，我们来看一个具体示例。</p>
<p>在下图中，四个词被嵌入在二维平面上，这四个词分别是cat（猫）、dog（狗）、wolf（狼）和tiger（虎）。对于我们这里选择的向量表示，这些词之间的某些语义关系可以被编码为几何变换。例如，从cat 到tiger 的向量与从dog 到wolf 的向量相等，这个向量可以被解释为“从宠物到野生动物”向量。同样，从dog 到cat 的向量与从wolf 到tiger 的向量也相等，它可以被解释为“从犬科到猫科”向量。</p>
<center>
    <img src="\Pic\DeepLearning_Pic\encoding_2.png" width="200" height="200" alt="词嵌入空间的简单示例" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">词嵌入空间的简单示例</div>
</center>

<p>在真实的词嵌入空间中，常见的有意义的几何变换的例子包括“性别”向量和“复数”向量。例如，将king（国王）向量加上female（女性）向量，得到的是queen（女王）向量。将king（国王）向量加上plural（复数）向量，得到的是kings 向量。词嵌入空间通常具有几千个这种可解释的、并且可能很有用的向量。</p>
<p>有没有一个理想的词嵌入空间，可以完美地映射人类语言，并可用于所有自然语言处理任务？可能有，但我们尚未发现。此外，也不存在人类语言（human language）这种东西。世界上有许多种不同的语言，而且它们不是同构的，因为语言是特定文化和特定环境的反射。但从更实际的角度来说，一个好的词嵌入空间在很大程度上取决于你的任务。英语电影评论情感分析模型的完美词嵌入空间，可能不同于英语法律文档分类模型的完美词嵌入空间，因为某些语义关系的重要性因任务而异。</p>
<p>因此，合理的做法是对每个新任务都学习一个新的嵌入空间。幸运的是，反向传播让这种学习变得很简单，而Keras 使其变得更简单。我们要做的就是学习一个层的权重，这个层就是Embedding 层。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将一个Embedding 层实例化</span></span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Embedding</span><br><span class="line">embedding_layer = Embedding(<span class="number">1000</span>, <span class="number">64</span>)</span><br></pre></td></tr></table></figure>
<p>最好将Embedding层理解为一个字典，将整数索引（表示特定单词）映射为密集向量。它接收整数作为输入，并在内部字典中查找这些整数，然后返回相关联的向量。Embedding 层实际上是一种字典查找</p>
<center>
    <img src="\Pic\DeepLearning_Pic\encoding_3.png" width="400" height="400" alt="Embedding层" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">Embedding层</div>
</center>

<p>Embedding 层的输入是一个二维整数张量，其形状为(samples, sequence_length)，每个元素是一个整数序列。它能够嵌入长度可变的序列，例如，对于前一个例子中的Embedding 层，你可以输入形状为(32, 10)（32 个长度为10 的序列组成的批量）或(64,15)（64 个长度为15 的序列组成的批量）的批量。不过一批数据中的所有序列必须具有相同的长度（因为需要将它们打包成一个张量），所以较短的序列应该用0 填充，较长的序列应该被截断。</p>
<p>这个Embedding层返回一个形状为$(samples, sequence_length, embedding_dimensionality)$的三维浮点数张量。然后可以用RNN 层或一维卷积层来处理这个三维张量（二者都会在后面介绍）。</p>
<p>将一个Embedding层实例化时，它的权重（即标记向量的内部字典）最开始是随机的，与其他层一样。在训练过程中，利用反向传播来逐渐调节这些词向量，改变空间结构以便下游模型可以利用。一旦训练完成，嵌入空间将会展示大量结构，这种结构专门针对训练模型所要解决的问题。</p>
<p>我们将这个想法应用于你熟悉的IMDB 电影评论情感预测任务。首先，我们需要快速准备数据。将电影评论限制为前10 000个最常见的单词（第一次处理这个数据集时就是这么做的），然后将评论长度限制为只有20个单词。对于这10 000个单词，网络将对每个词都学习一个8维嵌入，将输入的整数序列（二维整数张量）转换为嵌入序列（三维浮点数张量），然后将这个张量展平为二维，最后在上面训练一个Dense层用于分类。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 加载IMDB数据，准备用于Embedding层</span></span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> imdb</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> preprocessing</span><br><span class="line">max_features = <span class="number">10000</span></span><br><span class="line">maxlen = <span class="number">20</span></span><br><span class="line">(x_train, y_train), (x_test, y_test) = imdb.load_data(</span><br><span class="line">num_words=max_features)</span><br><span class="line">x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)</span><br><span class="line">x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在IMDB数据上使用Embedding层和分类器</span></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Flatten, Dense, Embedding</span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Embedding(<span class="number">10000</span>, <span class="number">8</span>, input_length=maxlen))</span><br><span class="line">model.add(Flatten())</span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>, loss=<span class="string">'binary_crossentropy'</span>, metrics=[<span class="string">'acc'</span>])</span><br><span class="line">model.summary()</span><br><span class="line">history = model.fit(x_train, y_train,</span><br><span class="line">epochs=<span class="number">10</span>,</span><br><span class="line">batch_size=<span class="number">32</span>,</span><br><span class="line">validation_split=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_1&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_2 (Embedding)      (None, 20, 8)             80000     
_________________________________________________________________
flatten_1 (Flatten)          (None, 160)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 161       
=================================================================
Total params: 80,161
Trainable params: 80,161
Non-trainable params: 0
_________________________________________________________________
</code></pre><p>得到的验证精度约为76%，考虑到仅查看每条评论的前20个单词，这个结果还是相当不错的。但请注意，仅仅将嵌入序列展开并在上面训练一个Dense层，会导致模型对输入序列中的每个单词单独处理，而没有考虑单词之间的关系和句子结构（举个例子，这个模型可能会将thismovie is a bomb 和this movie is the bomb 两条都归为负面评论a）。更好的做法是在嵌入序列上添加循环层或一维卷积层，将每个序列作为整体来学习特征。这也是接下来几节的重点。</p>
<p><strong>2. 使用预训练的词嵌入</strong><br>有时可用的训练数据很少，以至于只用手头数据无法学习适合特定任务的词嵌入。那么应该怎么办？</p>
<p>你可以从预计算的嵌入空间中加载嵌入向量（你知道这个嵌入空间是高度结构化的，并且具有有用的属性，即抓住了语言结构的一般特点），而不是在解决问题的同时学习词嵌入。在自然语言处理中使用预训练的词嵌入，其背后的原理与在图像分类中使用预训练的卷积神经网络是一样的：没有足够的数据来自己学习真正强大的特征，但你需要的特征应该是非常通用的，比如常见的视觉特征或语义特征。在这种情况下，重复使用在其他问题上学到的特征，这种做<br>法是有道理的。</p>
<p>这种词嵌入通常是利用词频统计计算得出的（观察哪些词共同出现在句子或文档中），用到的技术很多，有些涉及神经网络，有些则不涉及。Bengio等人在21 世纪初首先研究了一种思路，就是用无监督的方法计算一个密集的低维词嵌入空间，但直到最有名且最成功的词嵌入方案之一word2vec 算法发布之后，这一思路才开始在研究领域和工业应用中取得成功。word2vec算法由Google的Tomas Mikolov于2013 年开发，其维度抓住了特定的语义属性，比如性别。有许多预计算的词嵌入数据库， 你都可以下载并在Keras的Embedding层中使用。word2vec就是其中之一。另一个常用的是GloVe（global vectors for word representation，词表示全局向量），由斯坦福大学的研究人员于2014 年开发。这种嵌入方法基于对词共现统计矩阵进行因式分解。其开发者已经公开了数百万个英文标记的预计算嵌入，它们都是从维基百科数据和Common Crawl 数据得到的。</p>
<p>我们来看一下如何在Keras 模型中使用GloVe嵌入。同样的方法也适用于word2vec 嵌入或其他词嵌入数据库。这个例子还可以改进前面刚刚介绍过的文本分词技术，即从原始文本开始，一步步进行处理。</p>
<h2 id="3-从原始文本到词嵌入"><a href="#3-从原始文本到词嵌入" class="headerlink" title="3. 从原始文本到词嵌入"></a>3. 从原始文本到词嵌入</h2><p>本节的模型与之前刚刚见过的那个类似：将句子嵌入到向量序列中，然后将其展平，最后在上面训练一个Dense层。但此处将使用预训练的词嵌入。此外，我们将从头开始，先下载IMDB 原始文本数据，而不是使用Keras内置的已经预先分词的IMDB 数据。</p>
<blockquote>
<p>下载IMDB 数据的原始文本</p>
</blockquote>
<p>首先，打开<a href="http://mng.bz/0tIo" target="_blank" rel="noopener">http://mng.bz/0tIo</a> ，下载原始IMDB 数据集并解压。接下来，我们将训练评论转换成字符串列表，每个字符串对应一条评论。你也可以将评论标签（正面/ 负面）转换成labels列表。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 处理IMDB原始数据的标签</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">imdb_dir = <span class="string">'data/aclImdb'</span></span><br><span class="line">train_dir = os.path.join(imdb_dir, <span class="string">'train'</span>)</span><br><span class="line">labels = []</span><br><span class="line">texts = []</span><br><span class="line"><span class="keyword">for</span> label_type <span class="keyword">in</span> [<span class="string">'neg'</span>, <span class="string">'pos'</span>]:</span><br><span class="line">    dir_name = os.path.join(train_dir, label_type)</span><br><span class="line">    <span class="keyword">for</span> fname <span class="keyword">in</span> os.listdir(dir_name):</span><br><span class="line">        <span class="keyword">if</span> fname[<span class="number">-4</span>:] == <span class="string">'.txt'</span>:</span><br><span class="line">            f = open(os.path.join(dir_name, fname))</span><br><span class="line">            texts.append(f.read())</span><br><span class="line">            f.close()</span><br><span class="line">            <span class="keyword">if</span> label_type == <span class="string">'neg'</span>:</span><br><span class="line">                labels.append(<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                labels.append(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>对数据进行分词</p>
</blockquote>
<p>利用本节前面介绍过的概念，我们对文本进行分词，并将其划分为训练集和验证集。因为预训练的词嵌入对训练数据很少的问题特别有用（否则，针对于具体任务的嵌入可能效果更好），所以我们又添加了以下限制：将训练数据限定为前200个样本。因此，你需要在读取200个样本之后学习对电影评论进行分类。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对IMDB原始数据的文本进行分词</span></span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.text <span class="keyword">import</span> Tokenizer</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">maxlen = <span class="number">100</span></span><br><span class="line">training_samples = <span class="number">200</span></span><br><span class="line">validation_samples = <span class="number">10000</span></span><br><span class="line">max_words = <span class="number">10000</span></span><br><span class="line">tokenizer = Tokenizer(num_words=max_words)</span><br><span class="line">tokenizer.fit_on_texts(texts)</span><br><span class="line">sequences = tokenizer.texts_to_sequences(texts)</span><br><span class="line">word_index = tokenizer.word_index</span><br><span class="line">print(<span class="string">'Found %s unique tokens.'</span> % len(word_index))</span><br><span class="line">data = pad_sequences(sequences, maxlen=maxlen)</span><br><span class="line">labels = np.asarray(labels)</span><br><span class="line">print(<span class="string">'Shape of data tensor:'</span>, data.shape)</span><br><span class="line">print(<span class="string">'Shape of label tensor:'</span>, labels.shape)</span><br><span class="line">indices = np.arange(data.shape[<span class="number">0</span>])</span><br><span class="line">np.random.shuffle(indices)</span><br><span class="line">data = data[indices]</span><br><span class="line">labels = labels[indices]</span><br><span class="line">x_train = data[:training_samples]</span><br><span class="line">y_train = labels[:training_samples]</span><br><span class="line">x_val = data[training_samples: training_samples + validation_samples]</span><br><span class="line">y_val = labels[training_samples: training_samples + validation_samples]</span><br></pre></td></tr></table></figure>
<pre><code>Found 88582 unique tokens.
Shape of data tensor: (25000, 100)
Shape of label tensor: (25000,)
</code></pre><blockquote>
<p>下载GloVe词嵌入</p>
</blockquote>
<p>打开<a href="https://nlp.stanford.edu/projects/glove" target="_blank" rel="noopener">https://nlp.stanford.edu/projects/glove</a> ，下载2014年英文维基百科的预计算嵌入。这是一个822 MB的压缩文件，文件名是glove.6B.zip，里面包含400 000 个单词（或非单词的标记）的100 维嵌入向量，解压文件。</p>
<blockquote>
<p>对嵌入进行预处理</p>
</blockquote>
<p>我们对解压后的文件（一个.txt 文件）进行解析，构建一个将单词（字符串）映射为其向量表示（数值向量）的索引。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 解析GloVe词嵌入文件</span></span><br><span class="line">glove_dir = <span class="string">'model/glove.6B'</span></span><br><span class="line">embeddings_index = &#123;&#125;</span><br><span class="line">f = open(os.path.join(glove_dir, <span class="string">'glove.6B.100d.txt'</span>))</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">    values = line.split()</span><br><span class="line">    word = values[<span class="number">0</span>]</span><br><span class="line">    coefs = np.asarray(values[<span class="number">1</span>:], dtype=<span class="string">'float32'</span>)</span><br><span class="line">    embeddings_index[word] = coefs</span><br><span class="line">f.close()</span><br><span class="line">print(<span class="string">'Found %s word vectors.'</span> % len(embeddings_index))</span><br></pre></td></tr></table></figure>
<pre><code>Found 400000 word vectors.
</code></pre><p>接下来，需要构建一个可以加载到<code>Embedding</code>层中的嵌入矩阵。它必须是一个形状为<code>(max_words, embedding_dim)</code> 的矩阵，对于单词索引（在分词时构建）中索引为$i$的单词，这个矩阵的元素$i$就是这个单词对应的<code>embedding_dim</code>维向量。注意，索引0不应该代表任何单词或标记，它只是一个占位符。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 准备GloVe词嵌入矩阵</span></span><br><span class="line">embedding_dim = <span class="number">100</span></span><br><span class="line">embedding_matrix = np.zeros((max_words, embedding_dim))</span><br><span class="line"><span class="keyword">for</span> word, i <span class="keyword">in</span> word_index.items():</span><br><span class="line">    <span class="keyword">if</span> i &lt; max_words:</span><br><span class="line">        embedding_vector = embeddings_index.get(word)</span><br><span class="line">        <span class="keyword">if</span> embedding_vector <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            embedding_matrix[i] = embedding_vector</span><br></pre></td></tr></table></figure>
<blockquote>
<p>定义模型</p>
</blockquote>
<p>我们将使用与前面相同的模型架构。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Embedding, Flatten, Dense</span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Embedding(max_words, embedding_dim, input_length=maxlen))</span><br><span class="line">model.add(Flatten())</span><br><span class="line">model.add(Dense(<span class="number">32</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_2&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_3 (Embedding)      (None, 100, 100)          1000000   
_________________________________________________________________
flatten_2 (Flatten)          (None, 10000)             0         
_________________________________________________________________
dense_2 (Dense)              (None, 32)                320032    
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 33        
=================================================================
Total params: 1,320,065
Trainable params: 1,320,065
Non-trainable params: 0
_________________________________________________________________
</code></pre><blockquote>
<p>在模型中加载GloVe嵌入</p>
</blockquote>
<p>Embedding层只有一个权重矩阵，是一个二维的浮点数矩阵，其中每个元素$i$是与索引$i$相关联的词向量。将准备好的<code>GloVe</code>矩阵加载到<code>Embedding</code>层中，即模型的第一层。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将预训练的词嵌入加载到Embedding层中</span></span><br><span class="line">model.layers[<span class="number">0</span>].set_weights([embedding_matrix])</span><br><span class="line">model.layers[<span class="number">0</span>].trainable = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>此外，需要冻结<code>Embedding</code>层（即将其<code>trainable</code>属性设为<code>False</code>），其原理和预训练的卷积神经网络特征相同，你已经很熟悉了。如果一个模型的一部分是经过预训练的（如<code>Embedding</code>层），而另一部分是随机初始化的（如分类器），那么在训练期间不应该更新预训练的部分，以避免丢失它们所保存的信息。随机初始化的层会引起较大的梯度更新，会破坏已经学到的特征。</p>
<blockquote>
<p>训练模型与评估模型</p>
</blockquote>
<p>下面编译并训练模型。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>,</span><br><span class="line">            loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">            metrics=[<span class="string">'acc'</span>])</span><br><span class="line">history = model.fit(x_train, y_train,</span><br><span class="line">            epochs=<span class="number">10</span>,</span><br><span class="line">            batch_size=<span class="number">32</span>,</span><br><span class="line">            validation_data=(x_val, y_val))</span><br><span class="line">model.save_weights(<span class="string">'model/pre_trained_glove_model.h5'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">acc = history.history[<span class="string">'acc'</span>]</span><br><span class="line">val_acc = history.history[<span class="string">'val_acc'</span>]</span><br><span class="line">loss = history.history[<span class="string">'loss'</span>]</span><br><span class="line">val_loss = history.history[<span class="string">'val_loss'</span>]</span><br><span class="line">epochs = range(<span class="number">1</span>, len(acc) + <span class="number">1</span>)</span><br><span class="line">plt.plot(epochs, acc, <span class="string">'bo'</span>, label=<span class="string">'Training acc'</span>)</span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">'b'</span>, label=<span class="string">'Validation acc'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation accuracy'</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_29_11.png" width="400" height="400" alt="b" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.figure()</span><br><span class="line">plt.plot(epochs, loss, <span class="string">'bo'</span>, label=<span class="string">'Training loss'</span>)</span><br><span class="line">plt.plot(epochs, val_loss, <span class="string">'b'</span>, label=<span class="string">'Validation loss'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_30_0.png" width="400" height="400" alt="b" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>



<p>模型很快就开始过拟合，考虑到训练样本很少，这一点也不奇怪。出于同样的原因，验证精度的波动很大，但似乎达到了接近60%。</p>
<p>你也可以在不加载预训练词嵌入、也不冻结嵌入层的情况下训练相同的模型。在这种情况下，你将会学到针对任务的输入标记的嵌入。如果有大量的可用数据，这种方法通常比预训练词嵌入更加强大，但本例只有200个训练样本。我们来试一下这种方法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在不使用预训练词嵌入的情况下，训练相同的模型</span></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Embedding, Flatten, Dense</span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Embedding(max_words, embedding_dim, input_length=maxlen))</span><br><span class="line">model.add(Flatten())</span><br><span class="line">model.add(Dense(<span class="number">32</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line">model.summary()</span><br><span class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>,</span><br><span class="line">        loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">        metrics=[<span class="string">'acc'</span>])</span><br><span class="line">history = model.fit(x_train, y_train,</span><br><span class="line">        epochs=<span class="number">10</span>,</span><br><span class="line">        batch_size=<span class="number">32</span>,</span><br><span class="line">        validation_data=(x_val, y_val))</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_3&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_4 (Embedding)      (None, 100, 100)          1000000   
_________________________________________________________________
flatten_3 (Flatten)          (None, 10000)             0         
_________________________________________________________________
dense_4 (Dense)              (None, 32)                320032    
_________________________________________________________________
dense_5 (Dense)              (None, 1)                 33        
=================================================================
Total params: 1,320,065
Trainable params: 1,320,065
Non-trainable params: 0
_________________________________________________________________
</code></pre><p>验证精度停留在50% 多一点。因此，在本例中，预训练词嵌入的性能要优于与任务一起学习的嵌入。如果增加样本数量，情况将很快发生变化，你可以把它作为一个练习。</p>
<p>最后，我们在测试数据上评估模型。首先，你需要对测试数据进行分词。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">test_dir = os.path.join(imdb_dir, <span class="string">'test'</span>)</span><br><span class="line">labels = []</span><br><span class="line">texts = []</span><br><span class="line"><span class="keyword">for</span> label_type <span class="keyword">in</span> [<span class="string">'neg'</span>, <span class="string">'pos'</span>]:</span><br><span class="line">    dir_name = os.path.join(test_dir, label_type)</span><br><span class="line">    <span class="keyword">for</span> fname <span class="keyword">in</span> sorted(os.listdir(dir_name)):</span><br><span class="line">        <span class="keyword">if</span> fname[<span class="number">-4</span>:] == <span class="string">'.txt'</span>:</span><br><span class="line">            f = open(os.path.join(dir_name, fname))</span><br><span class="line">            texts.append(f.read())</span><br><span class="line">            f.close()</span><br><span class="line">            <span class="keyword">if</span> label_type == <span class="string">'neg'</span>:</span><br><span class="line">                labels.append(<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                labels.append(<span class="number">1</span>)</span><br><span class="line">sequences = tokenizer.texts_to_sequences(texts)</span><br><span class="line">x_test = pad_sequences(sequences, maxlen=maxlen)</span><br><span class="line">y_test = np.asarray(labels)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.load_weights(<span class="string">'model/pre_trained_glove_model.h5'</span>)</span><br><span class="line">model.evaluate(x_test, y_test)</span><br></pre></td></tr></table></figure>
<pre><code>25000/25000 [==============================] - 1s 44us/step
[0.7739053187370301, 0.5541599988937378]
</code></pre><p>我们只用了很少的训练样本，得到这样的结果很不容易。</p>
<h1 id="二、理解循环神经网络"><a href="#二、理解循环神经网络" class="headerlink" title="二、理解循环神经网络"></a>二、理解循环神经网络</h1><p>目前你见过的所有神经网络（比如密集连接网络和卷积神经网络）都有一个主要特点，那就是它们都没有记忆。它们单独处理每个输入，在输入与输入之间没有保存任何状态。对于这样的网络，要想处理数据点的序列或时间序列，你需要向网络同时展示整个序列，即将序列转换成单个数据点。例如，你在IMDB 示例中就是这么做的：将全部电影评论转换为一个大向量，然后一次性处理。这种网络叫作前馈网络（feedforward network）。</p>
<p>与此相反，当你在阅读这个句子时，你是一个词一个词地阅读（或者说，眼睛一次扫视一次扫视地阅读），同时会记住之前的内容。这让你能够动态理解这个句子所传达的含义。生物智能以渐进的方式处理信息，同时保存一个关于所处理内容的内部模型，这个模型是根据过去的信息构建的，并随着新信息的进入而不断更新。</p>
<p>循环神经网络（RNN，recurrent neural network）采用同样的原理，不过是一个极其简化的版本：它处理序列的方式是，遍历所有序列元素，并保存一个状态（state），其中包含与已查看内容相关的信息。实际上，RNN 是一类具有内部环的神经网络。在处理两个不同的独立序列（比如两条不同的IMDB 评论）之间，RNN 状态会被重置，因此，你仍可以将一个序列看作单个数据点，即网络的单个输入。真正改变的是，数据点不再是在单个步骤中进行处理，相反，网络内部会对序列元素进行遍历。</p>
<center>
    <img src="\Pic\DeepLearning_Pic\rnn1.png" width="200" height="200" alt="循环网络：带有环的网络" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">循环网络：带有环的网络</div>
</center>

<p>为了将环（loop）和状态的概念解释清楚，我们用Numpy来实现一个简单RNN的前向传递。这个RNN的输入是一个张量序列，我们将其编码成大小为$(timesteps, input_features)$的二维张量。它对时间步（timestep）进行遍历，在每个时间步，它考虑$t$时刻的当前状态与$t$时刻的输入［形状为$(input_ features,)$］，对二者计算得到$t$时刻的输出。然后，我们<strong>将下一个时间步的状态设置为上一个时间步的输出</strong>。对于第一个时间步，上一个时间步的输出没有定义，所以它没有当前状态。因此，你需要将状态初始化为一个全零向量，这叫作网络的初始状态（initial state）。</p>
<p>RNN的伪代码如下所示。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">state_t = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> input_t <span class="keyword">in</span> input_sequence:</span><br><span class="line">    output_t = f(input_t, state_t)</span><br><span class="line">    state_t = output_t</span><br></pre></td></tr></table></figure>
<p>你甚至可以给出具体的函数$f$：从输入和状态到输出的变换，其参数包括两个矩阵（$W$和$U$）和一个偏置向量。它类似于前馈网络中密集连接层所做的变换，因此更详细的RNN伪代码如下：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">state_t = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> input_t <span class="keyword">in</span> input_sequence:</span><br><span class="line">    output_t = activation(dot(W, input_t) + dot(U, state_t) + b)</span><br><span class="line">    state_t = output_t</span><br></pre></td></tr></table></figure></p>
<p>为了将这些概念的含义解释得更加清楚，我们为简单RNN的前向传播编写一个简单的Numpy实现。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">timesteps = <span class="number">100</span></span><br><span class="line">input_features = <span class="number">32</span></span><br><span class="line">output_features = <span class="number">64</span></span><br><span class="line">inputs = np.random.random((timesteps, input_features))</span><br><span class="line">state_t = np.zeros((output_features,))</span><br><span class="line">W = np.random.random((output_features, input_features))</span><br><span class="line">U = np.random.random((output_features, output_features))</span><br><span class="line">b = np.random.random((output_features,))</span><br><span class="line">successive_outputs = []</span><br><span class="line"><span class="keyword">for</span> input_t <span class="keyword">in</span> inputs:</span><br><span class="line">    output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b)</span><br><span class="line">    successive_outputs.append(output_t)</span><br><span class="line">    state_t = output_t</span><br><span class="line">final_output_sequence = np.stack(successive_outputs, axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>总之，RNN 是一个for 循环，它重复使用循环前一次迭代的计算结果，仅此而已。当然，你可以构建许多不同的RNN，它们都满足上述定义。这个例子只是最简单的RNN表述之一。RNN的特征在于其时间步函数，比如前面例子中的这个函数</p>
<h2 id="1-Keras-中的循环层"><a href="#1-Keras-中的循环层" class="headerlink" title="1. Keras 中的循环层"></a>1. Keras 中的循环层</h2><p>上面Numpy 的简单实现，对应一个实际的Keras 层，即SimpleRNN层。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> SimpleRNN</span><br></pre></td></tr></table></figure><br>二者有一点小小的区别：SimpleRNN层能够像其他Keras层一样处理序列批量，而不是像Numpy示例那样只能处理单个序列。因此，它接收形状为<code>(batch_size, timesteps,input_features)</code>的输入，而不是<code>(timesteps, input_features)</code>。</p>
<p>与Keras 中的所有循环层一样，SimpleRNN可以在两种不同的模式下运行：一种是返回每个时间步连续输出的完整序列，即形状为<code>(batch_size, timesteps, output_features)</code>的三维张量；另一种是只返回每个输入序列的最终输出，即形状为<code>(batch_size, output_features)</code>的二维张量。这两种模式由return_sequences 这个构造函数参数来控制。我们来看一个使用SimpleRNN的例子，它只返回最后一个时间步的输出。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Embedding, SimpleRNN</span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Embedding(<span class="number">10000</span>, <span class="number">32</span>))</span><br><span class="line">model.add(SimpleRNN(<span class="number">32</span>))</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_4&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_5 (Embedding)      (None, None, 32)          320000    
_________________________________________________________________
simple_rnn_1 (SimpleRNN)     (None, 32)                2080      
=================================================================
Total params: 322,080
Trainable params: 322,080
Non-trainable params: 0
_________________________________________________________________
</code></pre><p>下面这个例子返回完整的状态序列</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add(Embedding(<span class="number">10000</span>, <span class="number">32</span>))</span><br><span class="line">model.add(SimpleRNN(<span class="number">32</span>, return_sequences=<span class="literal">True</span>))</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_5&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_6 (Embedding)      (None, None, 32)          320000    
_________________________________________________________________
simple_rnn_2 (SimpleRNN)     (None, None, 32)          2080      
=================================================================
Total params: 322,080
Trainable params: 322,080
Non-trainable params: 0
_________________________________________________________________
</code></pre><p>为了提高网络的表示能力，将多个循环层逐个堆叠有时也是很有用的。在这种情况下，你需要让所有中间层都返回完整的输出序列。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add(Embedding(<span class="number">10000</span>, <span class="number">32</span>))</span><br><span class="line">model.add(SimpleRNN(<span class="number">32</span>, return_sequences=<span class="literal">True</span>))</span><br><span class="line">model.add(SimpleRNN(<span class="number">32</span>, return_sequences=<span class="literal">True</span>))</span><br><span class="line">model.add(SimpleRNN(<span class="number">32</span>, return_sequences=<span class="literal">True</span>))</span><br><span class="line">model.add(SimpleRNN(<span class="number">32</span>))</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_6&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_7 (Embedding)      (None, None, 32)          320000    
_________________________________________________________________
simple_rnn_3 (SimpleRNN)     (None, None, 32)          2080      
_________________________________________________________________
simple_rnn_4 (SimpleRNN)     (None, None, 32)          2080      
_________________________________________________________________
simple_rnn_5 (SimpleRNN)     (None, None, 32)          2080      
_________________________________________________________________
simple_rnn_6 (SimpleRNN)     (None, 32)                2080      
=================================================================
Total params: 328,320
Trainable params: 328,320
Non-trainable params: 0
_________________________________________________________________
</code></pre><p>接下来，我们将这个模型应用于IMDB电影评论分类问题。首先，对数据进行预处理。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> imdb</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> sequence</span><br><span class="line">max_features = <span class="number">10000</span></span><br><span class="line">maxlen = <span class="number">500</span></span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line">print(<span class="string">'Loading data...'</span>)</span><br><span class="line">(input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=max_features)</span><br><span class="line">print(len(input_train), <span class="string">'train sequences'</span>)</span><br><span class="line">print(len(input_test), <span class="string">'test sequences'</span>)</span><br><span class="line">print(<span class="string">'Pad sequences (samples x time)'</span>)</span><br><span class="line">input_train = sequence.pad_sequences(input_train, maxlen=maxlen)</span><br><span class="line">input_test = sequence.pad_sequences(input_test, maxlen=maxlen)</span><br><span class="line">print(<span class="string">'input_train shape:'</span>, input_train.shape)</span><br><span class="line">print(<span class="string">'input_test shape:'</span>, input_test.shape)</span><br></pre></td></tr></table></figure>
<pre><code>Loading data...
25000 train sequences
25000 test sequences
Pad sequences (samples x time)
input_train shape: (25000, 500)
input_test shape: (25000, 500)
</code></pre><p>我们用一个Embedding层和一个SimpleRNN层来训练一个简单的循环网络</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Embedding(max_features, <span class="number">32</span>))</span><br><span class="line">model.add(SimpleRNN(<span class="number">32</span>))</span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>, loss=<span class="string">'binary_crossentropy'</span>, metrics=[<span class="string">'acc'</span>])</span><br><span class="line">history = model.fit(input_train, y_train,</span><br><span class="line">                epochs=<span class="number">10</span>,</span><br><span class="line">                batch_size=<span class="number">128</span>,</span><br><span class="line">                validation_split=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Train on 20000 samples, validate on 5000 samples
Epoch 1/10
20000/20000 [==============================] - 17s 832us/step - loss: 0.6298 - acc: 0.6252 - val_loss: 0.5190 - val_acc: 0.7454
Epoch 2/10
20000/20000 [==============================] - 17s 832us/step - loss: 0.4073 - acc: 0.8216 - val_loss: 0.3733 - val_acc: 0.8438
Epoch 3/10
20000/20000 [==============================] - 17s 844us/step - loss: 0.2946 - acc: 0.8804 - val_loss: 0.3948 - val_acc: 0.8318
Epoch 4/10
20000/20000 [==============================] - 17s 856us/step - loss: 0.2396 - acc: 0.9059 - val_loss: 0.4578 - val_acc: 0.8388
Epoch 5/10
20000/20000 [==============================] - 17s 870us/step - loss: 0.2003 - acc: 0.9233 - val_loss: 0.4395 - val_acc: 0.8168
Epoch 6/10
20000/20000 [==============================] - 18s 887us/step - loss: 0.1601 - acc: 0.9406 - val_loss: 0.5268 - val_acc: 0.8204
Epoch 7/10
20000/20000 [==============================] - 17s 874us/step - loss: 0.1124 - acc: 0.9612 - val_loss: 0.5143 - val_acc: 0.8048
Epoch 8/10
20000/20000 [==============================] - 18s 914us/step - loss: 0.0923 - acc: 0.9682 - val_loss: 0.4945 - val_acc: 0.8362
Epoch 9/10
20000/20000 [==============================] - 18s 877us/step - loss: 0.0507 - acc: 0.9839 - val_loss: 0.5826 - val_acc: 0.8092
Epoch 10/10
20000/20000 [==============================] - 18s 879us/step - loss: 0.0540 - acc: 0.9821 - val_loss: 0.5969 - val_acc: 0.8182
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">acc = history.history[<span class="string">'acc'</span>]</span><br><span class="line">val_acc = history.history[<span class="string">'val_acc'</span>]</span><br><span class="line">loss = history.history[<span class="string">'loss'</span>]</span><br><span class="line">val_loss = history.history[<span class="string">'val_loss'</span>]</span><br><span class="line">epochs = range(<span class="number">1</span>, len(acc) + <span class="number">1</span>)</span><br><span class="line">plt.plot(epochs, acc, <span class="string">'bo'</span>, label=<span class="string">'Training acc'</span>)</span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">'b'</span>, label=<span class="string">'Validation acc'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation accuracy'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(epochs, loss, <span class="string">'bo'</span>, label=<span class="string">'Training loss'</span>)</span><br><span class="line">plt.plot(epochs, val_loss, <span class="string">'b'</span>, label=<span class="string">'Validation loss'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_49_0.png" width="400" height="400" alt="b" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>

<center>
    <img src="\Pic\DeepLearning_Pic\output_49_1.png" width="400" height="400" alt="b" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<p>处理这个数据集的第一个简单方法得到的测试精度是88%。不幸的是，与这个基准相比，这个小型循环网络的表现并不好（验证精度只有85%）。问题的部分原因在于，输入只考虑了前500 个单词，而不是整个序列，因此，RNN获得的信息比前面的基准模型更少。另一部分原因在于，SimpleRNN不擅长处理长序列，比如文本。其他类型的循环层的表现要好得多。我们来看几个更高级的循环层。</p>
<h2 id="2-理解LSTM层和GRU层"><a href="#2-理解LSTM层和GRU层" class="headerlink" title="2. 理解LSTM层和GRU层"></a>2. 理解LSTM层和GRU层</h2><p>SimpleRNN并不是Keras中唯一可用的循环层，还有另外两个：LSTM和GRU。在实践中总会用到其中之一，因为SimpleRNN通常过于简化，没有实用价值。SimpleRNN 的最大问题是，在时刻t，理论上来说，它应该能够记住许多时间步之前见过的信息，但实际上它是不可能学到这种长期依赖的。其原因在于梯度消失问题（vanishing gradient problem），这一效应类似于在层数较多的非循环网络（即前馈网络）中观察到的效应：随着层数的增加，网络最终变得无法训练。Hochreiter、Schmidhuber和Bengio在20世纪90年代初研究了这一效应的理论原因a。LSTM层和GRU层都是为了解决这个问题而设计的。</p>
<p>先来看LSTM层。其背后的长短期记忆（LSTM，long short-term memory）算法由Hochreiter和Schmidhuber在1997 年开发b，是二人研究梯度消失问题的重要成果。LSTM层是SimpleRNN层的一种变体，它增加了一种携带信息跨越多个时间步的方法。假设有一条传送带，其运行方向平行于你所处理的序列。序列中的信息可以在任意位置跳上传送带，然后被传送到更晚的时间步，并在需要时原封不动地跳回来。这实际上就是LSTM 的原理：它保存信息以便后面使用，从而防止较早期的信号在处理过程中逐渐消失。</p>
<p>为了详细了解LSTM，我们先从SimpleRNN单元开始讲起。因为有许多个权重矩阵，所以对单元中的$W$和$U$两个矩阵添加下标字母$o$（Wo 和Uo），表示输出。</p>
<center>
    <img src="\Pic\DeepLearning_Pic\lstm.png" width="200" height="200" alt="讨论LSTM层的出发点：SimpleRNN层" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">讨论LSTM层的出发点：SimpleRNN层</div>
</center>

<p>我们向这张图像中添加额外的数据流，其中携带着跨越时间步的信息。它在不同的时间步的值叫作$C_t$，其中$C$表示携带（carry）。这些信息将会对单元产生以下影响：它将与输入连接和循环连接进行运算（通过一个密集变换，即与权重矩阵作点积，然后加上一个偏置，再应用一个激活函数），从而影响传递到下一个时间步的状态（通过一个激活函数和一个乘法运算）。从概念上来看，携带数据流是一种调节下一个输出和下一个状态的方法，到目前为<br>止都很简单。</p>
<p>下面来看这一方法的精妙之处，即携带数据流下一个值的计算方法。它涉及三个不同的变换，这三个变换的形式都和SimpleRNN单元相同。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y = activation(dot(state_t, U) + dot(input_t, W) + b)</span><br></pre></td></tr></table></figure>
<p>但这三个变换都具有各自的权重矩阵，我们分别用字母$i$、$j$和$k$作为下标。目前的模型架构如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">output_t = activation(dot(state_t, Uo) + dot(input_t, Wo) + dot(C_t, Vo) + bo)</span><br><span class="line">i_t = activation(dot(state_t, Ui) + dot(input_t, Wi) + bi)</span><br><span class="line">f_t = activation(dot(state_t, Uf) + dot(input_t, Wf) + bf)</span><br><span class="line">k_t = activation(dot(state_t, Uk) + dot(input_t, Wk) + bk)</span><br><span class="line">c_t+<span class="number">1</span> = i_t * k_t + c_t * f_t</span><br></pre></td></tr></table></figure>
<p>如果要更哲学一点，你还可以解释每个运算的目的。比如你可以说，将<code>c_t</code>和<code>f_t</code>相乘，是为了故意遗忘携带数据流中的不相关信息。同时，<code>i_t</code>和<code>k_t</code>都提供关于当前的信息，可以用新信息来更新携带轨道。但归根结底，这些解释并没有多大意义，因为这些运算的实际效果是由参数化权重决定的，而权重是以端到端的方式进行学习，每次训练都要从头开始，不可能为某个运算赋予特定的目的。RNN单元的类型（如前所述）决定了你的假设空间，即在训练期间搜索良好模型配置的空间，但它不能决定RNN 单元的作用，那是由单元权重来决定的。同一个单元具有不同的权重，可以实现完全不同的作用。因此，组成RNN 单元的运算组合，最好被解释为对搜索的一组约束，而不是一种工程意义上的设计。</p>
<p>对于研究人员来说，这种约束的选择（即如何实现RNN单元）似乎最好是留给最优化算法来完成（比如遗传算法或强化学习过程），而不是让人类工程师来完成。在未来，那将是我们构建网络的方式。总之，你不需要理解关于LSTM单元具体架构的任何内容。作为人类，理解它不应该是你要做的。你只需要记住LSTM单元的作用：允许过去的信息稍后重新进入，从而解决梯度消失问题。</p>
<h2 id="3-Keras中一个LSTM-的具体例子"><a href="#3-Keras中一个LSTM-的具体例子" class="headerlink" title="3. Keras中一个LSTM 的具体例子"></a>3. Keras中一个LSTM 的具体例子</h2><p>现在我们来看一个更实际的问题：使用LSTM层来创建一个模型，然后在IMDB数据上训练模型。这个网络与前面介绍的SimpleRNN网络类似。你只需指定LSTM层的输出维度，其他所有参数（有很多）都使用Keras默认值。Keras具有很好的默认值，无须手动调参，模型通常也能正常运行。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> LSTM</span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Embedding(max_features, <span class="number">32</span>))</span><br><span class="line">model.add(LSTM(<span class="number">32</span>))</span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>,</span><br><span class="line">            loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">            metrics=[<span class="string">'acc'</span>])</span><br><span class="line">history = model.fit(input_train, y_train,</span><br><span class="line">                epochs=<span class="number">10</span>,</span><br><span class="line">                batch_size=<span class="number">128</span>,</span><br><span class="line">                validation_split=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Train on 20000 samples, validate on 5000 samples
Epoch 1/10
20000/20000 [==============================] - 44s 2ms/step - loss: 0.5221 - acc: 0.7523 - val_loss: 0.3656 - val_acc: 0.8520
Epoch 2/10
20000/20000 [==============================] - 43s 2ms/step - loss: 0.3005 - acc: 0.8812 - val_loss: 0.3048 - val_acc: 0.8766
Epoch 3/10
20000/20000 [==============================] - 43s 2ms/step - loss: 0.2410 - acc: 0.9086 - val_loss: 0.3063 - val_acc: 0.8700
Epoch 4/10
20000/20000 [==============================] - 43s 2ms/step - loss: 0.2031 - acc: 0.9252 - val_loss: 0.3210 - val_acc: 0.8862
Epoch 5/10
20000/20000 [==============================] - 43s 2ms/step - loss: 0.1816 - acc: 0.9348 - val_loss: 0.3304 - val_acc: 0.8542
Epoch 6/10
20000/20000 [==============================] - 43s 2ms/step - loss: 0.1661 - acc: 0.9412 - val_loss: 0.3082 - val_acc: 0.8778
Epoch 7/10
20000/20000 [==============================] - 44s 2ms/step - loss: 0.1480 - acc: 0.9482 - val_loss: 0.3066 - val_acc: 0.8738
Epoch 8/10
20000/20000 [==============================] - 45s 2ms/step - loss: 0.1429 - acc: 0.9513 - val_loss: 0.4828 - val_acc: 0.8404
Epoch 9/10
20000/20000 [==============================] - 47s 2ms/step - loss: 0.1278 - acc: 0.9554 - val_loss: 0.3790 - val_acc: 0.8838
Epoch 10/10
20000/20000 [==============================] - 49s 2ms/step - loss: 0.1162 - acc: 0.9593 - val_loss: 0.3512 - val_acc: 0.8512
</code></pre><p>LSTM更适用于评论分析全局的长期性结构（这正是LSTM所擅长的），对情感分析问题帮助不大。对于这样的基本问题，观察每条评论中出现了哪些词及其出现频率就可以很好地解决。这也正是第一个全连接方法的做法。但还有更加困难的自然语言处理问题，特别是问答和机器翻译，这时LSTM的优势就明显了。</p>
<h1 id="三、循环神经网络的高级用法"><a href="#三、循环神经网络的高级用法" class="headerlink" title="三、循环神经网络的高级用法"></a>三、循环神经网络的高级用法</h1><p>本节将介绍提高循环神经网络的性能和泛化能力的三种高级技巧。学完本节，你将会掌握用Keras实现循环网络的大部分内容。我们将在温度预测问题中介绍这三个概念。在这个问题中，数据点时间序列来自建筑物屋顶安装的传感器，包括温度、气压、湿度等，你将要利用这些数据来预测最后一个数据点24小时之后的温度。这是一个相当有挑战性的问题，其中包含许多处理时间序列时经常遇到的困难。</p>
<p>我们将会介绍以下三种技巧。</p>
<ul>
<li>循环<code>dropout</code>（recurrent dropout）。这是一种特殊的内置方法，在循环层中使用<code>dropout</code>来降低过拟合</li>
<li>堆叠循环层（stacking recurrent layers）。这会提高网络的表示能力（代价是更高的计算负荷）</li>
<li>双向循环层（bidirectional recurrent layer）。将相同的信息以不同的方式呈现给循环网络，可以提高精度并缓解遗忘问题</li>
</ul>
<h2 id="1-温度预测问题"><a href="#1-温度预测问题" class="headerlink" title="1. 温度预测问题"></a>1. 温度预测问题</h2><p>到目前为止，我们遇到的唯一一种序列数据就是文本数据，比如IMDB数据集和路透社数据集。但除了语言处理，其他许多问题中也都用到了序列数据。在本节的所有例子中，我们将使用一个天气时间序列数据集，它由德国耶拿的马克思• 普朗克生物地球化学研究所的气象站记录。</p>
<p>在这个数据集中，每10分钟记录14个不同的量（比如气温、气压、湿度、风向等），其中包含多年的记录。原始数据可追溯到2003年，但本例仅使用2009—2016年的数据。这个数据集非常适合用来学习处理数值型时间序列。我们将会用这个数据集来构建模型，输入最近的一些数据（几天的数据点），可以预测24小时之后的气温。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">data_dir = <span class="string">'data/climate/'</span></span><br><span class="line">fname = os.path.join(data_dir, <span class="string">'jena_climate_2009_2016.csv'</span>)</span><br><span class="line">f = open(fname)</span><br><span class="line">data = f.read()</span><br><span class="line">f.close()</span><br><span class="line">lines = data.split(<span class="string">'\n'</span>)</span><br><span class="line">header = lines[<span class="number">0</span>].split(<span class="string">','</span>)</span><br><span class="line">lines = lines[<span class="number">1</span>:]</span><br><span class="line">print(header)</span><br><span class="line">print(len(lines))</span><br></pre></td></tr></table></figure>
<pre><code>[&#39;&quot;Date Time&quot;&#39;, &#39;&quot;p (mbar)&quot;&#39;, &#39;&quot;T (degC)&quot;&#39;, &#39;&quot;Tpot (K)&quot;&#39;, &#39;&quot;Tdew (degC)&quot;&#39;, &#39;&quot;rh (%)&quot;&#39;, &#39;&quot;VPmax (mbar)&quot;&#39;, &#39;&quot;VPact (mbar)&quot;&#39;, &#39;&quot;VPdef (mbar)&quot;&#39;, &#39;&quot;sh (g/kg)&quot;&#39;, &#39;&quot;H2OC (mmol/mol)&quot;&#39;, &#39;&quot;rho (g/m**3)&quot;&#39;, &#39;&quot;wv (m/s)&quot;&#39;, &#39;&quot;max. wv (m/s)&quot;&#39;, &#39;&quot;wd (deg)&quot;&#39;]
420451
</code></pre><p>从输出可以看出，共有 420 551 行数据（每行是一个时间步，记录了一个日期和 14 个与天气有关的值），接下来，将 420 551 行数据转换成一个Numpy数组。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">float_data = np.zeros((len(lines), len(header) - <span class="number">1</span>))</span><br><span class="line"><span class="keyword">for</span> i, line <span class="keyword">in</span> enumerate(lines):</span><br><span class="line">    values = [float(x) <span class="keyword">for</span> x <span class="keyword">in</span> line.split(<span class="string">','</span>)[<span class="number">1</span>:]]</span><br><span class="line">    float_data[i, :] = values</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制温度时间序列</span></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">temp = float_data[:, <span class="number">1</span>] <span class="comment"># 温度（单位：摄氏度）</span></span><br><span class="line">plt.plot(range(len(temp)), temp)</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_56_1.png" width="400" height="400" alt="b" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>



<p>下图给出了前 10 天温度数据的图像，因为每 10 分钟记录一个数据，所以每天有 144 个数据点。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.plot(range(<span class="number">1440</span>), temp[:<span class="number">1440</span>])</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_58_1.png" width="400" height="400" alt="b" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<p>在这张图中，你可以看到每天的周期性变化，尤其是最后4 天特别明显。另外请注意，这 10 天一定是来自于很冷的冬季月份。</p>
<p>如果你想根据过去几个月的数据来预测下个月的平均温度，那么问题很简单，因为数据具有可靠的年度周期性。但从几天的数据来看，温度看起来更混乱一些。以天作为观察尺度，这个时间序列是可以预测的吗？我们来寻找这个问题的答案。</p>
<h2 id="2-准备数据"><a href="#2-准备数据" class="headerlink" title="2. 准备数据"></a>2. 准备数据</h2><p>这个问题的确切表述如下：一个时间步是 10 分钟，每 <code>steps</code> 个时间步采样一次数据，给定过去 <code>lookback</code> 个时间步之内的数据，能否预测 <code>delay</code> 个时间步之后的温度？用到的参数值如下。</p>
<ul>
<li><code>lookback = 720</code>：给定过去 5 天内的观测数据。</li>
<li><code>steps = 6</code>：观测数据的采样频率是每小时一个数据点。</li>
<li><code>delay = 144</code>：目标是未来 24 小时之后的数据。</li>
</ul>
<p>开始之前，你需要完成以下两件事。</p>
<ul>
<li>将数据预处理为神经网络可以处理的格式。这很简单。数据已经是数值型的，所以不需要做向量化。但数据中的每个时间序列位于不同的范围（比如温度通道位于 -20 到+30 之间，但气压大约在1000 毫巴上下）。你需要对每个时间序列分别做标准化，让它们在相似的范围内都取较小的值。</li>
<li>编写一个 Python 生成器，以当前的浮点数数组作为输入，并从最近的数据中生成数据批量，同时生成未来的目标温度。因为数据集中的样本是高度冗余的（对于第 <code>N</code> 个样本和第 <code>N+1</code> 个样本，大部分时间步都是相同的），所以显式地保存每个样本是一种浪费。相反，我们将使用原始数据即时生成样本。</li>
</ul>
<p>预处理数据的方法是，将每个时间序列减去其平均值，然后除以其标准差。我们将使用前 200 000 个时间步作为训练数据，所以只对这部分数据计算平均值和标准差。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mean = float_data[:<span class="number">200000</span>].mean(axis=<span class="number">0</span>)</span><br><span class="line">float_data -= mean</span><br><span class="line">std = float_data[:<span class="number">200000</span>].std(axis=<span class="number">0</span>)</span><br><span class="line">float_data /= std</span><br></pre></td></tr></table></figure>
<p>下面的代码给出了将要用到的生成器。它生成了一个元组<code>(samples, targets)</code>，其中<code>samples</code>是输入数据的一个批量，<code>targets</code>是对应的目标温度数组。生成器的参数如下：</p>
<ul>
<li><code>data</code>：浮点数数据组成的原始数组，我们已将其标准化。</li>
<li><code>lookback</code>：输入数据应该包括过去多少个时间步。</li>
<li><code>delay</code>：目标应该在未来多少个时间步之后。</li>
<li><code>min_index</code> 和 <code>max_index</code>：data 数组中的索引，用于界定需要抽取哪些时间步。这有助于保存一部分数据用于验证、另一部分用于测试。</li>
<li><code>shuffle</code>：是打乱样本，还是按顺序抽取样本。</li>
<li><code>batch_size</code>：每个批量的样本数。</li>
<li><code>step</code>：数据采样的周期（单位：时间步）。我们将其设为6，为的是每小时抽取一个数据点。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生成时间序列样本及其目标的生成器</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator</span><span class="params">(data, lookback, delay, min_index, max_index, shuffle=False, batch_size=<span class="number">128</span>, step=<span class="number">6</span>)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> max_index <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        max_index = len(data) - delay - <span class="number">1</span></span><br><span class="line">    i = min_index + lookback</span><br><span class="line">    <span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">if</span> shuffle:</span><br><span class="line">            rows = np.random.randint(min_index + lookback, max_index, size=batch_size)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> i + batch_size &gt;= max_index:</span><br><span class="line">                i = min_index + lookback</span><br><span class="line">            rows = np.arange(i, min(i + batch_size, max_index))</span><br><span class="line">            i += len(rows)</span><br><span class="line">        samples = np.zeros((len(rows), lookback // step, data.shape[<span class="number">-1</span>]))</span><br><span class="line">        targets = np.zeros((len(rows),))</span><br><span class="line">        <span class="keyword">for</span> j, row <span class="keyword">in</span> enumerate(rows):</span><br><span class="line">            indices = range(rows[j] - lookback, rows[j], step)</span><br><span class="line">            samples[j] = data[indices]</span><br><span class="line">            targets[j] = data[rows[j] + delay][<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">yield</span> samples, targets</span><br></pre></td></tr></table></figure>
<p>下面，我们使用这个抽象的<code>generator</code>函数来实例化三个生成器：一个用于训练，一个用于验证，还有一个用于测试。每个生成器分别读取原始数据的不同时间段：训练生成器读取前 200 000 个时间步，验证生成器读取随后的 100 000 个时间步，测试生成器读取剩下的时间步。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lookback = <span class="number">1440</span></span><br><span class="line">step = <span class="number">6</span></span><br><span class="line">delay = <span class="number">144</span></span><br><span class="line">batch_size = <span class="number">128</span></span><br><span class="line"></span><br><span class="line">train_gen = generator(float_data,</span><br><span class="line">                lookback=lookback,</span><br><span class="line">                delay=delay,</span><br><span class="line">                min_index=<span class="number">0</span>,</span><br><span class="line">                max_index=<span class="number">200000</span>,</span><br><span class="line">                shuffle=<span class="literal">True</span>,</span><br><span class="line">                step=step,</span><br><span class="line">                batch_size=batch_size)</span><br><span class="line">val_gen = generator(float_data,</span><br><span class="line">                lookback=lookback,</span><br><span class="line">                delay=delay,</span><br><span class="line">                min_index=<span class="number">200001</span>,</span><br><span class="line">                max_index=<span class="number">300000</span>,</span><br><span class="line">                step=step,</span><br><span class="line">                batch_size=batch_size)</span><br><span class="line">test_gen = generator(float_data,</span><br><span class="line">                lookback=lookback,</span><br><span class="line">                delay=delay,</span><br><span class="line">                min_index=<span class="number">300001</span>,</span><br><span class="line">                max_index=<span class="literal">None</span>,</span><br><span class="line">                step=step,</span><br><span class="line">                batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">val_steps = (<span class="number">300000</span> - <span class="number">200001</span> - lookback) //batch_size</span><br><span class="line">test_steps = (len(float_data) - <span class="number">300001</span> - lookback) //batch_size</span><br></pre></td></tr></table></figure>
<h2 id="3-一种基于常识的、非机器学习的基准方法"><a href="#3-一种基于常识的、非机器学习的基准方法" class="headerlink" title="3. 一种基于常识的、非机器学习的基准方法"></a>3. 一种基于常识的、非机器学习的基准方法</h2><p>开始使用黑盒深度学习模型解决温度预测问题之前，我们先尝试一种基于常识的简单方法。它可以作为合理性检查，还可以建立一个基准，更高级的机器学习模型需要打败这个基准才能表现出其有效性。面对一个尚没有已知解决方案的新问题时，这种基于常识的基准方法很有用。</p>
<p>一个经典的例子就是不平衡的分类任务，其中某些类别比其他类别更常见。如果数据集中包含 90% 的类别 A 实例和 10% 的类别B 实例，那么分类任务的一种基于常识的方法就是对新样本始终预测类别“A”。这种分类器的总体精度为90%，因此任何基于学习的方法在精度高于90%时才能证明其有效性。有时候，这样基本的基准方法可能很难打败。</p>
<p>本例中，我们可以放心地假设，温度时间序列是连续的（明天的温度很可能接近今天的温度），并且具有每天的周期性变化。因此，一种基于常识的方法就是始终预测 24 小时后的温度等于现在的温度。我们使用平均绝对误差（MAE）指标来评估这种方法。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.mean(np.abs(preds - targets))</span><br></pre></td></tr></table></figure><br>下面是评估的循环代码。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_naive_method</span><span class="params">()</span>:</span></span><br><span class="line">    batch_maes = []</span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> range(val_steps):</span><br><span class="line">        samples, targets = next(val_gen)</span><br><span class="line">        preds = samples[:, <span class="number">-1</span>, <span class="number">1</span>]</span><br><span class="line">        mae = np.mean(np.abs(preds - targets))</span><br><span class="line">        batch_maes.append(mae)</span><br><span class="line">    print(np.mean(batch_maes))</span><br><span class="line">evaluate_naive_method()</span><br><span class="line">    <span class="comment"># 0.2897359729905486</span></span><br></pre></td></tr></table></figure>
<p>得到的 MAE 为 0.29。因为温度数据被标准化成均值为0、标准差为1，所以无法直接对这个值进行解释。它转化成温度的平均绝对误差为<code>0.29×temperature_std</code>摄氏度，即2.57℃。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将 MAE 转换成摄氏温度误差</span></span><br><span class="line">celsius_mae = <span class="number">0.29</span> * std[<span class="number">1</span>]</span><br><span class="line">celsius_mae</span><br><span class="line">    <span class="comment"># 2.5672247338393395</span></span><br></pre></td></tr></table></figure>
<p>这个平均绝对误差还是相当大的。接下来的任务是利用深度学习知识来改进结果。</p>
<h2 id="4-一种基本的机器学习方法"><a href="#4-一种基本的机器学习方法" class="headerlink" title="4. 一种基本的机器学习方法"></a>4. 一种基本的机器学习方法</h2><p>在尝试机器学习方法之前，建立一个基于常识的基准方法是很有用的；同样，在开始研究复杂且计算代价很高的模型（比如RNN）之前，尝试使用简单且计算代价低的机器学习模型也是很有用的，比如小型的密集连接网络。这可以保证进一步增加问题的复杂度是合理的，并且会带来真正的好处。</p>
<p>下面代码给出了一个密集连接模型，首先将数据展平，然后通过两个<code>Dense</code>层并运行。注意，最后一个<code>Dense</code>层没有使用激活函数，这对于回归问题是很常见的。我们使用<code>MAE</code>作为损失。评估数据和评估指标都与常识方法完全相同，所以可以直接比较两种方法的结果。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 训练并评估一个密集连接模型</span></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> RMSprop</span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(layers.Flatten(input_shape=(lookback // step, float_data.shape[<span class="number">-1</span>])))</span><br><span class="line">model.add(layers.Dense(<span class="number">32</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>))</span><br><span class="line">model.compile(optimizer=RMSprop(), loss=<span class="string">'mae'</span>)</span><br><span class="line">history = model.fit_generator(train_gen,</span><br><span class="line">                        steps_per_epoch=<span class="number">500</span>,</span><br><span class="line">                        epochs=<span class="number">20</span>,</span><br><span class="line">                        validation_data=val_gen,</span><br><span class="line">                        validation_steps=val_steps)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 绘制曲线</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">loss = history.history[<span class="string">'loss'</span>]</span><br><span class="line">val_loss = history.history[<span class="string">'val_loss'</span>]</span><br><span class="line">epochs = range(<span class="number">1</span>, len(loss) + <span class="number">1</span>)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(epochs, loss, <span class="string">'bo'</span>, label=<span class="string">'Training loss'</span>)</span><br><span class="line">plt.plot(epochs, val_loss, <span class="string">'b'</span>, label=<span class="string">'Validation loss'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_70_1.png" width="400" height="400" alt="b" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<p>部分验证损失接近不包含学习的基准方法，但这个结果并不可靠。这也展示了首先建立这个基准方法的优点，事实证明，超越这个基准并不容易。我们的常识中包含了大量有价值的信息，而机器学习模型并不知道这些信息。</p>
<p>你可能会问，如果从数据到目标之间存在一个简单且表现良好的模型（即基于常识的基准方法），那为什么我们训练的模型没有找到这个模型并进一步改进呢？原因在于，这个简单的解决方案并不是训练过程所要寻找的目标。我们在模型空间（即假设空间）中搜索解决方案，这个模型空间是具有我们所定义的架构的所有两层网络组成的空间。这些网络已经相当复杂了。如果你在一个复杂模型的空间中寻找解决方案，那么可能无法学到简单且性能良好的基准方法，虽然技术上来说它属于假设空间的一部分。</p>
<p>通常来说，这对机器学习是一个非常重要的限制：如果学习算法没有被硬编码要求去寻找特定类型的简单模型，那么有时候参数学习是无法找到简单问题的简单解决方案的。</p>
<h2 id="5-第一个循环网络基准"><a href="#5-第一个循环网络基准" class="headerlink" title="5. 第一个循环网络基准"></a>5. 第一个循环网络基准</h2><p>第一个全连接方法的效果并不好，但这并不意味着机器学习不适用于这个问题。前一个方法首先将时间序列展平，这从输入数据中删除了时间的概念。我们来看一下数据本来的样子：它是一个序列，其中因果关系和顺序都很重要。我们将尝试一种循环序列处理模型，它应该特别适合这种序列数据，因为它利用了数据点的时间顺序，这与第一个方法不同。</p>
<p>我们将使用 Chung 等人在2014 年开发的 GRU 层，而不是上一节介绍的 LSTM 层。门控循环单元（GRU，gated recurrent unit）层的工作原理与 LSTM 相同。但它做了一些简化，因此运行的计算代价更低（虽然表示能力可能不如LSTM），机器学习中到处可以见到这种计算代价与表示能力之间的折中。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 训练并评估一个基于 GRU 的模型</span></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> RMSprop</span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(layers.GRU(<span class="number">32</span>, input_shape=(<span class="literal">None</span>, float_data.shape[<span class="number">-1</span>])))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>))</span><br><span class="line">model.compile(optimizer=RMSprop(), loss=<span class="string">'mae'</span>)</span><br><span class="line">history = model.fit_generator(train_gen,</span><br><span class="line">                        steps_per_epoch=<span class="number">500</span>,</span><br><span class="line">                        epochs=<span class="number">20</span>,</span><br><span class="line">                        validation_data=val_gen,</span><br><span class="line">                        validation_steps=val_steps)</span><br></pre></td></tr></table></figure>
<p>效果好多了！远优于基于常识的基准方法。这证明了机器学习的价值，也证明了循环网络与序列展平的密集网络相比在这种任务上的优势。</p>
<h2 id="6-使用循环dropout来降低过拟合"><a href="#6-使用循环dropout来降低过拟合" class="headerlink" title="6. 使用循环dropout来降低过拟合"></a>6. 使用循环<code>dropout</code>来降低过拟合</h2><p>从训练和验证曲线中可以明显看出，模型出现过拟合：几轮过后，训练损失和验证损失就开始显著偏离。我们已经学过降低过拟合的一种经典技术——<code>dropout</code>，即将某一层的输入单元随机设为0，其目的是打破该层训练数据中的偶然相关性。但在循环网络中如何正确地使用<code>dropout</code>，这并不是一个简单的问题。人们早就知道，在循环层前面应用<code>dropout</code>，这种正则化会妨碍学习过程，而不是有所帮助。2015 年，在关于贝叶斯深度学习的博士论文中，Yarin Gal确定了在循环网络中使用<code>dropout</code>的正确方法：<strong>对每个时间步应该使用相同的<code>dropout</code>掩码（dropout mask，相同模式的舍弃单元），而不是让<code>dropout</code>掩码随着时间步的增加而随机变化。</strong> 此外，为了对GRU、LSTM等循环层得到的表示做正则化，应该将不随时间变化的<code>dropout</code>掩码应用于层的内部循环激活（叫作循环<code>dropout</code>掩码）。对每个时间步使用相同的<code>dropout</code>掩码，可以让网络沿着时间正确地传播其学习误差，而随时间随机变化的<code>dropout</code>掩码则会破坏这个误差信号，并且不利于学习过程。</p>
<p>Yarin Gal 使用Keras开展这项研究，并帮助将这种机制直接内置到Keras循环层中。Keras的每个循环层都有两个与<code>dropout</code>相关的参数：一个是<code>dropout</code>，它是一个浮点数，指定该层输入单元的<code>dropout</code>比率；另一个是<code>recurrent_dropout</code>，指定循环单元的<code>dropout</code>比率。我们向GRU 层中添加<code>dropout</code>和循环<code>dropout</code>，看一下这么做对过拟合的影响。因为使用<code>dropout</code>正则化的网络总是需要更长的时间才能完全收敛，所以网络训练轮次增加为原来的2倍。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 训练并评估一个使用dropout正则化的基于GRU的模型</span></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> RMSprop</span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(layers.GRU(<span class="number">32</span>,</span><br><span class="line">        dropout=<span class="number">0.2</span>,</span><br><span class="line">        recurrent_dropout=<span class="number">0.2</span>,</span><br><span class="line">        input_shape=(<span class="literal">None</span>, float_data.shape[<span class="number">-1</span>])))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>))</span><br><span class="line">model.compile(optimizer=RMSprop(), loss=<span class="string">'mae'</span>)</span><br><span class="line">history = model.fit_generator(train_gen,</span><br><span class="line">                        steps_per_epoch=<span class="number">500</span>,</span><br><span class="line">                        epochs=<span class="number">1</span>,</span><br><span class="line">                        validation_data=val_gen,</span><br><span class="line">                        validation_steps=val_steps)</span><br></pre></td></tr></table></figure>
<p>成功！前30个轮次不再过拟合。不过，虽然评估分数更加稳定，但最佳分数并没有比之前低很多。</p>
<h2 id="7-循环层堆叠"><a href="#7-循环层堆叠" class="headerlink" title="7. 循环层堆叠"></a>7. 循环层堆叠</h2><p>模型不再过拟合，但似乎遇到了性能瓶颈，所以我们应该考虑增加网络容量。回想一下机器学习的通用工作流程：增加网络容量通常是一个好主意，直到过拟合变成主要的障碍（假设你已经采取基本步骤来降低过拟合，比如使用dropout）。只要过拟合不是太严重，那么很可能是容量不足的问题。</p>
<p>增加网络容量的通常做法是增加每层单元数或增加层数。循环层堆叠（recurrent layer stacking）是构建更加强大的循环网络的经典方法，例如，目前谷歌翻译算法就是7个大型LSTM 层的堆叠——这个架构很大。</p>
<p>在Keras中逐个堆叠循环层，所有中间层都应该返回完整的输出序列（一个3D张量），而不是只返回最后一个时间步的输出。这可以通过指定<code>return_sequences=True</code>来实现。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 训练并评估一个使用dropout正则化的堆叠GRU模型</span></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> RMSprop</span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(layers.GRU(<span class="number">32</span>,</span><br><span class="line">        dropout=<span class="number">0.1</span>,</span><br><span class="line">        recurrent_dropout=<span class="number">0.5</span>,</span><br><span class="line">        return_sequences=<span class="literal">True</span>,</span><br><span class="line">        input_shape=(<span class="literal">None</span>, float_data.shape[<span class="number">-1</span>])))</span><br><span class="line">model.add(layers.GRU(<span class="number">64</span>, activation=<span class="string">'relu'</span>,</span><br><span class="line">        dropout=<span class="number">0.1</span>,</span><br><span class="line">        recurrent_dropout=<span class="number">0.5</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>))</span><br><span class="line">model.compile(optimizer=RMSprop(), loss=<span class="string">'mae'</span>)</span><br><span class="line">history = model.fit_generator(train_gen,</span><br><span class="line">                            steps_per_epoch=<span class="number">500</span>,</span><br><span class="line">                            epochs=<span class="number">1</span>,</span><br><span class="line">                            validation_data=val_gen,</span><br><span class="line">                            validation_steps=val_steps)</span><br></pre></td></tr></table></figure>
<p>可以看到，添加一层的确对结果有所改进，但并不显著。我们可以得出两个结论:</p>
<ul>
<li>因为过拟合仍然不是很严重，所以可以放心地增大每层的大小，以进一步改进验证损失。但这么做的计算成本很高。</li>
<li>添加一层后模型并没有显著改进，所以你可能发现，提高网络能力的回报在逐渐减小。</li>
</ul>
<h2 id="8-使用双向RNN"><a href="#8-使用双向RNN" class="headerlink" title="8. 使用双向RNN"></a>8. 使用双向RNN</h2><p>本节介绍的最后一种方法叫作双向RNN（bidirectional RNN）。双向RNN是一种常见的RNN变体，它在某些任务上的性能比普通RNN更好。它常用于自然语言处理，可谓深度学习对自然语言处理的瑞士军刀。</p>
<p>RNN特别依赖于顺序或时间，RNN按顺序处理输入序列的时间步，而打乱时间步或反转时间步会完全改变RNN从序列中提取的表示。正是由于这个原因，如果顺序对问题很重要（比如温度预测问题），RNN的表现会很好。双向RNN利用了RNN 的顺序敏感性：它包含两个普通RNN，比如你已经学过的GRU层和LSTM层，每个RNN分别沿一个方向对输入序列进行处理（时间正序和时间逆序），然后将它们的表示合并在一起。通过沿这两个方向处理序列，双向RNN能够捕捉到可能被单向RNN忽略的模式。</p>
<p>值得注意的是，本节的RNN 层都是按时间正序处理序列（更早的时间步在前），这可能是一个随意的决定。至少，至今我们还没有尝试质疑这个决定。如果RNN按时间逆序处理输入序列（更晚的时间步在前），能否表现得足够好呢？我们在实践中尝试一下这种方法，看一下会发生什么。你只需要编写一个数据生成器的变体，将输入序列沿着时间维度反转（即将最后一行代码替换为<code>yield samples[:, ::-1, :], targets）</code>。本节第一个实验用到了一个单GRU层的网络，我们训练一个与之相同的网络，得到的结果如图所示。</p>
<center>
    <img src="\Pic\DeepLearning_Pic\res1.png" width="400" height="400" alt="对于耶拿温度预测任务，GRU在逆序序列上训练得到的训练损失和验证损失" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">对于耶拿温度预测任务，GRU在逆序序列上训练得到的训练损失和验证损失</div>
</center>


<p>逆序GRU的效果甚至比基于常识的基准方法还要差很多，这说明在本例中，按时间正序处理对成功解决问题很重要。这非常合理：GRU层通常更善于记住最近的数据，而不是久远的数据，与更早的数据点相比，更靠后的天气数据点对问题自然具有更高的预测能力（这也是基于常识的基准方法非常强大的原因）。因此，按时间正序的模型必然会优于时间逆序的模型。重要的是，对许多其他问题（包括自然语言）而言，情况并不是这样：直觉上来看，一个单词对理解句子的重要性通常并不取决于它在句子中的位置。我们尝试对IMDB示例中的LSTM应用相同的技巧。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用逆序序列训练并评估一个LSTM</span></span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> imdb</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> sequence</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line">max_features = <span class="number">10000</span></span><br><span class="line">maxlen = <span class="number">500</span></span><br><span class="line">(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)</span><br><span class="line">x_train = [x[::<span class="number">-1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> x_train]</span><br><span class="line">x_test = [x[::<span class="number">-1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> x_test]</span><br><span class="line">x_train = sequence.pad_sequences(x_train, maxlen=maxlen)</span><br><span class="line">x_test = sequence.pad_sequences(x_test, maxlen=maxlen)</span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(layers.Embedding(max_features, <span class="number">128</span>))</span><br><span class="line">model.add(layers.LSTM(<span class="number">32</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>,</span><br><span class="line">            loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">            metrics=[<span class="string">'acc'</span>])</span><br><span class="line">history = model.fit(x_train, y_train,</span><br><span class="line">            epochs=<span class="number">10</span>,</span><br><span class="line">            batch_size=<span class="number">128</span>,</span><br><span class="line">            validation_split=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Train on 20000 samples, validate on 5000 samples
Epoch 1/10
20000/20000 [==============================] - 83s 4ms/step - loss: 0.4988 - acc: 0.7621 - val_loss: 0.3412 - val_acc: 0.8684
Epoch 2/10
20000/20000 [==============================] - 85s 4ms/step - loss: 0.3184 - acc: 0.8795 - val_loss: 0.3068 - val_acc: 0.8814
Epoch 3/10
20000/20000 [==============================] - 86s 4ms/step - loss: 0.2544 - acc: 0.9025 - val_loss: 0.3151 - val_acc: 0.8798
Epoch 4/10
20000/20000 [==============================] - 78s 4ms/step - loss: 0.2133 - acc: 0.9225 - val_loss: 0.3849 - val_acc: 0.8544
Epoch 5/10
20000/20000 [==============================] - 83s 4ms/step - loss: 0.1877 - acc: 0.9332 - val_loss: 0.3698 - val_acc: 0.8684
Epoch 6/10
20000/20000 [==============================] - 73s 4ms/step - loss: 0.1675 - acc: 0.9416 - val_loss: 0.3680 - val_acc: 0.8418
Epoch 7/10
20000/20000 [==============================] - 76s 4ms/step - loss: 0.1474 - acc: 0.9488 - val_loss: 0.4329 - val_acc: 0.8504
Epoch 8/10
20000/20000 [==============================] - 70s 4ms/step - loss: 0.1316 - acc: 0.9559 - val_loss: 0.4002 - val_acc: 0.8484
Epoch 9/10
20000/20000 [==============================] - 77s 4ms/step - loss: 0.1163 - acc: 0.9593 - val_loss: 0.3937 - val_acc: 0.8736
Epoch 10/10
20000/20000 [==============================] - 73s 4ms/step - loss: 0.1023 - acc: 0.9685 - val_loss: 0.4931 - val_acc: 0.8652
</code></pre><p>模型性能与正序LSTM几乎相同。值得注意的是，在这样一个文本数据集上，逆序处理的效果与正序处理一样好，这证实了一个假设：虽然单词顺序对理解语言很重要，但使用哪种顺序并不重要。重要的是，在逆序序列上训练的RNN学到的表示不同于在原始序列上学到的表示，正如在现实世界中，如果时间倒流（你的人生是第一天死去、最后一天出生），那么你的心智模型也会完全不同。在机器学习中，如果一种数据表示不同但有用，那么总是值得加以利用，这种表示与其他表示的差异越大越好，它们提供了查看数据的全新角度，抓住了数据中被其他方法忽略的内容，因此可以提高模型在某个任务上的性能。这是集成（ensembling）方法背后的直觉。</p>
<p>双向RNN正是利用这个想法来提高正序RNN的性能。它从两个方向查看数据，从而得到更加丰富的表示，并捕捉到仅使用正序RNN时可能忽略的一些模式。</p>
<center>
    <img src="\Pic\DeepLearning_Pic\double_rnn.png" width="300" height="300" alt="双向RNN层的工作原理" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">双向RNN层的工作原理</div>
</center>

<p>在Keras中将一个双向RNN实例化，我们需要使用<code>Bidirectional</code>层，它的第一个参数是一个循环层实例。<code>Bidirectional</code>对这个循环层创建了第二个单独实例，然后使用一个实例按正序处理输入序列，另一个实例按逆序处理输入序列。我们在IMDB情感分析任务上来试一下这种方法。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 训练并评估一个双向LSTM</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(layers.Embedding(max_features, <span class="number">32</span>))</span><br><span class="line">model.add(layers.Bidirectional(layers.LSTM(<span class="number">32</span>)))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>, loss=<span class="string">'binary_crossentropy'</span>, metrics=[<span class="string">'acc'</span>])</span><br><span class="line">history = model.fit(x_train, y_train,</span><br><span class="line">                epochs=<span class="number">10</span>,</span><br><span class="line">                batch_size=<span class="number">128</span>,</span><br><span class="line">                validation_split=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Train on 20000 samples, validate on 5000 samples
Epoch 1/10
20000/20000 [==============================] - 133s 7ms/step - loss: 0.5509 - acc: 0.7215 - val_loss: 0.3725 - val_acc: 0.8560
Epoch 2/10
20000/20000 [==============================] - 146s 7ms/step - loss: 0.3318 - acc: 0.8729 - val_loss: 0.4149 - val_acc: 0.8526
Epoch 3/10
20000/20000 [==============================] - 134s 7ms/step - loss: 0.2647 - acc: 0.9024 - val_loss: 0.8188 - val_acc: 0.7226
Epoch 4/10
20000/20000 [==============================] - 136s 7ms/step - loss: 0.2384 - acc: 0.9178 - val_loss: 0.3252 - val_acc: 0.8760
Epoch 5/10
20000/20000 [==============================] - 143s 7ms/step - loss: 0.2025 - acc: 0.9269 - val_loss: 0.4345 - val_acc: 0.8728
Epoch 6/10
20000/20000 [==============================] - 146s 7ms/step - loss: 0.1841 - acc: 0.9362 - val_loss: 0.3524 - val_acc: 0.8728
Epoch 7/10
20000/20000 [==============================] - 136s 7ms/step - loss: 0.1692 - acc: 0.9416 - val_loss: 0.4050 - val_acc: 0.8450
Epoch 8/10
20000/20000 [==============================] - 138s 7ms/step - loss: 0.1523 - acc: 0.9474 - val_loss: 0.4994 - val_acc: 0.8456
Epoch 9/10
20000/20000 [==============================] - 141s 7ms/step - loss: 0.1356 - acc: 0.9538 - val_loss: 0.4161 - val_acc: 0.8792
Epoch 10/10
20000/20000 [==============================] - 141s 7ms/step - loss: 0.1338 - acc: 0.9547 - val_loss: 0.3581 - val_acc: 0.8648
</code></pre><p>这个模型的表现比上一节的普通LSTM略好，这个模型似乎也很快就开始过拟合，这并不令人惊讶，因为双向层的参数个数是正序LSTM 的2倍。添加一些正则化，双向方法在这个任务上可能会有很好的表现。</p>
<p>接下来，我们尝试将相同的方法应用于温度预测任务。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 训练一个双向GRU</span></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> RMSprop</span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(layers.Bidirectional(layers.GRU(<span class="number">32</span>), input_shape=(<span class="literal">None</span>, float_data.shape[<span class="number">-1</span>])))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>))</span><br><span class="line">model.compile(optimizer=RMSprop(), loss=<span class="string">'mae'</span>)</span><br><span class="line">history = model.fit_generator(train_gen,</span><br><span class="line">                            steps_per_epoch=<span class="number">500</span>,</span><br><span class="line">                            epochs=<span class="number">10</span>,</span><br><span class="line">                            validation_data=val_gen,</span><br><span class="line">                            validation_steps=val_steps)</span><br></pre></td></tr></table></figure>
<p>这个模型的表现与普通GRU层差不多一样好。其原因很容易理解：所有的预测能力肯定都来自于正序的那一半网络，因为我们已经知道，逆序的那一半在这个任务上的表现非常糟糕（本例同样是因为最近的数据比久远的数据更加重要）。</p>
<h2 id="9-更多尝试"><a href="#9-更多尝试" class="headerlink" title="9. 更多尝试"></a>9. 更多尝试</h2><p>为了提高温度预测问题的性能，你还可以尝试下面这些方法。</p>
<ul>
<li>在堆叠循环层中调节每层的单元个数，当前取值在很大程度上是任意选择的，因此可能不是最优的</li>
<li>调节RMSprop优化器的学习率</li>
<li>尝试使用LSTM层代替GRU层</li>
<li>在循环层上面尝试使用更大的密集连接回归器，即更大的Dense层或Dense层的堆叠</li>
<li>不要忘记最后在测试集上运行性能最佳的模型（即验证MAE最小的模型），否则，你开发的网络架构将会对验证集过拟合</li>
</ul>
<h1 id="四、用卷积神经网络处理序列"><a href="#四、用卷积神经网络处理序列" class="headerlink" title="四、用卷积神经网络处理序列"></a>四、用卷积神经网络处理序列</h1><p>前面我们学习了卷积神经网络（convnet），并知道它在计算机视觉问题上表现出色，原因在于它能够进行卷积运算，从局部输入图块中提取特征，并能够将表示模块化，同时可以高效地利用数据。这些性质让卷积神经网络在计算机视觉领域表现优异，同样也让它对序列处理特别有效。时间可以被看作一个空间维度，就像二维图像的高度或宽度。</p>
<p>对于某些序列处理问题，这种一维卷积神经网络的效果可以媲美RNN，而且计算代价通常要小很多。最近，一维卷积神经网络［通常与空洞卷积核（dilated kernel）一起使用］已经在音频生成和机器翻译领域取得了巨大成功。除了这些具体的成就，人们还早已知道，对于文本分类和时间序列预测等简单任务，小型的一维卷积神经网络可以替代RNN，而且速度更快。</p>
<h2 id="1-理解序列数据的一维卷积"><a href="#1-理解序列数据的一维卷积" class="headerlink" title="1. 理解序列数据的一维卷积"></a>1. 理解序列数据的一维卷积</h2><p>前面介绍的卷积层都是二维卷积，从图像张量中提取二维图块并对每个图块应用相同的变换。按照同样的方法，你也可以使用一维卷积，从序列中提取局部一维序列段（即子序列）</p>
<p>这种一维卷积层可以识别序列中的局部模式。因为对每个序列段执行相同的输入变换，所以在句子中某个位置学到的模式稍后可以在其他位置被识别，这使得一维卷积神经网络具有平移不变性（对于时间平移而言）。举个例子，使用大小为5的卷积窗口处理字符序列的一维卷积神经网络，应该能够学习长度不大于5的单词或单词片段，并且应该能够在输入句子中的任何位置识别这些单词或单词段。因此，字符级的一维卷积神经网络能够学会单词构词法。</p>
<center>
    <img src="\Pic\DeepLearning_Pic\ODRNN.png" width="300" height="300" alt="一维卷积神经网络的工作原理：每个输出时间步都是利用输入序列
在时间维度上的一小段得到的" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">一维卷积神经网络的工作原理：每个输出时间步都是利用输入序列在时间维度上的一小段得到的</div>
</center>

<h2 id="2-序列数据的一维池化"><a href="#2-序列数据的一维池化" class="headerlink" title="2. 序列数据的一维池化"></a>2. 序列数据的一维池化</h2><p>你已经学过二维池化运算，比如二维平均池化和二维最大池化，在卷积神经网络中用于对图像张量进行空间下采样。一维也可以做相同的池化运算：从输入中提取一维序列段（即子序列），然后输出其最大值（最大池化）或平均值（平均池化）。与二维卷积神经网络一样，该运算也是用于降低一维输入的长度（子采样）。</p>
<h2 id="3-实现一维卷积神经网络"><a href="#3-实现一维卷积神经网络" class="headerlink" title="3. 实现一维卷积神经网络"></a>3. 实现一维卷积神经网络</h2><p>Keras中的一维卷积神经网络是<code>Conv1D</code>层，其接口类似于<code>Conv2D</code>。它接收的输入是形状为<code>(samples, time, features)</code>的三维张量，并返回类似形状的三维张量。卷积窗口是时间轴上的一维窗口（时间轴是输入张量的第二个轴）。</p>
<p>我们来构建一个简单的两层一维卷积神经网络，并将其应用于我们熟悉的IMDB情感分类任务。提醒一下，获取数据并预处理的代码如下所示。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> imdb</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> sequence</span><br><span class="line">max_features = <span class="number">10000</span></span><br><span class="line">max_len = <span class="number">500</span></span><br><span class="line">print(<span class="string">'Loading data...'</span>)</span><br><span class="line">(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)</span><br><span class="line">print(len(x_train), <span class="string">'train sequences'</span>)</span><br><span class="line">print(len(x_test), <span class="string">'test sequences'</span>)</span><br><span class="line">print(<span class="string">'Pad sequences (samples x time)'</span>)</span><br><span class="line">x_train = sequence.pad_sequences(x_train, maxlen=max_len)</span><br><span class="line">x_test = sequence.pad_sequences(x_test, maxlen=max_len)</span><br><span class="line">print(<span class="string">'x_train shape:'</span>, x_train.shape)</span><br><span class="line">print(<span class="string">'x_test shape:'</span>, x_test.shape)</span><br></pre></td></tr></table></figure>
<p>一维卷积神经网络的架构与二维卷积神经网络相同，它是<code>Conv1D</code>层和<code>MaxPooling1D</code>层的堆叠，最后是一个全局池化层或<code>Flatten</code>层，将三维输出转换为二维输出，让你可以向模型中添加一个或多个<code>Dense</code>层，用于分类或回归。不过二者有一点不同：一维卷积神经网络可以使用更大的卷积窗口。对于二维卷积层，$3×3$的卷积窗口包含$3×3=9$个特征向量；但对于一位卷积层，大小为3的卷积窗口只包含3个卷积向量。因此，你可以轻松使用大小等于7或9 的一维卷积窗口。</p>
<p>用于IMDB数据集的一维卷积神经网络示例如下所示。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在IMDB数据上训练并评估一个简单的一维卷积神经网络</span></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> RMSprop</span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(layers.Embedding(max_features, <span class="number">128</span>, input_length=max_len))</span><br><span class="line">model.add(layers.Conv1D(<span class="number">32</span>, <span class="number">7</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling1D(<span class="number">5</span>))</span><br><span class="line">model.add(layers.Conv1D(<span class="number">32</span>, <span class="number">7</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.GlobalMaxPooling1D())</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>))</span><br><span class="line">model.summary()</span><br><span class="line">model.compile(optimizer=RMSprop(lr=<span class="number">1e-4</span>),</span><br><span class="line">            loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">            metrics=[<span class="string">'acc'</span>])</span><br><span class="line">history = model.fit(x_train, y_train,</span><br><span class="line">                epochs=<span class="number">10</span>,</span><br><span class="line">                batch_size=<span class="number">128</span>,</span><br><span class="line">                validation_split=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>
<p>验证精度略低于LSTM，但在CPU和GPU上的运行速度都要更快（速度提高多少取决于具体配置，会有很大差异）。现在，你可以使用正确的轮数（4 轮）重新训练这个模型，然后在测试集上运行。这个结果可以让我们确信，在单词级的情感分类任务上，一维卷积神经网络可以替代循环网络，并且速度更快、计算代价更低。</p>
<center>
    <img src="\Pic\DeepLearning_Pic\train_1.png" width="300" height="300" alt="简单的一维卷积神经网络在IMDB数据上的训练精度和验证精度" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">简单的一维卷积神经网络在IMDB数据上的训练损失和验证损失</div>
</center>

<center>
    <img src="\Pic\DeepLearning_Pic\train_2.png" width="300" height="300" alt="简单的一维卷积神经网络在IMDB数据上的训练精度和验证精度" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">简单的一维卷积神经网络在IMDB数据上的训练损失和验证损失</div>
</center>

<h2 id="4-结合CNN和RNN来处理长序列"><a href="#4-结合CNN和RNN来处理长序列" class="headerlink" title="4. 结合CNN和RNN来处理长序列"></a>4. 结合CNN和RNN来处理长序列</h2><p>一维卷积神经网络分别处理每个输入序列段，所以它对时间步的顺序不敏感（这里所说顺序的范围要大于局部尺度，即大于卷积窗口的大小），这一点与RNN不同。当然，为了识别更长期的模式，你可以将许多卷积层和池化层堆叠在一起，这样上面的层能够观察到原始输入中更长的序列段，但这仍然不是一种引入顺序敏感性的好方法。想要证明这种方法的不足，一种方法是在温度预测问题上使用一维卷积神经网络，在这个问题中顺序敏感性对良好的预测结果非常关键。以下示例复用了前面定义的这些变量：float_data、train_gen、val_gen 和val_steps。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> RMSprop</span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(layers.Conv1D(<span class="number">32</span>, <span class="number">5</span>, activation=<span class="string">'relu'</span>,</span><br><span class="line">input_shape=(<span class="literal">None</span>, float_data.shape[<span class="number">-1</span>])))</span><br><span class="line">model.add(layers.MaxPooling1D(<span class="number">3</span>))</span><br><span class="line">model.add(layers.Conv1D(<span class="number">32</span>, <span class="number">5</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling1D(<span class="number">3</span>))</span><br><span class="line">model.add(layers.Conv1D(<span class="number">32</span>, <span class="number">5</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.GlobalMaxPooling1D())</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>))</span><br><span class="line">model.compile(optimizer=RMSprop(), loss=<span class="string">'mae'</span>)</span><br><span class="line">history = model.fit_generator(train_gen,</span><br><span class="line">                        steps_per_epoch=<span class="number">500</span>,</span><br><span class="line">                        epochs=<span class="number">10</span>,</span><br><span class="line">                        validation_data=val_gen,</span><br><span class="line">                        validation_steps=val_steps)</span><br></pre></td></tr></table></figure>
<p>下图给出了训练和验证的MAE</p>
<center>
    <img src="\Pic\DeepLearning_Pic\train_3.png" width="300" height="300" alt="简单的一维卷积神经网络在温度预测任务上的训练损失和验证损失" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">简单的一维卷积神经网络在温度预测任务上的训练损失和验证损失</div>
</center>

<p>验证MAE 停留在<code>0.4~0.5</code>，使用小型卷积神经网络甚至无法击败基于常识的基准方法。同样，这是因为卷积神经网络在输入时间序列的所有位置寻找模式，它并不知道所看到某个模式的时间位置（距开始多长时间，距结束多长时间等）。对于这个具体的预测问题，对最新数据点的解释与对较早数据点的解释应该并不相同，所以卷积神经网络无法得到有意义的结果。卷积神经网络的这种限制对于IMDB 数据来说并不是问题，因为对于与正面情绪或负面情绪相关联的关键词模式，无论出现在输入句子中的什么位置，它所包含的信息量是一样的。</p>
<p>要想结合卷积神经网络的速度和轻量与RNN 的顺序敏感性，一种方法是在RNN前面使用一维卷积神经网络作为预处理步骤。对于那些非常长，以至于RNN 无法处理的序列（比如包含上千个时间步的序列），这种方法尤其有用。卷积神经网络可以将长的输入序列转换为高级特征组成的更短序列（下采样）。然后，提取的特征组成的这些序列成为网络中RNN的输入。</p>
<center>
    <img src="\Pic\DeepLearning_Pic\long_term.png" width="200" height="200" alt="结合一维CNN和RNN来处理长序列" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">结合一维CNN和RNN来处理长序列</div>
</center>

<p>这种方法在研究论文和实际应用中并不多见，可能是因为很多人并不知道。这种方法非常有效，应该被更多人使用。我们尝试将其应用于温度预测数据集。因为这种方法允许操作更长的序列，所以我们可以查看更早的数据（通过增大数据生成器的<code>lookback</code>参数）或查看分辨率更高的时间序列（通过减小生成器的<code>step</code>参数）。这里我们任意地将<code>step</code>减半，得到时间序列的长度变为之前的两倍，温度数据的采样频率变为每30分钟一个数据点。本示例复用了之前定义的<code>generator</code>函数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 为耶拿数据集准备更高分辨率的数据生成器</span></span><br><span class="line">step = <span class="number">3</span></span><br><span class="line">lookback = <span class="number">720</span></span><br><span class="line">delay = <span class="number">144</span></span><br><span class="line">train_gen = generator(float_data,</span><br><span class="line">                    lookback=lookback,</span><br><span class="line">                    delay=delay,</span><br><span class="line">                    min_index=<span class="number">0</span>,</span><br><span class="line">                    max_index=<span class="number">200000</span>,</span><br><span class="line">                    shuffle=<span class="literal">True</span>,</span><br><span class="line">                    step=step)</span><br><span class="line">val_gen = generator(float_data,</span><br><span class="line">                    lookback=lookback,</span><br><span class="line">                    delay=delay,</span><br><span class="line">                    min_index=<span class="number">200001</span>,</span><br><span class="line">                    max_index=<span class="number">300000</span>,</span><br><span class="line">                    step=step)</span><br><span class="line">test_gen = generator(float_data,</span><br><span class="line">                    lookback=lookback,</span><br><span class="line">                    delay=delay,</span><br><span class="line">                    min_index=<span class="number">300001</span>,</span><br><span class="line">                    max_index=<span class="literal">None</span>,</span><br><span class="line">                    step=step)</span><br><span class="line">val_steps = (<span class="number">300000</span> - <span class="number">200001</span> - lookback) // <span class="number">128</span></span><br><span class="line">test_steps = (len(float_data) - <span class="number">300001</span> - lookback) // <span class="number">128</span></span><br></pre></td></tr></table></figure>
<p>下面是模型，开始是两个<code>Conv1D</code>层，然后是一个<code>GRU</code>层。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 结合一维卷积基和GRU层的模型</span></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> RMSprop</span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(layers.Conv1D(<span class="number">32</span>, <span class="number">5</span>, activation=<span class="string">'relu'</span>,input_shape=(<span class="literal">None</span>, float_data.shape[<span class="number">-1</span>])))</span><br><span class="line">model.add(layers.MaxPooling1D(<span class="number">3</span>))</span><br><span class="line">model.add(layers.Conv1D(<span class="number">32</span>, <span class="number">5</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.GRU(<span class="number">32</span>, dropout=<span class="number">0.1</span>, recurrent_dropout=<span class="number">0.5</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>))</span><br><span class="line">model.summary()</span><br><span class="line">model.compile(optimizer=RMSprop(), loss=<span class="string">'mae'</span>)</span><br><span class="line">history = model.fit_generator(train_gen,</span><br><span class="line">                            steps_per_epoch=<span class="number">500</span>,</span><br><span class="line">                            epochs=<span class="number">20</span>,</span><br><span class="line">                            validation_data=val_gen,</span><br><span class="line">                            validation_steps=val_steps)</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\train_4.png" width="300" height="300" alt="一维卷积神经网络+GRU在耶拿温度预测任务上的训练损失和验证损失" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">一维卷积神经网络+GRU在耶拿温度预测任务上的训练损失和验证损失</div>
</center>

<p>从验证损失来看，这种架构的效果不如只用正则化GRU，但速度要快很多。它查看了两倍的数据量，在本例中可能不是非常有用，但对于其他数据集可能非常重要。</p>
<h2 id="5-小结"><a href="#5-小结" class="headerlink" title="5. 小结"></a>5. 小结</h2><p>下面是你应该从本节中学到的要点。</p>
<ul>
<li>二维卷积神经网络在二维空间中处理视觉模式时表现很好，与此相同，一维卷积神经网络在处理时间模式时表现也很好。对于某些问题，特别是自然语言处理任务，它可以替代RNN，并且速度更快。</li>
<li>通常情况下，一维卷积神经网络的架构与计算机视觉领域的二维卷积神经网络很相似，它将Conv1D层和MaxPooling1D层堆叠在一起，最后是一个全局池化运算或展平操作。</li>
<li>因为RNN在处理非常长的序列时计算代价很大，但一维卷积神经网络的计算代价很小，所以在RNN之前使用一维卷积神经网络作为预处理步骤是一个好主意，这样可以使序列变短，并提取出有用的表示交给RNN来处理。</li>
</ul>
<h1 id="五、本文总结"><a href="#五、本文总结" class="headerlink" title="五、本文总结"></a>五、本文总结</h1><ul>
<li>你在本文学到了以下技术，它们广泛应用于序列数据（从文本到时间序列）组成的数据集。<ul>
<li>如何对文本分词</li>
<li>什么是词嵌入，如何使用词嵌入。</li>
<li>什么是循环网络，如何使用循环网络。</li>
<li>如何堆叠 RNN层和使用双向RNN，以构建更加强大的序列处理模型。</li>
<li>如何使用一维卷积神经网络来处理序列。</li>
<li>如何结合一维卷积神经网络和 RNN来处理长序列。</li>
</ul>
</li>
<li>你可以用 RNN 进行时间序列回归（“预测未来”）、时间序列分类、时间序列异常检测和序列标记（比如找出句子中的人名或日期）。</li>
<li>同样，你可以将一维卷积神经网络用于机器翻译（序列到序列的卷积模型，比如SliceNet）、文档分类和拼写校正。</li>
<li>如果序列数据的整体顺序很重要，那么最好使用循环网络来处理。时间序列通常都是这样，最近的数据可能比久远的数据包含更多的信息量。</li>
<li>如果整体顺序没有意义，那么一维卷积神经网络可以实现同样好的效果，而且计算代价更小。文本数据通常都是这样，在句首发现关键词和在句尾发现关键词一样都很有意义。</li>
</ul>
]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
  </entry>
  <entry>
    <title>算法复现（二）——堆排序算法</title>
    <url>/posts/fda12dda.html</url>
    <content><![CDATA[<h1 id="二叉堆"><a href="#二叉堆" class="headerlink" title="二叉堆"></a>二叉堆</h1><p>二叉堆本质上是一种<strong>完全二叉树</strong>，它分为两个类型：最大堆和最小堆。</p>
<ol>
<li>最大堆：最大堆任何一个父节点的值，都大于等于它左右孩子节点的值</li>
<li>最小堆：最小堆任何一个父节点的值，都小于等于它左右孩子节点的值。</li>
</ol>
<p>二叉堆的根节点叫做<strong>堆顶</strong>，最大堆的堆顶是最大元素，最小堆的堆顶是最小元素。</p>
<h1 id="堆的自我调整"><a href="#堆的自我调整" class="headerlink" title="堆的自我调整"></a>堆的自我调整</h1><h2 id="插入节点"><a href="#插入节点" class="headerlink" title="插入节点"></a>插入节点</h2><p>我们首先有一个最大堆，我们希望给这个堆插入一个元素，我们首先直接将这个新元素放置到堆的最下部，此时发现最下面的子堆不满足最大堆的定义，依次<strong>向上调整</strong>：首先交换80和45，然后交换80和72，最终满足条件，此时插入节点完毕。</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy82NjI5MDgwLWJiZjQ4M2U4YTcyYzZjNzkucG5n?x-oss-process=image/format,png#pic_center" alt="在这里插入图片描述"></p>
<h2 id="删除节点"><a href="#删除节点" class="headerlink" title="删除节点"></a>删除节点</h2><p>首先我们要删除最小堆（如下图）的最顶端元素 0，我们首先将 0 与 3 进行交换，将最下面的元素交换到最上面。<br><img src="https://img-blog.csdn.net/20160521003432801?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center#pic_center" alt="在这里插入图片描述"><br>交换结果如下图，此时发现最上面的子堆不满足最小堆的定义：</p>
<p><img src="https://img-blog.csdn.net/20160521003454410?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center#pic_center" alt="在这里插入图片描述"><br>交换元素 1 和 3：</p>
<p><img src="https://img-blog.csdn.net/20160521003517583?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center#pic_center" alt="在这里插入图片描述"><br>一直向下调整，直到满足所有子堆最小堆的要求，得到最终结果：</p>
<p><img src="https://img-blog.csdn.net/20160521003536802?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center#pic_center" alt></p>
<h2 id="构建二叉堆"><a href="#构建二叉堆" class="headerlink" title="构建二叉堆"></a>构建二叉堆</h2><p>构建二叉堆也就是将一个无序的二叉树调整为二叉堆，本质上就是让所偶非叶子节点依次下沉，有两种方式——自下而上和自上而下。</p>
<p>自下而上就是首先看有叶子节点的最后一个堆，将其调整为一个最小堆（或最大堆），实际上就是和删除节点或插入节点时有类似的步骤，大家可以自己推一推。</p>
<h1 id="堆的实现"><a href="#堆的实现" class="headerlink" title="堆的实现"></a>堆的实现</h1><p>二叉堆虽然是一棵完全二叉树，但它的存储方式并不是链式存储，二十顺序存储，也就是说二叉堆的所有节点都存储在数组当中。</p>
<p>我们经过观察很容易发现，所有子堆的子节点和父节点满足 {2n+1&amp;2n+2 : n} 的关系，因此我们可以很容易得到一个节点的子节点或者父节点。因此数组和二叉树可以完全一一对应。</p>
<h1 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h1><p><strong>思想</strong>：我们删除一个最大堆的堆顶（替换到最后面），经过自我调整，第二大的元素就会被交换上来，成为最大堆的新堆顶。<br><strong>步骤</strong>：</p>
<ol>
<li>把无序数组构建成二叉堆（时间复杂度为 $O(n)$）</li>
<li>循环删除对顶元素，移到集合尾部，调节堆产生新的堆顶（时间复杂度为 $O(nlogn)$）</li>
</ol>
<h1 id="堆排序的应用"><a href="#堆排序的应用" class="headerlink" title="堆排序的应用"></a>堆排序的应用</h1><p>我们还是看到 Leetcode 的 215 题：<br><img src="https://img-blog.csdnimg.cn/2020051122003223.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="Leetcode"><br>我们直接看代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findKthLargest</span><span class="params">(self, nums, k)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :type k: int</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self._k = len(nums) - k</span><br><span class="line">        <span class="keyword">return</span> self.heapsort(nums)</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">heapsort</span><span class="params">(self, nums)</span>:</span></span><br><span class="line">        <span class="comment"># 第一步：建堆</span></span><br><span class="line">        self.build_heap(nums)</span><br><span class="line">        <span class="comment"># 第二部：循环交换位置 最上面的节点与最下面的节点交换位置，最上面的节点向下调整</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nums)<span class="number">-1</span>, self._k<span class="number">-1</span>,<span class="number">-1</span>):</span><br><span class="line">            nums[i], nums[<span class="number">0</span>] = nums[<span class="number">0</span>], nums[i]</span><br><span class="line">            self.max_heapify(nums, <span class="number">0</span>, i)</span><br><span class="line">        <span class="keyword">return</span> nums[self._k]</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_heap</span><span class="params">(self, nums)</span>:</span></span><br><span class="line">        length = len(nums)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range((length<span class="number">-1</span>) // <span class="number">2</span>, <span class="number">-1</span>, <span class="number">-1</span>):</span><br><span class="line">            self.max_heapify(nums, i, length)</span><br><span class="line">            </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">max_heapify</span><span class="params">(self, nums, i, length)</span>:</span></span><br><span class="line">        <span class="comment"># 找到左右孩子节点</span></span><br><span class="line">        left = i * <span class="number">2</span> + <span class="number">1</span></span><br><span class="line">        right = i * <span class="number">2</span> + <span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> left &lt; length <span class="keyword">and</span> nums[left] &gt; nums[i]:</span><br><span class="line">            largest = left</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            largest = i</span><br><span class="line">        <span class="keyword">if</span> right &lt; length <span class="keyword">and</span> nums[right] &gt; nums[largest]:</span><br><span class="line">            largest = right</span><br><span class="line">            <span class="comment"># 若最大元素不是父节点则需要交换</span></span><br><span class="line">        <span class="keyword">if</span> largest != i:</span><br><span class="line">            nums[i], nums[largest] = nums[largest], nums[i]</span><br><span class="line">            self.max_heapify(nums, largest, length)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
  </entry>
  <entry>
    <title>Python深度学习（二）深度学习用于计算机视觉</title>
    <url>/posts/1fc7d624.html</url>
    <content><![CDATA[<p>本节将介绍卷积神经网络，也叫<code>convnet</code>，它是计算机视觉应用几乎都在使用的一种深度学习模型。你将学到将卷积神经网络应用于图像分类问题，特别是那些训练数据集较小的问题。如果你工作的地方并非大型科技公司，这也将是你最常见的使用场景。</p>
<h1 id="一、卷积神经网络简介"><a href="#一、卷积神经网络简介" class="headerlink" title="一、卷积神经网络简介"></a>一、卷积神经网络简介</h1><p>我们将深入讲解卷积神经网络的原理，以及它在计算机视觉任务上为什么如此成功。但在此之前，我们先来看一个简单的卷积神经网络示例，即使用卷积神经网络对MNIST 数字进行分类，这个任务我们在第2 章用密集连接网络做过（当时的测试精度为97.8%）。虽然本例中的卷积神经网络很简单，但其精度肯定会超过前面的密集连接网络。</p>
<p>下列代码将会展示一个简单的卷积神经网络。它是Conv2D 层和MaxPooling2D 层的堆叠，很快你就会知道这些层的作用。</p>
<h2 id="1-实例化一个小型的卷积神经网络"><a href="#1-实例化一个小型的卷积神经网络" class="headerlink" title="1. 实例化一个小型的卷积神经网络"></a>1. 实例化一个小型的卷积神经网络</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>, input_shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br></pre></td></tr></table></figure>
<pre><code>Using TensorFlow backend.
</code></pre><p>重要的是，卷积神经网络接收形状为<code>(image_height, image_width, image_channels)</code>的输入张量（不包括批量维度）。本例中设置卷积神经网络处理大小为(28, 28, 1) 的输入张量，这正是MNIST 图像的格式。我们向第一层传入参数<code>input_shape=(28, 28, 1)</code> 来完成此设置。</p>
<p>我们来看一下目前卷积神经网络的架构。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_1&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     
=================================================================
Total params: 55,744
Trainable params: 55,744
Non-trainable params: 0
_________________________________________________________________
</code></pre><p>可以看到，每个Conv2D 层和MaxPooling2D 层的输出都是一个形状为(height, width,channels) 的3D 张量。宽度和高度两个维度的尺寸通常会随着网络加深而变小，通道数量由传<br>入Conv2D 层的第一个参数所控制（32 或64）。</p>
<p>下一步是将最后的输出张量［大小为(3, 3, 64)］输入到一个密集连接分类器网络中，即Dense 层的堆叠，你已经很熟悉了。这些分类器可以处理1D 向量，而当前的输出是3D 张量。首先，我们需要将3D 输出展平为1D，然后在上面添加几个Dense 层。</p>
<h2 id="2-在卷积神经网络上添加分类器"><a href="#2-在卷积神经网络上添加分类器" class="headerlink" title="2. 在卷积神经网络上添加分类器"></a>2. 在卷积神经网络上添加分类器</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>))</span><br></pre></td></tr></table></figure>
<p>我们将进行10 类别分类，最后一层使用带10 个输出的softmax 激活。现在网络的架构如下。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_1&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     
_________________________________________________________________
flatten_1 (Flatten)          (None, 576)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 64)                36928     
_________________________________________________________________
dense_2 (Dense)              (None, 10)                650       
=================================================================
Total params: 93,322
Trainable params: 93,322
Non-trainable params: 0
_________________________________________________________________
</code></pre><p>如你所见，在进入两个Dense层之前，形状(3, 3, 64) 的输出被展平为形状(576,) 的向量。</p>
<p>下面我们在MNIST数字图像上训练这个卷积神经网络。我们将复用MNIST示例中的很多代码。</p>
<h2 id="3-在MINST图像上训练卷积神经网络"><a href="#3-在MINST图像上训练卷积神经网络" class="headerlink" title="3. 在MINST图像上训练卷积神经网络"></a>3. 在MINST图像上训练卷积神经网络</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> to_categorical</span><br><span class="line">(train_images, train_labels), (test_images, test_labels) = mnist.load_data()</span><br><span class="line">train_images = train_images.reshape((<span class="number">60000</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))</span><br><span class="line">train_images = train_images.astype(<span class="string">'float32'</span>) / <span class="number">255</span></span><br><span class="line">test_images = test_images.reshape((<span class="number">10000</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))</span><br><span class="line">test_images = test_images.astype(<span class="string">'float32'</span>) / <span class="number">255</span></span><br><span class="line">train_labels = to_categorical(train_labels)</span><br><span class="line">test_labels = to_categorical(test_labels)</span><br><span class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>,</span><br><span class="line">            loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">            metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">model.fit(train_images, train_labels, epochs=<span class="number">5</span>, batch_size=<span class="number">64</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1/5
60000/60000 [==============================] - 25s 419us/step - loss: 0.1652 - accuracy: 0.9488
Epoch 2/5
60000/60000 [==============================] - 26s 429us/step - loss: 0.0458 - accuracy: 0.9864
Epoch 3/5
60000/60000 [==============================] - 24s 400us/step - loss: 0.0320 - accuracy: 0.9897
Epoch 4/5
60000/60000 [==============================] - 24s 396us/step - loss: 0.0247 - accuracy: 0.9924
Epoch 5/5
60000/60000 [==============================] - 24s 393us/step - loss: 0.0196 - accuracy: 0.9940
</code></pre><p>我们在测试数据上对模型进行评估。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">test_loss, test_acc = model.evaluate(test_images, test_labels)</span><br><span class="line">test_acc</span><br></pre></td></tr></table></figure>
<pre><code>10000/10000 [==============================] - 1s 112us/step


0.9923999905586243
</code></pre><p>密集连接网络的测试精度为97.8%，但这个简单卷积神经网络的测试精度达到了99.1%，我们将错误率降低了68%（相对比例）。相当不错！与密集连接模型相比，为什么这个简单卷积神经网络的效果这么好？要回答这个问题，我们来深入了解Conv2D 层和MaxPooling2D 层的作用。</p>
<h2 id="4-卷积神经网络"><a href="#4-卷积神经网络" class="headerlink" title="4. 卷积神经网络"></a>4. 卷积神经网络</h2><p>密集连接层和卷积层的根本区别在于，Dense 层从输入特征空间中学到的是全局模式（比如对于MNIST 数字，全局模式就是涉及所有像素的模式），而卷积层学到的是局部模式。对于图像来说，学到的就是在输入图像的二维小窗口中发现的模式。在上面的例子中，这些窗口的大小都是3×3。</p>
<center>
    <img src="\Pic\DeepLearning_Pic\conv_1.png" width="300" height="300" alt="图像可以被分解为局部模式，如边缘、纹理等" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图像可以被分解为局部模式，如边缘、纹理等</div>
</center>

<p>这个重要特性使卷积神经网络具有以下两个有趣的性质。</p>
<ul>
<li>卷积神经网络学到的模式具有平移不变性（translation invariant）。卷积神经网络在图像右下角学到某个模式之后，它可以在任何地方识别这个模式，比如左上角。对于密集连接网络来说，如果模式出现在新的位置，它只能重新学习这个模式。这使得卷积神经网络在处理图像时可以高效利用数据（因为视觉世界从根本上具有平移不变性），它只需要更少的训练样本就可以学到具有泛化能力的数据表示。</li>
<li>卷积神经网络可以学到模式的空间层次结构（spatial hierarchies of patterns）。第一个卷积层将学习较小的局部模式（比如边缘），第二个卷积层将学习由第一层特征组成的更大的模式，以此类推。这使得卷积神经网络可以有效地学习越来越复杂、越来越抽象的视觉概念（因为视觉世界从根本上具有空间层次结构）。</li>
</ul>
<p>对于包含两个空间轴（高度和宽度）和一个深度轴（也叫通道轴）的3D 张量，其卷积也叫特征图（feature map）。对于RGB 图像，深度轴的维度大小等于3，因为图像有3 个颜色通道：红色、绿色和蓝色。对于黑白图像（比如MNIST 数字图像），深度等于1（表示灰度等级）。卷积运算从输入特征图中提取图块，并对所有这些图块应用相同的变换，生成输出特征图（output feature map）。该输出特征图仍是一个3D 张量，具有宽度和高度，其深度可以任意取值，因为输出深度是层的参数，深度轴的不同通道不再像RGB 输入那样代表特定颜色，而是代表过滤器（filter）。过滤器对输入数据的某一方面进行编码，比如，单个过滤器可以从更高层次编码这样一个概念：“输入中包含一张脸。”</p>
<center>
    <img src="\Pic\DeepLearning_Pic\cat.png" width="300" height="300" alt="cat" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">视觉世界形成了视觉模块的空间层次结构：超局部的边缘组合成局部的对象，比如眼睛或耳朵，这些局部对象又组合成高级概念，比如“猫”</div>
</center>

<p>在MNIST示例中，第一个卷积层接收一个大小为<code>(28, 28, 1)</code>的特征图，并输出一个大小为<code>(26, 26, 32)</code>的特征图，即它在输入上计算32个过滤器。对于这32个输出通道，每个通道都包含一个26×26的数值网格，它是过滤器对输入的响应图（response map），表示这个过滤器模式在输入中不同位置的响应。这也是特征图这一术语的含义：深度轴的每个维度都是一个特征（或过滤器），而2D 张量<code>output[:, :, n]</code>是这个过滤器在输入上的响应的二维空间图（map）。</p>
<center>
    <img src="\Pic\DeepLearning_Pic\响应图.png" width="300" height="300" alt="响应图" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">响应图的概念：某个模式在输入中的不同位置是否存在的二维图</div>
</center>

<p>卷积由以下两个关键参数所定义：</p>
<ul>
<li>从输入中提取的图块尺寸：这些图块的大小通常是 3×3 或 5×5。本例中为 3×3，这是很常见的选择。</li>
<li>输出特征图的深度：卷积所计算的过滤器的数量。本例第一层的深度为32，最后一层的深度是64。</li>
</ul>
<p>对于Keras 的Conv2D 层，这些参数都是向层传入的前几个参数：<code>Conv2D(output_depth,(window_height, window_width))</code>。</p>
<p>卷积的工作原理：在3D 输入特征图上滑动（slide）这些3×3 或5×5 的窗口，在每个可能的位置停止并提取周围特征的3D图块［形状为<code>(window_height, window_width, input_depth)</code>］。然后每个3D 图块与学到的同一个权重矩阵［叫作卷积核（convolution kernel）］做张量积，转换成形状为<code>(output_depth,)</code> 的1D 向量。然后对所有这些向量进行空间重组，使其转换为形状为<code>(height, width, output_depth)</code>的3D 输出特征图。输出特征图中的每个空间位置都对应于输入特征图中的相同位置（比如输出的右下角包含了输入右下角的信息）。举个例子，利用3×3的窗口，向量<code>output[i, j, :]</code>来自3D 图块<code>input[i-1:i+1,j-1:j+1, :]</code>。整个过程详见下图：</p>
<center>
    <img src="\Pic\DeepLearning_Pic\卷积的工作原理.png" width="300" height="300" alt="卷积的工作原理" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">卷积的工作原理</div>
</center>

<p>注意，输出的宽度和高度可能与输入的宽度和高度不同，不同的原因可能有两点。</p>
<ul>
<li>边界效应，可以通过对输入特征图进行填充来抵消。</li>
<li>使用了步幅（stride），稍后会给出其定义。</li>
</ul>
<h2 id="5-最大池化运算"><a href="#5-最大池化运算" class="headerlink" title="5. 最大池化运算"></a>5. 最大池化运算</h2><p>在卷积神经网络示例中，你可能注意到，在每个MaxPooling2D层之后，特征图的尺寸都会减半。例如，在第一个MaxPooling2D层之前，特征图的尺寸是26×26，但最大池化运算将其减半为13×13。这就是最大池化的作用：<strong>对特征图进行下采样，与步进卷积类似。最大池化是从输入特征图中提取窗口，并输出每个通道的最大值。</strong>它的概念与卷积类似，但是最大池化使用硬编码的<code>max</code>张量运算对局部图块进行变换，而不是使用学到的线性变换（卷积核）。最大池化与卷积的最大不同之处在于，最大池化通常使用2×2的窗口和步幅2，其目的是将特征图下采样2倍。与此相对的是，卷积通常使用3×3 窗口和步幅1。为什么要用这种方式对特征图下采样？为什么不删除最大池化层，一直保留较大的特征图？我们来这么做试一下。这时模型的卷积基（convolutional base）如下所示。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model_no_max_pool = models.Sequential()</span><br><span class="line">model_no_max_pool.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>, input_shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)))</span><br><span class="line">model_no_max_pool.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model_no_max_pool.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model_no_max_pool.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_2&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 24, 24, 64)        18496     
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 22, 22, 64)        36928     
=================================================================
Total params: 55,744
Trainable params: 55,744
Non-trainable params: 0
_________________________________________________________________
</code></pre><p>这种架构有什么问题？有如下两点问题：</p>
<ul>
<li>这种架构不利于学习特征的空间层级结构。第三层的 3×3 窗口中只包含初始输入的 7×7 窗口中所包含的信息。卷积神经网络学到的高级模式相对于初始输入来说仍然很小，这可能不足以学会对数字进行分类（你可以试试仅通过7 像素×7 像素的窗口观察图像来识别其中的数字）。我们需要让最后一个卷积层的特征包含输入的整体信息。</li>
<li>最后一层的特征图对每个样本共有 22×22×64=30 976 个元素。这太多了。如果你将其展平并在上面添加一个大小为512 的Dense 层，那一层将会有1580 万个参数。这对于这样一个小模型来说太多了，会导致严重的过拟合。</li>
</ul>
<p>简而言之，使用下采样的原因，一是减少需要处理的特征图的元素个数，二是通过让连续卷积层的观察窗口越来越大（即窗口覆盖原始输入的比例越来越大），从而引入空间过滤器的层级结构。</p>
<p>注意，最大池化不是实现这种下采样的唯一方法。你已经知道，还可以在前一个卷积层中使用步幅来实现。此外，你还可以使用平均池化来代替最大池化，其方法是将每个局部输入图块变换为取该图块各通道的平均值，而不是最大值。但最大池化的效果往往比这些替代方法更好。</p>
<p>简而言之，原因在于特征中往往编码了某种模式或概念在特征图的不同位置是否存在（因此得名特征图），而观察不同特征的最大值而不是平均值能够给出更多的信息。因此，最合理的子采样策略是<strong>首先生成密集的特征图（通过无步进的卷积），然后观察特征每个小图块上的最大激活</strong>，而不是查看输入的稀疏窗口（通过步进卷积）或对输入图块取平均，因为后两种方法可能导致错过或淡化特征是否存在的信息。</p>
<p>现在你应该已经理解了卷积神经网络的基本概念，即特征图、卷积和最大池化，并且也知道如何构建一个小型卷积神经网络来解决简单问题，比如MNIST 数字分类。下面我们将介绍更加实用的应用。</p>
<h1 id="二、在小型数据集上从头开始训练一个卷积神经网络"><a href="#二、在小型数据集上从头开始训练一个卷积神经网络" class="headerlink" title="二、在小型数据集上从头开始训练一个卷积神经网络"></a>二、在小型数据集上从头开始训练一个卷积神经网络</h1><p>使用很少的数据来训练一个图像分类模型，这是很常见的情况，如果你要从事计算机视觉方面的职业，很可能会在实践中遇到这种情况。“很少的”样本可能是几百张图像，也可能是几万张图像。来看一个实例，我们将重点讨论猫狗图像分类，数据集中包含4000 张猫和狗的图像（2000 张猫的图像，2000 张狗的图像）。我们将2000 张图像用于训练，1000 张用于验证，1000张用于测试。</p>
<p>本节将介绍解决这一问题的基本策略，即使用已有的少量数据从头开始训练一个新模型。首先，在2000 个训练样本上训练一个简单的小型卷积神经网络，不做任何正则化，为模型目标设定一个基准。这会得到71% 的分类精度。此时主要的问题在于过拟合。然后，我们会介绍数据增强（data augmentation），它在计算机视觉领域是一种非常强大的降低过拟合的技术。使用数据增强之后，网络精度将提高到82%。随后我们会介绍将深度学习应用于小型数据集的另外两个重要技巧：用预训练的网络做特征提取（得到的精度范围在90%~96%），对预训练的网络进行微调（最终精度为97%）。总而言之，这三种策略——从头开始训练一个小型模型、使用预训练的网络做特征提取、对预训练的网络进行微调——构成了你的工具箱，未来可用于解决小型数据集的图像分类问题。</p>
<h2 id="1-深度学习与小数据问题的相关性"><a href="#1-深度学习与小数据问题的相关性" class="headerlink" title="1. 深度学习与小数据问题的相关性"></a>1. 深度学习与小数据问题的相关性</h2><p>有时你会听人说，仅在有大量数据可用时，深度学习才有效。这种说法部分正确：深度学习的一个基本特性就是能够独立地在训练数据中找到有趣的特征，无须人为的特征工程，而这只在拥有大量训练样本时才能实现。对于输入样本的维度非常高（比如图像）的问题尤其如此。</p>
<p>但对于初学者来说，所谓“大量”样本是相对的，即相对于你所要训练网络的大小和深度而言。只用几十个样本训练卷积神经网络就解决一个复杂问题是不可能的，但如果模型很小，并做了很好的正则化，同时任务非常简单，那么几百个样本可能就足够了。由于卷积神经网络学到的是局部的、平移不变的特征，它对于感知问题可以高效地利用数据。虽然数据相对较少，但在非常小的图像数据集上从头开始训练一个卷积神经网络，仍然可以得到不错的结果，而且无须任何自定义的特征工程。</p>
<p>此外，深度学习模型本质上具有高度的可复用性，比如，已有一个在大规模数据集上训练的图像分类模型或语音转文本模型，你只需做很小的修改就能将其复用于完全不同的问题。特别是在计算机视觉领域，许多预训练的模型（通常都是在ImageNet 数据集上训练得到的）现在都可以公开下载，并可以用于在数据很少的情况下构建强大的视觉模型。我们先来看一下数据。</p>
<h2 id="2-下载数据"><a href="#2-下载数据" class="headerlink" title="2. 下载数据"></a>2. 下载数据</h2><p>本节用到的猫狗分类数据集不包含在Keras 中。它由Kaggle 在2013 年末公开并作为一项计算视觉竞赛的一部分，当时卷积神经网络还不是主流算法。你可以从<a href="https://www.kaggle.com/c/dogs-vs-cats/data" target="_blank" rel="noopener">https://www.kaggle.com/c/dogs-vs-cats/data</a> 下载原始数据集。</p>
<p>这些图像都是中等分辨率的彩色JPEG 图像:</p>
<center>
    <img src="\Pic\DeepLearning_Pic\cat_dog_1.png" width="300" height="300" alt="猫狗分类数据集的一些样本。没有修改尺寸：样本在尺寸、外观等方面是不一样的" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">猫狗分类数据集的一些样本。没有修改尺寸：样本在尺寸、外观等方面是不一样的</div>
</center>

<p>不出所料，2013 年的猫狗分类Kaggle 竞赛的优胜者使用的是卷积神经网络。最佳结果达到了95% 的精度。本例中，虽然你只在不到参赛选手所用的10% 的数据上训练模型，但结果也和这个精度相当接近。</p>
<p>这个数据集包含25 000 张猫狗图像（每个类别都有12 500 张），大小为543MB（压缩后）。下载数据并解压之后，你需要创建一个新数据集，其中包含三个子集：每个类别各1000 个样本的训练集、每个类别各500 个样本的验证集和每个类别各500 个样本的测试集。创建新数据集的代码如下所示。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将图像复制到训练、验证和测试的目录</span></span><br><span class="line"><span class="keyword">import</span> os, shutil</span><br><span class="line">original_dataset_dir = <span class="string">'data/cat_dog/kaggle_original_data'</span></span><br><span class="line">base_dir = <span class="string">'data/cat_dog/cats_and_dogs_small'</span></span><br><span class="line">os.mkdir(base_dir)</span><br><span class="line">train_dir = os.path.join(base_dir, <span class="string">'train'</span>)</span><br><span class="line">os.mkdir(train_dir)</span><br><span class="line">validation_dir = os.path.join(base_dir, <span class="string">'validation'</span>)</span><br><span class="line">os.mkdir(validation_dir)</span><br><span class="line">test_dir = os.path.join(base_dir, <span class="string">'test'</span>)</span><br><span class="line">os.mkdir(test_dir)</span><br><span class="line">train_cats_dir = os.path.join(train_dir, <span class="string">'cats'</span>)</span><br><span class="line">os.mkdir(train_cats_dir)</span><br><span class="line">train_dogs_dir = os.path.join(train_dir, <span class="string">'dogs'</span>)</span><br><span class="line">os.mkdir(train_dogs_dir)</span><br><span class="line">validation_cats_dir = os.path.join(validation_dir, <span class="string">'cats'</span>)</span><br><span class="line">os.mkdir(validation_cats_dir)</span><br><span class="line">validation_dogs_dir = os.path.join(validation_dir, <span class="string">'dogs'</span>)</span><br><span class="line">os.mkdir(validation_dogs_dir)</span><br><span class="line">test_cats_dir = os.path.join(test_dir, <span class="string">'cats'</span>)</span><br><span class="line">os.mkdir(test_cats_dir)</span><br><span class="line">test_dogs_dir = os.path.join(test_dir, <span class="string">'dogs'</span>)</span><br><span class="line">os.mkdir(test_dogs_dir)</span><br><span class="line">fnames = [<span class="string">'cat.&#123;&#125;.jpg'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">dst = os.path.join(train_cats_dir, fname)</span><br><span class="line">shutil.copyfile(src, dst)</span><br><span class="line">fnames = [<span class="string">'cat.&#123;&#125;.jpg'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>, <span class="number">1500</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">dst = os.path.join(validation_cats_dir, fname)</span><br><span class="line">shutil.copyfile(src, dst)</span><br><span class="line">fnames = [<span class="string">'cat.&#123;&#125;.jpg'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1500</span>, <span class="number">2000</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">dst = os.path.join(test_cats_dir, fname)</span><br><span class="line">shutil.copyfile(src, dst)</span><br><span class="line">fnames = [<span class="string">'dog.&#123;&#125;.jpg'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">dst = os.path.join(train_dogs_dir, fname)</span><br><span class="line">shutil.copyfile(src, dst)</span><br><span class="line">fnames = [<span class="string">'dog.&#123;&#125;.jpg'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>, <span class="number">1500</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">dst = os.path.join(validation_dogs_dir, fname)</span><br><span class="line">shutil.copyfile(src, dst)</span><br><span class="line">fnames = [<span class="string">'dog.&#123;&#125;.jpg'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1500</span>, <span class="number">2000</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">dst = os.path.join(test_dogs_dir, fname)</span><br><span class="line">shutil.copyfile(src, dst)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os, shutil</span><br><span class="line">base_dir = <span class="string">'data/cat_dog/cats_and_dogs_small'</span></span><br><span class="line">train_dir = os.path.join(base_dir, <span class="string">'train'</span>)</span><br><span class="line">test_dir = os.path.join(base_dir, <span class="string">'test'</span>)</span><br><span class="line">validation_dir = os.path.join(base_dir, <span class="string">'validation'</span>)</span><br><span class="line">train_cats_dir = os.path.join(train_dir, <span class="string">'cats'</span>)</span><br><span class="line">test_cats_dir = os.path.join(test_dir, <span class="string">'cats'</span>)</span><br><span class="line">validation_cats_dir = os.path.join(validation_dir, <span class="string">'cats'</span>)</span><br><span class="line">train_dogs_dir = os.path.join(train_dir, <span class="string">'dogs'</span>)</span><br><span class="line">test_dogs_dir = os.path.join(test_dir, <span class="string">'dogs'</span>)</span><br><span class="line">validation_dogs_dir = os.path.join(validation_dir, <span class="string">'dogs'</span>)</span><br><span class="line">print(<span class="string">'total training cat images:'</span>, len(os.listdir(train_cats_dir)))</span><br><span class="line">print(<span class="string">'total training dog images:'</span>, len(os.listdir(train_dogs_dir)))</span><br><span class="line">print(<span class="string">'total validation cat images:'</span>, len(os.listdir(validation_cats_dir)))</span><br><span class="line">print(<span class="string">'total validation dog images:'</span>, len(os.listdir(validation_dogs_dir)))</span><br><span class="line">print(<span class="string">'total test cat images:'</span>, len(os.listdir(test_cats_dir)))</span><br><span class="line">print(<span class="string">'total test dog images:'</span>, len(os.listdir(test_dogs_dir)))</span><br></pre></td></tr></table></figure>
<pre><code>total training cat images: 1000
total training dog images: 1000
total validation cat images: 500
total validation dog images: 500
total test cat images: 500
total test dog images: 500
</code></pre><p>所以我们的确有2000 张训练图像、1000 张验证图像和1000 张测试图像。每个分组中两个类别的样本数相同，这是一个平衡的二分类问题，分类精度可作为衡量成功的指标。</p>
<h2 id="3-构建网络"><a href="#3-构建网络" class="headerlink" title="3. 构建网络"></a>3. 构建网络</h2><p>在前一个MNIST示例中，我们构建了一个小型卷积神经网络，所以你应该已经熟悉这种网络。我们将复用相同的总体结构，即卷积神经网络由<code>Conv2D</code>层（使用<code>relu</code>激活）和<code>MaxPooling2D</code>层交替堆叠构成。</p>
<p>但由于这里要处理的是更大的图像和更复杂的问题，你需要相应地增大网络，即再增加一个<code>Conv2D+MaxPooling2D</code>的组合。这既可以增大网络容量，也可以进一步减小特征图的尺寸，使其在连接<code>Flatten</code>层时尺寸不会太大。本例中初始输入的尺寸为150×150（有些随意的选择），所以最后在<code>Flatten</code>层之前的特征图大小为7×7。</p>
<p>你面对的是一个二分类问题，所以网络最后一层是使用<code>sigmoid</code>激活的单一单元（大小为 1 的<code>Dense</code>层）。这个单元将对某个类别的概率进行编码。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将猫狗分类的小型卷积神经网络实例化</span></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">"relu"</span>, input_shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>)))</span><br><span class="line">model.add(layers.MaxPooling2D(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">"relu"</span>))</span><br><span class="line">model.add(layers.MaxPooling2D(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dense(<span class="number">512</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_4&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_8 (Conv2D)            (None, 148, 148, 32)      896       
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 74, 74, 32)        0         
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 72, 72, 64)        18496     
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 36, 36, 64)        0         
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 34, 34, 128)       73856     
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 17, 17, 128)       0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 36992)             0         
_________________________________________________________________
dense_3 (Dense)              (None, 512)               18940416  
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 513       
=================================================================
Total params: 19,034,177
Trainable params: 19,034,177
Non-trainable params: 0
_________________________________________________________________
</code></pre><p>在编译这一步，和前面一样，我们将使用RMSprop 优化器。因为网络最后一层是单一sigmoid单元，所以我们将使用二元交叉熵作为损失函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 配置模型用于训练</span></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimizers</span><br><span class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>,optimizer=optimizers.RMSprop(lr=<span class="number">1e-4</span>),metrics=[<span class="string">'acc'</span>])</span><br></pre></td></tr></table></figure>
<h2 id="4-数据预处理"><a href="#4-数据预处理" class="headerlink" title="4. 数据预处理"></a>4. 数据预处理</h2><p>你现在已经知道，将数据输入神经网络之前，应该将数据格式化为经过预处理的浮点数张量。现在，数据以 JPEG 文件的形式保存在硬盘中，所以数据预处理步骤大致如下：</p>
<ol>
<li>读取图像文件</li>
<li>将JPEG文件解码为RGB像素网格</li>
<li>将这些像素网格转换为浮点数张量</li>
<li>将像素值（0~255 范围内）缩放到 <code>[0, 1]</code> 区间（正如你所知，神经网络喜欢处理较小的输<br>入值）</li>
</ol>
<p>这些步骤可能看起来有点吓人，但幸运的是，Keras 拥有自动完成这些步骤的工具。Keras有一个图像处理辅助工具的模块，位于<code>keras.preprocessing.image</code>。特别地，它包含<code>ImageDataGenerator</code>类，可以快速创建Python生成器，能够将硬盘上的图像文件自动转换为预处理好的张量批量。下面我们将用到这个类。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用ImageDataGenerator 从目录中读取图像</span></span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line">train_datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line">test_datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line">train_generator = train_datagen.flow_from_directory(</span><br><span class="line">        train_dir,</span><br><span class="line">        target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">        batch_size=<span class="number">20</span>,</span><br><span class="line">        class_mode=<span class="string">'binary'</span>)</span><br><span class="line">validation_generator = test_datagen.flow_from_directory(</span><br><span class="line">        validation_dir,</span><br><span class="line">        target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">        batch_size=<span class="number">20</span>,</span><br><span class="line">        class_mode=<span class="string">'binary'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Found 2000 images belonging to 2 classes.
Found 1000 images belonging to 2 classes.
</code></pre><p>我们来看一下其中一个生成器的输出：它生成了150×150 的RGB 图像［形状为(20,150, 150, 3)］与二进制标签［形状为(20,)］组成的批量。每个批量中包含20 个样本（批量大小）。注意，生成器会不停地生成这些批量，它会不断循环目标文件夹中的图像。因此，你需要在某个时刻终止（break）迭代循环。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> data_batch, labels_batch <span class="keyword">in</span> train_generator:</span><br><span class="line">    print(<span class="string">'data batch shape:'</span>, data_batch.shape)</span><br><span class="line">    print(<span class="string">'labels batch shape:'</span>, labels_batch.shape)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<pre><code>data batch shape: (20, 150, 150, 3)
labels batch shape: (20,)
</code></pre><p>利用生成器，我们让模型对数据进行拟合。我们将使用<code>fit_generator</code>方法来拟合，它在数据生成器上的效果和fit 相同。它的第一个参数应该是一个Python生成器，可以不停地生成输入和目标组成的批量，比如<code>train_generator</code>。因为数据是不断生成的，所以Keras模型要知道每一轮需要从生成器中抽取多少个样本。这是<code>steps_per_epoch</code>参数的作用：从生成器中抽取<code>steps_per_epoch</code>个批量后（即运行了<code>steps_per_epoch</code>次梯度下降），拟合过程将进入下一个轮次。本例中，每个批量包含20个样本，所以读取完所有2000 个样本需要100个批量。</p>
<p>使用<code>fit_generator</code>时，你可以传入一个<code>validation_data</code>参数，其作用和在<code>fit</code>方法中类似。值得注意的是，这个参数可以是一个数据生成器，但也可以是Numpy数组组成的元组。如果向<code>validation_data</code>传入一个生成器，那么这个生成器应该能够不停地生成验证数据批量，因此你还需要指定<code>validation_steps</code>参数，说明需要从验证生成器中抽取多少个批次用于评估。</p>
<h2 id="5-拟合模型"><a href="#5-拟合模型" class="headerlink" title="5. 拟合模型"></a>5. 拟合模型</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">history = model.fit_generator(</span><br><span class="line">    train_generator,</span><br><span class="line">    steps_per_epoch=<span class="number">100</span>,</span><br><span class="line">    epochs=<span class="number">30</span>,</span><br><span class="line">    validation_data=validation_generator,</span><br><span class="line">    validation_steps=<span class="number">50</span>)</span><br></pre></td></tr></table></figure>
<p>始终在训练完成后保存模型，这是一种良好实践。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 保存模型</span></span><br><span class="line">model.save(<span class="string">'model/ComputerVersion/cats_and_dogs_small_1.h5'</span>)</span><br></pre></td></tr></table></figure>
<p>我们来分别绘制训练过程中模型在训练数据和验证数据上的损失和精度</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">acc = history.history[<span class="string">'acc'</span>]</span><br><span class="line">val_acc = history.history[<span class="string">'val_acc'</span>]</span><br><span class="line">loss = history.history[<span class="string">'loss'</span>]</span><br><span class="line">val_loss = history.history[<span class="string">'val_loss'</span>]</span><br><span class="line">epochs = range(<span class="number">1</span>, len(acc) + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, acc, <span class="string">'bo'</span>, label=<span class="string">'Training acc'</span>)</span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">'b'</span>, label=<span class="string">'Validation acc'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation accuracy'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.figure()</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, loss, <span class="string">'bo'</span>, label=<span class="string">'Training loss'</span>)</span><br><span class="line">plt.plot(epochs, val_loss, <span class="string">'b'</span>, label=<span class="string">'Validation loss'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_29_0.png" width="400" height="400" alt="训练损失和验证损失" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">训练损失和验证损失</div>
</center>


<center>
    <img src="\Pic\DeepLearning_Pic\output_29_1.png" width="400" height="400" alt="训练精度和验证精度" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">训练精度和验证精度</div>
</center>



<p>从这些图像中都能看出过拟合的特征。训练精度随着时间线性增加，直到接近100%，而验证精度则停留在70%~72%。验证损失仅在5 轮后就达到最小值，然后保持不变，而训练损失则一直线性下降，直到接近于0。</p>
<p>因为训练样本相对较少（2000 个），所以过拟合是你最关心的问题。前面已经介绍过几种降低过拟合的技巧，比如dropout 和权重衰减（L2 正则化）。现在我们将使用一种针对于计算机视觉领域的新方法，在用深度学习模型处理图像时几乎都会用到这种方法，它就是数据增强（data augmentation）。</p>
<h2 id="6-使用数据增强"><a href="#6-使用数据增强" class="headerlink" title="6. 使用数据增强"></a>6. 使用数据增强</h2><p>过拟合的原因是学习样本太少，导致无法训练出能够泛化到新数据的模型。如果拥有无限的数据，那么模型能够观察到数据分布的所有内容，这样就永远不会过拟合。数据增强是从现有的训练样本中生成更多的训练数据，其方法是利用多种能够生成可信图像的随机变换来增加（augment）样本。其目标是，模型在训练时不会两次查看完全相同的图像。这让模型能够观察到数据的更多内容，从而具有更好的泛化能力。</p>
<p>在Keras 中，这可以通过对<code>ImageDataGenerator</code>实例读取的图像执行多次随机变换来实现。我们先来看一个例子。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 利用ImageDataGenerator 来设置数据增强</span></span><br><span class="line">datagen = ImageDataGenerator(</span><br><span class="line">    rotation_range=<span class="number">40</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    shear_range=<span class="number">0.2</span>,</span><br><span class="line">    zoom_range=<span class="number">0.2</span>,</span><br><span class="line">    horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">    fill_mode=<span class="string">'nearest'</span>)</span><br></pre></td></tr></table></figure>
<p>这里只选择了几个参数（想了解更多参数，请查阅Keras 文档）。我们来快速介绍一下这些<br>参数的含义。</p>
<ul>
<li><code>rotation_range</code>是角度值（在 0~180 范围内），表示图像随机旋转的角度范围。</li>
<li><code>width_shift</code> 和 <code>height_shift</code> 是图像在水平或垂直方向上平移的范围（相对于总宽度或总高度的比例）。</li>
<li><code>shear_range</code>是随机错切变换的角度。</li>
<li><code>zoom_range</code>是图像随机缩放的范围。</li>
<li><code>horizontal_flip</code> 是随机将一半图像水平翻转。如果没有水平不对称的假设（比如真实世界的图像），这种做法是有意义的。</li>
<li><code>fill_mode</code>是用于填充新创建像素的方法，这些新像素可能来自于旋转或宽度/高度平移。</li>
</ul>
<p>我们来看一下增强后的图像</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 显示几个随机增强后的训练图像</span></span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line">fnames = [os.path.join(train_cats_dir, fname) <span class="keyword">for</span> fname <span class="keyword">in</span> os.listdir(train_cats_dir)]</span><br><span class="line">img_path = fnames[<span class="number">3</span>]</span><br><span class="line">img = image.load_img(img_path, target_size=(<span class="number">150</span>, <span class="number">150</span>))</span><br><span class="line">x = image.img_to_array(img)</span><br><span class="line">x = x.reshape((<span class="number">1</span>,) + x.shape)</span><br><span class="line">i = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> datagen.flow(x, batch_size=<span class="number">1</span>):</span><br><span class="line">    plt.figure(i)</span><br><span class="line">    imgplot = plt.imshow(image.array_to_img(batch[<span class="number">0</span>]))</span><br><span class="line">    i += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">4</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_33_0.png" width="400" height="400" alt="增强后的图像" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">增强后的图像（1）</div>
</center>

<center>
    <img src="\Pic\DeepLearning_Pic\output_33_1.png" width="400" height="400" alt="增强后的图像" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">增强后的图像（2）</div>
</center>

<center>
    <img src="\Pic\DeepLearning_Pic\output_33_2.png" width="400" height="400" alt="增强后的图像" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">增强后的图像（3）</div>
</center>

<center>
    <img src="\Pic\DeepLearning_Pic\output_33_3.png" width="400" height="400" alt="增强后的图像" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">增强后的图像（4）</div>
</center>




<p>如果你使用这种数据增强来训练一个新网络，那么网络将不会两次看到同样的输入。但网络看到的输入仍然是高度相关的，因为这些输入都来自于少量的原始图像。你无法生成新信息，而只能混合现有信息。因此，这种方法可能不足以完全消除过拟合。为了进一步降低过拟合，你还需要向模型中添加一个<code>Dropout</code>层，添加到密集连接分类器之前。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = models.Sequential()</span><br><span class="line"></span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>,input_shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>)))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">512</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"></span><br><span class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>,optimizer=optimizers.RMSprop(lr=<span class="number">1e-4</span>),metrics=[<span class="string">'acc'</span>])</span><br></pre></td></tr></table></figure>
<p>我们来训练这个使用了数据增强和dropout 的网络。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 利用数据增强生成器训练卷积神经网络</span></span><br><span class="line">train_datagen = ImageDataGenerator(</span><br><span class="line">    rescale=<span class="number">1.</span>/<span class="number">255</span>,</span><br><span class="line">    rotation_range=<span class="number">40</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    shear_range=<span class="number">0.2</span>,</span><br><span class="line">    zoom_range=<span class="number">0.2</span>,</span><br><span class="line">    horizontal_flip=<span class="literal">True</span>,)</span><br><span class="line"></span><br><span class="line">test_datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line"></span><br><span class="line">train_generator = train_datagen.flow_from_directory(</span><br><span class="line">    train_dir,</span><br><span class="line">    target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">    batch_size=<span class="number">32</span>,</span><br><span class="line">    class_mode=<span class="string">'binary'</span>)</span><br><span class="line"></span><br><span class="line">validation_generator = test_datagen.flow_from_directory(</span><br><span class="line">    validation_dir,</span><br><span class="line">    target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">    batch_size=<span class="number">32</span>,</span><br><span class="line">    class_mode=<span class="string">'binary'</span>)</span><br><span class="line"></span><br><span class="line">history = model.fit_generator(</span><br><span class="line">    train_generator,</span><br><span class="line">    steps_per_epoch=<span class="number">100</span>,</span><br><span class="line">    epochs=<span class="number">100</span>,</span><br><span class="line">    validation_data=validation_generator,</span><br><span class="line">    validation_steps=<span class="number">50</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 保存模型</span></span><br><span class="line">model.save(<span class="string">'model/ComputerVersion/cats_and_dogs_small_2.h5'</span>)</span><br></pre></td></tr></table></figure>
<p>我们再次绘制结果，使用了数据增强和dropout 之后，模型不再过拟合：训练曲线紧紧跟随着验证曲线。现在的精度为82%，比未正则化的模型提高了15%（相对比例）。</p>
<p>通过进一步使用正则化方法以及调节网络参数（比如每个卷积层的过滤器个数或网络中的层数），你可以得到更高的精度，可以达到86%或87%。但只靠从头开始训练自己的卷积神经网络，再想提高精度就十分困难，因为可用的数据太少。想要在这个问题上进一步提高精度，下一步需要使用预训练的模型，这是接下来两节的重点。</p>
<h1 id="三、使用预训练的卷积神经网络"><a href="#三、使用预训练的卷积神经网络" class="headerlink" title="三、使用预训练的卷积神经网络"></a>三、使用预训练的卷积神经网络</h1><p>想要将深度学习应用于小型图像数据集，一种常用且非常高效的方法是使用预训练网络。预训练网络（pretrained network）是一个保存好的网络，之前已在大型数据集（通常是大规模图像分类任务）上训练好。如果这个原始数据集足够大且足够通用，那么预训练网络学到的特征的空间层次结构可以有效地作为视觉世界的通用模型，因此这些特征可用于各种不同的计算机视觉问题，即使这些新问题涉及的类别和原始任务完全不同。举个例子，你在ImageNet 上训练了一个网络（其类别主要是动物和日常用品），然后将这个训练好的网络应用于某个不相干的任务，比如在图像中识别家具。这种学到的特征在不同问题之间的可移植性，是深度学习与许多早期浅层学习方法相比的重要优势，它使得深度学习对小数据问题非常有效。</p>
<p>本例中，假设有一个在ImageNet 数据集（140 万张标记图像，1000 个不同的类别）上训练好的大型卷积神经网络。ImageNet 中包含许多动物类别，其中包括不同种类的猫和狗，因此可以认为它在猫狗分类问题上也能有良好的表现。我们将使用VGG16 架构，它由Karen Simonyan 和Andrew Zisserman 在2014 年开发a。对于ImageNet，它是一种简单而又广泛使用的卷积神经网络架构。虽然VGG16 是一个比较旧的模型，性能远比不了当前最先进的模型，而且还比许多新模型更为复杂，但我之所以选择它，是因为它的架构与你已经熟悉的架构很相似，因此无须引入新概念就可以很好地理解。这可能是你第一次遇到这种奇怪的模型名称——VGG、ResNet、Inception、Inception-ResNet、Xception 等。你会习惯这些名称的，因为如果你一直用深度学习做计算机视觉的话，它们会频繁出现。使用预训练网络有两种方法：<strong>特征提取</strong>（feature extraction）和<strong>微调模型</strong>（fine-tuning）。两种方法我们都会介绍。首先来看特征提取。</p>
<h2 id="1-特征提取"><a href="#1-特征提取" class="headerlink" title="1. 特征提取"></a>1. 特征提取</h2><p>特征提取是使用之前网络学到的表示来从新样本中提取出有趣的特征。然后将这些特征输入一个新的分类器，从头开始训练。</p>
<p>如前所述，用于图像分类的卷积神经网络包含两部分：首先是一系列池化层和卷积层，最后是一个密集连接分类器。第一部分叫作模型的卷积基（convolutional base）。对于卷积神经网络而言，特征提取就是取出之前训练好的网络的卷积基，在上面运行新数据，然后在输出上面训练一个新的分类器</p>
<center>
    <img src="\Pic\DeepLearning_Pic\预训练模型1.png" width="300" height="300" alt="保持卷积基不变，改变分类器" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">保持卷积基不变，改变分类器</div>
</center>

<p>为什么仅重复使用卷积基？我们能否也重复使用密集连接分类器？一般来说，应该避免这么做。原因在于卷积基学到的表示可能更加通用，因此更适合重复使用。卷积神经网络的特征图表示通用概念在图像中是否存在，无论面对什么样的计算机视觉问题，这种特征图都可能很有用。但是，分类器学到的表示必然是针对于模型训练的类别，其中仅包含某个类别出现在整张图像中的概率信息。此外，密集连接层的表示不再包含物体在输入图像中的位置信息。密集连接层舍弃了空间的概念，而物体位置信息仍然由卷积特征图所描述。如果物体位置对于问题很重要，那么密集连接层的特征在很大程度上是无用的。</p>
<p>注意，某个卷积层提取的表示的通用性（以及可复用性）取决于该层在模型中的深度。模型中更靠近底部的层提取的是局部的、高度通用的特征图（比如视觉边缘、颜色和纹理），而更靠近顶部的层提取的是更加抽象的概念（比如“猫耳朵”或“狗眼睛”）。因此，如果你的新数据集与原始模型训练的数据集有很大差异，那么最好只使用模型的前几层来做特征提取，而不是使用整个卷积基。</p>
<p>本例中，由于ImageNet的类别中包含多种狗和猫的类别，所以重复使用原始模型密集连接层中所包含的信息可能很有用。但我们选择不这么做，以便涵盖新问题的类别与原始模型的类别不一致的更一般情况。我们来实践一下，使用在ImageNet上训练的VGG16 网络的卷积基从猫狗图像中提取有趣的特征，然后在这些特征上训练一个猫狗分类器。VGG16 等模型内置于Keras 中。你可以从<code>keras.applications</code>模块中导入。下面是<code>keras.applications</code>中的一部分图像分类模型（都是在ImageNet数据集上预训练得到的）：</p>
<ul>
<li>Xception</li>
<li>Inception V3</li>
<li>ResNet50</li>
<li>VGG16</li>
<li>VGG19</li>
<li>MobileNet</li>
</ul>
<p>我们将<code>VGG16</code>模型实例化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将 VGG16 卷积基实例化</span></span><br><span class="line"><span class="keyword">from</span> keras.applications <span class="keyword">import</span> VGG16</span><br><span class="line">conv_base = VGG1616(weights=<span class="string">'imagenet'</span>, include_top=<span class="literal">False</span>, input_shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>))</span><br></pre></td></tr></table></figure>
<p>这里向构造函数中传入了三个参数。</p>
<ul>
<li>weights指定模型初始化的权重检查点。</li>
<li>include_top 指定模型最后是否包含密集连接分类器。默认情况下，这个密集连接分类器对应于ImageNet的1000个类别。因为我们打算使用自己的密集连接分类器（只有两个类别：cat和dog），所以不需要包含它。</li>
<li>input_shape是输入到网络中的图像张量的形状。这个参数完全是可选的，如果不传入这个参数，那么网络能够处理任意形状的输入。VGG16卷积基的详细架构如下所示。它和你已经熟悉的简单卷积神经网络很相似。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">conv_base.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;vgg16&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 150, 150, 3)       0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         
=================================================================
Total params: 14,714,688
Trainable params: 14,714,688
Non-trainable params: 0
_________________________________________________________________
</code></pre><p>最后的特征图形状为(4, 4, 512)。我们将在这个特征上添加一个密集连接分类器。接下来，下一步有两种方法可供选择：</p>
<ul>
<li>在你的数据集上运行卷积基，将输出保存成硬盘中的Numpy数组，然后用这个数据作为输入，输入到独立的密集连接分类器中。这种方法速度快，计算代价低，因为对于每个输入图像只需运行一次卷积基，而卷积基是目前流程中计算代价最高的。但出于同样的原因，这种方法不允许你使用数据增强。</li>
<li>在顶部添加<code>Dense</code>层来扩展已有模型（即<code>conv_base</code>），并在输入数据上端到端地运行整个模型。这样你可以使用数据增强，因为每个输入图像进入模型时都会经过卷积基。但出于同样的原因，这种方法的计算代价比第一种要高很多。</li>
</ul>
<h2 id="2-不使用数据增强的快速特征提取"><a href="#2-不使用数据增强的快速特征提取" class="headerlink" title="2. 不使用数据增强的快速特征提取"></a>2. 不使用数据增强的快速特征提取</h2><p>首先，运行<code>ImageDataGenerator</code>实例，将图像及其标签提取为<code>Numpy</code>数组。我们需要调用<code>conv_base</code>模型的<code>predict</code>方法来从这些图像中提取特征。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用预训练的卷积基提取特征</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line">base_dir = <span class="string">'data/cat_dog/cats_and_dogs_small'</span></span><br><span class="line">train_dir = os.path.join(base_dir, <span class="string">'train'</span>)</span><br><span class="line">validation_dir = os.path.join(base_dir, <span class="string">'validation'</span>)</span><br><span class="line">test_dir = os.path.join(base_dir, <span class="string">'test'</span>)</span><br><span class="line">datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line">batch_size = <span class="number">20</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_features</span><span class="params">(directory, sample_count)</span>:</span></span><br><span class="line">    features = np.zeros(shape=(sample_count, <span class="number">4</span>, <span class="number">4</span>, <span class="number">512</span>))</span><br><span class="line">    labels = np.zeros(shape=(sample_count))</span><br><span class="line">    generator = datagen.flow_from_directory(</span><br><span class="line">        directory,</span><br><span class="line">        target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">        batch_size=batch_size,</span><br><span class="line">        class_mode=<span class="string">'binary'</span>)</span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> inputs_batch, labels_batch <span class="keyword">in</span> generator:</span><br><span class="line">        features_batch = conv_base.predict(inputs_batch)</span><br><span class="line">        features[i * batch_size : (i + <span class="number">1</span>) * batch_size] = features_batch</span><br><span class="line">        labels[i * batch_size : (i + <span class="number">1</span>) * batch_size] = labels_batch</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> i * batch_size &gt;= sample_count:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> features, labels</span><br><span class="line"></span><br><span class="line">train_features, train_labels = extract_features(train_dir, <span class="number">2000</span>)</span><br><span class="line">validation_features, validation_labels = extract_features(validation_dir, <span class="number">1000</span>)</span><br><span class="line">test_features, test_labels = extract_features(test_dir, <span class="number">1000</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Found 2000 images belonging to 2 classes.
Found 1000 images belonging to 2 classes.
Found 1000 images belonging to 2 classes.
</code></pre><p>目前，提取的特征形状为<code>(samples, 4, 4, 512)</code>。我们要将其输入到密集连接分类器中，所以首先必须将其形状展平为<code>(samples, 8192)</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_features = np.reshape(train_features, (<span class="number">2000</span>, <span class="number">4</span> * <span class="number">4</span> * <span class="number">512</span>))</span><br><span class="line">validation_features = np.reshape(validation_features, (<span class="number">1000</span>, <span class="number">4</span> * <span class="number">4</span> * <span class="number">512</span>))</span><br><span class="line">test_features = np.reshape(test_features, (<span class="number">1000</span>, <span class="number">4</span> * <span class="number">4</span> * <span class="number">512</span>))</span><br></pre></td></tr></table></figure>
<p>现在你可以定义你的密集连接分类器（注意要使用<code>dropout</code>正则化），并在刚刚保存的数据和标签上训练这个分类器。</p>
<h3 id="定义并训练密集连接分类器"><a href="#定义并训练密集连接分类器" class="headerlink" title="定义并训练密集连接分类器"></a>定义并训练密集连接分类器</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimizers</span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">256</span>, activation=<span class="string">'relu'</span>, input_dim=<span class="number">4</span> * <span class="number">4</span> * <span class="number">512</span>))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line">model.compile(optimizer=optimizers.RMSprop(lr=<span class="number">2e-5</span>),</span><br><span class="line">    loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">    metrics=[<span class="string">'acc'</span>])</span><br><span class="line">history = model.fit(train_features, train_labels,</span><br><span class="line">    epochs=<span class="number">30</span>,</span><br><span class="line">    batch_size=<span class="number">20</span>,</span><br><span class="line">    validation_data=(validation_features, validation_labels))</span><br></pre></td></tr></table></figure>
<p>训练速度非常快，因为你只需处理两个<code>Dense</code>层。我们来看一下训练期间的损失曲线和精度曲线：</p>
<h3 id="绘制结果"><a href="#绘制结果" class="headerlink" title="绘制结果"></a>绘制结果</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">acc = history.history[<span class="string">'acc'</span>]</span><br><span class="line">val_acc = history.history[<span class="string">'val_acc'</span>]</span><br><span class="line">loss = history.history[<span class="string">'loss'</span>]</span><br><span class="line">val_loss = history.history[<span class="string">'val_loss'</span>]</span><br><span class="line"></span><br><span class="line">epochs = range(<span class="number">1</span>, len(acc) + <span class="number">1</span>)</span><br><span class="line">plt.plot(epochs, acc, <span class="string">'bo'</span>, label=<span class="string">'Training acc'</span>)</span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">'b'</span>, label=<span class="string">'Validation acc'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation accuracy'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(epochs, loss, <span class="string">'bo'</span>, label=<span class="string">'Training loss'</span>)</span><br><span class="line">plt.plot(epochs, val_loss, <span class="string">'b'</span>, label=<span class="string">'Validation loss'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_51_0.png" width="400" height="400" alt="训练损失和验证损失" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">训练损失和验证损失</div>
</center>


<center>
    <img src="\Pic\DeepLearning_Pic\output_51_1.png" width="400" height="400" alt="训练精度和验证精度" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">训练精度和验证精度</div>
</center>


<p>我们的验证精度达到了约90%，比上一节从头开始训练的小型模型效果要好得多。但从图中也可以看出，虽然<code>dropout</code>比率相当大，但模型几乎从一开始就过拟合。这是因为本方法没有使用数据增强，而数据增强对防止小型图像数据集的过拟合非常重要。</p>
<h2 id="3-使用数据增强的特征提取"><a href="#3-使用数据增强的特征提取" class="headerlink" title="3. 使用数据增强的特征提取"></a>3. 使用数据增强的特征提取</h2><p>下面我们来看一下特征提取的第二种方法，它的速度更慢，计算代价更高，但在训练期间可以使用数据增强。这种方法就是：扩展<code>conv_base</code>模型，然后在输入数据上端到端地运行模型。</p>
<blockquote>
<p>注意 本方法计算代价很高，只在有GPU的情况下才能尝试运行。它在CPU上是绝对难以运行的。如果你无法在GPU上运行代码，那么就采用第一种方法。</p>
</blockquote>
<p>模型的行为和层类似，所以你可以向<code>Sequential</code>模型中添加一个模型（比如<code>conv_base</code>），就像添加一个层一样。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在卷积基上添加一个密集连接分类器</span></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(conv_base)</span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dense(<span class="number">256</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br></pre></td></tr></table></figure>
<p>现在模型的架构如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_7&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
vgg16 (Model)                (None, 4, 4, 512)         14714688  
_________________________________________________________________
flatten_4 (Flatten)          (None, 8192)              0         
_________________________________________________________________
dense_9 (Dense)              (None, 256)               2097408   
_________________________________________________________________
dense_10 (Dense)             (None, 1)                 257       
=================================================================
Total params: 16,812,353
Trainable params: 16,812,353
Non-trainable params: 0
_________________________________________________________________
</code></pre><p>如你所见，<code>VGG16</code>的卷积基有14 714 688个参数，非常多。在其上添加的分类器有200万个参数。</p>
<p>在编译和训练模型之前，一定要“冻结”卷积基。冻结（<code>freeze</code>）一个或多个层是指在训练过程中保持其权重不变。如果不这么做，那么卷积基之前学到的表示将会在训练过程中被修改。因为其上添加的<code>Dense</code>层是随机初始化的，所以非常大的权重更新将会在网络中传播，对之前学到的表示造成很大破坏。</p>
<p>在<code>Keras</code>中，冻结网络的方法是将其<code>trainable</code>属性设为<code>False</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(<span class="string">'This is the number of trainable weights before freezing the conv base:'</span>, len(model.trainable_weights))</span><br><span class="line">conv_base.trainable = <span class="literal">False</span></span><br><span class="line">print(<span class="string">'This is the number of trainable weights after freezing the conv base:'</span>, len(model.trainable_weights))</span><br></pre></td></tr></table></figure>
<pre><code>This is the number of trainable weights before freezing the conv base: 30
This is the number of trainable weights after freezing the conv base: 4
</code></pre><p>如此设置之后，只有添加的两个Dense 层的权重才会被训练。总共有4 个权重张量，每层 2 个（主权重矩阵和偏置向量）。注意，为了让这些修改生效，你必须先编译模型。如果在编译之后修改了权重的<code>trainable</code>属性，那么应该重新编译模型，否则这些修改将被忽略。</p>
<p>现在你可以开始训练模型了，使用和前一个例子相同的数据增强设置。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 利用冻结的卷积基端到端地训练模型</span></span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimizers</span><br><span class="line"></span><br><span class="line">train_datagen = ImageDataGenerator(</span><br><span class="line">    rescale=<span class="number">1.</span>/<span class="number">255</span>,</span><br><span class="line">    rotation_range=<span class="number">40</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    shear_range=<span class="number">0.2</span>,</span><br><span class="line">    zoom_range=<span class="number">0.2</span>,</span><br><span class="line">    horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">    fill_mode=<span class="string">'nearest'</span>)</span><br><span class="line"></span><br><span class="line">test_datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line"></span><br><span class="line">train_generator = train_datagen.flow_from_directory(</span><br><span class="line">    train_dir,</span><br><span class="line">    target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">    batch_size=<span class="number">20</span>,</span><br><span class="line">    class_mode=<span class="string">'binary'</span>)</span><br><span class="line"></span><br><span class="line">validation_generator = test_datagen.flow_from_directory(</span><br><span class="line">    validation_dir,</span><br><span class="line">    target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">    batch_size=<span class="number">20</span>,</span><br><span class="line">    class_mode=<span class="string">'binary'</span>)</span><br><span class="line"></span><br><span class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">    optimizer=optimizers.RMSprop(lr=<span class="number">2e-5</span>),</span><br><span class="line">    metrics=[<span class="string">'acc'</span>])</span><br></pre></td></tr></table></figure>
<pre><code>Found 2000 images belonging to 2 classes.
Found 1000 images belonging to 2 classes.
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">history = model.fit_generator(</span><br><span class="line">    train_generator,</span><br><span class="line">    steps_per_epoch=<span class="number">100</span>,</span><br><span class="line">    epochs=<span class="number">30</span>,</span><br><span class="line">    validation_data=validation_generator,</span><br><span class="line">    validation_steps=<span class="number">50</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.save(<span class="string">'model/ComputerVersion/cats_and_dogs_small_dataEnforcementFeatureExtraction.h5'</span>)</span><br></pre></td></tr></table></figure>
<p>如你所见，这比从头开始训练的小型卷积神经网络要好得多。</p>
<h2 id="4-微调模型"><a href="#4-微调模型" class="headerlink" title="4. 微调模型"></a>4. 微调模型</h2><p>另一种广泛使用的模型复用方法是模型微调（fine-tuning），与特征提取互为补充。对于用于特征提取的冻结的模型基，微调是指将其顶部的几层“解冻”，并将这解冻的几层和新增加的部分（本例中是全连接分类器）联合训练。之所以叫作微调，是因为它只是略微调整了所复用模型中更加抽象的表示，以便让这些表示与手头的问题更加相关。</p>
<center>
    <img src="\Pic\DeepLearning_Pic\fine_tuning.png" width="200" height="200" alt="微调VGG16网络的最后一个卷积块" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">微调VGG16网络的最后一个卷积块</div>
</center>

<p>前面说过，冻结VGG16的卷积基是为了能够在上面训练一个随机初始化的分类器。同理，只有上面的分类器已经训练好了，才能微调卷积基的顶部几层。如果分类器没有训练好，那么训练期间通过网络传播的误差信号会特别大，微调的几层之前学到的表示都会被破坏。因此，微调网络的步骤如下。</p>
<ol>
<li>在已经训练好的基网络（base network）上添加自定义网络。</li>
<li>冻结基网络。</li>
<li>训练所添加的部分。</li>
<li>解冻基网络的一些层。</li>
<li>联合训练解冻的这些层和添加的部分。</li>
</ol>
<p>你在做特征提取时已经完成了前三个步骤。我们继续进行第四步：先解冻<code>conv_base</code>，然后冻结其中的部分层。提醒一下，卷积基的架构如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">conv_base.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;vgg16&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 150, 150, 3)       0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         
=================================================================
Total params: 14,714,688
Trainable params: 7,079,424
Non-trainable params: 7,635,264
_________________________________________________________________
</code></pre><p>我们将微调最后三个卷积层，也就是说，直到<code>block4_pool</code>的所有层都应该被冻结，而<code>block5_conv1</code>、<code>block5_conv2</code>和<code>block5_conv3</code>三层应该是可训练的。为什么不微调更多层？为什么不微调整个卷积基？你当然可以这么做，但需要考虑以下几点。</p>
<ul>
<li>卷积基中更靠底部的层编码的是更加通用的可复用特征，而更靠顶部的层编码的是更专业化的特征。微调这些更专业化的特征更加有用，因为它们需要在你的新问题上改变用途。微调更靠底部的层，得到的回报会更少。</li>
<li>训练的参数越多，过拟合的风险越大。卷积基有 1500 万个参数，所以在你的小型数据集上训练这么多参数是有风险的。</li>
</ul>
<p>因此，在这种情况下，一个好策略是仅微调卷积基最后的两三层。我们从上一个例子结束的地方开始，继续实现此方法。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 冻结直到某一层的所有层</span></span><br><span class="line">conv_base.trainable = <span class="literal">True</span></span><br><span class="line">set_trainable = <span class="literal">False</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> conv_base.layers:</span><br><span class="line">    <span class="keyword">if</span> layer.name == <span class="string">'block5_conv1'</span>:</span><br><span class="line">        set_trainable = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">if</span> set_trainable:</span><br><span class="line">        layer.trainable = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        layer.trainable = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>现在你可以开始微调网络。我们将使用学习率非常小的RMSProp优化器来实现。之所以让学习率很小，是因为对于微调的三层表示，我们希望其变化范围不要太大，太大的权重更新可能会破坏这些表示。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 微调模型</span></span><br><span class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">    optimizer=optimizers.RMSprop(lr=<span class="number">1e-5</span>),</span><br><span class="line">    metrics=[<span class="string">'acc'</span>])</span><br><span class="line">history = model.fit_generator(</span><br><span class="line">    train_generator,</span><br><span class="line">    steps_per_epoch=<span class="number">100</span>,</span><br><span class="line">    epochs=<span class="number">100</span>,</span><br><span class="line">    validation_data=validation_generator,</span><br><span class="line">    validation_steps=<span class="number">50</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.save(<span class="string">'model/ComputerVersion/cats_and_dogs_small_dataEnforcementFineTuning.h5'</span>)</span><br></pre></td></tr></table></figure>
<p>我们用和前面一样的绘图代码来绘制结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">acc = history.history[<span class="string">'acc'</span>]</span><br><span class="line">val_acc = history.history[<span class="string">'val_acc'</span>]</span><br><span class="line">loss = history.history[<span class="string">'loss'</span>]</span><br><span class="line">val_loss = history.history[<span class="string">'val_loss'</span>]</span><br><span class="line"></span><br><span class="line">epochs = range(<span class="number">1</span>, len(acc) + <span class="number">1</span>)</span><br><span class="line">plt.plot(epochs, acc, <span class="string">'bo'</span>, label=<span class="string">'Training acc'</span>)</span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">'b'</span>, label=<span class="string">'Validation acc'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation accuracy'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(epochs, loss, <span class="string">'bo'</span>, label=<span class="string">'Training loss'</span>)</span><br><span class="line">plt.plot(epochs, val_loss, <span class="string">'b'</span>, label=<span class="string">'Validation loss'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_70_0.png" width="400" height="400" alt="训练精度和验证精度" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">训练精度和验证精度</div>
</center>

<center>
    <img src="\Pic\DeepLearning_Pic\output_70_1.png" width="400" height="400" alt="训练损失和验证损失" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">训练损失和验证损失</div>
</center>




<p>这些曲线看起来包含噪声。为了让图像更具可读性，你可以将每个损失和精度都替换为指数移动平均值，从而让曲线变得平滑。下面用一个简单的实用函数来实现</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使曲线变得平滑</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">smooth_curve</span><span class="params">(points, factor=<span class="number">0.8</span>)</span>:</span></span><br><span class="line">    smoothed_points = []</span><br><span class="line">    <span class="keyword">for</span> point <span class="keyword">in</span> points:</span><br><span class="line">        <span class="keyword">if</span> smoothed_points:</span><br><span class="line">            previous = smoothed_points[<span class="number">-1</span>]</span><br><span class="line">            smoothed_points.append(previous * factor + point * (<span class="number">1</span> - factor))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            smoothed_points.append(point)</span><br><span class="line">    <span class="keyword">return</span> smoothed_points</span><br><span class="line"></span><br><span class="line">plt.plot(epochs,smooth_curve(acc), <span class="string">'bo'</span>, label=<span class="string">'Smoothed training acc'</span>)</span><br><span class="line">plt.plot(epochs,smooth_curve(val_acc), <span class="string">'b'</span>, label=<span class="string">'Smoothed validation acc'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation accuracy'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(epochs,smooth_curve(loss), <span class="string">'bo'</span>, label=<span class="string">'Smoothed training loss'</span>)</span><br><span class="line">plt.plot(epochs,smooth_curve(val_loss), <span class="string">'b'</span>, label=<span class="string">'Smoothed validation loss'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_72_0.png" width="400" height="400" alt="训练精度和验证精度" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">平滑后的训练精度和验证精度</div>
</center>

<center>
    <img src="\Pic\DeepLearning_Pic\output_72_1.png" width="400" height="400" alt="训练损失和验证损失" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">平滑后的训练损失和验证损失</div>
</center>


<p>注意，从损失曲线上看不出与之前相比有任何真正的提高（实际上还在变差）。你可能感到奇怪，如果损失没有降低，那么精度怎么能保持稳定或提高呢？答案很简单：图中展示的是逐点（pointwise）损失值的平均值，但影响精度的是损失值的分布，而不是平均值，因为精度是模型预测的类别概率的二进制阈值。即使从平均损失中无法看出，但模型也仍然可能在改进。现在，你可以在测试数据上最终评估这个模型。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">test_generator = test_datagen.flow_from_directory(</span><br><span class="line">    test_dir,</span><br><span class="line">    target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">    batch_size=<span class="number">20</span>,</span><br><span class="line">    class_mode=<span class="string">'binary'</span>)</span><br><span class="line">test_loss, test_acc = model.evaluate_generator(test_generator, steps=<span class="number">50</span>)</span><br><span class="line">print(<span class="string">'test acc:'</span>, test_acc)</span><br></pre></td></tr></table></figure>
<pre><code>Found 1000 images belonging to 2 classes.
test acc: 0.9399999976158142
</code></pre><h1 id="四、卷积神经网络的可视化"><a href="#四、卷积神经网络的可视化" class="headerlink" title="四、卷积神经网络的可视化"></a>四、卷积神经网络的可视化</h1><p>人们常说，深度学习模型是“黑盒”，即模型学到的表示很难用人类可以理解的方式来提取和呈现。虽然对于某些类型的深度学习模型来说，这种说法部分正确，但对卷积神经网络来说绝对不是这样。卷积神经网络学到的表示非常适合可视化，很大程度上是因为它们是视觉概念的表示。自2013 年以来，人们开发了多种技术来对这些表示进行可视化和解释。我们不会全部介绍，但会介绍三种最容易理解也最有用的方法。</p>
<ul>
<li>可视化卷积神经网络的中间输出（中间激活）：有助于理解卷积神经网络连续的层如何对输入进行变换，也有助于初步了解卷积神经网络每个过滤器的含义。</li>
<li>可视化卷积神经网络的过滤器：有助于精确理解卷积神经网络中每个过滤器容易接受的视觉模式或视觉概念。</li>
<li>可视化图像中类激活的热力图：有助于理解图像的哪个部分被识别为属于某个类别，从而可以定位图像中的物体。</li>
</ul>
<p>对于第一种方法（即激活的可视化），我们将使用猫狗分类问题上从头开始训练的小型卷积神经网络。对于另外两种可视化方法，我们将使用VGG16模型。</p>
<h2 id="1-可视化中间激活"><a href="#1-可视化中间激活" class="headerlink" title="1. 可视化中间激活"></a>1. 可视化中间激活</h2><p>可视化中间激活，是指对于给定输入，展示网络中各个卷积层和池化层输出的特征图（层的输出通常被称为该层的激活，即激活函数的输出）。这让我们可以看到输入如何被分解为网络学到的不同过滤器。我们希望在三个维度对特征图进行可视化：宽度、高度和深度（通道）。每个通道都对应相对独立的特征，所以将这些特征图可视化的正确方法是将每个通道的内容分别绘制成二维图像。我们首先来加载先前保存的模型。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line">model = load_model(<span class="string">'model/ComputerVersion/cats_and_dogs_small_2.h5'</span>)</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_5&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_11 (Conv2D)           (None, 148, 148, 32)      896       
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 74, 74, 32)        0         
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 72, 72, 64)        18496     
_________________________________________________________________
max_pooling2d_8 (MaxPooling2 (None, 36, 36, 64)        0         
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 34, 34, 128)       73856     
_________________________________________________________________
max_pooling2d_9 (MaxPooling2 (None, 17, 17, 128)       0         
_________________________________________________________________
conv2d_14 (Conv2D)           (None, 15, 15, 128)       147584    
_________________________________________________________________
max_pooling2d_10 (MaxPooling (None, 7, 7, 128)         0         
_________________________________________________________________
flatten_3 (Flatten)          (None, 6272)              0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 6272)              0         
_________________________________________________________________
dense_5 (Dense)              (None, 512)               3211776   
_________________________________________________________________
dense_6 (Dense)              (None, 1)                 513       
=================================================================
Total params: 3,453,121
Trainable params: 3,453,121
Non-trainable params: 0
_________________________________________________________________
</code></pre><p>接下来，我们需要一张输入图像，即一张猫的图像，它不属于网络的训练图像。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">img_path = <span class="string">"data/cat_dog/cats_and_dogs_small/test/cats/cat.1700.jpg"</span></span><br><span class="line">img = image.load_img(img_path, target_size=(<span class="number">150</span>, <span class="number">150</span>))</span><br><span class="line">img_tensor = image.img_to_array(img)</span><br><span class="line">img_tensor = np.expand_dims(img_tensor, axis=<span class="number">0</span>)</span><br><span class="line">img_tensor /= <span class="number">255.</span></span><br><span class="line">print(img_tensor.shape)</span><br></pre></td></tr></table></figure>
<pre><code>(1, 150, 150, 3)
</code></pre><p>我们来显示这张图像</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.imshow(img_tensor[<span class="number">0</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_80_0.png" width="400" height="400" alt="a" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<p>为了提取想要查看的特征图，我们需要创建一个<code>Keras</code>模型，以图像批量作为输入，并输出所有卷积层和池化层的激活。为此，我们需要使用<code>Keras</code>的<code>Model</code>类。模型实例化需要两个参数：一个输入张量（或输入张量的列表）和一个输出张量（或输出张量的列表）。得到的类是一个<code>Keras</code>模型，就像你熟悉的<code>Sequential</code>模型一样，将特定输入映射为特定输出。<code>Model</code>类允许模型有多个输出，这一点与<code>Sequential</code>模型不同。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 用一个输入张量和一个输出张量列表将模型实例化</span></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line">layer_outputs = [layer.output <span class="keyword">for</span> layer <span class="keyword">in</span> model.layers[:<span class="number">8</span>]]</span><br><span class="line">activation_model = models.Model(inputs=model.input, outputs=layer_outputs)</span><br></pre></td></tr></table></figure>
<p>输入一张图像，这个模型将返回原始模型前8 层的激活值。这是第一次遇到的多输出模型，之前的模型都是只有一个输入和一个输出。一般情况下，模型可以有任意个输入和输出。这个模型有一个输入和8 个输出，即每层激活对应一个输出。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 以预测模式运行模型</span></span><br><span class="line">activations = activation_model.predict(img_tensor)</span><br><span class="line"><span class="comment"># 例如，对于输入的猫图像，第一个卷积层的激活如下所示。</span></span><br><span class="line">first_layer_activation = activations[<span class="number">0</span>]</span><br><span class="line">print(first_layer_activation.shape)</span><br></pre></td></tr></table></figure>
<pre><code>(1, 148, 148, 32)
</code></pre><p>它是大小为148×148的特征图，有32个通道。我们来绘制原始模型第一层激活的第4个通道</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将第4个通道可视化</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.matshow(first_layer_activation[<span class="number">0</span>, :, :, <span class="number">4</span>], cmap=<span class="string">'viridis'</span>)</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_86_1.png" width="400" height="400" alt="通道激活" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">通道4激活</div>
</center>


<p>这个通道似乎是对角边缘检测器。我们再看一下第7个通道</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将第7个通道可视化</span></span><br><span class="line">plt.matshow(first_layer_activation[<span class="number">0</span>, :, :, <span class="number">7</span>], cmap=<span class="string">'viridis'</span>)</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_88_1.png" width="400" height="400" alt="通道激活" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">通道7激活</div>
</center>



<p>下面我们来绘制网络中所有激活的完整可视化。我们需要在8个特征图中的每一个中提取并绘制每一个通道，然后将结果叠加在一个大的图像张量中，按通道并排。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将每个中间激活的所有通道可视化</span></span><br><span class="line">layer_names = []</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> model.layers[:<span class="number">8</span>]:</span><br><span class="line">    layer_names.append(layer.name)</span><br><span class="line">images_per_row = <span class="number">16</span></span><br><span class="line"><span class="keyword">for</span> layer_name, layer_activation <span class="keyword">in</span> zip(layer_names, activations):</span><br><span class="line">    n_features = layer_activation.shape[<span class="number">-1</span>]</span><br><span class="line">    size = layer_activation.shape[<span class="number">1</span>]</span><br><span class="line">    n_cols = n_features // images_per_row</span><br><span class="line">    display_grid = np.zeros((size * n_cols, images_per_row * size))</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> range(n_cols):</span><br><span class="line">        <span class="keyword">for</span> row <span class="keyword">in</span> range(images_per_row):</span><br><span class="line">            channel_image = layer_activation[<span class="number">0</span>,:, :,col * images_per_row + row]</span><br><span class="line">            channel_image -= channel_image.mean()</span><br><span class="line">            channel_image /= channel_image.std()</span><br><span class="line">            channel_image *= <span class="number">64</span></span><br><span class="line">            channel_image += <span class="number">128</span></span><br><span class="line">            channel_image = np.clip(channel_image, <span class="number">0</span>, <span class="number">255</span>).astype(<span class="string">'uint8'</span>)</span><br><span class="line">            display_grid[col * size : (col + <span class="number">1</span>) * size,row * size : (row + <span class="number">1</span>) * size] = channel_image</span><br><span class="line">    scale = <span class="number">1.</span> / size</span><br><span class="line">    plt.figure(figsize=(scale * display_grid.shape[<span class="number">1</span>],</span><br><span class="line">    scale * display_grid.shape[<span class="number">0</span>]))</span><br><span class="line">    plt.title(layer_name)</span><br><span class="line">    plt.grid(<span class="literal">False</span>)</span><br><span class="line">    plt.imshow(display_grid, aspect=<span class="string">'auto'</span>, cmap=<span class="string">'viridis'</span>)</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_90_1.png" width="400" height="400" alt="通道激活" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>

<center>
    <img src="\Pic\DeepLearning_Pic\output_90_2.png" width="400" height="400" alt="通道激活" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<center>
    <img src="\Pic\DeepLearning_Pic\output_90_3.png" width="400" height="400" alt="通道激活" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<center>
    <img src="\Pic\DeepLearning_Pic\output_90_4.png" width="400" height="400" alt="通道激活" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<center>
    <img src="\Pic\DeepLearning_Pic\output_90_5.png" width="400" height="400" alt="通道激活" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>

<center>
    <img src="\Pic\DeepLearning_Pic\output_90_6.png" width="400" height="400" alt="通道激活" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>

<center>
    <img src="\Pic\DeepLearning_Pic\output_90_7.png" width="400" height="400" alt="通道激活" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>

<center>
    <img src="\Pic\DeepLearning_Pic\output_90_8.png" width="400" height="400" alt="通道激活" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>



<p>这里需要注意以下几点。</p>
<ul>
<li>第一层是各种边缘探测器的集合。在这一阶段，激活几乎保留了原始图像中的所有信息。</li>
<li>随着层数的加深，激活变得越来越抽象，并且越来越难以直观地理解。它们开始表示更高层次的概念，比如“猫耳朵”和“猫眼睛”。层数越深，其表示中关于图像视觉内容的信息就越少，而关于类别的信息就越多。</li>
<li>激活的稀疏度（sparsity）随着层数的加深而增大。在第一层里，所有过滤器都被输入图像激活，但在后面的层里，越来越多的过滤器是空白的。也就是说，输入图像中找不到这些过滤器所编码的模式。</li>
</ul>
<p>我们刚刚揭示了深度神经网络学到的表示的一个重要普遍特征：随着层数的加深，层所提取的特征变得越来越抽象。更高的层激活包含关于特定输入的信息越来越少，而关于目标的信息越来越多（本例中即图像的类别：猫或狗）。深度神经网络可以有效地作为信息蒸馏管道（information distillation pipeline），输入原始数据（本例中是RGB 图像），反复对其进行变换，将无关信息过滤掉（比如图像的具体外观），并放大和细化有用的信息（比如图像的类别）。</p>
<p>这与人类和动物感知世界的方式类似：人类观察一个场景几秒钟后，可以记住其中有哪些抽象物体（比如自行车、树），但记不住这些物体的具体外观。事实上，如果你试着凭记忆画一辆普通自行车，那么很可能完全画不出真实的样子，虽然你一生中见过上千辆自行车。你可以现在就试着画一下，这个说法绝对是真实的。你的大脑已经学会将视觉输入完全抽象化，即将其转换为更高层次的视觉概念，同时过滤掉不相关的视觉细节，这使得大脑很难记住周围事物的外观。</p>
<center>
    <img src="\Pic\DeepLearning_Pic\bike.png" width="200" height="200" alt="（左图）试着凭记忆画一辆自行车；（右图）自行车示意图" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">（左图）试着凭记忆画一辆自行车；（右图）自行车示意图</div>
</center>

<h2 id="2-可视化卷积神经网络的过滤器"><a href="#2-可视化卷积神经网络的过滤器" class="headerlink" title="2. 可视化卷积神经网络的过滤器"></a>2. 可视化卷积神经网络的过滤器</h2><p>想要观察卷积神经网络学到的过滤器，另一种简单的方法是显示每个过滤器所响应的视觉模式。这可以通过在输入空间中进行梯度上升来实现：从空白输入图像开始，将梯度下降应用于卷积神经网络输入图像的值，其目的是让某个过滤器的响应最大化。得到的输入图像是选定过滤器具有最大响应的图像。</p>
<p>这个过程很简单：我们需要构建一个损失函数，其目的是让某个卷积层的某个过滤器的值最大化；然后，我们要使用随机梯度下降来调节输入图像的值，以便让这个激活值最大化。例如，对于在<code>ImageNet</code>上预训练的<code>VGG16</code>网络，其<code>block3_conv1</code>层第0 个过滤器激活的损失如下所示。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 为过滤器的可视化定义损失张量</span></span><br><span class="line"><span class="keyword">from</span> keras.applications <span class="keyword">import</span> VGG16</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line">model = VGG16(weights=<span class="string">'imagenet'</span>,include_top=<span class="literal">False</span>)</span><br><span class="line">layer_name = <span class="string">'block3_conv1'</span></span><br><span class="line">filter_index = <span class="number">0</span></span><br><span class="line">layer_output = model.get_layer(layer_name).output</span><br><span class="line">loss = K.mean(layer_output[:, :, :, filter_index])</span><br></pre></td></tr></table></figure>
<p>为了实现梯度下降，我们需要得到损失相对于模型输入的梯度。为此，我们需要使用<code>Keras</code>的<code>backend</code>模块内置的<code>gradients</code>函数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 获取损失相对于输入的梯度</span></span><br><span class="line">grads = K.gradients(loss, model.input)[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p>为了让梯度下降过程顺利进行，一个非显而易见的技巧是将梯度张量除以其L2范数（张量中所有值的平方的平均值的平方根）来标准化。这就确保了输入图像的更新大小始终位于相同的范围。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 梯度标准化技巧</span></span><br><span class="line">grads /= (K.sqrt(K.mean(K.square(grads))) + <span class="number">1e-5</span>)</span><br></pre></td></tr></table></figure>
<p>现在你需要一种方法：给定输入图像，它能够计算损失张量和梯度张量的值。你可以定义一个Keras后端函数来实现此方法：<code>iterate</code>是一个函数，它将一个Numpy张量（表示为长度为1的张量列表）转换为两个Numpy张量组成的列表，这两个张量分别是损失值和梯度值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 给定Numpy输入值，得到Numpy输出值</span></span><br><span class="line">iterate = K.function([model.input], [loss, grads])</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">loss_value, grads_value = iterate([np.zeros((<span class="number">1</span>, <span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>))])</span><br></pre></td></tr></table></figure>
<p>现在你可以定义一个Python 循环来进行随机梯度下降。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 通过随机梯度下降让损失最大化</span></span><br><span class="line">input_img_data = np.random.random((<span class="number">1</span>, <span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>)) * <span class="number">20</span> + <span class="number">128.</span></span><br><span class="line">step = <span class="number">1.</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">40</span>):</span><br><span class="line">    loss_value, grads_value = iterate([input_img_data])</span><br><span class="line">    input_img_data += grads_value * step</span><br></pre></td></tr></table></figure>
<p>得到的图像张量是形状为<code>(1, 150, 150, 3)</code>的浮点数张量，其取值可能不是<code>[0, 255]</code>区间内的整数。因此，你需要对这个张量进行后处理，将其转换为可显示的图像。下面这个简单的实用函数可以做到这一点。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将张量转换为有效图像的实用函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">deprocess_image</span><span class="params">(x)</span>:</span></span><br><span class="line">    x -= x.mean()</span><br><span class="line">    x /= (x.std() + <span class="number">1e-5</span>)</span><br><span class="line">    x *= <span class="number">0.1</span></span><br><span class="line">    x += <span class="number">0.5</span></span><br><span class="line">    x = np.clip(x, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    x *= <span class="number">255</span></span><br><span class="line">    x = np.clip(x, <span class="number">0</span>, <span class="number">255</span>).astype(<span class="string">'uint8'</span>)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>接下来，我们将上述代码片段放到一个Python函数中，输入一个层的名称和一个过滤器索引，它将返回一个有效的图像张量，表示能够将特定过滤器的激活最大化的模式。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生成过滤器可视化的函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_pattern</span><span class="params">(layer_name, filter_index, size=<span class="number">150</span>)</span>:</span></span><br><span class="line">    layer_output = model.get_layer(layer_name).output</span><br><span class="line">    loss = K.mean(layer_output[:, :, :, filter_index])</span><br><span class="line">    grads = K.gradients(loss, model.input)[<span class="number">0</span>]</span><br><span class="line">    grads /= (K.sqrt(K.mean(K.square(grads))) + <span class="number">1e-5</span>)</span><br><span class="line">    iterate = K.function([model.input], [loss, grads])</span><br><span class="line">    input_img_data = np.random.random((<span class="number">1</span>, size, size, <span class="number">3</span>)) * <span class="number">20</span> + <span class="number">128.</span></span><br><span class="line">    step = <span class="number">1.</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">40</span>):</span><br><span class="line">        loss_value, grads_value = iterate([input_img_data])</span><br><span class="line">        input_img_data += grads_value * step</span><br><span class="line">    img = input_img_data[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> deprocess_image(img)</span><br></pre></td></tr></table></figure>
<p>我们来试用一下这个函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.imshow(generate_pattern(<span class="string">'block3_conv1'</span>, <span class="number">0</span>))</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_106_1.png" width="400" height="400" alt="通道激活" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>



<p>看起来，<code>block3_conv1</code>层第0个过滤器响应的是波尔卡点（polka-dot）图案。下面来看有趣的部分：我们可以将每一层的每个过滤器都可视化。为了简单起见，我们只查看每一层的前64 个过滤器，并只查看每个卷积块的第一层（即<code>block1_conv1</code>、<code>block2_conv1</code>、<code>block3_conv1</code>、<code>block4_ conv1</code>、<code>block5_conv1</code>）。我们将输出放在一个8×8的网格中，每个网格是一个64像素×64像素的过滤器模式，两个过滤器模式之间留有一些黑边</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生成某一层中所有过滤器响应模式组成的网格</span></span><br><span class="line">layer_name = <span class="string">'block1_conv1'</span></span><br><span class="line">size = <span class="number">64</span></span><br><span class="line">margin = <span class="number">5</span></span><br><span class="line">results = np.zeros((<span class="number">8</span> * size + <span class="number">7</span> * margin, <span class="number">8</span> * size + <span class="number">7</span> * margin, <span class="number">3</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">8</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">8</span>):</span><br><span class="line">        filter_img = generate_pattern(layer_name, i + (j * <span class="number">8</span>), size=size)</span><br><span class="line">        horizontal_start = i * size + i * margin</span><br><span class="line">        horizontal_end = horizontal_start + size</span><br><span class="line">        vertical_start = j * size + j * margin</span><br><span class="line">        vertical_end = vertical_start + size</span><br><span class="line">        results[horizontal_start: horizontal_end, vertical_start: vertical_end, :] = filter_img</span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">20</span>))</span><br><span class="line">plt.imshow(results)</span><br></pre></td></tr></table></figure>
<p>这些过滤器可视化包含卷积神经网络的层如何观察世界的很多信息：卷积神经网络中每一层都学习一组过滤器，以便将其输入表示为过滤器的组合。这类似于傅里叶变换将信号分解为一组余弦函数的过程。随着层数的加深，卷积神经网络中的过滤器变得越来越复杂，越来越精细。</p>
<ul>
<li>模型第一层（block1_conv1）的过滤器对应简单的方向边缘和颜色（还有一些是彩色边缘）。</li>
<li>block2_conv1层的过滤器对应边缘和颜色组合而成的简单纹理。</li>
<li>更高层的过滤器类似于自然图像中的纹理：羽毛、眼睛、树叶等。</li>
</ul>
<h2 id="3-可视化类激活的热力图"><a href="#3-可视化类激活的热力图" class="headerlink" title="3. 可视化类激活的热力图"></a>3. 可视化类激活的热力图</h2><p>我还要介绍另一种可视化方法，它有助于了解一张图像的哪一部分让卷积神经网络做出了最终的分类决策。这有助于对卷积神经网络的决策过程进行调试，特别是出现分类错误的情况下。这种方法还可以定位图像中的特定目标。</p>
<p>这种通用的技术叫作类激活图（CAM，class activation map）可视化，它是指对输入图像生成类激活的热力图。类激活热力图是与特定输出类别相关的二维分数网格，对任何输入图像的每个位置都要进行计算，它表示每个位置对该类别的重要程度。举例来说，对于输入到猫狗分类卷积神经网络的一张图像，CAM 可视化可以生成类别“猫”的热力图，表示图像的各个部分与“猫”的相似程度，CAM 可视化也会生成类别“狗”的热力图，表示图像的各个部分与“狗”的相似程度。</p>
<p>我们将使用的具体实现方式是“Grad-CAM: visual explanations from deep networks via gradientbasedlocalization”a 这篇论文中描述的方法。这种方法非常简单：给定一张输入图像，对于一个卷积层的输出特征图，用类别相对于通道的梯度对这个特征图中的每个通道进行加权。直观上来看，理解这个技巧的一种方法是，你是用“每个通道对类别的重要程度”对“输入图像对不同通道的激活强度”的空间图进行加权，从而得到了“输入图像对类别的激活强度”的空间图。</p>
<p>我们再次使用预训练的<code>VGG16</code>网络来演示此方法。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 加载带有预训练权重的VGG16网络</span></span><br><span class="line"><span class="keyword">from</span> keras.applications.vgg16 <span class="keyword">import</span> VGG16</span><br><span class="line">model = VGG16(weights=<span class="string">'imagenet'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5
553467904/553467096 [==============================] - 441s 1us/step
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 为VGG16模型预处理一张输入图像</span></span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"><span class="keyword">from</span> keras.applications.vgg16 <span class="keyword">import</span> preprocess_input, decode_predictions</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">img_path = <span class="string">'data/pic_input/elephant1.jpg'</span></span><br><span class="line">img = image.load_img(img_path, target_size=(<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">x = image.img_to_array(img)</span><br><span class="line">x = np.expand_dims(x, axis=<span class="number">0</span>)</span><br><span class="line">x = preprocess_input(x)</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\elephant1.jpg" width="200" height="200" alt="非洲象" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">非洲象</div>
</center>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">preds = model.predict(x)</span><br><span class="line">print(<span class="string">'Predicted:'</span>, decode_predictions(preds, top=<span class="number">3</span>)[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<pre><code>Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json
40960/35363 [==================================] - 0s 3us/step
Predicted: [(&#39;n02504458&#39;, &#39;African_elephant&#39;, 0.87728226), (&#39;n01871265&#39;, &#39;tusker&#39;, 0.11725453), (&#39;n02504013&#39;, &#39;Indian_elephant&#39;, 0.0054599163)]
</code></pre><p>对这张图像预测的前三个类别分别为：</p>
<ul>
<li>非洲象（African elephant，87.728226% 的概率）</li>
<li>长牙动物（tusker，11.725453% 的概率）</li>
<li>印度象（Indian elephant，0.54599163%的概率）</li>
</ul>
<p>网络识别出图像中包含数量不确定的非洲象。预测向量中被最大激活的元素是对应“非洲象”类别的元素，索引编号为386。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.argmax(preds[<span class="number">0</span>])</span><br><span class="line">    <span class="comment"># 386</span></span><br></pre></td></tr></table></figure>
<p>为了展示图像中哪些部分最像非洲象，我们来使用<code>Grad-CAM</code>算法。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">african_elephant_output = model.output[:, <span class="number">386</span>]</span><br><span class="line">last_conv_layer = model.get_layer(<span class="string">'block5_conv3'</span>)</span><br><span class="line">grads = K.gradients(african_elephant_output, last_conv_layer.output)[<span class="number">0</span>]</span><br><span class="line">pooled_grads = K.mean(grads, axis=(<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">iterate = K.function([model.input],[pooled_grads, last_conv_layer.output[<span class="number">0</span>]])</span><br><span class="line">pooled_grads_value, conv_layer_output_value = iterate([x])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">512</span>):</span><br><span class="line">    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]</span><br><span class="line">heatmap = np.mean(conv_layer_output_value, axis=<span class="number">-1</span>)</span><br></pre></td></tr></table></figure>
<p>为了便于可视化，我们还需要将热力图标准化到<code>0~1</code>范围内。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">heatmap = np.maximum(heatmap, <span class="number">0</span>)</span><br><span class="line">heatmap /= np.max(heatmap)</span><br><span class="line">plt.matshow(heatmap)</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_120_1.png" width="400" height="400" alt="b" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>



<p>最后，我们可以用OpenCV 来生成一张图像，将原始图像叠加在刚刚得到的热力图上</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">img = cv2.imread(img_path)</span><br><span class="line">heatmap = cv2.resize(heatmap, (img.shape[<span class="number">1</span>], img.shape[<span class="number">0</span>]))</span><br><span class="line">heatmap = np.uint8(<span class="number">255</span> * heatmap)</span><br><span class="line">heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)</span><br><span class="line">superimposed_img = heatmap * <span class="number">0.4</span> + img</span><br><span class="line">cv2.imwrite(<span class="string">'data/pic_output/elephant_cam.jpg'</span>, superimposed_img)</span><br><span class="line">    <span class="comment"># True</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cv2.imshow(<span class="string">'合并后的图像'</span>, superimposed_img)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>) </span><br><span class="line">    <span class="comment"># -1</span></span><br></pre></td></tr></table></figure>
<h1 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h1><ul>
<li>卷积神经网络是解决视觉分类问题的最佳工具。</li>
<li>卷积神经网络通过学习模块化模式和概念的层次结构来表示视觉世界。</li>
<li>卷积神经网络学到的表示很容易可视化，卷积神经网络不是黑盒。</li>
<li>现在你能够从头开始训练自己的卷积神经网络来解决图像分类问题。</li>
<li>你知道了如何使用视觉数据增强来防止过拟合。</li>
<li>你知道了如何使用预训练的卷积神经网络进行特征提取与模型微调。</li>
<li>你可以将卷积神经网络学到的过滤器可视化，也可以将类激活热力图可视化。</li>
</ul>
]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
  </entry>
  <entry>
    <title>算法复现（一）—— 快速排序算法</title>
    <url>/posts/f019e32d.html</url>
    <content><![CDATA[<p>快速排序是我们在面试时常常遇到的算法，我们接下来首先介绍快速排序的基本思想，然后手撸一遍快速排序算法，最后我们介绍一些特殊情景的应用。</p>
<h1 id="快速排序介绍"><a href="#快速排序介绍" class="headerlink" title="快速排序介绍"></a>快速排序介绍</h1><p>快速排序算法是冒泡排序算法的一种改进，其主要思想是通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据比另一部分所有数据小，整个过程可以递归进行，最终使整个数据变成有序序列。但快速排序是一种不稳定的排序算法，即相同元素不能保序，因此在一些实际场景中不能进行使用。</p>
<h1 id="快排实现步骤"><a href="#快排实现步骤" class="headerlink" title="快排实现步骤"></a>快排实现步骤</h1><ol>
<li>在数据集之中，选择一个元素作为“基准”（pivot）<br>· 可以选择第一个元素或随机选择一个元素，但最好随机选择<br>· 算法最坏情况复杂度为 $O(n^2)$，平均复杂度为$O(nlogn)$，其中 $n$ 为 partition 操作，$logn$ 为树的深度</li>
<li>所有小于“基准”的元素，都移到“基准”的左边；所有大于“基准”的元素，都移到“基准”的右边。这个操作称为”分区“（partition）<br>·    分区操作结束后，基准元素所处的位置就是最终排序后它的位置<br>·    partition 操作有两种方法：挖坑法和指针交换法</li>
<li>对“基准”左边和右边两个子集，不断重复第一步和第二步，直到所有子集只剩下一个元素为止</li>
</ol>
<h1 id="Partition-操作"><a href="#Partition-操作" class="headerlink" title="Partition 操作"></a>Partition 操作</h1><p>下图是 Partition 操作的主要方式，下面分别介绍两种方法 —— 挖坑法和指针交换法。</p>
<p><img src="https://img-blog.csdn.net/20180826153323609?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hX2hhbnFpYW5uYW4=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70#pic_center" alt="挖坑法"></p>
<h3 id="挖坑法"><a href="#挖坑法" class="headerlink" title="挖坑法"></a>挖坑法</h3><p>首先我们的数组元素排序如下：<br><img src="https://img-blog.csdn.net/20180826155543836?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hX2hhbnFpYW5uYW4=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70#pic_center" alt="数组元素"></p>
<p>首先我们选定基准元素Pivot，并记住这个位置index，这个位置相当于一个“坑”，并且设置两个指针 left 和 right ，指向数列的最左和最右两个元素。</p>
<p><img src="https://img-blog.csdn.net/20180826160755113?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hX2hhbnFpYW5uYW4=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70#pic_center" alt="第一步"></p>
<p>接下来，从right指针开始，把指针所指向的元素和基准元素做比较。如果比pivot大，则right指针向左移动；如果比pivot小，则把right所指向的元素填入坑中。两个指针接触时算法停止。</p>
<p>4&gt;2，所以4的位置不变，将right指针左移继续比较，right右边黄色的区域代表着大于基准元素的区域。</p>
<p>1&lt;2，所以把1填入基准元素所在位置，也就是坑的位置。这时候，元素1本来所在的位置成为了新的坑。同时，left向右移动一位。</p>
<p>此时，left左边绿色的区域代表着小于基准元素的区域，接下来，我们切换到left指针进行比较。如果left指向的元素小于pivot，则left指针向右移动；如果元素大于pivot，则把left指向的元素填入坑中。</p>
<p><img src="https://img-blog.csdn.net/20180826163431457?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hX2hhbnFpYW5uYW4=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70#pic_center" alt="第二步"></p>
<p>下面是挖坑法另一个例子，来自<a href="https://www.cnblogs.com/qq931399960/p/9550026.html" target="_blank" rel="noopener">这篇博客</a></p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWcyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvNTYyMDMwLzIwMTgxMi81NjIwMzAtMjAxODEyMDYxNzIxMzM5MDctMTkzNDE2NzExMi5wbmc?x-oss-process=image/format,png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="指针交换法"><a href="#指针交换法" class="headerlink" title="指针交换法"></a>指针交换法</h3><p>指针交换法的思想是同时遍历左右边，交换不满足条件的两个元素，下面的例子同样来自<a href="https://www.cnblogs.com/qq931399960/p/9550026.html" target="_blank" rel="noopener">这篇博客</a>：</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWcyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvNTYyMDMwLzIwMTgxMi81NjIwMzAtMjAxODEyMDYxODIzMjU5MDAtMTU3MTgyMjY5MS5wbmc?x-oss-process=image/format,png#pic_center" alt="在这里插入图片描述"></p>
<p>由于上面的图片讲的已经很清楚了，这里就不再进行讲解，下面直接上代码。</p>
<h1 id="快速排序代码实现"><a href="#快速排序代码实现" class="headerlink" title="快速排序代码实现"></a>快速排序代码实现</h1><p>下面提供一个最简单的实现，想要寻求刺激的可以直接看下一节。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quickSort</span><span class="params">(arr)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(arr) &lt; <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> arr</span><br><span class="line">    pivot = arr[random.randint(<span class="number">0</span>,<span class="number">9</span>)]</span><br><span class="line">    left, right = [], []</span><br><span class="line">    arr.remove(pivot)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> arr:</span><br><span class="line">        <span class="keyword">if</span> item &gt;= pivot:</span><br><span class="line">            right.append(item)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            left.append(item)</span><br><span class="line">    <span class="keyword">return</span> quickSort(left) + pivot + quickSort(right)</span><br></pre></td></tr></table></figure>
<h1 id="快速排序的应用"><a href="#快速排序的应用" class="headerlink" title="快速排序的应用"></a>快速排序的应用</h1><p>我们首先看到 leetcode 的215题：</p>
<p><img src="https://img-blog.csdnimg.cn/2020051122003223.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="Leetcode"></p>
<p>这个题我们可以用快速排序的思维来解题。我们在进行快速排序时，每进行一次 Partition，我们就能知道该基准元素的最终位置，因此我们只需要找到排名第二的元素即可，我们来看一下这个题的代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findKthLargest</span><span class="params">(self, nums, k)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :type k: int</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self._k = len(nums) - k</span><br><span class="line">        <span class="keyword">return</span> self.quickSort(nums, <span class="number">0</span>, len(nums)<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">quickSort</span><span class="params">(self, nums, left, right)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> left == right:</span><br><span class="line">            <span class="keyword">return</span> nums[left]</span><br><span class="line">        pivot = self.partition(nums, left, right)</span><br><span class="line">        <span class="keyword">if</span> pivot == self._k:</span><br><span class="line">            <span class="keyword">return</span> nums[pivot]</span><br><span class="line">        <span class="keyword">elif</span> pivot &lt; self._k:</span><br><span class="line">            <span class="keyword">return</span> self.quickSort(nums, pivot+<span class="number">1</span>, right)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.quickSort(nums, left, pivot<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">partition</span><span class="params">(self, nums, left, right)</span>:</span></span><br><span class="line">        pivot = nums[left]</span><br><span class="line">        i, j = left, right</span><br><span class="line">        <span class="keyword">while</span> i &lt; j:</span><br><span class="line">            <span class="keyword">while</span> i &lt; j <span class="keyword">and</span> nums[j] &gt;= pivot:</span><br><span class="line">                j -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> i &lt; j:</span><br><span class="line">                nums[i] = nums[j]</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> i &lt; j <span class="keyword">and</span> nums[i] &lt;= pivot:</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> i &lt; j:</span><br><span class="line">                nums[j] = nums[i]</span><br><span class="line">                j -= <span class="number">1</span></span><br><span class="line">        nums[i] = pivot</span><br><span class="line">        <span class="keyword">return</span> i</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
  </entry>
  <entry>
    <title>Python深度学习（一）神经网络入门</title>
    <url>/posts/d8ee3b71.html</url>
    <content><![CDATA[<h1 id="一、电影评论分类：二分类问题"><a href="#一、电影评论分类：二分类问题" class="headerlink" title="一、电影评论分类：二分类问题"></a>一、电影评论分类：二分类问题</h1><p>二分类问题可能是应用最广泛的机器学习问题。在这个例子中，你将学习根据电影评论的文字内容将其划分为正面或负面。</p>
<h2 id="1-IMDB-数据集"><a href="#1-IMDB-数据集" class="headerlink" title="1. IMDB 数据集"></a>1. IMDB 数据集</h2><p>本节使用IMDB 数据集，它包含来自互联网电影数据库（IMDB）的50 000条严重两极分化的评论。数据集被分为用于训练的25 000 条评论与用于测试的25 000 条评论，训练集和测试集都包含50% 的正面评论和50% 的负面评论。</p>
<p>为什么要将训练集和测试集分开？因为你不应该将训练机器学习模型的同一批数据再用于测试模型！模型在训练数据上的表现很好，并不意味着它在前所未见的数据上也会表现得很好，而且你真正关心的是模型在新数据上的性能（因为你已经知道了训练数据对应的标签，显然不再需要模型来进行预测）。例如，你的模型最终可能只是记住了训练样本和目标值之间的映射关系，但这对在前所未见的数据上进行预测毫无用处。后面将会更详细地讨论这一点。</p>
<p>与MNIST 数据集一样，IMDB 数据集也内置于Keras 库。它已经过预处理：评论（单词序列）已经被转换为整数序列，其中每个整数代表字典中的某个单词。</p>
<p>下列代码将会加载IMDB 数据集（第一次运行时会下载大约80MB 的数据）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> imdb</span><br><span class="line">(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=<span class="number">10000</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Using TensorFlow backend.
</code></pre><p>参数 <code>num_words=10000</code> 的意思是仅保留训练数据中前10 000个最常出现的单词。低频单词将被舍弃。这样得到的向量数据不会太大，便于处理。</p>
<p><code>train_data</code> 和 <code>test_data</code> 这两个变量都是评论组成的列表，每条评论又是单词索引组成的列表（表示一系列单词）。<code>train_labels</code> 和 <code>test_labels</code> 都是0 和1 组成的列表，其中0代表负面（negative），1 代表正面（positive）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(<span class="string">'train data'</span>, train_data[<span class="number">0</span>], <span class="string">'\ntrain label'</span>, train_labels[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<pre><code>train data [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32] 
train label 1
</code></pre><p>由于限定为前10 000 个最常见的单词，单词索引都不会超过10 000。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">max([max(sequence) <span class="keyword">for</span> sequence <span class="keyword">in</span> train_data])</span><br></pre></td></tr></table></figure>
<pre><code>9999
</code></pre><p>下面这段代码很有意思，你可以将某条评论迅速解码为英文单词。<br>注：</p>
<ol>
<li>索引减去了3，因为0、1、2是为“padding”（填充）、“start of sequence”（序列开始）、“unknown”（未知词）分别保留的索引</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">word_index = imdb.get_word_index()</span><br><span class="line">print(<span class="string">'word index of fawn: '</span>, word_index[<span class="string">'fawn'</span>])</span><br><span class="line">reverse_word_index = dict([(value, key) <span class="keyword">for</span> (key, value) <span class="keyword">in</span> word_index.items()])</span><br><span class="line">print(<span class="string">'the word with index 0, 1, 2 are: '</span>, reverse_word_index[<span class="number">1</span>], reverse_word_index[<span class="number">2</span>], reverse_word_index[<span class="number">3</span>])</span><br><span class="line">decoded_review = <span class="string">' '</span>.join(reverse_word_index.get(i<span class="number">-3</span>,<span class="string">'?'</span>) <span class="keyword">for</span> i <span class="keyword">in</span> train_data[<span class="number">0</span>])</span><br><span class="line">print(<span class="string">'decoded review of the first train data: '</span>, decoded_review)</span><br></pre></td></tr></table></figure>
<pre><code>word index of fawn:  34701
the word with index 0, 1, 2 are:  the and a
decoded review of the first train data:  ? this film was just brilliant casting location scenery story direction everyone&#39;s really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy&#39;s that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don&#39;t you think the whole story was so lovely because it was true and was someone&#39;s life after all that was shared with us all
</code></pre><h2 id="2-准备数据"><a href="#2-准备数据" class="headerlink" title="2. 准备数据"></a>2. 准备数据</h2><p>你不能将整数序列直接输入神经网络。你需要将列表转换为张量。转换方法有以下两种：</p>
<ul>
<li>填充列表，使其具有相同的长度，再将列表转换成形状为 (samples, word_indices)的整数张量，然后网络第一层使用能处理这种整数张量的层（即Embedding层）。</li>
<li>对列表进行 one-hot 编码，将其转换为 0 和 1 组成的向量。举个例子，序列[3, 5]将会被转换为10 000 维向量，只有索引为3 和5 的元素是1，其余元素都是0。然后网络第一层可以用Dense 层，它能够处理浮点数向量数据。</li>
</ul>
<p>下面我们采用后一种方法将数据向量化。为了加深理解，我们可以手动实现这一方法，如下所示。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将整数序列编码为二进制矩阵</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vectorize_sequences</span><span class="params">(sequences, dimension=<span class="number">10000</span>)</span>:</span></span><br><span class="line">    results = np.zeros((len(sequences), dimension))</span><br><span class="line">    <span class="keyword">for</span> i, sequence <span class="keyword">in</span> enumerate(sequences):</span><br><span class="line">        results[i, sequence] = <span class="number">1.</span></span><br><span class="line">    <span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line">x_train = vectorize_sequences(train_data)</span><br><span class="line">x_test = vectorize_sequences(test_data)</span><br></pre></td></tr></table></figure>
<p>样本现在变成了这样：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(x_train[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<pre><code>[0. 1. 1. ... 0. 0. 0.]
</code></pre><p>你还应该将标签向量化，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y_train = np.asarray(train_labels).astype(<span class="string">'float32'</span>)</span><br><span class="line">y_test = np.asarray(test_labels).astype(<span class="string">'float32'</span>)</span><br></pre></td></tr></table></figure>
<p>现在可以将数据输入到神经网络中。</p>
<h2 id="3-构建网络"><a href="#3-构建网络" class="headerlink" title="3. 构建网络"></a>3. 构建网络</h2><p>输入数据是向量，而标签是标量（1 和0），这是你会遇到的最简单的情况。有一类网络在这种问题上表现很好，就是带有<code>relu</code>激活的全连接层（Dense）的简单堆叠，比如<code>Dense(16, activation=&#39;relu&#39;)</code>。</p>
<p>传入<code>Dense</code>层的参数（16）是该层隐藏单元的个数。一个隐藏单元（hidden unit）是该层表示空间的一个维度。每个带有<code>relu</code>激活的<code>Dense</code>层都实现了下列张量运算：<code>output = relu(dot(W, input) + b)</code></p>
<p>16 个隐藏单元对应的权重矩阵<code>W</code>的形状为(input_dimension, 16)，与<code>W</code>做点积相当于将输入数据投影到16 维表示空间中（然后再加上偏置向量<code>b</code>并应用relu 运算）。你可以将表示空间的维度直观地理解为“网络学习内部表示时所拥有的自由度”。隐藏单元越多（即更高维的表示空间），网络越能够学到更加复杂的表示，但网络的计算代价也变得更大，而且可能会导致学到不好的模式（这种模式会提高训练数据上的性能，但不会提高测试数据上的性能）。</p>
<p>对于这种Dense 层的堆叠，你需要确定以下两个关键架构：</p>
<ul>
<li>网络有多少层；</li>
<li>每层有多少个隐藏单元。</li>
</ul>
<p>现在只需要选择下列架构：</p>
<ul>
<li>两个中间层，每层都有 16 个隐藏单元；</li>
<li>第三层输出一个标量，预测当前评论的情感。<br>中间层使用 relu 作为激活函数，最后一层使用 sigmoid 激活以输出一个0~1 范围内的概率值（表示样本的目标值等于1的可能性，即评论为正面的可能性）。 relu（rectified linear unit，整流线性单元）函数将所有负值归零，而sigmoid函数则将任意值“压缩”到<code>[0,1]</code>区间内，其输出值可以看作概率值。</li>
</ul>
<center>
    <img src="\Pic\DeepLearning_Pic\relu1.png" width="400" height="400" alt="整体线性流函数" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">整体线性流函数</div>
</center>

<center>
    <img src="\Pic\DeepLearning_Pic\sigmoid1.png" width="400" height="400" alt="sigmoid函数" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">sigmoid函数</div>
</center>

<p>下图显示了网络的结构：</p>
<center>
    <img src="\Pic\DeepLearning_Pic\structure_imdb_1.png" width="200" height="200" alt="structure_imdb_1" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">三层网络结构</div>
</center>

<h2 id="4-模型定义"><a href="#4-模型定义" class="headerlink" title="4. 模型定义"></a>4. 模型定义</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">"relu"</span>, input_shape=(<span class="number">10000</span>, )))</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">"relu"</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">"sigmoid"</span>))</span><br></pre></td></tr></table></figure>
<p>最后，你需要选择损失函数和优化器。由于你面对的是一个二分类问题，网络输出是一个概率值（网络最后一层使用<code>sigmoid</code>激活函数，仅包含一个单元），那么最好使用<code>binary_crossentropy</code>（二元交叉熵）损失。这并不是唯一可行的选择，比如你还可以使用<code>mean_squared_error</code>（均方误差）。但对于输出概率值的模型，交叉熵（crossentropy）往往是最好的选择。交叉熵是来自于信息论领域的概念，用于衡量概率分布之间的距离，在这个例子中就<br>是真实分布与预测值之间的距离。</p>
<p>下面的步骤是用<code>rmsprop</code>优化器和<code>binary_crossentropy</code>损失函数来配置模型。注意，我们还在训练过程中监控精度。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.compile(optimizer=<span class="string">"rmsprop"</span>, loss=<span class="string">"binary_crossentropy"</span>, metrics=[<span class="string">"accuracy"</span>])</span><br></pre></td></tr></table></figure>
<p>上述代码将优化器、损失函数和指标作为字符串传入，这是因为<code>rmsprop</code>、<code>binary_crossentropy</code>和<code>accuracy</code>都是Keras 内置的一部分。有时你可能希望配置自定义优化器的参数，或者传入自定义的损失函数或指标函数，前者可通过向<code>optimizer</code>参数传入一个优化器类实例来实现</p>
<h2 id="5-划分数据并训练模型"><a href="#5-划分数据并训练模型" class="headerlink" title="5. 划分数据并训练模型"></a>5. 划分数据并训练模型</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x_val = x_train[:<span class="number">10000</span>]</span><br><span class="line">partial_x_train = x_train[<span class="number">10000</span>:]</span><br><span class="line">y_val = y_train[:<span class="number">10000</span>]</span><br><span class="line">partial_y_train = y_train[<span class="number">10000</span>:]</span><br></pre></td></tr></table></figure>
<p>现在使用512 个样本组成的小批量，将模型训练20 个轮次（即对<code>x_train</code>和<code>y_train</code>两个张量中的所有样本进行20 次迭代）。与此同时，你还要监控在留出的10 000 个样本上的损失和精度。你可以通过将验证数据传入<code>validation_data</code>参数来完成。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">history = model.fit(partial_x_train,</span><br><span class="line">                    partial_y_train,</span><br><span class="line">                    epochs=<span class="number">20</span>,</span><br><span class="line">                    batch_size=<span class="number">512</span>,</span><br><span class="line">                    validation_data=(x_val, y_val))</span><br></pre></td></tr></table></figure>
<pre><code>Train on 15000 samples, validate on 10000 samples
Epoch 1/20
15000/15000 [==============================] - 10s 637us/step - loss: 0.5054 - accuracy: 0.7994 - val_loss: 0.3811 - val_accuracy: 0.8697
Epoch 2/20
15000/15000 [==============================] - 6s 402us/step - loss: 0.3009 - accuracy: 0.9039 - val_loss: 0.3074 - val_accuracy: 0.8841
Epoch 3/20
15000/15000 [==============================] - 2s 151us/step - loss: 0.2207 - accuracy: 0.9309 - val_loss: 0.2773 - val_accuracy: 0.8910
Epoch 4/20
15000/15000 [==============================] - 2s 137us/step - loss: 0.1777 - accuracy: 0.9433 - val_loss: 0.2731 - val_accuracy: 0.8912
Epoch 5/20
15000/15000 [==============================] - 2s 129us/step - loss: 0.1428 - accuracy: 0.9555 - val_loss: 0.2797 - val_accuracy: 0.8888
Epoch 6/20
15000/15000 [==============================] - 2s 137us/step - loss: 0.1201 - accuracy: 0.9629 - val_loss: 0.3101 - val_accuracy: 0.8818
Epoch 7/20
15000/15000 [==============================] - 2s 134us/step - loss: 0.1007 - accuracy: 0.9705 - val_loss: 0.3096 - val_accuracy: 0.8817
Epoch 8/20
15000/15000 [==============================] - 2s 129us/step - loss: 0.0845 - accuracy: 0.9768 - val_loss: 0.3309 - val_accuracy: 0.8826
Epoch 9/20
15000/15000 [==============================] - 2s 126us/step - loss: 0.0715 - accuracy: 0.9809 - val_loss: 0.3477 - val_accuracy: 0.8817
Epoch 10/20
15000/15000 [==============================] - 2s 127us/step - loss: 0.0604 - accuracy: 0.9848 - val_loss: 0.3675 - val_accuracy: 0.8788
Epoch 11/20
15000/15000 [==============================] - 2s 125us/step - loss: 0.0504 - accuracy: 0.9879 - val_loss: 0.4077 - val_accuracy: 0.8692
Epoch 12/20
15000/15000 [==============================] - 2s 125us/step - loss: 0.0410 - accuracy: 0.9908 - val_loss: 0.4214 - val_accuracy: 0.8725
Epoch 13/20
15000/15000 [==============================] - 2s 125us/step - loss: 0.0322 - accuracy: 0.9947 - val_loss: 0.4783 - val_accuracy: 0.8704
Epoch 14/20
15000/15000 [==============================] - 2s 125us/step - loss: 0.0291 - accuracy: 0.9939 - val_loss: 0.4782 - val_accuracy: 0.8741
Epoch 15/20
15000/15000 [==============================] - 2s 125us/step - loss: 0.0222 - accuracy: 0.9962 - val_loss: 0.5157 - val_accuracy: 0.8679
Epoch 16/20
15000/15000 [==============================] - 2s 126us/step - loss: 0.0188 - accuracy: 0.9966 - val_loss: 0.5413 - val_accuracy: 0.8714
Epoch 17/20
15000/15000 [==============================] - 2s 125us/step - loss: 0.0120 - accuracy: 0.9990 - val_loss: 0.5762 - val_accuracy: 0.8659
Epoch 18/20
15000/15000 [==============================] - 2s 129us/step - loss: 0.0129 - accuracy: 0.9979 - val_loss: 0.6005 - val_accuracy: 0.8674
Epoch 19/20
15000/15000 [==============================] - 2s 125us/step - loss: 0.0085 - accuracy: 0.9993 - val_loss: 0.6336 - val_accuracy: 0.8689
Epoch 20/20
15000/15000 [==============================] - 2s 124us/step - loss: 0.0070 - accuracy: 0.9993 - val_loss: 0.6647 - val_accuracy: 0.8675
</code></pre><p>在CPU 上运行，每轮的时间不到2秒，训练过程将在20 秒内结束。每轮结束时会有短暂的停顿，因为模型要计算在验证集的10 000 个样本上的损失和精度。</p>
<p>注意，调用<code>model.fit()</code>返回了一个<code>history</code>对象。这个对象有一个成员<code>history</code>，它是一个字典，包含训练过程中的所有数据，我们来看一下。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">history_dict = history.history</span><br><span class="line">history_dict.keys()</span><br></pre></td></tr></table></figure>
<pre><code>dict_keys([&#39;val_loss&#39;, &#39;val_accuracy&#39;, &#39;loss&#39;, &#39;accuracy&#39;])
</code></pre><h2 id="6-绘制训练损失和验证损失"><a href="#6-绘制训练损失和验证损失" class="headerlink" title="6. 绘制训练损失和验证损失"></a>6. 绘制训练损失和验证损失</h2><p>字典中包含4 个条目，对应训练过程和验证过程中监控的指标。我们将使用Matplotlib 在同一张图上绘制训练损失和验证损失，以及训练精度和验证精度。请注意，由于网络的随机初始化不同，你得到的结果可能会略有不同。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">history_dict = history.history</span><br><span class="line">loss_values = history_dict[<span class="string">'loss'</span>]</span><br><span class="line">val_loss_values = history_dict[<span class="string">'val_loss'</span>]</span><br><span class="line">epochs = range(<span class="number">1</span>, len(loss_values)+<span class="number">1</span>)</span><br><span class="line">plt.plot(epochs, loss_values, <span class="string">'bo'</span>, label=<span class="string">'Training loss'</span>)</span><br><span class="line">plt.plot(epochs, val_loss_values, <span class="string">'b'</span>, label=<span class="string">'Validation loss'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation loss'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Epochs'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_26_0.png" width="400" height="400" alt="训练损失和验证损失" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">训练损失和验证损失</div>
</center>


<h2 id="7-绘制训练精度和验证精度"><a href="#7-绘制训练精度和验证精度" class="headerlink" title="7. 绘制训练精度和验证精度"></a>7. 绘制训练精度和验证精度</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.clf()</span><br><span class="line">acc = history_dict[<span class="string">'accuracy'</span>]</span><br><span class="line">val_acc = history_dict[<span class="string">'val_accuracy'</span>]</span><br><span class="line">plt.plot(epochs, acc, <span class="string">'bo'</span>, label=<span class="string">'Training accuracy'</span>)</span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">'b'</span>, label=<span class="string">'Validation accuracy'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation accuracy'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Epochs'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Accuracy'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_28_0.png" width="400" height="400" alt="训练精度和验证精度" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">训练精度和验证精度</div>
</center>


<p>如你所见，训练损失每轮都在降低，训练精度每轮都在提升。这就是梯度下降优化的预期结果——你想要最小化的量随着每次迭代越来越小。但验证损失和验证精度并非如此：它们似乎在第四轮达到最佳值。这就是我们之前警告过的一种情况：模型在训练数据上的表现越来越好，但在前所未见的数据上不一定表现得越来越好。准确地说，你看到的是过拟合（overfit）：在第二轮之后，你对训练数据过度优化，最终学到的表示仅针对于训练数据，无法泛化到训练集之外的数据。</p>
<p>在这种情况下，为了防止过拟合，你可以在3 轮之后停止训练。通常来说，你可以使用许多方法来降低过拟合，我们将在后面详细介绍。</p>
<p>我们从头开始训练一个新的网络，训练4 轮，然后在测试数据上评估模型。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">'relu'</span>, input_shape=(<span class="number">10000</span>,)))</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>, loss=<span class="string">'binary_crossentropy'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">model.fit(x_train, y_train, epochs=<span class="number">4</span>, batch_size=<span class="number">512</span>)</span><br><span class="line">results = model.evaluate(x_test, y_test)</span><br><span class="line">print(results)</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1/4
25000/25000 [==============================] - 3s 100us/step - loss: 0.4556 - accuracy: 0.8245
Epoch 2/4
25000/25000 [==============================] - 2s 78us/step - loss: 0.2628 - accuracy: 0.9074
Epoch 3/4
25000/25000 [==============================] - 2s 81us/step - loss: 0.2002 - accuracy: 0.9290
Epoch 4/4
25000/25000 [==============================] - 2s 88us/step - loss: 0.1687 - accuracy: 0.9394
25000/25000 [==============================] - 7s 270us/step
[0.30153122137069704, 0.880840003490448]
</code></pre><p>这种相当简单的方法得到了88% 的精度。利用最先进的方法，你应该能够得到接近95% 的精度。</p>
<h2 id="8-使用训练好的网络在新数据上生成预测结果"><a href="#8-使用训练好的网络在新数据上生成预测结果" class="headerlink" title="8. 使用训练好的网络在新数据上生成预测结果"></a>8. 使用训练好的网络在新数据上生成预测结果</h2><p>训练好网络之后，你希望将其用于实践。你可以用<code>predict</code>方法来得到评论为正面的可能性大小。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.predict(x_test)</span><br></pre></td></tr></table></figure>
<pre><code>array([[0.17173755],
       [0.99980915],
       [0.77910084],
       ...,
       [0.08216667],
       [0.04566944],
       [0.51742095]], dtype=float32)
</code></pre><h1 id="二、新闻分类：多分类问题"><a href="#二、新闻分类：多分类问题" class="headerlink" title="二、新闻分类：多分类问题"></a>二、新闻分类：多分类问题</h1><p>下面你会构建一个网络，将路透社新闻划分为46 个互斥的主题。因为有多个类别，所以这是多分类（multiclass classification）问题的一个例子。因为每个数据点只能划分到一个类别，所以更具体地说，这是单标签、多分类（single-label, multiclass classification）问题的一个例子。如果每个数据点可以划分到多个类别（主题），那它就是一个多标签、多分类（multilabel,multiclass classification）问题。</p>
<h2 id="1-路透社数据集"><a href="#1-路透社数据集" class="headerlink" title="1. 路透社数据集"></a>1. 路透社数据集</h2><p>本节使用路透社数据集，它包含许多短新闻及其对应的主题，由路透社在1986 年发布。它是一个简单的、广泛使用的文本分类数据集。它包括46 个不同的主题：某些主题的样本更多，但训练集中每个主题都有至少10 个样本。与IMDB 和MNIST 类似，路透社数据集也内置为Keras 的一部分。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> reuters</span><br><span class="line">(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=<span class="number">10000</span>)</span><br><span class="line">print(<span class="string">'the length of train data: '</span>, len(train_data), <span class="string">'\nthe length of test data: '</span>, len(test_data))</span><br><span class="line">print(<span class="string">'train data 10: '</span>, train_data[<span class="number">10</span>], <span class="string">'\ntrain label 10: '</span>, train_labels[<span class="number">10</span>])</span><br></pre></td></tr></table></figure>
<pre><code>the length of train data:  8982 
the length of test data:  2246
train data 10:  [1, 245, 273, 207, 156, 53, 74, 160, 26, 14, 46, 296, 26, 39, 74, 2979, 3554, 14, 46, 4689, 4329, 86, 61, 3499, 4795, 14, 61, 451, 4329, 17, 12] 
train label 10:  3
</code></pre><p>如果好奇的话，你可以用下列代码将索引解码为单词。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">word_index = reuters.get_word_index()</span><br><span class="line">reverse_word_index = dict([(value, key) <span class="keyword">for</span> (key, value) <span class="keyword">in</span> word_index.items()])</span><br><span class="line">decoded_newswire = <span class="string">' '</span>.join([reverse_word_index.get(i - <span class="number">3</span>, <span class="string">'?'</span>) <span class="keyword">for</span> i <span class="keyword">in</span> train_data[<span class="number">0</span>]])</span><br><span class="line">print(decoded_newswire)</span><br></pre></td></tr></table></figure>
<pre><code>? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3
</code></pre><h2 id="2-准备数据-1"><a href="#2-准备数据-1" class="headerlink" title="2. 准备数据"></a>2. 准备数据</h2><p>你可以使用与上一个例子相同的代码将数据向量化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vectorize_sequences</span><span class="params">(sequences, dimension=<span class="number">10000</span>)</span>:</span></span><br><span class="line">    results = np.zeros((len(sequences), dimension))</span><br><span class="line">    <span class="keyword">for</span> i, sequence <span class="keyword">in</span> enumerate(sequences):</span><br><span class="line">        results[i, sequence] = <span class="number">1.</span></span><br><span class="line">    <span class="keyword">return</span> results</span><br><span class="line">x_train = vectorize_sequences(train_data)</span><br><span class="line">x_test = vectorize_sequences(test_data)</span><br></pre></td></tr></table></figure>
<p>将标签向量化有两种方法：你可以将标签列表转换为整数张量，或者使用one-hot 编码。</p>
<p>one-hot 编码是分类数据广泛使用的一种格式，也叫分类编码（categorical encoding）,在这个例子中，标签的one-hot 编码就是将每个标签表示为全零向量，只有标签索引对应的元素为1。其代码实现如下。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">to_one_hot</span><span class="params">(labels, dimension=<span class="number">46</span>)</span>:</span></span><br><span class="line">    results = np.zeros((len(labels), dimension))</span><br><span class="line">    <span class="keyword">for</span> i, label <span class="keyword">in</span> enumerate(labels):</span><br><span class="line">        results[i, label] = <span class="number">1.</span></span><br><span class="line">    <span class="keyword">return</span> results</span><br><span class="line">one_hot_train_labels = to_one_hot(train_labels)</span><br><span class="line">one_hot_test_labels = to_one_hot(test_labels)</span><br></pre></td></tr></table></figure>
<p>注意，Keras 内置方法可以实现这个操作：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.utils.np_utils <span class="keyword">import</span> to_categorical</span><br><span class="line">one_hot_train_labels = to_categorical(train_labels)</span><br><span class="line">one_hot_test_labels = to_categorical(test_labels)</span><br></pre></td></tr></table></figure>
<h2 id="3-构建网络-1"><a href="#3-构建网络-1" class="headerlink" title="3. 构建网络"></a>3. 构建网络</h2><p>这个主题分类问题与前面的电影评论分类问题类似，两个例子都是试图对简短的文本片段进行分类。但这个问题有一个新的约束条件：输出类别的数量从2 个变为46 个。输出空间的维度要大得多。</p>
<p>对于前面用过的Dense 层的堆叠，每层只能访问上一层输出的信息。如果某一层丢失了与分类问题相关的一些信息，那么这些信息无法被后面的层找回，也就是说，每一层都可能成为信息瓶颈。上一个例子使用了16 维的中间层，但对这个例子来说16 维空间可能太小了，无法学会区分46 个不同的类别。这种维度较小的层可能成为信息瓶颈，永久地丢失相关信息。</p>
<p>出于这个原因，下面将使用维度更大的层，包含64 个单元。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>, input_shape=(<span class="number">10000</span>,)))</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">46</span>, activation=<span class="string">'softmax'</span>))</span><br></pre></td></tr></table></figure>
<p>关于这个架构还应该注意另外两点：</p>
<ul>
<li>网络的最后一层是大小为 46 的 <code>Dense</code> 层。这意味着，对于每个输入样本，网络都会输出一个46 维向量。这个向量的每个元素（即每个维度）代表不同的输出类别。</li>
<li>最后一层使用了 <code>softmax</code> 激活。你在 MNIST 例子中见过这种用法。网络将输出在 46个不同输出类别上的概率分布——对于每一个输入样本，网络都会输出一个46 维向量，其中<code>output[i]</code>是样本属于第<code>i</code>个类别的概率。46 个概率的总和为1。</li>
</ul>
<p>对于这个例子，最好的损失函数是<code>categorical_crossentropy</code>（分类交叉熵）。它用于衡量两个概率分布之间的距离，这里两个概率分布分别是网络输出的概率分布和标签的真实分布。通过将这两个分布的距离最小化，训练网络可使输出结果尽可能接近真实标签。</p>
<h2 id="4-编译模型"><a href="#4-编译模型" class="headerlink" title="4. 编译模型"></a>4. 编译模型</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>,</span><br><span class="line">            loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">            metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure>
<h2 id="5-验证你的方法"><a href="#5-验证你的方法" class="headerlink" title="5. 验证你的方法"></a>5. 验证你的方法</h2><p>我们在训练数据中留出1000 个样本作为验证集。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x_val = x_train[:<span class="number">1000</span>]</span><br><span class="line">partial_x_train = x_train[<span class="number">1000</span>:]</span><br><span class="line">y_val = one_hot_train_labels[:<span class="number">1000</span>]</span><br><span class="line">partial_y_train = one_hot_train_labels[<span class="number">1000</span>:]</span><br></pre></td></tr></table></figure>
<p>现在开始训练网络，共20 个轮次。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">history = model.fit(partial_x_train,</span><br><span class="line">                    partial_y_train,</span><br><span class="line">                    epochs=<span class="number">20</span>,</span><br><span class="line">                    batch_size=<span class="number">512</span>,</span><br><span class="line">                    validation_data=(x_val, y_val))</span><br></pre></td></tr></table></figure>
<pre><code>Train on 7982 samples, validate on 1000 samples
Epoch 1/20
7982/7982 [==============================] - 2s 197us/step - loss: 2.7220 - accuracy: 0.5438 - val_loss: 1.7716 - val_accuracy: 0.6510
Epoch 2/20
7982/7982 [==============================] - 1s 90us/step - loss: 1.4464 - accuracy: 0.7068 - val_loss: 1.3297 - val_accuracy: 0.7160
Epoch 3/20
7982/7982 [==============================] - 1s 90us/step - loss: 1.0637 - accuracy: 0.7737 - val_loss: 1.1569 - val_accuracy: 0.7520
Epoch 4/20
7982/7982 [==============================] - 1s 92us/step - loss: 0.8311 - accuracy: 0.8247 - val_loss: 1.0649 - val_accuracy: 0.7690
Epoch 5/20
7982/7982 [==============================] - 1s 90us/step - loss: 0.6618 - accuracy: 0.8629 - val_loss: 0.9799 - val_accuracy: 0.7900
Epoch 6/20
7982/7982 [==============================] - 1s 90us/step - loss: 0.5263 - accuracy: 0.8905 - val_loss: 0.9437 - val_accuracy: 0.7910
Epoch 7/20
7982/7982 [==============================] - 1s 91us/step - loss: 0.4242 - accuracy: 0.9118 - val_loss: 0.9042 - val_accuracy: 0.8170
Epoch 8/20
7982/7982 [==============================] - 1s 92us/step - loss: 0.3445 - accuracy: 0.9295 - val_loss: 0.8994 - val_accuracy: 0.8200
Epoch 9/20
7982/7982 [==============================] - 1s 90us/step - loss: 0.2905 - accuracy: 0.9365 - val_loss: 0.9082 - val_accuracy: 0.8180
Epoch 10/20
7982/7982 [==============================] - 1s 89us/step - loss: 0.2414 - accuracy: 0.9437 - val_loss: 0.9217 - val_accuracy: 0.8090
Epoch 11/20
7982/7982 [==============================] - 1s 91us/step - loss: 0.2108 - accuracy: 0.9474 - val_loss: 0.9495 - val_accuracy: 0.8210
Epoch 12/20
7982/7982 [==============================] - 1s 91us/step - loss: 0.1879 - accuracy: 0.9530 - val_loss: 0.9722 - val_accuracy: 0.7960
Epoch 13/20
7982/7982 [==============================] - 1s 89us/step - loss: 0.1656 - accuracy: 0.9526 - val_loss: 1.0056 - val_accuracy: 0.7950
Epoch 14/20
7982/7982 [==============================] - 1s 91us/step - loss: 0.1504 - accuracy: 0.9545 - val_loss: 0.9687 - val_accuracy: 0.8090
Epoch 15/20
7982/7982 [==============================] - 1s 88us/step - loss: 0.1433 - accuracy: 0.9563 - val_loss: 1.0085 - val_accuracy: 0.8090
Epoch 16/20
7982/7982 [==============================] - 1s 90us/step - loss: 0.1312 - accuracy: 0.9551 - val_loss: 1.0123 - val_accuracy: 0.8040
Epoch 17/20
7982/7982 [==============================] - 1s 93us/step - loss: 0.1249 - accuracy: 0.9577 - val_loss: 1.0555 - val_accuracy: 0.8010
Epoch 18/20
7982/7982 [==============================] - 1s 90us/step - loss: 0.1226 - accuracy: 0.9554 - val_loss: 1.0423 - val_accuracy: 0.8000
Epoch 19/20
7982/7982 [==============================] - 1s 91us/step - loss: 0.1163 - accuracy: 0.9572 - val_loss: 1.0554 - val_accuracy: 0.8000
Epoch 20/20
7982/7982 [==============================] - 1s 113us/step - loss: 0.1086 - accuracy: 0.9588 - val_loss: 1.1368 - val_accuracy: 0.7790
</code></pre><h2 id="6-绘制图像"><a href="#6-绘制图像" class="headerlink" title="6. 绘制图像"></a>6. 绘制图像</h2><p>最后，我们来绘制损失曲线和精度曲线</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">loss = history.history[<span class="string">'loss'</span>]</span><br><span class="line">val_loss = history.history[<span class="string">'val_loss'</span>]</span><br><span class="line">epochs = range(<span class="number">1</span>, len(loss) + <span class="number">1</span>)</span><br><span class="line">plt.plot(epochs, loss, <span class="string">'bo'</span>, label=<span class="string">'Training loss'</span>)</span><br><span class="line">plt.plot(epochs, val_loss, <span class="string">'b'</span>, label=<span class="string">'Validation loss'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation loss'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Epochs'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_53_0.png" width="400" height="400" alt="训练损失和验证损失" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">训练损失和验证损失</div>
</center>



<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.clf()</span><br><span class="line">acc = history.history[<span class="string">'accuracy'</span>]</span><br><span class="line">val_acc = history.history[<span class="string">'val_accuracy'</span>]</span><br><span class="line">plt.plot(epochs, acc, <span class="string">'bo'</span>, label=<span class="string">'Training accuracy'</span>)</span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">'b'</span>, label=<span class="string">'Validation accuracy'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation accuracy'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Epochs'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Accuracy'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_54_0.png" width="400" height="400" alt="训练精度和验证精度" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">训练精度和验证精度</div>
</center>


<p>网络在训练9轮后开始过拟合。我们从头开始训练一个新网络，共9个轮次，然后在测试集上评估模型。</p>
<h2 id="7-从头开始重新训练一个模型"><a href="#7-从头开始重新训练一个模型" class="headerlink" title="7. 从头开始重新训练一个模型"></a>7. 从头开始重新训练一个模型</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>, input_shape=(<span class="number">10000</span>,)))</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">46</span>, activation=<span class="string">'softmax'</span>))</span><br><span class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>,</span><br><span class="line">            loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">            metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">model.fit(partial_x_train,</span><br><span class="line">        partial_y_train,</span><br><span class="line">        epochs=<span class="number">9</span>,</span><br><span class="line">        batch_size=<span class="number">512</span>,</span><br><span class="line">        validation_data=(x_val, y_val))</span><br><span class="line">results = model.evaluate(x_test, one_hot_test_labels)</span><br></pre></td></tr></table></figure>
<pre><code>Train on 7982 samples, validate on 1000 samples
Epoch 1/9
7982/7982 [==============================] - 1s 116us/step - loss: 2.7007 - accuracy: 0.5041 - val_loss: 1.7970 - val_accuracy: 0.6230
Epoch 2/9
7982/7982 [==============================] - 1s 103us/step - loss: 1.4223 - accuracy: 0.7050 - val_loss: 1.3018 - val_accuracy: 0.7210
Epoch 3/9
7982/7982 [==============================] - 1s 106us/step - loss: 1.0310 - accuracy: 0.7791 - val_loss: 1.1309 - val_accuracy: 0.7470
Epoch 4/9
7982/7982 [==============================] - 1s 106us/step - loss: 0.8089 - accuracy: 0.8242 - val_loss: 1.0300 - val_accuracy: 0.7800
Epoch 5/9
7982/7982 [==============================] - 1s 124us/step - loss: 0.6437 - accuracy: 0.8629 - val_loss: 0.9679 - val_accuracy: 0.7970
Epoch 6/9
7982/7982 [==============================] - 1s 116us/step - loss: 0.5177 - accuracy: 0.8931 - val_loss: 0.9502 - val_accuracy: 0.8040
Epoch 7/9
7982/7982 [==============================] - 1s 125us/step - loss: 0.4128 - accuracy: 0.9143 - val_loss: 0.9156 - val_accuracy: 0.8060
Epoch 8/9
7982/7982 [==============================] - 1s 123us/step - loss: 0.3394 - accuracy: 0.9267 - val_loss: 0.9121 - val_accuracy: 0.8110
Epoch 9/9
7982/7982 [==============================] - 1s 136us/step - loss: 0.2785 - accuracy: 0.9386 - val_loss: 0.8915 - val_accuracy: 0.8110
2246/2246 [==============================] - 0s 156us/step
</code></pre><p>这种方法可以得到约80% 的精度。对于平衡的二分类问题，完全随机的分类器能够得到50% 的精度。但在这个例子中，完全随机的精度约为19%，所以上述结果相当不错，至少和随机的基准比起来还不错。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> copy</span><br><span class="line">test_labels_copy = copy.copy(test_labels)</span><br><span class="line">np.random.shuffle(test_labels_copy)</span><br><span class="line">hits_array = np.array(test_labels) == np.array(test_labels_copy)</span><br><span class="line">float(np.sum(hits_array)) / len(test_labels)</span><br></pre></td></tr></table></figure>
<pre><code>0.18655387355298308
</code></pre><h2 id="8-在新数据上生成预测结果"><a href="#8-在新数据上生成预测结果" class="headerlink" title="8. 在新数据上生成预测结果"></a>8. 在新数据上生成预测结果</h2><p>你可以验证，模型实例的<code>predict</code>方法返回了在46 个主题上的概率分布。我们对所有测试数据生成主题预测。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">predictions = model.predict(x_test)</span><br></pre></td></tr></table></figure>
<p>predictions 中的每个元素都是长度为46 的向量</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">predictions[<span class="number">0</span>].shape</span><br></pre></td></tr></table></figure>
<pre><code>(46,)
</code></pre><p>最大的元素就是预测类别，即概率最大的类别。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.argmax(predictions[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<pre><code>3
</code></pre><h2 id="9-处理标签和损失的另一种方法"><a href="#9-处理标签和损失的另一种方法" class="headerlink" title="9. 处理标签和损失的另一种方法"></a>9. 处理标签和损失的另一种方法</h2><p>前面提到了另一种编码标签的方法，就是将其转换为整数张量，如下所示。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y_train = np.array(train_labels)</span><br><span class="line">y_test = np.array(test_labels)</span><br></pre></td></tr></table></figure><br>对于这种编码方法，唯一需要改变的是损失函数的选择。对于代码清单3-21 使用的损失函数<code>categorical_crossentropy</code>，标签应该遵循分类编码。对于整数标签，你应该使用<code>sparse_categorical_crossentropy</code>。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>,</span><br><span class="line">loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">metrics=[<span class="string">'acc'</span>])</span><br></pre></td></tr></table></figure><br>这个新的损失函数在数学上与<code>categorical_crossentropy</code>完全相同，二者只是接口不同</p>
<h1 id="三、预测房价：回归问题"><a href="#三、预测房价：回归问题" class="headerlink" title="三、预测房价：回归问题"></a>三、预测房价：回归问题</h1><p>前面两个例子都是分类问题，其目标是预测输入数据点所对应的单一离散的标签。另一种常见的机器学习问题是回归问题，它预测一个连续值而不是离散的标签，例如，根据气象数据预测明天的气温，或者根据软件说明书预测完成软件项目所需要的时间。</p>
<h2 id="1-波士顿房价数据集"><a href="#1-波士顿房价数据集" class="headerlink" title="1. 波士顿房价数据集"></a>1. 波士顿房价数据集</h2><p>下面将要预测20 世纪70 年代中期波士顿郊区房屋价格的中位数，已知当时郊区的一些数据点，比如犯罪率、当地房产税率等。</p>
<p>该数据集包含的数据点相对较少，只有506 个，分为404 个训练样本和102 个测试样本。输入数据的每个特征（比如犯罪率）都有不同的取值范围。例如，有些特性是比例，取值范围为0~1；有的取值范围为1~12；还有的取值范围为0~100，等等。</p>
<h2 id="2-加载波士顿房价数据"><a href="#2-加载波士顿房价数据" class="headerlink" title="2. 加载波士顿房价数据"></a>2. 加载波士顿房价数据</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> boston_housing</span><br><span class="line">(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()</span><br><span class="line">print(train_data.shape, test_data.shape)</span><br></pre></td></tr></table></figure>
<pre><code>(404, 13) (102, 13)
</code></pre><p>如你所见，我们有404 个训练样本和102 个测试样本，每个样本都有13 个数值特征，比如人均犯罪率、每个住宅的平均房间数、高速公路可达性等。</p>
<p>目标函数是房屋价格的中位数，单位是千美元。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_targets[:<span class="number">20</span>]</span><br></pre></td></tr></table></figure>
<pre><code>array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,
       17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5])
</code></pre><p>房价大都在10 000~50 000 美元。如果你觉得这很便宜，不要忘记当时是20 世纪70 年代中期，而且这些价格没有根据通货膨胀进行调整。</p>
<h2 id="3-准备数据"><a href="#3-准备数据" class="headerlink" title="3. 准备数据"></a>3. 准备数据</h2><p>将取值范围差异很大的数据输入到神经网络中，这是有问题的。网络可能会自动适应这种取值范围不同的数据，但学习肯定变得更加困难。对于这种数据，普遍采用的最佳实践是对每个特征做标准化，即对于输入数据的每个特征（输入数据矩阵中的列），减去特征平均值，再除以标准差，这样得到的特征平均值为0，标准差为1。用Numpy 可以很容易实现标准化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数据标准化</span></span><br><span class="line">mean = train_data.mean(axis=<span class="number">0</span>)</span><br><span class="line">train_data -= mean</span><br><span class="line">std = train_data.std(axis=<span class="number">0</span>)</span><br><span class="line">train_data /= std</span><br><span class="line">test_data -= mean</span><br><span class="line">test_data /= std</span><br></pre></td></tr></table></figure>
<p>注意，用于测试数据标准化的均值和标准差都是在训练数据上计算得到的。在工作流程中，你不能使用在测试数据上计算得到的任何结果，即使是像数据标准化这么简单的事情也不行。</p>
<h2 id="4-构建网络"><a href="#4-构建网络" class="headerlink" title="4. 构建网络"></a>4. 构建网络</h2><p>由于样本数量很少，我们将使用一个非常小的网络，其中包含两个隐藏层，每层有64 个单元。一般来说，训练数据越少，过拟合会越严重，而较小的网络可以降低过拟合。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 模型定义</span></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_model</span><span class="params">()</span>:</span></span><br><span class="line">    model = models.Sequential()</span><br><span class="line">    model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>, input_shape=(train_data.shape[<span class="number">1</span>],)))</span><br><span class="line">    model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">    model.add(layers.Dense(<span class="number">1</span>))</span><br><span class="line">    model.compile(optimizer=<span class="string">'rmsprop'</span>, loss=<span class="string">'mse'</span>, metrics=[<span class="string">'mae'</span>])</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<p>网络的最后一层只有一个单元，<strong>没有激活</strong>，是一个线性层。这是标量回归（标量回归是预测单一连续值的回归）的典型设置。添加激活函数将会限制输出范围。例如，如果向最后一层添加sigmoid 激活函数，网络只能学会预测0~1 范围内的值。这里最后一层是纯线性的，所以网络可以学会预测任意范围内的值。</p>
<p>注意，编译网络用的是<code>mse</code>损失函数，即均方误差（MSE，mean squared error），预测值与目标值之差的平方。这是回归问题常用的损失函数。</p>
<p>在训练过程中还监控一个新指标：平均绝对误差（MAE，mean absolute error）。它是预测值与目标值之差的绝对值。比如，如果这个问题的MAE 等于0.5，就表示你预测的房价与实际价格平均相差500 美元。</p>
<h2 id="5-利用K折验证来验证你的方法"><a href="#5-利用K折验证来验证你的方法" class="headerlink" title="5. 利用K折验证来验证你的方法"></a>5. 利用K折验证来验证你的方法</h2><p>为了在调节网络参数（比如训练的轮数）的同时对网络进行评估，你可以将数据划分为训练集和验证集，正如前面例子中所做的那样。但由于数据点很少，验证集会非常小（比如大约100 个样本）。因此，验证分数可能会有很大波动，这取决于你所选择的验证集和训练集。也就是说，验证集的划分方式可能会造成验证分数上有很大的方差，这样就无法对模型进行可靠的评估。</p>
<center>
    <img src="\Pic\DeepLearning_Pic\k-fold.png" width="400" height="400" alt="k-fold" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">k折验证</div>
</center>

<p>在这种情况下，最佳做法是使用<code>K</code>折交叉验证。这种方法将可用数据划分为<code>K</code>个分区（<code>K</code>通常取4 或5），实例化<code>K</code>个相同的模型，将每个模型在<code>K-1</code>个分区上训练，并在剩下的一个分区上进行评估。模型的验证分数等于<code>K</code>个验证分数的平均值。这种方法的代码实现很简单：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">k = <span class="number">4</span></span><br><span class="line">num_val_samples = len(train_data) // k</span><br><span class="line">num_epochs = <span class="number">100</span></span><br><span class="line">all_scores = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">    print(<span class="string">'processing fold #'</span>, i)</span><br><span class="line">    val_data = train_data[i * num_val_samples: (i + <span class="number">1</span>) * num_val_samples]</span><br><span class="line">    val_targets = train_targets[i * num_val_samples: (i + <span class="number">1</span>) * num_val_samples]</span><br><span class="line">    partial_train_data = np.concatenate([train_data[:i * num_val_samples],train_data[(i + <span class="number">1</span>) * num_val_samples:]],axis=<span class="number">0</span>)</span><br><span class="line">    partial_train_targets = np.concatenate([train_targets[:i * num_val_samples],train_targets[(i + <span class="number">1</span>) * num_val_samples:]],axis=<span class="number">0</span>)</span><br><span class="line">    model = build_model()</span><br><span class="line">    model.fit(partial_train_data, partial_train_targets,</span><br><span class="line">    epochs=num_epochs, batch_size=<span class="number">1</span>, verbose=<span class="number">0</span>)</span><br><span class="line">    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=<span class="number">0</span>)</span><br><span class="line">    all_scores.append(val_mae)</span><br></pre></td></tr></table></figure>
<pre><code>processing fold # 0
processing fold # 1
processing fold # 2
processing fold # 3
</code></pre><p>运行结果如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(<span class="string">'所有得分：'</span>, all_scores, <span class="string">'\n平均值为'</span>, np.mean(all_scores))</span><br></pre></td></tr></table></figure>
<pre><code>所有得分： [2.0891380310058594, 2.6256139278411865, 2.7675087451934814, 2.588402271270752] 
平均值为 2.51766574382782
</code></pre><p>每次运行模型得到的验证分数有很大差异，从2.6 到3.2 不等。平均分数（3.0）是比单一分数更可靠的指标——这就是K 折交叉验证的关键。在这个例子中，预测的房价与实际价格平均相差3000 美元，考虑到实际价格范围在10 000~50 000 美元，这一差别还是很大的。</p>
<p>我们可以让训练时间更长一点，达到500 个轮次。为了记录模型在每轮的表现，我们需要修改训练循环，以保存每轮的验证分数记录。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num_epochs = <span class="number">500</span></span><br><span class="line">all_mae_histories = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">    print(<span class="string">'processing fold #'</span>, i)</span><br><span class="line">    val_data = train_data[i * num_val_samples: (i + <span class="number">1</span>) * num_val_samples]</span><br><span class="line">    val_targets = train_targets[i * num_val_samples: (i + <span class="number">1</span>) * num_val_samples]</span><br><span class="line">    partial_train_data = np.concatenate([train_data[:i * num_val_samples],train_data[(i + <span class="number">1</span>) * num_val_samples:]],axis=<span class="number">0</span>)</span><br><span class="line">    partial_train_targets = np.concatenate([train_targets[:i * num_val_samples],train_targets[(i + <span class="number">1</span>) * num_val_samples:]],axis=<span class="number">0</span>)</span><br><span class="line">    model = build_model()</span><br><span class="line">    history = model.fit(partial_train_data, partial_train_targets,</span><br><span class="line">    validation_data=(val_data, val_targets),</span><br><span class="line">    epochs=num_epochs, batch_size=<span class="number">1</span>, verbose=<span class="number">0</span>)</span><br><span class="line">    mae_history = history.history[<span class="string">'val_mean_absolute_error'</span>]</span><br><span class="line">    all_mae_histories.append(mae_history)</span><br></pre></td></tr></table></figure><br>然后你可以计算每个轮次中所有折MAE 的平均值。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">average_mae_history = [np.mean([x[i] <span class="keyword">for</span> x <span class="keyword">in</span> all_mae_histories]) <span class="keyword">for</span> i <span class="keyword">in</span> range(num_epochs)]</span><br></pre></td></tr></table></figure><br>我们画图来看一下：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.plot(range(<span class="number">1</span>, len(average_mae_history) + <span class="number">1</span>), average_mae_history)</span><br><span class="line">plt.xlabel(<span class="string">'Epochs'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Validation MAE'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<center>
    <img src="\Pic\DeepLearning_Pic\MAE_1.png" width="400" height="400" alt="MAE_1" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">每轮的验证MAE</div>
</center>

<p>因为纵轴的范围较大，且数据方差相对较大，所以难以看清这张图的规律。我们来重新绘制一张图。</p>
<ul>
<li>删除前 10 个数据点，因为它们的取值范围与曲线上的其他点不同。</li>
<li>将每个数据点替换为前面数据点的指数移动平均值，以得到光滑的曲线。<br>代码如下所示：<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">smooth_curve</span><span class="params">(points, factor=<span class="number">0.9</span>)</span>:</span></span><br><span class="line">    smoothed_points = []</span><br><span class="line">    <span class="keyword">for</span> point <span class="keyword">in</span> points:</span><br><span class="line">        <span class="keyword">if</span> smoothed_points:</span><br><span class="line">            previous = smoothed_points[<span class="number">-1</span>]</span><br><span class="line">            smoothed_points.append(previous * factor + point * (<span class="number">1</span> - factor))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            smoothed_points.append(point)</span><br><span class="line">    <span class="keyword">return</span> smoothed_points</span><br><span class="line">smooth_mae_history = smooth_curve(average_mae_history[<span class="number">10</span>:])</span><br><span class="line">plt.plot(range(<span class="number">1</span>, len(smooth_mae_history) + <span class="number">1</span>), smooth_mae_history)</span><br><span class="line">plt.xlabel(<span class="string">'Epochs'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Validation MAE'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
从图中可以看出验证MAE 在80 轮后不再显著降低，之后就开始过拟合。</li>
</ul>
<center>
    <img src="\Pic\DeepLearning_Pic\MAE_2.png" width="400" height="400" alt="MAE_2" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">每轮的验证MAE（删除前十个数据点）</div>
</center>

<p>完成模型调参之后（除了轮数，还可以调节隐藏层大小），你可以使用最佳参数在所有训练数据上训练最终的生产模型，然后观察模型在测试集上的性能。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = build_model()</span><br><span class="line">model.fit(train_data, train_targets,</span><br><span class="line">epochs=<span class="number">80</span>, batch_size=<span class="number">16</span>, verbose=<span class="number">0</span>)</span><br><span class="line">test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)</span><br><span class="line">print(test_mae_score)</span><br></pre></td></tr></table></figure>
<pre><code>102/102 [==============================] - 0s 147us/step
2.905885696411133
</code></pre><p>你预测的房价还是和实际价格相差约2905 美元。</p>
]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
  </entry>
  <entry>
    <title>头疼的Borel</title>
    <url>/posts/c649d14b.html</url>
    <content><![CDATA[<div id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <div class="hbe-input-container">
  <input type="password" id="hbePass" placeholder="" />
    <label for="hbePass">Hey, password is required here.</label>
    <div class="bottom-line"></div>
  </div>
  <script id="hbeData" type="hbeData" data-hmacdigest="0eb29b3883ea72c2ea5b622beea2066bfc5a2313891254b25f78ea5de038d33e">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</script>
</div>
<script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>Mathematics</category>
      </categories>
  </entry>
  <entry>
    <title>数理统计笔记_假设检验</title>
    <url>/posts/55ea3ea0.html</url>
    <content><![CDATA[<h1 id="假设检验"><a href="#假设检验" class="headerlink" title="假设检验"></a>假设检验</h1><p><strong>含义</strong>：提出一个看法，判断一个看法（假设）是否成立，即为假设检验问题。</p>
<p><strong>检验</strong>：关于参数的判断，称为参数检验问题，不涉及参数的检验称为非参数检验，检验的基本思想是概率意义下的反证法。</p>
<p><strong>小概率原理</strong>：概率很小的时间在一次实验中，实际上几乎不会发生</p>
<p>假设检验也叫显著性检验，是以小概率反证法的逻辑推理，判断假设是否成立的统计方法，它首先假设样本对应的总体参数（或分布）与某个已知总体参数（或分布）相同，然后根据统计量的分布规律来分析样本数据，利用样本信息判断是否支持这种假设，并对检验假设做出取舍抉择，做出的结论是概率性的，不是绝对的肯定或者否定。</p>
<p>假设检验有两种错误，第一类型错误和第二类型错误。第一类型错误，是零假设成立的情况下拒绝零假设。第二类型错误，是备选假设成立的情况下接受零假设。</p>
<p>假设检验保证，第一类型错误概率不超过α。这是因为在零假设成立的情况下，统计量 st 值落在区域 I 的可能性小于等于α。对于第二类错误，假设检验就没有什么控制了。为什么假设检验控制第一类错误，而忽略第二类错误呢？一般情况下，零假设代表无效、无作用或者无影响，而备选假设代表有效、有作用或者有影响。这时候第一类错误的危害比第二类错误的大。比如在验证新算法有效性实验中，新算法实际无效但被认为有效的第一类型错误，会让大家错误地使用这个算法。新算法有效而被认为无效的第二类错误，只是让自己发不出论文，对大众没有影响。</p>
<h2 id="假设检验的步骤"><a href="#假设检验的步骤" class="headerlink" title="假设检验的步骤"></a>假设检验的步骤</h2><ol>
<li>建立检验假设和确定检验水准</li>
<li>选定检验方法和计算检验统计量</li>
<li>确定P值和做出推断结论</li>
</ol>
<h3 id="建立检验假设和确定检验水准"><a href="#建立检验假设和确定检验水准" class="headerlink" title="建立检验假设和确定检验水准"></a>建立检验假设和确定检验水准</h3><h4 id="建立检验假设"><a href="#建立检验假设" class="headerlink" title="建立检验假设"></a>建立检验假设</h4><p>在均数的比较中，检验假设是针对总体特征而言，包括相互对立的两个方面：</p>
<ul>
<li>原假设、零假设$H_0$：它是要否定的假设</li>
<li>备择假设$H_1$：它是$H_0$的对立面</li>
</ul>
<p>二者是从反证法的思想提出的，$H_0$和$H_1$是相互联系又相互对立的假设。</p>
<p>研究者可能有两种目的：</p>
<ol>
<li>推断两个总体均数有无明显差别。不管是病人某体征高于正常人还是低于正常人，两种可能性都存在，研究者同等关心，则应使用双侧检验。</li>
<li>根据专业知识，已知病人不会低于正常人，或是研究者只关心病人该体征是否高于正常人，应当使用单侧检验。</li>
</ol>
<h4 id="确定检验水准"><a href="#确定检验水准" class="headerlink" title="确定检验水准"></a>确定检验水准</h4><p>建设检验还需根据不同研究目的事先设置是否拒绝原假设的判断标准，即检验水准。检验水准也称为显著性水准，它指无效假设$H_0$为真，但被错误地拒绝的一个小概率值，一般取$\alpha=0.05$</p>
<p>原假设、备择假设和显著性水准的确定，以及单侧检验或双侧检验的选择，都应该结合研究设计，在未获得样本结果之前决定，而不受样本结果的影响。</p>
<h3 id="选定检验方法和计算检验统计量"><a href="#选定检验方法和计算检验统计量" class="headerlink" title="选定检验方法和计算检验统计量"></a>选定检验方法和计算检验统计量</h3><p>要根据研究设计的类型和统计推断的目的选用不同的检验方法。如成组设计的两样本均数的比较用t检验，多个样本均数的比较用F检验。</p>
<p>检验统计量时用于抉择是否拒绝原假设的统计量，其统计分布在统计推断中是至关重要的，不同的检验方法要用不同的方式计算现有样本的检验统计量值。</p>
<h3 id="确定P值和做出推断结论"><a href="#确定P值和做出推断结论" class="headerlink" title="确定P值和做出推断结论"></a>确定P值和做出推断结论</h3><p>P值是指由原假设成立时的检验统计量出现在由样本计算出来的检验统计量的末端或更末端处的概率值。</p>
<p><strong>$P≤α$时，结论为按所取检验水准拒原假设，接受备择假设。</strong>这样做出结论的理由是：在原假设成立的条件下，出现等于及大于现有检验统计量值的概率小于$α$（也即发生一类错误的概率），是小概率事件，这在一次抽样中是不大可能发生的，现有样本信息不支持原假设，因此拒绝他。</p>
<p><strong>如果$P&gt;α$，即样本信息支持原假设，就没有理由拒绝它，因此只好接受原假设。</strong></p>
<p>假设检验的结论是具有概率性的，不管是拒绝还是接受原假设，都有可能发生错误。拒绝原假设不等于原假设肯定不成立，因为小概率事件仍有可能发生只是可能性很小而已；同理，不拒绝原假设也不等于原假设肯定成立。</p>
<h2 id="均值的比较：-t-检验"><a href="#均值的比较：-t-检验" class="headerlink" title="均值的比较：$t$检验"></a>均值的比较：$t$检验</h2><p>$t$检验也称学生$t$检验，$t$检验是用于<strong>两个样本（或样本与群体）平均值差异程度</strong>的检验方法。它是用$T$分布理论来推断差异发生的概率，从而判定两个平均数的差异是否显著。</p>
<p>T检验的适用条件为<strong>样本分布符合正态分布</strong>。</p>
<p><strong>t检验的应用条件</strong>：</p>
<ol>
<li>当样本数较小时，要求样本取自正态总体</li>
<li>做两样本均数比较时，要求两样本的总体方差相同（如果方差不同也可进行t检验）</li>
</ol>
<h3 id="t-检验的类型"><a href="#t-检验的类型" class="headerlink" title="$t$检验的类型"></a>$t$检验的类型</h3><p>$t$检验有多种类型，可以分为只有一组样本的单体检验和有两组样本的双体检验。单体检验用于检验样本的分布期望是否等于某个值。双体检验用于检验两组样本的分布期望是否相等，又分为配对双体检验和非配对双体检验。配对双体检验的两组样本数据是一一对应的，而非配对双体检验的两组数据则是独立的。比如药物实验中，配对双体检验适用于观察同一组人服用药物之前和之后，非配对双体检验适用于一组服用药物而一组不服用药物。</p>
<h4 id="单体检验"><a href="#单体检验" class="headerlink" title="单体检验"></a>单体检验</h4><p>单体检验是针对一组样本的假设检验。零假设为$H_0:μ=μ_0$。统计量服从自由度为$n-1$的$T$分布:</p>
<script type="math/tex; mode=display">t = \frac{\bar x-\mu_0}{\frac{s}{\sqrt{n}}}</script><p>其中$\bar x$为样本均值，$s$为样本标准差，$n$为样本数。</p>
<h4 id="配对双体检验"><a href="#配对双体检验" class="headerlink" title="配对双体检验"></a>配对双体检验</h4><p>配对样本应用场景：同一个样本在两个时间点的检测数据、同一个样本用两种检测方式的检测数据。</p>
<p><strong>前提：两组独立样本必须都符合正态分布！！</strong></p>
<p>配对双体检验针对配对的两组样本。配对双体检验假设两组样本之间的差值服从正态分布。如果该正态分布的期望为零，则说明这两组样本不存在显著差异。零假设为$H_0:\mu=\mu_0$，统计量服从自由度$n-1$的$T$分布：</p>
<script type="math/tex; mode=display">t = \frac{d-\mu_0}{\frac{s}{\sqrt{n}}}</script><p>其中$d$是差值的平均值，$s$是差值的样本标准差。</p>
<blockquote>
<p>配对设计的t检验研究的是差值均数（样本均数）与理论上的差值总体均数的比较。<br>首先计算出各对差值$d$的均数。当两种处理结果无差别或某种处理不起作用时，理论上差值d的总体均数$μ_d=0$</p>
</blockquote>
<h4 id="非配对双体检验"><a href="#非配对双体检验" class="headerlink" title="非配对双体检验"></a>非配对双体检验</h4><p>非配对双体检验针对独立的两组样本。非配对双体检验假设两组样本是从不同的正态分布采样出来的。<strong>根据两个正态分布的标准差是否相等</strong>，非配对双体检验又可以分两类。</p>
<p>一种是分布标准差相等的情况（<strong>方差齐性</strong>）。零假设是两组样本的分布期望相等，统计量$T$服从自由度为$n_1+n_2-2$的$T$分布：</p>
<script type="math/tex; mode=display">t = \frac{\bar x_1-\bar x_2}{s_{x_1,x_2}\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}</script><script type="math/tex; mode=display">s_{x_1x_2} = \sqrt{\frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}}</script><p>另一种是分布标准差不相等的情况（方差非齐性），零假设也是两组样本的分布期望相等，统计量$T$服从$T$分布：</p>
<script type="math/tex; mode=display">t = \frac{\bar x_1 - \bar x_2}{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}</script><h2 id="卡方检验"><a href="#卡方检验" class="headerlink" title="卡方检验"></a>卡方检验</h2><p>$\chi^2$概率分布主要用于检查实际结果与期望结果之间何时存在显著差别，该概率分布使用检验统计量$X^2$进行检验：</p>
<script type="math/tex; mode=display">X^2 = \sum{\frac{(O-E)^2}{E}}</script><p>其中$X^2$~$\chi^2$，$O$代表观察值，$E$代表期望值，$v$表示自由度（即用于检验统计量$\chi_2$的独立变量的数目，或者说是独立信息段的数目），一般来说$v = $组数-限制数</p>
<p>检验统计量的值越大，则说明观察值与期望结果之间存在的差异越明显，因此当检验统计量的结果大于查表得到的拒绝域时，就认为实际观察值与期望值不符，需要拒绝原假设。</p>
<h3 id="卡方检验的两个主要用途"><a href="#卡方检验的两个主要用途" class="headerlink" title="卡方检验的两个主要用途"></a>卡方检验的两个主要用途</h3><h4 id="用于检验拟合优度"><a href="#用于检验拟合优度" class="headerlink" title="用于检验拟合优度"></a>用于检验拟合优度</h4><p>也就是可以检验一组给定的数据与指定分布的吻合程度，例如，用于检验给定数据的出现频率是否与理论频率相吻合。</p>
<p>$\chi^2$拟合优度检验对相当多的概率分布都有效，只要你得到一组观察频数，且能算出期望频数，就可以使用$\chi^2$分布检验任何概率分布的拟合优度。而最大的困难在于计算自由度$v$（在查表确定拒绝域的时候需要自由度）</p>
<h4 id="用于检验两个变量的独立性"><a href="#用于检验两个变量的独立性" class="headerlink" title="用于检验两个变量的独立性"></a>用于检验两个变量的独立性</h4><p>通过这个方法可以检查变量之间是否存在某种关联。</p>
<h2 id="方差的比较：F检验"><a href="#方差的比较：F检验" class="headerlink" title="方差的比较：F检验"></a>方差的比较：F检验</h2><p>F检验又叫方差齐性检验，用于检验两组服从正态分布的样本是否具有相同的总体方差，即方差齐性。</p>
<p>非参数检验</p>
<p>参数检验是在假设总体分布已知的情况下进行的，但在实际生活中，那种对总体的分布的假定并不是能随便做出的。数据并不是来自所假定分布的总体，或者，数据根本不是来自一个增提；还有可能数据因为种种原因被污染。在这种情形下，在假定总体分布已知的情况下进行推断的做法就可能产生错误甚至导致灾难性的结论。于是，人们希望在不对整体分布做出假定的情况下，尽量从数据本身来获得所需要的信息，这就是分参数统计推断的总宗旨。</p>
<p>参数检验中的重点是t检验，不同的t检验方法适用于不同的分析场景，在不满足t检验的条件的时候就需要非参数检验了，下表整理了不同场景下的检验方法：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>分析方法</th>
<th>功能</th>
<th>正态性（前提）</th>
<th>不服从正态时</th>
<th>方差齐性</th>
</tr>
</thead>
<tbody>
<tr>
<td>单样本T检验</td>
<td>与某数字对比差异</td>
<td>服从正态分布</td>
<td>单样本Wilcoxon检验</td>
<td>-</td>
</tr>
<tr>
<td>配对样本T检验</td>
<td>配对数据差异</td>
<td>差值服从正态分布</td>
<td>配对Wilcoxon检验</td>
<td>无要求</td>
</tr>
<tr>
<td>独立样本T检验</td>
<td>两组数据差异</td>
<td>两组数据均服从正态分布</td>
<td>Mann-Whitney检验</td>
<td>要求方差齐</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>本文转载自CSDN博客 <a href="https://blog.csdn.net/qq_26822029/article/details/103632054?utm_medium=distribute.pc_relevant.none-task-blog-baidujs-1" target="_blank" rel="noopener">https://blog.csdn.net/qq_26822029/article/details/103632054?utm_medium=distribute.pc_relevant.none-task-blog-baidujs-1</a> ，用于本人资料查询，不做商用</p>
</blockquote>
]]></content>
      <categories>
        <category>Mathematics</category>
      </categories>
  </entry>
  <entry>
    <title>XGBoost（二）解决二分类和多分类问题</title>
    <url>/posts/8c5e1ebd.html</url>
    <content><![CDATA[<p>XGBoost由多棵决策树（CART）组成，每棵决策树预测真实值与之前所有决策树预测值之和的残差（残差=真实值-预测值），将所有决策树的预测值累加起来即为最终结果。</p>
<h1 id="一、二分类问题"><a href="#一、二分类问题" class="headerlink" title="一、二分类问题"></a>一、二分类问题</h1><p>XGBoost树模型由多棵回归树组成，并将多棵决策树的预测值累计相加作为最终结果。回归树产生的是连续的回归值，如何用它解决二分类问题呢？通过前面的学习知道，逻辑回归是在线性回归的基础上通过<code>sigmoid</code>函数将预测值映射到0～1的区间来代表二分类结果的概率。和逻辑回归一样，XGBoost也是采用<code>sigmoid</code>函数来解决二分类问题，即先通过回归树对样本进行预测，得到每棵树的预测结果，然后将其进行累加求和，最后通过<code>sigmoid</code>函数将其映射到0～1的区间代表二分类结果的概率。另外，对于二分类问题，XGBoost的目标函数采用的是类似逻辑回归的<code>logloss</code>，而非最小二乘。</p>
<p>XGBoost中关于二分类的常用参数有如下几个：</p>
<ul>
<li><code>Objective</code>: 该参数用来指定目标函数，XGBoost可以根据该参数判断进行何种学习任务，<code>binary:logistic</code>和<code>binary:logitraw</code>都表示学习任务类型为二分类。<code>binary:logistic</code>输出为概率，<code>binary:logitraw</code>输出为逻辑转换前的输出分数。</li>
<li><code>eval_metric</code>: 该参数用来指定模型的评估函数，和二分类相关的评估函数有：error、logloss和auc。error也称错误率，即预测错误的样本数占总样本数的比例，准确来说是预测错误样本的权重和占总样本权重和的比例，也可通过error@k的形式手工指定二分类的阈值。logloss通过惩罚分类来量化模型的准确性，最大限度减少logloss，等同于最大化模型的准确率。另外，AUC也是二分类中最常用的评估指标之一，计算方法可另外查询。</li>
</ul>
<p>下面仍然以该案例数据集进行说明。蘑菇数据集是一个非常著名的二分类数据集。该数据集一共包含23个特征，包括大小、表面、颜色等，每一种蘑菇都会被定义为可食用的或者有毒的，需要通过样本数据分析这些特征与蘑菇毒性的关系。以下是各个特征的详细说明：</p>
<ul>
<li>帽形（cap-shape）：钟形=b，圆锥形=c，凸形=x，平面=f，把手形=k，凹陷=S</li>
<li>帽面（cap-surface）：纤维状=f，凹槽状=g，鳞片状=y，光滑=s</li>
<li>帽颜色（cap-color）：棕色=n，浅黄色=b，肉桂色=c，灰色=g，绿色=r，粉红色=p，紫色=u，红色=e，白色=w，黄色=y</li>
<li>创伤（bruises）：创伤=t，no=f</li>
<li>气味（odor）：杏仁=a，茴香=l，石灰=c，腥味=y，臭味=f，霉味=m，无=n，刺鼻=p，辣=s</li>
<li>菌褶附属物（gill-attachment:）：附着=a，下降=d，自由=f，缺口=n</li>
<li>菌褶间距（gill-spacing）：紧密=c，拥挤=w，远隔=d</li>
<li>菌褶大小（gill-size）：宽=b，窄=n。</li>
<li>菌褶颜色（gill-color）：黑色=k，棕色=n，浅黄色=b，巧克力色=h，灰色=g，绿色=r，橙色=o，粉红色=p，紫色=u，红色=e，白色=w，黄色=y</li>
<li>茎形（stalk-shape）：扩大=e，锥形=t</li>
<li>茎根（stalk-root）：球根=b，棒状=c，杯状=u，均等的=e，根状菌索=z，扎根=r，缺省=？</li>
<li>环上茎面（stalk-surface-above-ring）：纤维状=f，鳞片状=y，丝状=k，光滑=s</li>
<li>环下茎面（stalk-surface-below-ring）：纤维状=f，鳞片状=y，丝状=k，光滑=s</li>
<li>环上茎颜色（stalk-color-above-ring）：棕色=n，浅黄色=b，黄棕色=c，灰色=g，橙色=o，粉红色=p，红色=e，白色=w，黄色=y</li>
<li>环下茎颜色（stalk-color-below-ring）：棕色=n，浅黄色=b，黄棕色=c，灰色=g，橙色=o，粉红色=p，红色=e，白色=w，黄色=y</li>
<li>菌幕类型（veil-type）：部分=p，普遍=u</li>
<li>菌幕颜色（veil-color）：棕色=n，橙色=o，白色=w，黄色=y</li>
<li>环数量（ring-number）：没有=n，一个=o，两个=t</li>
<li>环类型（ring-type）：蛛网状=c，消散状=e，喇叭形=f，大规模的=l，无=n，悬垂的=p，覆盖=s，环带=z</li>
<li>孢子显现颜色（spore-print-color）：黑色=k，棕色=n，蓝色=b，巧克力色=h，绿色=r，橙色=o，紫色=u，白色=w，黄色=y</li>
<li>种群（population）：丰富=a，聚集=c，众多=n，分散=s，个别=v，单独=y</li>
<li>栖息地（habitat）：草地=g，树叶=l，草甸=m，路上=p，城市=u，荒地=w，树林=d</li>
<li>class：label字段，有可食用（edible）和有毒性（poisonous）两个取值</li>
</ul>
<p>该数据集总共有8124个样本，其中类别为可食用的样本有4208个，类别为有毒性的样本有3916个。对于该二分类问题，XGBoost工程文件中提供了示例代码。示例以命令行的方式调用XGBoost，完成模型训练、预测等过程。示例位于<code>demo/CLI/binary_classification</code>文件夹下，其中包括下面几个文件：</p>
<ul>
<li><code>agaricus-lepiota.data</code>——蘑菇数据文件</li>
<li><code>agaricus-lepiota.fmap</code>——字段名称映射文件</li>
<li><code>agaricus-lepiota.names</code>——蘑菇数据集描述文件</li>
<li><code>mapfeat.py</code>——数据集特征值预处理</li>
<li><code>mknfold.py</code>——划分数据集</li>
<li><code>mushroom.conf</code>——模型配置文件</li>
<li><code>runexp.sh</code>——运行脚本</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_dir = <span class="string">"xgboost_source_code/demo/CLI/binary_classification/"</span></span><br></pre></td></tr></table></figure>
<p>读者可自行尝试执行<code>runexp.sh</code>脚本，学习命令行形式的调用过程。本节重点介绍如何通过Python调用XGBoost进行模型训练和预测，并对处理流程中的各个阶段进行详细解析。</p>
<p>首先需要对特征进行预处理。因为原始文件<code>agaricus-lepiota.data</code>中的数据并不能直接作为XGBoost的输入进行加载，需要进行预处理。这里将其中的字符数据转为数值型，并以LibSVM的格式输出。LibSVM是机器学习中经常采用的一种数据格式，如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;label&gt; &lt;index1&gt;:&lt;value1&gt;&lt;index2&gt;:&lt;value2&gt;...</span><br></pre></td></tr></table></figure>
<p><code>label</code>为训练数据集的目标值；<code>index</code>为特征索引，是一个以1为起始的整数；<code>value</code>是该特征的取值，如果某一特征的值缺省，则该特征可以空着不填，因此对于一个样本来讲，输出后的数据文件<code>index</code>可能并不连续，上述样本处理后的格式如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1 3:1 10:1 11:1 21:1 30:1 34:1 36:1 40:1 41:1 53:1 58:1 65:1 69:1 77:1 86:1 88:1 92:1 95:1 102:1 105:1 117:1 124:1</span><br><span class="line">0 3:1 10:1 20:1 21:1 23:1 34:1 36:1 39:1 41:1 53:1 56:1 65:1 69:1 77:1 86:1 88:1 92:1 95:1 102:1 106:1 116:1 120:1</span><br></pre></td></tr></table></figure>
<p>第一个样本中最开始的“1”便是该样本的label，在二分类问题中，一般1代表正样本，0代表负样本。之后的每个特征为一项，冒号前为该特征的索引，如3、10等，冒号后为该特征取值，如3、10两个特征的取值都是1。另外，观察处理后的数据可以发现，特征索引已经远远超过了22，如第一行样本中特征索引最大已经达到了124。</p>
<p>观察该数据集可以发现，其中大部分特征是离散型特征，连续型特征较少。在机器学习算法中，特征之间距离的计算是十分重要的，因此，直接把离散变量的取值转化为数值，并不能很好地代表特征间的距离，如菌幕颜色特征，其总共有棕色、橙色、白色、黄色4种颜色，假如将其映射为1、2、3、4，则棕色和橙色之间的距离是2-1=1，而棕色和白色之间的距离是3-1=2。这显然是不符合实际情况的，因为任意两个颜色之间的距离应该是相等的。因此，需要对特征进行独热编码（one-hot encoding）。</p>
<p>简单来讲，独热编码就是离散特征有多少取值，就用多少维来表示该特征。仍然以菌幕颜色特征为例，经过独热编码后，其将会转为4个特征，分别是菌幕颜色是否为棕色、菌幕颜色是否为橙色、菌幕颜色是否为白色和菌幕颜色是否为黄色，并且这4个特征取值只有0和1。经过独热编码之后，每两个颜色之间的距离都是一样的，比之前的处理更合理。离散特征经过独热编码之后，数据集的总特征数会变多，这就是上述示例中出现较大特征索引的原因。下面来看一下特征处理的代码实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadmap</span><span class="params">(fname)</span>:</span></span><br><span class="line">    fmap = &#123;&#125;</span><br><span class="line">    nmap = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> open(fname):</span><br><span class="line">        arr = l.split()</span><br><span class="line">        <span class="keyword">if</span> arr[<span class="number">0</span>].find(<span class="string">'.'</span>) != <span class="number">-1</span>:</span><br><span class="line">            idx = int(arr[<span class="number">0</span>].strip(<span class="string">'.'</span>))</span><br><span class="line">            <span class="keyword">assert</span> idx <span class="keyword">not</span> <span class="keyword">in</span> fmap</span><br><span class="line">            fmap[idx] = &#123;&#125;</span><br><span class="line">            ftype = arr[<span class="number">1</span>].strip(<span class="string">":"</span>)</span><br><span class="line">            content = arr[<span class="number">2</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            content = arr[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> it <span class="keyword">in</span> content.split(<span class="string">','</span>):</span><br><span class="line">            <span class="keyword">if</span> it.strip() == <span class="string">''</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            k, v = it.split(<span class="string">'='</span>)</span><br><span class="line">            fmap[idx][v] = len(nmap) + <span class="number">1</span></span><br><span class="line">            nmap[len(nmap)] = ftype + <span class="string">'='</span> + k</span><br><span class="line">    <span class="keyword">return</span> fmap, nmap</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_nmap</span><span class="params">(fo, nmap)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nmap)):</span><br><span class="line">        fo.write(<span class="string">'%d\t%s\ti\n'</span>%(i, nmap[i]))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fmap, nmap = loadmap(data_dir+<span class="string">'agaricus-lepiota.fmap'</span>)</span><br><span class="line">fo = open(<span class="string">'output/data/featmap.txt'</span>, <span class="string">'w'</span>)</span><br><span class="line">write_nmap(fo, nmap)</span><br><span class="line">fo.close()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fo = open(<span class="string">'output/data/agaricus.txt'</span>, <span class="string">'w'</span>)</span><br><span class="line"><span class="keyword">for</span> l <span class="keyword">in</span> open(data_dir+<span class="string">'agaricus-lepiota.data'</span>):</span><br><span class="line">    arr = l.split(<span class="string">','</span>)</span><br><span class="line">    <span class="keyword">if</span> arr[<span class="number">0</span>] == <span class="string">'p'</span>:</span><br><span class="line">        fo.write(<span class="string">'1'</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">assert</span> arr[<span class="number">0</span>] == <span class="string">'e'</span></span><br><span class="line">        fo.write(<span class="string">'0'</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len(arr)):</span><br><span class="line">        fo.write(<span class="string">' %d:1'</span> %fmap[i][arr[i].strip()])</span><br><span class="line">    fo.write(<span class="string">'\n'</span>)</span><br><span class="line">fo.close()</span><br></pre></td></tr></table></figure>
<p>首先程序会加载特征描述文件<code>agaricus-lepiota.fmap</code>，为每个特征的每个取值均分配一个唯一的索引标识，并为其重新命名，并将处理后的新特征索引和名称的映射保存为<code>featmap.txt</code>文件（该映射文件会在XGBoost中用到）。然后加载蘑菇数据集，通过新特征索引处理该数据集，生成转化后的新数据文件<code>featmap.txt</code>。特征处理完后即可通过mknfold.py划分数据集。在本示例中，划分数据集是通过代码实现的，当然读者也可以采用第3章介绍的scikit-learn中的<code>train_test_split</code>来划分数据集。下面看一下<code>mknfold.py</code>的代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> len(sys.argv) &lt; <span class="number">2</span>:</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">'Usage:&lt;filename&gt; &lt;k&gt; [nfold = 5]'</span>)</span><br><span class="line">    exit(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">random.seed( <span class="number">10</span> )</span><br><span class="line"></span><br><span class="line">k = int( sys.argv[<span class="number">2</span>] )</span><br><span class="line"><span class="keyword">if</span> len(sys.argv) &gt; <span class="number">3</span>:</span><br><span class="line">    nfold = int( sys.argv[<span class="number">3</span>] )</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    nfold = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">fi = open( sys.argv[<span class="number">1</span>], <span class="string">'r'</span> )</span><br><span class="line">ftr = open( sys.argv[<span class="number">1</span>]+<span class="string">'.train'</span>, <span class="string">'w'</span> )</span><br><span class="line">fte = open( sys.argv[<span class="number">1</span>]+<span class="string">'.test'</span>, <span class="string">'w'</span> )</span><br><span class="line"><span class="keyword">for</span> l <span class="keyword">in</span> fi:</span><br><span class="line">    <span class="keyword">if</span> random.randint( <span class="number">1</span> , nfold ) == k:</span><br><span class="line">        fte.write( l )</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        ftr.write( l )</span><br><span class="line"></span><br><span class="line">fi.close()</span><br><span class="line">ftr.close()</span><br><span class="line">fte.close()</span><br></pre></td></tr></table></figure>
<p>生成训练集和测试集后，便可通过XGBoost加载数据进行训练，下面通过Python实现XGBoost的调用。先加载训练集和测试集：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line">xgb_train = xgb.DMatrix(<span class="string">"xgboost_source_code/demo/data/agaricus.txt.train"</span>)</span><br><span class="line">xgb_test = xgb.DMatrix(<span class="string">"xgboost_source_code/demo/data/agaricus.txt.test"</span>)</span><br></pre></td></tr></table></figure>
<p>设定模型训练参数，开始模型训练：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">params = &#123;</span><br><span class="line">    <span class="string">"objective"</span> : <span class="string">"binary:logistic"</span>,</span><br><span class="line">    <span class="string">"booster"</span> : <span class="string">"gbtree"</span>, </span><br><span class="line">    <span class="string">"eta"</span> : <span class="number">1.0</span>,</span><br><span class="line">    <span class="string">"gamma"</span> : <span class="number">1.0</span>,</span><br><span class="line">    <span class="string">"min_child_weight"</span> : <span class="number">1</span>,</span><br><span class="line">    <span class="string">"max_depth"</span> : <span class="number">3</span></span><br><span class="line">&#125;</span><br><span class="line">num_round = <span class="number">2</span></span><br><span class="line">watchlist = [(xgb_train, <span class="string">"train"</span>), (xgb_test, <span class="string">"test"</span>)]</span><br><span class="line">model = xgb.train(params, xgb_train, num_round, watchlist)</span><br></pre></td></tr></table></figure>
<pre><code>[0]    train-error:0.01443    test-error:0.01614
[1]    train-error:0.00123    test-error:0.00000
</code></pre><p><code>params</code>中的<code>objective</code>和<code>booster</code>参数已经介绍过了，分别用于指定任务的学习目标和<code>booster</code>类型，其他参数说明如下：</p>
<ul>
<li><code>objective</code>设为<code>binary:logistic</code>，表示任务为二分类问题，最终输出为<code>sigmoid</code>变换后的概率。</li>
<li><code>booster</code>为<code>gbtree</code>表示采用XGBoost中的树模型。参数<code>eta</code>表示学习率，类似于梯度下降中法的$\alpha$，每次迭代完更新权重的步长。</li>
<li><code>gamma</code>表示节点分裂时损失函数减小的最小值，此处为1.0，表示损失函数至少下降1.0该节点才会进行分裂。</li>
<li><code>min_child_weight</code>表示叶子节点最小样本权重和，若节点分裂导致叶子节点的样本权重和小于该值，则节点不进行分裂。</li>
<li><code>max_depth</code>表示决策树分裂的最大深度。</li>
</ul>
<p>另外，该示例中指定了<code>num_round</code>为2，即模型会进行两轮<code>booster</code>训练，最终会生成两棵决策树。通过定义参数<code>watchlist</code>，模型在训练过程中会实时输出训练集和验证集的评估指标。</p>
<p>模型训练完成之后，可通过<code>save_model</code>方法将模型保存成模型文件，以供后续预测使用，如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.save_model(<span class="string">"output/model/02_agaricus.model"</span>)</span><br></pre></td></tr></table></figure>
<p>预测时，先加载保存的模型文件，然后再对数据集进行预测，如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">bst = xgb.Booster()</span><br><span class="line">bst.load_model(<span class="string">"output/model/02_agaricus.model"</span>)</span><br><span class="line">pred = bst.predict(xgb_test)</span><br><span class="line">print(pred)</span><br></pre></td></tr></table></figure>
<pre><code>[0.10828121 0.85500014 0.10828121 ... 0.95467216 0.04156424 0.95467216]
</code></pre><p>可以看到，输出结果是一个浮点数组成的数组，其中每个值代表对应样本的预测概率。预测完成后，输出文本格式的模型，这里仍然采用两种方式，如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 未作特征名转换</span></span><br><span class="line">dump_model_raw = bst.dump_model(<span class="string">"output/data/dump.raw.txt"</span>)</span><br><span class="line"><span class="comment"># 完成特征名转换</span></span><br><span class="line">dump_model_nice = bst.dump_model(<span class="string">"output/data/dump.nice.txt"</span>, <span class="string">"output/data/featmap.txt"</span>)</span><br></pre></td></tr></table></figure>
<p>下面主要以完成特征名称转换后的模型文件为例进行介绍。先来看一下索引和特征名称映射文件<code>featmap.txt</code>，格式如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;featureid&gt; &lt;featurename&gt; &lt;q or i or int&gt;\n</span><br></pre></td></tr></table></figure>
<p>其中：</p>
<ul>
<li><code>featureid</code>为特征索引</li>
<li><code>featurename</code>为特征名称</li>
<li><code>q or i or int</code>为特征的数据类型，其中<code>q</code>代表特征是一个连续值，如距离、价格等；<code>i</code>代表特征是一个二值特征（即特征只有两个取值），一般为0或1；<code>int</code>代表特征是整型值。可以看到，<code>featmap.txt</code>中的很多特征都是二值特征。这个也不难理解，因为该数据集中大部分是离散型的类别特征，因此经过独热编码处理后，新生成的特征基本都是二值特征。</li>
</ul>
<p>了解了特征映射文件后，下面来看一下文本格式的XGBoost树模型文件，以下截取了<code>dump.nice.txt</code>的前几行：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">booster[0]:</span><br><span class="line">0:[odor&#x3D;pungent] yes&#x3D;2,no&#x3D;1</span><br><span class="line">1:[stalk-root&#x3D;cup] yes&#x3D;4,no&#x3D;3</span><br><span class="line">3:[stalk-root&#x3D;missing] yes&#x3D;8,no&#x3D;7</span><br><span class="line">			7:leaf&#x3D;1.90174532</span><br><span class="line">			8:leaf&#x3D;-1.95061731</span><br><span class="line">4:[bruises?&#x3D;no] yes&#x3D;10,no&#x3D;9</span><br><span class="line">			9:leaf&#x3D;1.77777779</span><br><span class="line">			10:leaf&#x3D;-1.98104262</span><br><span class="line">2:[spore-print-color&#x3D;orange] yes&#x3D;6,no&#x3D;5</span><br><span class="line">5:[stalk-surface-below-ring&#x3D;silky] yes&#x3D;12,no&#x3D;11</span><br></pre></td></tr></table></figure>
<p>上面的一个booster代表一棵决策树，该模型一共有两棵决策树。在每棵决策树中，每一行代表一个节点，位于行首的数字代表该节点的索引，数字0表示该节点为根节点。若该行节点是非叶子节点，则索引后面是该节点的分裂条件，如第2行：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0:[odor&#x3D;pungent] yes&#x3D;2,no&#x3D;1</span><br></pre></td></tr></table></figure>
<p>该节点的索引为0，表示该节点是根节点，其分裂条件是odor=pungent，满足该条件的样本会被划分到节点2，不满足的则被划分到节点1。若该行节点是叶子节点，则索引后面是该叶子节点最终得到的权重。如第5行：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">7:leaf&#x3D;1.90174532</span><br></pre></td></tr></table></figure>
<p><code>leaf</code>表示该节点为叶子节点，最终得到的权重为1.90174532。由此，通过文本格式的模型文件，可以使用户了解样本在模型中是如何被划分的，使模型更具有可解释性，并且在实际的机器学习任务中，也有利于用户更好地分析和优化模型。</p>
<h1 id="二、多分类问题"><a href="#二、多分类问题" class="headerlink" title="二、多分类问题"></a>二、多分类问题</h1><p>与处理二分类问题类似，XGBoost在处理多分类问题时也是在树模型的基础上进行转换，不过不再是<code>sigmoid</code>函数，而是<code>softmax</code>函数。相信大家对<code>softmax</code>变换并不陌生，它可以将多分类的预测值映射到0到1之间，代表样本属于该类别的概率。XGBoost中解决多分类问题的主要参数如下：</p>
<ul>
<li><code>num_class</code>：说明在该分类任务的类别数量</li>
<li><code>objective</code>：该参数中的<code>multi:softmax</code>和<code>multi:softprob</code>均是指定学习任务为多分类。<code>multi:softmax</code>通过<code>softmax</code>函数解决多分类问题。<code>multi:softprob</code>和<code>multi:softmax</code>一样，主要区别在于其输出的是一个$ndata*nclass$向量，表示样本属于每个分类的预测概率</li>
<li><code>eval_metric</code>：与多分类相关的评估函数有<code>merror</code>和<code>mlogloss</code>。<code>merror</code>也称多分类错误率，通过判断样本所有分类预测值中预测值最大的分类和样本label是否一致来确定预测是否正确，其计算方式和<code>error</code>相似。<code>mlogloss</code>也是多分类问题中常用的评估指标。有关<code>merror</code>和<code>mlogloss</code>会在后面详细介绍。</li>
</ul>
<p>下面以识别小麦种子的类别作为示例，介绍如何通过XGBoost解决多分类问题。已知小麦种子数据集包含7个特征，分别为面积、周长、紧凑度、籽粒长度、籽粒宽度、不对称系数、籽粒腹沟长度，且均为连续型特征，以及小麦类别字段，共有3个类别，分别用1、2、3表示。加载该数据并进行特征处理，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">"input/seeds_dataset.txt"</span>, header=<span class="literal">None</span>, sep=<span class="string">'\s+'</span>, converters=&#123;<span class="number">7</span>: <span class="keyword">lambda</span> x:int(x)<span class="number">-1</span>&#125;)</span><br><span class="line">data.rename(columns=&#123;<span class="number">7</span>:<span class="string">'label'</span>&#125;, inplace=<span class="literal">True</span>)</span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>15.26</td>
      <td>14.84</td>
      <td>0.8710</td>
      <td>5.763</td>
      <td>3.312</td>
      <td>2.221</td>
      <td>5.220</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>14.88</td>
      <td>14.57</td>
      <td>0.8811</td>
      <td>5.554</td>
      <td>3.333</td>
      <td>1.018</td>
      <td>4.956</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>14.29</td>
      <td>14.09</td>
      <td>0.9050</td>
      <td>5.291</td>
      <td>3.337</td>
      <td>2.699</td>
      <td>4.825</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>13.84</td>
      <td>13.94</td>
      <td>0.8955</td>
      <td>5.324</td>
      <td>3.379</td>
      <td>2.259</td>
      <td>4.805</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>16.14</td>
      <td>14.99</td>
      <td>0.9034</td>
      <td>5.658</td>
      <td>3.562</td>
      <td>1.355</td>
      <td>5.175</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<p>为便于后续处理，将最后一个类别字段作为<code>label</code>字段，因为<code>label</code>的取值需在0到<code>num_class-1</code>范围内，因此需对类别字段进行处理（数据集中的3个类别取值分别为1～3），这里直接减1即可。</p>
<p>可以看到，数据集共包含8列，其中前7列为特征列，最后1列为<code>label</code>列，和数据集描述相符。除<code>label</code>列外，剩余特征没有指定列名，所以pandas自动以数字索引作为列名。下面对数据集进行划分（训练集和测试集的划分比例为4:1），并指定<code>label</code>字段生成XGBoost中的<code>DMatrix</code>数据结构，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mask = np.random.rand(len(data)) &lt; <span class="number">0.8</span></span><br><span class="line">train = data[mask]</span><br><span class="line">test = data[~mask]</span><br><span class="line">xgb_train = xgb.DMatrix(train.iloc[:,:<span class="number">6</span>], label=train.label)</span><br><span class="line">xgb_test = xgb.DMatrix(test.iloc[:,:<span class="number">6</span>], label=test.label)</span><br></pre></td></tr></table></figure>
<p>设置模型训练参数。设置参数<code>objective</code>为<code>multi:softmax</code>，表示采用<code>softmax</code>进行多分类，学习率参数<code>eta</code>和最大树深度<code>max_depth</code>在之前的示例中已有所介绍，不再赘述。参数<code>num_class</code>指定类别数量为3。相关代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">params = &#123;</span><br><span class="line">    <span class="string">'objective'</span>:<span class="string">'multi:softmax'</span>,</span><br><span class="line">    <span class="string">'eta'</span>:<span class="number">0.1</span>,</span><br><span class="line">    <span class="string">'max_depth'</span>:<span class="number">5</span>,</span><br><span class="line">    <span class="string">'num_class'</span>:<span class="number">3</span></span><br><span class="line">&#125;</span><br><span class="line">watchlist = [(xgb_train, <span class="string">"train"</span>), (xgb_test, <span class="string">"test"</span>)]</span><br><span class="line">num_round = <span class="number">10</span></span><br><span class="line">bst = xgb.train(params, xgb_train, num_round, watchlist)</span><br></pre></td></tr></table></figure>
<pre><code>[0]    train-merror:0.01219    test-merror:0.10870
[1]    train-merror:0.01219    test-merror:0.10870
[2]    train-merror:0.01219    test-merror:0.10870
[3]    train-merror:0.01219    test-merror:0.10870
[4]    train-merror:0.01219    test-merror:0.13043
[5]    train-merror:0.00610    test-merror:0.13043
[6]    train-merror:0.00610    test-merror:0.13043
[7]    train-merror:0.00610    test-merror:0.13043
[8]    train-merror:0.00610    test-merror:0.15217
[9]    train-merror:0.00610    test-merror:0.15217
</code></pre><p>在未指定评估函数的情况下，XGBoost默认采用<code>merror</code>作为多分类问题的评估指标。下面通过训练好的模型对测试集进行预测，并计算错误率，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pred = bst.predict(xgb_test)</span><br><span class="line">error_rate = np.sum(pred != test.label) / test.shape[<span class="number">0</span>]</span><br><span class="line">print(error_rate)</span><br></pre></td></tr></table></figure>
<pre><code>0.15217391304347827
</code></pre><p>为了方便对比学习，下面采用<code>multi:softprob</code>方法重新训练模型，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">params[<span class="string">"objective"</span>] = <span class="string">"multi:softprob"</span></span><br><span class="line">bst = xgb.train(params, xgb_train, num_round, watchlist)</span><br></pre></td></tr></table></figure>
<pre><code>[0]    train-merror:0.01219    test-merror:0.10870
[1]    train-merror:0.01219    test-merror:0.10870
[2]    train-merror:0.01219    test-merror:0.10870
[3]    train-merror:0.01219    test-merror:0.10870
[4]    train-merror:0.01219    test-merror:0.13043
[5]    train-merror:0.00610    test-merror:0.13043
[6]    train-merror:0.00610    test-merror:0.13043
[7]    train-merror:0.00610    test-merror:0.13043
[8]    train-merror:0.00610    test-merror:0.15217
[9]    train-merror:0.00610    test-merror:0.15217
</code></pre><p>对比两种函数变换方法的训练输出结果可以看出，不论采用<code>multi:softmax</code>还是<code>multi:softprob</code>作为<code>objective</code>训练模型，并不会影响到模型精度。</p>
<p>下面对测试集进行预测并计算错误率，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pred_prop = bst.predict(xgb_test)</span><br><span class="line">pred_label = np.argmax(pred_prop, axis=<span class="number">1</span>)</span><br><span class="line">error_rate = np.sum(pred_label != test.label) / test.shape[<span class="number">0</span>]</span><br><span class="line">print(<span class="string">'测试集错误率(softprob):&#123;&#125;'</span>.format(error_rate))</span><br></pre></td></tr></table></figure>
<pre><code>测试集错误率(softprob):0.15217391304347827
</code></pre><p>之后的处理则和采用<code>multi:softmax</code>时一样，统计预测错误的样本数，最终计算出分类错误率。采用<code>multi:softprob</code>得到的错误率和<code>multi:softmax</code>也是一样的</p>
]]></content>
      <categories>
        <category>XGBoost</category>
      </categories>
  </entry>
  <entry>
    <title>数理统计笔记_参数估计</title>
    <url>/posts/c100533b.html</url>
    <content><![CDATA[<h1 id="数理统计"><a href="#数理统计" class="headerlink" title="数理统计"></a>数理统计</h1><p>核心内容是统计推断，基本理论和方法有两部分：参数估计和假设检验，有两大应用方法：方差分析和回归分析。</p>
<h2 id="参数估计"><a href="#参数估计" class="headerlink" title="参数估计"></a>参数估计</h2><p><strong>实际问题里常碰到两类问题</strong>：<br>（1）$X$ ~ $F(x;\theta)$，分布形式已知，但 $\theta$ 未知（ $\theta$ 可以是一个向量）<br>（2）$X$ 的分布自由，尽管新 $X$ 的某种数字特征 ，如期望、方差等</p>
<p>参数估计有<strong>点估计</strong>和<strong>区间估计</strong>之分，要求给出参数 $\theta$ 的一个值或一个范围的估计。</p>
<hr>
<h3 id="点估计"><a href="#点估计" class="headerlink" title="点估计"></a>点估计</h3><p><strong>点估计方法定义</strong>：设$\theta$为待估计参数，构造统计量来估计$\theta$，当用统计量$g(X_1, X_2,…,X_n)$来估计$\theta$时，称此统计量为$\theta$的估计量，记为 $\hat\theta$，即$\hat\theta = g(X_1,X_2,…,X_n)$。对样本的一次观察值  $(x_1,x_2,…x_n)$，估计量的值$g(x_1, x_2,…,x_n)$称为$\theta$的估计值，仍记为$\hat\theta$。</p>
<p><strong>常用的点估计方法有两种</strong>：矩估计法与极大似然估计法。</p>
<hr>
<h4 id="矩估计法"><a href="#矩估计法" class="headerlink" title="矩估计法"></a>矩估计法</h4><p><strong>计算方法</strong>：用样本k阶原点矩代替总体k阶原点矩：令$EX^k=\frac1n\sum_{i=1}^nX_i^k,k=1,2,…,L$，$L$是未知参数个数，理论依据是大数定律。<br>（1）未知参数仅一个时，则可以解方程$EX=\bar X$得到矩估计<br>（2）未知参数仅两个时，可以解方程组</p>
<script type="math/tex; mode=display">\begin{cases}
EX = \bar X\\
DX = S^2
\end{cases}</script><p>&emsp;&emsp; 得到矩估计，其中 $S^2 = \frac1n\sum^n_{i=1}(X_i-\bar X)^2$。</p>
<p><strong>矩估计的优点</strong>：简单易算，n大时精确度高，不依赖于总体分布形式。<br><strong>矩估计的理论依据</strong>：大数定律</p>
<blockquote>
<p>伯努利大数定律：解释频率的稳定性<br>独立同分布大数定律：$X_1,X_2,…X_n$独立同分布，则$X_1^k,X_2^k,…,X_n^k$也独立同分布</p>
</blockquote>
<p><strong>参数函数的矩估计</strong>：设 $\hat\theta$ 是$\theta$的矩估计，$g(\theta)$为$\theta$的连续函数，则定义$g(\theta)$的矩估计为$g(\hat\theta)$。</p>
<hr>
<h4 id="极大似然估计法"><a href="#极大似然估计法" class="headerlink" title="极大似然估计法"></a>极大似然估计法</h4><p><strong>思想</strong>：选择使样本出现可能性最大的p作为p的估计</p>
<p><strong>定义1（似然函数）</strong>：设总体$X$的密度函数为$f(x;\theta_1,\theta_2,…,\theta_k)$，来自$X$的样本为 $X_1, X_2,…,X_n$，其观察值为$x_1, x_2,…,x_n$，称$L(\theta_1,\theta_2,…,\theta_k)=\prod_{i=1}^nf(x_1;\theta_1,\theta_2,…,\theta_k)$为似然函数（注：它就是样本的联合密度函数，离散型变量换成联合分布率）</p>
<p><strong>定义2（极大似然估计）</strong>：若$L(\hat\theta_1,\hat\theta_2,…\hat\theta_k) = max_{\theta_1,\theta_2,…,\theta_k\in \Theta}L(\theta_1,\theta_2,…,\theta_k)$，则称$\hat\theta_i$是$\theta_i$的极大似然估计，简记为MLE。</p>
<p><strong>定义3（对数似然函数）</strong>：$LnL(\theta_1,\theta_2,…,\theta_k)$</p>
<p>对似然方程组：</p>
<script type="math/tex; mode=display">\begin{cases}
\frac{\partial LnL}{\partial \theta_1} = 0\\
\frac{\partial LnL}{\partial \theta_2} = 0\\
...\\
\frac{\partial LnL}{\partial \theta_k} = 0
\end{cases}</script><p>解此方程组并验证可得参数的MLE</p>
<p><strong>例1</strong>：设$X_1,X_2,…,X_n$为来自总体$X(\mu,\sigma^2)$的样本，求$\mu, \sigma^2$的MLE。<br>解：设样本观察值为 $x_1,x_2,…,x_n$</p>
<script type="math/tex; mode=display">L(\mu,\sigma^2) = \prod_{i=1}^nf(x_i) = \prod_{i=1}^n\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x_i-\mu)^2}{2\sigma^2}} = \frac{1}{\sqrt{2\pi}^n\sigma^n}e^{-\frac{\sum_{i=1}^n(x_i-\mu)^2}{2\sigma^2}}</script><p>则：</p>
<script type="math/tex; mode=display">LnL = ln\frac{1}{(\sqrt{2\pi})^n} + ln\frac{1}{\sigma^n} -\frac{\sum_{i=1}^n(x_i-\mu)^2}{2\sigma^2} = ln\frac{1}{(\sqrt{2\pi})^n} - \frac{n}{2}ln\sigma^2 -\frac{\sum_{i=1}^n(x_i-\mu)^2}{2\sigma^2}</script><p>置偏导为0：</p>
<script type="math/tex; mode=display">\frac{\partial lnL}{\partial \mu} = \frac{1}{\sigma^2}\sum_{i=1}^n(x_i-\mu) = 0</script><script type="math/tex; mode=display">\frac{\partial lnL}{\partial \sigma^2} = -\frac{n}{2\sigma^2} + \frac{\sum_{i=1}^{n}(x_i-\mu)^2}{2\sigma^4}</script><p>易解得：</p>
<script type="math/tex; mode=display">\mu = \bar x, \sigma^2 = s^2</script><p>（验证：若驻点唯一且不在边界上取到，则可以把驻点作为MLE）</p>
<p><strong>例2</strong>：设$X_1,X_2,…,X_n$为来自总体$B(1,p)$的样本，求$p$的MLE。<br>解：设样本观察值为$x_1,x_2,…,x_n$,</p>
<script type="math/tex; mode=display">L(p) = \prod_{i=1}^nP(X_i=x_i)</script><p>又 $P(X=x)=p^x(1-p)^{1-x}$，故</p>
<script type="math/tex; mode=display">L(p) = \prod_{i=1}^np^{x_i}(1-p)^{1-x_i} = p^{\sum_{i=1}^nx_i}(1-p)^{n-\sum_{i=1}^nx_i}</script><p>取对数似然函数：</p>
<script type="math/tex; mode=display">LnL(p) = \sum_{i=1}^nx_ilnp+(n-\sum_{i=1}^nx_i)ln(1-p)</script><p>对p求偏导：</p>
<script type="math/tex; mode=display">\frac{\partial lnL(p)}{\partial p} = \frac{\sum_{i=1}^nx_i}{p} - \frac{n-\sum_{i=1}^nx_i}{1-p}</script><p>解得：</p>
<script type="math/tex; mode=display">p = \bar x</script><p>求二阶导数，$\frac{\partial^2lnL(p)}{\partial^2p}$严格小于0，故$p=\bar x$是极大值点，故$p$的 MLE 为$\hat p=\bar x$.</p>
<p><strong>例3</strong>：设$X_1,X_2,…,X_n$为来自总体$U[0,\theta]$的样本，求$\theta$的MLE。<br>解：设样本观察值为$x_1,x_2,…,x_n$,<br>由密度函数：</p>
<script type="math/tex; mode=display">f(x) = \begin{cases}
\frac{1}{\theta},0\le x\le \theta\\
0，其他
\end{cases}</script><p>似然函数为：</p>
<script type="math/tex; mode=display">L(\theta) = \prod_{i=1}^nf(x_i) = \frac{1}{\theta^n}, 0\le x_i \le \theta,i=1,2,...,n</script><p>对$\theta$求导：</p>
<script type="math/tex; mode=display">\frac{\partial l(\theta)}{\partial \theta} = \frac{-n}{\theta^{n+1}} = 0</script><p>驻点不存在，只能通过定义求：</p>
<script type="math/tex; mode=display">\theta = \frac{1}{\theta^n}, 0\le x_i \le \theta,i=1,2,...,n = \frac{1}{\theta^n}, 0\le x_{(1)} \le x_{(n)} \le \theta</script><p>故 $\hat \theta = X_{(n)} = max{ {x_1, x_2,…,x_n} }$</p>
<p><strong>定理1</strong>：设$\hat\theta$是$\theta$的MLE，$g(\theta)$是$\theta$的严格单调函数，则$g(\theta)$的MLE为$\hat{g(\theta)}$ =  $g(\hat\theta)$.(与矩估计的相应结论类似)</p>
<p><strong>例4</strong>：从一批产品中抽取了n件产品检查质量，发现其中k件产品不合格，求这批产品中合格品数与不合格品数之比的MLE。<br>解：设这批产品的总数为N，其中不合格品数为K件，则这批产品中合格品数与不合格品数之比$=\frac{N-K}{K} = \frac{1-p}{p} = \frac{1}{p}-1$，其中p表示这批产品中的不合格率，关于 $p$ 严格单调，故所求的MLE$=\hat {\frac{1-p}{p}}= \frac{1-\hat p}{\hat p} = \frac{1-\bar x}{\bar x}$，其中$\bar x$是样本不合格率。</p>
<hr>
<h4 id="点估计的优良标准"><a href="#点估计的优良标准" class="headerlink" title="点估计的优良标准"></a>点估计的优良标准</h4><ol>
<li>无偏性：设 $\theta$ 是待估计参数，$\hat \theta$ 是 $\theta$ 的估计量，若 $E\hat \theta = \theta$，则称$\hat \theta$是$\theta$的无偏估计；（无偏估计有无穷多个）</li>
<li>有效性：设$T_1,T_2$均是$\theta$的无偏估计，若$DT_1\le DT_2$，则称$T_1$ 比$T_2$有效；（最佳点估计）</li>
<li>一致性：设$\hat \theta$是$\theta$的估计量，若任意的$\epsilon \lt 0$都有$\lim_{n\rightarrow \infty} P(|\hat \theta-\theta|\lt \epsilon) = 1$，则称 $\hat\theta$是$\theta$的一致估计。</li>
</ol>
<p><strong>定理2</strong>：样本均值是总体均值的无偏估计；样本方差是总体方差的无偏估计<br>证明：记总体$X$有$EX=\mu$，$DX = \delta^2$，来自$X$的样本为$x_1,x_2,…,x_n$，样本均值$\bar X = \frac1n\sum_{i=1}^nx_i$，方差$S^{*2} = \frac1{n-1}\sum_{i=1}^n(x_i-\bar x)^2$，有</p>
<script type="math/tex; mode=display">E\bar X = E\frac1n\sum_{i=1}^nEx_i = \frac1n\sum_{i=1}^n\mu = \mu</script><p>因此 $\bar X$ 是 $\mu$ 的无偏估计，又</p>
<script type="math/tex; mode=display">\begin{eqnarray}ES^{*2} &=& E\frac{n}{n-1}\sum_{i=1}^n\frac{(x_i-\bar x)^2}{n} \\
&=& \frac{n}{n-1}E(\frac1n\sum_{i=1}^nx_i^2 - \bar x^2) \\
&=& \frac{n}{n-1}(\frac1n\sum_{i=1}^nEx_i^2 - E\bar x^2)\\
&=& \frac{n}{n-1}(\frac1n\sum_{i=1}^n(\sigma^2+\mu^2) - (\frac{\sigma^2}{n} + \mu^2)\\
&=& \sigma^2
\end{eqnarray}</script><p>注意到 $ES^2 = \frac{n-1}{n}ES^{*2}$ 不是无偏估计，是有偏估计。</p>
<p><strong>定义4</strong>：若$E\hat \theta \neq \theta$，但$\lim\limits_{n \rightarrow +\infty} E\hat \theta = \theta$，则称$\hat \theta$是$\theta$的渐近无偏估计。<br>显见，$ES^2$是总体方差的渐近无偏估计。</p>
<p><strong>例5</strong>：设总体$X$ ~ $U[0,\theta]$，$\hat\theta$是$\theta$的MLE，找常数$a,b$使$a\hat \theta + b$是$\theta$的无偏估计。<br>解：由例3结果，$\hat\theta = X_{(n)}$，分布函数为：</p>
<script type="math/tex; mode=display">f_{X(n)} = n[F(x)]^{n-1}f(x)</script><p>且已知：</p>
<script type="math/tex; mode=display">f(x) = \begin{cases}
\frac{1}{\theta},0\le x\le \theta\\
0，其他
\end{cases}</script><p>以及：</p>
<script type="math/tex; mode=display">F(x) = \begin{cases}
0, x\lt 0\\
\frac{1}{\theta},0\le x\le \theta\\
1,x\geq\theta
\end{cases}</script><p>代入得：</p>
<script type="math/tex; mode=display">f_{X(n)}(x)=\begin{cases}
n(\frac{x}{\theta})^{n-1}\frac1\theta,0\le x\le \theta\\
0,其他
\end{cases}</script><p>故：</p>
<script type="math/tex; mode=display">\begin{eqnarray}
EX_{(n)} &=& \int_{-\infty}^{+\infty}xf_{x_{(n)}}(x){\rm d}x\\
&=& \int_0^\theta x·n\frac{x^{n-1}}{\theta^n}{\rm d}x\\
&=& \frac{n}{n+1}\theta
\end{eqnarray}</script><p>令</p>
<script type="math/tex; mode=display">E(aX_{(n)}+b) = aEX_{(n)} + b = a\frac{n}{n+1}\theta + b = \theta</script><p>有：</p>
<script type="math/tex; mode=display">a = \frac{n+1}{n}, b=0.</script><p>即 $\frac{n+1}{n}X_{(n)}$ 是$\theta$的无偏估计。</p>
<p><strong>定义5</strong>：$\theta$ 的无偏估计全体构成一个集合 —— $\theta$ 的无偏估计类，其中方差最小的估计称为最小元素无偏估计，记为MVUE。</p>
<p><strong>定义6</strong>：设$T$是 $g(\theta)$ 的任意一个无偏估计，在一定条件下，有下列 C-R 不等式：$DT\ge \frac{[g^`(\theta)]^2}{nI(\theta)}$，其中$I(\theta) = E[\frac{\partial (lnf(X;\theta))}{\partial \theta}]^2$，不等式右边实自被称为$g(\theta)$的无偏估计 C-R 下界。</p>
<p><strong>定义7</strong>：设T是$\theta$的无偏估计，称$e_T = \frac{\frac{1}{nI(\theta)}}{DT}$为$\theta$ 的有效率$(0\le e_T \le 1)$，有效率为1的估计称为优效估计。若$e_T\neq 1$，但$\lim_{n\rightarrow \infty}e_T = 1$，称为渐近优效估计。</p>
<h3 id="区间估计"><a href="#区间估计" class="headerlink" title="区间估计"></a>区间估计</h3><p><strong>定义1</strong>：设$T_1,T_2$是 $\theta$ 的估计量，若对于给定值 $\alpha(0\lt \alpha \lt 1)$有，$P(T_1\le \theta \le T_2)=1-\alpha$，则称$[T_1,T_2]$是$\theta$ 的置信水平为$1-\alpha$的区间估计或置信区间。</p>
<p><strong>区间估计的优良标准</strong>：</p>
<ol>
<li>可靠性：$1-\alpha$越大越可靠</li>
<li>精确性：$E(T_1-T_2)$越小越精确</li>
</ol>
<p>可靠性与精确性是一对矛盾，一般处理原则：在可靠性条件满足的下，找 $E[T_2-T_1]$ 最小的，这样的区间估计被认为是最优的。</p>
<h4 id="单个正态总体-N-mu-sigma-2-参数的区间估计"><a href="#单个正态总体-N-mu-sigma-2-参数的区间估计" class="headerlink" title="单个正态总体 $N(\mu,\sigma^2)$ 参数的区间估计"></a>单个正态总体 $N(\mu,\sigma^2)$ 参数的区间估计</h4><p><strong>$\mu$ 的区间估计</strong></p>
<ol>
<li><p>当$\sigma$已知时，$\mu$的置信水平为$1-\alpha$的区间估计是$[\bar x-z_{1-\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}},\bar x + z_{1-\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}})]$<br>证明：要找 $\mu \in [T_1, T_2]$，使得$P(T_1&lt;\mu &lt; T_2) = 1-\alpha$，取$a, b$，使得 $\mu \in [\bar x - a, \bar x + b]$，使得 $P(\bar x- a&lt;\mu &lt; \bar x + b) = 1-\alpha$，由于$\frac{\bar x - \mu}{\sigma}\sqrt n$~$N(0, 1)$，我们可以将原始化为</p>
<script type="math/tex; mode=display">P(-\frac{b\sqrt{n}}{\sigma} \le \frac{\bar x - \mu}{\sigma}\sqrt{n} \le \frac{a\sqrt n}{\sigma}) = 1-\alpha</script><p>我们只需找到$a^<em>$与$b^</em>$，使得</p>
<script type="math/tex; mode=display">P(b^* \le \frac{\bar x - \mu}{\sigma}\sqrt{n} \le a^*) = 1-\alpha</script><p>左式 = $\int_{b^<em>}^{a^</em>}\phi(x){\rm d}x$，设正态曲线分布图 $b^*$左边区域面积为 $\beta$，则有：</p>
<script type="math/tex; mode=display">P(z_{1-\alpha+\beta} \le \frac{\bar x - \mu}{\sigma}\sqrt{n} \le z_\beta) = 1-\alpha</script><p>即：</p>
<script type="math/tex; mode=display">P(\bar x-z_\beta \frac{\sigma}{\sqrt{n}} \le \mu \le \bar x - z_{1-\alpha+\beta}\frac{\sigma}{\sqrt{n}}) = 1-\alpha</script><p>(任意取定 $\alpha$，$\beta$有无穷多个取值，可以构造无穷多个满足条件的区间<br>找最优的区间估计：</p>
<script type="math/tex; mode=display">E[\bar x - z_{1-\alpha+\beta}\frac{\sigma}{\sqrt{n}} - \bar x+z_\beta \frac{\sigma}{\sqrt{n}}] = E(z_\beta - z_{1-\alpha+\beta})\frac{\sigma}{\sqrt{n}} = (z_\beta - z_{1-\alpha+\beta})\frac{\sigma}{\sqrt{n}}</script><p>令 $g^<code>(\beta) = z_\beta - z_{1-\alpha+\beta} = (z_\beta)^</code> - (z_{1-\alpha+\beta})^`$<br>设分布函数为 $\Phi(z_\beta) = \beta$，两边对$\beta$求导，得：</p>
<script type="math/tex; mode=display">\Phi(z_\beta)(z_{\beta})^`_\beta = 1</script><p>因此有 $(z_\beta)^`_\beta = \frac {1}{\Phi(z_\beta)}$，又有 $\Phi(z_{1-\alpha+\beta}) = 1-\alpha+\beta$，两边对 $\beta$ 求导，得：</p>
<script type="math/tex; mode=display">\Phi(z_{1-\alpha+\beta})(z_{1-\alpha+\beta})^`_\beta = 1</script><p>因此有 $(z_{1-\alpha+\beta})^<code>= \frac{1}{\Phi(z_{1-\alpha+\beta})}$
综上，要使 $g^</code>(\beta) =0$，即使 $\frac {1}{\Phi(z_\beta)} = \frac{1}{\Phi(z_{1-\alpha+\beta})}$，也就是$\Phi(z_\beta) = \Phi(z_{1-\alpha+\beta})$，因此两点关于 $y$ 轴对称，此时能保证平均长度最短</p>
</li>
<li><p>当 $\sigma$ 未知时， $\mu$ 的置信水平为 $1-\alpha$ 的区间估计是 $[\bar X - t_\frac{\alpha}{2}(n-1)\frac{S}{\sqrt{n}},\bar X + t_\frac{\alpha}{2}(n-1)\frac{S}{\sqrt{n}}]$<br>证明：$\sigma$ 未知，我们可以考虑它的估计量  $S^*$，由前面推导：</p>
<script type="math/tex; mode=display">\frac{\bar X-\mu}{S^*}\sqrt{n} - t(n-1)</script><p>因此有</p>
<script type="math/tex; mode=display">P(-a\le \frac{\bar X-\mu}{S^*}\sqrt{n}\le a) = \int_{-a}^a f_T(x){\rm d}x = 1-\alpha</script><p>容易确定 $a = t_{\frac{\alpha}{2}}(n-1)$，即得所证</p>
</li>
</ol>
<p><strong>$\sigma$ 的区间估计</strong></p>
<ol>
<li>$\sigma^2$的置信水平为$1-\alpha$的置信区间为 $[\frac{(n-1)S^{<em>2}}{\chi^2_{\frac{\alpha}{2}}(n-1)}, \frac{(n-1)S^{</em>2}}{\chi^2_{1-\frac{\alpha}{2}}(n-1)}]$.</li>
</ol>
<p>证明：由已知 </p>
<script type="math/tex; mode=display">\frac{(n-1)S^{*2}}{\sigma^2} - \chi^2(n-1)</script><p>设</p>
<script type="math/tex; mode=display">P(a\le \frac{(n-1)S^{*2}}{\sigma^2} \le b) = 1-\alpha</script><p>实际上，卡方密度函数并不对称，但我们可以近似认为其对称以求出简单化的结果：</p>
<script type="math/tex; mode=display">a = \chi^2_{1-\frac{\alpha}{2}}(n-1), b = \chi^2_{\frac{\alpha}{2}}(n-1)</script><p>取倒数，不等号反向即可</p>
<ol>
<li>$\sigma$ 的置信水平为 $1-\alpha$ 的置信区间为 $[\sqrt{\frac{(n-1)S^{<em>2}}{\chi^2_{\frac{\alpha}{2}}(n-1)}}, \sqrt{\frac{(n-1)S^{</em>2}}{\chi^2_{1-\frac{\alpha}{2}}(n-1)}}]$</li>
</ol>
<p>证明：事实上，由于 $\sigma&gt;0$，有：</p>
<script type="math/tex; mode=display">P(T_1\le \sigma^2 \le T_2) = 1-\alpha  P(\sqrt{T_1} \le \sigma \le \sqrt{T_2}) = 1-\alpha</script><p>故 $\sigma \in [\sqrt{T_1},\sqrt{T2}]$<br>(类似的有： $e^{\sigma} \in [e^{\sqrt{T_1}}, e^{\sqrt{T_2}}]$)</p>
<h4 id="分布自由时总体均值的区间估计"><a href="#分布自由时总体均值的区间估计" class="headerlink" title="分布自由时总体均值的区间估计"></a>分布自由时总体均值的区间估计</h4><p>$EX$的置信水平为$1-\alpha$的近似区间估计为$[\bar X-u_{1-\frac{\alpha}{2}}\frac{S^<em>}{\sqrt{n}}, \bar X+u_{1-\frac{\alpha}{2}}\frac{S^</em>}{\sqrt{n}}]$</p>
<blockquote>
<p>中心极限定理：设$x_1,x_2,…,x_n$独立同分布，且$Ex_1 = \mu, Dx_1=\sigma^2$存在，则 $lim_{n\rightarrow \infty}P(\frac{\sum_{i=1}^nx_i - n\mu}{\sqrt{n}\sigma} \le x) = \Phi(x), x \in R$，因此当$n$充分大时，$\frac{\sum_{i=1}^nx_i-n\mu}{\sqrt{n}\sigma}$ ~ $N(0,1)$，由于左式实际上为关于$\sum_{i=1}^nx_i$的线性变换，因此$\sum_{i=1}^nx_i$~$N(a, b)$，其中$a=n\mu, b=n\sigma^2$，同理$\bar X =\frac{\sum_{i=1}^nx_i}{n}$ ~ $N(\mu, \frac{\sigma^2}{n})$。</p>
</blockquote>
<p><strong>例</strong>：设样本总体 $X$ ~ $E(\lambda)$，来自$X$的样本为 $x_1,x_2,…,x_n$，求$\lambda$的置信水平为$1-\alpha$的区间估计，提示：若$x$~$E(\lambda)$，则$2x\lambda$ ~ $\chi^2(2)$</p>
<p>解：$P(a\le2\lambda n\bar x\le b) = 1-\alpha$，直接取左右两边各为$\frac{\alpha}{2}$即可满足，因此$a=\chi_{1-\frac{\alpha}{2}}^2(2n)$，$b=\chi_{\frac{\alpha}{2}}^2(2n)$，取倒数即可解出$\lambda$的区间估计。</p>
<h4 id="两个正态总体参数的区间估计"><a href="#两个正态总体参数的区间估计" class="headerlink" title="两个正态总体参数的区间估计"></a>两个正态总体参数的区间估计</h4><p><strong>均值差的区间估计</strong></p>
<ol>
<li><p>$\sigma_1^2, \sigma_2^2$已知，则$\mu_1-\mu_2$的置信水平为$1-\alpha$的区间估计为$[\bar X - \bar Y -Z_{1-\frac{\alpha}{2}}\sqrt{\frac{\sigma_1^2}{n} + \frac{\sigma_2^2}{m}}, \bar X - \bar Y +Z_{1-\frac{\alpha}{2}}\sqrt{\frac{\sigma_1^2}{n} + \frac{\sigma_2^2}{m}}]$<br>证明：$\bar X$ ~ $N(\mu_1, \frac{\sigma_1^2}{n})$，$\bar Y$ ~ $N(\mu_2, \frac{\sigma_2^2}{m})$，<br>$E(\bar X-\bar Y)=\mu_1-\mu_2$，$D(\bar X-\bar Y) = D\bar X+D(-\bar Y) = D\bar X +D\bar Y$，<br>因此$\frac{\bar X-\bar Y - (\mu_1-\mu_2)}{\sqrt{\frac{\sigma_1^2}{n}+\frac{\sigma_2^2}{m}}}$~$N(0,1)$，由枢轴量法易解</p>
</li>
<li><p>$\sigma_1^2,\sigma_2^2$未知，但$\sigma_1^2=\sigma_2^2 = \sigma^2$.<br>证明：$\frac{\bar X-\bar Y - (\mu_1-\mu_2)}{\sqrt{\frac{\sigma^2}{n}+\frac{\sigma^2}{m}}} = \frac{\bar X-\bar Y - (\mu_1-\mu_2)}{\sigma\sqrt{\frac{1}{n}+\frac{1}{m}}}$~$N(0,1)$，由于$\sigma$未知，因此不可以直接作为枢轴量。<br>由已知<br>$\frac{(n-1)S_X^2}{\sigma^2}+\frac{(m-1)S_Y^2}{\sigma^2}$ ~ $\chi^2(n+m-2)$，易知该变量与标准正态独立，因此联立消去$\sigma$即可</p>
</li>
</ol>
<h4 id="求区间估计的常用方法——找枢轴量法"><a href="#求区间估计的常用方法——找枢轴量法" class="headerlink" title="求区间估计的常用方法——找枢轴量法"></a>求区间估计的常用方法——找枢轴量法</h4><p>设 $\theta$ 是待估计参数，样本为 $x_1, x_2, …, x_n$</p>
<ol>
<li>构造函数$g(x_1, x_2, …, x_n;\theta)$关于$\theta$单调；</li>
<li>求此函数得分布；</li>
<li>确定分位数；</li>
<li>解不等式可得$\theta$得区间估计.</li>
</ol>
]]></content>
      <categories>
        <category>Mathematics</category>
      </categories>
  </entry>
  <entry>
    <title>XGBoost（一）简单机器学习示例</title>
    <url>/posts/298496a6.html</url>
    <content><![CDATA[<h1 id="一、XGBoost简单应用"><a href="#一、XGBoost简单应用" class="headerlink" title="一、XGBoost简单应用"></a>一、XGBoost简单应用</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">xgb_train = xgb.DMatrix(<span class="string">"xgboost_source_code/demo/data/agaricus.txt.train"</span>)</span><br><span class="line">xgb_test = xgb.DMatrix(<span class="string">"xgboost_source_code/demo/data/agaricus.txt.test"</span>)</span><br><span class="line">param = &#123;<span class="string">'max_depth'</span>:<span class="number">2</span>, <span class="string">'eta'</span>:<span class="number">1</span>, <span class="string">'objective'</span>:<span class="string">'binary:logistic'</span>&#125;</span><br><span class="line">num_round = <span class="number">5</span></span><br><span class="line">watch_list = [(xgb_train, <span class="string">"train"</span>), (xgb_test, <span class="string">"test"</span>)]</span><br><span class="line">model = xgb.train(param, xgb_train, num_round, watch_list)</span><br></pre></td></tr></table></figure>
<pre><code>[0]    train-error:0.04652    test-error:0.04283
[1]    train-error:0.02226    test-error:0.02173
[2]    train-error:0.00706    test-error:0.00621
[3]    train-error:0.01520    test-error:0.01800
[4]    train-error:0.00706    test-error:0.00621
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">preds = model.predict(xgb_test)</span><br><span class="line">preds</span><br></pre></td></tr></table></figure>
<pre><code>array([0.08073306, 0.92217326, 0.08073306, ..., 0.98059034, 0.01182149,
       0.98059034], dtype=float32)
</code></pre><h1 id="二、机器学习算法基础"><a href="#二、机器学习算法基础" class="headerlink" title="二、机器学习算法基础"></a>二、机器学习算法基础</h1><p>我们首先介绍几个基础的机器学习算法的实现原理和应用，如KNN、线性回归、逻辑回归等，使读者对机器学习算法有一个基本认识的同时，了解如何在模型训练过程中进行优化，以及如何对模型结果进行评估。然后，对决策树模型做了详细介绍。决策树是XGBoost模型的重要组成部分，学习和掌握决策树的生成、剪枝等内容将会对后续的学习提供巨大帮助。排序问题是机器学习中的常见问题，神经网络和支持向量机也是经常采用的机器学习算法，最后将分别介绍两者的实现原理，结合详细的公式推导过程，使读者能够深入理解算法背后的数学原理。</p>
<h2 id="1-KNN做鸢尾花数据预测"><a href="#1-KNN做鸢尾花数据预测" class="headerlink" title="1. KNN做鸢尾花数据预测"></a>1. KNN做鸢尾花数据预测</h2><p>KNN的主要算法思想为：特征空间中的一个样本，如果与其最相似的k个样本中的大部分属于某个类别，则该样本也属于该类别。KNN既可以用于解决分类问题，也可以用于回归问题。</p>
<p>对于分类问题，离样本最近的k个邻居中占多数的类别作为该样本的类别，如果k=1，则选取最近邻居的类别作为该样本的类别。对于回归问题，样本的预测值是最近的k个邻居的平均值。</p>
<p>KNN的计算步骤如下。</p>
<ol>
<li>计算测试样本与训练集中所有（或大部分）样本的距离，该距离可以是欧氏距离、余弦距离等，较常用的是欧氏距离。</li>
<li>找到步骤1中距离最短的k个样本，作为预测样本的邻居。</li>
<li>对于分类问题，通过投票机制选出k个邻居中最多的类别作为预测样本的预测值。对于回归问题，则采用k个邻居的平均值。</li>
</ol>
<p>Iris也称鸢尾花卉数据集，是一类多重变量分析的数据集。数据集包含150个数据集，分为3类，每类50个数据，每个数据包含4个属性。可通过花萼长度，花萼宽度，花瓣长度，花瓣宽度4个属性预测鸢尾花卉属于（Setosa，Versicolour，Virginica）三个种类中的哪一类。</p>
<p><strong>数据描述</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>变量名</th>
<th>sepal_length</th>
<th>sepal_width</th>
<th>petal_length</th>
<th>petal_width</th>
<th>species</th>
</tr>
</thead>
<tbody>
<tr>
<td>变量解释</td>
<td>花萼长度（单位cm）</td>
<td>花萼宽度（单位cm）</td>
<td>花瓣长度（单位cm）</td>
<td>花瓣宽度（单位cm）</td>
<td>种类</td>
</tr>
<tr>
<td>数据类型</td>
<td>numeric</td>
<td>numeric</td>
<td>numeric</td>
<td>numeric</td>
<td>categorical</td>
</tr>
</tbody>
</table>
</div>
<h3 id="1-1-导入数据集并观察分布"><a href="#1-1-导入数据集并观察分布" class="headerlink" title="1.1 导入数据集并观察分布"></a>1.1 导入数据集并观察分布</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line">iris = load_iris()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.DataFrame(iris.data, columns=iris.feature_names).head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal length (cm)</th>
      <th>sepal width (cm)</th>
      <th>petal length (cm)</th>
      <th>petal width (cm)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
  </tbody>
</table>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">setosa_sepal_len = iris.data[:<span class="number">50</span>, <span class="number">0</span>]</span><br><span class="line">setosa_sepal_width = iris.data[:<span class="number">50</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">versi_sepal_len = iris.data[<span class="number">50</span>:<span class="number">100</span>, <span class="number">0</span>]</span><br><span class="line">versi_sepal_width = iris.data[<span class="number">50</span>:<span class="number">100</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">vergi_sepal_len = iris.data[<span class="number">100</span>:, <span class="number">0</span>]</span><br><span class="line">vergi_sepal_width = iris.data[<span class="number">100</span>:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">pyplot.scatter(setosa_sepal_len, setosa_sepal_width, marker = <span class="string">'o'</span>, c = <span class="string">'b'</span>,  s = <span class="number">30</span>, label = <span class="string">'Setosa'</span>)</span><br><span class="line">pyplot.scatter(versi_sepal_len, versi_sepal_width, marker = <span class="string">'o'</span>, c = <span class="string">'r'</span>,  s = <span class="number">50</span>, label = <span class="string">'Versicolour'</span>)</span><br><span class="line">pyplot.scatter(vergi_sepal_len, vergi_sepal_width, marker = <span class="string">'o'</span>, c = <span class="string">'y'</span>,  s = <span class="number">35</span>, label = <span class="string">'Virginica'</span>)</span><br><span class="line">pyplot.xlabel(<span class="string">"sepal length"</span>)</span><br><span class="line">pyplot.ylabel(<span class="string">"sepal width"</span>)</span><br><span class="line">pyplot.title(<span class="string">"sepal length and width scatter"</span>)</span><br><span class="line">pyplot.legend(loc = <span class="string">"upper right"</span>)</span><br></pre></td></tr></table></figure>
<p><img src="\Pic\XGBoost_Pic\output_7_1.png" alt="png"></p>
<h3 id="2-绘制各个品种各个特征平均值的直方图"><a href="#2-绘制各个品种各个特征平均值的直方图" class="headerlink" title="2. 绘制各个品种各个特征平均值的直方图"></a>2. 绘制各个品种各个特征平均值的直方图</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">iris_data = pd.DataFrame(iris.data, columns=iris.feature_names)</span><br><span class="line">iris_data[<span class="string">"class"</span>] = iris.target</span><br><span class="line">iris_data.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal length (cm)</th>
      <th>sepal width (cm)</th>
      <th>petal length (cm)</th>
      <th>petal width (cm)</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">grouped_data = iris_data.groupby(<span class="string">"class"</span>)</span><br><span class="line">group_mean = grouped_data.mean()</span><br><span class="line">group_mean.plot(kind=<span class="string">'bar'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">"center right"</span>, bbox_to_anchor=(<span class="number">1.4</span>, <span class="number">0.3</span>), ncol=<span class="number">1</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="\Pic\XGBoost_Pic\output_10_0.png" alt="png"></p>
<h3 id="3-划分数据集"><a href="#3-划分数据集" class="headerlink" title="3. 划分数据集"></a>3. 划分数据集</h3><p>因为我们至少需要一个训练集来训练模型（KNN则用于最终预测计算），一个测试集来检验模型对新样本的预测能力，而目前只有一个数据集，因此需要对数据集进行划分。划分数据集有很多方法，比如留出法（hold-out）、交叉验证法等，本示例采用较常用的留出法。留出法的实现原理是，按照一定比例将数据集划分为互不相交的两部分，分别作为训练集和测试集。此处选用的训练集、测试集的比例为4:1，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">msk = np.random.rand(len(iris_data)) &lt; <span class="number">0.8</span></span><br><span class="line">train_data_origin = iris_data[msk]</span><br><span class="line">test_data_origin = iris_data[~msk]</span><br><span class="line"></span><br><span class="line">train_data = train_data_origin.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">test_data = test_data_origin.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">train_label = train_data[<span class="string">"class"</span>]</span><br><span class="line">test_label = test_data[<span class="string">"class"</span>]</span><br><span class="line"></span><br><span class="line">train_fea = train_data.drop(<span class="string">"class"</span>, <span class="number">1</span>)</span><br><span class="line">test_fea = test_data.drop(<span class="string">"class"</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数据归一化</span></span><br><span class="line">train_norm = (train_fea - train_fea.min()) / (train_fea.max() - train_fea.min())</span><br><span class="line">test_norm = (test_fea - test_fea.min()) / (test_fea.max() - test_fea.min())</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> neighbors</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">knn = neighbors.KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line">knn.fit(train_norm, train_label)</span><br><span class="line">predict = knn.predict(test_norm)</span><br><span class="line">accuracy = accuracy_score(test_label, predict)</span><br><span class="line">accuracy</span><br></pre></td></tr></table></figure>
<pre><code>0.9166666666666666
</code></pre><p>KNN算法是机器学习中最简单、有效的算法。上面通过鸢尾花品种分类的示例详细介绍了KNN算法的实现原理和应用。KNN算法属于懒惰学习算法，当数据集的样本容量比较大时，计算量也会比较大，并且需要较大的存储空间。此外，它无法给出数据的任何基础结构信息，后面介绍的算法将会解决这个问题。</p>
<h2 id="2-线性回归预测波士顿房价"><a href="#2-线性回归预测波士顿房价" class="headerlink" title="2. 线性回归预测波士顿房价"></a>2. 线性回归预测波士顿房价</h2><p>下面通过一个示例来说明如何应用线性回归。以波士顿房屋价格数据集作为示例数据集，该数据集包含了波士顿房屋以及周边环境的一些详细信息，包括城镇人均犯罪率、一氧化碳浓度、住宅平均房屋数等。该数据集包含506个样本、13个特征字段、1个label字段</p>
<p><strong>数据描述</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>No</th>
<th>属性</th>
<th>数据类型</th>
<th>字段描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>CRIM</td>
<td>Float</td>
<td>城镇人均犯罪率</td>
</tr>
<tr>
<td>2</td>
<td>ZN</td>
<td>Float</td>
<td>占地面积超过2.5万平方英尺的住宅用地比例</td>
</tr>
<tr>
<td>3</td>
<td>INDUS</td>
<td>Float</td>
<td>城镇非零售业务地区的比例</td>
</tr>
<tr>
<td>4</td>
<td>CHAS</td>
<td>Integer</td>
<td>查尔斯河虚拟变量 (= 1 如果土地在河边；否则是0)</td>
</tr>
<tr>
<td>5</td>
<td>NOX</td>
<td>Float</td>
<td>一氧化氮浓度（每1000万份）</td>
</tr>
<tr>
<td>6</td>
<td>RM</td>
<td>Float</td>
<td>平均每居民房数</td>
</tr>
<tr>
<td>7</td>
<td>AGE</td>
<td>Float</td>
<td>在1940年之前建成的所有者占用单位的比例</td>
</tr>
<tr>
<td>8</td>
<td>DIS</td>
<td>Float</td>
<td>与五个波士顿就业中心的加权距离</td>
</tr>
<tr>
<td>9</td>
<td>RAD</td>
<td>Integer</td>
<td>辐射状公路的可达性指数</td>
</tr>
<tr>
<td>10</td>
<td>TAX</td>
<td>Float</td>
<td>每10,000美元的全额物业税率</td>
</tr>
<tr>
<td>11</td>
<td>PTRATIO</td>
<td>Float</td>
<td>城镇师生比例</td>
</tr>
<tr>
<td>12</td>
<td>B</td>
<td>Float</td>
<td>1000（Bk - 0.63）^ 2其中Bk是城镇黑人的比例</td>
</tr>
<tr>
<td>13</td>
<td>LSTAT</td>
<td>Float</td>
<td>人口中地位较低人群的百分数</td>
</tr>
<tr>
<td>14</td>
<td>MEDV</td>
<td>Float</td>
<td>（目标变量/类别属性）以1000美元计算的自有住房的中位数</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line">boston = load_boston()</span><br><span class="line">X = boston.data</span><br><span class="line">y = boston.target</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line">lr = LinearRegression()</span><br><span class="line">lr.fit(X_train, y_train)</span><br><span class="line">y_pred = lr.predict(X_test)</span><br><span class="line">mean_squared_error(y_test, y_pred)</span><br></pre></td></tr></table></figure>
<pre><code>23.380836480270315
</code></pre><p>另外XGBoost也提供了线性回归的API，其数据加载步骤与上述<code>scikit-learn</code>的方法相同，不再赘述。使用XGBoost，首先要把数据转化为其自定义的<code>DMatrix</code>格式，该格式为XGBoost特定的输入格式。然后定义模型参数，此处定义较为简单，只选用了2个参数，如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">params = &#123;<span class="string">"objective"</span>:<span class="string">"reg:linear"</span>, <span class="string">"booster"</span>:<span class="string">"gblinear"</span>&#125;</span><br></pre></td></tr></table></figure>
<p>其中，<code>objective</code>用于确定模型的目标函数，这里以<code>reg:squarederror</code>作为目标函数。参数<code>booster</code>用于确定采用什么样的模型，此处选择的是线性模型（gblinear），读者也可根据应用场景选择其他模型（gbtree、dart），因本节主要介绍线性回归，因此选用线性模型。定义好参数后即可训练模型，最后用该模型对测试集进行预测。代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_xgb = xgb.DMatrix(X_train, y_train)</span><br><span class="line">params = &#123;<span class="string">"objective"</span>:<span class="string">"reg:squarederror"</span>, <span class="string">"booster"</span>:<span class="string">"gblinear"</span>&#125;</span><br><span class="line">model = xgb.train(dtrain=train_xgb, params=params)</span><br><span class="line">y_pred = model.predict(xgb.DMatrix(X_test))</span><br></pre></td></tr></table></figure>
<p>综上，线性回归是一种解决回归问题的常见方法。在线性回归中，求解最优参数的方法是最小化其损失函数。最小化损失函数有两种方法：<strong>正规方程和梯度下降法</strong>。</p>
<p>正规方程通过矩阵运算求得最优参数，但其必须满足$X^TX$可逆，当样本数比特征数还少时，$X^TX$的逆是不能直接计算的。</p>
<p>梯度下降法是沿负梯度的方向一步步最小化损失函数，求解最优参数。梯度下降法需要指定步长并进行多次迭代，但相比于正规方程，梯度下降法可以应用于特征数较大的情况。最后，通过波士顿房价的示例展示了通过scikit-learn和XGBoost如何应用线性回归。</p>
<h2 id="3-逻辑回归预测良性-恶性乳腺肿瘤"><a href="#3-逻辑回归预测良性-恶性乳腺肿瘤" class="headerlink" title="3. 逻辑回归预测良性/恶性乳腺肿瘤"></a>3. 逻辑回归预测良性/恶性乳腺肿瘤</h2><p>下面将使用逻辑回归预测乳腺肿瘤是良性的还是恶性的。示例采用的数据集为威斯康星诊断乳腺癌数据集，它通过细胞核的相关特征来预测乳腺肿瘤为良性/恶性，这是一个非常著名的二分类数据集。该数据集包含569个样本，其中有212个恶性肿瘤样本，357个良性肿瘤样本。共有32个字段，字段1为ID，字段2为label，其他30个字段为细胞核的相关特征，例如：</p>
<ul>
<li>半径（从中心到周边点的平均距离）</li>
<li>纹理（灰度值的标准偏差）</li>
<li>周长</li>
<li>面积</li>
<li>光滑度（半径长度的局部变化）</li>
<li>紧凑性（周长的二次方/面积的负一次方）</li>
<li>凹度（轮廓的凹陷程度）</li>
<li>凹点（轮廓中凹部的数量）</li>
<li>对称</li>
<li>分形维数</li>
</ul>
<p>对于每张图像，分别计算以上10个特征的平均值、标准误差和最差/最大（最大的3个值的平均）值，由此生成30个特征。例如，字段3表示平均半径，字段13表示半径的标准误差，字段23表示最差半径。所有特征都保留4位有效数字。</p>
<p>scikit-learn已经集成了该数据集，并进行了相应的处理（如去掉了ID字段），使用时直接加载即可，如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_breast_cancer</span><br><span class="line">cancer = load_breast_cancer()</span><br><span class="line">X = cancer.data</span><br><span class="line">y = cancer.target</span><br></pre></td></tr></table></figure>
<p>其中，X为特征数据，包含上面介绍的30个特征，y为标签数据，标记乳腺肿瘤类型，1代表良性，0代表恶性。下面按4:1的比例将数据集划分为训练集和测试集：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lr.fit(X_train, y_train)</span><br><span class="line">y_pred = lr.predict(X_test)</span><br><span class="line">print(classification_report(y_test, y_pred, target_names=[<span class="string">"Benign"</span>, <span class="string">"Malignant"</span>]))</span><br></pre></td></tr></table></figure>
<pre><code>              precision    recall  f1-score   support

      Benign       0.95      0.90      0.93        42
   Malignant       0.95      0.97      0.96        72

    accuracy                           0.95       114
   macro avg       0.95      0.94      0.94       114
weighted avg       0.95      0.95      0.95       114
</code></pre><p>其中，列表的左边一列为分类的标签名，<code>avg/total</code>为各列的均值。<code>support</code>表示该类别样本出现的次数。</p>
<p>XGBoost提供了逻辑回归的API，读者可以通过XGBoost中的逻辑回归对数据集进行预测，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_xgb = xgb.DMatrix(X_train, y_train)</span><br><span class="line">params = &#123;<span class="string">"objective"</span>:<span class="string">"reg:logistic"</span>, <span class="string">"booster"</span>:<span class="string">"gblinear"</span>&#125;</span><br><span class="line">model = xgb.train(dtrain=train_xgb, params=params)</span><br><span class="line">y_pred = model.predict(xgb.DMatrix(X_test))</span><br></pre></td></tr></table></figure>
<p>XGBoost逻辑回归API的调用方式和线性回归类似，唯一不同的是目标函数<code>objective</code>改为<code>reg:logistic</code>，<code>booster</code>仍然选择线性模型。</p>
<p>注意，XGBoost在预测结果上和scikit-learn有些差别，XGBoost的预测结果是概率，而scikit-learn的预测结果是0或1的分类（scikit-learn也可通过<code>predict_proba</code>输出概率）。在XGBoost中，如果需要输出0或1的分类，需要用户自己对其进行转化，例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ypred_bst = np.array(y_pred)</span><br><span class="line">y_pred_bst = ypred_bst &gt; <span class="number">0.5</span></span><br><span class="line">y_pred_bst = y_pred_bst.astype(int)</span><br><span class="line">print(classification_report(y_test, y_pred_bst, target_names=[<span class="string">"Benign"</span>, <span class="string">"Malignant"</span>]))</span><br></pre></td></tr></table></figure>
<pre><code>              precision    recall  f1-score   support

      Benign       0.90      0.67      0.77        42
   Malignant       0.83      0.96      0.89        72

    accuracy                           0.85       114
   macro avg       0.87      0.81      0.83       114
weighted avg       0.86      0.85      0.84       114
</code></pre><h2 id="4-决策树解决肿瘤分类问题"><a href="#4-决策树解决肿瘤分类问题" class="headerlink" title="4. 决策树解决肿瘤分类问题"></a>4. 决策树解决肿瘤分类问题</h2><p>scikit-learn实现了决策树算法，它采用的是一种优化的CART版本，既可以解决分类问题，也可以解决回归问题。分类问题使用DecisionTreeClassifier类，回归问题使用DecisionTreeRegressor类。两个类的参数相似，只有部分有所区别，以下是对主要参数的说明。</p>
<ol>
<li><code>criterion</code>：特征选择采用的标准。DecisionTreeClassifier分类树默认采用<code>gini</code>（基尼系数）进行特征选择，也可以使用<code>entropy</code>（信息增益）。DecisionTreeRegressor默认采用MSE（均方误差），也可以使用MAE（平均绝对误差）。</li>
<li><code>splitter</code>：节点划分的策略。支持<code>best</code>和<code>random</code>两种方式，默认为<code>best</code>，即选取所有特征中最优的切分点作为节点的分裂点，<code>random</code>则随机选取部分切分点，从中选取局部最优的切分点作为节点的分裂点。</li>
<li><code>max_depth</code>：树的最大深度，默认为None，表示没有最大深度限制。节点停止分裂的条件是：样本均属于相同类别或所有叶子节点包含的样本数量小于$min_samples_split$。若将该参数设置为None以外的其他值，则决策树生成过程中达到该阈值深度时，节点停止分裂。</li>
<li><code>min_samples_split</code>：节点划分的最小样本数，默认为2。若节点包含的样本数小于该值，则该节点不再分裂。若该字段设置为浮点数，则表示最小样本百分比，划分的最小样本数为$ceil（min_samples_split*n_samples）$。</li>
<li><code>min_samples_leaf</code>：叶子节点包含的最小样本数，默认为1。此字段和<code>min_samples_split</code>类似，取值可以是整型，也可以是浮点型。整型表示一个叶子节点包含的最小样本数，浮点型则表示百分比。叶子节点包含的最小样本数为$ceil（min_samples_leaf*n_samples）$。</li>
<li><code>max_features</code> ：划分节点时备选的最大特征数，默认为None，表示选用所有特征。若该字段为整数，表示选用的最大特征数；若为浮点数，则表示选用特征的最大百分比。最大特征数为$int（max_features*n_features）$。</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_breast_cancer</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"></span><br><span class="line">cancer = load_breast_cancer()</span><br><span class="line">X = cancer.data</span><br><span class="line">y = cancer.target</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">clf = tree.DecisionTreeClassifier(max_depth=<span class="number">4</span>)</span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line">y_pred = clf.predict(X_test)</span><br><span class="line">print(classification_report(y_test, y_pred, target_names=[<span class="string">"Benign"</span>, <span class="string">"Malignant"</span>]))</span><br></pre></td></tr></table></figure>
<pre><code>              precision    recall  f1-score   support

      Benign       0.95      0.87      0.91        46
   Malignant       0.92      0.97      0.94        68

    accuracy                           0.93       114
   macro avg       0.93      0.92      0.93       114
weighted avg       0.93      0.93      0.93       114
</code></pre><p>为便于读者直观地理解树模型，可以使用Graphviz工具包将模型可视化。Graphviz是一个开源的图形可视化软件，可以将结构数据转化为形象的图形或网络，在软件工程、数据库、机器学习等领域的可视化界面中有应用。函数<code>export_graphviz</code>可以将<code>scikit-learn</code>中的决策树导出为Graphviz的格式，导出完成后即可对Graphviz格式的决策树进行图形渲染，如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> graphviz</span><br><span class="line">dot_data = tree.export_graphviz(clf, out_file=<span class="literal">None</span>,</span><br><span class="line">                               feature_names=cancer.feature_names,</span><br><span class="line">                               class_names=cancer.target_names,</span><br><span class="line">                               filled=<span class="literal">True</span>, rounded=<span class="literal">True</span>,</span><br><span class="line">                               special_characters=<span class="literal">True</span>)</span><br><span class="line">graph = graphviz.Source(dot_data)</span><br><span class="line"><span class="comment"># graph</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将dot_data写入到txt文件中</span></span><br><span class="line">f = open(<span class="string">'output/img/dot_data.txt'</span>, <span class="string">'w'</span>) </span><br><span class="line">f.write(dot_data) </span><br><span class="line">f.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解决中文乱码问题</span></span><br><span class="line"><span class="comment"># import re </span></span><br><span class="line"><span class="comment"># f_old = open('dot_data.txt', 'r') </span></span><br><span class="line"><span class="comment"># f_new = open('dot_data_new.txt', 'w', encoding='utf-8') </span></span><br><span class="line"><span class="comment"># for line in f_old: </span></span><br><span class="line"><span class="comment">#     if 'fontname' in line:</span></span><br><span class="line"><span class="comment">#         font_re = 'fontname=(.*?)]'</span></span><br><span class="line"><span class="comment">#     old_font = re.findall(font_re, line)[0]</span></span><br><span class="line"><span class="comment">#     line = line.replace(old_font, 'SimHei')</span></span><br><span class="line"><span class="comment">#     f_new.write(line)</span></span><br><span class="line"><span class="comment">#     f_old.close()</span></span><br><span class="line"><span class="comment">#     f_new.close()</span></span><br></pre></td></tr></table></figure>
<h2 id="5-神经网络识别手写体数字"><a href="#5-神经网络识别手写体数字" class="headerlink" title="5. 神经网络识别手写体数字"></a>5. 神经网络识别手写体数字</h2><p>手写体数字数据集（MNIST）是一个经典的多分类数据集，由不同的手写体数字图片以及0～9的数字标签样本构成。scikit-learn中的手写体数字数据集共有1797个样本，每个样本包含一个8×8像素的图像和0～9的数字标签。scikit-learn通过<code>MLPClassifier</code>类实现的多层感知器完成分类任务，通过<code>MLPRegressor</code>类完成回归任务。对于手写体数字数据集这样的多分类问题，显然要采用<code>MLPClassifier</code>。<code>MLPClassifier</code>的常用参数如下:</p>
<ul>
<li><code>hidden_layer_sizes</code>：用来指定隐藏层包含的节点数量，其类型为tuple，长度是<code>n_layers-2</code>，其中n_layers为网络总层数；</li>
<li><code>activation</code>：指定隐藏层的激活函数，默认为relu；</li>
<li><code>solver</code>：指定权重的更新方法，默认为sgd，即随机梯度下降法；</li>
<li><code>alpha</code>：指定L2正则的惩罚系数；</li>
<li><code>learning_rate</code>：指定训练过程中学习率更新方法，有constant、invscaling和adaptive这3种方法。其中，constant表示学习率在训练过程中为固定值；invscaling表示随着训练的进行，学习率指数降低；adaptive表示动态调整，当训练误差不断减少时（减少量超过一定阈值），学习率保持不变，若连续两次迭代训练损失未达到上述条件，则学习率缩小为原值的1/5。</li>
<li><code>max_iter</code>表示迭代的最大轮数，对于solver为sgd和adam的情况，<code>max_iter</code>相当于epoch的数量。</li>
</ul>
<p>了解了<code>MLPClassifier</code>类的常用参数后，下面介绍如何使用<code>MLPClassifier</code>来解决识别手写体数字的问题。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_digits</span><br><span class="line">digits = load_digits()</span><br><span class="line">X = digits.data</span><br><span class="line">y = digits.target</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">8</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line">mlp = MLPClassifier(hidden_layer_sizes=(<span class="number">128</span>, <span class="number">64</span>), max_iter=<span class="number">50</span>, alpha=<span class="number">1e-4</span>, solver=<span class="string">'sgd'</span>)</span><br><span class="line">mlp.fit(X_train, y_train)</span><br><span class="line">y_pred = mlp.predict(X_test)</span><br><span class="line">print(<span class="string">"Accuracy: "</span>, accuracy_score(y_test, y_pred))</span><br></pre></td></tr></table></figure>
<pre><code>Accuracy:  0.9555555555555556
</code></pre><h2 id="6-支持向量机识别手写体数字"><a href="#6-支持向量机识别手写体数字" class="headerlink" title="6. 支持向量机识别手写体数字"></a>6. 支持向量机识别手写体数字</h2><p>下面仍以手写体数字数据集（MNIST）为例，介绍如何使用SVM解决分类问题。SVM既可以解决二分类问题，也能解决多分类问题。SVM解决多分类问题的方法主要有两种：one-vs-one和one-vs-the-rest。</p>
<ul>
<li><code>one-vs-one</code>为每两类样本建立一个二分类器，则$k$个类别的样本需要建立$\frac{k(k-1)}{2}$个二分类器。</li>
<li><code>one-vs-the-rest</code>是为每个类别和其他剩余类别建立一个二分类器，从中选择预测概率最大的分类作为最终分类，k个类别的样本需建立k个二分类器。</li>
</ul>
<p>scikit-learn通过SVC类来解决分类问题，通过SVR类来解决回归问题（SVM也可以解决回归问题），下面采用SVC类解决手写体数字识别的多分类问题。</p>
<p>SVC可以通过参数kernel指定采用的核函数，支持的核函数有：<code>linear</code>（线性核函数）、<code>poly</code>（多项式）、<code>rbf</code>（高斯）、<code>sigmoid</code>、<code>precomputed</code>以及自定义形式<code>callable</code>。若不指定kernel，其默认采用<code>rbf</code>。SVC还有几个比较常用的参数：</p>
<ul>
<li>惩罚参数$C$，即前面松弛变量中介绍的不满足约束条件样本的惩罚系数；</li>
<li>参数<code>degree</code>是多项式核函数（kernel设置为<code>poly</code>）的阶数；</li>
<li>参数gamma表示高斯核和sigmoid核中的内核系数，在高斯核中对应的是高斯核函数公式中的$\frac{1}{2\sigma^2}$。</li>
</ul>
<p>数据集的加载和划分同神经网络中的示例，不再赘述。此处主要介绍模型拟合与评估。</p>
<p>先定义一个SVC模型，这里采用高斯核函数，惩罚系数C为1.0，gamma为0.001，当然也可以通过参数调优来确定参数。定义模型之后即可训练模型，然后对测试集进行预测，最后以准确率为指标评估预测结果。具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line">svc = svm.SVC(C=<span class="number">1.0</span>, kernel=<span class="string">"rbf"</span>, gamma=<span class="number">0.001</span>)</span><br><span class="line">svc.fit(X_train, y_train)</span><br><span class="line">y_pred = svc.predict(X_test)</span><br><span class="line">print(<span class="string">"Accuracy"</span>, accuracy_score(y_test, y_pred))</span><br></pre></td></tr></table></figure>
<pre><code>Accuracy 0.9861111111111112
</code></pre><p>也可以采用其他核函数，如多项式核函数，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">svc = svm.SVC(C=<span class="number">1.0</span>, kernel=<span class="string">"poly"</span>, degree=<span class="number">3</span>)</span><br><span class="line">svc.fit(X_train, y_train)</span><br><span class="line">y_pred = svc.predict(X_test)</span><br><span class="line">print(<span class="string">"Accuracy"</span>, accuracy_score(y_test, y_pred))</span><br></pre></td></tr></table></figure>
<pre><code>Accuracy 0.9861111111111112
</code></pre><p>可以看到，在本例中采用多项式核函数和高斯核函数的预测准确率是相同的。读者也可自行尝试其他参数，观察不同参数对模型预测的影响。</p>
]]></content>
      <categories>
        <category>XGBoost</category>
      </categories>
  </entry>
  <entry>
    <title>R语言实战（三）</title>
    <url>/posts/17ce1303.html</url>
    <content><![CDATA[<p>本次分享，我们将评述用于生成基本的描述性统计量和推断统计量的R函数。首先，我们将着眼于定量变量的位置和尺度的衡量方式。然后我们将学习生成类别型变量的频数表和列联表的方法（以及连带的卡方检验）。接下来，我们将考察连续型和有序型变量相关系数的多种形式。最后，我们将转而通过参数检验（t检验）和非参数检验（Mann-WhitneyU检验、Kruskal-Wallis检验）方法研究组间差异。</p>
<p>参考书籍：</p>
<blockquote>
<p>《R语言实战—第2版》————-Robert I.Kabacoff</p>
</blockquote>
<p><strong>本次内容：</strong></p>
<ol>
<li><strong>描述性统计分析</strong></li>
<li><strong>频数表和列联表</strong></li>
<li><strong>相关</strong></li>
<li><strong>t检验</strong></li>
<li><strong>组间差异的非参数检验</strong></li>
</ol>
<h1 id="1-描述性统计分析"><a href="#1-描述性统计分析" class="headerlink" title="1. 描述性统计分析"></a>1. 描述性统计分析</h1><p>我们将使用中Motor Trend杂志的车辆路试（mtcars）数据集。我们的关注焦点是每加仑汽油行驶英里数（mpg） 、马力（hp）和车重（wt）。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(car)</span><br><span class="line">attach(mtcars)</span><br><span class="line">myvars &lt;- c(&quot;mpg&quot;,&quot;hp&quot;,&quot;wt&quot;)</span><br><span class="line">head(mtcars[myvars])</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-fd475d968ea368e2d950241e22eda92e_720w.jpg" alt="img"></p>
<p>我们将首先查看所有32种车型的描述性统计量，然后按照变速箱类型（am）和汽缸数（cyl）考察描述性统计量。变速箱类型是一个以0表示自动挡、1表示手动挡来编码的二分变量，而汽缸数可为4、5或6。</p>
<h2 id="1-1-使用summary-函数来获取描述性统计量"><a href="#1-1-使用summary-函数来获取描述性统计量" class="headerlink" title="1.1 使用summary()函数来获取描述性统计量"></a>1.1 使用summary()函数来获取描述性统计量</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">myvars &lt;- c(&quot;mpg&quot;,&quot;hp&quot;,&quot;wt&quot;)</span><br><span class="line">summary(mtcars[myvars])</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-579306ded6133d2c94a145c57c98a0f5_720w.jpg" alt="img"></p>
<p><strong>summary()函数提供了最小值、最大值、四分位数和数值型变量的均值，以及因子向量和逻辑型向量的频数统计。</strong></p>
<h2 id="1-2-通过sapply-计算描述性统计量"><a href="#1-2-通过sapply-计算描述性统计量" class="headerlink" title="1.2 通过sapply()计算描述性统计量"></a>1.2 通过sapply()计算描述性统计量</h2><p>sapply()函数，其使用格式为：</p>
<p>sapply(x, FUN, options)</p>
<p>其中的x是你的数据框（或矩阵），FUN为一个任意的函数。如果指定了options，它们将被传递给FUN。你可以在这里插入的典型函数有mean()、sd()、var()、min()、max()、median()、length()、 range()和quantile()。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mystats &lt;- function(x,na.omit&#x3D;FALSE)&#123;</span><br><span class="line">  if(na.omit)&#123;x &lt;- x[!is.na(x)]&#125;</span><br><span class="line">  m &lt;- mean(x)</span><br><span class="line">  n &lt;- length(x)</span><br><span class="line">  s &lt;- sd(x)</span><br><span class="line">  skew &lt;- sum((x-m)^3&#x2F;s^3)&#x2F;n</span><br><span class="line">  kurt &lt;- sum((x-m)^4&#x2F;s^4)&#x2F;n-3</span><br><span class="line">  return(c(n&#x3D;n,mean&#x3D;m,stdev&#x3D;s,skew&#x3D;skew,kurtosis&#x3D;kurt))</span><br><span class="line">&#125;</span><br><span class="line">myvars &lt;- c(&quot;mpg&quot;,&quot;hp&quot;,&quot;wt&quot;)</span><br><span class="line">sapply(mtcars[myvars], mystats)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-d020b9a1a2901cee219233013eaaeac1_720w.jpg" alt="img"></p>
<p>对于样本中的车型， 每加仑汽油行驶英里数的平均值为20.1，标准差为6.0。分布呈现右偏（偏度+0.61），并且较正态分布稍平（峰度–0.37）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(RColorBrewer) </span><br><span class="line">mycolors &lt;- brewer.pal(8, &quot;Set1&quot;) </span><br><span class="line">hist(mtcars$mpg,col &#x3D; mycolors[2],xlab &#x3D; &quot;mpg&quot;,breaks &#x3D; 15,freq &#x3D; FALSE)</span><br><span class="line">lines(density(mtcars$mpg), col&#x3D;mycolors[1], lwd&#x3D;2) </span><br><span class="line">abline(v &#x3D; mean(mtcars$mpg),lty&#x3D;2,col&#x3D;mycolors[3])</span><br><span class="line">text(mean(mtcars$mpg)-2.5,0.01,&quot;mean(mpg)&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-a5f7b6a6b1f751e142dc31d8eacf4028_720w.jpg" alt="img"></p>
<h2 id="1-3-pastecs包中的stat-desc-函数计算描述性统计量"><a href="#1-3-pastecs包中的stat-desc-函数计算描述性统计量" class="headerlink" title="1.3 pastecs包中的stat.desc()函数计算描述性统计量"></a>1.3 pastecs包中的stat.desc()函数计算描述性统计量</h2><p>pastecs包中有一个名为stat.desc()的函数， 它可以计算种类繁多的描述性统计量。 使用格式为：</p>
<p>stat.desc(x, basic=TRUE, desc=TRUE, norm=FALSE, p=0.95)</p>
<p>其中的x是一个数据框或时间序列。若basic=TRUE（默认值），则计算其中所有值、空值、缺失值的数量，以及最小值、最大值、值域，还有总和。若desc=TRUE（同样也是默认值），则计算中位数、平均数、平均数的标准误、平均数置信度为95%的置信区间、方差、标准差以及变异系数。最后，若norm=TRUE（不是默认的），则返回正态分布统计量，包括偏度和峰度（以及它们的统计显著程度）和Shapiro-Wilk正态检验结果。这里使用了p值来计算平均数的置信区间（默认置信度为0.95） 。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(pastecs)</span><br><span class="line">myvars &lt;- c(&quot;mpg&quot;,&quot;hp&quot;,&quot;wt&quot;)</span><br><span class="line">stat.desc(mtcars[myvars],norm&#x3D;TRUE)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-80fc3b04c7cf18fb3e76f457e5b4a625_720w.jpg" alt="img"></p>
<h2 id="1-4-使用aggregate-分组获取描述性统计量"><a href="#1-4-使用aggregate-分组获取描述性统计量" class="headerlink" title="1.4 使用aggregate()分组获取描述性统计量"></a>1.4 使用aggregate()分组获取描述性统计量</h2><p>在比较多组个体或观测时，关注的焦点经常是各组的描述性统计信息，而不是样本整体的描述性统计信息。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">myvars &lt;- c(&quot;mpg&quot;,&quot;hp&quot;,&quot;wt&quot;)</span><br><span class="line">aggregate(mtcars[myvars],by&#x3D;list(am&#x3D;mtcars$am),mean)</span><br><span class="line">aggregate(mtcars[myvars],by&#x3D;list(am&#x3D;mtcars$am),sd)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-87aa841532fd1c70e91b8f856a643afc_720w.jpg" alt="img"></p>
<p>注意list(am=mtcars$am)的使用。如果使用的是list(mtcars$am)，则am列将被标注为Group.1而不是am。你使用这个赋值指定了一个更有帮助的列标签。如果有多个分组变量，可以使用by=list(name1=groupvar1, name2=groupvar2, … , nameN=groupvarN)这样的语句。<strong>遗憾的是，aggregate()仅允许在每次调用中使用平均数、标准差这样的单返回值函数。它无法一次返回若干个统计量。</strong></p>
<h2 id="1-5-使用by-分组计算描述性统计量"><a href="#1-5-使用by-分组计算描述性统计量" class="headerlink" title="1.5 使用by()分组计算描述性统计量"></a>1.5 使用by()分组计算描述性统计量</h2><p>使用by()函数。格式为:by(data, INDICES, FUN)</p>
<p>其中data是一个数据框或矩阵，INDICES是一个因子或因子组成的列表，定义了分组，FUN是任意函数。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dstats &lt;- function(x)sapply(x, mystats)</span><br><span class="line">myvars &lt;- c(&quot;mpg&quot;,&quot;hp&quot;,&quot;wt&quot;)</span><br><span class="line">by(mtcars[myvars],mtcars$am,dstats)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-4acbddeb930ae4a6aa2380440873cf05_720w.jpg" alt="img"></p>
<p>dstats()调用了mystats()函数，将其应用于数据框的每一栏中。再通过by()函数则可得到am中每一水平的概括统计量。</p>
<h1 id="2-频数表和列联表"><a href="#2-频数表和列联表" class="headerlink" title="2.频数表和列联表"></a>2.频数表和列联表</h1><p>本节中的数据来自vcd包中的Arthritis数据集。这份数据来自Kock &amp; Edward （1988） ，表示了一项风湿性关节炎新疗法的双盲临床实验的结果。前几个观测是这样的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(vcd)</span><br><span class="line">head(Arthritis)</span><br></pre></td></tr></table></figure>
<p><img src="/posts/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-972fc849bd835e7a447f3d9ae9860a6f_720w.jpg" alt="img"></p>
<p>治疗情况（安慰剂治疗、用药治疗）、性别（男性、女性）和改善情况（无改善、一定程度的改善、显著改善）均为类别型因子。</p>
<h2 id="2-1-生成频数表"><a href="#2-1-生成频数表" class="headerlink" title="2.1 生成频数表"></a>2.1 生成频数表</h2><p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-6f00e070172c5d851f8495984c366532_720w.jpg" alt="img"></p>
<h3 id="2-1-1-一维列联表"><a href="#2-1-1-一维列联表" class="headerlink" title="2.1.1 一维列联表"></a>2.1.1 一维列联表</h3><p>可以使用table()函数生成简单的频数统计表。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mytable &lt;- with(Arthritis,table(Improved))</span><br><span class="line">mytable</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-eabe2646cde6814b487b071eebb2f281_720w.jpg" alt="img"></p>
<p>可以用prop.table()将这些频数转化为比例值：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">prop.table(mytable)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-1f6818def8bbcfe0bd5c3031c902257d_720w.jpg" alt="img"></p>
<h3 id="2-1-2-二维列联表"><a href="#2-1-2-二维列联表" class="headerlink" title="2.1.2 二维列联表"></a>2.1.2 二维列联表</h3><p>对于二维列联表，table()函数的使用格式为：</p>
<p>mytable &lt;- table(A, B)</p>
<p>其中的A是行变量，B是列变量。除此之外，xtabs()函数还可使用公式风格的输入创建列联表，格式为：</p>
<p>mytable &lt;- xtabs(~ A + B, data=mydata)</p>
<p>其中的mydata是一个矩阵或数据框。总的来说，要进行交叉分类的变量应出现在公式的右侧 （即~符号的右方），以+作为分隔符。若某个变量写在公式的左侧，则其为一个频数向量（在数据已经被表格化时很有用） 。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mytable &lt;- xtabs(~Treatment+Improved,data&#x3D;Arthritis)</span><br><span class="line">mytable</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-56bd9cc92a366a59f757ecf77cd84312_720w.jpg" alt="img"></p>
<p>可以使用margin.table()和prop.table()函数分别生成边际频数和比例。行和与行比例可以这样计算：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">margin.table(mytable,1)</span><br><span class="line">prop.table(mytable,1)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-9326520883031626c2a575be5a2e8090_720w.jpg" alt="img"></p>
<p>下标1指代table()语句中的第一个变量。观察表格可以发现，与接受安慰剂的个体中有显著改善的16%相比，接受治疗的个体中的51%的个体病情有了显著的改善。</p>
<p>列和与列比例可以这样计算：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">margin.table(mytable,2)</span><br><span class="line">prop.table(mytable,2)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-57aef697a03f4b4d62e0e187961ce011_720w.jpg" alt="img"></p>
<p>这里的下标2指代table()语句中的第二个变量。</p>
<p>各单元格所占比例可用如下语句获取：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">prop.table(mytable)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-68e40ba2b2c4c7c70091647b8a8517f1_720w.jpg" alt="img"></p>
<p>可以使用addmargins()函数为这些表格添加边际和。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">addmargins(mytable)</span><br><span class="line">addmargins(prop.table(mytable))</span><br><span class="line"># 仅添加了各行和各列的和</span><br><span class="line">addmargins(prop.table(mytable,1),2)</span><br><span class="line">addmargins(prop.table(mytable,2),1)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-f4f4ee9f11ce0614ee839d46e00f8e76_720w.jpg" alt="img"></p>
<p>使用gmodels包中的CrossTable()函数是创建二维列联表的第三种方法。CrossTable()函数仿照SAS中PROC FREQ或SPSS中CROSSTABS的形式生成二维列联表。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(gmodels)</span><br><span class="line">CrossTable(Arthritis$Treatment,Arthritis$Improved)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-944c6dfd0b270d47d69c62eca2881e59_720w.jpg" alt="img"></p>
<h3 id="2-1-3-多维列联表"><a href="#2-1-3-多维列联表" class="headerlink" title="2.1.3 多维列联表"></a>2.1.3 多维列联表</h3><p>table() 和 xtabs() 都 可 以 基 于 三 个 或 更 多 的 类 别 型 变 量 生 成 多 维 列 联 表 。margin.table()、prop.table()和addmargins()函数可以自然地推广到高于二维的情况。另外，ftable()函数可以以一种紧凑而吸引人的方式输出多维列联表。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 三维列联表</span><br><span class="line">mytable &lt;- xtabs(~Treatment+Sex+Improved,data&#x3D;Arthritis)</span><br><span class="line">mytable</span><br><span class="line">ftable(mytable)</span><br><span class="line"># 边际频数</span><br><span class="line">margin.table(mytable,1)</span><br><span class="line">margin.table(mytable,2)</span><br><span class="line">margin.table(mytable,3)</span><br><span class="line">margin.table(mytable,c(1,3))</span><br><span class="line">margin.table(mytable,c(1,2))</span><br><span class="line">ftable(prop.table(mytable, c(1, 2))) </span><br><span class="line">ftable(addmargins(prop.table(mytable, c(1, 2)), 3))</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-f7fe47703252fd15da9760065638c9b1_720w.jpg" alt="img"></p>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-be904c2c25c43a6815a79a16b9c931e5_720w.jpg" alt="img"></p>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-8b0b97c90344759abdd96cc5194ec7ef_720w.jpg" alt="img"></p>
<h2 id="2-2-独立性检验"><a href="#2-2-独立性检验" class="headerlink" title="2.2 独立性检验"></a>2.2 独立性检验</h2><h3 id="2-2-1-卡方独立性检验"><a href="#2-2-1-卡方独立性检验" class="headerlink" title="2.2.1 卡方独立性检验"></a>2.2.1 卡方独立性检验</h3><p>可以使用chisq.test()函数对二维表的行变量和列变量进行卡方独立性检验。</p>
<p>这里的p值表示从总体中抽取的样本行变量与列变量是相互独立的概率。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(vcd)</span><br><span class="line">mytable &lt;- xtabs(~Treatment+Improved, data&#x3D;Arthritis)</span><br><span class="line">chisq.test(mytable)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-14c7354be5c3b24d058efce40a7bf264_720w.jpg" alt="img"></p>
<p>结果中，患者接受的治疗和改善的水平看上去存在着某种关系（p&lt;0.01）(不独立)。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mytable &lt;- xtabs(~Improved+Sex,data&#x3D;Arthritis)</span><br><span class="line">chisq.test(mytable)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-d5617a30cc6df7df25742c48303f9f35_720w.jpg" alt="img"></p>
<p>患者性别和改善情况之间却不存在关系（p&gt;0.05）(独立)。</p>
<h3 id="2-2-2-Fisher精确检验"><a href="#2-2-2-Fisher精确检验" class="headerlink" title="2.2.2 Fisher精确检验"></a>2.2.2 Fisher精确检验</h3><p>可以使用fisher.test()函数进行Fisher精确检验。Fisher精确检验的原假设是：边界固定的列联表中行和列是相互独立的。其调用格式为fisher.test(mytable)，其中的mytable是一个二维列联表。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mytable &lt;- xtabs(~Treatment+Improved,data&#x3D;Arthritis)</span><br><span class="line">fisher.test(mytable)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-7dcdadec1b25fbd0e07ea36c5cd2f0a1_720w.jpg" alt="img"></p>
<p>结果中，患者接受的治疗和改善的水平看上去存在着某种关系（p&lt;0.01）(不独立)。</p>
<h3 id="2-2-3-Cochran-Mantel-Haenszel检验"><a href="#2-2-3-Cochran-Mantel-Haenszel检验" class="headerlink" title="2.2.3 Cochran-Mantel-Haenszel检验"></a>2.2.3 Cochran-Mantel-Haenszel检验</h3><p>mantelhaen.test()函数可用来进行Cochran-Mantel-Haenszel卡方检验，其原假设是， 两个名义变量在第三个变量的每一层中都是条件独立的。下列代码可以检验治疗情况和改善情况在性别的每一水平下是否独立。此检验假设不存在三阶交互作用（治疗情况×改善情况×性别） 。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mytable &lt;- xtabs(~Treatment+Improved+Sex,data&#x3D;Arthritis)</span><br><span class="line">mantelhaen.test(mytable)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-c6167b3cd925aad769c5ef748bd96587_720w.jpg" alt="img"></p>
<p>结果表明，患者接受的治疗与得到的改善在性别的每一水平下并不独立（分性别来看，用药治疗的患者较接受安慰剂的患者有了更多的改善） 。</p>
<h2 id="2-3-相关性度量"><a href="#2-3-相关性度量" class="headerlink" title="2.3 相关性度量"></a>2.3 相关性度量</h2><h3 id="2-3-1-相关性度量指标"><a href="#2-3-1-相关性度量指标" class="headerlink" title="2.3.1 相关性度量指标"></a>2.3.1 相关性度量指标</h3><p>显著性检验评估了是否存在充分的证据以拒绝变量间相互独立的原假设。如果可以拒绝原假设，那么你的兴趣就会自然而然地转向用以衡量相关性强弱的相关性度量。vcd包中的assocstats()函数可以用来计算二维列联表的phi系数、列联系数和Cramer’s V系数。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(vcd)</span><br><span class="line">mytable &lt;- xtabs(~Treatment+Improved,data&#x3D;Arthritis)</span><br><span class="line">assocstats(mytable)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-da1d9da82243a58dd56873294b5bc31f_720w.jpg" alt="img"></p>
<p>总体来说，较大的值意味着较强的相关性。</p>
<h3 id="2-3-2-相关性度量的可视化-类别型变量-马赛克图"><a href="#2-3-2-相关性度量的可视化-类别型变量-马赛克图" class="headerlink" title="2.3.2 相关性度量的可视化(类别型变量):马赛克图"></a>2.3.2 相关性度量的可视化(类别型变量):马赛克图</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(vcd)</span><br><span class="line">mosaic(~Treatment+Improved+Sex,data&#x3D;Arthritis,shade&#x3D;TRUE,legend&#x3D;TRUE)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-bf383ec481c0583433fc514d80beba76_720w.jpg" alt="img"></p>
<h1 id="3-相关"><a href="#3-相关" class="headerlink" title="3.相关"></a>3.相关</h1><p>相关系数可以用来描述定量变量之间的关系。相关系数的符号（±）表明关系的方向（正相关或负相关） ，其值的大小表示关系的强弱程度（完全不相关时为0，完全相关时为1） 。 本节中，我们将关注多种相关系数和相关性的显著性检验。我们将使用R基础安装中的state.x77数据集，它提供了美国50个州在1977年的人口、收入、文盲率、预期寿命、谋杀率和高中毕业率数据。数据集中还收录了气温和土地面积数据，但为了节约空间，这里将其丢弃。你可以使用help(state.x77)了解数据集的更多信息。除了基础安装以外，我们还将使用psych和ggm包。</p>
<h2 id="3-1-相关的类型"><a href="#3-1-相关的类型" class="headerlink" title="3.1 相关的类型"></a>3.1 相关的类型</h2><p>R可以计算多种相关系数，包括Pearson相关系数、Spearman相关系数、Kendall相关系数、偏相关系数、多分格（polychoric）相关系数和多系列（polyserial）相关系数。</p>
<h3 id="3-1-1-Pearson、Spearman和Kendall相关"><a href="#3-1-1-Pearson、Spearman和Kendall相关" class="headerlink" title="3.1.1 Pearson、Spearman和Kendall相关"></a>3.1.1 Pearson、Spearman和Kendall相关</h3><p>Pearson积差相关系数衡量了两个定量变量之间的线性相关程度。Spearman等级相关系数则衡量分级定序变量之间的相关程度。Kendall’sTau相关系数也是一种非参数的等级相关度量。cor()函数可以计算这三种相关系数，而cov()函数可用来计算协方差。两个函数的参数有很多，其中与相关系数的计算有关的参数可以简化为：</p>
<p>cor(x, use= , method= )</p>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-ed29b85654228302f4b8881f00dde68f_720w.jpg" alt="img"></p>
<p>默认参数为use=”everything”和method=”pearson”。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">states &lt;- state.x77[,1:6]</span><br><span class="line">cov(states)</span><br><span class="line">cor(states)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-e4ed2232587b65753a8e369b7ef88317_720w.jpg" alt="img"></p>
<p>我们可以看到收入和高中毕业率之间存在很强的正相关，而文盲率和预期寿命之间存在很强的负相关。</p>
<p>在默认情况下得到的结果是一个方阵（所有变量之间两两计算相关） 。当你对某一组变量与另外一组变量之间的关系感兴趣时,你同样可以计算非方形的相关矩阵。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x &lt;- states[,c(&quot;Population&quot;, &quot;Income&quot;, &quot;Illiteracy&quot;, &quot;HS Grad&quot;)] </span><br><span class="line">y &lt;- states[,c(&quot;Life Exp&quot;, &quot;Murder&quot;)]  </span><br><span class="line">cor(x,y)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-020367797dcb742a83ce3e24b2ca0f35_720w.jpg" alt="img"></p>
<p><strong>注意，上述结果并未指明相关系数是否显著不为0（即，根据样本数据是否有足够的证据得出总体相关系数不为0的结论）。由于这个原因，你需要对相关系数进行显著性检验。</strong></p>
<h3 id="3-1-2-偏相关"><a href="#3-1-2-偏相关" class="headerlink" title="3.1.2 偏相关"></a>3.1.2 偏相关</h3><p>偏相关是指在控制一个或多个定量变量时，另外两个定量变量之间的相互关系。你可以使用ggm包中的pcor()函数计算偏相关系数。函数调用格式为：</p>
<p>pcor(u, S)</p>
<p>其中的u是一个数值向量，前两个数值表示要计算相关系数的变量下标，其余的数值为条件变量（即要排除影响的变量）的下标。S为变量的协方差阵。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(ggm)</span><br><span class="line">colnames(states)</span><br><span class="line">pcor(c(1,5,2,3,6),cov(states))</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-62da63dd940bc0f83a6f33a296481ecf_720w.jpg" alt="img"></p>
<p>在控制了收入、文盲率和高中毕业率的影响时，人口和谋杀率之间的相关系数为0.346。偏相关系数常用于社会科学的研究中。</p>
<h2 id="3-2-相关性显著性检验"><a href="#3-2-相关性显著性检验" class="headerlink" title="3.2 相关性显著性检验"></a>3.2 相关性显著性检验</h2><p>在计算好相关系数以后， 如何对它们进行统计显著性检验呢？常用的原假设为变量间不相关（即总体的相关系数为0）。</p>
<p>(1) 可以使用cor.test()函数对单个的Pearson、Spearman和Kendall相关系数进行检验。</p>
<p>简化后的使用格式为：</p>
<p>cor.test(x, y, alternative = , method = )</p>
<p>其中的x和y为要检验相关性的变量，alternative则用来指定进行双侧检验或单侧检验（取值为”two.side”、”less”或”greater”），而method用以指定要计算的相关类型（”pearson”、”kendall” 或 “spearman” ） 。 当 研 究 的 假 设 为 总 体 的 相 关 系 数 小 于 0 时 ， 请 使 用alternative=”less” 。 在 研 究 的 假 设 为 总 体 的相关系 数 大 于 0 时 ， 应 使 用alternative=”greater”。在默认情况下，假设为alternative=”two.side”（总体相关系数不等于0） 。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cor.test(states[,3],states[,5])</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-3da029401fc1c12fc43a78d14f466543_720w.jpg" alt="img"></p>
<p>这段代码检验了预期寿命和谋杀率的Pearson相关系数为0的原假设。假设总体的相关度为0，则预计在一千万次中只会有少于一次的机会见到0.703这样大的样本相关度（即p=1.258e–08） 。由于这种情况几乎不可能发生，所以你可以拒绝原假设，从而支持了要研究的猜想，即预期寿命和谋杀率之间的总体相关度不为0。</p>
<p>(2) 通过corr.test计算相关矩阵并进行显著性检验:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(psych)</span><br><span class="line">corr.test(states,use&#x3D;&quot;complete&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-8092025a9c4f220a10b29b8553e4e025_720w.jpg" alt="img"></p>
<p>参数use=的取值可为”pairwise”或”complete”（分别表示对缺失值执行成对删除或行删除）。参数method=的取值可为”pearson”（默认值）、”spearman”或”kendall”。这里可以看到，人口数量和高中毕业率的相关系数（–0.10）并不显著地不为0（p=0.5） 。</p>
<h2 id="3-3-相关系数的可视化"><a href="#3-3-相关系数的可视化" class="headerlink" title="3.3 相关系数的可视化"></a>3.3 相关系数的可视化</h2><h3 id="3-3-1-散点图"><a href="#3-3-1-散点图" class="headerlink" title="3.3.1 散点图"></a>3.3.1 散点图</h3><p>(1) 添加了最佳拟合曲线的散点图</p>
<p>abline()函数用来添加最佳拟合的线性直线， 而lowess()函数则用来添加一条平滑曲线。 该平滑曲线拟合是一种基于局部加权多项式回归的非参数方法。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">attach(mtcars)  </span><br><span class="line">plot(wt, mpg, </span><br><span class="line">     main&#x3D;&quot;Basic Scatter plot of MPG vs. Weight&quot;, </span><br><span class="line">     xlab&#x3D;&quot;Car Weight (lbs&#x2F;1000)&quot;, </span><br><span class="line">     ylab&#x3D;&quot;Miles Per Gallon &quot;, pch&#x3D;19) </span><br><span class="line">abline(lm(mpg~wt), col&#x3D;&quot;red&quot;, lwd&#x3D;2, lty&#x3D;1) </span><br><span class="line">lines(lowess(wt,mpg), col&#x3D;&quot;blue&quot;, lwd&#x3D;2, lty&#x3D;2)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-785d6b790ae8c195748540284bcc6e98_720w.jpg" alt="img"></p>
<p>(2) car包中的scatterplot()函数增强了散点图的许多功能</p>
<p>此处，scatterplot()函数用来绘制四缸、六缸和八缸汽车每加仑英里数对车重的图形。表达式mpg ~ wt | cyl表示按条件绘图（即按cyl的水平分别绘制mpg和wt的关系图）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(car)  </span><br><span class="line">scatterplot(mpg ~ wt | cyl, data&#x3D;mtcars, lwd&#x3D;2, span&#x3D;0.75, </span><br><span class="line">            main&#x3D;&quot;Scatter Plot of MPG vs. Weight by # Cylinders&quot;, </span><br><span class="line">            xlab&#x3D;&quot;Weight of Car (lbs&#x2F;1000)&quot;, </span><br><span class="line">            ylab&#x3D;&quot;Miles Per Gallon&quot;, </span><br><span class="line">            legend.plot&#x3D;TRUE, </span><br><span class="line">            id.method&#x3D;&quot;identify&quot;, </span><br><span class="line">            #labels&#x3D;row.names(mtcars), </span><br><span class="line">            boxplots&#x3D;&quot;xy&quot; </span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-eb708d7f4869fb0c84b1d2b201f4fc6a_720w.jpg" alt="img"></p>
<p>(3) 散点图矩阵</p>
<p>pairs()函数可以创建基础的散点图矩阵。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pairs(~mpg+disp+drat+wt, data&#x3D;mtcars, </span><br><span class="line">      main&#x3D;&quot;Basic Scatter Plot Matrix&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-9548b951880161b515b96076c87cfe63_720w.jpg" alt="img"></p>
<p>car包中的scatterplotMatrix()函数也可以生成散点图矩阵:</p>
<ul>
<li>以某个因子为条件绘制散点图矩阵；</li>
<li>包含线性和平滑拟合曲线；</li>
<li>在主对角线放置箱线图、密度图或者直方图；</li>
<li>在各单元格的边界添加轴须图。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(car)  </span><br><span class="line">scatterplotMatrix(~ mpg + disp + drat + wt, data&#x3D;mtcars, </span><br><span class="line">                  spread&#x3D;FALSE, smoother.args&#x3D;list(lty&#x3D;2), </span><br><span class="line">                  main&#x3D;&quot;Scatter Plot Matrix via car Package&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-27d029d69a1fe74927775a140eed4cc9_720w.jpg" alt="img"></p>
<p>(4) 高密度散点图</p>
<p>当数据点重叠很严重时，用散点图来观察变量关系就显得“力不从心”了。</p>
<p>smoothScatter()函数可利用核密度估计生成用颜色密度来表示点分布的散点图。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set.seed(1234) </span><br><span class="line">n &lt;- 10000 </span><br><span class="line">c1 &lt;- matrix(rnorm(n, mean&#x3D;0, sd&#x3D;.5), ncol&#x3D;2) </span><br><span class="line">c2 &lt;- matrix(rnorm(n, mean&#x3D;3, sd&#x3D;2), ncol&#x3D;2) </span><br><span class="line">mydata &lt;- rbind(c1, c2) </span><br><span class="line">mydata &lt;- as.data.frame(mydata) </span><br><span class="line">names(mydata) &lt;- c(&quot;x&quot;, &quot;y&quot;) </span><br><span class="line">with(mydata,smoothScatter(x,y,main&#x3D;&quot;Scatter Plot Colored by Smoothed Densities&quot;))</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-7d4a0d5aaed85d28b8b5334118266439_720w.jpg" alt="img"></p>
<p>hexbin包中的hexbin()函数将二元变量的封箱放到六边形单元格中（图形比名称更直观） 。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(hexbin)</span><br><span class="line">with(mydata,&#123;bin &lt;- hexbin(x,y,xbins&#x3D;50)</span><br><span class="line">plot(bin,main &#x3D; &quot;Hexagonal Binning with 10,000 Observations&quot;)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-7c26291c28d5db5d9c51c43ed8b2cf7c_720w.jpg" alt="img"></p>
<p>(5) 三维散点图</p>
<p>散点图和散点图矩阵展示的都是二元变量关系。 倘若你想一次对三个定量变量的交互关系进行可视化呢？</p>
<p>假使你对汽车英里数、车重和排量间的关系感兴趣，可用scatterplot3d包中的scatterplot3d()函数来绘制它们的关系。格式如下：</p>
<p>scatterplot3d(x, y, z)</p>
<p>x被绘制在水平轴上，y被绘制在竖直轴上，z被绘制在透视轴上。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(scatterplot3d)  </span><br><span class="line">attach(mtcars) </span><br><span class="line">scatterplot3d(wt, disp, mpg, </span><br><span class="line">    main&#x3D;&quot;Basic 3D Scatter Plot&quot;)</span><br><span class="line">&#96;&#96;&#96;</span><br><span class="line">satterplot3d()函数提供了许多选项，包括设置图形符号、轴、颜色、线条、网格线、突出显示和角度等功能。         </span><br><span class="line">&#96;&#96;&#96;&#123;r&#125;</span><br><span class="line">library(scatterplot3d) </span><br><span class="line">attach(mtcars)  </span><br><span class="line">scatterplot3d(wt, disp, mpg, </span><br><span class="line">              pch&#x3D;16, </span><br><span class="line">              highlight.3d&#x3D;TRUE, </span><br><span class="line">              type&#x3D;&quot;h&quot;, </span><br><span class="line">              main&#x3D;&quot;3D Scatter Plot with Vertical Lines&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-cd861dfd961bb7e1d8bdc736bb6cf638_720w.jpg" alt="img"></p>
<p>我们在刚才那幅图上添加一个回归面。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(scatterplot3d)  </span><br><span class="line">attach(mtcars) </span><br><span class="line">s3d &lt;-scatterplot3d(wt, disp, mpg, </span><br><span class="line">      pch&#x3D;16, </span><br><span class="line">      highlight.3d&#x3D;TRUE, </span><br><span class="line">      type&#x3D;&quot;h&quot;, </span><br><span class="line">      main&#x3D;&quot;3D Scatter Plot with Vertical Lines and Regression Plane&quot;) </span><br><span class="line">fit &lt;- lm(mpg ~ wt+disp) </span><br><span class="line">s3d$plane3d(fit)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-f97a3592e3295ced265e053acb5155e3_720w.jpg" alt="img"></p>
<p>(6) 气泡图</p>
<p>先创建一个二维散点图， 然后用点的大小来代表第三个变量的值。这便是气泡图（bubbleplot）。你可用symbols()函数来创建气泡图。该函数可以在指定的(x,y)坐标上绘制圆圈图、方形图、星形图、温度计图和箱线图。以绘制圆圈图为例： symbols(x, y, circle=radius) 其中x、y和radius是需要设定的向量，分别表示x、y坐标和圆圈半径。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">attach(mtcars)  </span><br><span class="line">r &lt;- sqrt(disp&#x2F;pi) </span><br><span class="line">symbols(wt, mpg, circle&#x3D;r, inches&#x3D;0.30, </span><br><span class="line">        fg&#x3D;&quot;white&quot;, bg&#x3D;&quot;lightblue&quot;, </span><br><span class="line">        main&#x3D;&quot;Bubble Plot with point size proportional to displacement&quot;, </span><br><span class="line">        ylab&#x3D;&quot;Miles Per Gallon&quot;, </span><br><span class="line">        xlab&#x3D;&quot;Weight of Car (lbs&#x2F;1000)&quot;) </span><br><span class="line"># text(wt, mpg, rownames(mtcars), cex&#x3D;0.6) </span><br><span class="line">detach(mtcars)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-d9d1490084558962c6499afb25bdc0c3_720w.jpg" alt="img"></p>
<p>一般来说，统计人员使用R时都倾向于避免用气泡图，原因和避免使用饼图一样：相比对长度的判断，人们对体积/面积的判断通常更困难。但是气泡图在商业应用中非常受欢迎。</p>
<h3 id="3-3-2-折线图"><a href="#3-3-2-折线图" class="headerlink" title="3.3.2 折线图"></a>3.3.2 折线图</h3><p>如果将散点图上的点从左往右连接起来，就会得到一个折线图。</p>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-04bce0238cce2474611f2f4f7e0e25e6_720w.jpg" alt="img"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">opar &lt;- par(no.readonly&#x3D;TRUE) </span><br><span class="line">par(mfrow&#x3D;c(1,2))  </span><br><span class="line">t1 &lt;- subset(Orange, Tree&#x3D;&#x3D;1) </span><br><span class="line">plot(t1$age, t1$circumference, </span><br><span class="line">     xlab&#x3D;&quot;Age (days)&quot;, </span><br><span class="line">     ylab&#x3D;&quot;Circumference (mm)&quot;, </span><br><span class="line">     main&#x3D;&quot;Orange Tree 1 Growth&quot;) </span><br><span class="line">plot(t1$age, t1$circumference, </span><br><span class="line">     xlab&#x3D;&quot;Age (days)&quot;, </span><br><span class="line">     ylab&#x3D;&quot;Circumference (mm)&quot;, </span><br><span class="line">     main&#x3D;&quot;Orange Tree 1 Growth&quot;, </span><br><span class="line">     type&#x3D;&quot;b&quot;) </span><br><span class="line">par(opar)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-e0c28fdb60f1a6f2c7e609f0fa479c4c_720w.jpg" alt="img"></p>
<h3 id="3-3-3-相关图"><a href="#3-3-3-相关图" class="headerlink" title="3.3.3 相关图"></a>3.3.3 相关图</h3><p>利用corrgram包中的corrgram()函数，你可以用图形的方式展示该相关系数矩阵。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(corrgram)  </span><br><span class="line">corrgram(mtcars, order&#x3D;TRUE, lower.panel&#x3D;panel.shade, </span><br><span class="line">         upper.panel&#x3D;panel.pie, text.panel&#x3D;panel.txt, </span><br><span class="line">         main&#x3D;&quot;Corrgram of mtcars intercorrelations&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-322d850317327893382beb102ef4feba_720w.jpg" alt="img"></p>
<p>我们先从下三角单元格（在主对角线下方的单元格）开始解释这幅图形。默认地，蓝色和从左下指向右上的斜杠表示单元格中的两个变量呈正相关。反过来，红色和从左上指向右下的斜杠表示变量呈负相关。色彩越深，饱和度越高，说明变量相关性越大。相关性接近于0的单元格基本无色。上三角单元格用饼图展示了相同的信息。颜色的功能同上，但相关性大小由被填充的饼图块的大小来展示。 正相关性将从12点钟处开始顺时针填充饼图， 而负相关性则逆时针方向填充饼图。</p>
<p>corrgram()函数的格式如下：</p>
<p>corrgram(x, order=, panel=, text.panel=, diag.panel=)</p>
<p>其中，x是一行一个观测的数据框。当order=TRUE时，相关矩阵将使用主成分分析法对变量重排序，这将使得二元变量的关系模式更为明显。选项panel设定非对角线面板使用的元素类型。你可以通过选项lower.panel和upper.panel来分别设置主对角线下方和上方的元素类型。而text.panel和diag.panel选项控制着主对角线元素类型。</p>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-62268d5df6923cd36f5fd75a44c4f801_720w.jpg" alt="img"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(corrgram)  </span><br><span class="line">corrgram(mtcars, order&#x3D;TRUE, lower.panel&#x3D;panel.ellipse, </span><br><span class="line">         upper.panel&#x3D;panel.pts, text.panel&#x3D;panel.txt, </span><br><span class="line">         diag.panel&#x3D;panel.minmax, </span><br><span class="line">         main&#x3D;&quot;Corrgram of mtcars data using scatter plots </span><br><span class="line">               and ellipses&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-87b3236d14ece13573241bf810ee619b_720w.jpg" alt="img"></p>
<p>最后一个例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(corrgram)  </span><br><span class="line">corrgram(mtcars, lower.panel&#x3D;panel.shade, </span><br><span class="line">         upper.panel&#x3D;NULL, text.panel&#x3D;panel.txt, </span><br><span class="line">         main&#x3D;&quot;Car Mileage Data (unsorted)&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-8f348bc44894ede15fcd912809f0d70d_720w.jpg" alt="img"></p>
<h3 id="3-3-4-马赛克图"><a href="#3-3-4-马赛克图" class="headerlink" title="3.3.4 马赛克图"></a>3.3.4 马赛克图</h3><p>vcd包中的mosaic()函数可以绘制马赛克图。 （R基础安装中的mosaicplot()也可绘制马赛克图，但我还是推荐vcd包，因为它具有更多扩展功能。）以基础安装中的Titanic数据集为例，它包含存活或者死亡的乘客数、乘客的船舱等级（一等、二等、三等和船员） 、性别（男性、女性） ，以及年龄层（儿童、成人）。这是一个被充分研究过的数据集。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(vcd) </span><br><span class="line">mosaic(~Class+Sex+Age+Survived, data&#x3D;Titanic, shade&#x3D;TRUE, legend&#x3D;TRUE)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-9aa752871ba075ea62b9f3409b5af814_720w.jpg" alt="img"></p>
<p>在本例中，蓝色阴影表明，在假定生存率与船舱等级、性别和年龄层无关的条件下，该类别下的生存率通常超过预期值。红色阴影则含义相反。</p>
<p>赛克图隐含着大量的数据信息。例如：(1) 从船员到头等舱，存活率陡然提高；(2)大部分孩子都处在三等舱和二等舱中；(3)在头等舱中的大部分女性都存活了下来，而三等舱仅有一半女性存活；(4) 船员中女性很少，导致该组的Survived标签重叠（图底部的No和Yes） 。</p>
<h1 id="4-t检验"><a href="#4-t检验" class="headerlink" title="4.t检验"></a>4.t检验</h1><h2 id="4-1-独立样本的-t-检验"><a href="#4-1-独立样本的-t-检验" class="headerlink" title="4.1 独立样本的 t 检验"></a>4.1 独立样本的 t 检验</h2><p>如果你在美国的南方犯罪，是否更有可能被判监禁？我们比较的对象是南方和非南方各州，因变量为监禁的概率。一个针对两组的独立样本t检验<strong>可以用于检验两个总体的均值相等的假设</strong>。这里假设两组数据是独立的，并且是从正态总体中抽得。检验的调用格式为：</p>
<p>t.test(y ~ x, data)</p>
<p>其中的y是一个数值型变量，x是一个二分变量。调用格式或为：</p>
<p>t.test(y1, y2)</p>
<p>其中的y1和y2为数值型向量（即各组的结果变量） 。可选参数data的取值为一个包含了这些变量的矩阵或数据框。与其他多数统计软件不同的是，这里的t检验默认假定方差不相等，并使用Welsh的修正自由度。你可以添加一个参数var.equal=TRUE以假定方差相等，并使用合并方差估计。默认的备择假设是双侧的（即均值不相等，但大小的方向不确定）。你可以添加一个参数alternative=”less”或alternative=”greater”来进行有方向的检验。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(MASS)</span><br><span class="line">head(UScrime)</span><br><span class="line">t.test(Prob~So,data&#x3D;UScrime)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-fb6bd99acfdc234f1389ba509da7de81_720w.jpg" alt="img"></p>
<p>你可以拒绝南方各州和非南方各州拥有相同监禁概率的假设（p&lt;0.001） 。</p>
<h2 id="4-2-非独立样本t检验"><a href="#4-2-非独立样本t检验" class="headerlink" title="4.2 非独立样本t检验"></a>4.2 非独立样本t检验</h2><p>再举个例子，你可能会问：较年轻（14~24岁）男性的失业率是否比年长（35~39岁）男性的失业率更高？在这种情况下，这两组数据并不独立。你不能说亚拉巴马州的年轻男性和年长男性的失业率之间没有关系。</p>
<p><strong>非独立样本的t检验假定组间的差异呈正态分布</strong>。对于本例，检验的调用格式为：</p>
<p>t.test(y1, y2, paired=TRUE)</p>
<p>其中的y1和y2为两个非独立组的数值向量。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(MASS)</span><br><span class="line">sapply(UScrime[c(&quot;U1&quot;,&quot;U2&quot;)], function(x)(c(mean(x),sd(x))))</span><br><span class="line">with(UScrime,t.test(U1,U2,paired&#x3D;TRUE))</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-047e0d929a945486decafe20fb4e0455_720w.jpg" alt="img"></p>
<p>差异的均值（61.5）足够大，可以保证拒绝年长和年轻男性的平均失业率相同的假设。年轻男性的失业率更高。事实上，若总体均值相等，获取一个差异如此大的样本的概率小于0.000 000 000 000 000 22（即2.2e–16） 。</p>
<h1 id="5-组间差异的非参数检验"><a href="#5-组间差异的非参数检验" class="headerlink" title="5.组间差异的非参数检验"></a>5.组间差异的非参数检验</h1><p>如果数据无法满足t检验或ANOVA的参数假设，若结果变量在本质上就严重偏倚或呈现有序关系，可以转而使用非参数方法。</p>
<h2 id="5-1-两组的比较"><a href="#5-1-两组的比较" class="headerlink" title="5.1 两组的比较"></a>5.1 两组的比较</h2><p>若两组数据独立，可以使用Wilcoxon秩和检验（更广为人知的名字是Mann-WhitneyU检验）来评估观测是否是从相同的概率分布中抽得的（即，在一个总体中获得更高得分的概率是否比另一个总体要大） 。调用格式为：</p>
<p>wilcox.test(y ~ x, data)</p>
<p>其中的y是数值型变量，而x是一个二分变量。调用格式或为：</p>
<p>wilcox.test(y1, y2)</p>
<p>其中的y1和y2为各组的结果变量。可选参数data的取值为一个包含了这些变量的矩阵或数据框。默认进行一个双侧检验。你可以添加参数exact来进行精确检验，指定alternative=”less”或alternative=”greater”进行有方向的检验。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">with(UScrime, by(Prob, So, median)) </span><br><span class="line">with(UScrime,wilcox.test(Prob~So,data&#x3D;UScrime))</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-613a74ae52943f25e2f1686a1eacfe7b_720w.jpg" alt="img"></p>
<p>你可以再次拒绝南方各州和非南方各州监禁率相同的假设（p&lt;0.001） 。</p>
<p>Wilcoxon符号秩检验是非独立样本t检验的一种非参数替代方法。它适用于两组成对数据和无法保证正态性假设的情境。调用格式与Mann-WhitneyU检验完全相同，不过还可以添加参数paired=TRUE。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sapply(UScrime[c(&quot;U1&quot;,&quot;U2&quot;)], median)</span><br><span class="line">with(UScrime,wilcox.test(U1,U2,paired &#x3D; TRUE))</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-93154106af0a60e4a3ec71d4a8785dca_720w.jpg" alt="img"></p>
<p>你再次得到了与配对t检验相同的结论。</p>
<p>在本例中，含参的t检验和与其作用相同的非参数检验得到了相同的结论。当t检验的假设合理时，参数检验的功效更强（更容易发现存在的差异）。而非参数检验在假设非常不合理时（如<strong>对于等级有序数据</strong>）更适用。</p>
<h2 id="5-2-多于两组的比较"><a href="#5-2-多于两组的比较" class="headerlink" title="5.2 多于两组的比较"></a>5.2 多于两组的比较</h2><p>考虑state.x77数据集。它包含了美国各州的人口、收入、文盲率、预期寿命、谋杀率和高中毕业率数据。如果你想比较美国四个地区（东北部、南部、中北部和西部）的文盲率， 应该怎么做呢？这称为单向设计 （one-waydesign），我们可以使用参数或非参数的方法来解决这个问题。如果无法满足ANOVA设计的假设，那么可以使用非参数方法来评估组间的差异。如果各组独立，则Kruskal-Wallis检验将是一种实用的方法。如果各组不独立（如重复测量设计或随机区组设计），那么Friedman检验会更合适。</p>
<p>Kruskal-Wallis检验的调用格式为：</p>
<p>kruskal.test(y ~ A, data)</p>
<p>其中的y是一个数值型结果变量，A是一个拥有两个或更多水平的分组变量（grouping variable）。（若有两个水平，则它与Mann-Whitney U检验等价。 ）</p>
<p>而Friedman检验的调用格式为：</p>
<p>friedman.test(y ~ A | B, data)</p>
<p>其中的y是数值型结果变量，A是一个分组变量，而B是一个用以认定匹配观测的区组变量（blockingvariable）。在以上两例中，data皆为可选参数，它指定了包含这些变量的矩阵或数据框。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">states &lt;- data.frame(state.region, state.x77) </span><br><span class="line">kruskal.test(Illiteracy ~ state.region, data&#x3D;states)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-d4e51ee79856f83cc3814cd589f68244_720w.jpg" alt="img"></p>
<p>显著性检验的结果意味着美国四个地区的文盲率各不相同（p&lt;0.001） 。</p>
<p>虽然你可以拒绝不存在差异的原假设， 但这个检验并没有告诉你哪些地区显著地与其他地区不同。要回答这个问题，你可以使用Wilcoxon检验每次比较两组数据。一种更为优雅的方法是在控制犯第一类错误的概率（发现一个事实上并不存在的差异的概率）的前提下，执行可以同步进行的多组比较， 这样可以直接完成所有组之间的成对比较。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Nonparametric pairwise multiple comparisons using the Wilcoxon Signed Rank Test</span><br><span class="line"># Probability values are adjusted using the p.adjust function</span><br><span class="line">wmc &lt;- function(formula, data, exact&#x3D;FALSE, sort&#x3D;TRUE, method&#x3D;&quot;holm&quot;)&#123;</span><br><span class="line"></span><br><span class="line">  # setup</span><br><span class="line">  df &lt;- model.frame(formula, data)</span><br><span class="line">  y &lt;- df[[1]]</span><br><span class="line">  x &lt;- as.factor(df[[2]])</span><br><span class="line"> </span><br><span class="line">  </span><br><span class="line">  # reorder levels of x by median y</span><br><span class="line">  if(sort)&#123;</span><br><span class="line">    medians &lt;- aggregate(y, by&#x3D;list(x), FUN&#x3D;median)[2]</span><br><span class="line">    index &lt;- order(medians)</span><br><span class="line">    x &lt;- factor(x, levels(x)[index])</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  groups &lt;- levels(x)</span><br><span class="line">  k &lt;- length(groups)</span><br><span class="line">  </span><br><span class="line">  # summary statistics</span><br><span class="line">  stats &lt;- function(z)(c(N &#x3D; length(z), Median &#x3D; median(z), MAD &#x3D; mad(z)))</span><br><span class="line">  sumstats &lt;- t(aggregate(y, by&#x3D;list(x), FUN&#x3D;stats)[2])</span><br><span class="line">  rownames(sumstats) &lt;- c(&quot;n&quot;, &quot;median&quot;, &quot;mad&quot;)</span><br><span class="line">  colnames(sumstats) &lt;- groups</span><br><span class="line">  cat(&quot;Descriptive Statistics\n\n&quot;)</span><br><span class="line">  print(sumstats)</span><br><span class="line">  </span><br><span class="line">  # multiple comparisons</span><br><span class="line">  mc &lt;- data.frame(Group.1&#x3D;character(0), </span><br><span class="line">                   Group.2&#x3D;character(0), </span><br><span class="line">                   W&#x3D;numeric(0),</span><br><span class="line">                   p.unadj&#x3D;numeric(0), </span><br><span class="line">                   p&#x3D;numeric(0),</span><br><span class="line">                   stars&#x3D;character(0),</span><br><span class="line">                   stringsAsFactors&#x3D;FALSE)</span><br><span class="line">  </span><br><span class="line">  # perform Wilcoxon test</span><br><span class="line">  row &lt;- 0</span><br><span class="line">  for(i in 1:k)&#123;</span><br><span class="line">    for(j in 1:k)&#123;</span><br><span class="line">      if (j &gt; i)&#123;</span><br><span class="line">        row &lt;- row + 1</span><br><span class="line">        y1 &lt;- y[x&#x3D;&#x3D;groups[i]]</span><br><span class="line">        y2 &lt;- y[x&#x3D;&#x3D;groups[j]] </span><br><span class="line">        test &lt;- wilcox.test(y1, y2, exact&#x3D;exact)</span><br><span class="line">        mc[row,1] &lt;- groups[i]</span><br><span class="line">        mc[row,2] &lt;- groups[j]</span><br><span class="line">        mc[row,3] &lt;- test$statistic</span><br><span class="line">        mc[row,4] &lt;- test$p.value</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  mc$p &lt;- p.adjust(mc$p.unadj, method&#x3D;method)</span><br><span class="line">  </span><br><span class="line">  # add stars</span><br><span class="line">  mc$stars &lt;- &quot; &quot;</span><br><span class="line">  mc$stars[mc$p &lt;   .1] &lt;- &quot;.&quot;</span><br><span class="line">  mc$stars[mc$p &lt;  .05] &lt;- &quot;*&quot;</span><br><span class="line">  mc$stars[mc$p &lt;  .01] &lt;- &quot;**&quot;</span><br><span class="line">  mc$stars[mc$p &lt; .001] &lt;- &quot;***&quot;</span><br><span class="line">  names(mc)[6] &lt;- &quot; &quot;</span><br><span class="line">  </span><br><span class="line">  cat(&quot;\nMultiple Comparisons (Wilcoxon Rank Sum Tests)\n&quot;)</span><br><span class="line">  cat(paste(&quot;Probability Adjustment &#x3D; &quot;, method, &quot;\n\n&quot;, sep&#x3D;&quot;&quot;))</span><br><span class="line">  print(mc[-4], right&#x3D;TRUE)</span><br><span class="line">  cat(&quot;---\nSignif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1\n&quot;)</span><br><span class="line">  return(invisible(NULL))</span><br><span class="line">  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">wmc(Illiteracy ~ state.region, data&#x3D;states, method&#x3D;&quot;holm&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/v2-988542c2ecda1aab54a4cba442d63b7e_720w.jpg" alt="img"></p>
<p>wmc()函数首先给出了样本量、样本中位数、每组的绝对中位差。其中，西部地区（West）的文盲率最低，南部地区（South）文盲率最高。然后，函数生成了六组统计比较（南部与中北部（North Central） 、西部与东北部（Northeast）、西部与南部、中北部与东北部、中北部与南部、东北部与南部）。可以从双侧p值（p）看到，南部与其他三个区域有明显差别，但当显著性水平p＜0.05时，其他三个区域间并没有统计显著的差别。</p>
<h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>在本次分享中，我们评述了R中用于生成统计概要和进行假设检验的函数。我们关注了样本统计量和频数表、独立性检验和类别型变量的相关性度量、定量变量的相关系数（和连带的显著性检验）以及两组或更多组定量结果变量的比较。下次分享，我们将探索一元回归和多元回归，讨论的焦点在于如何理解一个预测变量（一元回归）或多个预测变量（多元回归）与某个被预测变量或效标变量（criterion variable）之间的关系。图形将有助于诊断潜在的问题、评估和提高模型的拟合精度，并发现数据中意料之外的信息瑰宝。</p>
<blockquote>
<p>本文转载自知乎：<a href="https://zhuanlan.zhihu.com/p/181729801" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/181729801</a></p>
</blockquote>
]]></content>
      <categories>
        <category>R</category>
      </categories>
  </entry>
  <entry>
    <title>R语言实战（二）</title>
    <url>/posts/5ad0b051.html</url>
    <content><![CDATA[<p>R是用于统计分析、绘图的语言和操作环境。R是属于GNU系统的一个自由、免费、源代码开放的软件，它是一个用于统计计算和统计制图的优秀工具。在学习R数据科学之前，我们首先要对R语言的基础语法有一个良好的了解，方便我们理解以后的数据科学算法。本次语法精讲分三次讲完，每次负责讲解其中一部分！<strong>本次的R语言语法精讲（二）主要介绍了 R语言的数据的输入输出以及R语言内置的绘图语法。学完本文后，您将可以具备初步的R语言数据可视化的基本能力并结合R语言语法精讲（一）做简单的数据分析项目以及报告。</strong></p>
<p>本文引用：</p>
<blockquote>
<p>《R语言实战—第2版》————-Robert I.Kabacoff<br>《统计计算与模拟》课程课件———-深圳大学林炳清老师</p>
</blockquote>
<p>本文内容：</p>
<ul>
<li>R常用数据结构</li>
<li>R的运算以及常用函数</li>
<li>R语言编程结构<br>判断if-else<br>循环for、while、repeat<br>自定义函数</li>
<li>R的输入与输出（本文）</li>
<li>R基础绘图（本文）</li>
<li>基本数据管理</li>
<li>高级数据管理</li>
</ul>
<h1 id="1-R的输入与输出"><a href="#1-R的输入与输出" class="headerlink" title="1.R的输入与输出"></a>1.R的输入与输出</h1><h2 id="1-1-导入数据"><a href="#1-1-导入数据" class="headerlink" title="1.1 导入数据"></a>1.1 导入数据</h2><p><strong>(1) 从带分隔符的文本文件导入数据</strong></p>
<p>使用read.table()从带分隔符的文本文件中导入数据。此函数可读入一个表格格式的文件并将其保存为一个数据框。表格的每一行分别出现在文件中每一行。</p>
<p>其语法如下：</p>
<p>mydataframe &lt;- read.table(file, options)</p>
<p>其中，file是一个带分隔符的ASCII文本文件，options是控制如何处理数据的选项。</p>
<p>表2-2列出了常见的选项:</p>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-2bcda690f5e7bb685dc1b89cb27edff6_720w.jpg" alt="img"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 文件第一行包含表头，指定了列名，可以通过如下步骤读取该文件(注意参数header的设置)</span><br><span class="line">z &#x3D; read.table(&quot;.&#x2F;z1.txt&quot;, header&#x3D;T)</span><br><span class="line">z</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-a0ceb85fcab690ae11475bd78ff9c4c3_720w.jpg" alt="img"></p>
<p><strong>(2) read.csv()读取.csv文件</strong></p>
<p>函数read.csv()可以读取excel文档中后缀为.csv的文件。在函数read.csv()中，参数header的默认值是TRUE。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x &#x3D; read.csv(&quot;.&#x2F;edf.csv&quot;)</span><br><span class="line">x</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-3be8e6f31c414a64a3f895eb5687e35f_720w.jpg" alt="img"></p>
<p><strong>(3) 函数read.csv()网上文件</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">uci &#x3D; &quot;http:&#x2F;&#x2F;archive.ics.uci.edu&#x2F;ml&#x2F;machine-learning-databases&#x2F;&quot;</span><br><span class="line">uci &#x3D; paste(uci, &quot;echocardiogram&#x2F;echocardiogram.data&quot;, sep&#x3D;&quot;&quot;)</span><br><span class="line">ecc&#x3D; read.csv(uci)</span><br><span class="line">head(ecc)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-0367b99a320636b3b68a01997dd955a7_720w.jpg" alt="img"></p>
<p><strong>(4) read.xlsx()读取.xlsx文件</strong></p>
<p>读取后缀为.xlsx的文件的包有很多。在这里，我们介绍的是R包openxlsx。在这个包中，我们可以使用函数read.xlsx()读取xlsx文件 （首次使用，请先安装此包install.packages(“openxlsx”)）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">require(openxlsx)</span><br><span class="line">x &#x3D; read.xlsx(&quot;.&#x2F;abc.xlsx&quot;)</span><br><span class="line">x</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-377507aa46443e2e970faf8c7bb35a0d_720w.jpg" alt="img"></p>
<h2 id="1-2-导出数据"><a href="#1-2-导出数据" class="headerlink" title="1.2 导出数据"></a>1.2 导出数据</h2><p><strong>(1) 函数cat()输出到屏幕</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x &#x3D; &quot;I love R!&quot;</span><br><span class="line">y &#x3D; &quot;R is very powerful!&quot;</span><br><span class="line">cat(x, y)</span><br><span class="line">cat(x, &quot;\n&quot;, y)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-632856de89ecb378c7fc565fd796bee0_720w.jpg" alt="img"></p>
<p><strong>(2) 函数cat()输出到文件</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat(&quot;abc\n&quot;, file&#x3D;&quot;.&#x2F;u.txt&quot;)</span><br><span class="line">cat(&quot;de\n&quot;, file&#x3D;&quot;.&#x2F;u.txt&quot;, append&#x3D;TRUE)</span><br></pre></td></tr></table></figure>
<p>第一次调用函数cat()创建了文件u，包含一行内容abc;第二次调用追加了第二行，内容是de。</p>
<p><strong>(3) 函数write.table()输出到文件</strong></p>
<p>函数write.table()的用法与函数read.table()非常相似，只不过它是把数据框写入文件。例如:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kids &#x3D; c(&quot;jack&quot;, &quot;jill&quot;)</span><br><span class="line">ages &#x3D; c(12, 10)</span><br><span class="line">d &#x3D; data.frame(kids, ages, stringsAsFactors &#x3D; F)</span><br><span class="line">d</span><br><span class="line">write.table(d, &quot;.&#x2F;kds.txt&quot;)</span><br><span class="line"># 如果不需要行名和列名，可以使用参数row.names，col.names</span><br><span class="line">write.table(d, &quot;.&#x2F;kds2.txt&quot;, row.names&#x3D;F, col.names&#x3D;F)</span><br></pre></td></tr></table></figure>
<p><strong>(4) 函数write.csv()输出到文件</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">write.csv(d, &quot;.&#x2F;kds.csv&quot;)</span><br></pre></td></tr></table></figure>
<p><strong>(5) 函数write.xlsx()输出到文件</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">require(openxlsx)</span><br><span class="line">write.xlsx(d, &quot;.&#x2F;kds.xslx&quot;)</span><br></pre></td></tr></table></figure>
<h1 id="2-R基础绘图"><a href="#2-R基础绘图" class="headerlink" title="2.R基础绘图"></a>2.R基础绘图</h1><h2 id="2-1-R绘图的基础设置"><a href="#2-1-R绘图的基础设置" class="headerlink" title="2.1 R绘图的基础设置"></a>2.1 R绘图的基础设置</h2><p><strong>(1) 一个简单的小例子引入</strong></p>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-4772d99e8e1a69328f87826ec7151bcf_720w.jpg" alt="img"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dose  &lt;- c(20, 30, 40, 45, 60) </span><br><span class="line">drugA &lt;- c(16, 20, 27, 40, 60) </span><br><span class="line">drugB &lt;- c(15, 18, 25, 31, 40)</span><br><span class="line"># 创建一幅描述药物A的剂量和响应关系的图形：</span><br><span class="line">plot(dose, drugA, type&#x3D;&quot;b&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-6fbb86aa5c200784644120f94c094516_720w.jpg" alt="img"></p>
<p>plot()是R中为对象作图的一个泛型函数 （它的输出将根据所绘制对象类型的不同而变化）。 本例中，plot(x, y, type=”b”)将x置于横轴，将y置于纵轴，绘制点集(x,y)，然后使用线段将其连接。选项type=”b”表示同时绘制点和线。使用help(plot)可以查看其他选项。</p>
<p><strong>(2) 图形参数：</strong></p>
<p>我们可以通过修改称为图形参数的选项来自定义一幅图形的多个特征 （字体、颜色、坐标轴、标签等）。</p>
<p><strong>(2.1) 符号和线条</strong>：</p>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-22c8098ffb63668f3c46568ab6987d53_720w.jpg" alt="img"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 绘制一幅图形，其线条类型为点线，宽度为默认宽度的3倍，点的符号为实心正方形，大小为默认符号大小的2倍</span><br><span class="line">plot(dose, drugA, type&#x3D;&quot;b&quot;, lty&#x3D;3, lwd&#x3D;3, pch&#x3D;15, cex&#x3D;2)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-d4636e1c91c435cdd12b46c21af72ba2_720w.jpg" alt="img"></p>
<p><strong>(2.2) 颜色:</strong></p>
<p>R中有若干和颜色相关的参数。表3-3列出了一些常用参数:</p>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-dcc26577b7778a612b657f6ab8447e91_720w.jpg" alt="img"></p>
<p>在R中，可以通过颜色下标、颜色名称、十六进制的颜色值、RGB值或HSV值来指定颜色。举例来说，col=1、col=”white”、col=”#FFFFFF”、col=rgb(1,1,1)和col=hsv(0,0,1)都是表示白色的等价方式。函数rgb()可基于红－绿－蓝三色值生成颜色，而hsv()则基于色相－饱和度－亮度值来生成颜色。</p>
<p><strong>对于创建吸引人的颜色配对，RColorBrewer特别受到欢迎。注意在第一次使用它之前先进行下载(install.packages(“RColorBrewer”))。安装之后， 使用函数brewer.pal(n, name)来创建一个颜色值的向量。</strong>比如说，以下代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 从Set1调色板中抽取了7种用十六进制表示的颜色并返回一个向量。</span><br><span class="line">library(RColorBrewer) </span><br><span class="line">n &lt;- 7 </span><br><span class="line">mycolors &lt;- brewer.pal(n, &quot;Set1&quot;) </span><br><span class="line">barplot(rep(1,n), col&#x3D;mycolors)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-ac71a017baeb0d39b5b5c0552a90f90e_720w.jpg" alt="img"></p>
<p>若要得到所有可选调色板的列表，<a href="https://link.zhihu.com/?target=http%3A//%E8%BE%93%E5%85%A5brewer.pal.info">输入 brewer.pal.info</a>；或者输入display.brewer.all()从而在一个显示输出中产生每个调色板的图形。</p>
<p><strong>(2.3) 文本属性:</strong></p>
<p>图形参数同样可以用来指定字号、字体和字样。表3-4阐释了用于控制文本大小的参数。字体族和字样可以通过字体选项进行控制（见表3-5）</p>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-e5dfe80c174383bf5f228a15cc7f395d_720w.jpg" alt="img"></p>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-eccd8babe0fcca378b87ebc88f4a339b_720w.jpg" alt="img"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 创建的所有图形都将拥有斜体、1.5倍于默认文本大小的坐标轴标签（名称） ，以及粗斜体、2倍于默认文本大小的标题。</span><br><span class="line">par(font.lab&#x3D;3, cex.lab&#x3D;1.5, font.main&#x3D;4, cex.main&#x3D;2)</span><br><span class="line"># 在Windows系统中，等宽字体映射为TT Courier New，衬线字体映射为TT Times New Roman，无衬线字体则映射为TT Arial（TT代表True Type） </span><br><span class="line">windowsFonts( </span><br><span class="line">  A&#x3D;windowsFont(&quot;Arial Black&quot;), </span><br><span class="line">  B&#x3D;windowsFont(&quot;Bookman Old Style&quot;), </span><br><span class="line">  C&#x3D;windowsFont(&quot;Comic Sans MS&quot;) </span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><strong>(2.4) 图形尺寸与边界尺寸:</strong></p>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-3cf3d890f6348dc987a9b563952603e7_720w.jpg" alt="img"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 生成一幅4英寸宽、3英寸高、上下边界为1英寸、左边界为0.5英寸、右边界为0.2英寸的图形</span><br><span class="line">par(pin&#x3D;c(4,3), mai&#x3D;c(1,.5, 1, .2))</span><br></pre></td></tr></table></figure>
<p><strong>(2.5) 使用图形参数控制图形外观例子:</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dose  &lt;- c(20, 30, 40, 45, 60) </span><br><span class="line">drugA &lt;- c(16, 20, 27, 40, 60) </span><br><span class="line">drugB &lt;- c(15, 18, 25, 31, 40) </span><br><span class="line"> </span><br><span class="line">opar &lt;- par(no.readonly&#x3D;TRUE)</span><br><span class="line">par(mfrow&#x3D;c(1,2),pin&#x3D;c(2, 3),opar) </span><br><span class="line">par(lwd&#x3D;2, cex&#x3D;1.5) </span><br><span class="line">par(cex.axis&#x3D;.75, font.axis&#x3D;3) </span><br><span class="line">plot(dose, drugA, type&#x3D;&quot;b&quot;, pch&#x3D;19, lty&#x3D;2, col&#x3D;&quot;red&quot;) </span><br><span class="line">plot(dose, drugB, type&#x3D;&quot;b&quot;, pch&#x3D;23, lty&#x3D;6, col&#x3D;&quot;blue&quot;, bg&#x3D;&quot;green&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-6091b253b6ca199ce33d1e74ba36e68e_720w.jpg" alt="img"></p>
<p><strong>(3) 添加文本、自定义坐标轴和图例</strong></p>
<p>除了图形参数，许多高级绘图函数（例如plot、hist、boxplot）也允许自行设定坐标轴和文本标注选项。举例来说，以下代码在图形上添加了标题（main） 、副标题（sub） 、坐标轴标签（xlab、ylab）并指定了坐标轴范围（xlim、ylim）。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">plot(dose, drugA, type&#x3D;&quot;b&quot;,  </span><br><span class="line">     col&#x3D;&quot;red&quot;, lty&#x3D;2, pch&#x3D;2, lwd&#x3D;2, </span><br><span class="line">     main&#x3D;&quot;Clinical Trials for Drug A&quot;, </span><br><span class="line">     sub&#x3D;&quot;This is hypothetical data&quot;, </span><br><span class="line">     xlab&#x3D;&quot;Dosage&quot;, ylab&#x3D;&quot;Drug Response&quot;, </span><br><span class="line">     xlim&#x3D;c(0, 60), ylim&#x3D;c(0, 70))</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-694d49033888a017014e1ab5a22bd97c_720w.jpg" alt="img"></p>
<p><strong>(3.1) 标题:</strong></p>
<p>使用title()函数为图形添加标题和坐标轴标签。调用格式为：</p>
<p>title(main=”main title”, sub=”subtitle”,</p>
<p>xlab=”x-axis label”, ylab=”y-axis label”)</p>
<p>函数title()中亦可指定其他图形参数（如文本大小、字体、旋转角度和颜色） 。</p>
<p>函数title()一般来说被用于添加信息到一个默认标题和坐标轴标签被ann=FALSE选项移除的图形中。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">par(ann&#x3D;FALSE)   # 不生成默认坐标轴标签</span><br><span class="line">plot(dose, drugA, type&#x3D;&quot;b&quot;,  </span><br><span class="line">     col&#x3D;&quot;red&quot;, lty&#x3D;2, pch&#x3D;2, lwd&#x3D;2, </span><br><span class="line">     xlim&#x3D;c(0, 60), ylim&#x3D;c(0, 70))</span><br><span class="line"># 生成红色的标题和蓝色的副标题，以及比默认大小小25%的绿色x轴、y轴标签</span><br><span class="line">title(main&#x3D;&quot;My Title&quot;, col.main&#x3D;&quot;red&quot;,  </span><br><span class="line">      sub&#x3D;&quot;My Subtitle&quot;, col.sub&#x3D;&quot;blue&quot;, </span><br><span class="line">      xlab&#x3D;&quot;My X label&quot;, ylab&#x3D;&quot;My Y label&quot;, </span><br><span class="line">      col.lab&#x3D;&quot;green&quot;, cex.lab&#x3D;0.75)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-dfc9768313e9514e6c924f792ba49e4f_720w.jpg" alt="img"></p>
<p><strong>(3.2) 坐标轴:</strong></p>
<p>可以使用函数axis()来创建自定义的坐标轴，而非使用R中的默认坐标轴。其格式为：</p>
<p>axis(side, at=, labels=, pos=, lty=, col=, las=, tck=, …)</p>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-d674f67eb096fe0e5d8e9dc8080a391a_720w.jpg" alt="img"></p>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-7889cd51fecfcd0619f6f6ae9d6a7dca_720w.jpg" alt="img"></p>
<p>创建自定义坐标轴时，你应当禁用高级绘图函数自动生成的坐标轴。参数axes=FALSE将禁用全部坐标轴（包括坐标轴框架线，除非你添加了参数frame.plot=TRUE） 。参数xaxt=”n”和yaxt=”n”将分别禁用X轴或Y轴（会留下框架线，只是去除了刻度） 。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x &lt;- c(1:10) </span><br><span class="line">y &lt;- x  </span><br><span class="line">z &lt;- 10&#x2F;x </span><br><span class="line">opar &lt;- par(no.readonly&#x3D;TRUE)  </span><br><span class="line">par(opar)</span><br><span class="line">par(mar&#x3D;c(5, 4, 4, 8) + 0.1)  </span><br><span class="line">plot(x, y, type&#x3D;&quot;b&quot;,  </span><br><span class="line">     pch&#x3D;21, col&#x3D;&quot;red&quot;, </span><br><span class="line">     yaxt&#x3D;&quot;n&quot;, lty&#x3D;3, ann&#x3D;FALSE) </span><br><span class="line">lines(x, z, type&#x3D;&quot;b&quot;, pch&#x3D;22, col&#x3D;&quot;blue&quot;, lty&#x3D;2) </span><br><span class="line"> </span><br><span class="line">axis(2, at&#x3D;x, labels&#x3D;x, col.axis&#x3D;&quot;red&quot;, las&#x3D;2)  </span><br><span class="line"> </span><br><span class="line">axis(4, at&#x3D;z, labels&#x3D;round(z, digits&#x3D;2), </span><br><span class="line">     col.axis&#x3D;&quot;blue&quot;, las&#x3D;2, cex.axis&#x3D;0.7, tck&#x3D;-.01)  </span><br><span class="line"> </span><br><span class="line">mtext(&quot;y&#x3D;1&#x2F;x&quot;, side&#x3D;4, line&#x3D;3, cex.lab&#x3D;1, las&#x3D;2, col&#x3D;&quot;blue&quot;) </span><br><span class="line"> </span><br><span class="line">title(&quot;An Example of Creative Axes&quot;,  </span><br><span class="line">      xlab&#x3D;&quot;X values&quot;, </span><br><span class="line">      ylab&#x3D;&quot;Y&#x3D;X&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-f64f8deb4036bfc3976293fb3cb399cd_720w.jpg" alt="img"></p>
<p><strong>(3.3) 参考线:</strong></p>
<p>函数abline()可以用来为图形添加参考线。其使用格式为：</p>
<p>abline(h=yvalues, v=xvalues)</p>
<p>函数abline()中也可以指定其他图形参数（如线条类型、颜色和宽度）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">plot(x, y, type&#x3D;&quot;b&quot;,  </span><br><span class="line">     pch&#x3D;21, col&#x3D;&quot;red&quot;, </span><br><span class="line">     yaxt&#x3D;&quot;n&quot;, lty&#x3D;3, ann&#x3D;FALSE) </span><br><span class="line"># 为1、3、5、7、9的位置添加了垂直的蓝色虚线</span><br><span class="line">abline(v&#x3D;seq(1, 10, 2), lty&#x3D;2, col&#x3D;&quot;blue&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-de2459e13da3eb3d944446cc01696cec_720w.jpg" alt="img"></p>
<p><strong>(3.4) 图例:</strong></p>
<p>当图形中包含的数据不止一组时，图例可以帮助你辨别出每个条形、扇形区域或折线各代表哪一类数据。我们可以使用函数legend()来添加图例（果然不出所料） 。其使用格式为：</p>
<p>legend(location, title, legend, …)</p>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-caee56fd438e7b47bb1f6c08c7d90264_720w.jpg" alt="img"></p>
<p>其他常用的图例选项包括用于指定盒子样式的bty、指定背景色的bg、指定大小的cex，以及指定文本颜色的text.col。指定horiz=TRUE将会水平放置图例，而不是垂直放置。关于图例的更多细节，请参考help(legend)。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dose  &lt;- c(20, 30, 40, 45, 60)  </span><br><span class="line">drugA &lt;- c(16, 20, 27, 40, 60) </span><br><span class="line">drugB &lt;- c(15, 18, 25, 31, 40) </span><br><span class="line"> </span><br><span class="line">opar &lt;- par(no.readonly&#x3D;TRUE) </span><br><span class="line">par(opar)</span><br><span class="line">par(lwd&#x3D;2, cex&#x3D;1.5, font.lab&#x3D;2)</span><br><span class="line">plot(dose, drugA, type&#x3D;&quot;b&quot;, </span><br><span class="line">     pch&#x3D;15, lty&#x3D;1, col&#x3D;&quot;red&quot;, ylim&#x3D;c(0, 60),  </span><br><span class="line">     main&#x3D;&quot;Drug A vs. Drug B&quot;, </span><br><span class="line">     xlab&#x3D;&quot;Drug Dosage&quot;, ylab&#x3D;&quot;Drug Response&quot;)  </span><br><span class="line"> </span><br><span class="line">lines(dose, drugB, type&#x3D;&quot;b&quot;, </span><br><span class="line">      pch&#x3D;17, lty&#x3D;2, col&#x3D;&quot;blue&quot;) </span><br><span class="line"> </span><br><span class="line">abline(h&#x3D;c(30), lwd&#x3D;1.5, lty&#x3D;2, col&#x3D;&quot;gray&quot;) </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">legend(&quot;topleft&quot;, inset&#x3D;.05, title&#x3D;&quot;Drug Type&quot;, c(&quot;A&quot;,&quot;B&quot;) ,lty&#x3D;c(1, 2), pch&#x3D;c(15, 17), col&#x3D;c(&quot;red&quot;, &quot;blue&quot;))</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-721294eb02e466621734aee77606f3d4_720w.jpg" alt="img"></p>
<p><strong>(3.5) 文本标注:</strong></p>
<p>可以通过函数text()和mtext()将文本添加到图形上。text()可向绘图区域内部添加文本，而mtext()则向图形的四个边界之一添加文本。使用格式分别为：</p>
<p>text(location, “text to place”, pos, …)</p>
<p>mtext(“text to place”, side, line=n, …)</p>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-bf68ca4eae613ac8d395a588200f3e3f_720w.jpg" alt="img"></p>
<p>其他常用的选项有cex、col和font（分别用来调整字号、颜色和字体样式） 。</p>
<p>除了用来添加文本标注以外，text()函数也通常用来标示图形中的点。我们只需指定一系列的x、y坐标作为位置参数，同时以向量的形式指定要放置的文本。x、y和文本标签向量的长度应当相同。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">attach(mtcars) </span><br><span class="line">plot(wt, mpg, </span><br><span class="line">     main&#x3D;&quot;Mileage vs. Car Weight&quot;, </span><br><span class="line">     xlab&#x3D;&quot;Weight&quot;, ylab&#x3D;&quot;Mileage&quot;, </span><br><span class="line">     pch&#x3D;18, col&#x3D;&quot;blue&quot;) </span><br><span class="line">text(wt, mpg, </span><br><span class="line">     row.names(mtcars), </span><br><span class="line">     cex&#x3D;0.6, pos&#x3D;4, col&#x3D;&quot;red&quot;) </span><br><span class="line">detach(mtcars)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-e541b01550b094f2426a733c41aaddaa_720w.jpg" alt="img"></p>
<p><strong>(3.6) 数学标注:</strong></p>
<p>函数plotmath()可以为图形主体或边界上的标题、坐标轴名称或文本标注添加数学符号。</p>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-6f90b9d000def6d2d6da3857022e0c65_720w.jpg" alt="img"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x &#x3D; seq(-2, 2, 0.5)</span><br><span class="line">plot(x, x^2, type&#x3D;&quot;l&quot;, main&#x3D;expression(paste(&quot;f(x)&#x3D;&quot;,x^2)), ylab&#x3D;expression(x^2), cex.axis&#x3D;1.2, cex.lab&#x3D;1.2, cex.main&#x3D;1.2, lwd&#x3D;2, xlim&#x3D;c(-3, 3), ylim&#x3D;c(-1, 5))</span><br><span class="line">points(x, x^2+0.5, type&#x3D;&quot;b&quot;, lwd&#x3D;3, lty&#x3D;2)</span><br><span class="line">points(x, x^2-0.5, pch&#x3D;10, lwd&#x3D;1)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-e79cb4a8cbc3ddda1e9d19865607d55a_720w.jpg" alt="img"></p>
<p><strong>(4) 图形组合：</strong></p>
<p>在R中使用函数par()或layout()可以容易地组合多幅图形为一幅总括图形。</p>
<p>可以在par()函数中使用图形参数mfrow=c(nrows,ncols)来创建按行填充的、行数为nrows、列数为ncols的图形矩阵。另外，可以使用mfcol=c(nrows, ncols)按列填充矩阵。</p>
<p><strong>(4.1) 示例1</strong>：创建了四幅图形并将其排布在两行两列中</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">attach(mtcars) </span><br><span class="line">opar &lt;- par(no.readonly&#x3D;TRUE) </span><br><span class="line">par(mfrow&#x3D;c(2,2))</span><br><span class="line">plot(wt,mpg, main&#x3D;&quot;Scatterplot of wt vs. mpg&quot;) </span><br><span class="line">plot(wt,disp, main&#x3D;&quot;Scatterplot of wt vs. disp&quot;) </span><br><span class="line">hist(wt, main&#x3D;&quot;Histogram of wt&quot;) </span><br><span class="line">boxplot(wt, main&#x3D;&quot;Boxplot of wt&quot;) </span><br><span class="line">par(opar) </span><br><span class="line">detach(mtcars)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-e84469fc8ec4bb0d16835c20abf477f0_720w.jpg" alt="img"></p>
<p><strong>(4.2) 示例2：</strong>依三行一列排布三幅图形</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">attach(mtcars) </span><br><span class="line">opar &lt;- par(no.readonly&#x3D;TRUE) </span><br><span class="line">par(mfrow&#x3D;c(3,1)) </span><br><span class="line">hist(wt) </span><br><span class="line">hist(mpg) </span><br><span class="line">hist(disp) </span><br><span class="line">par(opar) </span><br><span class="line">detach(mtcars)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-6c345e92e6a5e9d7daff75afd3c740c2_720w.jpg" alt="img"></p>
<p><strong>(4.3) 示例3：</strong>函数layout()的调用形式为layout(mat)，其中的mat是一个矩阵，它指定了所要组合的多个图形的所在位置。在以下代码中，一幅图被置于第1行，另两幅图则被置于第2行</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">attach(mtcars) </span><br><span class="line">layout(matrix(c(1,1,2,3), 2, 2, byrow &#x3D; TRUE)) </span><br><span class="line">hist(wt) </span><br><span class="line">hist(mpg) </span><br><span class="line">hist(disp) </span><br><span class="line">detach(mtcars)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-93b1871008a8395326a0f88b16659127_720w.jpg" alt="img"></p>
<p><strong>(4.4) 示例4:</strong>为了更精确地控制每幅图形的大小，可以有选择地在layout()函数中使用widths=和heights=两个参数。其形式为：</p>
<p>widths = 各列宽度值组成的一个向量</p>
<p>heights = 各行高度值组成的一个向量</p>
<p>相对宽度可以直接通过数值指定，绝对宽度（以厘米为单位）可以通过函数lcm()来指定。</p>
<p>在以下代码中，我们再次将一幅图形置于第1行，两幅图形置于第2行。但第1行中图形的高度是第2行中图形高度的二分之一。除此之外，右下角图形的宽度是左下角图形宽度的三分之一 :</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">attach(mtcars) </span><br><span class="line">layout(matrix(c(1, 1, 2, 3), 2, 2, byrow &#x3D; TRUE), </span><br><span class="line">       widths&#x3D;c(3, 1), heights&#x3D;c(1, 2)) </span><br><span class="line">hist(wt) </span><br><span class="line">hist(mpg) </span><br><span class="line">hist(disp) </span><br><span class="line">detach(mtcars)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-f59067d2d1726dc02e557581233e6520_720w.jpg" alt="img"></p>
<p><strong>(5) 图形布局的精细控制</strong></p>
<p>可能有很多时候，你想通过排布或叠加若干图形来创建单幅的、有意义的图形，这需要有对图形布局的精细控制能力。你可以使用图形参数fig=完成这个任务。 参数fig=的取值是一个形如c(x1, x2, y1, y2)的数值向量。</p>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-c7928563ef2c59d852074423fb376907_720w.jpg" alt="img"></p>
<p>第一个fig=将散点图设定为占据横向范围0~0.8，纵向范围0~0.8。上方的箱线图横向占据0~0.8，纵向0.55~1。右侧的箱线图横向占据0.65~1，纵向0~0.8。fig=默认会新建一幅图形，所以在添加一幅图到一幅现有图形上时，请设定参数new=TRUE。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 在散点图上添加两幅箱线图，创建了单幅的增强型图形</span><br><span class="line">opar &lt;- par(no.readonly&#x3D;TRUE) </span><br><span class="line">par(fig&#x3D;c(0, 0.8, 0, 0.8))  </span><br><span class="line">plot(mtcars$wt, mtcars$mpg, </span><br><span class="line">     xlab&#x3D;&quot;Miles Per Gallon&quot;, </span><br><span class="line">     ylab&#x3D;&quot;Car Weight&quot;) </span><br><span class="line">par(fig&#x3D;c(0, 0.8, 0.55, 1), new&#x3D;TRUE) </span><br><span class="line">boxplot(mtcars$wt, horizontal&#x3D;TRUE, axes&#x3D;FALSE)  </span><br><span class="line"> </span><br><span class="line">par(fig&#x3D;c(0.65, 1, 0, 0.8), new&#x3D;TRUE) </span><br><span class="line">boxplot(mtcars$mpg, axes&#x3D;FALSE)</span><br><span class="line">mtext(&quot;Enhanced Scatterplot&quot;, side&#x3D;3, outer&#x3D;TRUE, line&#x3D;-3) </span><br><span class="line"> </span><br><span class="line">par(opar)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-03aab7b882b8d083b1cd8239c93e9cdf_720w.jpg" alt="img"></p>
<h2 id="2-2-R绘图的基本图形"><a href="#2-2-R绘图的基本图形" class="headerlink" title="2.2 R绘图的基本图形"></a>2.2 R绘图的基本图形</h2><p><strong>(1) 条形图</strong></p>
<p>条形图通过垂直的或水平的条形展示了类别型变量的分布（频数） 。函数barplot()的最简单用法是：</p>
<p>barplot(height) ，其中的height是一个向量或一个矩阵。</p>
<p><strong>(1.1) 简单的条形图</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(vcd) </span><br><span class="line"># 变量Improved记录了对每位接受了安慰剂或药物治疗的病人的治疗结果</span><br><span class="line">counts &lt;- table(Arthritis$Improved) </span><br><span class="line">counts </span><br><span class="line"># 简单条形图</span><br><span class="line">barplot(counts,  </span><br><span class="line">       main&#x3D;&quot;Simple Bar Plot&quot;, </span><br><span class="line">       xlab&#x3D;&quot;Improvement&quot;, ylab&#x3D;&quot;Frequency&quot;) </span><br><span class="line"># 水平条形图</span><br><span class="line">barplot(counts, </span><br><span class="line">       main&#x3D;&quot;Horizontal Bar Plot&quot;, </span><br><span class="line">       xlab&#x3D;&quot;Frequency&quot;, ylab&#x3D;&quot;Improvement&quot;,  </span><br><span class="line">       horiz&#x3D;TRUE)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-48dd29f7f75afa13ecf30028c850ae61_720w.jpg" alt="img"></p>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-2c00b4ee98cf70f6037f5509e879c830_720w.jpg" alt="img"></p>
<p><strong>(1.2) 堆砌条形图和分组条形图</strong></p>
<p>如果height是一个矩阵而不是一个向量，则绘图结果将是一幅堆砌条形图或分组条形图。</p>
<p>若beside=FALSE（默认值） ，则矩阵中的每一列都将生成图中的一个条形，各列中的值将给出堆砌的“子条”的高度。</p>
<p>若beside=TRUE，则矩阵中的每一列都表示一个分组，各列中的值将并列而不是堆砌。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(vcd)</span><br><span class="line">counts &lt;- table(Arthritis$Improved, Arthritis$Treatment) </span><br><span class="line">counts </span><br><span class="line"># 堆砌条形图</span><br><span class="line">barplot(counts, </span><br><span class="line">     main&#x3D;&quot;Stacked Bar Plot&quot;,  </span><br><span class="line">     xlab&#x3D;&quot;Treatment&quot;, ylab&#x3D;&quot;Frequency&quot;, </span><br><span class="line">     col&#x3D;c(&quot;red&quot;, &quot;yellow&quot;,&quot;green&quot;), </span><br><span class="line">     legend&#x3D;rownames(counts))</span><br><span class="line"># 分组条形图</span><br><span class="line">barplot(counts, </span><br><span class="line">     main&#x3D;&quot;Grouped Bar Plot&quot;, </span><br><span class="line">     xlab&#x3D;&quot;Treatment&quot;, ylab&#x3D;&quot;Frequency&quot;, </span><br><span class="line">     col&#x3D;c(&quot;red&quot;, &quot;yellow&quot;, &quot;green&quot;), </span><br><span class="line">     legend&#x3D;rownames(counts), beside&#x3D;TRUE)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-c52c823982317fac7de81e4cfcac4241_720w.jpg" alt="img"></p>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-4b9bc3b71dc3c6674779bcfffd0bfe82_720w.jpg" alt="img"></p>
<p><strong>(1.3) 均值条形图</strong></p>
<p>条形图并不一定要基于计数数据或频率数据。你可以使用数据整合函数并将结果传递给barplot()函数，来创建表示均值、中位数、标准差等的条形图。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">states &lt;- data.frame(state.region, state.x77) </span><br><span class="line">means &lt;- aggregate(states$Illiteracy, by&#x3D;list(state.region), FUN&#x3D;mean) </span><br><span class="line">means </span><br><span class="line"># 将均值从小到大排序</span><br><span class="line">means &lt;- means[order(means$x),]</span><br><span class="line">means </span><br><span class="line">barplot(means$x, names.arg&#x3D;means$Group.1)</span><br><span class="line">title(&quot;Mean Illiteracy Rate&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-86482e96dc2914c2fa25df0738395a7d_720w.jpg" alt="img"></p>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-28ff7aca91c26f2431a7f740eced3583_720w.jpg" alt="img"></p>
<p><strong>(1.4) 荆棘图</strong></p>
<p>棘状图对堆砌条形图进行了重缩放，这样每个条形的高度均为1，每一段的高度即表示比例。棘状图可由vcd包中的函数spine()绘制。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(vcd) </span><br><span class="line">attach(Arthritis) </span><br><span class="line">counts &lt;- table(Treatment, Improved) </span><br><span class="line">spine(counts, main&#x3D;&quot;Spinogram Example&quot;) </span><br><span class="line">detach(Arthritis)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-7069fd3c44d5d03948063c64d6ce4fac_720w.jpg" alt="img"></p>
<p><strong>(2) 饼图</strong></p>
<p>饼图可由以下函数创建：</p>
<p>pie(x, labels)</p>
<p>其中x是一个非负数值向量， 表示每个扇形的面积， 而labels则是表示各扇形标签的字符型向量。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">par(mfrow&#x3D;c(2, 2))  </span><br><span class="line">slices &lt;- c(10, 12,4, 16, 8)  </span><br><span class="line">lbls &lt;- c(&quot;US&quot;, &quot;UK&quot;, &quot;Australia&quot;, &quot;Germany&quot;, &quot;France&quot;) </span><br><span class="line">pie(slices, labels &#x3D; lbls, </span><br><span class="line">    main&#x3D;&quot;Simple Pie Chart&quot;) </span><br><span class="line"> </span><br><span class="line">pct &lt;- round(slices&#x2F;sum(slices)*100) </span><br><span class="line">lbls2 &lt;- paste(lbls, &quot; &quot;, pct, &quot;%&quot;, sep&#x3D;&quot;&quot;) </span><br><span class="line">pie(slices, labels&#x3D;lbls2, col&#x3D;rainbow(length(lbls2)),  </span><br><span class="line">    main&#x3D;&quot;Pie Chart with Percentages&quot;) </span><br><span class="line">library(plotrix) </span><br><span class="line">pie3D(slices, labels&#x3D;lbls,explode&#x3D;0.1, </span><br><span class="line">      main&#x3D;&quot;3D Pie Chart &quot;)  </span><br><span class="line">mytable &lt;- table(state.region)  </span><br><span class="line">lbls3 &lt;- paste(names(mytable), &quot;\n&quot;, mytable, sep&#x3D;&quot;&quot;) </span><br><span class="line">pie(mytable, labels &#x3D; lbls3, </span><br><span class="line">    main&#x3D;&quot;Pie Chart from a Table\n (with sample sizes)&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-abf72d617493d4e802ffb8618f03b114_720w.jpg" alt="img"></p>
<p>扇形图提供了一种同时展示相对数量和相互差异的方法。在R中，扇形图是通过plotrix包中的fan.plot()函数实现的。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(plotrix) </span><br><span class="line">slices &lt;- c(10, 12,4, 16, 8) </span><br><span class="line">lbls &lt;- c(&quot;US&quot;, &quot;UK&quot;, &quot;Australia&quot;, &quot;Germany&quot;, &quot;France&quot;) </span><br><span class="line">fan.plot(slices, labels &#x3D; lbls, main&#x3D;&quot;Fan Plot&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-6c979ae6ad79f2fa1cb97b7a4a8d3baa_720w.jpg" alt="img"></p>
<p><strong>(3) 直方图</strong></p>
<p>直方图通过在x轴上将值域分割为一定数量的组，在y轴上显示相应值的频数，展示了连续型变量的分布。可以使用如下函数创建直方图：</p>
<p>hist(x)</p>
<p>其中的x是一个由数据值组成的数值向量。参数freq=FALSE表示根据概率密度而不是频数绘制图形。参数breaks用于控制组的数量。在定义直方图中的单元时，默认将生成等距切分。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">par(mfrow&#x3D;c(2,2)) </span><br><span class="line">  </span><br><span class="line">hist(mtcars$mpg)  </span><br><span class="line"> </span><br><span class="line">hist(mtcars$mpg, </span><br><span class="line">     breaks&#x3D;12, </span><br><span class="line">     col&#x3D;&quot;red&quot;, </span><br><span class="line">     xlab&#x3D;&quot;Miles Per Gallon&quot;, </span><br><span class="line">     main&#x3D;&quot;Colored histogram with 12 bins&quot;) </span><br><span class="line"> </span><br><span class="line">hist(mtcars$mpg, </span><br><span class="line">     freq&#x3D;FALSE, </span><br><span class="line">     breaks&#x3D;12, </span><br><span class="line">     col&#x3D;&quot;red&quot;, </span><br><span class="line">     xlab&#x3D;&quot;Miles Per Gallon&quot;, </span><br><span class="line">     main&#x3D;&quot;Histogram, rug plot, density curve&quot;)  </span><br><span class="line">rug(jitter(mtcars$mpg)) </span><br><span class="line">lines(density(mtcars$mpg), col&#x3D;&quot;blue&quot;, lwd&#x3D;2) </span><br><span class="line"> </span><br><span class="line">x &lt;- mtcars$mpg </span><br><span class="line">h&lt;-hist(x, </span><br><span class="line">        breaks&#x3D;12, </span><br><span class="line">        col&#x3D;&quot;red&quot;, </span><br><span class="line">        xlab&#x3D;&quot;Miles Per Gallon&quot;, </span><br><span class="line">        main&#x3D;&quot;Histogram with normal curve and box&quot;) </span><br><span class="line">xfit&lt;-seq(min(x), max(x), length&#x3D;40) </span><br><span class="line">yfit&lt;-dnorm(xfit, mean&#x3D;mean(x), sd&#x3D;sd(x)) </span><br><span class="line">yfit &lt;- yfit*diff(h$mids[1:2])*length(x)  </span><br><span class="line">lines(xfit, yfit, col&#x3D;&quot;blue&quot;, lwd&#x3D;2) </span><br><span class="line">box()</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-7cc8ce761e9aeca0a0d5285d03b16203_720w.jpg" alt="img"></p>
<p><strong>(4) 核密度图</strong></p>
<p>核密度估计是用于估计随机变量概率密度函数的一种非参数方法。从总体上讲，核密度图不失为一种用来观察连续型变量分布的有效方法。绘制密度图的方法（不叠加到另一幅图上方）为：</p>
<p>plot(density(x)) 其中的x是一个数值型向量。</p>
<p>由于plot()函数会创建一幅新的图形，所以要向一幅已经存在的图形上叠加一条密度曲线，可以使用lines()函数。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">par(mfrow&#x3D;c(2,1)) </span><br><span class="line">d &lt;- density(mtcars$mpg) </span><br><span class="line">plot(d)  </span><br><span class="line">d &lt;- density(mtcars$mpg)  </span><br><span class="line">plot(d, main&#x3D;&quot;Kernel Density of Miles Per Gallon&quot;) </span><br><span class="line"># 将曲线修改为蓝色，并使用实心红色填充曲线下方的区域 </span><br><span class="line"># polygon()函数根据顶点的x和y坐标（本例中由density()函数提供）绘制了多边形。 </span><br><span class="line">polygon(d, col&#x3D;&quot;red&quot;, border&#x3D;&quot;blue&quot;) </span><br><span class="line"># 添加棕色的轴须图 </span><br><span class="line">rug(mtcars$mpg, col&#x3D;&quot;brown&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-46816645fcfd87bf2673d2cb8b3d9d63_720w.jpg" alt="img"></p>
<p><a href="https://link.zhihu.com/?target=http%3A//%E4%BD%BF%E7%94%A8sm%E5%8C%85%E4%B8%AD%E7%9A%84sm.density.compare">使用sm包中的sm.density.compare</a>()函数可向图形叠加两组或更多的核密度图。使用格式为：</p>
<p><a href="https://link.zhihu.com/?target=http%3A//sm.density.compare">sm.density.compare</a>(x, factor) 其中的x是一个数值型向量，factor是一个分组变量。请在第一次使用sm包之前安装它。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(sm)  </span><br><span class="line">attach(mtcars) </span><br><span class="line"> </span><br><span class="line">cyl.f &lt;- factor(cyl, levels&#x3D; c(4,6,8), </span><br><span class="line">              labels &#x3D; c(&quot;4 cylinder&quot;, &quot;6 cylinder&quot;,  </span><br><span class="line">                         &quot;8 cylinder&quot;)) </span><br><span class="line"> </span><br><span class="line">sm.density.compare(mpg, cyl, xlab&#x3D;&quot;Miles Per Gallon&quot;) </span><br><span class="line">title(main&#x3D;&quot;MPG Distribution by Car Cylinders&quot;) </span><br><span class="line"> </span><br><span class="line">detach(mtcars)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-5211f46ac859cc57836f32fc2d382079_720w.jpg" alt="img"></p>
<p><strong>(5) 箱线图</strong></p>
<p>箱线图（又称盒须图）通过绘制连续型变量的五数总括，即最小值、下四分位数（第25百分位数）、中位数（第50百分位数）、上四分位数（第75百分位数）以及最大值，描述了连续型变量的分布。箱线图能够显示出可能为离群点（范围±1.5*IQR以外的值，IQR表示四分位距，即上四分位数与下四分位数的差值）的观测。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">boxplot(mtcars$mpg, main&#x3D;&quot;Box plot&quot;, ylab&#x3D;&quot;Miles per Gallon&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-a8c4ac7a9823054b18d7699759bc08fd_720w.jpg" alt="img"></p>
<p>我们使用并列箱线图重新研究了四缸、六缸、八缸发动机对每加仑汽油行驶的英里数的影响。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">boxplot(mpg ~ cyl, data&#x3D;mtcars, </span><br><span class="line">        main&#x3D;&quot;Car Mileage Data&quot;,  </span><br><span class="line">        xlab&#x3D;&quot;Number of Cylinders&quot;, </span><br><span class="line">        ylab&#x3D;&quot;Miles Per Gallon&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-cae2e3bc1592dc13a9f91c4b03371642_720w.jpg" alt="img"></p>
<p>最后，你可以为多个分组因子绘制箱线图。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 创建汽缸数量的因子 </span><br><span class="line">mtcars$cyl.f &lt;- factor(mtcars$cyl, </span><br><span class="line">                      levels&#x3D;c(4,6,8),  </span><br><span class="line">                      labels&#x3D;c(&quot;4&quot;,&quot;6&quot;,&quot;8&quot;)) </span><br><span class="line"># 创建变速箱类型的因子 </span><br><span class="line">mtcars$am.f &lt;- factor(mtcars$am, </span><br><span class="line">                     levels&#x3D;c(0,1), </span><br><span class="line">                     labels&#x3D;c(&quot;auto&quot;, &quot;standard&quot;))  </span><br><span class="line"># 生成箱线图 </span><br><span class="line">boxplot(mpg ~ am.f *cyl.f, </span><br><span class="line">       data&#x3D;mtcars, </span><br><span class="line">       varwidth&#x3D;TRUE, </span><br><span class="line">       col&#x3D;c(&quot;gold&quot;,&quot;darkgreen&quot;), </span><br><span class="line">       main&#x3D;&quot;MPG Distribution by Auto Type&quot;, </span><br><span class="line">       xlab&#x3D;&quot;Auto Type&quot;, ylab&#x3D;&quot;Miles Per Gallon&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-5c91212fe36e63ad7f0dd73f3083fa82_720w.jpg" alt="img"></p>
<p><strong>(6) 小提琴图</strong></p>
<p>小提琴图是箱线图与核密度图的结合。 你可以使用vioplot包中的vioplot()函数绘制它。 请在第一次使用之前安装vioplot包。</p>
<p>vioplot()函数的使用格式为：</p>
<p>vioplot(x1, x2, … , names=, col=)</p>
<p>其中x1, x2, …表示要绘制的一个或多个数值向量（将为每个向量绘制一幅小提琴图）。参数names是小提琴图中标签的字符向量，而col是一个为每幅小提琴图指定颜色的向量。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(vioplot)  </span><br><span class="line">x1 &lt;- mtcars$mpg[mtcars$cyl&#x3D;&#x3D;4] </span><br><span class="line">x2 &lt;- mtcars$mpg[mtcars$cyl&#x3D;&#x3D;6] </span><br><span class="line">x3 &lt;- mtcars$mpg[mtcars$cyl&#x3D;&#x3D;8] </span><br><span class="line">vioplot(x1, x2, x3, </span><br><span class="line">        names&#x3D;c(&quot;4 cyl&quot;, &quot;6 cyl&quot;, &quot;8 cyl&quot;), </span><br><span class="line">        col&#x3D;&quot;gold&quot;) </span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">title(&quot;Violin Plots of Miles Per Gallon&quot;, ylab&#x3D;&quot;Miles Per Gallon&quot;, </span><br><span class="line">       xlab&#x3D;&quot;Number of Cylinders&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-aa868d0531ad3a67f8834cf4b0f8a536_720w.jpg" alt="img"></p>
<p><strong>(7) 点图</strong></p>
<p>点图提供了一种在简单水平刻度上绘制大量有标签值的方法。你可以使用dotchart()函数创建点图，格式为：</p>
<p>dotchart(x, labels=)</p>
<p>其中的x是一个数值向量，而labels则是由每个点的标签组成的向量。你可以通过添加参数groups来选定一个因子，用以指定x中元素的分组方式。如果这样做，则参数gcolor可以控制不同组标签的颜色，cex可以控制标签的大小。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dotchart(mtcars$mpg, labels&#x3D;row.names(mtcars), cex&#x3D;.7, </span><br><span class="line">         main&#x3D;&quot;Gas Mileage for Car Models&quot;, </span><br><span class="line">         xlab&#x3D;&quot;Miles Per Gallon&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-021e1478a4881257d4b116a5c203430f_720w.jpg" alt="img"></p>
<p>分组、排序、着色后的点图</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x &lt;- mtcars[order(mtcars$mpg),] </span><br><span class="line"> </span><br><span class="line">x$cyl &lt;- factor(x$cyl)  </span><br><span class="line"> </span><br><span class="line">x$color[x$cyl&#x3D;&#x3D;4] &lt;- &quot;red&quot; </span><br><span class="line">x$color[x$cyl&#x3D;&#x3D;6] &lt;- &quot;blue&quot; </span><br><span class="line">x$color[x$cyl&#x3D;&#x3D;8] &lt;- &quot;darkgreen&quot; </span><br><span class="line">dotchart(x$mpg,  </span><br><span class="line">          labels &#x3D; row.names(x),  </span><br><span class="line">          cex&#x3D;.7, </span><br><span class="line">          groups &#x3D; x$cyl, </span><br><span class="line">          gcolor &#x3D; &quot;black&quot;, </span><br><span class="line">          color &#x3D; x$color,  </span><br><span class="line">          pch&#x3D;19, </span><br><span class="line">          main &#x3D; &quot;Gas Mileage for Car Models\ngrouped by cylinder&quot;, </span><br><span class="line">          xlab &#x3D; &quot;Miles Per Gallon&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-a5be3049f4c902914b18bd17b810f9ee_720w.jpg" alt="img"></p>
<h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>本次的R语言语法精讲（二）主要介绍了 R语言的数据的输入输出以及R语言内置的绘图语法。学完本文后，您将可以具备初步的R语言数据可视化的基本能力并结合R语言语法精讲（一）做简单的数据分析项目以及报告。</p>
<blockquote>
<p>本文转载自知乎：<a href="https://zhuanlan.zhihu.com/p/180425068" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/180425068</a></p>
</blockquote>
]]></content>
      <categories>
        <category>R</category>
      </categories>
  </entry>
  <entry>
    <title>R语言实战（一）</title>
    <url>/posts/6ac65c89.html</url>
    <content><![CDATA[<p>R是用于统计分析、绘图的语言和操作环境。R是属于GNU系统的一个自由、免费、源代码开放的软件，它是一个用于统计计算和统计制图的优秀工具。在学习R数据科学之前，我们首先要对R语言的基础语法有一个良好的了解，方便我们理解以后的数据科学算法。<strong>本次语法精讲分三次讲完，每次负责讲解其中一部分！本次的R语言语法精讲（一）主要介绍了 R语言的数据结构，R语言的运算以及R语言的编程结构。学完本文后，您将可以具备初步的R语言编程技巧，并能编写大部分程序以及算法。</strong></p>
<p><strong>本文引用：</strong></p>
<blockquote>
<p><strong>《R语言实战—第2版》————-Robert I.Kabacoff</strong><br><strong>《统计计算与模拟》课程课件———-深圳大学林炳清老师</strong></p>
</blockquote>
<p>本文内容：</p>
<ul>
<li>R常用数据结构（本文）</li>
<li>R的运算以及常用函数（本文）</li>
<li>R语言编程结构（本文）<br>判断if-else（本文）<br>循环for、while、repeat（本文）<br>自定义函数（本文）</li>
<li>R的输入与输出</li>
<li>R基础绘图</li>
<li>基本数据管理</li>
<li>高级数据管理</li>
</ul>
<h2 id="1-R常用数据结构"><a href="#1-R常用数据结构" class="headerlink" title="1. R常用数据结构"></a>1. R常用数据结构</h2><p>R拥有许多用于存储数据的对象类型，包括标量、向量、矩阵、数组、数据框和列表。它们在存储数据的类型、创建方式、结构复杂度，以及用于定位和访问其中个别元素的标记等方面均有所不同。</p>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-b5d1b28ef8d8b558f8902dcb90450a08_720w.jpg" alt="img"></p>
<h2 id="1-1-向量-Vector"><a href="#1-1-向量-Vector" class="headerlink" title="1.1 向量(Vector)"></a>1.1 向量(Vector)</h2><p>我们可以把vector想象:vector是一串糖葫芦，把山楂都串在一起。vector包含的是一串数据，要求这一串的数据类型是一样的。在R中，常见的数据类型有3种:</p>
<ul>
<li>numeric (数值型, Ex, 1, 3.14, -2。在R中，我们可以不区分整数型，浮点型，双精度型等)</li>
<li>character (字符型, Ex, “a”, “hello world”)</li>
<li>logical (布尔型, Ex, “TRUE” and “FALSE”)</li>
</ul>
<p><strong>(1) 创建向量：</strong></p>
<p>我们可以使用 c() 创造一个vector, c是英文单词cancatenate的缩写，意思是连结，连锁。所以c()可以把括号里的数字或者其他的数据类型的元素串成一个vector. 例如:(&lt;-代表R语言中的赋值符号，绝大多数也可以用=代替；相当于python的“=”)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a &lt;- c(1, 2, 5, 3, 6, -2, 4) </span><br><span class="line">a</span><br><span class="line">b &lt;- c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;) </span><br><span class="line">b</span><br><span class="line">c &lt;- c(TRUE, TRUE, TRUE, FALSE, TRUE, FALSE)</span><br><span class="line">c</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-6b9204ed8835961830ea09a23fac8335_720w.jpg" alt="img"></p>
<p>这里，a是数值型向量，b是字符型向量，而c是逻辑型向量。 注意，单个向量中的数据必须拥有相同的类型或模式（数值型、字符型或逻辑型） 。同一向量中无法混杂不同模式的数据。</p>
<p><strong>(2) 向量vector的索引</strong></p>
<p>vector索引指的是R会给vector的每个元素一个位置坐标。R的位置坐标从1开始，从左到右依次给予vector的每个元素。例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a &lt;- c(&quot;k&quot;, &quot;j&quot;, &quot;h&quot;, &quot;a&quot;, &quot;c&quot;, &quot;m&quot;) </span><br><span class="line">a[3]</span><br><span class="line">a[c(1, 3, 5)] </span><br><span class="line">a[2:6]</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-f00d843889afd15b73b30096302b8d49_720w.jpg" alt="img"></p>
<p>此外，我们还可以很方便的输出vector除去某些位置的对应元素后的vector, 例如:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x  &lt;- c(1, 3, 6, 4)</span><br><span class="line">x[-c(3, 4)]</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-24b9ed7c9bb4b00b233ef51a02f86b28_720w.jpg" alt="img"></p>
<p>我们还可以用names()函数给vector的每一个元素赋予一个名字，例如:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">score &lt;- c(98, 100, 60, 20)                      # score 表示一次考试的成绩</span><br><span class="line">names(score) &lt;- c(&quot;Lin&quot;, &quot;Wang&quot;, &quot;Chen&quot;, &quot;Sun&quot;)  # score 每一个成绩对应的人名</span><br><span class="line">score</span><br><span class="line">score[2]</span><br><span class="line">score[&quot;Wang&quot;]   # 可以通过vector元素的名字得到第二个同学的成绩</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-6e0841e936aabd78245c760ea867afcd_720w.jpg" alt="img"></p>
<p><strong>(3) 产生常用vector的方法：:, seq(), rep()</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1:50</span><br><span class="line">6:2</span><br><span class="line">-5:-10</span><br><span class="line">seq(from &#x3D; 3, to &#x3D; 10)</span><br><span class="line">seq(from &#x3D; 1, to &#x3D; 10, by &#x3D; 2)   # seq()可以自定义递增或者递减的步长</span><br><span class="line">rep(10, 5)    # 产生一个vector, 该vector包含5个10</span><br><span class="line">rep(c(2:4), 3) # 产生一个vector, 该vecotr包含3个 &#96;c(2:4)&#96;</span><br><span class="line">rep(&quot;I Love R!&quot;, 3)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-22ced1d4aa66c80b6d3c4047e6f53d69_720w.jpg" alt="img"></p>
<h2 id="1-2-矩阵matrix"><a href="#1-2-矩阵matrix" class="headerlink" title="1.2 矩阵matrix"></a>1.2 矩阵matrix</h2><p>矩阵是一个二维数组，只是每个元素都拥有相同的模式（数值型、字符型或逻辑型）。可通过函数matrix()创建矩阵。一般使用格式为：</p>
<p>myymatrix &lt;- matrix(vector, nrow=number_of_rows, ncol=number_of_columns,byrow=logical_value, dimnames=list(char_vector_rownames, char_vector_colnames))</p>
<p>其中vector包含了矩阵的元素，nrow和ncol用以指定行和列的维数，dimnames包含了可选的、以字符型向量表示的行名和列名。选项byrow则表明矩阵应当按行填充（byrow=TRUE）还是按列填充（byrow=FALSE） ，默认情况下按列填充。代码清单2-1中的代码演示了matrix函数的用法。</p>
<p><strong>(1) 创建矩阵</strong></p>
<p>我们首先创建了一个5×4的矩阵, 接着创建了一个2×2的含列名标签的矩阵， 并按行进行填 充,最后创建了一个2×2的矩阵并按列进行了填充。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">y &lt;- matrix(1:20, nrow&#x3D;5, ncol&#x3D;4)  # 创建一个5×4的矩阵</span><br><span class="line">y</span><br><span class="line">cells    &lt;- c(1,26,24,68)</span><br><span class="line">rnames   &lt;- c(&quot;R1&quot;, &quot;R2&quot;)</span><br><span class="line">cnames   &lt;- c(&quot;C1&quot;, &quot;C2&quot;)</span><br><span class="line">mymatrix &lt;- matrix(cells, nrow&#x3D;2, ncol&#x3D;2, byrow&#x3D;TRUE,    # 按行填充的2×2矩阵 </span><br><span class="line">                     dimnames&#x3D;list(rnames, cnames)) </span><br><span class="line">mymatrix</span><br><span class="line">mymatrix &lt;- matrix(cells, nrow&#x3D;2, ncol&#x3D;2, byrow&#x3D;FALSE,  # 按列填充的2×2矩阵 </span><br><span class="line">                     dimnames&#x3D;list(rnames, cnames))</span><br><span class="line">mymatrix</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-6122695124438c5200681555cf2e9ab4_720w.jpg" alt="img"></p>
<p><strong>(2) 矩阵的索引</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x &lt;- matrix(1:10, nrow&#x3D;2)</span><br><span class="line">x</span><br><span class="line">x[2,]</span><br><span class="line">x[,2]</span><br><span class="line">x[1,4]</span><br><span class="line">x[1, c(4,5)]</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-1b95d74739867a21d1add7623521d206_720w.jpg" alt="img"></p>
<p><strong>(3) 删除矩阵的某些行，列</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x &lt;- c(3, 1, 5, 2, 3, 8, 5, 8, 9, 4, 2, 3)</span><br><span class="line">x &lt;- matrix(x, nrow &#x3D; 3, ncol &#x3D; 4, byrow &#x3D; T)</span><br><span class="line">x</span><br><span class="line">y &lt;- x[-2, ]</span><br><span class="line">y</span><br><span class="line">z &lt;- x[, -c(2:3)]</span><br><span class="line">z</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-ea29a588644bec8058226764adfd87f8_720w.jpg" alt="img"></p>
<p><strong>(4) 添加一行或一列：cbind或者rbind合并两个矩阵</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">y &lt;- cbind(x, c(3, 4, 5))    # 添加一列c(3,4,5)到x矩阵最后</span><br><span class="line">y</span><br><span class="line">z &lt;- rbind(c(7, 8, 9, 10), x)  # 添加X到c(7,8,9,10)的行上</span><br><span class="line">z</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-1c848c74ec42d1282a30dd57449b8b8a_720w.jpg" alt="img"></p>
<p><strong>(5) 给matrix的行和列加上名字</strong></p>
<p>rownames()和colnames()给matrix的行和列添加或者修改名字:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x &lt;- c(3, 1, 5, 2, 3, 8, 5, 8, 9, 4, 2, 3)</span><br><span class="line">x &lt;- matrix(x, nrow &#x3D; 3, ncol &#x3D; 4, byrow &#x3D; T)</span><br><span class="line">x</span><br><span class="line">rownames(x) &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)   # 添加行名</span><br><span class="line">colnames(x) &lt;- c(&quot;w&quot;, &quot;x&quot;, &quot;y&quot;, &quot;z&quot;)  # 添加列名</span><br><span class="line">x</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-34f79eaa1b005662c967756b6fc8f1b9_720w.jpg" alt="img"></p>
<h2 id="1-3-数组"><a href="#1-3-数组" class="headerlink" title="1.3 数组"></a>1.3 数组</h2><p>数组（array）与矩阵类似，但是维度可以大于2。数组可通过array函数创建，形式如下：</p>
<p>myarray &lt;- array(vector, dimensions, dimnames)</p>
<p>其中vector包含了数组中的数据， dimensions是一个数值型向量， 给出了各个维度下标的最大值，而dimnames是可选的、各维度名称标签的列表。</p>
<p><strong>(1) 数组的创建</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dim1 &lt;- c(&quot;A1&quot;, &quot;A2&quot;)</span><br><span class="line">dim2 &lt;- c(&quot;B1&quot;, &quot;B2&quot;, &quot;B3&quot;) </span><br><span class="line">dim3 &lt;- c(&quot;C1&quot;, &quot;C2&quot;, &quot;C3&quot;, &quot;C4&quot;) </span><br><span class="line">z &lt;- array(1:24, c(2, 3, 4), dimnames&#x3D;list(dim1, dim2, dim3))</span><br><span class="line">z</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-69fbf822be8bf6bc83805650b80b6651_720w.jpg" alt="img"></p>
<p>如你所见，数组是矩阵的一个自然推广。它们在编写新的统计方法时可能很有用。像矩阵一样，数组中的数据也只能拥有一种模式。</p>
<p><strong>(2) 数组的索引</strong></p>
<p>从数组中选取元素的方式与矩阵相同。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">z[1,2,3]</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-802bdd6e4bd921e2b3e2a9ba9e91593b_720w.jpg" alt="img"></p>
<h2 id="1-4-数据框-dataframe"><a href="#1-4-数据框-dataframe" class="headerlink" title="1.4 数据框 dataframe"></a>1.4 数据框 dataframe</h2><p>data frame可以看成是一个excel表格。dataframe是数据分析中非常常用的一种储存数据的方式。dataframe也是一个2维的表格，和matrix一样不一样的地方是data frame的每一列的数据类型可以不一样，但是要求每一列内部数据类型是一样的。数据框可通过函数data.frame()创建：</p>
<p>mydata &lt;- data.frame(col1, col2, col3,…)</p>
<p>其中的列向量col1、col2、col3等可为任何类型（如字符型、数值型或逻辑型） 。每一列的名称可由函数names指定。</p>
<p><strong>(1) 数据框的创建</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">patientID &lt;- c(1, 2, 3, 4)</span><br><span class="line">age &lt;- c(25, 34, 28, 52)</span><br><span class="line">diabetes &lt;- c(&quot;Type1&quot;, &quot;Type2&quot;, &quot;Type1&quot;, &quot;Type1&quot;) </span><br><span class="line">status &lt;- c(&quot;Poor&quot;, &quot;Improved&quot;, &quot;Excellent&quot;, &quot;Poor&quot;) </span><br><span class="line">patientdata &lt;- data.frame(patientID, age, diabetes, status) </span><br><span class="line">patientdata</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-467781882029c8229e48da9da98044f8_720w.jpg" alt="img"></p>
<p>每一列数据的模式必须唯一，不过你却可以将多个模式的不同列放到一起组成数据框。由于数据框与分析人员通常设想的数据集的形态较为接近，我们在讨论数据框时将交替使用术语 <strong>列</strong>和 <strong>变量</strong>。</p>
<p>如果想指定index，那么：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">patientdata &lt;- data.frame(patientID, age, diabetes, </span><br><span class="line">                          status, row.names&#x3D;patientID) </span><br><span class="line">patientdata</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-cd57fdd4f0f5ce97ed22453f09fc22c2_720w.jpg" alt="img"></p>
<p><strong>(2) 数据框的索引</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">patientdata &lt;- data.frame(patientID, age, diabetes, status) </span><br><span class="line">patientdata  </span><br><span class="line">patientdata[1:2]</span><br><span class="line">patientdata[c(&quot;diabetes&quot;, &quot;status&quot;)] </span><br><span class="line">patientdata$age   # 表示patientdata数据框中的变量age</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-c73d3d4612ecfc78e802b0cd90e31ec0_720w.jpg" alt="img"></p>
<p><strong>(3) 粘结两个dataframe:用cbind和’rbind’结合两个data frame.</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x &lt;- data.frame(Name &#x3D; c(&quot;Jone&quot;,&quot;Lily&quot;), Grade &#x3D; c(80,90))</span><br><span class="line">x</span><br><span class="line">x &lt;- cbind(x, data.frame(Asia &#x3D; c(F, F)) )</span><br><span class="line">x</span><br><span class="line">x &lt;- rbind(x, data.frame(Name &#x3D; &quot;Wang&quot;, Grade &#x3D; 100, Asia &#x3D; T))</span><br><span class="line">x</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-00ee92fb4f896eda540ac617e49abe3f_720w.jpg" alt="img"></p>
<h2 id="1-5-因子factor"><a href="#1-5-因子factor" class="headerlink" title="1.5 因子factor"></a>1.5 因子factor</h2><p>如你所见，变量可归结为名义型、有序型或连续型变量。名义型变量是没有顺序之分的类别变量。糖尿病类型Diabetes（Type1、Type2）是名义型变量的一例。即使在数据中Type1编码为1而Type2编码为2，这也并不意味着二者是有序的。有序型变量表示一种顺序关系，而非数量关系。病情Status（poor、improved、excellent）是顺序型变量的一个上佳示例。我们明白，病情为poor（较差）病人的状态不如improved（病情好转）的病人，但并不知道相差多少。连续型变量可以呈现为某个范围内的任意值，并同时表示了顺序和数量。年龄Age就是一个连续型变量，它能够表示像14.5或22.8这样的值以及其间的其他任意值。很清楚，15岁的人比14岁的人年长一岁。</p>
<p>类别（名义型）变量和有序类别（有序型）变量在R中称为因子（factor） 。因子在R中非常重要，因为它决定了数据的分析方式以及如何进行视觉呈现。</p>
<p>函数factor()以一个整数向量的形式存储类别值，整数的取值范围是[1…k]（其中k是名义型变量中唯一值的个数），同时一个由字符串（原始值）组成的内部向量将映射到这些整数上。要表示有序型变量，需要为函数factor()指定参数ordered=TRUE。通过指定levels选项来覆盖默认排序。</p>
<p><strong>(1) 因子类型的使用</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">patientID &lt;- c(1, 2, 3, 4)</span><br><span class="line">age &lt;- c(25, 34, 28, 52)</span><br><span class="line">diabetes &lt;- c(&quot;Type1&quot;, &quot;Type2&quot;, &quot;Type1&quot;, &quot;Type1&quot;) </span><br><span class="line">status &lt;- c(&quot;Poor&quot;, &quot;Improved&quot;, &quot;Excellent&quot;, &quot;Poor&quot;)</span><br><span class="line">diabetes &lt;- factor(diabetes)</span><br><span class="line">status &lt;- factor(status, order&#x3D;TRUE)    # 有序型变量</span><br><span class="line">patientdata &lt;- data.frame(patientID, age, diabetes, status) </span><br><span class="line">str(patientdata)</span><br><span class="line">summary(patientdata)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-a5d67716b7bab9244f0b96a97900a70e_720w.jpg" alt="img"></p>
<h2 id="1-6-列表"><a href="#1-6-列表" class="headerlink" title="1.6 列表"></a>1.6 列表</h2><p>列表（list）是R的数据类型中最为复杂的一种。一般来说，列表就是一些对象（或成分，component）的有序集合。列表允许你整合若干（可能无关的）对象到单个对象名下。例如，某个列表中可能是若干向量、矩阵、数据框，甚至其他列表的组合。</p>
<p>可以使用函数list()创建列表：</p>
<p>mylist &lt;- list(object1, object2, …)</p>
<p>其中的对象可以是目前为止讲到的任何结构。</p>
<p>你还可以为列表中的对象命名：</p>
<p>mylist &lt;- list(name1=object1, name2=object2, …)</p>
<p><strong>(1) 列表的创建</strong></p>
<p>本例创建了一个列表，其中有四个成分：一个字符串、一个数值型向量、一个矩阵及一个字符型向量。可以组合任意多的对象，并将它们保存为一个列表。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">g &lt;- &quot;My First List&quot; </span><br><span class="line">h &lt;- c(25, 26, 18, 39) </span><br><span class="line">j &lt;- matrix(1:10, nrow&#x3D;5)</span><br><span class="line">k &lt;- c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;)</span><br><span class="line">mylist &lt;- list(title&#x3D;g, ages&#x3D;h, j, k)</span><br><span class="line">mylist</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-9513912f779da1b962d76039fce6cec2_720w.jpg" alt="img"></p>
<p>(2) 列表的索引</p>
<p>可以通过在<strong>双重方括号</strong>中指明代表某个成分的数字或名称来访问列表中的元素。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mylist[[2]] </span><br><span class="line">mylist[[&quot;ages&quot;]]</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-bd358c6480c81a64f99d0ad9c7024363_720w.jpg" alt="img"></p>
<h2 id="2-R的运算以及常用函数"><a href="#2-R的运算以及常用函数" class="headerlink" title="2.R的运算以及常用函数"></a>2.R的运算以及常用函数</h2><h2 id="2-1-R的四则运算法则"><a href="#2-1-R的四则运算法则" class="headerlink" title="2.1 R的四则运算法则"></a>2.1 R的四则运算法则</h2><p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-40ecb2fcb241129858e90118614faf0d_720w.jpg" alt="img"></p>
<p>R数字的四则运算+,-,*,/和算数中的四则运算时一致的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2 + 3</span><br><span class="line">2 - 3</span><br><span class="line">2 * 3</span><br><span class="line">2 &#x2F; 3</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-0bbc581c484b9173aebb09cff68174cc_720w.jpg" alt="img"></p>
<p>我们需要注意R的vector和matrix的运算。<strong>在R中，vector和matrix的+,-,*,/ 指的是相同位置元素之间的 +,-,*,/。</strong></p>
<p><strong>(1) 向量的四则运算法则：</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x &lt;- c(1, 2, 3)</span><br><span class="line">y &lt;- c(4, 5, 6)</span><br><span class="line">x + y</span><br><span class="line">x - y </span><br><span class="line">x * y</span><br><span class="line">x &#x2F; y</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-d9ed0976a02a9af0ca8f2400b0d9714a_720w.jpg" alt="img"></p>
<p><strong>(2) 矩阵的四则运算法则：</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x &lt;- matrix(1:6, nrow &#x3D; 3, ncol &#x3D; 2)</span><br><span class="line">y &lt;- matrix(3:8, nrow &#x3D; 3, ncol &#x3D; 2)</span><br><span class="line">x+y</span><br><span class="line">x-y</span><br><span class="line">x*y</span><br><span class="line">x&#x2F;y</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-2fc21f9fde002bf05280a79f5bcc70ae_720w.jpg" alt="img"></p>
<p><strong>(3) 矩阵与矩阵的乘法：</strong></p>
<p>矩阵相乘的函数是%<em>%,同样的，我们要求<em>*第1个矩阵的列数（column）和第2个矩阵的行数（row）相同</em></em> 。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x &lt;- matrix(1:6, nrow &#x3D; 2, byrow &#x3D; T)</span><br><span class="line">y &lt;- matrix(7:12, nrow &#x3D; 3, byrow &#x3D; T)</span><br><span class="line">x %*% y</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-4300e0a0fb66d11f40cacc2da9e04efb_720w.jpg" alt="img"></p>
<p>矩阵乘法中，需要注意，当矩阵和向量相乘时，把向量当成一个列数为1的矩阵即可。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x &lt;- matrix(1:6, nrow &#x3D; 2, byrow &#x3D; T)</span><br><span class="line">x %*% c(1, 2, 3)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-8d6da7080bcdf8d0dd40bc8312c6eb77_720w.jpg" alt="img"></p>
<p><strong>(4) 矩阵的转置：t()</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x &lt;- matrix(1:6, nrow &#x3D; 2)</span><br><span class="line">t(x)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-e1dbe144176ff828983b5d425cf8613b_720w.jpg" alt="img"></p>
<h2 id="2-2-R的逻辑运算"><a href="#2-2-R的逻辑运算" class="headerlink" title="2.2 R的逻辑运算"></a>2.2 R的逻辑运算</h2><p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-bac902d5c38a5f797940213a3dc61a6b_720w.jpg" alt="img"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">manager &lt;- c(1, 2, 3, 4, 5) </span><br><span class="line">date &lt;- c(&quot;10&#x2F;24&#x2F;08&quot;, &quot;10&#x2F;28&#x2F;08&quot;, &quot;10&#x2F;1&#x2F;08&quot;, &quot;10&#x2F;12&#x2F;08&quot;, &quot;5&#x2F;1&#x2F;09&quot;) </span><br><span class="line">country &lt;- c(&quot;US&quot;, &quot;US&quot;, &quot;UK&quot;, &quot;UK&quot;, &quot;UK&quot;) </span><br><span class="line">gender &lt;- c(&quot;M&quot;, &quot;F&quot;, &quot;F&quot;, &quot;M&quot;, &quot;F&quot;) </span><br><span class="line">age &lt;- c(32, 45, 25, 39, 99) </span><br><span class="line">q1 &lt;- c(5, 3, 3, 3, 2) </span><br><span class="line">q2 &lt;- c(4, 5, 5, 3, 2) </span><br><span class="line">q3 &lt;- c(5, 2, 5, 4, 1) </span><br><span class="line"></span><br><span class="line">leadership &lt;- data.frame(manager, date, country, gender, age, </span><br><span class="line">                         q1, q2, q3, stringsAsFactors&#x3D;FALSE)</span><br><span class="line">leadership</span><br><span class="line">leadership$agecat[leadership$age  &gt; 75]  &lt;- &quot;Elder&quot; </span><br><span class="line">leadership$agecat[leadership$age &gt;&#x3D; 55 &amp;  </span><br><span class="line">                  leadership$age &lt;&#x3D; 75]  &lt;- &quot;Middle Aged&quot; </span><br><span class="line">leadership$agecat[leadership$age  &lt; 55]  &lt;- &quot;Young&quot;</span><br><span class="line">leadership</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-f52eb4f60eb78e7a506ad71f7d56c076_720w.jpg" alt="img"></p>
<h2 id="2-3-常用函数"><a href="#2-3-常用函数" class="headerlink" title="2.3 常用函数"></a>2.3 常用函数</h2><p>在探索数据的阶段，常常会先探索数据分布的一些统计量，如求和，均值，标准差，方差，中值，分位数等。对vector,R有函数可以直接得到这些统计量，sum()(求和), mean()(均值), sd()(标准差), var()(方差), median()(中值), quantile()(分位数)。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x &lt;- 1:10</span><br><span class="line">sum(x)</span><br><span class="line">mean(x)</span><br><span class="line">sd(x)</span><br><span class="line">var(x)</span><br><span class="line">median(x)</span><br><span class="line">quantile(x)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-a57737f669a0cc6c19fa42c7e0249685_720w.jpg" alt="img"></p>
<p>对matrix, R有函数rowMeans(), colMeans()可以得到每一行或者每一列的平均值(注意：M要大写哦)，而rowSums,colSums可以得到每一行或者每一列的和(注意：S要大写哦)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x &lt;- matrix(1:6, 3, 2)</span><br><span class="line">rowMeans(x)</span><br><span class="line">colMeans(x)</span><br><span class="line">rowSums(x)</span><br><span class="line">colSums(x)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-32dff95c5b3e1bd30bf431fb224038ec_720w.jpg" alt="img"></p>
<p>R的基本函数库里没有函数可以直接计算，方差，标准差等其他信息，我们可以用apply()函数。apply(X,MARGIN,FUN)的参数主要有3个，X通常是一个matrix， MARGIN通常的取值有两个，1或者2，1表示按照行计算，2表示按照列计算，FUN指的是一个函数。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x &lt;- matrix(1:6, 3, 2)</span><br><span class="line">apply(x, 1, sd)   # 计算x每一行的标准差</span><br><span class="line">apply(x, 2, quantile)   # 计算x每一列的分位数</span><br><span class="line">apply(x, 1, mean)     # 计算x每一行的均值</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-702ab3afa11576a763d0b12b1a5ba21c_720w.jpg" alt="img"></p>
<p>函数length()可以输出vector的长度，dim()可以输出matrix的2个维度</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x &lt;- rep(2, 8)</span><br><span class="line">length(x)</span><br><span class="line">y &lt;- matrix(1:10, 5, 2)</span><br><span class="line">dim(y)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-1186ae6cebec35c438a24bac3dbe7f04_720w.jpg" alt="img"></p>
<p>函数rnorm()可以产生服从正态分布的随机数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x &lt;- rnorm(50)    # 产生50个服从标准正态分布的随机数</span><br><span class="line">x</span><br><span class="line">hist(x, breaks &#x3D; 10, cex.lab &#x3D; 1.5, cex.axis &#x3D; 1.5)</span><br><span class="line">abline(v &#x3D; 0, col &#x3D; &quot;red&quot;, lty &#x3D; 2, lwd &#x3D; 2)</span><br><span class="line">y &lt;- rnorm(50, mean &#x3D; 50, sd &#x3D; 0.2)   # 产生50个服从均值是50，标准差是0.2的正态分布随机数</span><br><span class="line">y</span><br><span class="line">hist(y, cex.lab &#x3D; 1.5, cex.axis &#x3D; 1.5)</span><br><span class="line">abline(v &#x3D; 50, col &#x3D; &quot;red&quot;, lty &#x3D; 2, lwd &#x3D; 2)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-ad0afd65df89391a33613dbe7eafb6bf_720w.jpg" alt="img"></p>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-ce08f486ed3827df2976fd6d9f68f8a1_720w.jpg" alt="img"></p>
<p>有时候我们需要重复我们的计算或者实验，这时我们需要用到set.seed()函数固定一个产生随机数的种子。下面的形式可以保证我们每次运行产生一样的随机数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set.seed(123)</span><br><span class="line">rnorm(5)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-dc9425b67bdd6a18b1f6aedc8faef318_720w.jpg" alt="img"></p>
<p>函数cor()可以计算两个vector的相关关系</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x &lt;- rnorm(100)</span><br><span class="line">y &lt;- x + rnorm(100, 0, 0.2)</span><br><span class="line">cor(x, y)</span><br><span class="line">plot(x, y, col &#x3D; &quot;blue&quot;, pch &#x3D; 20, cex.lab &#x3D; 1.5, cex.axis &#x3D; 1.5)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-283e72023b5081b8e5c22b69141d40e2_720w.jpg" alt="img"></p>
<p>函数summary()可以得到matrix或者data frame的每一列的基本信息，包括最大值，最小值，中间值，25%和75%分位数，均值。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x &lt;- matrix(rnorm(100*3), 100, 3)</span><br><span class="line">summary(x)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-f81c30bc5f05b8a53548ebb143e4e164_720w.jpg" alt="img"></p>
<h2 id="3-R语言编程结构"><a href="#3-R语言编程结构" class="headerlink" title="3.R语言编程结构"></a>3.R语言编程结构</h2><h2 id="3-1-if-else语句"><a href="#3-1-if-else语句" class="headerlink" title="3.1 if-else语句"></a>3.1 if-else语句</h2><p>(1) 在R中，if-else语句的形式通常如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a &lt;- 3</span><br><span class="line">if (a &#x3D;&#x3D; 4) &#123;</span><br><span class="line">  x &lt;- 2</span><br><span class="line">  y &lt;- 3</span><br><span class="line">&#125; else &#123;</span><br><span class="line">  x &lt;- 3</span><br><span class="line">  y &lt;- 4</span><br><span class="line">&#125;</span><br><span class="line">x</span><br><span class="line">y</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-84e7f286a35c45a6760914db5e7f8326_720w.jpg" alt="img"></p>
<p>需要根据不同条件执行不同代码时，使用函数if(), 在括号里写入判断的语句，在上面的例子中，我们根据a == 4是TRUE, 还是FALSE执行不同的语句。</p>
<p>如果a=4, 那么a == 4是TRUE, 执行if()后面大括号{ }内的代码；</p>
<p>如果a!=4, 那么a == 4是FALSE, 执行else后面大括号{ }内的代码。</p>
<p>(2) if()也可以单独使用，例如:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if (a &#x3D;&#x3D; 4) &#123;</span><br><span class="line">  x &lt;- 2</span><br><span class="line">  y &lt;- 3</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-d9d319628748ddb0117a04716d1601f6_720w.jpg" alt="img"></p>
<p>(3) 多个if-else可以一起使用，例如:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if (a &#x3D;&#x3D; 4) &#123;</span><br><span class="line">  x &lt;- 2</span><br><span class="line">  y &lt;- 3</span><br><span class="line">&#125; else if (a &#x3D;&#x3D; 5)&#123;</span><br><span class="line">  x &lt;- 3</span><br><span class="line">  y &lt;- 4</span><br><span class="line">&#125; else &#123;</span><br><span class="line">  x &lt;- 5</span><br><span class="line">  y &lt;- 6</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>(4) if-else还可以有如下的使用方式:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># v &#x3D; if(cond) expression1 else expression2 # v可能取expression1或者expression2的结果，这取决于cond是否为真。</span><br><span class="line">x &#x3D; 2</span><br><span class="line">y &#x3D; if(x&#x3D;&#x3D;2) x else x+1</span><br><span class="line">y</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-fe6a07d6a553659460e31a3035669e81_720w.jpg" alt="img"></p>
<h2 id="3-2-循环"><a href="#3-2-循环" class="headerlink" title="3.2 循环"></a>3.2 循环</h2><p><strong>(1) For循环</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 我们如果要计算1到10的平均值</span><br><span class="line">s &lt;- 0</span><br><span class="line">for (i in 1:10) &#123;</span><br><span class="line">  s &lt;- s + i</span><br><span class="line">&#125;</span><br><span class="line">s &#x2F; 10</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-e374f1aa259824fc0d65487b95b9bc43_720w.jpg" alt="img"></p>
<p><strong>(2) while循环(一)</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">s &lt;- 0</span><br><span class="line">i &lt;- 1</span><br><span class="line">while(i&lt;&#x3D;10) &#123;</span><br><span class="line">  s &lt;- s + i</span><br><span class="line">  i &lt;- i + 1</span><br><span class="line">&#125;</span><br><span class="line">s &#x2F; 10</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-56499369f4dd0d99fa30aba9ab11383f_720w.jpg" alt="img"></p>
<p><strong>(3) while循环(二)</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">s &lt;- 0</span><br><span class="line">i &lt;- 1</span><br><span class="line">while(TRUE) &#123;</span><br><span class="line">  s &lt;- s + i</span><br><span class="line">  i &lt;- i + 1</span><br><span class="line">  if(i &gt; 10) break</span><br><span class="line">  </span><br><span class="line">&#125;</span><br><span class="line">s &#x2F; 10</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-64d51fb9b5842b92e39e18e1ad7f0c88_720w.jpg" alt="img"></p>
<p><strong>(4) repeat循环</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">s &lt;- 0</span><br><span class="line">i &lt;- 1</span><br><span class="line">repeat &#123;</span><br><span class="line">  s &lt;- s + i</span><br><span class="line">  i &lt;- i + 1</span><br><span class="line">  if(i &gt; 10) break</span><br><span class="line">  </span><br><span class="line">&#125;</span><br><span class="line">s &#x2F; 10</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-7b40d56a9a335187b2c2a55fb07ad2a1_720w.jpg" alt="img"></p>
<h2 id="3-3-自定义R函数"><a href="#3-3-自定义R函数" class="headerlink" title="3.3 自定义R函数"></a>3.3 自定义R函数</h2><p>在R中，函数可以通过如下形式定义：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 自定义函数求一个向量中所有偶数的和</span><br><span class="line">sumEvenNum &#x3D; function(v)&#123;</span><br><span class="line">  even_num &#x3D; v[(v %% 2)&#x3D;&#x3D;0]</span><br><span class="line">  sum_even_num  &#x3D; sum(even_num)</span><br><span class="line">  return(sum_even_num)</span><br><span class="line">&#125;</span><br><span class="line">x &#x3D; 1:10</span><br><span class="line">sumEvenNum(x)</span><br></pre></td></tr></table></figure>
<p><img src="/Pic/R%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/v2-562fad8f8149b8c5c4935e6fdbcabd44_720w.jpg" alt="img"></p>
<p>赋值号(=或者&lt;-)左边是自定义函数的函数名</p>
<p>赋值号右边是定义函数的函数function()</p>
<p>函数function()括号内是我们要传到自定义函数的参数</p>
<p>大括号内写函数的代码</p>
<p>最后使用函数return()返回结果</p>
<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>本次的R语言语法精讲（一）主要介绍了 R语言的数据结构，R语言的运算以及R语言的编程结构。学完本文后，您将可以具备初步的R语言编程技巧，并能编写大部分程序以及算法。</p>
<blockquote>
<p>本文转载自知乎：<a href="https://zhuanlan.zhihu.com/p/180119895" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/180119895</a></p>
</blockquote>
]]></content>
      <categories>
        <category>R</category>
      </categories>
  </entry>
  <entry>
    <title>Python爬虫初级（十五）—— Scrapy爬虫实践（更新中）</title>
    <url>/posts/b0f5da86.html</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>Spider</category>
      </categories>
  </entry>
  <entry>
    <title>Python爬虫初级（十四）—— Scrapy爬虫基础</title>
    <url>/posts/cd76fad2.html</url>
    <content><![CDATA[<p>Scrapy库不是一个简单的函数，而是一个爬虫框架。爬虫框架就是实现爬虫功能的一个软件结构和功能组件集合爬虫框架就是一个半成品，能够帮助用户实现专业网络爬虫。</p>
<h1 id="Scrapy爬虫框架结构"><a href="#Scrapy爬虫框架结构" class="headerlink" title="Scrapy爬虫框架结构"></a>Scrapy爬虫框架结构</h1><p><strong>“5+2”结构</strong>：</p>
<ul>
<li>Engine模块</li>
<li>Spider模块</li>
<li>Downloader模块</li>
<li>ItemPipelines模块</li>
<li>Scheduler模块</li>
</ul>
<p>下图为嵩天教授讲授爬虫课程时的Scrapy框架图截图：</p>
<p><img src="/posts/Spider/Scrapy_Engine.jpg" alt></p>
<p>另外在Engine和Spider模块之间，以及Engine和Downloader模块之间包含了两个MiddleWare模块这个结构就称为Scrapy爬虫框架。在Scrapy框架中，数据包括用户提交的网络爬虫请求，以及从网络上提取地相关内容，在这些结构之间进行流动，形成数据流。</p>
<p>Scrapy框架主要包含<strong>三条主要的数据流路径</strong>：</p>
<ul>
<li><p>第一条从Spiders经过Engine到达Scheduler，Engine从Spiders处获得用户的请求（Requests），可以简单地认为是一个URL，请求到达Engine后，Engine将其分配给Scheduler模块，而Scheduler模块负责对爬取请求进行调度。</p>
</li>
<li><p>Scrapy的第二条数据流路径是从Scheduler模块通过Engine模块到达Downloader模块，并且最终返回Spider模块。首先Engine模块从Scheduler模块获取下一个要爬取的网络请求，这一个网络请求是真实的要到网络上进行爬取的请求，Engine获得这个请求后通过中间键发送给Downloader模块，Downloader模块和获取请求之后真实地连接互联网并且爬取相关网页，爬取到网页后Downloader模块形成响应（Response），将所有内容封装为Response后打包通过Engine中间键发送给Spiders。在这条路径中一个真实地爬取URL的请求经过Scheduler,Downloader最终返回了相关内容返回Spiders。</p>
</li>
<li><p>第三条数据流路径是从 Spiders模块经过Engine模块到达ItemPipelines模块以及Scheduler模块。首先Spiders处理从Downloader获得的响应（从网络中爬取的相关内容），得到两个数据类型，一个数据类型叫爬取项（Scrapy Item），另一个数据类型是新的爬取请求。也就是我们从网络上获得一个网页之后，如果网页中有我们感兴趣的链接，我们可以在Spiders中增加相关的功能，对新的链接发起再次的爬取。Spiders生成了这两个数据类型之后，将它们发送给Engine模块，Engine随后将Item发送给ItemPipelines，将Requests发送给Requests进行调度，从而为后期的数据处理以及再获取网络爬虫请求提供了相应的数据来源。</p>
</li>
</ul>
<p>在这条路径中，Engine控制着各个模块的数据流，并且它不断地从Scheduler获取真正要爬取的请求并发送给Downloader。这个框架的入口是Spiders，出口是ItemPipelines。在这个“5+2”结构中，Engine，Scheduler和Downloader都已有实现，用户不需要去编写他们，他们会按照既定的功能 完成相关的任务。用户需要编写的是Spiders模块和Item Pipelines模块，其中Spiders模块向整个Scrapy模块提供访问URL链接，同时解析从网络上获得的页面内容，ItemPipeline模块负责对提取的信息进行后处理。由于在这个框架下，用户只需要编写部分代码，因此这个过程也被称为配置，用户只需要在这个框架下进行简单的配置即可完成爬取需求。</p>
<p>Downloader Middleware目的是实施Engine、Scheduler、Downloader之间进行用户可配置的控制，功能是修改、丢弃、新增请求或响应。Spider Middleware目的是对请求和爬取项进行再处理，功能是修改、丢弃、新增请求或爬取项。</p>
<h1 id="Requests库和Scrapy爬虫的比较"><a href="#Requests库和Scrapy爬虫的比较" class="headerlink" title="Requests库和Scrapy爬虫的比较"></a>Requests库和Scrapy爬虫的比较</h1><p><strong>相同点</strong>：</p>
<ol>
<li>两者都可以进行页面请求和爬取，Python爬虫的两个重要技术路线</li>
<li>两者可用性都好，文档丰富，入门简单</li>
<li>两者都没有处理js、提交表单、用对验证码功能（可扩展）</li>
</ol>
<p><strong>不同点</strong>：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>requests</th>
<th>Scrapy</th>
</tr>
</thead>
<tbody>
<tr>
<td>页面级爬虫</td>
<td>网站级爬虫</td>
</tr>
<tr>
<td>功能库</td>
<td>框架</td>
</tr>
<tr>
<td>并发性考虑不足，性能较差</td>
<td>并发性好，性能较高</td>
</tr>
<tr>
<td>重点在于页面下载</td>
<td>重点在于爬虫结构</td>
</tr>
<tr>
<td>定制灵活</td>
<td>一般定制灵活，深度定制困难</td>
</tr>
<tr>
<td>上手简单</td>
<td>入门稍难</td>
</tr>
</tbody>
</table>
</div>
<p>具体选择：</p>
<ul>
<li>非常小的请求：Requests库</li>
<li>不太小的请求：Scrapy框架</li>
<li>定制成都很高的请求，自搭框架：Requests库</li>
</ul>
<h1 id="Scarpy爬虫的常用命令"><a href="#Scarpy爬虫的常用命令" class="headerlink" title="Scarpy爬虫的常用命令"></a>Scarpy爬虫的常用命令</h1><ul>
<li>Scrapy命令行的启用——直接在命令行输入：scrapy -h</li>
<li>命令格式：scarpy &lt;command&gt; [options] [args]，Scrapy的命令在command体现</li>
</ul>
<p>常用命令如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
<th>格式</th>
</tr>
</thead>
<tbody>
<tr>
<td>startproject</td>
<td>创建一个工程</td>
<td>scrapy startproject &lt;name&gt;[dir]</td>
</tr>
<tr>
<td>genspider</td>
<td>创建一个爬虫</td>
<td>scrapy genspider [options] &lt;name&gt;&lt;domain&gt;</td>
</tr>
<tr>
<td>settings</td>
<td>获得爬虫配置信息</td>
<td>scrapy settings [options]</td>
</tr>
<tr>
<td>crawl</td>
<td>运行一个爬虫</td>
<td>scrapy crawl &lt;spider&gt;</td>
</tr>
<tr>
<td>list</td>
<td>列出工程中所有爬虫</td>
<td>scrapy list</td>
</tr>
<tr>
<td>shell</td>
<td>启动URL调试命令行</td>
<td>scrapy shell [url]</td>
</tr>
</tbody>
</table>
</div>
<p><strong>为什么Scrapy采用命令行创建和运行爬虫？</strong></p>
<ul>
<li>命令行（不是图形界面）更容易自动化，适合脚本控制（只有用户才会关注图形界面）</li>
</ul>
<h1 id="Scrapy爬虫第一个实例"><a href="#Scrapy爬虫第一个实例" class="headerlink" title="Scrapy爬虫第一个实例"></a>Scrapy爬虫第一个实例</h1><p>首先我们有Scrapy爬虫的产生步骤：</p>
<ol>
<li>建立一个Scrapy爬虫工程</li>
<li>在工程中产生一个Scrapy爬虫</li>
<li>配置产生的spider爬虫</li>
<li>运行爬虫，获取网页</li>
</ol>
<h2 id="建立一个Scrapy爬虫工程"><a href="#建立一个Scrapy爬虫工程" class="headerlink" title="建立一个Scrapy爬虫工程"></a>建立一个Scrapy爬虫工程</h2><p>演示HTML页面地址：<a href="http://python123.io/ws/demo.html" target="_blank" rel="noopener">http://python123.io/ws/demo.html</a></p>
<p>文件名称：demo.html</p>
<p>我们建立工程的所有的操作如下：</p>
<p><img src="/posts/Spider/Scrapy_Start_1.png" alt></p>
<p><img src="/posts/Spider/Scrapy_Start_2.png" alt></p>
<p>我们可以看到整个文件的架构：</p>
<p><img src="/posts/Spider/Scrapy_Start.jpg" alt></p>
<p>在生成的工程目录spider/下，含有Spiders代码模板目录（继承类），内部含有两个文件：</p>
<p><img src="/posts/Spider/Scrapy_Start_3.png" alt></p>
<p>其中 __init__.py是初始文件，无需修改；而__pycache__是我们熟悉的缓存目录，也无需修改</p>
<h2 id="在工程中产生一个Scrapy爬虫"><a href="#在工程中产生一个Scrapy爬虫" class="headerlink" title="在工程中产生一个Scrapy爬虫"></a>在工程中产生一个Scrapy爬虫</h2><p>我们在工作目录下先输入scrapy genspider demo python123.io命令，然后将会在python123demo文件夹下的spiders文件夹中产生一个新的文件：demo.py，具体操作如下：</p>
<p><img src="/posts/Spider/Scrapy_Start_4.png" alt></p>
<p>这条命令的作用仅是生成demo.py，demo.py文件内容如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DemoSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'demo'</span></span><br><span class="line">    allowed_domains = [<span class="string">'python123.io'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://python123.io/'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>这个类函数DemoSpider必须是继承scrapy.Spider，name指的是这个爬虫的名字，allowed_domains是用户提交给命令行的域名，也就是爬虫在爬取网站时，只能爬取该域名下的链接，start_urls就是scrapy爬取框架爬取的初始页面。parse函数是解析页面的空的类的方法，用于处理响应，可以解析从网络中爬取内容，形成字典类型，同时从网页中发现新的要爬取的内容，生成url。</p>
<h2 id="配置产生的spider爬虫"><a href="#配置产生的spider爬虫" class="headerlink" title="配置产生的spider爬虫"></a>配置产生的spider爬虫</h2><p>我们对parse的要求是将返回的html存成文件，下面直接看这部分代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DemoSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'demo'</span></span><br><span class="line">    <span class="comment"># allowed_domains = ['python123.io']</span></span><br><span class="line">    start_urls = [<span class="string">'http://python123.io/ws/demo.html'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="comment"># 从响应的url中提取名字作为本地文件名</span></span><br><span class="line">        fname = response.url.split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line">        <span class="comment"># 将返回内容保存为文件</span></span><br><span class="line">        <span class="keyword">with</span> open(fname, <span class="string">"wb"</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(response.body)</span><br><span class="line">        self.log(<span class="string">"Saved file %s."</span> %name)</span><br></pre></td></tr></table></figure>
<h2 id="运行爬虫，获取网页"><a href="#运行爬虫，获取网页" class="headerlink" title="运行爬虫，获取网页"></a>运行爬虫，获取网页</h2><p>我们在命令行下执行crawl命令获取网页：</p>
<p><img src="/posts/Spider/Scrapy_Start_5.png" alt></p>
<p>捕获的文件存在python123demo路径下的demo.html文件中</p>
<p>事实上，官方给出的更标准的写法是下面这个：</p>
<p><img src="/posts/Spider/Scrapy_Start_6.png" alt></p>
<p>这里主要使用了yield，这个函数当返回的URL列表很大时，能够极大地节省存储空间，若有需要进一步了解yield的用法可自行看文档。</p>
<h1 id="Scrapy爬虫的使用步骤"><a href="#Scrapy爬虫的使用步骤" class="headerlink" title="Scrapy爬虫的使用步骤"></a>Scrapy爬虫的使用步骤</h1><p>下面我们对爬虫使用步骤做个总结：</p>
<ol>
<li>创建一个工程和Spider模板</li>
<li>编写Item Pipeline</li>
<li>编写Spider</li>
<li>优化策略配置</li>
</ol>
<p>Scrapy爬虫的数据类型有：</p>
<ol>
<li>Requests类</li>
<li>Response类</li>
<li>Item类</li>
</ol>
<p><strong>Request对象</strong>表示一个HTTP请求，由Spider生成，由Downloader执行。具体来说Request类包含六个属性方法：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>属性或方法</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>.url</td>
<td>Request对应的请求URL地址</td>
</tr>
<tr>
<td>.method</td>
<td>对应的请求方法，’GET’’POST’等</td>
</tr>
<tr>
<td>.headers</td>
<td>字典类型风格请求头</td>
</tr>
<tr>
<td>.body</td>
<td>请求内容主体，字符串类型</td>
</tr>
<tr>
<td>.meta</td>
<td>用户添加的扩展信息，在Scrapy内部模块间传递信息使用</td>
</tr>
<tr>
<td>.copy()</td>
<td>复制该请求</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Response对象</strong>表示一个HTTP响应，由Downloader生成，由Spider处理。包含了七个主要的属性和方法：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>属性或方法</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>.url</td>
<td>Response对应的响应URL地址</td>
</tr>
<tr>
<td>.status</td>
<td>HTTP状态码，默认是200</td>
</tr>
<tr>
<td>.headers</td>
<td>Response对应的头部信息</td>
</tr>
<tr>
<td>.body</td>
<td>Response对应的内容信息，字符串类型</td>
</tr>
<tr>
<td>.flags</td>
<td>一组标记</td>
</tr>
<tr>
<td>.request</td>
<td>产生Response类型对应的Request对象</td>
</tr>
<tr>
<td>.copy()</td>
<td>复制该响应</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Item对象</strong>表示一个从HTML页面中提取的信息内容，由Spider生成，由Item Pipeline处理。Item类似字典类型，可以按照字典类型操作</p>
<p><strong>Scrapy爬虫提取信息的方法</strong><br>Scrapy支持多种HTML信息提取的方法：Beautiful Soup，lxml，re，XPATH Selector，CSS Selector等</p>
]]></content>
      <categories>
        <category>Spider</category>
      </categories>
  </entry>
  <entry>
    <title>Python爬虫初级（十三）—— 水木社区论坛爬取实战</title>
    <url>/posts/e97854a0.html</url>
    <content><![CDATA[<h1 id="实战阶段一：分析首页大板块-URL"><a href="#实战阶段一：分析首页大板块-URL" class="headerlink" title="实战阶段一：分析首页大板块 URL"></a>实战阶段一：分析首页大板块 URL</h1><p>我们首先打开待爬取页面 —— 水木社区的首页：<a href="http://www.newsmth.net/nForum/#!mainpage，进入后页面如下：" target="_blank" rel="noopener">http://www.newsmth.net/nForum/#!mainpage，进入后页面如下：</a><br><img src="https://img-blog.csdnimg.cn/20200428102419709.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="水木社区板块">我们看到左边有很多讨论区板块，我们点进去试试：<br><img src="https://img-blog.csdnimg.cn/20200428102956475.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="休闲娱乐板块页面"><br>我们现在就已经点进去了休闲娱乐讨论区，在这个讨论区中我们可以看到最上面的链接：<a href="http://www.newsmth.net/nForum/#!section/2，那这个链接就很有灵魂了，我们很容易就能猜到只要我们修改不同的" target="_blank" rel="noopener">http://www.newsmth.net/nForum/#!section/2，那这个链接就很有灵魂了，我们很容易就能猜到只要我们修改不同的</a> section，我们就可以进入不同的讨论区，我们进入讨论区后可以看到有不同的板块：<br><img src="https://img-blog.csdnimg.cn/20200428110506257.png#pic_center" alt="在这里插入图片描述"></p>
<h1 id="实战阶段二：获取子板块-URL"><a href="#实战阶段二：获取子板块-URL" class="headerlink" title="实战阶段二：获取子板块 URL"></a>实战阶段二：获取子板块 URL</h1><p>我们希望获取到这些板块的链接和标题，但点进去之后发现这些板块并不像它的上一级打开一样有 section 给我们选择，它是一个个的板块名称的英文，有人或许会想我们可以直接把这些对应的名称输入字典翻译过来再输回来不就可以了吗，但事实上每一个英文单词可能有不同的表达，而且就算我们能够确定他们的表达，我们还得建一个字典爬虫，这多麻烦啊。<br>我们先试着查看一下这篇网页的 notwork，打开 network 再点击刷新，我们筛选 XML 类型的数据：<br><img src="https://img-blog.csdnimg.cn/20200428111143949.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="XML数据">事实上 XML 的数据并不多，我们只需要都看一看他们的响应值就可以找到这样一个汇总了所有条目信息的数据，我们点开这条 XML 的消息头：<br><img src="https://img-blog.csdnimg.cn/20200428111322899.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="消息头"><br>将对应的请求网址输入 POSTMAN 工具，点击 send 后得到对应的消息头：</p>
<p><img src="https://img-blog.csdnimg.cn/20200428111530817.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="POSTMAN"><br>点击最右侧的 code，此时它就会把我们所需的 headers 返回给我们：</p>
<p><img src="https://img-blog.csdnimg.cn/20200428111648269.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="Code"><br>我们直接复制 headers 部分，然后就按套路就能得到响应了（如果连套路都不会的话大家赶紧复习一下前面的内容：<a href="https://blog.csdn.net/ChenKai_164/article/details/105617886" target="_blank" rel="noopener">requests 实战</a>，最好把前前后后的知识都补一遍！<br>下面是这个部分的代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line">url = <span class="string">"http://www.newsmth.net/nForum/slist.json?uid=guest&amp;root=sec-9"</span></span><br><span class="line">headers = &#123;</span><br><span class="line">  <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:75.0) Gecko/20100101 Firefox/75.0'</span>,</span><br><span class="line">  <span class="string">'Host'</span>: <span class="string">'www.newsmth.net'</span>,</span><br><span class="line">  <span class="string">'Accept'</span>: <span class="string">'application/json, text/javascript, */*; q=0.01'</span>,</span><br><span class="line">  <span class="string">'Accept-Language'</span>: <span class="string">'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2'</span>,</span><br><span class="line">  <span class="string">'Accept-Encoding'</span>: <span class="string">'gzip, deflate'</span>,</span><br><span class="line">  <span class="string">'X-Requested-With'</span>: <span class="string">'XMLHttpRequest'</span>,</span><br><span class="line">  <span class="string">'Connection'</span>: <span class="string">'keep-alive'</span>,</span><br><span class="line">  <span class="string">'Referer'</span>: <span class="string">'http://www.newsmth.net/nForum/'</span>,</span><br><span class="line">  <span class="string">'Cookie'</span>: <span class="string">'Hm_lvt_bbac0322e6ee13093f98d5c4b5a10912=1587005280; main[UTMPUSERID]=guest; main[UTMPKEY]=40324888; main[UTMPNUM]=37000; Hm_lpvt_bbac0322e6ee13093f98d5c4b5a10912=1587005521; main[XWJOKE]=hoho; __gads=ID=c8ebf8ba150e0059:T=1587005311:S=ALNI_MZ_fNqTOR1qs7ZaHX7DWAcYp5CD8A; left-index=00100000000'</span>,</span><br><span class="line">  <span class="string">'Cache-Control'</span>: <span class="string">'max-age=0'</span>,</span><br><span class="line">  <span class="string">'Cookie'</span>: <span class="string">'main[UTMPUSERID]=guest; main[UTMPKEY]=10851192; main[UTMPNUM]=83713'</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_text</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        res = requests.get(url, headers=headers)</span><br><span class="line">        res.raise_for_status</span><br><span class="line">        res.encoding = res.apparent_encoding</span><br><span class="line">        text = res.text</span><br><span class="line">        <span class="keyword">return</span> text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">""</span></span><br><span class="line"></span><br><span class="line">text = get_text(url)</span><br><span class="line">text = text.replace(<span class="string">"["</span>, <span class="string">""</span>)</span><br><span class="line">text = text.replace(<span class="string">"]"</span>, <span class="string">""</span>)</span><br><span class="line">text_split = text.split(<span class="string">","</span>)</span><br><span class="line">href_list = []</span><br><span class="line">title_list = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(text_split)):</span><br><span class="line">    str_i = text_split[i]</span><br><span class="line">    pat1 = re.compile(<span class="string">r'a href=\\"(.*?)" title='</span>)</span><br><span class="line">    pat2 = re.compile(<span class="string">r'title=\\"(.*?)\\"&gt;'</span>)</span><br><span class="line">    href_ = re.findall(pat1, str_i)</span><br><span class="line">    title_ = re.findall(pat2, str_i)</span><br><span class="line">    <span class="keyword">if</span> (len(href_)) &gt; <span class="number">0</span> &amp; (len(title_) &gt; <span class="number">0</span>):</span><br><span class="line">        href_list.append(href_[<span class="number">0</span>])</span><br><span class="line">        title_list.append(title_[<span class="number">0</span>])</span><br><span class="line">print(href_list,<span class="string">"\n"</span>,title_list)</span><br><span class="line"></span><br><span class="line">href_list = [<span class="string">"http://www.newsmth.net"</span> + href.replace(<span class="string">"\\"</span>, <span class="string">""</span>) <span class="keyword">for</span> href <span class="keyword">in</span> href_list]</span><br><span class="line">href_list</span><br></pre></td></tr></table></figure>
<p>大家最好都手敲一遍，事实上这段代码大家完全不用看我的，自己都可以敲出来，这是最终得到的结果，URL 和标题信息都有了：</p>
<p><img src="https://img-blog.csdnimg.cn/20200428112224201.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="URL和标题信息"><br>我们上面得到的标题，可以作为我们建立新文件夹的依据，我们得到的 URL，我们可以进一步分析得到文章的条件，然后按照套路抓取到所有的文章。接下来我们就看看怎么通过这些 URL 得到对应的文章：</p>
<h1 id="实战阶段三：获取子版块下所有文章"><a href="#实战阶段三：获取子版块下所有文章" class="headerlink" title="实战阶段三：获取子版块下所有文章"></a>实战阶段三：获取子版块下所有文章</h1><p>我们任意点进去一个子版块，以 AppleDev 子版块为例，依然是点开 network 刷新，得到一些 ajax 信息， ajax 在我们前面的 <a href="https://blog.csdn.net/ChenKai_164/article/details/105786852" target="_blank" rel="noopener">Ajax 详解</a><br>已经有讲过了，我们仍然按照套路抓取链接得到内容，然后由正则表达式匹配文章链接，文章链接的形式我们可以任意点开一篇文章观察到，或者也可以直接通过返回的信息得到，下面是抓取的代码：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">res_ = requests.get(<span class="string">"http://www.newsmth.net/nForum/board/AppleDev?ajax"</span>, headers=headers)</span><br><span class="line">res_.encoding = res_.apparent_encoding</span><br><span class="line">text = res_.text</span><br><span class="line">pat3 = re.compile(<span class="string">r'(/nForum/article/AppleDev/\d+)'</span>)</span><br><span class="line">href_text = re.findall(pat3, text)</span><br><span class="line">total_href_text = [<span class="string">"http://www.newsmth.net"</span>+ href <span class="keyword">for</span> href <span class="keyword">in</span> href_text]</span><br><span class="line">print(total_href_text)</span><br></pre></td></tr></table></figure><br>我们将得到的链接内容进行截图：</p>
<p><img src="https://img-blog.csdnimg.cn/20200428115615131.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="链接内容"><br>不出意料，我们点进去任何一个链接看到的文章都正是我们想要得到的内容！</p>
<h1 id="实战阶段四：编写结构化代码"><a href="#实战阶段四：编写结构化代码" class="headerlink" title="实战阶段四：编写结构化代码"></a>实战阶段四：编写结构化代码</h1><p>我们现在直接开始编写结构化的代码：<br>首先导入我们所需要的包：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br></pre></td></tr></table></figure>
<p>有人可能会好奇，为什么还要导入 selenium 包，事实上在爬取文章内容的时候，我试图分析了一波网页源代码和 Network 的 response，似乎并没有好的方法获得文章内容，于是我果断放弃，选择了相对低效的 selenium，至于问为什么低效，是因为我的代码中每一次都需要打开 passage 的网页才能抓取，当然现在有不需要打开网页的 selenium 方法，别问，问就是懒。<br>下面我们写一个很常用很老套的函数，从 URL 获得文章的 Text：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getText</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        res = requests.get(url)</span><br><span class="line">        res.raise_for_status</span><br><span class="line">        res.encoding = res.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> res.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">""</span></span><br></pre></td></tr></table></figure>
<p>这几行代码如果大家看了前几期文章，现在倒着都能默出来了吧，如果没有的话赶紧去看看前面所有爬虫系列的文章噢~</p>
<p>然后我们定义一个函数，获取所有的 Section 的 URL：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getSectionURL</span><span class="params">()</span>:</span></span><br><span class="line">    url_list = []</span><br><span class="line">    base_url = <span class="string">r"http://www.newsmth.net/nForum/#!section/"</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        url_list.append(base_url+str(i))</span><br><span class="line">    <span class="keyword">return</span> url_list</span><br></pre></td></tr></table></figure>
<p>下面这堆代码的用途是获得 Section 的名称，大家可以用这个名称在爬取完文章后建立文件夹保存文章：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getSectionList</span><span class="params">()</span>:</span></span><br><span class="line">    sectionTitleURL = <span class="string">"http://www.newsmth.net/nForum/slist.json?uid=guest&amp;root=list-section"</span></span><br><span class="line">    text = getText(sectionTitleURL)</span><br><span class="line">    textList = text.split(<span class="string">","</span>)</span><br><span class="line">    textList = [i <span class="keyword">for</span> i <span class="keyword">in</span> textList <span class="keyword">if</span> i.endswith(<span class="string">'&lt;/a&gt;"'</span>)]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(textList)):</span><br><span class="line">        textList[i] = re.findall(<span class="string">r'\\"&gt;(.*?)&lt;/a&gt;'</span>, textList[i])</span><br><span class="line">    textList = [i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> textList <span class="keyword">if</span> len(i)&gt;<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> textList</span><br></pre></td></tr></table></figure>
<p>下面这段代码用于爬取大板块下面的所有子版块的链接和标题：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getSubSectionList</span><span class="params">(section_num)</span>:</span></span><br><span class="line">    url = <span class="string">"http://www.newsmth.net/nForum/section/"</span> + str(section_num) + <span class="string">"?ajax"</span></span><br><span class="line">    text = getText(url)</span><br><span class="line">    soup = BeautifulSoup(text, <span class="string">"html"</span>)</span><br><span class="line">    hrefList = soup.select(<span class="string">"td a"</span>)</span><br><span class="line">    hrefList = [str(href) <span class="keyword">for</span> href <span class="keyword">in</span> hrefList]</span><br><span class="line">    hrefList = [href <span class="keyword">for</span> href <span class="keyword">in</span> hrefList <span class="keyword">if</span> href.startswith(<span class="string">r'&lt;a href="/nForum/board'</span>)]</span><br><span class="line">    pat1 = re.compile(<span class="string">r'&lt;a href="(.*?)"&gt;'</span>)</span><br><span class="line">    pat2 = re.compile(<span class="string">r'"&gt;(.*?)&lt;/a&gt;'</span>)</span><br><span class="line">    HrefList = []</span><br><span class="line">    TitleList = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(hrefList)):</span><br><span class="line">        href = re.findall(pat1, hrefList[i])</span><br><span class="line">        href = <span class="string">"http://www.newsmth.net"</span> + href[<span class="number">0</span>]</span><br><span class="line">        title = re.findall(pat2, hrefList[i])</span><br><span class="line">        HrefList.append(href)</span><br><span class="line">        TitleList.append(title[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">return</span> HrefList, TitleList</span><br></pre></td></tr></table></figure>
<p>下面这行代码用于从上面获得的 SubSectionURL 中获得所有文章的 URL 链接：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getPassageURL</span><span class="params">(SubSectionURL)</span>:</span></span><br><span class="line">    TextURL = SubSectionURL + <span class="string">"?ajax"</span></span><br><span class="line">    text = getText(TextURL)</span><br><span class="line">    title = re.findall(<span class="string">r"nForum/board/(.*)\?ajax"</span>, TextURL)[<span class="number">0</span>]</span><br><span class="line">    pat = re.compile(<span class="string">r'href="/nForum/article/'</span> + re.escape(title) + <span class="string">r'/(\d&#123;2,10&#125;)'</span>)</span><br><span class="line">    article_num = re.findall(pat, text)</span><br><span class="line">    href_list = [<span class="string">r"http://www.newsmth.net/nForum/#!article/"</span> + title + <span class="string">"/"</span> + href <span class="keyword">for</span> href <span class="keyword">in</span> article_num]</span><br><span class="line">    <span class="keyword">return</span> href_list</span><br></pre></td></tr></table></figure>
<p>下面这行代码用于从上面的文章 URL 中解析出文章内容，评论区内容被截掉了，大家可根据需要修改代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getPassageFromURL</span><span class="params">(PassageURL_List)</span>:</span></span><br><span class="line">    text_List = []</span><br><span class="line">    i=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> PassageURL_List:</span><br><span class="line">        driver = webdriver.Firefox()</span><br><span class="line">        driver.get(url)</span><br><span class="line">        page = driver.page_source</span><br><span class="line">        soup = BeautifulSoup(page)</span><br><span class="line">        content = soup.select(<span class="string">"td[class~=a-content]"</span>)</span><br><span class="line">        passage = re.findall(<span class="string">r'&lt;td class="a-content"&gt;(.*?)&lt;/td&gt;'</span>, str(content[<span class="number">0</span>]))</span><br><span class="line">        print(passage)</span><br><span class="line">        text_List.append(passage)</span><br><span class="line">        driver.close()</span><br><span class="line">    <span class="keyword">return</span> text_List</span><br></pre></td></tr></table></figure>
<p>大功告成！大家试着运行一下代码看看能不能跑通吧~</p>
]]></content>
      <categories>
        <category>Spider</category>
      </categories>
  </entry>
  <entry>
    <title>Python爬虫初级（十二）—— 新闻消息爬取实战</title>
    <url>/posts/ac35ade0.html</url>
    <content><![CDATA[<h1 id="链接介绍"><a href="#链接介绍" class="headerlink" title="链接介绍"></a>链接介绍</h1><p>我们需要爬取的链接是：<a href="https://news.qq.com/" target="_blank" rel="noopener">https://news.qq.com/</a><br>我们最终的爬取目标是将所有标题及其内容罗列出来存储为表格文档</p>
<h1 id="爬取过程"><a href="#爬取过程" class="headerlink" title="爬取过程"></a>爬取过程</h1><p>其实这个爬虫的代码特别简单，就是使用我们前面学的 <a href="https://blog.csdn.net/Mikow/article/details/105787541" target="_blank" rel="noopener">Selenium</a><br> 教程，下面拆分代码进行讲解：</p>
<p>首先自然就是导入所需的所有库：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver  </span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.keys <span class="keyword">import</span> Keys  </span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> csv</span><br></pre></td></tr></table></figure>
<p>然后通过 driver 打开上面给出的链接：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">driver = webdriver.Chrome()</span><br><span class="line">driver.get(<span class="string">"https://news.qq.com/"</span>)</span><br></pre></td></tr></table></figure>
<p>然后由于新闻页面需要滑动才会显示下面的内容，我们设置一个控制屏幕滑动的代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">100</span>):</span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line">    driver.execute_script(<span class="string">"window.scrollTo(window.scrollX, %d);"</span>%(i*<span class="number">150</span>))</span><br></pre></td></tr></table></figure>
<p>我们知道爬取这些由 JS 控制的页面时的困难主要在于我们得到的页面源代码和我们点击 F12 查看控制台看到的东西不是一回事，而 Selenium 的一大好处就是我们可以模拟浏览器查看时的状态，也就是我们可以像平时一样查看 Element 等属性，我们只需要定位到相应的标题行，得到对应的内容格式：</p>
<p><img src="https://img-blog.csdnimg.cn/20200427221951190.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="Element1"></p>
<p>以及打开每一个 li 后得到的内容：</p>
<p><img src="https://img-blog.csdnimg.cn/20200427221752383.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="Element">我们可以写出代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">html=driver.page_source</span><br><span class="line">soup=BeautifulSoup(html,<span class="string">"lxml"</span>)</span><br><span class="line">jx_tit=soup.find_all(<span class="string">"div"</span>,&#123;<span class="string">"class"</span>:<span class="string">"jx-tit"</span>&#125;)[<span class="number">0</span>].find_next_sibling().find_all(<span class="string">"li"</span>)</span><br></pre></td></tr></table></figure>
<p>然后根据上面第二张 Element 图中解析出的格式保存相关信息即可：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">f = open(<span class="string">'news.csv'</span>,<span class="string">'w'</span>,encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">csv_writer = csv.writer(f)</span><br><span class="line">csv_writer.writerow([<span class="string">"index"</span>,<span class="string">","</span>,<span class="string">"title"</span>,<span class="string">","</span>,<span class="string">"url"</span>])</span><br><span class="line"><span class="keyword">for</span> i,jxtit <span class="keyword">in</span> enumerate(jx_tit):    </span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        text=jxtit.find_all(<span class="string">"img"</span>)[<span class="number">0</span>][<span class="string">"alt"</span>]</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        text=jxtit.find_all(<span class="string">"div"</span>,&#123;<span class="string">"class"</span>:<span class="string">"lazyload-placeholder"</span>&#125;)[<span class="number">0</span>].text</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        url=jxtit.find_all(<span class="string">"a"</span>)[<span class="number">0</span>][<span class="string">"href"</span>]</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        print(jxtit)</span><br><span class="line">    csv_writer.writerow([i+<span class="number">1</span>,text,url]) </span><br><span class="line">f.close()</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Spider</category>
      </categories>
  </entry>
  <entry>
    <title>Python爬虫初级（十一）—— Selenium 详解</title>
    <url>/posts/26182e00.html</url>
    <content><![CDATA[<h1 id="Selenium-库的安装"><a href="#Selenium-库的安装" class="headerlink" title="Selenium 库的安装"></a>Selenium 库的安装</h1><p>Selenium 的安装比起其他 python 库的安装稍显复杂，下面对此做简要介绍：<br>首先自然是 pip install selenium，然后我们需要安装对应的浏览器 driver，driver是什么呢，在介绍怎么安装之前，我们先看下面这两行代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">driver = webdriver.Firefox()</span><br></pre></td></tr></table></figure>
<p>也就是说我们 selenium 是需要启用 Firefox 等浏览器才能执行某些操作的，因此我们需要让 selenium 可以通过某种方式连接到我们的浏览器。</p>
<h4 id="Firefox-driver-的安装"><a href="#Firefox-driver-的安装" class="headerlink" title="Firefox driver 的安装"></a>Firefox driver 的安装</h4><p>直接戳 <a href="https://github.com/mozilla/geckodriver/releases" target="_blank" rel="noopener">https://github.com/mozilla/geckodriver/releases</a> ，在下面的这些地址中找到适合自己系统的安装包进行安装：</p>
<p><img src="https://img-blog.csdnimg.cn/20200427201928244.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="安装包">相应的，Chrome浏览器需要安装chromedriver，IE浏览器要安装IEdriver。</p>
<p>driver的路径可以直接放在python路径下，我这里把driver放在了python的Scripts路径下，同时把script路径加入环境变量。也可以选择将相应的 driver 安装到其他文件夹中，但要记得将这个文件夹添加到环境变量 PATH 中。</p>
<h4 id="Chrome-driver"><a href="#Chrome-driver" class="headerlink" title="Chrome driver"></a>Chrome driver</h4><p>Chrome driver 有两个下载地址：<br>1、<a href="http://chromedriver.storage.googleapis.com/index.html" target="_blank" rel="noopener">http://chromedriver.storage.googleapis.com/index.html</a><br>2、<a href="https://npm.taobao.org/mirrors/chromedriver/" target="_blank" rel="noopener">https://npm.taobao.org/mirrors/chromedriver/</a></p>
<p>只需要记得一定要下载对应的版本即可！</p>
<p>同时 selenium 还支持 IE 浏览器，因为想来也没什么人会用，有需要的就自行安装吧。</p>
<h1 id="Selenium-入门"><a href="#Selenium-入门" class="headerlink" title="Selenium 入门"></a>Selenium 入门</h1><p>这里直接通过代码方式给大家演示 Selenium 的使用，大家并不需要了解每个语句的具体运作，只需要了解每条代码的大体意思即可：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">driver = webdriver.Firefox()</span><br></pre></td></tr></table></figure>
<p>这部分代码是用来导入 selenium 库，此时会直接启动一个 Firefox 界面，它是由 selenium 直接控制的，我打开的是一个空白标签页：<br><img src="https://img-blog.csdnimg.cn/20200427205654733.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="空白标签页"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">driver.find_element_by_id(<span class="string">"kw"</span>).clear()</span><br><span class="line">driver.find_element_by_id(<span class="string">"kw"</span>).send_keys(<span class="string">"P2P"</span>)</span><br><span class="line">driver.find_element_by_id(<span class="string">"su"</span>).click()</span><br></pre></td></tr></table></figure>
<p>这三行代码会打开搜索框，清空搜索框内容，输入 P2P 字样，点击搜索，其中的 id 内容正是指向相应位置（点击按钮或输入框）的定位。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">e_items = driver.find_elements_by_xpath(<span class="string">"//*[@class='result c-container ']"</span>)</span><br><span class="line">print(<span class="string">"\n"</span>.join([e.find_element_by_tag_name(<span class="string">"a"</span>).text <span class="keyword">for</span> e <span class="keyword">in</span> e_items]))</span><br><span class="line"><span class="comment"># P2P种子搜索器_p2psearcher官方下载【种子搜索神器】-华军软件园</span></span><br><span class="line"><span class="comment"># P2P金融_百度百科</span></span><br><span class="line"><span class="comment"># P2P_最有钛度的P2P资讯-钛媒体官方网站</span></span><br><span class="line"><span class="comment"># 种子搜索神器_p2p种子搜索器下载[p2psearcher]下载之家</span></span><br><span class="line"><span class="comment"># 网贷之家-中国普惠金融投资理财行业门户_P2P网贷银行存款贷款保险...</span></span><br><span class="line"><span class="comment"># 富金利_P2P平台_专业安全的P2P网贷投融资平台【唯一官网】</span></span><br><span class="line"><span class="comment"># P2P概念板块_股票行情-手机金融界</span></span><br></pre></td></tr></table></figure>
<p>这两行代码的作用是找到搜索条目中的标题并返回。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(<span class="string">'\n'</span>.join([e.find_element_by_tag_name(<span class="string">"a"</span>).get_attribute(<span class="string">"href"</span>) <span class="keyword">for</span> e <span class="keyword">in</span> e_items]))</span><br></pre></td></tr></table></figure>
<p>上面这行代码是找到相应的标题链接，我们可以发现，其实这些函数名都和 js 的函数名几乎相同，下面这行代码是点击网页最下方的下一页：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">driver.find_element_by_xpath(<span class="string">"//div[@id='page']/a/span[2]"</span>).click()</span><br></pre></td></tr></table></figure>
<p>我们可以综合上述代码，实现整个爬取标题过程的自动化，实现代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support <span class="keyword">import</span> expected_conditions <span class="keyword">as</span> EC </span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support.ui <span class="keyword">import</span> WebDriverWait </span><br><span class="line"></span><br><span class="line">driver.get(<span class="string">"https://www.baidu.com"</span>)</span><br><span class="line">WebDriverWait(driver, <span class="number">10</span>).until(EC.presence_of_element_located((By.ID, <span class="string">"kw"</span>)))</span><br><span class="line"></span><br><span class="line">driver.find_element_by_id(<span class="string">"kw"</span>).clear()</span><br><span class="line">driver.find_element_by_id(<span class="string">"kw"</span>).send_keys(<span class="string">"P2P"</span>)</span><br><span class="line">driver.find_element_by_id(<span class="string">"su"</span>).click()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>,<span class="number">5</span>,<span class="number">1</span>):</span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line">    e_items = driver.find_elements_by_xpath(<span class="string">"//*[@class='result c-container ']"</span>)</span><br><span class="line">    print(<span class="string">"page "</span>,i<span class="number">-1</span>)</span><br><span class="line">    print(<span class="string">"\n"</span>.join([e.find_element_by_tag_name(<span class="string">"a"</span>).text <span class="keyword">for</span> e <span class="keyword">in</span> e_items]))</span><br><span class="line">    driver.find_element_by_xpath(<span class="string">f"//div[@id='page']/a/span[<span class="subst">&#123;i&#125;</span>]"</span>).click()</span><br></pre></td></tr></table></figure>
<p>事实上，我们并不需要自己写这些代码的函数，我们可以直接在 Firefox 安装 Katalon 插件，点击运行，然后在浏览器上执行我们需要执行的操作即可导出代码。</p>
<p>下面是 Katalon 扩展程序页面，点击 Record，然后在 Firefox 像往常操作一样输入内容，检索内容，翻页：</p>
<p><img src="https://img-blog.csdnimg.cn/20200427211523448.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="Katalon"></p>
<p>执行内容时，Katalon 会弹出一些提示窗，说明已经执行了指令并转化为了代码：</p>
<p><img src="https://img-blog.csdnimg.cn/20200427211807844.png#pic_center" alt="Katalon 提示"><br>执行完毕后点击 Stop（在刚刚点击 Record 的位置）即可，然后点击 Export，就可以发现我们可以导出任何形式我们需要的代码，甚至可以自己定制：</p>
<p><img src="https://img-blog.csdnimg.cn/20200427211940518.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="导出代码"></p>
]]></content>
      <categories>
        <category>Spider</category>
      </categories>
  </entry>
  <entry>
    <title>Python爬虫初级（十）—— Session 和 Cookie 详解</title>
    <url>/posts/5cc32bbc.html</url>
    <content><![CDATA[<h1 id="Session-和-Cookie"><a href="#Session-和-Cookie" class="headerlink" title="Session 和 Cookie"></a>Session 和 Cookie</h1><p>我们先介绍 Session 和 Cookie 的区别：</p>
<h4 id="Cookie"><a href="#Cookie" class="headerlink" title="Cookie"></a>Cookie</h4><p>在网站中，http 请求是无状态的。也就是说即使第一次和服务器连接后并且登录成功后，第二次请求服务器依然不能知道当前请求是哪个用户。cookie 的出现就是为了解决这个问题，第一次登录后服务器返回一些数据（cookie）给浏览器，然后浏览器保存在本地，当该用户发送第二次请求的时候，就会自动的把上次请求存储的 cookie 数据自动的携带给服务器，服务器通过浏览器携带的数据就能判断当前用户是哪个了。cookie 存储的数据量有限，不同的浏览器有不同的存储大小，但一般不超过4KB。因此使用 cookie 只能存储一些小量的数据。<br>可以简单理解为 Cookies 中保存了登录凭证，我们只要持有这个凭证，就可以在服务端保持一个登录状态。</p>
<h4 id="Session"><a href="#Session" class="headerlink" title="Session"></a>Session</h4><p>session和cookie的作用有点类似，都是为了存储用户相关的信息。不同的是，cookie是存储在本地浏览器，而session存储在服务器。存储在服务器的数据会更加的安全，不容易被窃取。但存储在服务器也有一定的弊端，就是会占用服务器的资源，但现在服务器已经发展至今，一些session信息还是绰绰有余的。</p>
<h4 id="两者的联系"><a href="#两者的联系" class="headerlink" title="两者的联系"></a>两者的联系</h4><p>我们举个例子，在我们执行登录操作时，当我们输入好用户名和密码后，客户端会将这个 Cookies 放在请求头一起发送给服务端，这时，服务端就知道是谁在进行登录操作，并且可以判断这个人输入的用户名和密码对不对，如果输入正确，则在服务端的 Session 记录一下这个人已经登录成功了，下次再请求的时候这个人就是登录状态了。</p>
<p>如果客户端传给服务端的 Cookies 是无效的，或者这个 Cookies 根本不是由这个服务端下发的，或者这个 Cookies 已经过期了，那么接下里的请求将不再能访问需要登录后才能访问的页面。</p>
<p>所以， Session 和 Cookies 之间是需要相互配合的，一个在服务端，一个在客户端。</p>
<p>事实上，在如今的市场或者企业里，一般有两种存储方式：<br>1、存储在服务端：通过cookie存储一个session_id，然后具体的数据则是保存在session中。如果用户已经登录，则服务器会在cookie中保存一个session_id，下次再次请求的时候，会把该session_id携带上来，服务器根据session_id在session库中获取用户的session数据。就能知道该用户到底是谁，以及之前保存的一些状态信息。这种专业术语叫做server side session。<br>2、将session数据加密，然后存储在cookie中。这种专业术语叫做client side session。flask采用的就是这种方式，但是也可以替换成其他形式。</p>
<h4 id="查看-Cookie"><a href="#查看-Cookie" class="headerlink" title="查看 Cookie"></a>查看 Cookie</h4><p>我们打开京东的网站，在 Chrome 中按 F12 打开开发者工具，选择 Application 标签，点开 Cookies 这一栏，会出现如下页面：<br><img src="https://img-blog.csdnimg.cn/20200427153645515.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="京东 Cookie"></p>
<p>我们解析一下这些参数：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>内容</th>
<th>解析</th>
</tr>
</thead>
<tbody>
<tr>
<td>Name</td>
<td>这个是 Cookie 的名字。一旦创建，该名称便不可更改</td>
</tr>
<tr>
<td>Value</td>
<td>这个是 Cookie 的值</td>
</tr>
<tr>
<td>Domain</td>
<td>这个是可以访问该 Cookie 的域名。例如，如果设置为 .jd.com ，则所有以 jd.com ，结尾的域名都可以访问该Cookie</td>
</tr>
<tr>
<td>Max Age</td>
<td>Cookie 失效的时间，单位为秒，也常和 Expires 一起使用。 Max Age 如果为正数，则在 Max Age 秒之后失效，如果为负数，则关闭浏览器时 Cookie 即失效，浏览器也不会保存该 Cookie </td>
</tr>
<tr>
<td>Path</td>
<td>Cookie 的使用路径。如果设置为 /path/ ，则只有路径为 /path/ 的页面可以访问该 Cookie 。如果设置为 / ，则本域名下的所有页面都可以访问该 Cookie</td>
</tr>
<tr>
<td>Size</td>
<td>Cookie 的大小</td>
</tr>
<tr>
<td>HTTPOnly</td>
<td>如果此项打勾，那么通过 JS 脚本将无法读取到 Cookie 信息，这样能有效的防止 XSS 攻击，窃取 Cookie 内容，可以增加 Cookie 的安全性</td>
</tr>
<tr>
<td>Secure</td>
<td>如果此项打勾，那么这个 Cookie 只能用 HTTPS 协议发送给服务器，用 HTTP 协议是不发送的</td>
</tr>
</tbody>
</table>
</div>
<h4 id="退出操作"><a href="#退出操作" class="headerlink" title="退出操作"></a>退出操作</h4><p>当我们关闭浏览器的时候会自动销毁服务端的会话，这个是错误的，因为在关闭浏览器的时候，浏览器并不会额外的通知服务端说，我要关闭了，你把和我的会话销毁掉吧。<br>因为服务端的会话是保存在内存中的，虽然一个会话不会很大，但是架不住会话多啊，硬件毕竟是会有限制的，不能无限扩充下去的，所以在服务端设置会话的过期时间就非常有必要。<br>当然，有没有方式能让浏览器在关闭的时候同步的关闭服务端的会话，当然是可以的，我们可以通过脚本语言 JS 来监听浏览器关闭的动作，当浏览器触发关闭动作的时候，由 JS 像服务端发起一个请求来通知服务端销毁会话。<br>由于不同的浏览器对 JS 事件的实现机制不一致，不一定保证 JS 能监听到浏览器关闭的动作，所以现在常用的方式还是在服务端自己设置会话的过期时间</p>
<h1 id="模拟登录163"><a href="#模拟登录163" class="headerlink" title="模拟登录163"></a>模拟登录163</h1><p>在这里我们提前使用了 Selenium 库，该库的具体使用方法可以见下期，下面简单展示相关代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"></span><br><span class="line">name = <span class="string">'*'</span></span><br><span class="line">passwd = <span class="string">'*'</span></span><br><span class="line">driver = webdriver.Chrome()</span><br><span class="line">driver.get(<span class="string">'https://mail.163.com/'</span>)</span><br><span class="line"><span class="comment"># 将窗口调整最大</span></span><br><span class="line">driver.maximize_window()</span><br><span class="line"><span class="comment"># 休息5s</span></span><br><span class="line">time.sleep(<span class="number">5</span>)</span><br><span class="line">current_window_1 = driver.current_window_handle</span><br><span class="line">print(current_window_1)</span><br><span class="line"><span class="comment"># CDwindow-28F02680782B96D54B997F9A8E8334DD</span></span><br><span class="line"></span><br><span class="line">button = driver.find_element_by_id(<span class="string">'lbNormal'</span>)</span><br><span class="line">button.click()</span><br><span class="line">driver.switch_to.frame(driver.find_element_by_xpath(<span class="string">"//iframe[starts-with(@id, 'x-URS-iframe')]"</span>))</span><br><span class="line"></span><br><span class="line">email = driver.find_element_by_name(<span class="string">'email'</span>)</span><br><span class="line"><span class="comment">#email = driver.find_element_by_xpath('//input[@name="email"]')</span></span><br><span class="line">email.send_keys(name)</span><br><span class="line">password = driver.find_element_by_name(<span class="string">'password'</span>)</span><br><span class="line"><span class="comment">#password = driver.find_element_by_xpath("//input[@name='password']")</span></span><br><span class="line">password.send_keys(passwd)</span><br><span class="line">submit = driver.find_element_by_id(<span class="string">"dologin"</span>)</span><br><span class="line">time.sleep(<span class="number">15</span>)</span><br><span class="line">submit.click()</span><br><span class="line">time.sleep(<span class="number">10</span>)</span><br><span class="line">print(driver.page_source)</span><br><span class="line"><span class="comment"># 返回页面源代码</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Spider</category>
      </categories>
  </entry>
  <entry>
    <title>Python爬虫初级（九）—— ajax 详解</title>
    <url>/posts/1dee9666.html</url>
    <content><![CDATA[<h1 id="ajax-介绍"><a href="#ajax-介绍" class="headerlink" title="ajax 介绍"></a>ajax 介绍</h1><p>我们看到 ajax 这个词，大多数人都会觉得这个词和以前的不太一样，似乎听的更少了更陌生了，我们要怎么理解 ajax 呢？我们先看看它的英文全称：AJAX = Asynchronous JavaScript and XML，翻译成中文就是异步的 JavaScript 和 XML，异步也就是说，它可以在不重新加载整个页面的情况下，可以与服务器交换数据并更新部分网页内容。<br>举个例子：你打开一个股票实时数据网站，假如这个网站不是使用 ajax 的，那么你每次想要得到这个网站的最新信息都需要刷新一下这个网站，而若采用了 ajax，你可以实时获得股票的信息更新，而无需刷新网站。因此简单来说，ajax 是一种用于创建快速动态网页的技术，它可以实现在不重新加载整个网页的情况下，对网页的某部分进行更新。<br>下面是 AJAX 工作原理图：<br><img src="https://img-blog.csdnimg.cn/2020042711365962.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="AJAX工作原理"></p>
<p>这张图其实已经很清晰的反映了我们对 ajax 信息进行爬取的路线 —— 根据需要的内容，模拟相应的请求，发送至服务器，得到需要的内容。可能术语说的尚不标准，但大概就是这个意思。</p>
<h1 id="分析网页的-Ajax-请求"><a href="#分析网页的-Ajax-请求" class="headerlink" title="分析网页的 Ajax 请求"></a>分析网页的 Ajax 请求</h1><p>我们打开下面网址：<a href="https://unsplash.com/" target="_blank" rel="noopener">https://unsplash.com/</a> 这是一个图片网站，页面如下：</p>
<p><img src="https://img-blog.csdnimg.cn/20200427120716268.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="unsplash 页面"><br>我们希望获取到该页面所有图片，先点开控制台的 Network，最开始可能什么都没有，这时候我们刷新页面，勾选XML，就得到了这么多返回数据：</p>
<p><img src="https://img-blog.csdnimg.cn/20200427120911945.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="返回数据"><br>我们随便点开一个 “photo?” 的内容，点开 preview：</p>
<p><img src="https://img-blog.csdnimg.cn/20200427121204639.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="preview"><br>找到 urls 的 full，复制链接到浏览器打开，得到的正是我们需要的图片。我们分析一下这个 Ajax 请求，找到 Header 部分：<br><img src="https://img-blog.csdnimg.cn/20200427121538482.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="header"><br> 于是我们的思路就是根据这个 Headers 模拟 Ajax 请求，从网页的回复中解析出图片的 URL 列表，然后遍历图片的 URL 列表得到图片，存储下来即可。这个思路不正和上面的 Ajax 工作流程图吻合吗？</p>
<h1 id="代码测试"><a href="#代码测试" class="headerlink" title="代码测试"></a>代码测试</h1><p>下面我们测试上面的想法的可行性：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> json</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> time</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>header = &#123;<span class="string">"referer"</span>:<span class="string">"https://unsplash.com/"</span>, <span class="string">"user-agent"</span>:<span class="string">"Mozilla/5.0"</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ajax_url = <span class="string">"https://unsplash.com/napi/photos?page=3&amp;per_page=12"</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>res = requests.get(ajax_url, headers=header)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>res.status_code</span><br><span class="line"><span class="number">200</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>res.encoding = res.apparent_encoding</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>text = res.text</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>js = json.loads(text)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>len(js)</span><br><span class="line"><span class="number">12</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>js[<span class="number">1</span>][<span class="string">"urls"</span>]</span><br><span class="line">&#123;<span class="string">'raw'</span>: <span class="string">'https://images.unsplash.com/photo-1587825159137-0b606e25fe80?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9'</span>, <span class="string">'full'</span>: <span class="string">'https://images.unsplash.com/photo-1587825159137-0b606e25fe80?ixlib=rb-1.2.1&amp;q=85&amp;fm=jpg&amp;crop=entropy&amp;cs=srgb&amp;ixid=eyJhcHBfaWQiOjEyMDd9'</span>, <span class="string">'regular'</span>: <span class="string">'https://images.unsplash.com/photo-1587825159137-0b606e25fe80?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1080&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjEyMDd9'</span>, <span class="string">'small'</span>: <span class="string">'https://images.unsplash.com/photo-1587825159137-0b606e25fe80?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=400&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjEyMDd9'</span>, <span class="string">'thumb'</span>: <span class="string">'https://images.unsplash.com/photo-1587825159137-0b606e25fe80?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=200&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjEyMDd9'</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>js[<span class="number">1</span>][<span class="string">"urls"</span>][<span class="string">"raw"</span>]</span><br><span class="line"><span class="string">'https://images.unsplash.com/photo-1587825159137-0b606e25fe80?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9'</span></span><br></pre></td></tr></table></figure>
<p>我们将最后得到的这段 URL 输入网址查询，发现确实是我们需要找的图片内容，我们倒数第二段代码可以发现，这些返回的内容正是我们之前看到的那些内容，于是我们可以着手编写完整代码。</p>
<h1 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">header = &#123;<span class="string">"referer"</span>:<span class="string">"https://unsplash.com/"</span>, <span class="string">"user-agent"</span>:<span class="string">"Mozilla/5.0"</span>&#125;</span><br><span class="line">url_list = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">    ajax_url = <span class="string">"https://unsplash.com/napi/photos?page="</span> + str(i) + <span class="string">"&amp;per_page=12"</span></span><br><span class="line">    url_list.append(ajax_url)</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_json</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        res = requests.get(url, headers=header)</span><br><span class="line">        res.raise_for_status</span><br><span class="line">        res.encoding = res.apparent_encoding</span><br><span class="line">        text = res.text</span><br><span class="line">        js = json.loads(text)</span><br><span class="line">        <span class="keyword">return</span> js</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"get_json ERROR"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ParseFromJSON</span><span class="params">(list_, json)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(json)):</span><br><span class="line">        url_i = &#123;&#125;</span><br><span class="line">        url_i[<span class="string">"url"</span>] = js[i][<span class="string">"urls"</span>][<span class="string">"raw"</span>]</span><br><span class="line">        url_i[<span class="string">"id"</span>] = js[i][<span class="string">"id"</span>]</span><br><span class="line">        list_.append(url_i)</span><br><span class="line">    <span class="keyword">return</span> list_</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getPic</span><span class="params">(pic_list)</span>:</span></span><br><span class="line">    path = <span class="string">"UnsplashPic"</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path):</span><br><span class="line">        os.makedirs(path)</span><br><span class="line">    <span class="keyword">for</span> pic <span class="keyword">in</span> pic_list:</span><br><span class="line">        <span class="keyword">if</span> os.path.exists(path + <span class="string">"/"</span> + pic[<span class="string">"id"</span>] + <span class="string">".jpg"</span>):</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            res = requests.get(pic[<span class="string">"url"</span>], headers=header)</span><br><span class="line">            <span class="keyword">if</span> res.status_code == <span class="number">200</span>:</span><br><span class="line">                <span class="keyword">with</span> open(path + <span class="string">"/"</span> + pic[<span class="string">"id"</span>] + <span class="string">".jpg"</span>, <span class="string">"wb"</span>) <span class="keyword">as</span> f:</span><br><span class="line">                    f.write(res.content)</span><br><span class="line">                    print(<span class="string">"PIC"</span>+pic[<span class="string">"id"</span>]+<span class="string">"is saved"</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                print(<span class="string">"STATUS_CODE ERROR"</span>)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            print(<span class="string">"PIC"</span>+pic[<span class="string">"id"</span>]+<span class="string">" save FAIL"</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    pic_list = []</span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> url_list:</span><br><span class="line">        js = get_json(url)</span><br><span class="line">        ParseFromJSON(pic_list, js)</span><br><span class="line">    getPic(pic_list)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Spider</category>
      </categories>
  </entry>
  <entry>
    <title>MySQL入门（九）DML语言</title>
    <url>/posts/dda6bdb1.html</url>
    <content><![CDATA[<p>本文使用的数据集下载链接为：<a href="https://pan.baidu.com/s/18_iwB072qpwUEvhxnF83qA" target="_blank" rel="noopener">https://pan.baidu.com/s/18_iwB072qpwUEvhxnF83qA</a> ，提取码：by2k </p>
<p>DML语言指的是数据操作语言，包含数据的插入（insert）、修改（update）和删除（delete）</p>
<h1 id="一、插入语句"><a href="#一、插入语句" class="headerlink" title="一、插入语句"></a>一、插入语句</h1><p>MySQL 表中使用 <strong>INSERT INTO</strong> SQL语句来插入数据。</p>
<h2 id="1-语法"><a href="#1-语法" class="headerlink" title="1. 语法"></a>1. 语法</h2><h3 id="方式一"><a href="#方式一" class="headerlink" title="方式一"></a>方式一</h3><p>以下为向MySQL数据表插入数据通用的 <strong>INSERT INTO</strong> SQL语法：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">INSERT INTO table_name ( field1, field2,...fieldN )</span><br><span class="line">                       VALUES</span><br><span class="line">                       ( value1, value2,...valueN );</span><br></pre></td></tr></table></figure>
<p>如果数据是字符型，必须使用单引号或者双引号，如：”value”。</p>
<p><strong>注意</strong></p>
<ol>
<li>插入的值的类型要与列的类型一致或兼容，个数也需要一致</li>
<li>创建表时默认数据类型为<code>Nullable</code>，意思为选填，可以为空</li>
<li><code>Nullable</code>列不想设置值可以赋<code>NULL</code>或什么都不写</li>
<li>列的顺序可以调换，但需要一一对应</li>
<li>可以省略列名，默认所有列，而且列的顺序与表中一致，此时为空的值需用NULL填充</li>
</ol>
<h3 id="方式二"><a href="#方式二" class="headerlink" title="方式二"></a>方式二</h3><p>语法为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">INSERT INTO 表名</span><br><span class="line">SET 列名&#x3D;值, 列名&#x3D;值, ...</span><br></pre></td></tr></table></figure>
<h2 id="2-示例"><a href="#2-示例" class="headerlink" title="2. 示例"></a>2. 示例</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 方式一：</span><br><span class="line">INSERT INTO beauty(id, NAME, sex, borndate, phone, photo, boyfriend_id)</span><br><span class="line">VALUES(13, &quot;Melody Marks&quot;, &quot;女&quot;, &#39;2000-2-29&#39;, &#39;12345678&#39;, NULL, 2);</span><br><span class="line"></span><br><span class="line"># 方式二：</span><br><span class="line">INSERT INTO beauty</span><br><span class="line">SET id&#x3D;19, NAME&#x3D;&quot;刘涛&quot;, phone&#x3D;&#39;99999&#39;;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>Python爬虫初级（八）—— lxml 详解及代理IP爬取</title>
    <url>/posts/ea515678.html</url>
    <content><![CDATA[<p>前一篇文章的末尾我们提到，可以使用 lxml + xpath 提取文章内容，在这篇文章中，我们将对 lxml 与 xpath 进行详细阐述，在这之前我们使用 pip install lxml 安装 lxml 库。</p>
<h1 id="Xpath-语法"><a href="#Xpath-语法" class="headerlink" title="Xpath 语法"></a>Xpath 语法</h1><p>XPath 即为 XML 路径语言（XML Path Language），它是一种用来确定 XML 文档中某部分位置的语言。而 XML 我们在<a href="https://blog.csdn.net/ChenKai_164/article/details/105635357" target="_blank" rel="noopener">这篇文章</a>中已经提到了，它的语法与 HTML 基本一致，可以说是通过 HTML发展而来的通用表达形式。</p>
<h3 id="路径表达式"><a href="#路径表达式" class="headerlink" title="路径表达式"></a>路径表达式</h3><p>XPath 使用路径表达式在 XML 文档中选取节点，节点是通过沿着路径选取的。下面列出了最常用的路径表达式：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>表达式</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>nodename</td>
<td>选取此节点的所有节点</td>
</tr>
<tr>
<td>/</td>
<td>从根节点选取</td>
</tr>
<tr>
<td>//</td>
<td>从匹配选择的当前节点选择文档中的节点，而不考虑它们的位置</td>
</tr>
<tr>
<td>.</td>
<td>选取当前节点</td>
</tr>
<tr>
<td>..</td>
<td>选取当前节点的父节点</td>
</tr>
<tr>
<td>@</td>
<td>选取属性</td>
</tr>
</tbody>
</table>
</div>
<h3 id="Predicates"><a href="#Predicates" class="headerlink" title="Predicates"></a>Predicates</h3><div class="table-container">
<table>
<thead>
<tr>
<th>表达式</th>
<th>描述</th>
<th>实例</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td>[n]</td>
<td>选择某节点的第n(n&gt;=1)个子节点</td>
<td>xpath(“//h//a[1]”)</td>
<td>选择h节点下第1个a节点</td>
</tr>
<tr>
<td>[last()]</td>
<td>选择某节点的最后一个子节点</td>
<td>xpath(“//h//a[last()]”)</td>
<td>选择h节点下最后一个a节点</td>
</tr>
<tr>
<td>[@attribute]</td>
<td>选择节点带有attribute属性的节点</td>
<td>xpath(“//img[@src]”)</td>
<td>选择带有src属性的img节点</td>
</tr>
<tr>
<td>[@attribute=value]</td>
<td>选择带有attribute属性值的节点</td>
<td>xpath(“//a[@href=”aaa.jpg”]”)</td>
<td>选择href属性值为aaa.jpg的a节点</td>
</tr>
<tr>
<td>*</td>
<td>任意匹配元素或者属性</td>
<td>xpath(“//a/“),xpath(“//a[@]”)</td>
<td>选择a节点下的所有子节点,选择带有属性的a节点</td>
</tr>
</tbody>
</table>
</div>
<h3 id="模糊搜索与匹配"><a href="#模糊搜索与匹配" class="headerlink" title="模糊搜索与匹配"></a>模糊搜索与匹配</h3><div class="table-container">
<table>
<thead>
<tr>
<th>函数</th>
<th>用法</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td>starts-with</td>
<td>xpath(“//div[starts-with(@id,’user’)]”)</td>
<td>选择id值以user开头的div节点</td>
</tr>
<tr>
<td>contains</td>
<td>xpath(“//div[contains(@id,’user’)]”)</td>
<td>选择id值包含user的div节点</td>
</tr>
<tr>
<td>and</td>
<td>xpath(“//div[starts-with(@class,”login”) and contains(@id,’user’)]”)</td>
<td>选择class值以login开头和id值包括user的div节点</td>
</tr>
<tr>
<td>text()</td>
<td>xpath(“//div[starts-with(text(),”mytest”)]”)</td>
<td>选取节点文本包含myest的div节点</td>
</tr>
</tbody>
</table>
</div>
<h3 id="xpath轴"><a href="#xpath轴" class="headerlink" title="xpath轴"></a>xpath轴</h3><div class="table-container">
<table>
<thead>
<tr>
<th>轴名称</th>
<th>表达式</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>ancestor</td>
<td>xpath(“./ancestor:: *”)</td>
<td>选取当前节点的所有父辈节点</td>
</tr>
<tr>
<td>ancestor-or.self</td>
<td>xpath(“./ancestor-or-self:: *”)</td>
<td>选取当前节点的父辈节点和节点自身</td>
</tr>
<tr>
<td>child</td>
<td>xpath(“./child:: *”)</td>
<td>选择当前节点的所有子节点</td>
</tr>
<tr>
<td>descendant</td>
<td>xpath(“./descendant:: *”)</td>
<td>选择当前节点的所有后代节点(子节点、孙节点等)</td>
</tr>
<tr>
<td>follow</td>
<td>xpath(“./following:: *”)</td>
<td>选取当前节点结束标签后的所有节点</td>
</tr>
<tr>
<td>follow-sibling</td>
<td>xpath(“./follow-sibling:: *”)</td>
<td>选取当前节点之后的兄弟节点</td>
</tr>
<tr>
<td>preceding</td>
<td>xpath(“./preceding:: *”)</td>
<td>选取当前开始标签前的所有节点</td>
</tr>
</tbody>
</table>
</div>
<h1 id="lxml-使用"><a href="#lxml-使用" class="headerlink" title="lxml 使用"></a>lxml 使用</h1><p>首先需要导入库：from lxml import etree，下面这行代码 lxml 会将 html 文本转成 xml 对象</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tree = etree.HTML(html)</span><br></pre></td></tr></table></figure>
<p>我们要使用 lxml + Xpath 从源代码直接获取信息时，会使用 tree.xpath() 语句，括号内的是所需获取内容的一些形式，具体形式在上面已经列出了，比如我们要获取<a href="http://www.dxy.cn/bbs/topic/43201486" target="_blank" rel="noopener">丁香园</a>页面的用户名称信息，首先查看该页面源代码：<br><img src="https://img-blog.csdnimg.cn/20200425135042154.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70" alt="用户信息">我们可以使用：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tree.xpath(<span class="string">'//div[@class=“auth”]/a/text()'</span>)</span><br></pre></td></tr></table></figure><br>我们想要获取评论信息：<br><img src="https://img-blog.csdnimg.cn/20200425135042227.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70" alt="评论信息"><br>我们可以使用<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tree.xpath(<span class="string">'//td[@class=“postbody”]'</span>)</span><br></pre></td></tr></table></figure><br>我们需要注意的是，当我们将文本对象转换为了 lxml 对象后，实际获取内容的方式也发生了改变，参看下面代码：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">text = <span class="string">'''</span></span><br><span class="line"><span class="string">&lt;div&gt;</span></span><br><span class="line"><span class="string">    &lt;ul&gt;</span></span><br><span class="line"><span class="string">         &lt;li class="item-0"&gt;&lt;a href="link1.html"&gt;first item&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">         &lt;li class="item-1"&gt;&lt;a href="link2.html"&gt;second item&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">         &lt;li class="item-inactive"&gt;&lt;a href="link3.html"&gt;third item&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">         &lt;li class="item-1"&gt;&lt;a href="link4.html"&gt;fourth item&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">         &lt;li class="item-0"&gt;&lt;a href="link5.html"&gt;fifth item&lt;/a&gt;</span></span><br><span class="line"><span class="string">     &lt;/ul&gt;</span></span><br><span class="line"><span class="string"> &lt;/div&gt;</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">html = etree.HTML(text)</span><br><span class="line"><span class="comment"># 返回 &lt;Element html at 0x233468e5788&gt;</span></span><br><span class="line">result = etree.tostring(html)</span><br><span class="line">print(result)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回 text 中信息</span></span><br></pre></td></tr></table></figure></p>
<h1 id="代理-IP-爬取"><a href="#代理-IP-爬取" class="headerlink" title="代理 IP 爬取"></a>代理 IP 爬取</h1><p>介绍完 xpath 的基本内容，我们下面来实战一个非常有用的爬虫 —— 爬取代理IP，其具体页面内容如下：<br><img src="https://img-blog.csdnimg.cn/20200425133902765.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="西刺代理IP主页"><br>我们点击查看源代码，可以发现相关的IP地址直接出现在页面中，因此我们能够通过现有知识进行爬取：</p>
<p><img src="https://img-blog.csdnimg.cn/20200425134041233.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="西刺代理IP主页源代码"><br>下面是测试代码：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>url = <span class="string">"https://www.xicidaili.com/"</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>headers = &#123;<span class="string">"user-agent"</span>:<span class="string">"Mozilla/5.0"</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>res = requests.get(url, headers=headers)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>res.status_code</span><br><span class="line"><span class="number">200</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>res.encoding = res.apparent_encoding</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>text = res.text</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>html = etree.HTML(text)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>html.xpath(<span class="string">'/html/body/div[1]/div[2]/div[1]/div[1]/table/tbody/tr[3]/td[2]'</span>)</span><br><span class="line">[]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ip_ = html.xpath(<span class="string">'/html/body/div[1]/div[2]/div[1]/div[1]/table//tr[3]/td[2]'</span>)</span><br><span class="line">[&lt;Element td at <span class="number">0x233473b8d08</span>&gt;]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>result = etree.tostring(ip_[<span class="number">0</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>result</span><br><span class="line"><span class="string">b'&lt;td&gt;119.4.13.26&lt;/td&gt;\n</span></span><br></pre></td></tr></table></figure></p>
<p>事实上，我们在实际使用时，想要获得 Xpath 不一定会直接一行行代码看过去，更可能直接复制 Xpath：</p>
<p><img src="https://img-blog.csdnimg.cn/20200425140302427.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="查看器获取 Xpath"></p>
<p>我们右键移至复制，会出现一个名为“复制Xpath”的选项，点击复制Xpath 后即可得到相应的 Xpath，但在这里有一点需要注意的是，Xpath 会给页面 HTML 树进行自动补齐，也就是说会出现一些原来没有的东西，就会出现上面代码中倒数第六行出现空返回的问题，这时候就需要我们去仔细检查哪里的信息可能是多余的。</p>
<p>下面我们展示完整代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle<span class="comment">#我们封装数据要用到的库</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="comment">#请求头</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.162 Safari/537.36'</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">construct_url</span><span class="params">()</span>:</span><span class="comment">#老样子，先构建url列表，我这就爬一页</span></span><br><span class="line">    urls = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range (<span class="number">1</span>,<span class="number">2</span>):</span><br><span class="line">        url = <span class="string">'https://www.xicidaili.com/nn/'</span>+str(i)</span><br><span class="line">        urls.append(url)</span><br><span class="line">    <span class="keyword">return</span> urls</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_proxy</span><span class="params">(url)</span>:</span><span class="comment">#从数据中解析出ip数据，并验证ip是否可用</span></span><br><span class="line">    res = requests.get(url,headers=headers)</span><br><span class="line">    html = etree.HTML(res.text,etree.HTMLParser())</span><br><span class="line">    <span class="comment">#把返回的数据解析成etree._Element对象，这样才可以使用Xpath语句提取数据</span></span><br><span class="line">    ip = html.xpath(<span class="string">'//*[@id="ip_list"]/tr/td[2]/text()'</span>)<span class="comment">#ip</span></span><br><span class="line">    ip_port = html.xpath(<span class="string">'//*[@id="ip_list"]/tr/td[3]/text()'</span>)<span class="comment">#端口号</span></span><br><span class="line">    ip_type = html.xpath(<span class="string">'//*[@id="ip_list"]/tr/td[6]/text()'</span>)<span class="comment">#网络类型</span></span><br><span class="line"></span><br><span class="line">    lis = []</span><br><span class="line">    <span class="keyword">for</span> i,j,k <span class="keyword">in</span> zip(ip,ip_port,ip_type):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            proxies = &#123;</span><br><span class="line">                    k.lower():i+<span class="string">':'</span>+j<span class="comment">#注意到爬下来的是HTTP或者是HTTPS，我们要将它们变成http或https</span></span><br><span class="line">                    &#125;</span><br><span class="line">            print(proxies)<span class="comment">#把IP输出来看看</span></span><br><span class="line">            requests.get(<span class="string">'https://www.baidu.com/'</span>,headers=headers,timeout=<span class="number">1</span>,proxies=proxies)</span><br><span class="line">            <span class="comment">#用这个IP发一个请求给百度，测试一下这个IP能不能用</span></span><br><span class="line">            lis.append(proxies)<span class="comment">#如果没有超时，说明能用，存进列表里</span></span><br><span class="line">            print(<span class="string">'http://'</span>+i+<span class="string">':'</span>+j+<span class="string">" is fine"</span>)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            print(<span class="string">'http://'</span>+i+<span class="string">':'</span>+j+<span class="string">" is timeout"</span>)<span class="comment">#超时抛出错误，输出哪个IP超时</span></span><br><span class="line">    <span class="keyword">return</span> lis<span class="comment">#返回可用IP列表</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    urls = construct_url()</span><br><span class="line">    lis = []</span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">        rlist = get_proxy(url)</span><br><span class="line">        lis += rlist</span><br><span class="line">    pickle.dump(lis,open(<span class="string">'ip.pkl'</span>,<span class="string">'wb'</span>))<span class="comment">#将可用的IP进行存储</span></span><br><span class="line">    print(<span class="string">'----可用IP---'</span>)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> lis:</span><br><span class="line">        print(item)</span><br><span class="line">    print(<span class="string">'---  END  ---'</span>)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Spider</category>
      </categories>
  </entry>
  <entry>
    <title>MySQL入门（八）子查询</title>
    <url>/posts/9a307df7.html</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>Python爬虫初级（七）—— 丁香园评论留言板爬取</title>
    <url>/posts/4905f1d8.html</url>
    <content><![CDATA[<h1 id="观察待爬取页面，判断爬取可行性"><a href="#观察待爬取页面，判断爬取可行性" class="headerlink" title="观察待爬取页面，判断爬取可行性"></a>观察待爬取页面，判断爬取可行性</h1><p>我们首先查看待爬取页面：<a href="http://www.dxy.cn/bbs/thread/626626#626626" target="_blank" rel="noopener">http://www.dxy.cn/bbs/thread/626626#626626</a> ，具体形式为下图：<br><img src="https://img-blog.csdnimg.cn/20200425085817786.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70" alt="丁香园待爬取页面">我们查看源代码信息：<br><img src="https://img-blog.csdnimg.cn/20200425085925913.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="页面源代码">可以发现留言板块的内容在页面源代码全部直接显示了出来，那么我们可以尝试直接进行爬取，我们采取的思路首先是 <a href="https://blog.csdn.net/ChenKai_164/article/details/105610353" target="_blank" rel="noopener">requests 库</a> + <a href="https://blog.csdn.net/ChenKai_164/article/details/105625042" target="_blank" rel="noopener">bs4 库</a>，这两者的具体用法在前面的文章均已涉及。</p>
<h1 id="检测爬取链接，初步尝试爬取"><a href="#检测爬取链接，初步尝试爬取" class="headerlink" title="检测爬取链接，初步尝试爬取"></a>检测爬取链接，初步尝试爬取</h1><p>首先我们可以在IDLE上检查爬取链接是否正常，直接展示代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>url = <span class="string">"http://www.dxy.cn/bbs/thread/626626#626626"</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>headers = &#123;<span class="string">"user-agent"</span>:<span class="string">"Mozilla/5.0"</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>res = requests.get(url, headers=headers, stream=<span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>res.status_code</span><br><span class="line"><span class="number">200</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>text = res.text</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(text)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>text[<span class="number">1000</span>:<span class="number">1300</span>]</span><br><span class="line"><span class="string">'og:description" content="我遇到一个“怪”病人，向大家请教。她，42岁。反复惊吓后晕厥30余年。每次受响声惊吓后发生跌倒，短暂意识丧失。无逆行性遗忘，无抽搐，无口吐白沫，无大小便失禁。多次跌倒致外伤。婴儿时有惊厥史。入院查体无殊。ECG、24小时动态心电图无殊；头颅MRI示小软化灶；脑电图无殊。入院后有数次类似发作。请问该患者该做何诊断，还需做什么检查，治疗方案怎样？"/&gt;\n        &lt;meta property="og:author" content="楼医生"/&gt;\n        &lt;meta property="og:release_date" content'</span></span><br></pre></td></tr></table></figure>
<p>我们想要抓取链接，先在上面的源代码中对标题层级结构进行分析:<br><img src="https://img-blog.csdnimg.cn/20200425091636816.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="标题代码"></p>
<p>然后直接写出相关代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>title = soup(<span class="string">"div"</span>, id=<span class="string">"postview"</span>)[<span class="number">0</span>].tr.th.h1.contents[<span class="number">0</span>]</span><br><span class="line">[<span class="string">'\n                    晕厥待查——请教各位同仁                 '</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>title = title.replace(<span class="string">" "</span>, <span class="string">""</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>title = title.replace(<span class="string">"\n"</span>, <span class="string">""</span>)</span><br><span class="line">&gt;&gt;&gt;&gt; title</span><br><span class="line"><span class="string">'晕厥待查——请教各位同仁'</span></span><br></pre></td></tr></table></figure>
<p>下面同理可以查看其他信息，下面我们为了便于操作直接采用 CSS 类名查找：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>context = soup.select(<span class="string">"[class~=postbody]"</span>)</span><br><span class="line"><span class="comment"># 返回所有内容信息</span></span><br></pre></td></tr></table></figure>
<p>返回的信息内容如下：<br><img src="https://img-blog.csdnimg.cn/20200425093131992.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="爬取返回内容">对内容进行清理：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>cont = context[<span class="number">1</span>].contents[<span class="number">0</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cont = cont.replace(<span class="string">" "</span>, <span class="string">""</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cont = cont.replace(<span class="string">"\n"</span>, <span class="string">""</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cont</span><br><span class="line"><span class="string">'从发作的症状上比较符合血管迷走神经性晕厥，直立倾斜试验能协助诊断。在行直立倾斜实验前应该做常规的体格检查、ECG、UCG、holter和X-ray胸片除外器质性心脏病。'</span></span><br></pre></td></tr></table></figure>
<p>测试代码写完后，我们写出完整代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTML</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        headers = &#123;<span class="string">"user-agent"</span>:<span class="string">"Mozilla/5.0"</span>&#125;</span><br><span class="line">        res = requests.get(url, headers=headers, stream=<span class="literal">True</span>)</span><br><span class="line">        res.raise_for_status</span><br><span class="line">        res.encoding = res.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> res.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">""</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ParseFromPage</span><span class="params">(html)</span>:</span></span><br><span class="line">    commentList = []</span><br><span class="line">    soup = BeautifulSoup(html)</span><br><span class="line">    title = soup(<span class="string">"div"</span>, id=<span class="string">"postview"</span>)[<span class="number">0</span>].tr.th.h1.contents[<span class="number">0</span>]</span><br><span class="line">    title = title.replace(<span class="string">" "</span>, <span class="string">""</span>)</span><br><span class="line">    title = title.replace(<span class="string">"\n"</span>, <span class="string">""</span>)</span><br><span class="line">    context = soup.select(<span class="string">"[class~=postbody]"</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(context)):</span><br><span class="line">        cont = context[i].contents[<span class="number">0</span>]</span><br><span class="line">        cont = cont.replace(<span class="string">" "</span>, <span class="string">""</span>)</span><br><span class="line">        commentList.append(cont)</span><br><span class="line">    <span class="keyword">return</span> title, commentList</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    base_url = <span class="string">"http://www.dxy.cn/bbs/thread/626626#626626"</span></span><br><span class="line">    html = getHTML(base_url)</span><br><span class="line">    title, cList = ParseFromPage(html)</span><br><span class="line">    print(title, cList)</span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>
<h1 id="拓展一"><a href="#拓展一" class="headerlink" title="拓展一"></a>拓展一</h1><p>我们爬取完单一页面后，我们可以考虑，是否可以爬取更多的页面。我们的思考出发点是丁香园每个页面的链接下面都会存在一个引向其他同类型页面的链接，比如：<br><img src="https://img-blog.csdnimg.cn/2020042510254560.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="链接抓取">我们可以看到，下面的 “骨折手术后一周突发心跳骤停，抢救无效死亡，什么原因？”这段话不就是我们要找的链接，点开后也确实如我们所料，页面结构的解析和本页面的解析一样，我们完全可以复用这段代码，只需要改变一下 url 即可。下面我们尝试通过 re 库获取此 url 链接：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>href = re.findall(<span class="string">r'&amp;#149; &lt;a href="(.*?)" target'</span>, text)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>href</span><br><span class="line">[<span class="string">'http://job.dxy.cn/bbs/topic/43200651'</span>, <span class="string">'http://www.dxy.cn/bbs/topic/43177945'</span>, <span class="string">'http://Radiology.dxy.cn/bbs/topic/43179123'</span>, <span class="string">'http://www.dxy.cn/bbs/topic/43172871'</span>]</span><br></pre></td></tr></table></figure>
<p>这里我们看到有四个链接，但并不是每个链接都是我们需要的，通过观察后我们发现，只有以 “<a href="http://www.dxy.cn/bbs/topic" target="_blank" rel="noopener">http://www.dxy.cn/bbs/topic</a>“ 开头的链接才是我们需要的，我们可以将查找链接的方式改为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>re.findall(<span class="string">r'&lt;a href="(http://www.dxy.cn/bbs/topic/.*?) target="_blank"'</span>,text)</span><br><span class="line">[<span class="string">'http://www.dxy.cn/bbs/topic/43177945"'</span>, <span class="string">'http://www.dxy.cn/bbs/topic/43172871"'</span>]</span><br></pre></td></tr></table></figure>
<p>我们看到返回了两个正确结果，为了不增大网站压力，我们修改主函数，仅仅爬取十条链接的内容，并存储到 dxy.txt 文件中，主函数代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    base_url = <span class="string">"http://www.dxy.cn/bbs/thread/626626#626626"</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        html = getHTML(base_url)</span><br><span class="line">        title, cList = ParseFromPage(html)</span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">"dxy.txt"</span>, <span class="string">"a"</span>, encoding=<span class="string">"utf-8"</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(title)</span><br><span class="line">            f.write(<span class="string">"\n"</span>)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(cList)):</span><br><span class="line">                f.write(cList[i])</span><br><span class="line">                f.write(<span class="string">"\n"</span>)</span><br><span class="line">            f.write(<span class="string">"\n"</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            url_list = re.findall(<span class="string">r'&lt;a href="(http://www.dxy.cn/bbs/topic/.*?) target="_blank"'</span>,html)</span><br><span class="line">            base_url = url_list[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br></pre></td></tr></table></figure>
<p>此代码应能正确爬取链接，代码规范有待网友指正。</p>
<h1 id="拓展二"><a href="#拓展二" class="headerlink" title="拓展二"></a>拓展二</h1><p>我们还可以使用 lxml 爬取内容，事实上此代码会更加简洁, lxml 的具体用法将在下期内容展开，以下直接简单使用之：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> html, etree</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tree1 = html.tostring(tree.xpath(<span class="string">'//td[@class="postbody"]'</span>)[<span class="number">1</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>txt = HTMLParser().unescape(tree1.decode(<span class="string">'utf-8'</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>txt.replace(<span class="string">" "</span>,<span class="string">""</span>)</span><br><span class="line"><span class="string">'&lt;tdclass="postbody"&gt;\n\n从发作的症状上比较符合血管迷走神经性晕厥，直立倾斜试验能协助诊断。在行直立倾斜实验前应该做常规的体格检查、ECG、UCG、holter和X-ray胸片除外器质性心脏病。&lt;br&gt;&lt;br&gt;贴一篇“口服氨酰心安和依那普利治疗血管迷走性晕厥的疗效观察”&lt;br&gt;作者：林文华任自文丁燕生&lt;br&gt;&lt;br&gt;&lt;ahref="http://www.ccheart.com.cn/ccheart_site/Templates/jieru/200011/1-1.htm"target="_blank"class="ilink"rel="nofollow"&gt;http://www.ccheart.com.cn/ccheart_site/Templates/jieru/200011/1-1.htm&lt;/a&gt;\n\t&lt;/td&gt;\n'</span>                           <span class="string">'</span></span><br></pre></td></tr></table></figure>
<p>其他信息的抽取以及代码的结构化同上即可。</p>
]]></content>
      <categories>
        <category>Spider</category>
      </categories>
  </entry>
  <entry>
    <title>MySQL入门（七）连接查询</title>
    <url>/posts/2517aedb.html</url>
    <content><![CDATA[<h1 id="一、连接查询基础"><a href="#一、连接查询基础" class="headerlink" title="一、连接查询基础"></a>一、连接查询基础</h1><p>我们已经学会了如何在一张表中读取数据，这是相对简单的，但是在真正的应用中经常需要从多个数据表中读取数据。现在将向大家介绍如何使用 <code>MySQL</code> 的<code>JOIN</code> 在两个或多个表中查询数据。</p>
<p>你可以在 <code>SELECT</code>, <code>UPDATE</code> 和 <code>DELETE</code> 语句中使用 Mysql 的 <code>JOIN</code> 来联合多表查询。<code>JOIN</code> 按照功能大致分为如下三类：</p>
<ul>
<li><strong>INNER JOIN（内连接,或等值连接）</strong>：获取两个表中字段匹配关系的记录。</li>
<li><strong>LEFT JOIN（左连接）：</strong>获取左表所有记录，即使右表没有对应匹配的记录。</li>
<li><strong>RIGHT JOIN（右连接）：</strong> 与 LEFT JOIN 相反，用于获取右表所有记录，即使左表没有对应匹配的记录。</li>
</ul>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>Python爬虫初级（六）—— 正则表达式库入门</title>
    <url>/posts/617da02a.html</url>
    <content><![CDATA[<p>正则表达式，即 RE，是 regular expression 的简称，是用来简洁表达一组字符串的表达式。</p>
<h1 id="正则表达式的语法"><a href="#正则表达式的语法" class="headerlink" title="正则表达式的语法"></a>正则表达式的语法</h1><div class="table-container">
<table>
<thead>
<tr>
<th>操 作 符</th>
<th>说 明</th>
<th>正 则 表 达 式 样 例</th>
</tr>
</thead>
<tbody>
<tr>
<td> .</td>
<td>匹配任何字符（换行符除外）</td>
<td>b.b</td>
</tr>
<tr>
<td>[…]</td>
<td>匹配字符组里出现的任意一个字符</td>
<td>[abcd]</td>
</tr>
<tr>
<td>*</td>
<td>匹配前面出现的正则表达式零次或多次</td>
<td>abc*</td>
</tr>
<tr>
<td>+</td>
<td>匹配前面出现的正则表达式一次或多次</td>
<td>abc+</td>
</tr>
<tr>
<td>？</td>
<td>匹配前面出现的正则表达式零次或一次</td>
<td>abc?</td>
</tr>
<tr>
<td>\</td>
<td></td>
<td>匹配左或右任意一个正则表达式</td>
<td>re1</td>
<td>re2</td>
</tr>
<tr>
<td>{A}</td>
<td>匹配前面出现的正则表达式A次</td>
<td>[0-9]{5}</td>
</tr>
<tr>
<td>{A, B}</td>
<td>匹配前面出现的正则表达式A-B次（含B）</td>
<td>[0-9]{1, 5}</td>
</tr>
<tr>
<td>^</td>
<td>匹配字符串的开始</td>
<td>^abc</td>
</tr>
<tr>
<td>$</td>
<td>匹配字符串的结束</td>
<td>abc$</td>
</tr>
<tr>
<td>[…a-b…]</td>
<td>匹配从字符a-b中的任意一个字符</td>
<td>[0-9],[A-Za-z]</td>
</tr>
<tr>
<td><sup><a href="#fn_..." id="reffn_...">...</a></sup></td>
<td>不匹配此字符集中出现的任何一个字符， 包括某一范围的字符</td>
<td><sup><a href="#fn_abc" id="reffn_abc">abc</a></sup>, <sup><a href="#fn_a-z" id="reffn_a-z">a-z</a></sup></td>
</tr>
<tr>
<td>(…)</td>
<td>匹配封闭括号中的正则表达式，并保存为子组</td>
<td>（[1-3]{2})</td>
</tr>
<tr>
<td>\d</td>
<td>匹配任何数字</td>
<td>\d.txt</td>
</tr>
<tr>
<td>\w</td>
<td>匹配任何数字字母字符（包括_),\W与\w作用相反</td>
<td>\w? </td>
</tr>
<tr>
<td>\s</td>
<td>匹配任何空白符，等价于[\n\s\r\v\f]，\S与\s作用相反</td>
<td>\s?</td>
</tr>
<tr>
<td>\b</td>
<td>匹配单词边界，\B与\b作用相反</td>
<td>\bMonkey\b</td>
</tr>
<tr>
<td>\nn</td>
<td>匹配已保存的子组      </td>
</tr>
<tr>
<td>\c</td>
<td>逐一匹配特殊字符c      </td>
</tr>
<tr>
<td>\A(\Z)</td>
<td>匹配字符串的起始（结束）</td>
<td>\ATest</td>
</tr>
</tbody>
</table>
</div>
<p>我们可以举一些其他常用例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">^[A - Z a - z]+$ 表示由26个字母组成的字符串</span><br><span class="line">^[A - Z a - z 0 - 9]+$ 表示由26个字母和数字组成的字符串</span><br><span class="line">^-?\d+$ 表示整数形式的字符串（有正负）</span><br><span class="line">[1-9]\d&#123;5&#125; 表示中国境内邮政编码，6位</span><br><span class="line">[\u4e00 - \u9fa5] 匹配中文字符</span><br><span class="line">\d&#123;3&#125; - \d&#123;8&#125; | \d&#123;4&#125; - \d&#123;7&#125; 匹配国外电话号码</span><br></pre></td></tr></table></figure>
<p>我们思考一下，我们应该怎么匹配 IP 地址呢？<br>我们知道，IP 地址分为4段，每段取值范围是 0-255，那么我们会考虑到根据这256个数字的特殊性进行划分，比如：<br>1、当取值为 0-99 时，我们可以记为 [1-9] ? \d<br>2、当取值为 100-199 时，我们可以记为 1\d{2}<br>3、当取值为 200-249 时，我们可以记为 2[0-4]\d<br>4、当取值为 250-255 时，我们可以记为 25[0-5]<br>我们只需要将每个区间按 | 预算符进行划分即可获得每段 IP 地址的正确表达式。</p>
<h1 id="Re-库的基本使用"><a href="#Re-库的基本使用" class="headerlink" title="Re 库的基本使用"></a>Re 库的基本使用</h1><p>我们先介绍 Re 库的主要功能函数：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>函数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>re.search()</td>
<td>在一个字符串中搜索匹配正则表达式的第一个位置，返回 match 对象</td>
</tr>
<tr>
<td>re.match()</td>
<td>从一个字符串的开始位置起匹配正则表达式，返回 match 对象</td>
</tr>
<tr>
<td>re.findall()</td>
<td>搜索字符串，以列表类型返回全部能匹配的子串</td>
</tr>
<tr>
<td>re.split()</td>
<td>将一个字符串按照正则表达式匹配结果进行分割，返回列表类型</td>
</tr>
<tr>
<td>re.finditer()</td>
<td>搜索字符串，返回一个匹配结果的迭代类型，每个迭代元素是 match 对象</td>
</tr>
<tr>
<td>re.sub()</td>
<td>在一个字符串中替换所有匹配正则表达式的子串，返回替换后的字符串</td>
</tr>
</tbody>
</table>
</div>
<p>下面一一介绍这六个函数：</p>
<h3 id="re-search-pattern-string-flags-0"><a href="#re-search-pattern-string-flags-0" class="headerlink" title="re.search(pattern, string, flags=0)"></a>re.search(pattern, string, flags=0)</h3><p>其中 pattern 是正则表达式的字符串或原生字符串表示，string 是待匹配字符串，flags 是正则表达式使用时的控制标记。<br>flags 的控制常用标记如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>常用标记</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>re.I re.IGNORECASE</td>
<td>忽略正则表达式的大小写，[A-Z] 能够匹配小写字符</td>
</tr>
<tr>
<td>re.M re.MULTILINE</td>
<td>正则表达式中的 ^ 操作符能够将给定字符串的每行当作匹配开始</td>
</tr>
<tr>
<td>re.S re.DOTAIL</td>
<td>正则表达式中的 . 操作能够匹配所有字符，默认匹配除换行外的所有字符</td>
</tr>
</tbody>
</table>
</div>
<p>下面是一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>match = re.search(<span class="string">r'[1-9]\d&#123;5&#125;'</span>,<span class="string">'BIT 100081'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">if</span> match:</span><br><span class="line">		print(match.group(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line"><span class="number">100081</span></span><br></pre></td></tr></table></figure>
<h3 id="re-match-pattern-string-flags-0"><a href="#re-match-pattern-string-flags-0" class="headerlink" title="re.match(pattern, string, flags=0)"></a>re.match(pattern, string, flags=0)</h3><p>match 对象的三个参数和标记都与 search 对象相同，我们直接看一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>match = re.match(<span class="string">r'[0-9]\d&#123;5&#125;'</span>, <span class="string">'BIT 100081'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">if</span> match:</span><br><span class="line">	match.group(<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 无结果</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>match.group(<span class="number">0</span>)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"&lt;pyshell#15&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    match.group(<span class="number">0</span>)</span><br><span class="line">AttributeError: <span class="string">'NoneType'</span> object has no attribute <span class="string">'group'</span></span><br></pre></td></tr></table></figure>
<p>我们发现上述代码的 match 对象并没有任何结果返回，也就是说这个对象是空的，因为我们知道 match 是从头开始匹配，而字符串的头为 ‘BIT’，自然匹配错误。我们换一下字符串的表示，看看是否能匹配出相关结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>match = re.match(<span class="string">r'[1-9]\d&#123;5&#125;'</span>,<span class="string">'100081 BIT'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">if</span> match:</span><br><span class="line">	match.group(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">'100081'</span></span><br></pre></td></tr></table></figure>
<p>这印证了我们上面的讨论</p>
<h3 id="re-findall-pattern-string-flags-0"><a href="#re-findall-pattern-string-flags-0" class="headerlink" title="re.findall(pattern, string, flags=0)"></a>re.findall(pattern, string, flags=0)</h3><p>我们直接看例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ls = re.findall(<span class="string">r'[1-9]\d&#123;5&#125;'</span>, <span class="string">'BIT100081 TSU100084'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ls</span><br><span class="line">[<span class="string">'100081'</span>, <span class="string">'100084'</span>]</span><br></pre></td></tr></table></figure>
<h3 id="re-split-pattern-string-maxsplit-0-flags-0"><a href="#re-split-pattern-string-maxsplit-0-flags-0" class="headerlink" title="re.split(pattern, string, maxsplit=0, flags=0)"></a>re.split(pattern, string, maxsplit=0, flags=0)</h3><p>split 函数的三个参数我们都已经熟知，中间新增加的参数 maxsplit 表示最大分割数，剩余部分作为最后一个元素输出，下面看看例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ls = re.findall(<span class="string">r'[1-9]\d&#123;5&#125;'</span>, <span class="string">'BIT100081 TSU100084'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ls</span><br><span class="line">[<span class="string">'100081'</span>, <span class="string">'100084'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>re.split(<span class="string">r'[1-9]\d&#123;5&#125;'</span>, <span class="string">'BIT100081 TSU100084'</span>)</span><br><span class="line">[<span class="string">'BIT'</span>, <span class="string">' TSU'</span>, <span class="string">''</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>re.split(<span class="string">r'[1-9]\d&#123;5&#125;'</span>, <span class="string">'BIT100081 TSU100084'</span>, maxsplit=<span class="number">1</span>)</span><br><span class="line">[<span class="string">'BIT'</span>, <span class="string">' TSU100084'</span>]</span><br></pre></td></tr></table></figure>
<h3 id="re-finditer-pattern-string-flags-0"><a href="#re-finditer-pattern-string-flags-0" class="headerlink" title="re.finditer(pattern, string, flags=0)"></a>re.finditer(pattern, string, flags=0)</h3><p>我们直接看代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> m <span class="keyword">in</span> re.finditer(<span class="string">r'[1-9]\d&#123;5&#125;'</span>, <span class="string">'BIT100081 TSU100084'</span>):</span><br><span class="line">	<span class="keyword">if</span> m:</span><br><span class="line">		print(m.group(<span class="number">0</span>))</span><br><span class="line"><span class="number">100081</span></span><br><span class="line"><span class="number">100084</span></span><br></pre></td></tr></table></figure>
<h3 id="re-sub-pattern-repl-string-count-0-flags-0"><a href="#re-sub-pattern-repl-string-count-0-flags-0" class="headerlink" title="re.sub(pattern, repl, string, count=0, flags=0)"></a>re.sub(pattern, repl, string, count=0, flags=0)</h3><p>我们可以看到所有参数中新增了两个参数，repl 是指替换匹配字符串的字符串，而 count 是匹配的最大替换次数，下面我们看一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>re.sub(<span class="string">r'[1-9]\d&#123;5&#125;'</span>, <span class="string">'zipcode'</span>, <span class="string">'BIT100081 TSU100084'</span>)</span><br><span class="line"><span class="string">'BITzipcode TSUzipcode'</span></span><br></pre></td></tr></table></figure>
<h3 id="Re-库的另一种等价用法"><a href="#Re-库的另一种等价用法" class="headerlink" title="Re 库的另一种等价用法"></a>Re 库的另一种等价用法</h3><p>我们上面给出的函数例子都是函数使用法，也就是仅支持一次性操作的用法，这是什么意思呢，我们对比一下下面的面向对象用法就知道了：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pat = re.compile(<span class="string">r'[1-9]\d&#123;5&#125;'</span>)</span><br><span class="line">rst = pat.search(<span class="string">'BIT 100081'</span>)</span><br></pre></td></tr></table></figure>
<p>re.compile 函数的完整形式是：re.compile(pattern, flags=0)，该函数将正则表达式的字符串形式编译成正则表达式对象。编译后才是一个正则表达式，表示一组字符串。</p>
<h1 id="Re-库的-Match-对象"><a href="#Re-库的-Match-对象" class="headerlink" title="Re 库的 Match 对象"></a>Re 库的 Match 对象</h1><p>Match 就是一次匹配的结果，它返回了匹配的相关信息，我们直接看前面的一个代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>match = re.match(<span class="string">r'[1-9]\d&#123;5&#125;'</span>,<span class="string">'100081 BIT'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">if</span> match:</span><br><span class="line">	match.group(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">'100081'</span></span><br></pre></td></tr></table></figure>
<p>在这里我们想看一下 match 的类型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>type(match)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">re</span>.<span class="title">Match</span>'&gt;</span></span><br></pre></td></tr></table></figure>
<p>Match 对象有很多属性，下面我们重点介绍4个属性：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>属性</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>.string</td>
<td>待匹配的文本</td>
</tr>
<tr>
<td>.re</td>
<td>匹配时使用的 pattern 对象（正则表达式）</td>
</tr>
<tr>
<td>.pos</td>
<td>正则表达式搜索文本的开始位置</td>
</tr>
<tr>
<td>.endpos</td>
<td>正则表达式搜索文本的结束位置</td>
</tr>
</tbody>
</table>
</div>
<p>Match 对象有很多方法，下面列举4个常用对象：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>方法</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>.group(0)</td>
<td>获得匹配后的字符串</td>
</tr>
<tr>
<td>.start()</td>
<td>匹配字符串在原始字符串的开始位置</td>
</tr>
<tr>
<td>.end()</td>
<td>匹配字符串在原始字符串的结束位置</td>
</tr>
<tr>
<td>.span()</td>
<td>返回 (.start(), .end())</td>
</tr>
</tbody>
</table>
</div>
<p>我们看一下相关例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = re.search(<span class="string">r'[1-9]\d&#123;5&#125;'</span>, <span class="string">'BIT100081 TSU100084'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.string</span><br><span class="line"><span class="string">'BIT100081 TSU100084'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.re</span><br><span class="line">re.compile(<span class="string">'[1-9]\\d&#123;5&#125;'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.pos</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.endpos</span><br><span class="line"><span class="number">19</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.group(<span class="number">0</span>)</span><br><span class="line"><span class="string">'100081'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.start()</span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.end()</span><br><span class="line"><span class="number">9</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.span()</span><br><span class="line">(<span class="number">3</span>, <span class="number">9</span>)</span><br></pre></td></tr></table></figure>
<h1 id="Re-库的贪婪匹配和最小匹配"><a href="#Re-库的贪婪匹配和最小匹配" class="headerlink" title="Re 库的贪婪匹配和最小匹配"></a>Re 库的贪婪匹配和最小匹配</h1><p>首先我们看一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>match = re.search(<span class="string">r'PY.*N'</span>, <span class="string">'PYANBNCNDN'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>match.group(<span class="number">0</span>)</span><br><span class="line"><span class="string">'PYANBNCNDN'</span></span><br></pre></td></tr></table></figure>
<p>其中的 ‘.*‘ 表示匹配任意字符串，这里我们应该留意到， Re 库默认采用贪婪匹配，即输出匹配最长的子串。那么我们应该如何实现输出最短的子串呢？<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>match = re.search(<span class="string">r'PY.*?N'</span>, <span class="string">'PYANBNCNDN'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>match.group(<span class="number">0</span>)</span><br><span class="line"><span class="string">'PYAN'</span></span><br></pre></td></tr></table></figure></p>
<p>最小匹配操作符有下面四种：<br>操作符 | 说明<br>———|———<br>*? | 前一个字符0次或无限次扩展<br>+? | 前一个字符1次或无限次扩展<br>?? | 前一个字符0次或1次扩展<br>{m,n}? | 扩展前一个字符 m 至 n 次（含 n）</p>
]]></content>
      <categories>
        <category>Spider</category>
      </categories>
  </entry>
  <entry>
    <title>MySQL入门（六）分组查询</title>
    <url>/posts/ceaf7866.html</url>
    <content><![CDATA[<p>本文数据集下载链接：<a href="https://pan.baidu.com/s/1sVcSXfVZimc6ruyMr4Gr3g" target="_blank" rel="noopener">https://pan.baidu.com/s/1sVcSXfVZimc6ruyMr4Gr3g</a> ，提取码：7gfa </p>
<h1 id="一、分组函数简介"><a href="#一、分组函数简介" class="headerlink" title="一、分组函数简介"></a>一、分组函数简介</h1><p><code>GROUP BY</code> 语句根据一个或多个列对结果集进行分组，在分组的列上我们可以使用 <code>COUNT, SUM, AVG</code>等函数。</p>
<p><strong>功能</strong>：用于统计，又称为聚合函数或统计函数或组函数</p>
<p><strong>分类</strong>：<code>sum</code>求和，<code>avg</code>平均值，<code>max</code>最大值，<code>min</code>最小值，<code>count</code>计算个数</p>
<p><strong>特点</strong>：</p>
<ol>
<li><code>SUM, AVG</code>一般处理数值型， <code>MAX, MIN, COUNT</code>可以处理任何类型</li>
<li>是否忽略<code>NULL</code>值：所有分组函数都忽略<code>NULL</code>值</li>
<li>可以和<code>DISTINCT</code>搭配实现去重运算</li>
<li><code>COUNT</code>函数的专门介绍</li>
</ol>
<h2 id="1-简单使用"><a href="#1-简单使用" class="headerlink" title="1. 简单使用"></a>1. 简单使用</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT SUM(salary) FROM employees;</span><br><span class="line">SELECT AVG(salary) FROM employees;</span><br><span class="line">SELECT MIN(salary) FROM employees;</span><br><span class="line">SELECT MAX(salary) FROM employees;</span><br><span class="line">SELECT COUNT(salary) FROM employees; </span><br><span class="line">SELECT SUM(salary) 和, ROUND(AVG(salary), 2) 平均, MAX(salary) 最高, MIN(salary) 最低, COUNT(salary) FROM employees;</span><br></pre></td></tr></table></figure>
<h2 id="2-参数类型"><a href="#2-参数类型" class="headerlink" title="2. 参数类型"></a>2. 参数类型</h2><p>以下为无意义但不报错的使用方式：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT SUM(last_name), AVG(last_name) </span><br><span class="line">FROM employees;</span><br></pre></td></tr></table></figure>
<p>同理还有对日期求和等，也是无意义的。以下使用方式是合理的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT MAX(last_name), MIN(last_name) </span><br><span class="line">FROM employees;</span><br></pre></td></tr></table></figure>
<p>这是因为可以按照首字母排序，于是也有最大值和最小值，同理对日期求最大最小值也是可以的</p>
<p>也可以使用<code>COUNT</code>语句对其他类型求和：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT COUNT(commission_pct), COUNT(last_name) </span><br><span class="line">FROM employees;</span><br><span class="line"># 返回35和107</span><br></pre></td></tr></table></figure>
<p>两者不同是因为<code>COUNT</code>返回 不为NULL的个数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT SUM(DISTINCT salary), sum(salary) </span><br><span class="line">FROM employees;</span><br></pre></td></tr></table></figure>
<h2 id="3-COUNT函数详解"><a href="#3-COUNT函数详解" class="headerlink" title="3. COUNT函数详解"></a>3. <code>COUNT</code>函数详解</h2><p><strong>统计总行数</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT COUNT(*) </span><br><span class="line">FROM employees;</span><br></pre></td></tr></table></figure>
<p>每一行中只要有不为<code>NULL</code>的计数器就加一，同理也可以使用以下方式统计总行数：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT COUNT(1) </span><br><span class="line">FROM employees;</span><br></pre></td></tr></table></figure>
<p>事实上，<code>COUNT()</code>中的常量值可以取任何值获得同样的效果，但就效率而言</p>
<ul>
<li>在MYISAM存储引擎下，<code>COUNT(*)</code>的效率高</li>
<li>在INNODB存储引擎下，<code>COUNT(*)</code>的效率和<code>COUNT(1)</code>差不多，但比<code>COUNT(字段)</code>效率高</li>
</ul>
<p>因此一般使用<code>COUNT(*)</code>来统计行数</p>
<p><strong>注意：和分组函数一同查询的字段有限制(要求是group by后的字段)</strong></p>
<h1 id="二、分组查询"><a href="#二、分组查询" class="headerlink" title="二、分组查询"></a>二、分组查询</h1><ul>
<li>筛选条件可分为两类：分组前筛选和分组后筛选</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th><strong>数据源</strong></th>
<th><strong>位置</strong></th>
<th><strong>关键字</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>分组前筛选</strong></td>
<td>原始表</td>
<td><code>GROUP BY</code>子句的前面</td>
<td><code>WHERE</code></td>
</tr>
<tr>
<td><strong>分组后筛选</strong></td>
<td>分组后的结果集</td>
<td><code>GROUP BY</code>子句的后面</td>
<td><code>HAVING</code></td>
</tr>
</tbody>
</table>
</div>
<ul>
<li><p>GROUP BY`子句支持单个字段分组、多个字段分组（多个字段之间用逗号隔开，没有顺序要求）</p>
</li>
<li><p>也可以添加排序（放在整个分组查询最后）</p>
</li>
</ul>
<p>注：</p>
<ol>
<li>分组函数做条件肯定是放在HAVING子句中</li>
<li>能用分组前筛选的优先使用分组前筛选</li>
</ol>
<h2 id="1-GROUP-BY语法"><a href="#1-GROUP-BY语法" class="headerlink" title="1. GROUP BY语法"></a>1. <code>GROUP BY</code>语法</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT column_name, function(column_name)</span><br><span class="line">FROM table_name</span><br><span class="line">WHERE column_name operator value</span><br><span class="line">GROUP BY column_name;</span><br></pre></td></tr></table></figure>
<h2 id="2-具体示例"><a href="#2-具体示例" class="headerlink" title="2. 具体示例"></a>2. 具体示例</h2><p><strong>查询每个部门的平均工资</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT department_id, AVG(salary) </span><br><span class="line">FROM employees </span><br><span class="line">GROUP BY department_id;</span><br></pre></td></tr></table></figure>
<p><strong>查询每个工种有奖金的员工的最高工资</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT MAX(salary), job_id </span><br><span class="line">FROM employees </span><br><span class="line">WHERE commission_pct IS NOT NULL </span><br><span class="line">GROUP BY job_id;</span><br></pre></td></tr></table></figure>
<p><strong>根据上一题查询结果筛选最高工资&gt;12000</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT MAX(salary), job_id </span><br><span class="line">FROM employees </span><br><span class="line">WHERE commission_pct IS NOT NULL </span><br><span class="line">GROUP BY job_id </span><br><span class="line">HAVING MAX(salary)&gt;12000;</span><br></pre></td></tr></table></figure>
<p><strong>查询领导编号&gt;102的每个领导手下的最低工资&gt;5000的领导编号是哪个，以及其最低工资</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT MIN(salary), manager_id </span><br><span class="line">FROM employees </span><br><span class="line">WHERE manager_id&gt;102</span><br><span class="line">GROUP BY manager_id </span><br><span class="line">HAVING MIN(salary)&gt;5000</span><br></pre></td></tr></table></figure>
<p><strong>按表达式（函数）分组：按员工姓名的长度分组，查询每一组的员工个数，筛选员工个数&gt;5的有哪些</strong></p>
<p>① 查询每个长度的员工个数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT COUNT(*), LENGTH(last_name) len_name </span><br><span class="line">FROM employees </span><br><span class="line">GROUP BY LENGTH(last_name);</span><br></pre></td></tr></table></figure>
<p>② 添加筛选条件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT COUNT(*), LENGTH(last_name) len_name </span><br><span class="line">FROM employees </span><br><span class="line">GROUP BY LENGTH(last_name) </span><br><span class="line">HAVING COUNT(*) &gt; 5;</span><br></pre></td></tr></table></figure>
<p><strong>按多个字段分组</strong></p>
<p>案例：查询每个部门每个工种的员工的平均工资</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT AVG(salary), department_id, job_id </span><br><span class="line">FROM employees </span><br><span class="line">GROUP BY department_id, job_id;</span><br></pre></td></tr></table></figure>
<p><strong>添加排序</strong></p>
<p>案例：查询部门编号不为NULL的每个工种的员工的平均工资，并按工资高低显示</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT AVG(salary), department_id, job_id </span><br><span class="line">FROM employees </span><br><span class="line">WHERE department_id IS NOT NULL </span><br><span class="line">GROUP BY department_id, job_id </span><br><span class="line">ORDER BY AVG(salary) DESC;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>Python爬虫初级（五）—— 中国大学排名定向爬虫</title>
    <url>/posts/f995f5ca.html</url>
    <content><![CDATA[<h1 id="实例介绍"><a href="#实例介绍" class="headerlink" title="实例介绍"></a>实例介绍</h1><p>我们准备从上海交大设计的最好大学网获得大学的排名，由下面链接打开就能直接看到中国最好大学的基本信息：<br><a href="http://www.zuihaodaxue.com/zuihaodaxuepaiming2016.html" target="_blank" rel="noopener">http://www.zuihaodaxue.com/zuihaodaxuepaiming2016.html</a></p>
<p>我们要写一段程序，从网上获得大学的排名，然后以此输出，具体的功能描述就是：</p>
<blockquote>
<p>输入：大学排名 URL 链接<br>输出： 大学排名信息的屏幕输出（排名， 大学名称， 总分）<br>技术路线： requests-bs4<br>定向爬虫： 仅对输入 URL 进行爬取，不扩展爬取</p>
</blockquote>
<p>我们在该网站首页观察到的是下图：<br><img src="https://img-blog.csdnimg.cn/2020042018273636.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="中国大学排名">我们首先看看根据我们目前掌握的知识能否进行爬取，右键点开源代码，发现相应内容可以在源代码中找到，说明这些内容不是由一个动态脚本控制 的，这个定向爬虫是我们可以实现的：<br><img src="https://img-blog.csdnimg.cn/20200420182907319.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="中国大学排名网站源代码">此外，我们还需看一下这个网站是否提供了 robots 协议的约定，我们直接打开 www.zuihaodaxue.cn/robots.cn ，我们发现网页不存在，因此我们是可以对该网站进行爬取的。<br>验证可行性之后，我们需要首先对爬虫做一个初步的设计，获取大学排名并且输出大学排名信息：</p>
<blockquote>
<p>步骤一：从网络上获取大学排名网页内容<br>步骤二：提取网页内容中信息到合适的数据结构<br>步骤三：利用数据结构输出其中的信息并且获得我们需要的结果</p>
</blockquote>
<p>对应上述步骤，我们可以提取出具体的程序结构设计：</p>
<blockquote>
<p>步骤一：getHTMLText()<br>步骤二：fillUnivList()<br>步骤三：printUnivList()</p>
</blockquote>
<h1 id="代码部分"><a href="#代码部分" class="headerlink" title="代码部分"></a>代码部分</h1><p>下面我们直接展示代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> bs4</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLText</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url, timeout=<span class="number">30</span>)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> r.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">""</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fillUnivList</span><span class="params">(ulist, html)</span>:</span></span><br><span class="line">    soup = BeautifulSoup(html)</span><br><span class="line">    <span class="keyword">for</span> tr <span class="keyword">in</span> soup.find(<span class="string">"tbody"</span>).children:</span><br><span class="line">        <span class="keyword">if</span> isinstance(tr, bs4.element.Tag):</span><br><span class="line">            tds = tr(<span class="string">"td"</span>)</span><br><span class="line">            ulist.append([tds[<span class="number">0</span>].string, tds[<span class="number">1</span>].string, tds[<span class="number">2</span>].string])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printUnivList</span><span class="params">(ulist, num)</span>:</span> </span><br><span class="line">    print(<span class="string">"&#123;:^10&#125;\t&#123;:^6&#125;\t&#123;:^10&#125;"</span>.format(<span class="string">"排名"</span>,<span class="string">"学校"</span>,<span class="string">"总分"</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num):</span><br><span class="line">        u = ulist[i]</span><br><span class="line">        print(<span class="string">"&#123;:^10&#125;\t&#123;:^6&#125;\t&#123;:^10&#125;"</span>.format(u[<span class="number">0</span>],u[<span class="number">1</span>],u[<span class="number">2</span>]))</span><br><span class="line">    print(<span class="string">"Suc"</span> + str(num)) </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    uinfo = []</span><br><span class="line">    url = <span class="string">"http://www.zuihaodaxue.com/zuihaodaxuepaiming2016.html"</span></span><br><span class="line">    html = getHTMLText(url)</span><br><span class="line">    fillUnivList(uinfo, html)</span><br><span class="line">    printUnivList(uinfo, <span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>
<p>最后输出结果为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">排名    	  学校  	    总分</span><br><span class="line">    1     	 清华大学 	   北京市</span><br><span class="line">    2     	 北京大学 	   北京市</span><br><span class="line">    3     	 浙江大学 	   浙江省</span><br><span class="line">    4     	上海交通大学	   上海市</span><br><span class="line">    5     	 复旦大学 	   上海市</span><br><span class="line">    6     	 南京大学 	   江苏省</span><br><span class="line">    7     	中国科学技术大学	   安徽省</span><br><span class="line">    8     	哈尔滨工业大学	   黑龙江省</span><br><span class="line">    9     	华中科技大学	   湖北省</span><br><span class="line">    10    	 中山大学 	   广东省</span><br><span class="line">    11    	 东南大学 	   江苏省</span><br><span class="line">    12    	 天津大学 	   天津市</span><br><span class="line">    13    	 同济大学 	   上海市</span><br><span class="line">    14    	北京航空航天大学	   北京市</span><br><span class="line">    15    	 四川大学 	   四川省</span><br><span class="line">    16    	 武汉大学 	   湖北省</span><br><span class="line">    17    	西安交通大学	   陕西省</span><br><span class="line">    18    	 南开大学 	   天津市</span><br><span class="line">    19    	大连理工大学	   辽宁省</span><br><span class="line">    20    	 山东大学 	   山东省</span><br><span class="line">Suc20</span><br></pre></td></tr></table></figure>
<p>接下来我们将对上述显示结果进行优化。</p>
<h1 id="实例优化"><a href="#实例优化" class="headerlink" title="实例优化"></a>实例优化</h1><p>我们发现上述显示结果并不美观，没有按我们想象中的居中对齐，这是由于中西文的空格填充方式不同，要怎么解决这个问题呢？我们可以采用中文字符的空格填充，即 chr(12288)，我们将上述代码中的 printUnivList 函数进行如下修改：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printUnivList</span><span class="params">(ulist, num)</span>:</span> </span><br><span class="line">    tplt = <span class="string">"&#123;0:^10&#125;\t&#123;1:&#123;3&#125;^10&#125;\t&#123;2:^10&#125;"</span></span><br><span class="line">    print(tplt.format(<span class="string">"排名"</span>,<span class="string">"学校"</span>,<span class="string">"总分"</span>,chr(<span class="number">12288</span>)))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num):</span><br><span class="line">        u = ulist[i]</span><br><span class="line">        print(tplt.format(u[<span class="number">0</span>],u[<span class="number">1</span>],u[<span class="number">2</span>], chr(<span class="number">12288</span>)))</span><br><span class="line">    print(<span class="string">"Suc"</span> + str(num))</span><br></pre></td></tr></table></figure>
<p>输出结果为：<br><img src="https://img-blog.csdnimg.cn/20200420212749712.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="输出结果"></p>
]]></content>
      <categories>
        <category>Spider</category>
      </categories>
  </entry>
  <entry>
    <title>MySQL入门（五）函数</title>
    <url>/posts/a5e4959e.html</url>
    <content><![CDATA[<p>本文数据集下载链接：<a href="https://pan.baidu.com/s/1sVcSXfVZimc6ruyMr4Gr3g" target="_blank" rel="noopener">https://pan.baidu.com/s/1sVcSXfVZimc6ruyMr4Gr3g</a> ，提取码：7gfa </p>
<h1 id="一、常见函数"><a href="#一、常见函数" class="headerlink" title="一、常见函数"></a>一、常见函数</h1><p><strong>调用方法</strong>：<code>SELECT 函数名(实参列表) [FROM 表]</code></p>
<p><strong>优点</strong>：隐藏实现细节；提高代码的重用性</p>
<p><strong>分类</strong>：</p>
<ol>
<li>单行函数，如<code>concat</code>、<code>length</code>、<code>ifnull</code></li>
<li>分组函数，传递一组值进去，传出一个值（又称统计函数）</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT DATABASE();		# 查看当前DATABASE</span><br><span class="line">SELECT USER();</span><br><span class="line">SELECT VERSION();</span><br></pre></td></tr></table></figure>
<h1 id="二、单行函数"><a href="#二、单行函数" class="headerlink" title="二、单行函数"></a>二、单行函数</h1><h2 id="1-字符函数"><a href="#1-字符函数" class="headerlink" title="1. 字符函数"></a>1. 字符函数</h2><p><strong>函数1：<code>LENGTH</code></strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT LENGTH(&quot;MySQL&quot;);</span><br><span class="line">SELECT LENGTH(&quot;MySQL真简单&quot;);</span><br></pre></td></tr></table></figure>
<p>第一个显示为5，第二个显示为14（一个汉字占3个字节），由此我们知道<code>LENGTH</code>函数是用于获取参数值的字节个数的</p>
<p><strong>函数2：<code>CONCAT</code>拼接函数</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT CONCAT(last_name, &#39;_&#39;, first_name) 姓名 FROM employees;</span><br></pre></td></tr></table></figure>
<p><strong>函数3：<code>UPPER、LOWER</code></strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT UPPER(&#39;MySQL&#39;);</span><br><span class="line">SELECT LOWER(&#39;MySQL&#39;);</span><br></pre></td></tr></table></figure>
<p><strong>套娃1：将姓大写，名小写然后拼接</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT CONCAT(UPPER(last_name),LOWER(first_name)) FROM employees;</span><br></pre></td></tr></table></figure>
<p>由此可见函数可以嵌套调用</p>
<p><strong>函数4：<code>SUBSTR\SUBSTRING</code></strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT SUBSTR(&#39;我喜欢MySQL&#39;, 4) output;</span><br></pre></td></tr></table></figure>
<p>该函数返回<code>MySQL</code>，由此我们可见该函数的作用是返回索引及其之后的内容，同时我们可以发现MySQL中的<strong>索引是从0开始</strong>的</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT SUBSTR(&#39;我喜欢你&#39;, 2, 4) output;</span><br></pre></td></tr></table></figure>
<p>该函数返回<code>喜欢你</code>，这里是截取从指定索引处指定字符长度的字符</p>
<p><strong>套娃2：姓名中首字符大写，其他字符小写，并用_拼接显示出来</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT CONCAT(UPPER(SUBSTR(last_name, 1, 1)),&#39;_&#39;,LOWER(SUBSTR(last_name, 2))) output FROM employees;</span><br></pre></td></tr></table></figure>
<p><strong>函数5：<code>instr</code>返回起始索引</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT INSTR(&#39;我喜欢MySQL&#39;, &#39;MySQL&#39;) AS output;</span><br></pre></td></tr></table></figure>
<p>返回结果为4</p>
<p>注意：如果找不到对应索引，返回0</p>
<p><strong>函数6：<code>trim</code>去首尾空格</strong></p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">SELECT TRIM(<span class="string">'    MySQL   '</span>) AS output;</span><br></pre></td></tr></table></figure>
<p>实际上也可以去除前后某个指定的元素，比如我们要去除下例中首尾的<code>a</code>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT TRIM(&#39;a&#39; FROM &#39;aaaaaaaMySQLaaaa&#39;) AS output;</span><br></pre></td></tr></table></figure>
<p><strong>函数7：<code>lpad</code>用指定字符实现左填充指定长度</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT LPAD(&#39;MySQL&#39;, 10, &#39;*&#39;) AS output;</span><br></pre></td></tr></table></figure>
<p>返回结果为<code>*****MySQL</code>，若我们将长度指定为小于字段长的数字，例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT LPAD(&#39;MySQL&#39;, 3, &#39;*&#39;) AS output;</span><br></pre></td></tr></table></figure>
<p>返回值为<code>MyS</code></p>
<p><strong>函数8：<code>rpad</code>用指定字符右填充指定长度</strong></p>
<p>用法与左填充一样</p>
<p><strong>函数9：<code>replace</code>替换</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT REPLACE(&#39;我爱MySQL&#39;, &#39;爱&#39;, &#39;讨厌&#39;) AS output;</span><br></pre></td></tr></table></figure>
<p>结果很容易猜到，嘿嘿这里就不说啦。而且注意哦，这里的替换是全部替换，可以自己验证一下</p>
<h2 id="2-数学函数"><a href="#2-数学函数" class="headerlink" title="2. 数学函数"></a>2. 数学函数</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;*</span><br><span class="line">round: 四舍五入</span><br><span class="line">*&#x2F;</span><br><span class="line">SELECT ROUND(-1.55);		# 输出结果为-2</span><br><span class="line">SELECT ROUND(1.467,2);		# 输出结果为1.47</span><br><span class="line"></span><br><span class="line">&#x2F;*</span><br><span class="line">ceil: 向上取整(返回大于等于该数的最小整数)</span><br><span class="line">floor: 向下取整(返回小于等于该数的最大整数)</span><br><span class="line">*&#x2F;</span><br><span class="line">SELECT CEIL(1.01);			# 输出结果为2</span><br><span class="line">SELECT FLOOR(-9.99);		# 输出结果为-10</span><br><span class="line"></span><br><span class="line">&#x2F;*</span><br><span class="line">truncate: 截断</span><br><span class="line">*&#x2F;</span><br><span class="line">SELECT TRUNCATE(1.65, 1);	# 输出结果为1.6</span><br><span class="line"></span><br><span class="line">&#x2F;*</span><br><span class="line">mod: 取余</span><br><span class="line">*&#x2F;</span><br><span class="line">SELECT MOD(10, 3);			# 输出结果为1</span><br><span class="line"># 被除数如果是正则为正，如果是负则为负，因为运算方式为：MOD(a,b)&#x3D;a-a&#x2F;b*b</span><br></pre></td></tr></table></figure>
<h2 id="3-日期函数"><a href="#3-日期函数" class="headerlink" title="3. 日期函数"></a>3. 日期函数</h2><h3 id="3-1-获取日期的函数"><a href="#3-1-获取日期的函数" class="headerlink" title="3.1 获取日期的函数"></a>3.1 获取日期的函数</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># now: 返回当前系统日期+时间</span><br><span class="line">SELECT NOW();</span><br><span class="line"></span><br><span class="line"># curdate: 返回当前系统日期，不包含时间</span><br><span class="line">SELECT CURDATE();</span><br><span class="line"></span><br><span class="line"># curtime: 返回当前系统时间，不包含日期</span><br><span class="line">SELECT CURTIME();</span><br><span class="line"></span><br><span class="line"># 也可以自己定其他截取的时间特征:</span><br><span class="line">SELECT YEAR(NOW()); 		# 返回今年</span><br><span class="line"># 若希望返回英文：</span><br><span class="line">SELECT MONTHNAME(NOW());</span><br></pre></td></tr></table></figure>
<h3 id="3-2-转换日期的函数"><a href="#3-2-转换日期的函数" class="headerlink" title="3.2 转换日期的函数"></a>3.2 转换日期的函数</h3><p><strong><code>STR_TO_DATE</code></strong></p>
<p>该函数的作用是按日期格式的字符转换成指定格式的日期，示例如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT STR_TO_DATE(&#39;1999&#x2F;2&#x2F;18&#39;,&#39;%Y&#x2F;%m&#x2F;%d&#39;);</span><br></pre></td></tr></table></figure>
<p>返回<code>1999-02-18</code>，小伙伴可以自己尝试大小写的区别，并自行查阅其他格式符的含义和功能</p>
<p><strong><code>DATE_FORMAT</code></strong></p>
<p>该函数的作用是将日期转换成字符，恰好与<code>STR_TO_DATE</code>反过来，示例如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT DATE_FORMAT(NOW(),&#39;%Y年%m月%d日&#39;);</span><br></pre></td></tr></table></figure>
<p><strong>案例1：查询入职日期是1992年4月3号的员工信息</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * </span><br><span class="line">FROM employees </span><br><span class="line">WHERE hiredate &#x3D; STR_TO_DATE(&#39;1992年4月3日&#39;,&#39;%Y年%m月%d日&#39;);</span><br></pre></td></tr></table></figure>
<p><strong>案例2：查询有奖金的员工名及入职日期，要求格式为：xx月/xx日/xx年</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name, DATE_FORMAT(hiredate,&#39;%m月&#x2F;%d日 %y年&#39;) 入职日期 </span><br><span class="line">FROM employees </span><br><span class="line">WHERE commission_pct IS NOT NULL;</span><br></pre></td></tr></table></figure>
<h1 id="三、流程控制函数"><a href="#三、流程控制函数" class="headerlink" title="三、流程控制函数"></a>三、流程控制函数</h1><h2 id="1-IF函数"><a href="#1-IF函数" class="headerlink" title="1. IF函数"></a>1. <code>IF</code>函数</h2><p><code>IF</code>函数有三个参数，第一个表达式的结果若为 true，则返回表达式二的值，否则返回表达式三的值，如下将返回21</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT IF(10&gt;5, 21, 10);</span><br></pre></td></tr></table></figure>
<p><strong>示例：若员工有奖金则提示有，否则提示没有</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name, commission_pct, IF(commission_pct IS NULL, &#39;没奖金&#39;, &#39;有奖金&#39;) FROM employees;</span><br></pre></td></tr></table></figure>
<h2 id="2-case函数"><a href="#2-case函数" class="headerlink" title="2. case函数"></a>2. <code>case</code>函数</h2><p><strong>使用语法一</strong>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CASE 要判断的字段或表达式</span><br><span class="line">WHEN 常量1  THEN  要显示的值1或语句1</span><br><span class="line">WHEN 常量2  THEN  要显示的值2或语句2</span><br><span class="line">...</span><br><span class="line">ELSE 要显示的值n或语句n</span><br><span class="line">END</span><br></pre></td></tr></table></figure>
<p><strong>案例1：查询员工的工资，要求部门编号=30，则显示工资为1.1倍，部门编号=20，则显示工资为1.2倍，部门编号=30，则显示工资为1.3倍，其他部门显示的工资为原工资</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT salary 原始工资, department_id, </span><br><span class="line">CASE department_id </span><br><span class="line">WHEN 30 THEN salary*1.1</span><br><span class="line">WHEN 40 THEN salary*1.2</span><br><span class="line">WHEN 50 THEN salary*1.3</span><br><span class="line">ELSE salary;</span><br><span class="line">END AS 新工资</span><br><span class="line">FROM employees;</span><br></pre></td></tr></table></figure>
<p><strong>使用语法二：类似于多重<code>if</code></strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CASE</span><br><span class="line">WHEN 条件1 THEN 要显示的值1或语句1</span><br><span class="line">WHEN 条件2 THEN 要显示的值2或语句2</span><br><span class="line">...</span><br><span class="line">THEN 要显示的值n或语句n</span><br><span class="line">END</span><br></pre></td></tr></table></figure>
<p><strong>案例2:查询员工的工资情况：如果工资&gt;20000，显示级别A，若工资&gt;15000，显示级别B，若工资&gt;10000，显示级别C，否则显示级别D </strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT salary,</span><br><span class="line">CASE</span><br><span class="line">WHEN salary&gt;20000 THEN &#39;A&#39;</span><br><span class="line">WHEN salary&gt;15000 THEN &#39;B&#39;</span><br><span class="line">WHEN salary&gt;10000 THEN &#39;C&#39;</span><br><span class="line">ELSE &#39;D&#39;</span><br><span class="line">END AS &#39;工资级别&#39;</span><br><span class="line">FROM employees;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>Python爬虫初级（四）—— 信息组织与提取方法</title>
    <url>/posts/85092151.html</url>
    <content><![CDATA[<h1 id="信息标记的三种形式"><a href="#信息标记的三种形式" class="headerlink" title="信息标记的三种形式"></a>信息标记的三种形式</h1><blockquote>
<p>信息的标记：<br>标记后的信息可形成信息组织结构，增加信息维度<br>标记后的信息可用于通信、存储或展示<br>标记的结构和信息一样具有重要价值<br>标记后的信息更利于程序理解和运用</p>
</blockquote>
<p>国际公认的信息标记的三种形式分别是 XML、JSON、YAML，下面分别介绍这三者：<br><strong>XML 即 eXtensible Markup Language</strong>，采用了以标签为主来构建信息和表达信息的方式，比如：<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">"china.jpg size="</span><span class="attr">10</span>"&gt;</span> ... <span class="tag">&lt;/<span class="name">img</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">"china.jpg size="</span><span class="attr">10</span>" /&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- This is a comment --&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>我们不难发现，XML 的形式与 HTML 几乎完全一致，可以说 XML 是通过 HTML发展而来的通用表达形式。<br>另一种信息标记形式是 <strong>JSON (JavaScript Object Notation)</strong>，它是 JavaScript 语言中对面向对象的信息的一种表达形式，简单来讲，JSON 是由有类型的键值对构建的信息表达方式，具体形式如下：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">"key1":"value1"</span><br><span class="line">"key2":["value2", "value3"]</span><br><span class="line">"key3":&#123;"subkey":"subvalue"&#125;</span><br></pre></td></tr></table></figure>
<p><strong>YAML(YAML Ain’t Markup Language)</strong> 是一种递归的定义，采用的是五类型的键值对来组织信息，和 Python 语言类似，YAML 通过缩进的方式表达所属关系比如：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">name:</span>	<span class="comment"># 用 tab 表示所属关系</span></span><br><span class="line">	<span class="attr">newName :</span> <span class="string">abc</span></span><br><span class="line">	<span class="attr">oldName :</span> <span class="string">ABC</span></span><br><span class="line"></span><br><span class="line"><span class="attr">name:</span>	<span class="comment"># 用-表示并列关系</span></span><br><span class="line">	<span class="string">-abc</span></span><br><span class="line">	<span class="string">-ABC</span></span><br><span class="line"></span><br><span class="line"><span class="attr">text:</span> <span class="string">|</span>	<span class="comment"># 用 | 表示整块数据</span></span><br><span class="line">	<span class="string">简介：汉武帝刘彻（前156年7月7日—前87年3月29日），</span></span><br><span class="line">	<span class="string">西汉第七位皇帝（含前后少帝），政治家、文学家。</span></span><br><span class="line">	<span class="string">汉武帝在位期间（前141年—前87年），在政治上，创设中外朝制、刺史制、察举制，</span></span><br><span class="line">	<span class="string">颁行推恩令，加强君主专制与中央集权。</span></span><br></pre></td></tr></table></figure>
<h1 id="三种信息标记形式的比较"><a href="#三种信息标记形式的比较" class="headerlink" title="三种信息标记形式的比较"></a>三种信息标记形式的比较</h1><div class="table-container">
<table>
<thead>
<tr>
<th>信息标记形式</th>
<th>特点</th>
<th>应用情况</th>
</tr>
</thead>
<tbody>
<tr>
<td>XML</td>
<td>是最早的通用信息标记语言，可扩展性好，但较为繁琐</td>
<td>Internet 上的信息交互与传递</td>
</tr>
<tr>
<td>JSON</td>
<td>信息有类型，适合程序处理，比 XML 更简洁</td>
<td>移动应用云端和节点的信息通信，无注释</td>
</tr>
<tr>
<td>YAML</td>
<td>信息无类型，文本信息比例最高，可读性好</td>
<td>各类系统的配置文件，有注释易读，应用相对较广泛</td>
</tr>
</tbody>
</table>
</div>
<h1 id="信息提取的一般方法"><a href="#信息提取的一般方法" class="headerlink" title="信息提取的一般方法"></a>信息提取的一般方法</h1><div class="table-container">
<table>
<thead>
<tr>
<th>方法</th>
<th>例子</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td>完整解析信息标记形式，再提取关键信息，需要标记解析器</td>
<td>bs4 库的标签树遍历</td>
<td>信息解析准确</td>
<td>提取过程繁琐、速度慢</td>
</tr>
<tr>
<td>无视标记形式，直接搜索关键信息</td>
<td>Word 对信息的文本查找函数</td>
<td>提取过程简介，速度较快</td>
<td>提取结果准确性与信息内容相关</td>
</tr>
</tbody>
</table>
</div>
<p>实际上更常用的是两者结合的融合方法：即结合形式解析与搜索方法，提取关键信息，这需要标记解析器及文本查找函数。下面我们考虑实例：提取 HTML 中所有的 URL 链接，具体思路是：</p>
<blockquote>
<p>  1） 搜索所有 \<a> 标签<br>  2） 解析 \<a> 标签格式，提取 href 后的链接内容</a></a></p>
</blockquote>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>url = <span class="string">"http://python123.io/ws/demo.html"</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>res = requests.get(url)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>demo = res.text</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>demo</span><br><span class="line"><span class="string">'&lt;html&gt;&lt;head&gt;&lt;title&gt;This is a python demo page&lt;/title&gt;&lt;/head&gt;\r\n&lt;body&gt;\r\n&lt;p class="title"&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;\r\n&lt;p class="course"&gt;Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:\r\n&lt;a href="http://www.icourse163.org/course/BIT-268001" class="py1" id="link1"&gt;Basic Python&lt;/a&gt; and &lt;a href="http://www.icourse163.org/course/BIT-1001870001" class="py2" id="link2"&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;\r\n&lt;/body&gt;&lt;/html&gt;'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(demo, <span class="string">"html.parser"</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> link <span class="keyword">in</span> soup.find_all(<span class="string">"a"</span>):</span><br><span class="line">	print(link.get(<span class="string">"href"</span>))</span><br><span class="line"></span><br><span class="line">http://www.icourse163.org/course/BIT<span class="number">-268001</span></span><br><span class="line">http://www.icourse163.org/course/BIT<span class="number">-1001870001</span></span><br></pre></td></tr></table></figure>
<h1 id="基于-BeautifulSoup-库的内容查找方法"><a href="#基于-BeautifulSoup-库的内容查找方法" class="headerlink" title="基于 BeautifulSoup 库的内容查找方法"></a>基于 BeautifulSoup 库的内容查找方法</h1><p>由前例我们可以看见， find_all 方法可以返回一个列表类型，存储查找的结果，find_all 的具体使用方法为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&lt;&gt;.find_all(name, attrs, recursive, string, **kwargs)</span><br></pre></td></tr></table></figure>
<p>其中，name 为对标签的检索字符串，如果我们希望查找两个标签，可以以列表形式传入：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(<span class="string">"a"</span>)</span><br><span class="line">[&lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt;, &lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;Advanced Python&lt;/a&gt;]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all([<span class="string">"a"</span>,<span class="string">"b"</span>])</span><br><span class="line">[&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;, &lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt;, &lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;Advanced Python&lt;/a&gt;]</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> tag <span class="keyword">in</span> soup.find_all(true):</span><br><span class="line">		print(tag.name)</span><br><span class="line">	</span><br><span class="line">html</span><br><span class="line">head</span><br><span class="line">title</span><br><span class="line">body</span><br><span class="line">p</span><br><span class="line">b</span><br><span class="line">p</span><br><span class="line">a</span><br><span class="line">a</span><br></pre></td></tr></table></figure>
<p>我们看到，若 find_all(true) ，则会返回所有标签。若希望只显示所有以 b 开头的标签，包括 b 和 body 标签，我们应该怎么办呢？这时我们应该使用正则表达式：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> tag <span class="keyword">in</span> soup.find_all(re.compile(<span class="string">'b'</span>)):</span><br><span class="line">	print(tag.name)</span><br><span class="line">	</span><br><span class="line">body</span><br><span class="line">b</span><br></pre></td></tr></table></figure>
<p>find_all 的第二个参数 attrs 是对标签属性值的检索字符串，可标注属性检索。</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(<span class="string">"p"</span>, <span class="string">"course"</span>)</span><br><span class="line">[&lt;p class="course"&gt;Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:</span><br><span class="line">&lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt; and &lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;]</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(id=<span class="string">"link1"</span>)</span><br><span class="line">[&lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt;]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(id=<span class="string">"link"</span>)</span><br><span class="line">[]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(id=re.compile(<span class="string">"link"</span>))</span><br><span class="line">[&lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt;, &lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;Advanced Python&lt;/a&gt;]</span><br></pre></td></tr></table></figure>
<p>find_all 的第三个参数是 recursive，即是否对子孙进行全部检索，默认为 True。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(<span class="string">"a"</span>)</span><br><span class="line">[&lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt;, &lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;Advanced Python&lt;/a&gt;]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(<span class="string">"a"</span>,recursive=<span class="literal">False</span>)</span><br><span class="line">[]</span><br></pre></td></tr></table></figure>
<p>上述代码说明，soup 的根节点下是没有 a 标签的， a 标签在其子孙节点中。<br>find_all 的第四个参数是 string，是对 <>...</> 中字符串区域的检索字符串，下面看一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(string=<span class="string">"Basic Python"</span>)</span><br><span class="line">[<span class="string">'Basic Python'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(string=<span class="string">"Python"</span>)</span><br><span class="line">[]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(string=re.compile(<span class="string">"Python"</span>))</span><br><span class="line">[<span class="string">'Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:\r\n'</span>, <span class="string">'Basic Python'</span>, <span class="string">'Advanced Python'</span>]</span><br></pre></td></tr></table></figure>
<p>事实上，我们有一个简写的形式，即：</p>
<blockquote>
<p>\<tag>(…)  等价于 \<tag>.find_all(…)<br>soup(…) 等价于 soup.find_all(…)</tag></tag></p>
</blockquote>
<p>BeautifulSoup 库有八个常用方法，都是顾名思义的，就不在此做详细介绍了，方法列举为：find_all, find, find_parent, find_parents, find_next_siblings, find_next_sibling, find_previous_sibling, find_previous_siblings </p>
]]></content>
      <categories>
        <category>Spider</category>
      </categories>
  </entry>
  <entry>
    <title>MySQL入门（四）排序查询</title>
    <url>/posts/6b667049.html</url>
    <content><![CDATA[<p>本文数据集下载链接：<a href="https://pan.baidu.com/s/1sVcSXfVZimc6ruyMr4Gr3g" target="_blank" rel="noopener">https://pan.baidu.com/s/1sVcSXfVZimc6ruyMr4Gr3g</a> ，提取码：7gfa </p>
<h1 id="一、排序查询"><a href="#一、排序查询" class="headerlink" title="一、排序查询"></a>一、排序查询</h1><p>我们知道从 MySQL 表中使用 SQL SELECT 语句来读取数据，如果我们需要对读取的数据进行排序，我们就可以使用 MySQL 的 <strong>ORDER BY</strong> 子句来设定你想按哪个字段哪种方式来进行排序，再返回搜索结果。</p>
<h2 id="1-语法"><a href="#1-语法" class="headerlink" title="1. 语法"></a>1. 语法</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT 查询列表</span><br><span class="line">FROM 表</span><br><span class="line">[WHERE 筛选条件]</span><br><span class="line">ORDER BY 排序列表 【ASC】</span><br></pre></td></tr></table></figure>
<p>一般ORDER BY语句放在查询语句的最后【<code>LIMIT</code>子句除外】</p>
<ul>
<li>你可以使用任何字段来作为排序的条件，从而返回排序后的查询结果。</li>
<li>你可以设定多个字段来排序。</li>
<li>你可以使用 <code>ASC</code> 或 <code>DESC</code> 关键字来设置查询结果是按升序或降序排列。 默认情况下，它是按升序排列。</li>
<li>你可以添加 <code>WHERE...LIKE</code> 子句来设置条件。</li>
</ul>
<h2 id="2-案例"><a href="#2-案例" class="headerlink" title="2. 案例"></a>2. 案例</h2><p><strong>案例1</strong>：<strong>查询员工信息，要求工资从高到低排序</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * </span><br><span class="line">FROM employees </span><br><span class="line">ORDER BY salary DESC;</span><br></pre></td></tr></table></figure>
<p><strong>查询员工信息，要求工资从低到高排序</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * </span><br><span class="line">FROM employees </span><br><span class="line">ORDER BY salary ASC;</span><br></pre></td></tr></table></figure>
<p><strong>案例2：查询部门编号&gt;=90的员工信息，按入职时间的先后进行排序</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * </span><br><span class="line">FROM employees </span><br><span class="line">WHERE department_id &gt;&#x3D; 90 </span><br><span class="line">ORDER BY hiredate ASC;</span><br></pre></td></tr></table></figure>
<p><strong>案例3：按年薪高低显示员工的信息和年薪【按表达式排序】</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT *, salary*12*(1+IFNULL(commission_pct,0)) 年薪 </span><br><span class="line">FROM employees </span><br><span class="line">ORDER BY 年薪</span><br></pre></td></tr></table></figure>
<p><strong>案例4：按姓名长度显示员工的姓名和工资【按函数排序】</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT LENGTH(last_name) 字节长度,last_name,salary </span><br><span class="line">FROM employees </span><br><span class="line">ORDER BY 字节长度 DESC;</span><br></pre></td></tr></table></figure>
<p><strong>案例5：查询员工信息，要求先按工资排序，再按员工编号排序【按多个字段排序】</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * </span><br><span class="line">FROM employees </span><br><span class="line">ORDER BY salary ASC, employee_id DESC;</span><br></pre></td></tr></table></figure>
<h1 id="二、MySQL拼音排序"><a href="#二、MySQL拼音排序" class="headerlink" title="二、MySQL拼音排序"></a>二、MySQL拼音排序</h1><p>如果字符集采用的是 gbk(汉字编码字符集)，直接在查询语句后边添加 <code>ORDER BY</code>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * </span><br><span class="line">FROM runoob_tbl</span><br><span class="line">ORDER BY runoob_title;</span><br></pre></td></tr></table></figure>
<p>如果字符集采用的是 utf8(万国码)，需要先对字段进行转码然后排序：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * </span><br><span class="line">FROM runoob_tbl</span><br><span class="line">ORDER BY CONVERT(runoob_title using gbk);</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>Python爬虫初级（三）—— Beautiful Soup 库入门</title>
    <url>/posts/caae3505.html</url>
    <content><![CDATA[<h1 id="BeautifulSoup-库的安装"><a href="#BeautifulSoup-库的安装" class="headerlink" title="BeautifulSoup 库的安装"></a>BeautifulSoup 库的安装</h1><p>安装beautiful soup 库可以直接使用命令 pip install beautifulsoup4，安装完成之后可以通过演示 HTML 页面地址：<a href="http://python123.io/ws/demo.html" target="_blank" rel="noopener">http://python123.io/ws/demo.html</a> 进行测试。我们打开这个网址，查询源代码，得到下面的结果：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span><span class="tag">&lt;<span class="name">head</span>&gt;</span><span class="tag">&lt;<span class="name">title</span>&gt;</span>This is a python demo page<span class="tag">&lt;/<span class="name">title</span>&gt;</span><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"title"</span>&gt;</span><span class="tag">&lt;<span class="name">b</span>&gt;</span>The demo python introduces several python courses.<span class="tag">&lt;/<span class="name">b</span>&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"course"</span>&gt;</span>Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:</span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"http://www.icourse163.org/course/BIT-268001"</span> <span class="attr">class</span>=<span class="string">"py1"</span> <span class="attr">id</span>=<span class="string">"link1"</span>&gt;</span>Basic Python<span class="tag">&lt;/<span class="name">a</span>&gt;</span> and <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"http://www.icourse163.org/course/BIT-1001870001"</span> <span class="attr">class</span>=<span class="string">"py2"</span> <span class="attr">id</span>=<span class="string">"link2"</span>&gt;</span>Advanced Python<span class="tag">&lt;/<span class="name">a</span>&gt;</span>.<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>我们刚刚查看源代码是直接右键查看源代码进行拷贝的，除此之外，我们还可以使用 requests 库自动获得该链接的源代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">"http://python123.io/ws/demo.html"</span>)</span><br><span class="line">demo = r.text</span><br><span class="line">soup = BeautifulSoup(demo, <span class="string">"html.parser"</span>)</span><br><span class="line">print(soup.prettify())</span><br></pre></td></tr></table></figure>
<p>这是上述代码的返回结果：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">title</span>&gt;</span></span><br><span class="line">   This is a python demo page</span><br><span class="line">  <span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"title"</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">b</span>&gt;</span></span><br><span class="line">    The demo python introduces several python courses.</span><br><span class="line">   <span class="tag">&lt;/<span class="name">b</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"course"</span>&gt;</span></span><br><span class="line">   Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:</span><br><span class="line">   <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">"py1"</span> <span class="attr">href</span>=<span class="string">"http://www.icourse163.org/course/BIT-268001"</span> <span class="attr">id</span>=<span class="string">"link1"</span>&gt;</span></span><br><span class="line">    Basic Python</span><br><span class="line">   <span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">   and</span><br><span class="line">   <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">"py2"</span> <span class="attr">href</span>=<span class="string">"http://www.icourse163.org/course/BIT-1001870001"</span> <span class="attr">id</span>=<span class="string">"link2"</span>&gt;</span></span><br><span class="line">    Advanced Python</span><br><span class="line">   <span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>看得出来，这个效果还是蛮好看的。实际上，Beautiful Soup 库是解析、遍历和维护“标签树”的功能库，可以理解为：BeautifulSoup 对应一个 HTML/XML 文档的全部内容。</p>
<h1 id="BeautifulSoup-库详解"><a href="#BeautifulSoup-库详解" class="headerlink" title="BeautifulSoup 库详解"></a>BeautifulSoup 库详解</h1><p>BeautifulSoup 库的解析器一共有四种，分别列举如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>解析器</th>
<th>使用方法</th>
<th>条件</th>
</tr>
</thead>
<tbody>
<tr>
<td>bs4 的 HTML 解析器</td>
<td>BeautifulSoup(mk, “html.parser”)</td>
<td>pip install bs4</td>
</tr>
</tbody>
</table>
</div>
<p>lxml 的 HTML 解析器|BeautifulSoup(mk, “lxml”)|pip install lxml|<br>|lxml 的 XML 解析器|BeautifulSoup(mk, “xml”)|pip install lxml|<br>|html5lib 的解析器|BeautifulSoup(mk, “html5lib”)|pip install html5lib|</p>
<p>BeautifulSoup 类的基本元素列举如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>基本元素</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>Tag</td>
<td>标签，最基本的信息组织单元，分别用 <> 和 </>标明开头和结尾</td>
</tr>
<tr>
<td>Name</td>
<td>标签的名字，获取格式：\<tag>.name</tag></td>
</tr>
<tr>
<td>Attributes</td>
<td>标签的属性，获取格式：\<tag>.attrs</tag></td>
</tr>
<tr>
<td>NavigableString</td>
<td>标签内非属性字符串，获取格式：\<tag>.string</tag></td>
</tr>
<tr>
<td>Comment</td>
<td>标签内字符串的注释部分，一种特殊的Comment类型</td>
</tr>
</tbody>
</table>
</div>
<p>我们可以对前面获得的 soup 进行 尝试：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(soup.title)</span><br><span class="line"><span class="comment"># 返回 &lt;title&gt;This is a python demo page&lt;/title&gt;</span></span><br><span class="line">tag = soup.a</span><br><span class="line">print(tag)</span><br><span class="line"><span class="comment"># 返回 &lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt; </span></span><br><span class="line">print(soup.a.parent.name)	<span class="comment"># 返回 'p'</span></span><br><span class="line">print(soup.a.parent.parent.name)	<span class="comment"># 返回 'body'</span></span><br><span class="line">print(tag.attrs)</span><br><span class="line"><span class="comment"># 返回 &#123;'href': 'http://www.icourse163.org/course/BIT-268001', 'class': ['py1'], 'id': 'link1'&#125;</span></span><br><span class="line">prin(soup.a.string)	<span class="comment"># 返回 Basic Python</span></span><br></pre></td></tr></table></figure>
<p>我们需要注意的是，当我们的 HTML 存在多个相同的标签时，只会返回第一个。我们再来看一下 Comment 元素的使用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">newsoup = Beautiful(<span class="string">"&lt;b&gt;&lt;!--This is a comment--&gt;&lt;/b&gt;&lt;p&gt;This is not a comment&lt;/p&gt;"</span>, <span class="string">"html.parser"</span>)</span><br><span class="line">print(newsoup.b.string) <span class="comment"># 返回 'This is a comment'</span></span><br><span class="line">print(newsoup.p.string)	<span class="comment"># 返回 'This is not a comment'</span></span><br></pre></td></tr></table></figure>
<p>我们总结一下，对于 &lt; p class=”title”&gt; … \&lt;/p&gt;，若要得到 p ，我们使用： <strong>.name</strong>，若要得到 class=”title”，我们使用：<strong>属性.attrs</strong>，若要得到 title，我们使用<strong>标签.\<tag> </tag></strong>，若要得到…(文本)，我们使用：<strong>非属性字符串/注释.string</strong></p>
<h1 id="基于-bs4-库的-HTML-内容遍历方法"><a href="#基于-bs4-库的-HTML-内容遍历方法" class="headerlink" title="基于 bs4 库的 HTML 内容遍历方法"></a>基于 bs4 库的 HTML 内容遍历方法</h1><p>在 HTML 中我们有三种遍历方式 —— 上行遍历、下行遍历和平行遍历，下面分别介绍这几种遍历的直接方法。</p>
<h3 id="标签树的下行遍历"><a href="#标签树的下行遍历" class="headerlink" title="标签树的下行遍历"></a>标签树的下行遍历</h3><div class="table-container">
<table>
<thead>
<tr>
<th>属性</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>.contents</td>
<td>子节点的列表，将 \<tag> 所有儿子节点存入列表</tag></td>
</tr>
<tr>
<td>.children</td>
<td>子节点的迭代类型，与 .contents 类似，用于循环遍历儿子节点</td>
</tr>
<tr>
<td>.descendants</td>
<td>子孙节点的迭代类型，包括所有子孙节点，用于循环遍历</td>
</tr>
</tbody>
</table>
</div>
<p>例如：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(demo, <span class="string">"html.parser"</span>)</span><br><span class="line">&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.head</span><br><span class="line">&lt;head&gt;&lt;title&gt;This is a python demo page&lt;/title&gt;&lt;/head&gt;</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;soup.head.contents</span><br><span class="line">[&lt;title&gt;This is a python demo page&lt;/title&gt;]</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.body.contents</span><br><span class="line">['\n', &lt;p class="title"&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;, '\n', &lt;p class="course"&gt;Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:</span><br><span class="line"></span><br><span class="line">&lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt; and &lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;, '\n']</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>len(soup.body.contents)</span><br><span class="line"><span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.body.contents[<span class="number">1</span>]</span><br><span class="line">&lt;p class="title"&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;</span><br></pre></td></tr></table></figure>
<h3 id="标签树的上行遍历"><a href="#标签树的上行遍历" class="headerlink" title="标签树的上行遍历"></a>标签树的上行遍历</h3><div class="table-container">
<table>
<thead>
<tr>
<th>属性</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>.parent</td>
<td>节点的父亲标签</td>
</tr>
<tr>
<td>.parents</td>
<td>节点父辈标签的迭代类型，用于循环遍历先辈节点</td>
</tr>
</tbody>
</table>
</div>
<p>下面是上行遍历的代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(demo, <span class="string">"html.parser"</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> parent <span class="keyword">in</span> soup.a.parents:</span><br><span class="line">		<span class="keyword">if</span> parent <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">			print(parent)</span><br><span class="line">		<span class="keyword">else</span>:</span><br><span class="line">			print(parent.name)</span><br><span class="line">			</span><br><span class="line">p</span><br><span class="line">body</span><br><span class="line">html</span><br><span class="line">[document]</span><br></pre></td></tr></table></figure>
<h3 id="标签树的平行遍历"><a href="#标签树的平行遍历" class="headerlink" title="标签树的平行遍历"></a>标签树的平行遍历</h3><div class="table-container">
<table>
<thead>
<tr>
<th>属性</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>.next_sibling</td>
<td>返回按照 HTML 文本顺序的下一个平行节点标签</td>
</tr>
<tr>
<td>.previous_sibling</td>
<td>返回按照 HTML 文本顺序的上一个平行节点标签</td>
</tr>
<tr>
<td>.next_siblings</td>
<td>返回按照 HTML 文本顺序的后续所有平行节点标签</td>
</tr>
<tr>
<td>.previous_siblings</td>
<td>返回按照 HTML 文本顺序的前续所有平行节点标签</td>
</tr>
</tbody>
</table>
</div>
<p>需要注意的是：平行遍历发生在同一个父节点下的各节点间。<br>还记得我们前面的那个标签树吗？我们截取一部分来回顾一下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"course"</span>&gt;</span></span><br><span class="line">   Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:</span><br><span class="line">   <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">"py1"</span> <span class="attr">href</span>=<span class="string">"http://www.icourse163.org/course/BIT-268001"</span> <span class="attr">id</span>=<span class="string">"link1"</span>&gt;</span></span><br><span class="line">    Basic Python</span><br><span class="line">   <span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">   and</span><br><span class="line">   <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">"py2"</span> <span class="attr">href</span>=<span class="string">"http://www.icourse163.org/course/BIT-1001870001"</span> <span class="attr">id</span>=<span class="string">"link2"</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>我们接下来对 a 标签进行简单的平行遍历尝试：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(demo, <span class="string">"html.parser"</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.a.next_sibling</span><br><span class="line"><span class="string">' and '</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.a.next_sibling.next_sibling</span><br><span class="line">&lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;Advanced Python&lt;/a&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.a.previous_sibling</span><br><span class="line"><span class="string">'Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:\r\n'</span></span><br></pre></td></tr></table></figure>
<p>我们可以通过以下代码做标签树的平行遍历：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> sibling <span class="keyword">in</span> soup.a.next_siblings:</span><br><span class="line">	print(sibling)</span><br><span class="line"><span class="keyword">for</span> sibling <span class="keyword">in</span> soup.a.previous_siblings:</span><br><span class="line">	print(sibling)</span><br></pre></td></tr></table></figure>
<h1 id="基于-bs4-库的-HTML-格式输出"><a href="#基于-bs4-库的-HTML-格式输出" class="headerlink" title="基于 bs4 库的 HTML 格式输出"></a>基于 bs4 库的 HTML 格式输出</h1><p>我们应该如何让 \<html> 内容更加友好地输出呢？就是我们前面使用的 BeautifulSoup.prettify() 函数来实现。</html></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(<span class="string">"&lt;p&gt; 中文 china &lt;/p&gt;"</span>,<span class="string">"html.parser"</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.prettify()</span><br><span class="line"><span class="string">'&lt;p&gt;\n 中文 china\n&lt;/p&gt;'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(soup.prettify())</span><br><span class="line">&lt;p&gt;</span><br><span class="line"> 中文 china</span><br><span class="line">&lt;/p&gt;</span><br></pre></td></tr></table></figure>
<p>下面附上一张总结（截）图：<br><img src="https://img-blog.csdnimg.cn/20200420105036148.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="总结图"></p>
]]></content>
      <categories>
        <category>Spider</category>
      </categories>
  </entry>
  <entry>
    <title>MySQL入门（三）条件查询</title>
    <url>/posts/ca70db86.html</url>
    <content><![CDATA[<p>本文数据集下载链接：<a href="https://pan.baidu.com/s/1sVcSXfVZimc6ruyMr4Gr3g" target="_blank" rel="noopener">https://pan.baidu.com/s/1sVcSXfVZimc6ruyMr4Gr3g</a> ，提取码：7gfa </p>
<h1 id="一、条件查询基础"><a href="#一、条件查询基础" class="headerlink" title="一、条件查询基础"></a>一、条件查询基础</h1><p>我们知道从 MySQL 表中使用 SQL<code>SELECT</code> 语句来读取数据，如需有条件地从表中选取数据，可将 <code>WHERE</code> 子句添加到 <code>SELECT</code>语句中。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">操作符</th>
<th style="text-align:left">描述</th>
<th style="text-align:left">实例</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">=</td>
<td style="text-align:left">等号，检测两个值是否相等，如果相等返回true</td>
<td style="text-align:left">(A = B) 返回false。</td>
</tr>
<tr>
<td style="text-align:left">&lt;&gt;, !=</td>
<td style="text-align:left">不等于，检测两个值是否相等，如果不相等返回true</td>
<td style="text-align:left">(A != B) 返回 true。</td>
</tr>
<tr>
<td style="text-align:left">&gt;</td>
<td style="text-align:left">大于号，检测左边的值是否大于右边的值, 如果左边的值大于右边的值返回true</td>
<td style="text-align:left">(A &gt; B) 返回false。</td>
</tr>
<tr>
<td style="text-align:left">&lt;</td>
<td style="text-align:left">小于号，检测左边的值是否小于右边的值, 如果左边的值小于右边的值返回true</td>
<td style="text-align:left">(A &lt; B) 返回 true。</td>
</tr>
<tr>
<td style="text-align:left">&gt;=</td>
<td style="text-align:left">大于等于号，检测左边的值是否大于或等于右边的值, 如果左边的值大于或等于右边的值返回true</td>
<td style="text-align:left">(A &gt;= B) 返回false。</td>
</tr>
<tr>
<td style="text-align:left">&lt;=</td>
<td style="text-align:left">小于等于号，检测左边的值是否小于或等于右边的值, 如果左边的值小于或等于右边的值返回true</td>
<td style="text-align:left">(A &lt;= B) 返回 true。</td>
</tr>
</tbody>
</table>
</div>
<p><strong>语法</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT </span><br><span class="line">				查询列表 </span><br><span class="line">	FROM </span><br><span class="line">				表名 </span><br><span class="line">	WHERE </span><br><span class="line">				筛选条件</span><br></pre></td></tr></table></figure>
<p><strong>分类</strong></p>
<ol>
<li>按条件表达式筛选：&gt; &lt; = != &lt;&gt; &gt;+ &lt;=</li>
<li>按逻辑表达式筛选：&amp;&amp;  ||  !（and or not）</li>
<li>模糊查询：LIKE,  BETWEEN AND, IN, IS NULL</li>
</ol>
<h1 id="二、三种查询方式介绍"><a href="#二、三种查询方式介绍" class="headerlink" title="二、三种查询方式介绍"></a>二、三种查询方式介绍</h1><h2 id="1-按条件表达式筛选"><a href="#1-按条件表达式筛选" class="headerlink" title="1. 按条件表达式筛选"></a>1. 按条件表达式筛选</h2><p><strong>案例一：查询工资&gt;12000的员工信息</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * </span><br><span class="line">FROM employees </span><br><span class="line">WHERE salary&gt;12000;</span><br></pre></td></tr></table></figure>
<p><strong>案例二：查询部门编号不等于90号的员工名和部门编号</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name, department_id </span><br><span class="line">FROM employees </span><br><span class="line">WHERE department_id&lt;&gt;90;</span><br></pre></td></tr></table></figure>
<h2 id="2-按逻辑表达式筛选"><a href="#2-按逻辑表达式筛选" class="headerlink" title="2. 按逻辑表达式筛选"></a>2. 按逻辑表达式筛选</h2><p><strong>案例一：查询工资在10000到20000之间的员工名、工资及奖金</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name, salary, commission_pct </span><br><span class="line">FROM employees </span><br><span class="line">WHERE salary&gt;&#x3D;10000 AND salary&lt;&#x3D;20000;</span><br></pre></td></tr></table></figure>
<p><strong>案例二：查询部门编号不是在90到110之间的，或者工资高于15000的员工信息</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * </span><br><span class="line">FROM employees </span><br><span class="line">WHERE department_id&lt;90 </span><br><span class="line">OR department_id&gt;110 </span><br><span class="line">OR salary&gt;15000;</span><br></pre></td></tr></table></figure>
<p>更为简洁的写法是（使用逻辑表达式）：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * </span><br><span class="line">FROM employees </span><br><span class="line">WHERE NOT(department_id&gt;&#x3D;90 AND department_id&lt;&#x3D;110) OR salary&gt;15000;</span><br></pre></td></tr></table></figure>
<h2 id="3-模糊查询"><a href="#3-模糊查询" class="headerlink" title="3. 模糊查询"></a>3. 模糊查询</h2><h3 id="3-1-LIKE"><a href="#3-1-LIKE" class="headerlink" title="3.1 LIKE"></a>3.1 LIKE</h3><ul>
<li>一般和通配符搭配使用</li>
<li>通配符：<ul>
<li>$\%$ 百分号：任意多个字符，包含0个字符</li>
<li>$_$ 下划线：任意单个字符</li>
</ul>
</li>
</ul>
<p><strong>案例一：查询员工名中包含字符a的员工信息</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * </span><br><span class="line">FROM employees </span><br><span class="line">WHERE last_name LIKE &#39;%a%&#39;;</span><br></pre></td></tr></table></figure>
<p><strong>案例二：查询员工名中第三个字符为n，第五个字符为l的员工名和工资</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name, salary </span><br><span class="line">FROM employees </span><br><span class="line">WHERE last_name LIKE &#39;__n_l%&#39;;</span><br></pre></td></tr></table></figure>
<p><strong>案例三：查询员工名中第二个字符为下划线（_）的员工名，第二种方法为手动指定转义字符</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name </span><br><span class="line">FROM employees </span><br><span class="line">WHERE last_name </span><br><span class="line">LIKE &#39;_\_%&#39;;</span><br></pre></td></tr></table></figure>
<p>第二种方法代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name </span><br><span class="line">FROM employees </span><br><span class="line">WHERE last_name LIKE &#39;_$_%&#39; ESCAPE &#39;$&#39;;</span><br></pre></td></tr></table></figure>
<h3 id="3-2-BETWEEN-AND"><a href="#3-2-BETWEEN-AND" class="headerlink" title="3.2 BETWEEN AND"></a>3.2 BETWEEN AND</h3><ol>
<li><p>使用BETWEEN AND可以提高语句的简洁度</p>
<ol>
<li>包含临界值</li>
<li>两个值不能颠倒顺序</li>
</ol>
</li>
</ol>
<p><strong>案例：查询员工编号在100到120之间的员工信息，第一种做法较繁琐，第二种用BETWEEN AND</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * </span><br><span class="line">FROM employees </span><br><span class="line">WHERE employee_id&gt;&#x3D;100 </span><br><span class="line">AND employee_id&lt;&#x3D;120;</span><br></pre></td></tr></table></figure>
<p>或者更简洁的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * </span><br><span class="line">FROM employees </span><br><span class="line">WHERE employee_id BETWEEN 100 AND 120;</span><br></pre></td></tr></table></figure>
<h3 id="3-3-IN"><a href="#3-3-IN" class="headerlink" title="3.3 IN"></a>3.3 IN</h3><ol>
<li>使用IN提高语句简洁度</li>
<li>IN列表的值类型必须一致或兼容</li>
<li>不支持下划线或通配符</li>
</ol>
<p><strong>案例：查询员工的工种编号是 IT_PROG、AD_VP、AD_PRES中的一个员工名和工种编号</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name, job_id </span><br><span class="line">FROM employees </span><br><span class="line">WHERE job_id&#x3D;&#39;IT_PROG&#39; </span><br><span class="line">OR job_id&#x3D;&#39;AD_VP&#39; OR job_id&#x3D;&#39;AD_PRES&#39;;</span><br></pre></td></tr></table></figure>
<p>或者更简洁的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name, job_id </span><br><span class="line">FROM employees </span><br><span class="line">WHERE job_id IN (&#39;IT_PROG&#39;, &#39;AD_VP&#39;, &#39;AD_PRES&#39;);</span><br></pre></td></tr></table></figure>
<h3 id="3-4-IS-NULL"><a href="#3-4-IS-NULL" class="headerlink" title="3.4 IS NULL"></a>3.4 IS NULL</h3><ul>
<li>=或&lt;&gt;不能用于判断null值</li>
<li>is null或is not null可以判断null值</li>
</ul>
<p><strong>案例：查询没有奖金的员工名和奖金率</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name, commission_pct </span><br><span class="line">FROM employees </span><br><span class="line">WHERE commission_pct IS NULL;</span><br></pre></td></tr></table></figure>
<p><strong>变式：查询有奖金的员工名和奖金率</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name, commission_pct </span><br><span class="line">FROM employees </span><br><span class="line">WHERE commission_pct IS NOT NULL;</span><br></pre></td></tr></table></figure>
<p><strong>注意：以下为错误：</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * FROM employees</span><br><span class="line">WHERE salary IS 12000;</span><br></pre></td></tr></table></figure>
<h2 id="4-安全等与-lt-gt"><a href="#4-安全等与-lt-gt" class="headerlink" title="4. 安全等与 &lt;=&gt;"></a>4. 安全等与 &lt;=&gt;</h2><ol>
<li>优点：既可以判断NULL值又可以判断普通数值</li>
<li>缺点：可读性较低</li>
</ol>
<p><strong>案例1：查询没有奖金的员工名和奖金率</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name, commission_pct </span><br><span class="line">FROM employees </span><br><span class="line">WHERE commission_pct &lt;&#x3D;&gt; NULL;</span><br></pre></td></tr></table></figure>
<p><strong>案例2：查询工资为12000的员工信息</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name, commission_pct </span><br><span class="line">FROM employees </span><br><span class="line">WHERE salary &lt;&#x3D;&gt; 12000;</span><br></pre></td></tr></table></figure>
<h1 id="三、易混辨析"><a href="#三、易混辨析" class="headerlink" title="三、易混辨析"></a>三、易混辨析</h1><p><strong>where：</strong>数据库中常用的是where关键字，用于在初始表中筛选查询。它是一个约束声明，用于约束数据，在返回结果集之前起作用。</p>
<p><strong>group by:</strong>对select查询出来的结果集按照某个字段或者表达式进行分组，获得一组组的集合，然后从每组中取出一个指定字段或者表达式的值。</p>
<p><strong>having：</strong>用于对where和group by查询出来的分组经行过滤，查出满足条件的分组结果。它是一个过滤声明，是在查询返回结果集以后对查询结果进行的过滤操作。</p>
<p><strong>执行顺序</strong></p>
<p><code>select –&gt;where –&gt; group by–&gt; having–&gt;order by</code></p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>Python爬虫初级（二）—— Requests 网络爬虫实战</title>
    <url>/posts/e8ecbe5c.html</url>
    <content><![CDATA[<p>前面我们讲了网络爬虫常用库——Requests，下面我们直接通过几个实例实现网络爬虫：</p>
<h1 id="实例一：京东商品页面的爬取"><a href="#实例一：京东商品页面的爬取" class="headerlink" title="实例一：京东商品页面的爬取"></a>实例一：京东商品页面的爬取</h1><p>首先我们打开京东页面选择商品：<br><a href="https://item.jd.com/100008348530.html" target="_blank" rel="noopener">https://item.jd.com/100008348530.html</a> ，我们要做的事情是通过网络爬虫获取该商品的有关信息，该页面内容如下：<br><img src="https://img-blog.csdnimg.cn/20200419165244644.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="京东商品 Apple iphone 11"> 下面我们对网页进行简单爬取测试：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">r = requests.get(<span class="string">"https://item.jd.com/100008348530.html"</span>)</span><br><span class="line">print(r.statue_code) 		<span class="comment"># 返回200</span></span><br><span class="line">print(r.encoding)     		<span class="comment"># 返回'gbk'</span></span><br><span class="line">r.text[:<span class="number">1000</span>]				<span class="comment"># 返回了正确内容</span></span><br></pre></td></tr></table></figure>
<p>测试基本正常，我们按照前面的文章所说的爬虫通用框架对网页进行爬取：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url = <span class="string">"https://item.jd.com/100008348530.html"</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    r = requests.get(url)</span><br><span class="line">    r.raise_for_status()</span><br><span class="line">    r.encoding = r.apparent_encoding</span><br><span class="line">    print(r.text)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">"爬取失败"</span>)</span><br></pre></td></tr></table></figure>
<h1 id="实例二：亚马逊商品页面的爬取"><a href="#实例二：亚马逊商品页面的爬取" class="headerlink" title="实例二：亚马逊商品页面的爬取"></a>实例二：亚马逊商品页面的爬取</h1><p>我们首先访问页面 <a href="https://www.amazon.cn/dp/B0785D5L1H/ref=sr_1_1" target="_blank" rel="noopener">https://www.amazon.cn/dp/B0785D5L1H/ref=sr_1_1</a> ，下面直接通过代码实现对商品信息的爬取：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    r = requests.get(<span class="string">"https://www.amazon.cn/dp/B0785D5L1H/ref=sr_1_1"</span>)</span><br><span class="line">    r.raise_for_status()</span><br><span class="line">    r.encoding = apparent_encoding</span><br><span class="line">    print(r.text[:<span class="number">100</span>])</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">"爬取错误"</span>)</span><br><span class="line">    print(r.status_code)</span><br><span class="line"><span class="comment"># 返回 503</span></span><br></pre></td></tr></table></figure>
<p>由此例我们可见，亚马逊对我们的爬虫有限制，我们输入以下命令：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">r.request.headers</span><br><span class="line"><span class="comment"># &#123;'User-Agent': 'python-requests/2.22.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'&#125;</span></span><br></pre></td></tr></table></figure>
<p>我们发现在 ‘User-Agent’ 字段下，我们的爬虫忠实地告诉了亚马逊地服务器，这次访问是由 python 的 requests 库发起的，因此我们需要模拟浏览器的请求：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url = <span class="string">"https://www.amazon.cn/dp/B0785D5L1H/ref=sr_1_1"</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">	kv = &#123;<span class="string">'user-agent'</span>:<span class="string">'Mozilla/5.0'</span>&#125;</span><br><span class="line">	r = requests.get(url, headers=kv)</span><br><span class="line">	r.raise_for_status()</span><br><span class="line">	r.encoding = r.apparent_encoding</span><br><span class="line">	print(r.text[<span class="number">1000</span>:<span class="number">2000</span>])</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">	print(<span class="string">"爬取失败"</span>)</span><br></pre></td></tr></table></figure>
<p>此时已成功爬取到数据</p>
<h1 id="实例三：百度-360搜索关键词提交"><a href="#实例三：百度-360搜索关键词提交" class="headerlink" title="实例三：百度/360搜索关键词提交"></a>实例三：百度/360搜索关键词提交</h1><p>首先我们观察一下百度和360的搜索接口：</p>
<blockquote>
<p>百度的关键词接口： <a href="http://www.baidu.com/s?wd=keyword" target="_blank" rel="noopener">http://www.baidu.com/s?wd=keyword</a><br>360的关键词接口：<a href="http://www.so.com/s?q=keyword" target="_blank" rel="noopener">http://www.so.com/s?q=keyword</a></p>
</blockquote>
<p>也就是在这两个接口中，我们只需要将关键词代入 keyword，即可实现提交关键词了，下面我们用 requests 实现相关代码：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">kv = &#123;<span class="string">"wd"</span>:<span class="string">"python"</span>&#125;</span><br><span class="line">r = requests.get(<span class="string">"http://www.baidu.com/s"</span>,params=kv)</span><br><span class="line">print(r.status_code)</span><br><span class="line">print(r.request.url)</span><br></pre></td></tr></table></figure></p>
<p>若无意外状态码返回值为200，而后面的 url 返回的是一个百度安全验证的东西，360搜索的返回值则正常。</p>
<h1 id="实例四：网络图片的爬取和存储"><a href="#实例四：网络图片的爬取和存储" class="headerlink" title="实例四：网络图片的爬取和存储"></a>实例四：网络图片的爬取和存储</h1><p>首先我们看一下网络图片链接的格式：</p>
<blockquote>
<p><a href="http://www.example.com/picture.jpg" target="_blank" rel="noopener">http://www.example.com/picture.jpg</a></p>
</blockquote>
<p>那么我们应该怎样进行图片存储呢？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">root = <span class="string">"D://Temp//Python//Spider//Spider_lecture//Real_test//"</span></span><br><span class="line">url = <span class="string">"http://img0.dili360.com/pic/2019/05/13/5cd93370871d19s75711409_t.jpg"</span></span><br><span class="line">path = root + url.split(<span class="string">"/"</span>)[<span class="number">-1</span>]</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(root):</span><br><span class="line">        os.mkdir(root)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path):</span><br><span class="line">        r = requests.get(url)</span><br><span class="line">        <span class="keyword">with</span> open(path, <span class="string">"wb"</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(r.content)</span><br><span class="line">            f.close()</span><br><span class="line">            print(<span class="string">"文件保存成功 "</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">"文件已存在"</span>)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">"爬取失败"</span>)</span><br></pre></td></tr></table></figure>
<h1 id="实例五：IP地址归属地的自动查询"><a href="#实例五：IP地址归属地的自动查询" class="headerlink" title="实例五：IP地址归属地的自动查询"></a>实例五：IP地址归属地的自动查询</h1><p>当给出一个 IP 地址，我们要怎么判断这个地址是在北京呢，还是在广州呢？事实上，我们有一个网站可以查询相关数据：www.ip138.com ，下图即为该网站的界面：<br><img src="https://img-blog.csdnimg.cn/20200419224808694.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5LYWlfMTY0,size_16,color_FFFFFF,t_70#pic_center" alt="IP地址查询网站界面">那么我们应该怎样通过爬虫进行自动实现呢？事实上，我们通过输入不同的 URL 链接可以发现这样一个规律，即该网站的 URL 组成为：</p>
<blockquote>
<p><a href="http://www.ip138.com/iplookup.asp?ip=**ipaddress**&amp;action=2" target="_blank" rel="noopener">http://www.ip138.com/iplookup.asp?ip=**ipaddress**&amp;action=2</a></p>
</blockquote>
<p>其中 ipaddress 即为用户输入的 IP 地址，我们通过以下代码尝试爬取成功：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url = <span class="string">"https://www.ip138.com/iplookup.asp?ip="</span></span><br><span class="line">header=&#123;<span class="string">'user-agent'</span>:<span class="string">'Mozilla/5.0'</span>&#125;</span><br><span class="line">url_back = <span class="string">"&amp;action=2"</span></span><br><span class="line">r = requests.get(url+<span class="string">"202.204.80.112"</span>+url_back, headers = header,timeout=<span class="number">7</span>)</span><br><span class="line">print(r.status_code)</span><br><span class="line">r.encoding = r.apparent_encoding</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Spider</category>
      </categories>
  </entry>
  <entry>
    <title>MySQL入门（二）基础查询</title>
    <url>/posts/8bec0637.html</url>
    <content><![CDATA[<p>本文数据集下载链接：<a href="https://pan.baidu.com/s/1sVcSXfVZimc6ruyMr4Gr3g" target="_blank" rel="noopener">https://pan.baidu.com/s/1sVcSXfVZimc6ruyMr4Gr3g</a> ，提取码：7gfa </p>
<p><strong>DQL指的是Data Query Language，即数据查询语言，是MySQL语言中的一个子集</strong></p>
<h1 id="基础查询"><a href="#基础查询" class="headerlink" title="基础查询"></a>基础查询</h1><p>MySQL 数据库使用SQL SELECT语句来查询数据。你可以通过 mysql&gt; 命令提示窗口中在数据库中查询数据，或者通过PHP脚本来查询数据。</p>
<ul>
<li>查询语句中你可以使用一个或者多个表，表之间使用逗号(,)分割，并使用WHERE语句来设定查询条件。</li>
<li>SELECT 命令可以读取一条或者多条记录。</li>
<li>你可以使用星号（*）来代替其他字段，SELECT语句会返回表的所有字段数据</li>
<li>你可以使用 WHERE 语句来包含任何条件。</li>
<li>你可以使用 LIMIT 属性来设定返回的记录数。</li>
<li>你可以通过OFFSET指定SELECT语句开始查询的数据偏移量。默认情况下偏移量为0。</li>
</ul>
<h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><ol>
<li><code>select</code> 查询列表 <code>from</code> 表名;</li>
<li>可以使用 <code>字段</code>区分关键字</li>
</ol>
<h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><pre><code> 1. 查询列表可以是：表中的字段、常量、表达式、函数
 2. 查询的结果是一个虚拟的表格
</code></pre><h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><p><strong>查询表中的单个字段</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name FROM employees;</span><br></pre></td></tr></table></figure>
<p><strong>查询表中的多个字段</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name, salary, email FROM employees;</span><br></pre></td></tr></table></figure>
<p><strong>查询表中的所有字段（可以通过全选复制字段名快速复制）</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT employee_id,	first_name,	last_name	email,	phone_number,	job_id,	salary,	commission_pct,	manager_id,	department_id,	hiredate FROM employees;</span><br></pre></td></tr></table></figure>
<p><strong>等同于下面语句（但*使得顺序与原来一样）</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * FROM employees;</span><br></pre></td></tr></table></figure>
<p><strong>查询常量值</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT 100；</span><br><span class="line">SELECT &#39;john&#39;;</span><br></pre></td></tr></table></figure>
<p><strong>查询表达式</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT 100%98;</span><br></pre></td></tr></table></figure>
<p><strong>查询函数</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT VERSION();</span><br></pre></td></tr></table></figure>
<h1 id="为字段取别名"><a href="#为字段取别名" class="headerlink" title="为字段取别名"></a>为字段取别名</h1><pre><code> 1. 便于理解
 2. 如果要查询的字段有重名的情况，使用别名可以区分开
</code></pre><p><strong>方式一：使用As</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT 100%98 AS 结果;</span><br><span class="line"></span><br><span class="line">SELECT last_name AS 姓, first_name As 名 </span><br><span class="line">FROM employees;</span><br></pre></td></tr></table></figure>
<p><strong>方式二：使用空格</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name 姓, first_name 名 </span><br><span class="line">FROM employees;</span><br></pre></td></tr></table></figure>
<p><strong>案例：查询salary，显示结果为out put</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT salary AS &#39;out put&#39; </span><br><span class="line">FROM employees;</span><br></pre></td></tr></table></figure>
<h1 id="去重"><a href="#去重" class="headerlink" title="去重"></a>去重</h1><p>去重的关键字是<code>DISTINCT</code>，注意：不可以同时对多个字段去重</p>
<p><strong>案例：查询员工表中涉及到的所有的部门编号(DISTINCT关键字)</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT DISTINCT department_id </span><br><span class="line">FROM employees;</span><br></pre></td></tr></table></figure>
<h1 id="加号和CONCAT的作用"><a href="#加号和CONCAT的作用" class="headerlink" title="加号和CONCAT的作用"></a>加号和CONCAT的作用</h1><p>JAVA中的加号有两个功能：</p>
<pre><code>1. 运算符，两个操作数都是数值型
2. 连接符，只要有一个操作数为字符串
</code></pre><p>MySQL中的加号只有一个功能：运算符</p>
<pre><code>1. 若两个操作数都为数值型，则做加法运算： select 100 + 90;
2. 若其中一方为字符型，试图将字符型数值转换成数值型：select &#39;123&#39;+90;
3. 若转换失败，则将字符型数值转换成0：select &#39;john&#39;+90;
4. 只要有其中一方为null，则结果必为null
</code></pre><p><strong>案例：查询员工名和姓连接成一个字段，并显示为姓名</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT CONCAT(last_name,&#39; &#39;,first_name) AS 姓名 </span><br><span class="line">FROM employees;</span><br></pre></td></tr></table></figure>
<p><strong>案例：显示出表employees的全部列，各个列之间用逗号连接，列头显示成OUT_PUT</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT </span><br><span class="line">		CONCAT(employee_id, &#39;,&#39;,	first_name, &#39;,&#39;,	last_name, &#39;,&#39;,	email, &#39;,&#39;,	phone_number, &#39;,&#39;,	job_id, &#39;,&#39;,	salary, &#39;,&#39;,	IFNULL(commission_pct,0), &#39;,&#39;,	manager_id, &#39;,&#39;,	department_id, &#39;,&#39;,	hiredate)</span><br><span class="line">AS </span><br><span class="line">		out_put </span><br><span class="line">FROM </span><br><span class="line">		employees;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>Python爬虫初级（一）—— Requests 库入门</title>
    <url>/posts/a8332004.html</url>
    <content><![CDATA[<h1 id="requests-模块的导入"><a href="#requests-模块的导入" class="headerlink" title="requests 模块的导入"></a>requests 模块的导入</h1><p>request 函数的导入可以直接使用 import requests 来实现，当然，若事先没有安装可以直接在命令行输入 pip install reqeusts 来进行安装。<br>requests 模块中包含了七个主要的方法，下面将进行一一解析和尝试调用。</p>
<h1 id="requests-get-函数"><a href="#requests-get-函数" class="headerlink" title="requests.get() 函数"></a>requests.get() 函数</h1><p>requests.get() 函数是一个用于向服务器构造请求资源的 Requests 对象，具体实例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url = www.baidu.com</span><br><span class="line">r = requests.get(url)</span><br><span class="line">print(r.status_code)	<span class="comment"># 返回200表示爬取成功</span></span><br><span class="line">r.encoding = <span class="string">"utf-8"</span>	<span class="comment"># 转换编码</span></span><br><span class="line">print(r.text)			<span class="comment"># 打印对应的HTML文本</span></span><br><span class="line">print(type(r))			<span class="comment"># 应返回 &lt;class 'requests.model.Response'&gt;</span></span><br><span class="line">print(r.headers)		<span class="comment"># 应返回&#123;'Cache-Control': 'private （省略）</span></span><br></pre></td></tr></table></figure>
<p>其中 r 是一个 response 对象，即存储了服务器返回本地的数据，我们对数据的操作即对 r 的操作，response 对象有五个属性，这五个属性是爬虫处理数据的重中之重，其具体含义如下表所示：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>属性</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>r.status_code</td>
<td>HTTP请求的返回状态，202表示连接成功，404表示失败</td>
</tr>
<tr>
<td>r.text</td>
<td>HTTP相应内容的字符串形式，即 url 对应的页面内容</td>
</tr>
<tr>
<td>r.encoding</td>
<td>从HTTP header 中猜测的相应内容编码方式</td>
</tr>
<tr>
<td>r.apparent_encoding</td>
<td>从内容中分析出的相应内容编码方式（备选编码方式）</td>
</tr>
<tr>
<td>r.content</td>
<td>HTTP相应内容的二进制形式</td>
</tr>
</tbody>
</table>
</div>
<p>在我们使用 get 方法从网上获取资源时有基本流程如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">graph LR</span><br><span class="line">A((r.status_code)) -- 返回值为 200 --&gt; B[可以使用 r.text 和 r.encoding 等方法]</span><br><span class="line">A -- 返回值为 404 或其他--&gt; C[某些原因出错将产生异常]</span><br></pre></td></tr></table></figure>
<p>我们要怎么区分 response 的两种编码方式呢？我们来看一个简单的例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">r = requests.get(<span class="string">"http://www.baidu.com"</span>)</span><br><span class="line">print(r.status_code)			<span class="comment"># 返回200表示正常运行,可以继续</span></span><br><span class="line">print(r.text)					<span class="comment"># 显示的内容很多是乱码看不清编码是什么</span></span><br><span class="line">print(r.encoding)				<span class="comment"># 返回 'ISO-8859-1'</span></span><br><span class="line">print(r.apparent_encoding)		<span class="comment"># 返回 'utf-8'</span></span><br><span class="line">r.encoding = <span class="string">'utf-8'</span></span><br><span class="line">print(r.text)					<span class="comment">#返回了正确信息</span></span><br></pre></td></tr></table></figure>
<p>事实上，r.encoding 中的编码方式是从 HTTP 的 header 中的 charset 字段中获得，如果 HTTP 的 header 中有这个字段，说明我们访问的服务器对其资源的编码是有要求的，编码获得后存在 encoding 中，但若 HTTP 的 header中不含有此字段，将默认编码为 ‘ISO-8859-1’，但此编码并不能解析中文。而 apparent_encoding 则是从 HTTP 内容部分分析出可能的编码形式，原则来说此方法会更准确。</p>
<h1 id="爬取网页的通用代码框架"><a href="#爬取网页的通用代码框架" class="headerlink" title="爬取网页的通用代码框架"></a>爬取网页的通用代码框架</h1><p>在实际爬取过程中，requests.get(url) 并不是时时通用的，经常会遇到各种问题，Requests 库支持六种常用的连接异常：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>异常</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>requests.ConnectionError</td>
<td>网络连接错误异常，如 DNS 查询失败，拒绝连接等</td>
</tr>
<tr>
<td>requests.HTTPError</td>
<td>HTTP 错误异常</td>
</tr>
<tr>
<td>requests.URL.Required</td>
<td>URL 缺失异常</td>
</tr>
<tr>
<td>requests.TooManyRedirects</td>
<td>超过最大重定向次数，产生重定向异常</td>
</tr>
<tr>
<td>requests.ConnectTimeout</td>
<td>连接远程服务器超时异常</td>
</tr>
<tr>
<td>requests.Timeout</td>
<td>请求 URL 超时，产生超时异常）</td>
</tr>
</tbody>
</table>
</div>
<p>Response 的异常：<br>异常 | 说明<br>———— | ——-<br>r.raise_for_status() | 如果不是200，产生异常 requests.HTTPError<br>这个异常有什么用呢，我们来看一下爬取网页的通用代码框架就一目了然了：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">geetHTMLText</span><span class="params">(url)</span>:</span></span><br><span class="line">	<span class="keyword">try</span>:</span><br><span class="line">		r = requests.get(url, timeout=<span class="number">30</span>)</span><br><span class="line">		r.raise_for_status() </span><br><span class="line">		r.encoding = r.apparent_encoding</span><br><span class="line">		<span class="keyword">return</span> r.text</span><br><span class="line">	<span class="keyword">except</span>:</span><br><span class="line">		<span class="keyword">return</span> <span class="string">"产生异常"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">	url = <span class="string">"http://www.baidu.com"</span></span><br><span class="line">	print(geteHTMLText(url))</span><br></pre></td></tr></table></figure>
<h1 id="HTTP-协议与-Requests-库的主要方法"><a href="#HTTP-协议与-Requests-库的主要方法" class="headerlink" title="HTTP 协议与 Requests 库的主要方法"></a>HTTP 协议与 Requests 库的主要方法</h1><p>requests 库有七个主要方法，分别如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>方法</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>requests.request()</td>
<td>构造一个请求，支撑以下各方法的基础方法</td>
</tr>
<tr>
<td>requests.get()</td>
<td>获取 HTML 网页的主要方法，对应于 HTTP 的 GET</td>
</tr>
<tr>
<td>requests.head()</td>
<td>获取 HTML网页头信息的方法，对应于 HTTP的 HEAD</td>
</tr>
<tr>
<td>requests.post()</td>
<td>向 HTML 网页提交 POST 请求的方法，对应 HTTP 的 POST</td>
</tr>
<tr>
<td>requests.put()</td>
<td>向 HTML 网页提交 PUT 请求的方法，对应于 HTTP 的 PUT</td>
</tr>
<tr>
<td>requests.patch()</td>
<td>向 HTML 网页提交局部修改请求请求，对应 HTTP 的 PATCH</td>
</tr>
<tr>
<td>requests.delete()</td>
<td>向 HTML 网页提交删除请求，对应于 HTTP 的 DELETE</td>
</tr>
</tbody>
</table>
</div>
<p>为了理解以上方法，我们需要首先了解 HTTP 协议。</p>
<h2 id="HTTP协议"><a href="#HTTP协议" class="headerlink" title="HTTP协议"></a>HTTP协议</h2><p>HTTP 协议是超文本传输协议，是一种基于“请求与响应“模式的、无状态的应用层协议，其中无状态指的是第一次请求与第二次请求之间没有直接关联。HTTP 协议采用 URL 作为定位网络资源的标识，URL 格式为<br><a href="http://host[:port][path]，其中">http://host[:port][path]，其中</a> host 是一个合法的 Internet 主机域名或 IP 地址，port 为端口号，缺省端口为80，path 是请求资源的路径。HTTP协议对资源的操作方法如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>方法</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>GET</td>
<td>请求获取 URL 位置的资源</td>
</tr>
<tr>
<td>HEAD</td>
<td>请求获取 URL 位置的资源的响应消息报告，即获得该资源的头部信息</td>
</tr>
<tr>
<td>POST</td>
<td>请求获取 URL 位置的资源后附加新的数据</td>
</tr>
<tr>
<td>PUT</td>
<td>请求获取 URL 位置存储一个资源，覆盖原 URL 位置的资源</td>
</tr>
<tr>
<td>PATCH</td>
<td>请求局部更新 URL 位置的资源，即改变该处资源的部分内容</td>
</tr>
<tr>
<td>DELETE</td>
<td>请求删除 URL 位置存储的资源</td>
</tr>
</tbody>
</table>
</div>
<p>我们通过HTTP协议可以对资源进行上述操作，即：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">graph LR </span><br><span class="line">A[User] -- GET&#x2F;HEAD --&gt; B((cloud))</span><br><span class="line">B --PUT&#x2F;POST&#x2F;PATCH&#x2F;DELETE--&gt;A</span><br></pre></td></tr></table></figure>
<p>事实上，HTTP 协议通过 URL 做定位，通过上述六个方法对资源进行管理，每个操作都是无状态的。HTTP 协议与 Requests 库的方法是一一对应的，下面以 requests.post() 方法为例说明之：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">payload =  &#123;<span class="string">"key1"</span>:<span class="string">"value1"</span>, <span class="string">"key2"</span>:<span class="string">"value2"</span>&#125;</span><br><span class="line">r = requests.post(<span class="string">"http://httpbin.org/post"</span>, data=payload)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">返回内容：</span><br><span class="line">&#123;...</span><br><span class="line"> &quot;form&quot; : &#123;</span><br><span class="line">	&quot;key2&quot;:&quot;value2&quot;,</span><br><span class="line">   &quot;key1&quot;:&quot;value1&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这说明用 requests.post() 提交一个键值对时会将数据存储在表单（ form ) 下，若提交的是数据，则会存储在 data 下。</p>
<h1 id="Requests-库主要方法解析"><a href="#Requests-库主要方法解析" class="headerlink" title="Requests 库主要方法解析"></a>Requests 库主要方法解析</h1><h2 id="request-方法"><a href="#request-方法" class="headerlink" title="request 方法"></a>request 方法</h2><p>request 方法的使用规则是：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">requests.request(method, url, **kwargs)</span><br></pre></td></tr></table></figure>
<p>其中 method 表示请求方式，具体可填参数有 ‘GET’ , ‘HEAD’, ‘POST’, ‘PUT’, ‘PATCH’, ‘delete’, ‘OPTIONS’，**kwargs 为可选项，有13个参数，下面将进行部分举例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># params 参数</span></span><br><span class="line">kv = &#123;<span class="string">"key1"</span>:<span class="string">"value1"</span>, <span class="string">"key2"</span>:<span class="string">"value2"</span>&#125;</span><br><span class="line">r = requests.request(<span class="string">'GET'</span>, <span class="string">'http://python123.io/ws'</span>, params=kv)</span><br><span class="line">print(r.url)</span><br><span class="line"><span class="comment"># http://python123.io/ws?key1=value1&amp;key2=value2</span></span><br></pre></td></tr></table></figure>
<p>其中”？”后面带的参数可供浏览器进行筛选，再将页面返回。除此之外更常用的是 header 参数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">hd = &#123;<span class="string">'user=agent'</span>:<span class="string">'Chrome/10'</span>&#125;</span><br><span class="line">r = requests.request(<span class="string">'POST'</span>,<span class="string">'http://python123.io/ws'</span>, headers=hd)</span><br></pre></td></tr></table></figure></p>
<p>由上述代码可见，我们可以通过修改 headers 的 ‘user-agent’ 部分模拟不同的浏览器进行访问。另外我们也常常需要隐藏自己的 IP 地址来防止爬虫的逆追踪，我们会使用 proxies 可选项：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pxs = &#123;<span class="string">'http'</span> : <span class="string">'http://user:pass@10.10.10.1:1234'</span> </span><br><span class="line">	   <span class="string">'https'</span> : <span class="string">'https://10.10.10.1:4321'</span> &#125;</span><br><span class="line">r = requests.request(<span class="string">'GET'</span>, <span class="string">'http://www.baidu.com'</span>, proxies=pxs)</span><br></pre></td></tr></table></figure>
<p>其余的可选项还有 data, json, cookies, auth, files, timeout, allow_redirects, stream, verify, cert。</p>
<h1 id="get-方法"><a href="#get-方法" class="headerlink" title="get 方法"></a>get 方法</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">requests.get(url, params=<span class="literal">None</span>, **kwargs)</span><br></pre></td></tr></table></figure>
<p>其中 params 为 url 中的额外参数，是字典或字节流格式，为可选项。**kwargs 有12个控制访问参数，即 request 方法中除了 params 的其他访问参数，就不一一介绍了。</p>
<h1 id="post-方法"><a href="#post-方法" class="headerlink" title="post 方法"></a>post 方法</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">requests.post(url, data=<span class="literal">None</span>, json=<span class="literal">None</span>, **kwargs)</span><br></pre></td></tr></table></figure>
<p>其中 url 为拟更新页面的 url 链接， data 为字典、字节序列或文件，是 Requests 的内容， json 为 JSON 格式的数据， 是 Requests 的内容，**kwargs 为除了 data 与 json 外的其他控制访问参数。</p>
<h1 id="其他方法"><a href="#其他方法" class="headerlink" title="其他方法"></a>其他方法</h1><p>由于其他三个方法使用情况大同小异，直接在下面列出了调用格式：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">requests.put(url, data=<span class="literal">None</span>, **kwargs)</span><br><span class="line">requests.patch(url, data=<span class="literal">None</span>, **kwargs)</span><br><span class="line">requests.delete(url, **kwargs)</span><br></pre></td></tr></table></figure></p>
<p>事实上我们可以发现，除了 request 方法，其他几个方法都不过是显式定义了 kwargs 中的部分参数。这样定义是因为这几个参数的使用频率更高，因此单独定义出来更方便。</p>
]]></content>
      <categories>
        <category>Spider</category>
      </categories>
  </entry>
  <entry>
    <title>MySQL入门（一）数据库基础概念</title>
    <url>/posts/e89e7d68.html</url>
    <content><![CDATA[<h1 id="一、数据库基本概念"><a href="#一、数据库基本概念" class="headerlink" title="一、数据库基本概念"></a>一、数据库基本概念</h1><p>数据库（Database）是按照数据结构来组织、存储和管理数据的仓库。每个数据库都有一个或多个不同的 API 用于创建，访问，管理，搜索和复制所保存的数据。我们也可以将数据存储在文件中，但是在文件中读写数据速度相对较慢。</p>
<p>所以，现在我们使用关系型数据库管理系统（RDBMS）来存储和管理大数据量。所谓的关系型数据库，是建立在关系模型基础上的数据库，借助于集合代数等数学概念和方法来处理数据库中的数据。<strong>数据库的好处</strong>是可以持久化数据到本地，同时可以实现结构化查询，方便管理<strong>数据库相关概念</strong>如下：</p>
<ol>
<li>DB：数据库，保存一组有组织的数据的容器</li>
<li>DBMS：数据库管理系统，又称为数据库软件（产品），用于管理数据库中的数据</li>
<li>SQL：结构化查询语言，用于和DBMS通信的语言</li>
</ol>
<h2 id="1-RDBMS-术语"><a href="#1-RDBMS-术语" class="headerlink" title="1. RDBMS 术语"></a>1. RDBMS 术语</h2><p>在我们开始学习MySQL 数据库前，让我们先了解下RDBMS的一些术语：</p>
<ul>
<li><strong>数据库:</strong> 数据库是一些关联表的集合。</li>
<li><strong>数据表:</strong> 表是数据的矩阵。在一个数据库中的表看起来像一个简单的电子表格。</li>
<li><strong>列:</strong> 一列(数据元素) 包含了相同类型的数据, 例如邮政编码的数据。</li>
<li><strong>行：</strong>一行（=元组，或记录）是一组相关的数据，例如一条用户订阅的数据。</li>
<li><strong>冗余</strong>：存储两倍数据，冗余降低了性能，但提高了数据的安全性。</li>
<li><strong>主键</strong>：主键是唯一的。一个数据表中只能包含一个主键。你可以使用主键来查询数据。</li>
<li><strong>外键：</strong>外键用于关联两个表。</li>
<li><strong>复合键</strong>：复合键（组合键）将多个列作为一个索引键，一般用于复合索引。</li>
<li><strong>索引：</strong>使用索引可快速访问数据库表中的特定信息。索引是对数据库表中一列或多列的值进行排序的一种结构。类似于书籍的目录。</li>
<li><strong>参照完整性:</strong> 参照的完整性要求关系中不允许引用不存在的实体。与实体完整性是关系模型必须满足的完整性约束条件，目的是保证数据的一致性。</li>
</ul>
<h2 id="2-MySQL数据库基本概况"><a href="#2-MySQL数据库基本概况" class="headerlink" title="2. MySQL数据库基本概况"></a>2. MySQL数据库基本概况</h2><p>MySQL 是一个关系型数据库管理系统，由瑞典 MySQL AB 公司开发，目前属于 Oracle 公司。MySQL 是一种关联数据库管理系统，关联数据库将数据保存在不同的表中，而不是将所有数据放在一个大仓库内，这样就增加了速度并提高了灵活性。</p>
<ul>
<li>MySQL 是开源的，目前隶属于 Oracle 旗下产品。</li>
<li>MySQL 支持大型的数据库。可以处理拥有上千万条记录的大型数据库。</li>
<li>MySQL 使用标准的 SQL 数据语言形式。</li>
<li>MySQL 可以运行于多个系统上，并且支持多种语言。这些编程语言包括 C、C++、Python、Java、Perl、PHP、Eiffel、Ruby 和 Tcl 等。</li>
<li>MySQL 对PHP有很好的支持，PHP 是目前最流行的 Web 开发语言。</li>
<li>MySQL 支持大型数据库，支持 5000 万条记录的数据仓库，32 位系统表文件最大可支持 4GB，64 位系统支持最大的表文件为8TB。</li>
<li>MySQL 是可以定制的，采用了 GPL 协议，你可以修改源码来开发自己的 MySQL 系统。</li>
</ul>
<h2 id="4-数据库存储数据的特点"><a href="#4-数据库存储数据的特点" class="headerlink" title="4. 数据库存储数据的特点"></a>4. 数据库存储数据的特点</h2><ol>
<li>将数据放到表中，表再放到库中</li>
<li>一个数据库中可以有多个表，每个表都有一个名字用来标识自己，表名具有唯一性</li>
<li>表具有一些特性，这些特性定义了数据在表中如何存储，类似java中的“类”的设计</li>
<li>表由列组成，我们也称之为字段。所有表都是由一个或多个列组成的，每一列类似java中的”属性“</li>
<li>表中的数据是按行存储的，每一行类似java中的“对象”</li>
</ol>
<h1 id="二、MySQL基本操作"><a href="#二、MySQL基本操作" class="headerlink" title="二、MySQL基本操作"></a>二、MySQL基本操作</h1><p><strong>MySQL服务的启动和终止</strong></p>
<p>假设已经 安装好了MySQL，我们可以通过Windows中的服务手动 启动或关闭MySQL服务，也可以通过管理员模式打开命令行，使用<code>net stop mysql</code>与<code>net start mysql</code>分别关闭和启动MySQL，</p>
<p><strong>MySQL服务端的登陆和退出</strong></p>
<p>MySQL服务端可以直接通过MySQL Shell进入，但这种方式<strong>只能容许root用户进入</strong>，我们推荐使用命令行进入，在命令行下输入：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql -h localhost -P 3307 -u root -p</span><br></pre></td></tr></table></figure>
<p>其中3307为本机设定的端口号，每个人可能不一样，-p之后将会要去输入密码，此时输入之前预设的密码即可，也可以直接在后面接，但注意-p若后面直接接密码，<strong>不加空格</strong>。若是直接本机进入，可以省略<code>-h localhost -P 3307</code>。</p>
<p>退出时直接使用<code>exit</code>或<code>Ctrl+C</code>即可</p>
<h1 id="三、MySQL常用命令"><a href="#三、MySQL常用命令" class="headerlink" title="三、MySQL常用命令"></a>三、MySQL常用命令</h1><p>以下命令结尾都需要加分号；</p>
<ul>
<li><p><code>show databases;</code>可以显示所有数据库</p>
</li>
<li><p><code>use+库名</code>：打开某个数据库</p>
</li>
<li><p><code>show tables</code>：显示库中的某个表内容</p>
</li>
<li><p><code>show tables from+库名（比如MySQL）</code>：从某个库显示表</p>
</li>
<li><p><code>select database()</code>：显示所在的库</p>
</li>
<li><p>创建表名为stuinfo：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create table stuinfo(                                                                                   -&gt; id int,                                                                                              -&gt; name varchar(20));</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>select * from stuinfo</code>：由于为空表，故返回Empty Set</p>
</li>
<li><p><code>desc stuinfo</code>：显示stuinfo表</p>
</li>
<li><p><code>insert info stuinfo(id,name) values(1, &#39;rose&#39;)</code>：插入表</p>
<p>此时再显示，如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select * from stuinfo;                                                                                 +------+------+                                                                                         | id   | name |                                                                                         +------+------+                                                                                         |    1 | rose |                                                                                         |    2 | john |                                                                                          +------+------+</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>update stuinfo set name=&#39;lilei&#39; where id=1;</code>将rose的名字修改为lilei</p>
</li>
<li><code>delete from stuinfo where id=1</code>：将lilei删除</li>
<li><code>select version()</code>：显示版本号（也可以退出之后<code>mysql --version</code>查看）</li>
</ul>
<h1 id="四、MySQL的语法规范"><a href="#四、MySQL的语法规范" class="headerlink" title="四、MySQL的语法规范"></a>四、MySQL的语法规范</h1><ol>
<li>不区分大小写，但建议关键字大写，表名、列名小写</li>
<li>每条命令最好分号结尾</li>
<li>每条命令根据需要，可以进行缩进或换行</li>
<li>注释：<ul>
<li>单行注释：#注释文字</li>
<li>单行注释：— 注释文字（需要加空格）</li>
<li>多行注释：/<em> 注释文字 </em>/</li>
</ul>
</li>
</ol>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>区块链入门（五）合约编写实例补充</title>
    <url>/posts/a4c5a08d.html</url>
    <content><![CDATA[<font color="red"> 注：本教程为技术教程，不谈论且不涉及炒作任何数字货币 </font>

<h1 id="合约编写实战实例"><a href="#合约编写实战实例" class="headerlink" title="合约编写实战实例"></a>合约编写实战实例</h1><h2 id="一、简单代币合约"><a href="#一、简单代币合约" class="headerlink" title="一、简单代币合约"></a>一、简单代币合约</h2><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity &gt; <span class="number">0.4</span><span class="number">.22</span>;</span><br><span class="line"></span><br><span class="line">contract Coin&#123;</span><br><span class="line">    <span class="comment">//这里我们定义了一个address 作为key, uint做为value的hashTable balances; 我们还定义了一个address的变量minter;</span></span><br><span class="line">    address public minter;</span><br><span class="line">    mapping(<span class="function"><span class="params">address</span>=&gt;</span>uint) balances;</span><br><span class="line">    event Sent(address <span class="keyword">from</span>, address to, uint amount);</span><br><span class="line">    <span class="keyword">constructor</span>()&#123;</span><br><span class="line">        <span class="comment">//代表创建这个合约的账户地址，被赋值给变量minter.</span></span><br><span class="line">        minter = msg.sender;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//添加一个挖矿合约 </span></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">mint</span>(<span class="params">address receiver, uint amount</span>) <span class="title">public</span></span>&#123;</span><br><span class="line">        <span class="built_in">require</span>(msg.sender == minter);</span><br><span class="line">        balances[receiver] += amount;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">send</span>(<span class="params">address receiver, uint amount</span>) <span class="title">public</span></span>&#123;</span><br><span class="line">        <span class="built_in">require</span>(balances[msg.sender] &gt;= amount);</span><br><span class="line">        balances[msg.sender] -= amount;</span><br><span class="line">        balances[receiver] += amount;</span><br><span class="line">        emit Sent(msg.sender,receiver,amount);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>解析：<br>上面实现一个简单的加密货币，币在这里可以无中生有，但只有创建合约的人才能做到，且任何人都可以给他人转币，无需注册名和密码。</p>
<p><code>address</code>类型是一个160位的值，不允许任何算数操作，这种类型适合存储合约地址或外部人员。</p>
<p><code>mappings</code>可看作是一个哈希表，它会执行虚拟初始化，以使得所有可能存在的键都映射到一个字节表示为全零的值。</p>
<p><code>event Sent(address from, address to, uint amount)</code>;声明了一个所谓的事件，它在send函数最后一行被发出。用户界面可以监听区块链上正在发送的事件，且不会花费太多成本，一旦它被发出，监听该事件的listener都将收到通知，而所有的事件都包含了<code>from</code>,<code>t</code>o和<code>amoun</code>t三个参数，可方便追踪事务。</p>
<p><code>msg.sender</code>始终是当前函数或者外部函数调用的来源地址。</p>
<p>最后真正被用户和其他合约所调用的，用于完成本合约功能的方法是<code>mint</code>和<code>send</code>。若<code>mint</code>被合约创建者外的其他调用则说明都不会发生。</p>
<p><code>send</code>函数可被任何人用于向其他人发送代币，前提是发送者拥有这些代币，若使用合约发送代币给一个地址，当在区块链浏览器上查到该地址时时看不到任何相关信息的，因为，实际上发送币和更改余额的信息仅仅存在特定合约的数据存储器中。通过使用事件，可非常简单地为新币创建一个区块链浏览器来追踪交易和余额。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-15.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>



<h2 id="二、水龙头合约"><a href="#二、水龙头合约" class="headerlink" title="二、水龙头合约"></a>二、水龙头合约</h2><p>在前面我们通过 Ropsten 测试网络的水龙头（Faucet）获取了一些以太币，并提到可以向水龙头账户发送以太币来捐赠以太币。实际上，水龙头账户是一个合约账户，水龙头就是一份合约，而整个网站就是合约+前端组成的DApp。下面我们通过 Remix 来编写一个简单的水龙头合约，借此了解如何创建、部署合约以及一些 Solidity 的基本语法。</p>
<p>首先打开 Remix，并新建一个名为 faucet.sol 的文件，该文件就是 Solidity 的源文件</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-16.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>

<p>打开 faucet.sol，并写入如下代码</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.7</span><span class="number">.0</span>;</span><br><span class="line"></span><br><span class="line">contract faucet &#123;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">withdraw</span> (<span class="params">uint amount</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        <span class="built_in">require</span> (amount &lt;= <span class="number">1e18</span>);</span><br><span class="line">        msg.sender.transfer (amount);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    receive () external payable &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过这几行代码我们就实现了一个非常简单的水龙头合约。首行代码 <code>pragma solidity ^0.7.0</code>是一个<strong>杂注</strong>，指定了我们的源文件使用的编译器版本不能低于 0.7.0，也不能高于 0.8.0。</p>
<p><code>contract faucet{...}</code> 声明了一个合约对象，合约对象类似面向对象语言中的类，对象名必须跟文件名相同。</p>
<p>接下来通过  <code>function withdraw (uint amount) public {...}</code> 创建了一个名为  withdraw 的函数，该函数接收一个无符号整数（uint）作为参数，并且被声明为 public 函数，意为可以被其他合约调用。</p>
<p>withdraw 函数体中的 <code>require</code> 是 Solidity 的内置函数，用来检测括号中的条件是否满足。条件满足则继续执行合约，条件不满足则合约停止执行，回撤所有执行过的操作，并抛出异常。在这里我们通过 <code>require (amount &lt;= 1e18)</code> 来检测输入的以太币值是否小于等于1个以太。</p>
<p>接下来的这一行 <code>msg.sender.transfer (amount)</code> 就是实际的提款操作了。<code>msg</code> 是 Solidity 中内置的对象，所有合约都可以访问，它代表触发此合约的交易。也就是说当我们调用 <code>withdraw</code> 函数的时候实际上触发了一笔交易，并用 <code>msg</code> 来表示它。<code>sender</code> 是交易 <code>msg</code> 的属性，表示了交易的发件人地址。函数 <code>transfer</code> 是一个内置函数，它接收一个参数作为以太币的数量，并将该数量的以太币从合约账户发送到调用合约的用户的地址中。</p>
<p>最后一行是一个特殊的函数 <code>receive</code> ，这是所谓的 <code>fallback</code> 或 <code>default</code> 函数。当合约中的其他函数无法处理发送到合约中的交易信息时，就会执行该函数。在这里，我们将该函数声明为 <code>external</code> 和 <code>payable</code> ，<code>external</code> 意味着该函数可以接收来自外部账户的调用，<code>payable</code> 意味着该函数可以接收来自外部账户发送的以太币。</p>
<p>这样，当我们调用合约中的 <code>withdraw</code> 并提供一个参数时，我们可以从这份合约中提出以太币；当我们向合约发送以太币时，就会调用 <code>receive</code> 函数往合约中捐赠以太币。</p>
<p>代码编写完毕后，在 Remix 左侧的功能栏中选择第二项，并点击 <em>Compile faucet.sol</em> 来编译我们的 sol 文件。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-17.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<p>编译完成后会出现一个 Warning，提示我们添加 SPDX license，可以忽略。</p>
<p>随后选择 Remix 左侧工具栏的第三项，进入合约部署界面</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-18.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<p>首先将 ENVIRONMENT 选择为 Injected Web3，这样才能通过 MetaMask 钱包来发送交易。</p>
<p>随后点击 Deploy 部署合约，MetaMask 会弹出部署合约的交易界面</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-19.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<p>因为该笔交易是合约创建交易，因此我们支付的以太币为0，但仍需支付一定的 Gas 费用，可以自己设定 Gas 的价格。</p>
<p>合约部署成功后会收到 Chrome 的消息提示，并在 Remix 的 Deployed Contracts 中也会有显示</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-20.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<p>这样我们就完成了这个水龙头合约的部署。</p>
<h4 id="水龙头测试"><a href="#水龙头测试" class="headerlink" title="水龙头测试"></a>水龙头测试</h4><p>我们刚刚创建的水龙头中还没有以太坊，因此我们可以通过 MetaMask 向水龙头合约的地址中发送一些以太坊。水龙头合约的地址会显示在 Remix 中的，见上图 FAUCET AT 0X7A4…34219，可以直接复制。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-21.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<p>交易被确认后，我们的水龙头中就有了0.999726个以太币，现在我们可以通过 Remix 中合约一栏的 withdraw 按钮来提取以太币了。需要注意，这里输入的以太币个数是以 wei 为单位的。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-22.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<p>点击 withdraw 后，会弹出警告框</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-23.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<p>这是因为目前我们还没有设置这笔交易的 Gas，不用担心，点击 Send Transaction 后，在弹出的 MetaMask 中设置即可。</p>
<p>交易被确认后，我们得到了刚刚提取的0.999726个以太币</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-15.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<p>若大家没有执行成功可以重新做一次、查找其他资料或者<a href="https://www.bilibili.com/video/BV1sJ411D72u?p=465" target="_blank" rel="noopener">观看此视频</a></p>
<h2 id="三、投票合约的实现"><a href="#三、投票合约的实现" class="headerlink" title="三、投票合约的实现"></a>三、投票合约的实现</h2><p><img src="\Pic\Blockchain_Pic\rating.png" style="zoom:67%;"></p>
<p>本次教程将以一个较复杂的投票合约作为结束，我们希望实现的功能是为每个（投票）建议建立一份合约,然后作为合约的创造者-主席，主席将赋予每个成员(地址)投票权，而成员的投票权可以选择委托给其他人也可以自己投票，结束时将返回投票最多的提案。听起来很简单一个功能实现起来却较为复杂，下面我们拆分开进行讲解</p>
<p>注：</p>
<ol>
<li>代码可直接在Remix编辑器的已有solidity文件中找到,在contract/_Ballot.sol文件里</li>
<li>若学习者前面部分掌握较牢固，不妨尝试直接自行阅读代码，无需阅读本节内容</li>
</ol>
<p>首先我们定义成员类型，我们为每个投票者定义权重、是否已投票、</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">struct Voter &#123;</span><br><span class="line">    uint weight; <span class="comment">// weight is accumulated by delegation</span></span><br><span class="line">    bool voted;  <span class="comment">// if true, that person already voted</span></span><br><span class="line">    address delegate; <span class="comment">// person delegated to</span></span><br><span class="line">    uint vote;   <span class="comment">// index of the voted proposal</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后我们定义提案类型，包含提案名和投票总数：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">struct Proposal &#123;</span><br><span class="line">    bytes32 name;   <span class="comment">// short name (up to 32 bytes)</span></span><br><span class="line">    uint voteCount; <span class="comment">// number of accumulated votes</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>定义三个变量，主席是一个公开的地址，建立投票者与地址的映射，然后定义提案动态数组：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">address public chairperson;</span><br><span class="line">mapping(<span class="function"><span class="params">address</span> =&gt;</span> Voter) public voters;</span><br><span class="line">Proposal[] public proposals;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>address public chairperson</code>：投票发起人，类型为 address。</li>
<li><code>mapping(address =&gt; Voter) public voters</code>：所有投票人，类型为 <code>address</code> 到 <code>Voter</code> 的映射。</li>
<li><code>Proposal[] public proposals</code>：所有提案，类型为动态大小的 <code>Proposal</code> 数组。</li>
</ul>
<p>3 个状态变量都使用了 <code>public</code> 关键字，使得变量可以被外部访问（即通过消息调用）。事实上，编译器会自动为 <code>public</code>的变量创建同名的 <code>getter</code> 函数，供外部直接读取。</p>
<p>我们还需要为每个投票赋予初始权值，并将主席的权重设置为1。我们一般使用<code>constructor</code>赋初值，这与C++等语言类似：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">constructor</span>(bytes32[] memory proposalNames) &#123;</span><br><span class="line">    chairperson = msg.sender;</span><br><span class="line">    voters[chairperson].weight = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (uint i = <span class="number">0</span>; i &lt; proposalNames.length; i++) &#123;</span><br><span class="line">        proposals.push(Proposal(&#123;</span><br><span class="line">            name: proposalNames[i],</span><br><span class="line">            voteCount: <span class="number">0</span></span><br><span class="line">        &#125;));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>所有提案的名称通过参数 <code>bytes32[] proposalNames</code> 传入，逐个记录到状态变量 <code>proposals</code> 中。同时用 <code>msg.sender</code> 获取当前调用消息的发送者的地址，记录为投票发起人 <code>chairperson</code>，该发起人投票权重设为 1。</p>
<p>接下来我们需要给每个投票者赋予权重：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">giveRightToVote</span>(<span class="params">address voter</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">    <span class="built_in">require</span>(</span><br><span class="line">        msg.sender == chairperson,</span><br><span class="line">        <span class="string">"Only chairperson can give right to vote."</span></span><br><span class="line">    );</span><br><span class="line">    <span class="built_in">require</span>(</span><br><span class="line">        !voters[voter].voted,</span><br><span class="line">        <span class="string">"The voter already voted."</span></span><br><span class="line">    );</span><br><span class="line">    <span class="built_in">require</span>(voters[voter].weight == <span class="number">0</span>);</span><br><span class="line">    voters[voter].weight = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该函数给 <code>address voter</code> 赋予投票权，即将 <code>voter</code> 的投票权重设为 1，存入 <code>voters</code> 状态变量。</p>
<p>上面这个函数只有投票发起人 <code>chairperson</code> 可以调用。这里用到了 <code>require((msg.sender == chairperson) &amp;&amp; !voters[voter].voted)</code> 函数。如果<code>require</code> 中表达式结果为 <code>false</code>，这次调用会中止，且回滚所有状态和以太币余额的改变到调用前。但已消耗的 <code>Gas</code> 不会返还。</p>
<p>下面一段是整段代码的重点，其作用是委托其他人代理投票，基本思路是：</p>
<ol>
<li>使用<code>require</code>判断委托人是否已投票（若投过票再委托则重复投票），并判断被委托对象是否是自己</li>
<li>当判断被委托人不是0地址（主席）时，被委托人代理委托人的票，【绕口警告】由于被委托人也可能委托了别人，因此这里需要一直循环直到找到最后没有委托别人的被委托人为止！</li>
<li>委托人找到对应的被委托人，委托人已投票（避免重复投票）</li>
<li>判断被委托人是否已投票，若投了票则将被委托人投的提案票数加上委托人的权重，若未投票则令被委托人的权重加上委托人的权重（以后投票自然相当于投两票）</li>
</ol>
<p>注：该函数使用了 <code>while</code> 循环，这里合约编写者需要十分谨慎，防止调用者消耗过多 <code>Gas</code>，甚至出现死循环。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">delegate</span>(<span class="params">address to</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">    Voter storage sender = voters[msg.sender];</span><br><span class="line">    <span class="built_in">require</span>(!sender.voted, <span class="string">"You already voted."</span>);</span><br><span class="line">    <span class="built_in">require</span>(to != msg.sender, <span class="string">"Self-delegation is disallowed."</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (voters[to].delegate != address(<span class="number">0</span>)) &#123;</span><br><span class="line">    	to = voters[to].delegate;</span><br><span class="line">    	<span class="built_in">require</span>(to != msg.sender, <span class="string">"Found loop in delegation."</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    sender.voted = <span class="literal">true</span>;</span><br><span class="line">    sender.delegate = to;</span><br><span class="line">    Voter storage delegate_ = voters[to];</span><br><span class="line">    <span class="keyword">if</span> (delegate_.voted) &#123;</span><br><span class="line">    	proposals[delegate_.vote].voteCount += sender.weight;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    	delegate_.weight += sender.weight;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>投票部分仅是几个简单的条件判断：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">vote</span>(<span class="params">uint proposal</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        Voter storage sender = voters[msg.sender];</span><br><span class="line">        <span class="built_in">require</span>(sender.weight != <span class="number">0</span>, <span class="string">"Has no right to vote"</span>);</span><br><span class="line">        <span class="built_in">require</span>(!sender.voted, <span class="string">"Already voted."</span>);</span><br><span class="line">        sender.voted = <span class="literal">true</span>;</span><br><span class="line">        sender.vote = proposal;</span><br><span class="line">        proposals[proposal].voteCount += sender.weight;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>用 <code>voters[msg.sender]</code> 获取投票人，即此次调用的发起人。接下来检查是否是重复投票，如果不是，进行投票后相关状态变量的更新。</p>
<p>接下来是计算获胜提案:</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">winningProposal</span>(<span class="params"></span>) <span class="title">public</span> <span class="title">view</span></span></span><br><span class="line"><span class="function">        <span class="title">returns</span> (<span class="params">uint winningProposal_</span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    uint winningVoteCount = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (uint p = <span class="number">0</span>; p &lt; proposals.length; p++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (proposals[p].voteCount &gt; winningVoteCount) &#123;</span><br><span class="line">            winningVoteCount = proposals[p].voteCount;</span><br><span class="line">            winningProposal_ = p;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>returns (uint winningProposal)</code> 指定了函数的返回值类型，<code>constant</code> 表示该函数不会改变合约状态变量的值。</p>
<p>最后是查询获胜者名称：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">winnerName</span>(<span class="params"></span>) <span class="title">public</span> <span class="title">view</span></span></span><br><span class="line"><span class="function">        <span class="title">returns</span> (<span class="params">bytes32 winnerName_</span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    winnerName_ = proposals[winningProposal()].name;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里采用内部调用 <code>winningProposal()</code> 函数的方式获得获胜提案。如果需要采用外部调用，则需要写为 <code>this.winningProposal()</code>。</p>
<p><strong>参考自：</strong></p>
<p><a href="https://www.bilibili.com/video/BV1sJ411D72u" target="_blank" rel="noopener">尚硅谷区块链全套Go语言→GoWeb→以太坊→项目实战</a><br><a href="http://cw.hubwiz.com/card/c/web3.js-1.0/" target="_blank" rel="noopener">web3.js 1.0中文手册</a></p>
]]></content>
      <categories>
        <category>Blockchain</category>
      </categories>
  </entry>
  <entry>
    <title>区块链入门（四）web3js</title>
    <url>/posts/5521455b.html</url>
    <content><![CDATA[<font color="red">注：本教程为技术教程，不谈论且不涉及炒作任何数字货币 </font>

<h2 id="一、以太坊客户端"><a href="#一、以太坊客户端" class="headerlink" title="一、以太坊客户端"></a>一、以太坊客户端</h2><h3 id="1-1、什么是以太坊客户端"><a href="#1-1、什么是以太坊客户端" class="headerlink" title="1.1、什么是以太坊客户端"></a>1.1、什么是以太坊客户端</h3><ul>
<li>以太坊客户端是一个软件应用程序，它实现以太坊规范并通过p2p网络与其他以太坊客户端进行通信。如果不同的以太坊客户端符合参考规范和标准化通信协议，则可以进行相互操作。</li>
<li>以太坊是一个开源项目，由“黄皮书”正式规范定义。除了各种以太坊改进提案之外，此正式规范还定义了以太坊客户端的标准行为。</li>
<li>因为以太坊有明确的正式规范，以太网客户端有了许多独立开发的软件实现，它们之间又可以彼此交互。</li>
</ul>
<h3 id="1-2、基于以太坊规范的网络"><a href="#1-2、基于以太坊规范的网络" class="headerlink" title="1.2、基于以太坊规范的网络"></a>1.2、基于以太坊规范的网络</h3><ul>
<li>存在各种基于以太坊规范的网络，这些网络基本符合以太坊“黄皮书”中定义的形式规范，但它们之间可能相互也可能不相互操作。</li>
<li>这些基于以太坊的网络中有：以太坊，以太坊经典，Ella，Expanse，Ubiq，Musicoin等等。</li>
<li>虽然大多数在协议级别兼容，但这些网络通常具有特殊要求，以太坊客户端软件的维护人员、需要进行微小更改、以支持每个网络的功能或属性</li>
</ul>
<h3 id="1-3、太坊的多种客户端"><a href="#1-3、太坊的多种客户端" class="headerlink" title="1.3、太坊的多种客户端"></a>1.3、太坊的多种客户端</h3><ul>
<li><a href="https://github.com/ethereum/go-ethereum" target="_blank" rel="noopener">go-ethereum ( Go )</a><br>官方推荐，开发使用最多</li>
<li>parity ( Rust )<br>最轻便客户端，在历次以太坊网络攻击中表现卓越</li>
<li><p>cpp-ethereum (C++)</p>
</li>
<li><p>pyethapp (python)</p>
</li>
<li><p>ethereumjs-lib ( javascript )</p>
</li>
<li><p>EthereumJ / Harmony ( Java )</p>
</li>
</ul>
<h3 id="1-4、以太坊全节点"><a href="#1-4、以太坊全节点" class="headerlink" title="1.4、以太坊全节点"></a>1.4、以太坊全节点</h3><ul>
<li>全节点是整个主链的一个副本，存储并维护链上的所有数据，并随时验证新区块的合法性。</li>
<li>区块链的健康和扩展弹性，取决于具有许多独立操作和地理上分散的全节点。每个全节点都可以帮助其他新节点获取区块数据，并提供所有交易和合约的独立验证。</li>
<li>运行全节点将耗费巨大的成本，包括硬件资源和带宽。</li>
<li>以太坊开发不需要在实时网络（主网）上运行的全节点。我们可以使用测试网络的节点来代替，也可以用本地私链，或者使用服务商提供的基于云的以太坊客户端；这些几乎都可以执行所有操作。</li>
</ul>
<h3 id="1-5、远程客户端和轻节点"><a href="#1-5、远程客户端和轻节点" class="headerlink" title="1.5、远程客户端和轻节点"></a>1.5、远程客户端和轻节点</h3><ul>
<li><p>远程客户端</p>
<p>不存储区块链的本地副本或验证块和交易。这些客户端一般只提供钱包的功能，可以创建和广播交易。远程客户端可用于连接到现有网络，MetaMask 就是一个这样的客户端。</p>
</li>
<li><p>轻节点</p>
<p>  不保存链上的区块历史数据，只保存区块链当前的状态。轻节点可以对块和交易进行验证。</p>
</li>
</ul>
<ul>
<li><p>全节点的优缺点</p>
<ul>
<li>优点<ul>
<li>为以太坊网络的灵活性和抗审查性提供有力支持</li>
<li>权威地验证所有交易</li>
<li>可以直接与公众区块链上的任何合约交互</li>
<li>可以离线查询区块链状态（账户、合约等）</li>
<li>可以直接把自己的合约部署到公共区块链中</li>
</ul>
</li>
<li>缺点<ul>
<li>需要巨大的硬件和带宽资源，而且会不断增长</li>
<li>第一次下载往往需要几天才能完全同步</li>
<li>必须及时维护、升级并保持在线状态以同步区块</li>
</ul>
</li>
</ul>
<h5 id="公共测试网络节点的优缺点"><a href="#公共测试网络节点的优缺点" class="headerlink" title="公共测试网络节点的优缺点"></a>公共测试网络节点的优缺点</h5><ul>
<li>优点<ul>
<li>一个testnet节点需要同步和存储更少的数据，大约10GB，具体取决于不同的网络</li>
<li>一个testnet节点一般可以在几个小时内完成同步</li>
<li>部署合约或进行交易只需要发送测试以太，可以从”水龙头“免费获得</li>
<li>测试网络是公共区块链，有许多其他用户和合约运行（区别于私链）</li>
</ul>
</li>
<li>缺点<ul>
<li>测试网络上使用测试以太没有价值。因此无法测试交易对手的安全性，因为没有任何利害关系</li>
<li>测试网络上的测试无法涵盖所有真实主网特性。例如：交易费用虽然是发送交易所必需的，但由于gas免费，因此 testnet上往往不会考虑。而且一般来说，测试网络不会像主网一样经常拥堵</li>
</ul>
</li>
</ul>
<h5 id="本地私链的优缺点"><a href="#本地私链的优缺点" class="headerlink" title="本地私链的优缺点"></a>本地私链的优缺点</h5><ul>
<li>优点<ul>
<li>磁盘上几乎没有数据，也不同步别的数据，是一个完全干净的环境</li>
<li>无需获取测试以太，可以分配任意以太，也可以随时自己挖矿获得</li>
<li>没有其他用户与合约，无外部干扰</li>
</ul>
</li>
<li>缺点<ul>
<li>没有其他用户意味与公链的行为不同，发送的交易并不存在空间或交易顺序的竞争</li>
<li>除自己之外没有矿工意味着挖矿更容易预测，因此无法测试公链上发生的某些情况</li>
<li>没有其他合约意味着必须部署要测试的所有内容，包括所有的依赖项和合约库</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>我们的教程主要基于本地私链的搭建，以后的交易等也主要基于我们的私链，因此以太坊客户端及私链的搭建在我们本次学习中至关重要。</p>
<p><strong>JSON-RPC</strong></p>
<ul>
<li>以太坊客户端提供了API 和一组远程调用（RPC）命令，这些命令被编码为 JSON。这被称为 JSON-RPC API。本质上，JSON-RPCAPI 就是一个接口，允许我们编写的程序使用以太坊客户端作为网关，访问以太坊网络和链上数据。</li>
<li>通常，RPC 接口作为一个 HTTP 服务，端口设定为 8545。出于安全原因，默认情况下，它仅限于接受来自localhost 的连接。</li>
<li>要访问JSON-RPC API，我们可以使用编程语言编写的专用库，例如JavaScript的 web3.js。</li>
<li>或者也可以手动构建HTTP请求并发送/接收JSON编码的请求，如：</li>
</ul>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">curl -X POST -H <span class="string">"Content-Type:application/json"</span> --data <span class="string">'&#123;"jsonrpc":"2.0","method":"web3_clientVersion","params":[],"id":1&#125;'</span> http:<span class="comment">//127.0.0.1:8545</span></span><br></pre></td></tr></table></figure>
<h2 id="二、用-Geth-搭建以太坊私链"><a href="#二、用-Geth-搭建以太坊私链" class="headerlink" title="二、用 Geth 搭建以太坊私链"></a>二、用 Geth 搭建以太坊私链</h2><h3 id="2-1安装-go"><a href="#2-1安装-go" class="headerlink" title="2.1安装 go"></a>2.1安装 go</h3><p>大家首先输入<code>go version</code>查看自己是否配置成功go环境，若不成功参考下面博客：</p>
<p><a href="https://blog.csdn.net/qq_44702847/article/details/108597386" target="_blank" rel="noopener">go ： GoLand安装及环境配置</a></p>
<p>若成功则如下图所示</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part3-1.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 1</div>
</center>



<h3 id="2-2-安装-Geth"><a href="#2-2-安装-Geth" class="headerlink" title="2.2 安装 Geth"></a>2.2 安装 Geth</h3><p>安装 Geth 有很多种方式，这里主要就 Linux 环境给出两种方法：系统包管理器（apt-get）安装和源码安装。更加推荐大家用源码安装，在整个过程中可以看到 Geth 各组件的构建步骤。</p>
<p>其他OS安装方法见<a href="https://geth.ethereum.org/docs/install-and-build/installing-geth" target="_blank" rel="noopener">本教程</a></p>
<p><strong>方法一、apt-get</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">sudo apt-<span class="keyword">get</span> install software-properties-common</span><br><span class="line">sudo add-apt-repository -y ppa:ethereum/ethereum</span><br><span class="line">sudo apt-<span class="keyword">get</span> update</span><br><span class="line">sudo apt-<span class="keyword">get</span> install ethereum</span><br></pre></td></tr></table></figure>
<p><strong>方法二、源码安装</strong></p>
<ol>
<li>克隆 github 仓库我们的第一步是克隆 git 仓库，以获取源代码的副本。</li>
</ol>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">git clone https:<span class="comment">//github.com/ethereum/go-ethereum.git</span></span><br></pre></td></tr></table></figure>
<ol>
<li>从源码构建 Geth要构建 Geth，切换到下载源代码的目录并使用 make 命令：</li>
</ol>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">cd go-ethereum</span><br><span class="line">make geth</span><br></pre></td></tr></table></figure>
<p>如果一切顺利，我们将看到 Go 编译器构建每个组件，直到它生成 geth 可执行文件：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">build/env.sh go run build/ci.go install ./cmd/geth</span><br><span class="line">&gt;&gt;&gt; <span class="regexp">/usr/</span>local/go/bin/go install -ldflags -X</span><br><span class="line">main.gitCommit=<span class="number">58</span>a1e13e6dd7f52a1d5e67bee47d23fd6cfdee5c -v ./cmd/geth</span><br><span class="line">github.com/ethereum/go-ethereum/common/hexutil</span><br><span class="line">github.com/ethereum/go-ethereum/common/math</span><br><span class="line">github.com/ethereum/go-ethereum/crypto/sha3 github.com/ethereum/go-ethereum/rlp</span><br><span class="line">github.com/ethereum/go-ethereum/crypto/secp256k1</span><br><span class="line">github.com/ethereum/go-ethereum/common [...]</span><br><span class="line">github.com/ethereum/go-ethereum/cmd/utils</span><br><span class="line">github.com/ethereum/go-ethereum/cmd/geth Done building. Run <span class="string">"build/bin/geth"</span> to</span><br><span class="line">launch geth.</span><br></pre></td></tr></table></figure>
<p> 查看 geth version，确保在真正运行之前安装正常：</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part3-2.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 2</div>
</center>



<h3 id="启动节点同步"><a href="#启动节点同步" class="headerlink" title="启动节点同步"></a>启动节点同步</h3><p>安装好了 Geth，现在我们可以尝试运行一下它。执行下面的命令，geth 就会开始同步区块，并存储在当前目录下。</p>
<p>这里的 —syncmode fast 参数表示我们会以“快速”模式同步区块。在这种模式下，我们只会下载每个区块头和区块体，但不会执行验证所有的交易，直到所有区块同步完毕再去获取一个系统当前的状态。这样就节省了很多交易验证的时间。</p>
 <figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">geth –datadir . --syncmode fast</span><br></pre></td></tr></table></figure>
<p>—datadir：后面的参数是区块数据及秘钥存放目录</p>
<p>通常，在同步以太坊区块链时，客户端会一开始就下载并验证每个块和每个交易，也就是说从创世区块开始。 毫无疑问，如果我们不加 —syncmode fast 参数，同步将花费很长时间并且具有很高的资源要求（它将需要更多的 RAM，如果你没有快速存储，则需要很长时间）。有些文章会把这个参数写成 —fast，这是以前快速同步模式的参数写法，现在已经被 –syncmode fast取代。如果我们想同步测试网络的区块，可以用下面的命令：</p>
 <figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">geth --testnet --datadir . --syncmode fast</span><br></pre></td></tr></table></figure>
<p>—testnet 这个参数会告诉 geth 启动并连接到最新的测试网络，也就是 Ropsten。测试网络的区块和交易数量会明显少于主网，所以会更快一点。但即使是用快速模式同步测试网络，也会需要几个小时的时间</p>
<h3 id="2-3-搭建自己的私有链"><a href="#2-3-搭建自己的私有链" class="headerlink" title="2.3 搭建自己的私有链"></a>2.3 搭建自己的私有链</h3><p>因为公共网络的区块数量太多，同步耗时太长，我们为了方便快速了解 Geth，可以试着用它来搭一个只属于自己的私链。首先，我们需要创建网络的“创世”（genesis）状态，这写在一个小小的 JSON 文件里（例如，我们将其命名为 genesis.json，保存到当前目录下）：</p>
 <figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="string">"config"</span>: &#123;</span><br><span class="line">    <span class="string">"chainId"</span>: <span class="number">15</span></span><br><span class="line">    &#125;,</span><br><span class="line"><span class="string">"difficulty"</span>: <span class="string">"2000"</span>,</span><br><span class="line"><span class="string">"gasLimit"</span>: <span class="string">"2100000"</span>,</span><br><span class="line"><span class="string">"alloc"</span>: &#123;</span><br><span class="line">    <span class="string">"7df9a875a174b3bc565e6424a0050ebc1b2d1d82"</span>: &#123;   <span class="string">"balance"</span>: <span class="string">"300000"</span> &#125;,</span><br><span class="line">    <span class="string">"f41c74c9ae680c1aa78f42e5647a62f353b7bdde"</span>: &#123; <span class="string">"balance"</span>: <span class="string">"400000"</span> &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>genesis.json介绍</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part3-3.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 3</div>
</center>



<p>要创建一条以它作为创世块的区块链，我们可以使用下面的命令：</p>
 <figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">geth --datadir . init genesis.json</span><br></pre></td></tr></table></figure>
<p>初始化完成后目录下多了geth和keystore两个文件夹：</p>
<ul>
<li>geth：保存该链上的区块数据</li>
<li>keystore：保存该链上的账户信息</li>
</ul>
<p><strong>可能遇到问题</strong>：</p>
<ul>
<li><p>Fatal: invalid genesis file: missing 0x prefix for hex data：这个错误信息意思很明白，就是你的json文件中，对于16进制数据，需要加上0x前缀</p>
</li>
<li><p>Fatal: invalid genesis file: hex string has odd length: 从Geth 1.6版本开始，设置的十六进制数值，不能是奇数位， 比如不能是0x0，而应该是0x00。</p>
</li>
<li><p>Fatal: failed to write genesis block: genesis has no chain configuration ：这个错误信息，就是说，你的配置文件中，缺少config部分。</p>
</li>
<li><p>Error: invalid sender: 这个错误虽然不会导致私有链初始化时出现失败的情况，但是会在以后的转账（web3.eth.sendTransaction），或者部署智能合约的时候产生。解决方法就是chainId 不能设置为0。 如果你完全按照Geth官方文档上给出的配置文件进行配置，就会产生这个错误。</p>
</li>
</ul>
<p>在当前目录下运行 geth，就会启动这条私链，注意要将 networked 设置为与创世块配置里的chainId 一致。</p>
 <figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 简单开启</span></span><br><span class="line">(base) haobo@haobo:~<span class="regexp">/home/m</span>nt/bitcoin/test$ geth --datadir . --networkid <span class="number">150</span> --nodiscover <span class="built_in">console</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 更一般的形式</span></span><br><span class="line">(base) haobo@haobo:~<span class="regexp">/home/m</span>nt/bitcoin/test$ geth --networkid <span class="number">150</span> --datadir <span class="string">"."</span> --identity <span class="string">"kexin"</span> --rpc --rpcport <span class="string">"8545"</span> --rpcaddr <span class="string">"localhost"</span> --port <span class="string">"30303"</span> --nodiscover --allow-insecure-unlock --rpcapi <span class="string">"eth,net,web3,personal,admin,shh,txpool,debug,miner"</span> <span class="built_in">console</span></span><br></pre></td></tr></table></figure>
<p>参数含义：</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part3-4.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 4</div>
</center>



<p>我们可以看到节点正常启动：</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part3-5.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 5</div>
</center>


<p>启动完之后，就可以通过<code>admin.nodeInfo.protocols.eth</code>来获取到刚启动的节点的一些信息（如下），比较上文初始化的配置，相关内容是一致的。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part3-6.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 6</div>
</center>


<p>恭喜！我们已经成功启动了一条自己的私链。</p>
<h2 id="3、Geth-控制台命令"><a href="#3、Geth-控制台命令" class="headerlink" title="3、Geth 控制台命令"></a>3、Geth 控制台命令</h2><p><code>Geth Console</code> 是一个交互式的 JavaScript 执行环境，其中 &gt; 是命令提示符,里面内置了一些用来操作以太坊的 JavaScript对象，我们可以直接调用这些对象来获取区块链上的相关信息。</p>
<p><strong>这些对象主要包括：</strong></p>
<ul>
<li>eth：主要包含对区块链进行访问和交互相关的方法；</li>
<li>net：主要包含查看 p2p 网络状态的方法；</li>
<li>admin：主要包含与管理节点相关的方法；</li>
<li>miner：主要包含挖矿相关的一些方法；</li>
<li>personal：包含账户管理的方法；</li>
<li>txpool：包含查看交易内存池的方法；</li>
<li>web3：包含以上所有对象，还包含一些通用方法。</li>
</ul>
<p><strong>常用命令有：</strong></p>
<ul>
<li>personal.newAccount()：创建账户；</li>
<li>personal.unlockAccount()：解锁账户；</li>
<li>eth.accounts：枚举系统中的账户；</li>
<li>eth.getBalance()：查看账户余额，返回值的单位是 Wei（Wei 是以太坊中最小货币面额单位，类似比特币中的聪，1 ether = 10^18 Wei）；</li>
<li>eth.blockNumber：列出区块总数；</li>
<li>eth.getTransaction()：获取交易；</li>
<li>eth.getBlock()：获取区块；</li>
<li>miner.start()：开始挖矿；</li>
<li>miner.stop()：停止挖矿；</li>
<li>web3.fromWei()：Wei 换算成以太币；</li>
<li>web3.toWei()：以太币换算成 Wei；</li>
<li>txpool.status：交易池中的状态；</li>
<li>admin.addPeer()：连接到其他节点</li>
</ul>
<h3 id="3-1-操作测试"><a href="#3-1-操作测试" class="headerlink" title="3.1 操作测试"></a>3.1 操作测试</h3><p><strong>3.1.1 创建账户</strong></p>
<p>进入控制台后，可以通过使用命令来与私有链进行交互。创建一个新的账户：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; personal.newAccount()</span><br><span class="line">Passphrase:</span><br><span class="line">Repeat passphrase:</span><br><span class="line"><span class="string">"0xc8248c7ecbfd7c4104923275b99fafb308bbff92"</span></span><br></pre></td></tr></table></figure>
<p>输入两遍密码后，生成账户地址。以同样的方式，可创建多个账户，查看账户：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; eth.accounts</span><br></pre></td></tr></table></figure>
<p>查看账户余额</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; eth.getBalance(eth.accounts[<span class="number">0</span>])</span><br><span class="line"><span class="number">0</span></span><br></pre></td></tr></table></figure>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part3-7.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 7</div>
</center>


<p><strong>3.1.2 挖矿</strong></p>
<p>启动挖矿：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; miner.start(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>其中 <code>start</code> 的参数表示挖矿使用的线程数。第一次启动挖矿会先生成挖矿所需的 <code>DAG</code>文件，这个过程有点慢，等进度达到 100% 后，就会开始挖矿，此时屏幕会被挖矿信息刷屏。</p>
<p>停止挖矿，在 控制台 中输入：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; miner.stop()</span><br></pre></td></tr></table></figure>
<p>挖到一个区块会奖励以太币，挖矿所得的奖励会进入矿工的账户，这个账户叫做 coinbase，默认情况下 coinbase 是本地账户中的第一个账户，可以通过 miner.setEtherbase() 将其他账户设置成 coinbase。</p>
<p>可以使用以下命令，当新区块挖出后，挖矿即可结束。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; miner.start(<span class="number">1</span>);admin.sleepBlocks(<span class="number">1</span>);miner.stop();</span><br></pre></td></tr></table></figure>
<p><strong>3.1.3 交易</strong></p>
<p>目前，账户 0 已经挖到了 3 个块的奖励，账户 1 的余额还是0：<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; eth.getBalance(eth.accounts[<span class="number">0</span>])</span><br><span class="line"><span class="number">15000000000000000000</span></span><br><span class="line">&gt; eth.getBalance(eth.accounts[<span class="number">1</span>])</span><br><span class="line"><span class="number">0</span></span><br></pre></td></tr></table></figure></p>
<p>我们要从账户 0 向账户 1 转账，先解锁账户 0，才能发起交易：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; personal.unlockAccount(eth.accounts[<span class="number">0</span>])</span><br><span class="line">Unlock account <span class="number">0x3443ffb2a5ce3f4b80080791e0fde16a3fac2802</span></span><br><span class="line">Passphrase: </span><br><span class="line"><span class="literal">true</span></span><br></pre></td></tr></table></figure>
<p>发送交易，账户 0 -&gt; 账户 1：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; amount = web3.toWei(<span class="number">5</span>,<span class="string">'ether'</span>)</span><br><span class="line"><span class="string">"5000000000000000000"</span></span><br><span class="line">&gt; eth.sendTransaction(&#123;<span class="attr">from</span>:eth.accounts[<span class="number">0</span>],<span class="attr">to</span>:eth.accounts[<span class="number">1</span>],<span class="attr">value</span>:amount&#125;)</span><br><span class="line">INFO [<span class="number">09</span><span class="number">-12</span>|<span class="number">07</span>:<span class="number">38</span>:<span class="number">12</span>] Submitted transaction                    fullhash=<span class="number">0x9f5e61f3d686f793e2df6378d1633d7a9d1df8ec8c597441e1355112d102a6ce</span> recipient=<span class="number">0x02bee2a1582bbf58c42bbdfe7b8db4685d4d4c62</span></span><br><span class="line"><span class="string">"0x9f5e61f3d686f793e2df6378d1633d7a9d1df8ec8c597441e1355112d102a6ce"</span></span><br></pre></td></tr></table></figure>
<p>此时如果没有挖矿，用 <code>txpool.status</code> 命令可以看到本地交易池中有一个待确认的交易，可以使用 <code>eth.getBlock(&quot;pending&quot;, true).transactions</code>查看当前待确认交易。使用下面命令开始挖矿。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt;miner.start(<span class="number">1</span>);admin.sleepBlocks(<span class="number">1</span>);miner.stop();</span><br></pre></td></tr></table></figure>
<p>新区块挖出后，挖矿结束，查看账户 1 的余额，已经收到了账户 0 的以太币：<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; web3.fromWei(eth.getBalance(eth.accounts[<span class="number">1</span>]),<span class="string">'ether'</span>)</span><br><span class="line"><span class="number">5</span></span><br></pre></td></tr></table></figure></p>
<p><strong>3.1.3 查看交易和区块</strong></p>
<p>查看当前区块总数：<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; eth.blockNumber</span><br><span class="line"><span class="number">4</span></span><br></pre></td></tr></table></figure></p>
<p>通过区块号查看区块：<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; eth.getBlock(<span class="number">4</span>)</span><br></pre></td></tr></table></figure></p>
<p>通过交易 Hash 查看交易（Hash 值包含在上面交易返回值中）：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt;  eth.getTransaction(<span class="string">"0x9f5e61f3d686f793e2df6378d1633d7a9d1df8ec8c597441e1355112d102a6ce"</span>)</span><br></pre></td></tr></table></figure>
<p><strong>3.1.3 其他节点加入</strong></p>
<p>此时，私有链已经通过该节点创建好了，如果其他节点想加入，需要通过以太坊客户端连接到该私有区块网络，并连接该网络的节点来同步区块信息。在其他主机上安装以太坊客户端Geth，通过Geth命令进入该私有区块链，注意要指定相同的网络号。</p>
<p>假设有两个节点：节点一和节点二，NetWorkID 都是 6666，通过下面的步骤就可以从节点一连接到节点二。</p>
<p>首先要知道节点二的 enode 信息，在节点二的 Geth Console 中执行下面的命令查看 enode 信息：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; admin.nodeInfo.enode</span><br><span class="line"><span class="string">"enode://d465bcbd5c34da7f4b8e00cbf9dd18e7e2c38fbd6642b7435f340c7d5168947ff2b822146e1dc1b07e02f7c15d5ca09249a92f1d0caa34587c9b2743172259ee@[::]:30303"</span></span><br></pre></td></tr></table></figure>
<p>然后在节点一的 Geth Console 中执行 <code>admin.addPeer()</code>，就可以连接到节点二：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; admin.addPeer(<span class="string">"enode://d465bcbd5c34da7f4b8e00cbf9dd18e7e2c38fbd6642b7435f340c7d5168947ff2b822146e1dc1b07e02f7c15d5ca09249a92f1d0caa34587c9b2743172259ee@[::]:30303"</span>)</span><br></pre></td></tr></table></figure>
<p><code>addPeer()</code> 的参数就是节点二的 enode 信息，注意要把 enode 中的 <code>[::]</code> 替换成节点二的 IP 地址。连接成功后，节点二就会开始同步节点一的区块，同步完成后，任意一个节点开始挖矿，另一个节点会自动同步区块，向任意一个节点发送交易，另一个节点也会收到该笔交易。</p>
<p>通过 <code>admin.peers</code>可以查看连接到的其他节点信息，通过 <code>net.peerCount</code>可以查看已连接到的节点数量。</p>
<p>除了上面的方法，也可以在启动节点的时候指定<code>--bootnodes</code>选项连接到其他节点。</p>
<blockquote>
<p>如果只是自己测试开发使用，建议使用dev环境，在需要在启动时增加<code>–dev</code>参数即可，在dev模式下会监听交易，一旦有交易发送就会打包然后挖矿确认，且默认的<code>account[0]</code>开发者账户初始有一大堆以太币。</p>
</blockquote>
<h2 id="3、智能合约操作"><a href="#3、智能合约操作" class="headerlink" title="3、智能合约操作"></a>3、智能合约操作</h2><h3 id="3-1、创建和编译智能合约"><a href="#3-1、创建和编译智能合约" class="headerlink" title="3.1、创建和编译智能合约"></a>3.1、创建和编译智能合约</h3><p>经过part2的学习大家已经基本上掌握了Solidity，接下来我们编写一个智能合约：</p>
<p>该合约包含一个方法 multiply()，将输入的两个数相乘后输出：<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br><span class="line">contract TestContract</span><br><span class="line">&#123;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">multiply</span>(<span class="params">uint a, uint b</span>) <span class="title">returns</span> (<span class="params">uint</span>)</span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> a * b;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>将上面的代码复制到Remix编辑器里，程序将自动完成编译。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part3-8.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 8</div>
</center>


<p>点击 run 在Environment中设选择JavaScript VM, Value可设置为1，点击Deploy，则可创建该部署智能合约的交易。</p>
<p>因为我们要将该智能合约部署到私有链上，需要得到智能合约编译后的EVM二进制码和JSON ABI（Application Binary Interface）。将生成的交易保存到scenario.json文件，点击箭头所指按钮</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part3-9.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 9</div>
</center>



<p>其中38-65行为该智能合约的ABI（注意前面还有一个[符号），ABI指定了合约接口，包括可调用的合约方法、变量、事件等。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part3-10.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 10</div>
</center>


<p>input`字段为合约EVM二进制码，可点击直接复制。</p>
<p>在Linux下可以直接使用安装好的编译器进行编译，把合约代码保存到文件名为testContract.sol 里,通过下面两个命令分别得到EVM二进制码和JSON ABI。</p>
<p>如果没有安装solc先执行</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">sudo snap install solc</span><br></pre></td></tr></table></figure>
<p>接下来执行<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">$solc --bin testContract.sol</span><br><span class="line">$solc --abi testContract.sol</span><br></pre></td></tr></table></figure></p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part3-11.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 11</div>
</center>


<h3 id="3-2、部署智能合约"><a href="#3-2、部署智能合约" class="headerlink" title="3.2、部署智能合约"></a>3.2、部署智能合约</h3><p>回到 Geth 的控制台，用变量 code 和 abi 记录上面两个值：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; code = <span class="string">"608060405234801561001057600080fd5b5060b88061001f6000396000f3fe6080604052348015600f57600080fd5b506004361060285760003560e01c8063165c4a1614602d575b600080fd5b606060048036036040811015604157600080fd5b8101908080359060200190929190803590602001909291905050506076565b6040518082815260200191505060405180910390f35b600081830290509291505056fea265627a7a7231582049ecffb2740a6e31f7c8fbf4a928b88d3a95f417b985dc23cd1ad4c06a9b043864736f6c63430005100032"</span></span><br><span class="line">&gt; abi = [&#123;</span><br><span class="line">    <span class="string">"0xd1ef8ab8f12bde83ebaee1be4183c75f45ab5835643812016a7751173bfb9dc0"</span>: [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="string">"constant"</span>: <span class="literal">true</span>,</span><br><span class="line">        <span class="string">"inputs"</span>: [</span><br><span class="line">          &#123;</span><br><span class="line">            <span class="string">"name"</span>: <span class="string">"a"</span>,</span><br><span class="line">            <span class="string">"type"</span>: <span class="string">"uint256"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          &#123;</span><br><span class="line">            <span class="string">"name"</span>: <span class="string">"b"</span>,</span><br><span class="line">            <span class="string">"type"</span>: <span class="string">"uint256"</span></span><br><span class="line">          &#125;</span><br><span class="line">        ],</span><br><span class="line">        <span class="string">"name"</span>: <span class="string">"multiply"</span>,</span><br><span class="line">        <span class="string">"outputs"</span>: [</span><br><span class="line">          &#123;</span><br><span class="line">            <span class="string">"name"</span>: <span class="string">""</span>,</span><br><span class="line">            <span class="string">"type"</span>: <span class="string">"uint256"</span></span><br><span class="line">          &#125;</span><br><span class="line">        ],</span><br><span class="line">        <span class="string">"payable"</span>: <span class="literal">false</span>,</span><br><span class="line">        <span class="string">"stateMutability"</span>: <span class="string">"view"</span>,</span><br><span class="line">        <span class="string">"type"</span>: <span class="string">"function"</span></span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;]</span><br></pre></td></tr></table></figure>
<p>使用账户 0 来部署合约，首先解锁账户：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; personal.unlockAccount(eth.accounts[<span class="number">0</span>])</span><br><span class="line">Unlock account <span class="number">0xb51654f60dee35265558a1d2e61468fe00f12888</span></span><br><span class="line">Passphrase:</span><br><span class="line"><span class="literal">true</span></span><br></pre></td></tr></table></figure>
<p>创建合约实例，发送部署合约的交易：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; myContract = eth.contract(abi)   </span><br><span class="line">...</span><br><span class="line">&gt; contract = myContract.new(&#123;<span class="attr">from</span>:eth.accounts[<span class="number">0</span>],<span class="attr">data</span>:code,<span class="attr">gas</span>:<span class="number">1000000</span>&#125;)</span><br></pre></td></tr></table></figure>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part3-12.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 12</div>
</center>

<p>此时如果没有挖矿，用 <code>txpool.status</code> 命令可以看到本地交易池中有一个待确认的交易。使用 <code>miner.start()</code> 命令开始挖矿，一段时间后交易会被确认。通过查询该交易可得到合约地址，使用命令：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt;eth.getTransactionReceipt(<span class="string">"0x085b66b2591ee31c3ad58a66ca485bd19bea6c1fc8ca7550a896853ab52855a6"</span>)</span><br><span class="line">contractAddress: <span class="string">"0xd92845cc4bffc1d6a4b6a389933b88880d5ded24"</span></span><br></pre></td></tr></table></figure>
<h3 id="3-3、调用智能合约"><a href="#3-3、调用智能合约" class="headerlink" title="3.3、调用智能合约"></a>3.3、调用智能合约</h3><p>使用以下命令通过发送交易来调用合约，sendTransaction 方法的前几个参数应该与合约中 multiply 方法的输入参数对应。这种情况下，交易会通过挖矿记录到区块链中：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt;contract.multiply.sendTransaction(<span class="number">2</span>, <span class="number">4</span>, &#123;<span class="attr">from</span>:eth.accounts[<span class="number">0</span>]&#125;)</span><br></pre></td></tr></table></figure>
<p>在本地运行该方法可直接查看返回结果，不会记录到区块链中，命令如下：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt;contract.multiply.call(<span class="number">2</span>，<span class="number">4</span>)</span><br><span class="line"><span class="number">8</span></span><br></pre></td></tr></table></figure>
<p>如果其他节点要调用这个已经部署好的合约，需要知道该合约的地址以及ABI。可以通过发送交易调用，也可以本地调用。我们以本地调用为例。<br>创建合约实例：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt;abi = [&#123;</span><br><span class="line">    <span class="string">"0xd1ef8ab8f12bde83ebaee1be4183c75f45ab5835643812016a7751173bfb9dc0"</span>: [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="string">"constant"</span>: <span class="literal">true</span>,</span><br><span class="line">        <span class="string">"inputs"</span>: [</span><br><span class="line">          &#123;</span><br><span class="line">            <span class="string">"name"</span>: <span class="string">"a"</span>,</span><br><span class="line">            <span class="string">"type"</span>: <span class="string">"uint256"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          &#123;</span><br><span class="line">            <span class="string">"name"</span>: <span class="string">"b"</span>,</span><br><span class="line">            <span class="string">"type"</span>: <span class="string">"uint256"</span></span><br><span class="line">          &#125;</span><br><span class="line">        ],</span><br><span class="line">        <span class="string">"name"</span>: <span class="string">"multiply"</span>,</span><br><span class="line">        <span class="string">"outputs"</span>: [</span><br><span class="line">          &#123;</span><br><span class="line">            <span class="string">"name"</span>: <span class="string">""</span>,</span><br><span class="line">            <span class="string">"type"</span>: <span class="string">"uint256"</span></span><br><span class="line">          &#125;</span><br><span class="line">        ],</span><br><span class="line">        <span class="string">"payable"</span>: <span class="literal">false</span>,</span><br><span class="line">        <span class="string">"stateMutability"</span>: <span class="string">"view"</span>,</span><br><span class="line">        <span class="string">"type"</span>: <span class="string">"function"</span></span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;]</span><br><span class="line">&gt;sample=eth.contract(abi)</span><br><span class="line">&gt;samplecontract=sample.at(<span class="string">"0xd92845cc4bffc1d6a4b6a389933b88880d5ded24"</span>)</span><br></pre></td></tr></table></figure>
<p>调用合约</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt;samplecontract.multiply.call(<span class="number">2</span>，<span class="number">4</span>)</span><br><span class="line"><span class="number">8</span></span><br></pre></td></tr></table></figure>
<h2 id="4、web3-js-简介"><a href="#4、web3-js-简介" class="headerlink" title="4、web3.js 简介"></a>4、web3.js 简介</h2><p>我们除了通过Geth的JavaScript Console进行交互以外，还有许多第三方库可以使用，方便开发基于以太坊区块链的应用：</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part3-13.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 13</div>
</center>


<p>本文使用web3.js与Geth客户端交互，首先搭建开发环境。</p>
<h3 id="4-1-环境搭建"><a href="#4-1-环境搭建" class="headerlink" title="4.1 环境搭建"></a>4.1 环境搭建</h3><p><strong>4.1.1 node.js安装</strong></p>
<p>更新源<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">sudo apt-<span class="keyword">get</span> update</span><br><span class="line">sudo apt-<span class="keyword">get</span> install -y python-software-properties software-properties-common</span><br><span class="line">sudo add-apt-repository ppa:chris-lea/node.js</span><br><span class="line">sudo apt-<span class="keyword">get</span> update</span><br></pre></td></tr></table></figure></p>
<p>node.js、npm安装<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">sudo apt-<span class="keyword">get</span> install nodejs</span><br><span class="line">sudo apt install nodejs-legacy</span><br><span class="line">sudo apt install npm</span><br></pre></td></tr></table></figure><br>安装完后，可以通过 <code>node --version npm --version</code> 查看是否安装成功及版本号。npm 包管理工具随 node 一起安装，如果版本太低，建议升到新版本。</p>
<p><strong>4.1.2 web3.js模块安装</strong><br>使用npm可完成本地安装、全局安装模块。<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">npm install -global &lt;package name&gt; <span class="comment">//全局安装</span></span><br><span class="line">npm install &lt;package name&gt; <span class="comment">//本地安装</span></span><br></pre></td></tr></table></figure></p>
<p>我这里选择使用本地安装模块，这样方便开发的应用移植、上线等。创建一个工程文件夹etherjs。在该文件夹下初始化一个新的 package.json 文件，使用下面命令自动生成。<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">npm init -y</span><br></pre></td></tr></table></figure></p>
<p>本地安装并添加模块名到 package.json<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">npm install &lt;package name&gt; --save</span><br><span class="line">或者npm install &lt;package name&gt; --save-dev</span><br></pre></td></tr></table></figure></p>
<p>区别在于—save-dev 是你开发时候依赖的东西，—save 是你发布之后还依赖的东西。一般使用—save。<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">npm install web3 --save</span><br></pre></td></tr></table></figure></p>
<p>如果这样安装不成功，使用下面命令安装指定版本：<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">npm install web3@^<span class="number">0.20</span><span class="number">.1</span> --save</span><br></pre></td></tr></table></figure></p>
<p><strong>4.1.3 solc.js模块安装</strong><br>solc是用来编译智能合约的模块<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">npm install solc --save</span><br></pre></td></tr></table></figure></p>
<p><strong>4.1.4 编译器——Visual Studio Code</strong></p>
<p>这里选择Visual Studio Code，适合node.js开发，集成的终端可以很方便运行程序。</p>
<p>安装Ubuntu Make<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">sudo add-apt-repository ppa:ubuntu-desktop/ubuntu-make</span><br><span class="line">sudo apt-<span class="keyword">get</span> update</span><br><span class="line">sudo apt-<span class="keyword">get</span> install ubuntu-make</span><br></pre></td></tr></table></figure><br>安装visual-studio-code<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">umake web visual-studio-code</span><br></pre></td></tr></table></figure><br>安装完成后，直接搜索Visual Studio Code应用，把图标拖拽到Unity启动器上，就可以方便使用了。</p>
<h3 id="4-2-web3-js-介绍"><a href="#4-2-web3-js-介绍" class="headerlink" title="4.2 web3.js 介绍"></a>4.2 web3.js 介绍</h3><p>web3js 的全称是Web3 JavaScript app API，它是一个JavaScript API库。要使DApper在以太坊上运行，我们可以使用web3.js库提供的web3对象。web3.js通过RPC调用与本地节点通信，它可以用于任何暴露了RPC层的以太坊节点，web3包含了eth对象 - web3.eth（专门与以太坊区块链交互）和 shh对象 - web3.shh（用于与 Whisper交互）[Whisper是以太坊生态系统的一部分，主要用来做消息传递]</p>
<p>如果我们想要在以太坊上开发合约，目前来说最方便的方法就是调用Web3.js库，它会给我们一个Web3对象。我们进入geth控制台，直接键入web3就可以看到所有的方法。下面主要介绍如何通过web3js创建合约并调用</p>
<p><strong>4.2.1异步回调（callback）</strong></p>
<ul>
<li>web3js API 设计的最初目的，主要是为了和本地 RPC 节点共同使用，所以默认情况下发送的是同步 HTTP 请求</li>
<li>如果要发送异步请求，可以在函数的最后一个参数位置上，传入一个回调函数。回调函数是可选（optioanl）的</li>
<li><p>我们一般采用的回调风格是所谓的“错误优先”，例如：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">web3.eth.getBlock(<span class="number">48</span>, <span class="function"><span class="keyword">function</span>(<span class="params">error, result</span>)</span>&#123;</span><br><span class="line"><span class="keyword">if</span>(!error)</span><br><span class="line">　　<span class="built_in">console</span>.log(<span class="built_in">JSON</span>.stringify(result));</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">　　<span class="built_in">console</span>.error(error);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>4.2.2 回调 Promise 事件（v1.0.0）</strong></p>
<ul>
<li>为了帮助 web3 集成到不同标准的所有类型项目中，1.0.0 版本提供了多种方式来处理异步函数。大多数的 web3 对象允许将一个回调函数作为最后一个函数参数传入，同时会返回一个promise 用于链式函数调用。</li>
<li>以太坊作为一个区块链系统，一次请求具有不同的结束阶段。为了满足这样的要求，1.0.0 版本将这类函数调用的返回值包成一个“承诺事件”（promiEvent），这是一个 promise 和EventEmitter 的结合体。</li>
<li>PromiEvent 的用法就像 promise 一样，另外还加入了.on，.once 和.off方法</li>
</ul>
 <figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">web3.eth.sendTransaction(&#123;<span class="attr">from</span>: <span class="string">'0x123...'</span>, <span class="attr">data</span>: <span class="string">'0x432...'</span>&#125;)</span><br><span class="line">.once(<span class="string">'transactionHash'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">hash</span>)</span>&#123; ... &#125;)</span><br><span class="line">.once(<span class="string">'receipt'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">receipt</span>)</span>&#123; ... &#125;)</span><br><span class="line">.on(<span class="string">'confirmation'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">confNumber, receipt</span>)</span>&#123; ... &#125;)</span><br><span class="line">.on(<span class="string">'error'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">error</span>)</span>&#123; ... &#125;)</span><br><span class="line">.then(<span class="function"><span class="keyword">function</span>(<span class="params">receipt</span>)</span>&#123; <span class="comment">// will be fired once the receipt is mined &#125;);</span></span><br></pre></td></tr></table></figure>
<p><strong>4.2.3 应用二进制接口（ABI）</strong></p>
<ul>
<li>web3.js 通过以太坊智能合约的 json 接口（Application Binary Interface，ABI）创建一个 JavaScript 对象，用来在 js代码中描述\</li>
<li>函数（functions）</li>
<li>type：函数类型，默认“function”，也可能是“constructor”</li>
<li>constant, payable, stateMutability：函数的状态可变性</li>
<li>inputs, outputs: 函数输入、输出参数描述列表</li>
<li>事件（events）</li>
<li>type：类型，总是“event”</li>
<li>inputs：输入对象列表，包括 name、type、indexed</li>
</ul>
<p><strong>4.2.4 批处理请求（batch requests）</strong></p>
<ul>
<li>批处理请求允许我们将请求排序，然后一起处理它们。</li>
<li>注意：批量请求不会更快。实际上，在某些情况下，一次性地发出许多请求会更快，因为请求是异步处理的。</li>
<li>批处理请求主要用于确保请求的顺序，并串行处理。</li>
</ul>
 <figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> batch = web3.createBatch();</span><br><span class="line">batch.add(web3.eth.getBalance.request(<span class="string">'0x0000000000000000</span></span><br><span class="line"><span class="string">000000000000000000000000'</span>, <span class="string">'latest'</span>, callback));</span><br><span class="line">batch.add(web3.eth.contract(abi).at(address).balance.request(a</span><br><span class="line">ddress, callback2));</span><br><span class="line">batch.execute();</span><br></pre></td></tr></table></figure>
<p><strong>4.2.5 大数处理（big numbers）</strong></p>
<ul>
<li>JavaScript 中默认的数字精度较小，所以web3.js 会自动添加一个依赖库 BigNumber，专门用于大数处理</li>
<li><p>对于数值，我们应该习惯把它转换成 BigNumber 对象来处理</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> balance = <span class="keyword">new</span></span><br><span class="line">BigNumber(<span class="string">'131242344353464564564574574567456'</span>);</span><br><span class="line"><span class="comment">// or var balance = web3.eth.getBalance(someAddress);</span></span><br><span class="line">balance.plus(<span class="number">21</span>).toString(<span class="number">10</span>);</span><br><span class="line"><span class="comment">//"131242344353464564564574574567477"</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>BigNumber.toString(10) 对小数只保留20位浮点精度。所以推荐的做法是，我们内部总是用 wei 来表示余额（大整数），只有在需要显示给用户看的时候才转换为ether或其它单位</p>
</li>
</ul>
<h3 id="4-3-常用-API-——-基本信息查询"><a href="#4-3-常用-API-——-基本信息查询" class="headerlink" title="4.3 常用 API —— 基本信息查询"></a>4.3 常用 API —— 基本信息查询</h3><p><strong>4.3.1 查看 web3 版本</strong></p>
<ul>
<li>v0.2x.x：web3.version.api</li>
<li>v1.0.0：web3.version</li>
</ul>
<p>查看 web3 连接到的节点版本（ clientVersion ）</p>
<ul>
<li>同步：web3.version.node</li>
<li>异步：web3.version.getNode((error,result)=&gt;{console.log(result)})</li>
<li>v1.0.0：web3.eth.getNodeInfo().then(console.log)</li>
</ul>
<p><strong>4.3.2 基本信息查询</strong></p>
<p>获取 network id</p>
<ul>
<li>同步：web3.version.network</li>
<li>异步：web3.version.getNetwork((err, res)=&gt;{console.log(res)})</li>
<li>v1.0.0：web3.eth.net.getId().then(console.log)</li>
</ul>
<p>获取节点的以太坊协议版本</p>
<ul>
<li>同步：web3.version.ethereum</li>
<li>异步：web3.version.getEthereum((err, res)=&gt;{console.log(res)}</li>
<li>v1.0.0：web3.eth.getProtocolVersion().then(console.log)</li>
</ul>
<p><strong>4.3.3 网络状态查询</strong></p>
<p>是否有节点连接 / 监听，返回 true/false</p>
<ul>
<li>同步：web3.isConnect() 或者 web3.net.listening</li>
<li>异步：web3.net.getListening((err,res)=&gt;console.log(res))</li>
<li>v1.0.0：web3.eth.net.isListening().then(console.log)</li>
</ul>
<p>查看当前连接的 peer 节点</p>
<ul>
<li>同步：web3.net.peerCount</li>
<li>异步：web3.net.getPeerCount((err,res)=&gt;console.log(res))</li>
<li>v1.0.0：web3.eth.net.getPeerCount().then(console.log)</li>
</ul>
<p><strong>4.3.4 Provider</strong></p>
<p>查看当前设置的 web3 provider</p>
<ul>
<li>web3.currentProvider</li>
</ul>
<p>查看浏览器环境设置的 web3 provider （ v1.0.0 ）</p>
<ul>
<li>web3.givenProvider</li>
</ul>
<p>设置 provider</p>
<ul>
<li>web3.setProvider(provider)</li>
<li>web3.setProvider(new web3.providers.HttpProvider(‘<a href="http://localhost:8545" target="_blank" rel="noopener">http://localhost:8545</a>‘))</li>
</ul>
<h3 id="4-4-web3-通用工具方法"><a href="#4-4-web3-通用工具方法" class="headerlink" title="4.4 web3 通用工具方法"></a>4.4 web3 通用工具方法</h3><p>以太单位转换</p>
<ul>
<li>web3.fromWei web3.toWei数据类型转换</li>
<li>web3.toString web3.toDecimal web3.toBigNumber字符编码转换</li>
<li>web3.toHex web3.toAscii web3.toUtf8 web3.fromUtf8地址相关</li>
<li>web3.isAddress web3.toChecksumAddress</li>
</ul>
<h3 id="4-5-web3-eth"><a href="#4-5-web3-eth" class="headerlink" title="4.5 web3.eth"></a>4.5 web3.eth</h3><p><strong>4.5.1 账户相关</strong></p>
<p>coinbase 查询</p>
<ul>
<li>同步：web3.eth.coinbase</li>
<li>异步：web3.eth.getCoinbase( (err, res)=&gt;console.log(res) )</li>
<li>v1.0.0：web3.eth.getCoinbase().then(console.log)</li>
</ul>
<p>账户查询</p>
<ul>
<li>同步：web3.eth.accounts</li>
<li>异步：web3.eth.getAccounts( (err, res)=&gt;console.log(res) )</li>
<li>v1.0.0：web3.eth.getAccounts().then(console.log)</li>
</ul>
<p><strong>4.5.2 区块相关</strong></p>
<p>区块高度查询</p>
<ul>
<li>同步：web3.eth. blockNumber</li>
<li>异步：web3.eth.getBlockNumber( callback )</li>
</ul>
<p>gasPrice 查询</p>
<ul>
<li>同步：web3.eth.gasPrice</li>
<li>异步：web3.eth.getGasPrice( callback )</li>
</ul>
<p>区块查询</p>
<ul>
<li>同步：web3.eth.getBlockNumber( hashStringOrBlockNumber[ ,returnTransactionObjects] )</li>
<li>异步：web3.eth.getBlockNumber( hashStringOrBlockNumber, callback )</li>
</ul>
<p>块中交易数量查询</p>
<ul>
<li>同步：web3.eth.getBlockTransactionCount( hashStringOrBlockNumber )</li>
<li>异步：web3.eth.getBlockTransactionCount( hashStringOrBlockNumber, callback )</li>
</ul>
<p><strong>4.5.3 交易相关</strong></p>
<p>余额查询</p>
<ul>
<li>同步：web3.eth.getBalance(addressHexString [, defaultBlock])</li>
<li>异步：web3.eth.getBalance(addressHexString [, defaultBlock][, callback])</li>
</ul>
<p>交易查询</p>
<ul>
<li>同步：web3.eth.getTransaction(transactionHash)</li>
<li>异步：web3.eth.getTransaction(transactionHash [, callback])</li>
</ul>
<p>交易执行相关</p>
<ul>
<li>交易收据查询（已进块）</li>
<li>同步：web3.eth.getTransactionReceipt(hashString)</li>
<li>异步：web3.eth.getTransactionReceipt(hashString [,callback])</li>
<li>估计 gas 消耗量</li>
<li>同步：web3.eth.estimateGas(callObject)</li>
<li>异步：web3.eth.estimateGas(callObject [, callback])</li>
</ul>
<p><strong>4.5.4 发送交易</strong></p>
<ul>
<li>web3.eth.sendTransaction(transactionObject [, callback])</li>
<li>交易对象：</li>
<li>from：发送地址</li>
<li>to：接收地址，如果是创建合约交易，可不填</li>
<li>value：交易金额，以wei为单位，可选</li>
<li>gas：交易消耗 gas 上限，可选</li>
<li>gasPrice：交易 gas 单价，可选</li>
<li>data：交易携带的字串数据，可选</li>
<li>nonce：整数 nonce 值，可选</li>
</ul>
<p><strong>4.5.5 消息调用</strong></p>
<ul>
<li>web3.eth.call(callObject [, defaultBlock] [, callback])</li>
<li>参数：<ul>
<li>调用对象：与交易对象相同，只是from也是可选的</li>
<li>默认区块：默认“latest”，可以传入指定的区块高度</li>
<li>回调函数，如果没有则为同步调用</li>
</ul>
</li>
</ul>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> result = web3.eth.call(&#123; <span class="attr">to</span>:<span class="string">"0xc4abd0339eb8d57087278718986382264244252f"</span>,</span><br><span class="line">data:<span class="string">"0xc6888fa1000000000000000000000000000000000000000000000000000 0000000000003"</span> &#125;);</span><br><span class="line"><span class="built_in">console</span>.log(result);</span><br></pre></td></tr></table></figure>
<p><strong>4.5.6 日志过滤（事件监听）</strong><br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">web3.eth.filter( filterOptions [ , callback ] )</span><br><span class="line"><span class="comment">// filterString 可以是 'latest' or 'pending'</span></span><br><span class="line"><span class="keyword">var</span> filter = web3.eth.filter(filterString);</span><br><span class="line"><span class="comment">// 或者可以填入一个日志过滤 options</span></span><br><span class="line"><span class="keyword">var</span> filter = web3.eth.filter(options);</span><br><span class="line"><span class="comment">// 监听日志变化</span></span><br><span class="line">filter.watch(<span class="function"><span class="keyword">function</span>(<span class="params">error, result</span>)</span>&#123; <span class="keyword">if</span> (!error) <span class="built_in">console</span>.log(result); &#125;);</span><br><span class="line"><span class="comment">// 还可以用传入回调函数的方法，立刻开始监听日志</span></span><br><span class="line">web3.eth.filter(options, <span class="function"><span class="keyword">function</span>(<span class="params">error, result</span>)</span>&#123;</span><br><span class="line"><span class="keyword">if</span> (!error) <span class="built_in">console</span>.log(result);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p>
<p><strong>4.5.7 合约相关 —— 创建合约</strong></p>
<p>web3.eth.contract</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> MyContract = web3.eth.contract(abiArray);</span><br><span class="line"><span class="comment">// 通过地址初始化合约实例</span></span><br><span class="line"><span class="keyword">var</span> contractInstance = MyContract.at(address);</span><br><span class="line"><span class="comment">// 或者部署一个新合约</span></span><br><span class="line"><span class="keyword">var</span> contractInstance = MyContract.new([constructorParam1][, constructorParam2], &#123;<span class="attr">data</span>: <span class="string">'0x12345...'</span>, <span class="attr">from</span>:myAccount, <span class="attr">gas</span>: <span class="number">1000000</span>&#125;);</span><br></pre></td></tr></table></figure>
<p><strong>4.5.8 调用合约函数</strong></p>
<p>可以通过已创建的合约实例，直接调用合约函数</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 直接调用，自动按函数类型决定用 sendTransaction 还是 call</span></span><br><span class="line">myContractInstance.myMethod(param1 [, param2, ...] [,transactionObject] [, defaultBlock] [, callback]);</span><br><span class="line"><span class="comment">// 显式以消息调用形式 call 该函数</span></span><br><span class="line">myContractInstance.myMethod.call(param1 [, param2, ...] [,transactionObject] [, defaultBlock] [, callback]);</span><br><span class="line"><span class="comment">// 显式以发送交易形式调用该函数</span></span><br><span class="line">myContractInstance.myMethod.sendTransaction(param1 [,param2, ...] [, transactionObject] [, callback]);</span><br></pre></td></tr></table></figure>
<p><strong>4.5.9 监听合约事件</strong></p>
<p>合约的 event 类似于 filter，可以设置过滤选项来监听</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> event = myContractInstance.MyEvent(&#123;<span class="attr">valueA</span>: <span class="number">23</span>&#125;[, additionalFilterObject])</span><br><span class="line"><span class="comment">// 监听事件</span></span><br><span class="line">event.watch(<span class="function"><span class="keyword">function</span>(<span class="params">error, result</span>)</span>&#123; </span><br><span class="line"><span class="keyword">if</span> (!error) </span><br><span class="line">　　<span class="built_in">console</span>.log(result); </span><br><span class="line">&#125;);</span><br><span class="line"><span class="comment">// 还可以用传入回调函数的方法，立刻开始监听事件</span></span><br><span class="line"><span class="keyword">var</span> event = myContractInstance.MyEvent([&#123;<span class="attr">valueA</span>: <span class="number">23</span>&#125;][, additionalFilterObject] , <span class="function"><span class="keyword">function</span>(<span class="params">error, result</span>)</span>&#123;</span><br><span class="line">　　<span class="keyword">if</span> (!error) <span class="built_in">console</span>.log(result);</span><br><span class="line">&#125;</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<h2 id="5、交互实现——部署智能合约"><a href="#5、交互实现——部署智能合约" class="headerlink" title="5、交互实现——部署智能合约"></a>5、交互实现——部署智能合约</h2><p>通过编写一个depoly.js程序实现自动化的部署智能合约。首先要保持Geth客户端正常运行，并开启rpc。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">geth --identity <span class="string">"TestNode"</span> --rpc --rpcport <span class="string">"8545"</span> --datadir data0 --port <span class="string">"30303"</span> --nodiscover --networkid <span class="number">6666</span> --rpcapi admin,eth,miner,personal,txpool,eth,web3,net <span class="built_in">console</span></span><br></pre></td></tr></table></figure>
<p>合约应该在智能合约编译器（如remix）调试好，然后将其写到test.sol文件里。<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br><span class="line">contract TestContract</span><br><span class="line">&#123;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">multiply</span>(<span class="params">uint a, uint b</span>) <span class="title">returns</span> (<span class="params">uint</span>)</span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> a * b;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>使用solc模块生成合约的code和abi，我将该过程自定义为一个模块test.js，方便depoly.js调用。<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> fs = <span class="built_in">require</span>(<span class="string">'fs'</span>);</span><br><span class="line"><span class="keyword">var</span> solc = <span class="built_in">require</span>(<span class="string">'solc'</span>);</span><br><span class="line"><span class="comment">//compile smart contract to get bytecode and abi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> source = fs.readFileSync(<span class="string">"./test.sol"</span>,<span class="string">'utf8'</span>);  <span class="comment">//读取代码</span></span><br><span class="line">    <span class="comment">//console.log("compiling contract...");</span></span><br><span class="line"><span class="keyword">var</span> compiledcontract = solc.compile(source); <span class="comment">//编译</span></span><br><span class="line">    <span class="comment">//console.log('done');</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">var</span> contractName <span class="keyword">in</span> compiledcontract.contracts)&#123;</span><br><span class="line">    <span class="keyword">var</span> bytecode = compiledcontract.contracts[contractName].bytecode;</span><br><span class="line">    <span class="keyword">var</span> abi = <span class="built_in">JSON</span>.parse(compiledcontract.contracts[contractName].interface);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//console.log(JSON.stringify(abi, undefined, 2));</span></span><br><span class="line"><span class="comment">//console.log(bytecode);</span></span><br><span class="line"><span class="comment">//console.log(abi);</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">bytecode</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(bytecode);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">abi</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(abi);</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">module</span>.exports = &#123;<span class="attr">bytecode</span>:bytecode,<span class="attr">abi</span>:abi&#125;;</span><br></pre></td></tr></table></figure><br>depoly.js通过与Geth交互部署智能合约。当合约被区块链确认后，会直接返回合约地址。<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> Web3 = <span class="built_in">require</span>(<span class="string">'web3'</span>);</span><br><span class="line"><span class="keyword">var</span> contract = <span class="built_in">require</span>(<span class="string">'./test'</span>);</span><br><span class="line"><span class="keyword">var</span> web;</span><br><span class="line"></span><br><span class="line"><span class="comment">//connect to node</span></span><br><span class="line"><span class="keyword">var</span> ethereumUri = <span class="string">'http://localhost:8545'</span>;</span><br><span class="line"><span class="keyword">if</span> (<span class="keyword">typeof</span> web3 !== <span class="string">'undefined'</span>) &#123;</span><br><span class="line">    web3 = <span class="keyword">new</span> Web3(web3.currentProvider);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// set the provider you want from Web3.providers</span></span><br><span class="line">    web3 = <span class="keyword">new</span> Web3(<span class="keyword">new</span> Web3.providers.HttpProvider(ethereumUri));</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//查询区块链中基本的账户信息</span></span><br><span class="line"><span class="keyword">if</span>(!web3.isConnected())&#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="built_in">Error</span>(<span class="string">'unable to connect to ethereum node at '</span>+ ethereumUri);</span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">'connected to etherum node at '</span>+ ethereumUri);</span><br><span class="line">    <span class="keyword">var</span> coinbase = web3.eth.accounts[<span class="number">0</span>];</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">'coinbase:'</span> + coinbase);</span><br><span class="line">    <span class="keyword">var</span> balance = web3.eth.getBalance(coinbase);</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">'balance:'</span> + web3.fromWei(balance, <span class="string">'ether'</span>) + <span class="string">" ETH"</span>);</span><br><span class="line">    <span class="keyword">var</span> accounts = web3.eth.accounts;</span><br><span class="line">    <span class="built_in">console</span>.log(accounts);    </span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//通过coinbase部署智能合约</span></span><br><span class="line"><span class="keyword">var</span> abi = contract.abi;</span><br><span class="line"><span class="keyword">var</span> bytecode = contract.bytecode;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (web3.personal.unlockAccount(coinbase, <span class="string">'123'</span>)) &#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">`<span class="subst">$&#123;coinbase&#125;</span> is unlocaked`</span>);</span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">`unlock failed, <span class="subst">$&#123;coinbase&#125;</span>`</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> gasEstimate = web3.eth.estimateGas(&#123;<span class="attr">data</span>: <span class="string">'0x'</span> + bytecode&#125;); <span class="comment">//gas估计</span></span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'gasEstimate = '</span> + gasEstimate);</span><br><span class="line"><span class="keyword">var</span> MyContract = web3.eth.contract(abi);</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'deploying contract...'</span>);</span><br><span class="line"><span class="keyword">var</span> myContractReturned = MyContract.new(&#123;</span><br><span class="line">    <span class="keyword">from</span>: coinbase,</span><br><span class="line">    data: <span class="string">'0x'</span>+ bytecode,</span><br><span class="line">    gas: gasEstimate + <span class="number">50000</span></span><br><span class="line">&#125;, <span class="function"><span class="keyword">function</span> (<span class="params">err, myContract</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!err) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!myContract.address) &#123;</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">`myContract.transactionHash = <span class="subst">$&#123;myContract.transactionHash&#125;</span>`</span>); <span class="comment">// The hash of the transaction, which deploys the contract</span></span><br><span class="line">        <span class="comment">// check address on the second call (contract deployed)</span></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">`myContract.address = <span class="subst">$&#123;myContract.address&#125;</span>`</span>); <span class="comment">// the contract address</span></span><br><span class="line">            global.contractAddress = myContract.address;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">console</span>.log(err);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p>
<p><strong>参考自：</strong></p>
<p><a href="https://geth.ethereum.org/docs/install-and-build/installing-geth" target="_blank" rel="noopener">Go Ethereum</a></p>
<p><a href="https://www.jianshu.com/p/9fa31e4cdf4d" target="_blank" rel="noopener">以太坊私有链Geth控制台操作教程</a></p>
<p><a href="https://www.bilibili.com/video/BV1sJ411D72u" target="_blank" rel="noopener">尚硅谷区块链全套Go语言→GoWeb→以太坊→项目实战</a><br><a href="http://cw.hubwiz.com/card/c/web3.js-1.0/" target="_blank" rel="noopener">web3.js 1.0中文手册</a></p>
]]></content>
      <categories>
        <category>Blockchain</category>
      </categories>
  </entry>
  <entry>
    <title>区块链入门（三）Solidity基础</title>
    <url>/posts/f6ff6959.html</url>
    <content><![CDATA[<font color="red"> 注：本教程为技术教程，不谈论且不涉及炒作任何数字货币 </font>

<h1 id="Solidity-入门教学"><a href="#Solidity-入门教学" class="headerlink" title="Solidity 入门教学"></a>Solidity 入门教学</h1><h2 id="1、-简介"><a href="#1、-简介" class="headerlink" title="1、 简介"></a>1、 简介</h2><h3 id="1-1-Solidity是什么"><a href="#1-1-Solidity是什么" class="headerlink" title="1.1 Solidity是什么"></a>1.1 Solidity是什么</h3><ul>
<li>Solidity 是一门面向合约的、为实现智能合约而创建的高级编程语言。这门语言受到了 C++，Python 和 Javascript 语言的影响，设计的目的是能在以太坊虚拟机（EVM）上运行。</li>
<li>Solidity 是静态类型语言，支持继承、库和复杂的用户定义类型等特性。</li>
<li>内含的类型除了常见编程语言中的标准类型，还包括 <code>address</code>等以太坊独有的类型，Solidity 源码文件通常以 .sol 作为扩展名</li>
<li>目前尝试 Solidity 编程的推荐方式是使用 Remix。Remix是一个基于 Web 浏览器的 IDE，它可以让你编写 Solidity 智能合约，然后部署并运行该智能合约。</li>
</ul>
<h3 id="1-2-Solidity语言特性"><a href="#1-2-Solidity语言特性" class="headerlink" title="1.2 Solidity语言特性"></a>1.2 Solidity语言特性</h3><p>Solidity的语法接近于JavaScript，是一种面向对象的语言。但作为一种真正意义上运行在网络上的去中心合约，它又有很多的不同：</p>
<ul>
<li>以太坊底层基于帐户，而不是 <a href="https://cloud.tencent.com/developer/article/1367743" target="_blank" rel="noopener">UTXO</a>，所以增加了一个特殊的address 的数据类型用于定位用户和合约账户。</li>
<li>语言内嵌框架支持支付。提供了 <code>payable</code> 等关键字，可以在语言层面直接支持支付。</li>
<li>使用区块链进行数据存储。数据的每一个状态都可以永久存储，所以在使用时需要确定变量使用内存，还是区块链存储。</li>
<li>运行环境是在去中心化的网络上，所以需要强调合约或函数执行的调用的方式。</li>
<li>不同的异常机制。一旦出现异常，所有的执行都将会被回撤，这主要是为了保证合约执行的原子性，以避免中间状态出现的数据不一致。</li>
</ul>
<h3 id="1-3-Solidity源码和智能合约"><a href="#1-3-Solidity源码和智能合约" class="headerlink" title="1.3 Solidity源码和智能合约"></a>1.3 Solidity源码和智能合约</h3><p>Solidity 源代码要成为可以运行在以太坊上的智能合约需要经历如下的</p>
<p><strong>步骤：</strong></p>
<ol>
<li>用 Solidity 编写的智能合约源代码需要先使用编译器编译为字节码（Bytecode），编译过程中会同时产生智能合约的二进制接口规范（Application Binary Interface，简称为ABI）；</li>
<li>通过交易（Transaction）的方式将字节码部署到以太坊网络，每次成功部署都会产生一个新的智能合约账户；</li>
<li>使用 Javascript 编写的 DApp 通常通过 web3.js + ABI去调用智能合约中的函数来实现数据的读取和修改。</li>
</ol>
<h3 id="1-4-合约结构"><a href="#1-4-合约结构" class="headerlink" title="1.4 合约结构"></a>1.4 合约结构</h3><ul>
<li>状态变量（State Variables）作为合约状态的一部分，值会永久保存在存储空间内。</li>
<li>函数（Functions）合约中可执行的代码块。</li>
<li>函数修饰器（Function Modifiers）在函数声明中，用来补充修饰函数的语义。</li>
<li>事件（Events）非常方便的 EVM 日志工具接口。</li>
</ul>
<h2 id="2、-Solidity编译器安装以及简单使用"><a href="#2、-Solidity编译器安装以及简单使用" class="headerlink" title="2、 Solidity编译器安装以及简单使用"></a>2、 Solidity编译器安装以及简单使用</h2><p>Remix 是一个开源的 IDE,是一个浏览器在线编辑器。作为 Solidity 智能合约开发环境，Solidity IDE  Remix(在线浏览器编辑器)提供基本的编译、部署至本地或测试网络、执行合约等功能。</p>
<h3 id="2-1-remix安装以及使用"><a href="#2-1-remix安装以及使用" class="headerlink" title="2.1 remix安装以及使用"></a>2.1 remix安装以及使用</h3><ol>
<li><strong>浏览器端配置</strong></li>
</ol>
<p>在浏览器端有俩个选择，分别为英文版与中文版（有些许差别）</p>
<ul>
<li><p>Remix中文版地址：<a href="http://remix.hubwiz.com" target="_blank" rel="noopener">http://remix.hubwiz.com</a></p>
</li>
<li><p>Remix英文版地址（<strong>推荐</strong>）：<a href="https://remix.ethereum.org/" target="_blank" rel="noopener">https://remix.ethereum.org/</a></p>
</li>
</ul>
<p><strong>PS.可能需要科学上网</strong></p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-1.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 1</div>
</center>



<p>下面都以<code>英文版</code>为例子介绍</p>
<p>1、<strong>浏览器输入 <a href="https://remix.ethereum.org/" target="_blank" rel="noopener">https://remix.ethereum.org/</a></strong></p>
<p>如果出现加载慢，加载不完全的情况，刷新几次即可</p>
<p>2、左侧可以看到我们所有的文件，下面是我们的remix控制台</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-2.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 2</div>
</center>



<p>上图小图标从左到右依次为：</p>
<ul>
<li>创建新文件</li>
<li>创建新文件夹</li>
<li>Github代码片段分享</li>
<li>表示打开一个本地文件</li>
</ul>
<p>控制台图片如下：</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-3.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 3</div>
</center>



<ul>
<li>1 从左至右表示隐藏控制台、清除控制台输出、pending的交易数量</li>
<li>2 表示监听所有交易</li>
<li>3 表示搜索框</li>
<li>4 表示输出区域</li>
<li>5 表示使用JavaScript与以太坊交互的区域，可以使用Web3对象</li>
</ul>
<p>3、点击文件样式图标输入我们的文件名即可(以.sol为后缀)</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-4.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 4</div>
</center>


<p>4、安装必要的插件</p>
<p>点击插件管理器，页面中为这个图标</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-5.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 5</div>
</center>




<ul>
<li><p>安装compiler</p>
<p>  搜索关键字compiler</p>
<center>
  <img style="border-radius: 0.3125em;
  box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-6.png">
  <br>
  <div style="color:orange; border-bottom: 1px solid #d9d9d9;
  display: inline-block;
  color: #999;
  padding: 2px;">图 6</div>
</center>



</li>
</ul>
<p>5、写一个简单的样例</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br><span class="line"></span><br><span class="line">contract SimpleStorage &#123;</span><br><span class="line">    uint storedData;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">set</span>(<span class="params">uint x</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        storedData = x;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">get</span>(<span class="params"></span>) <span class="title">public</span> <span class="title">view</span> <span class="title">returns</span> (<span class="params">uint</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> storedData;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>第一行就是告诉大家源代码使用Solidity版本0.4.0写的，并且使用0.4.0以上版本运行也没问题（最高到0.5.0，但是不包含0.5.0）。这是为了确保合约不会在新的编译器版本中突然行为异常。关键字 <code>pragma</code> 的含义是，一般来说，pragmas（编译指令）是告知编译器如何处理源代码的指令的。</p>
<p>Solidity中合约的含义就是一组代码（它的 函数 )和数据（它的 状态 ），它们位于以太坊区块链的一个特定地址上。 代码行 <code>uint storedData</code>; 声明一个类型为 <code>uint</code> (256位无符号整数）的状态变量，叫做 <code>storedData</code> 。 你可以认为它是数据库里的一个位置，可以通过调用管理数据库代码的函数进行查询和变更。对于以太坊来说，上述的合约就是拥有合约（owning contract）。在这种情况下，函数 <code>set</code> 和 <code>get</code> 可以用来变更或取出变量的值。</p>
<p>要访问一个状态变量，并不需要像 <code>this.</code> 这样的前缀，虽然这是其他语言常见的做法。</p>
<p>该合约能完成的事情并不多（由于以太坊构建的基础架构的原因）：它能允许任何人在合约中存储一个单独的数字，并且这个数字可以被世界上任何人访问，且没有可行的办法阻止你发布这个数字。当然，任何人都可以再次调用 <code>set</code> ，传入不同的值，覆盖你的数字，但是这个数字仍会被存储在区块链的历史记录中。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-7.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 7</div>
</center>



<p>点击<code>compile test.sol</code>，可以看到编译按钮，建议将<code>Auto compile</code>打钩（自动编译）,之后会在编译图标上看到一个以绿色为背景的对勾。</p>
<p>编译组件说明：</p>
<ul>
<li><code>Compiler</code>可以选择Solidity的编译器版本</li>
<li><code>Language</code>可以选择编程语言</li>
<li><code>EVM Version</code>可以选择EVM虚拟机版本</li>
<li><code>Auto compile</code>可以设置自动编译，修改完代码后自动执行编译操作</li>
<li><code>Enable optimization</code>可以设置对编译进行优化</li>
<li><code>Hide warnings</code>可以设置隐藏警告信息。</li>
<li><code>Contract</code>选择需要编译的合约</li>
<li><code>Publish on Swarm</code>和<code>Publish on Ipfs</code>分别将合约上传到Swarm和Ipfs这两个分布式文件系统上去</li>
<li><code>Compilation Details</code>很重要，可以查看编译的信息，包括ABI、字节码、函数Hash等</li>
<li><code>ABI</code>和<code>Bytecode</code>分别复制ABI和字节码。</li>
<li>再下面的部分空白用来显示编译的Warnings和Errors。</li>
</ul>
<p>我们点击<code>Compilation Details</code>就能看到编译之后的一些信息，如下图所示（部分）</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-8.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 8</div>
</center>


<ul>
<li><code>NAME</code>：合约名</li>
<li><code>METADATA</code>：一些编译相关的信息，比如版本、所用的语言、设置等</li>
<li><code>BYTECODE</code>：写入区块的字节码</li>
<li><code>ABI</code>：此智能合约对应的 ABI ，也就是我们合约里面定义的一些接口</li>
<li><code>WEB3DEPLOY</code>：智能合约编译之后的发布命令，这个就是比较重要的，之后的web3就是调用这段命令来部署合约的</li>
<li><code>METADATAHASH</code>：数据的一个哈希值</li>
<li><code>SWARMLOCATION</code>：Swarm网络的一个地址</li>
<li><code>FUNCTIONHASHES</code>：合约定义的方法的hash，其实我们执行合约的时候就是通过这个hash去找到对应的方法进行执行的</li>
<li><code>GASESTIMATES</code>：关于矿工费的一个预算，在ETH上进行合约的部署，执行等都是需要矿工费的。一般合约代码越多矿工费越高。</li>
</ul>
<p>点击下面的run图标，可以看到部署，以及账户信息，环境等等</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-9.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 9</div>
</center>



<p>点击deploy之后天可以看到自己的合约已经部署完成，打开之后可以看见我们写的函数<code>set</code>,<code>get</code>了，给<code>set</code>函数输入一个值，点击<code>get</code>会得到相应的值</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-10.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 10</div>
</center>



<ul>
<li><code>Environment</code> 表示合约部署的环境。<code>Javascript VM</code>是虚拟了一个节点，而<code>Injected Web3</code>和<code>Web3 Provider</code>则真正连接一个节点。</li>
<li><code>Account</code>代表不同的虚拟账户，每个虚拟账户每个有 100 ETH</li>
<li><code>Deploy</code>表示合约部署按钮</li>
<li><code>Deployed Contracts</code>表示已经部署的合约</li>
</ul>
<p>中文版界面与英文版界面有些许不一致，但都大同小异，想了解同学可以查看本博客(界面与中文版大致相同）：<br><a href="https://cloud.tencent.com/developer/article/1182404" target="_blank" rel="noopener">Solidity语言编辑器REMIX指导大全</a></p>
<ol>
<li><strong>本地配置：</strong><ul>
<li><a href="https://cloud.tencent.com/developer/article/1374376" target="_blank" rel="noopener">win下</a></li>
<li><a href="https://blog.csdn.net/qq_41944960/article/details/100134020" target="_blank" rel="noopener">ubuntu下</a></li>
</ul>
</li>
</ol>
<ol>
<li><strong>Docker</strong></li>
</ol>
<p>我们为编译器提供了最新的docker构建。 stable 仓库里的是已发布的版本，nightly 仓库则是在开发分支中的带有不稳定变更的版本。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run ethereum&#x2F;solc:stable solc --version</span><br></pre></td></tr></table></figure>
<p>目前，docker 镜像只含有 solc 的可执行程序，因此你需要额外的工作去把源代码和输出目录连接起来。</p>
<h2 id="3、Solidity基础操作"><a href="#3、Solidity基础操作" class="headerlink" title="3、Solidity基础操作"></a>3、Solidity基础操作</h2><p><strong>由于篇幅有限，以下只会讲解一些较基础、重要的概念(足够后面使用)，有些可能会一带而过或者“忽略”，如果大家途中有没太明白地方建议先百度、Google，或者查看此教程<a href="https://solidity-cn.readthedocs.io/zh/develop/index.html" target="_blank" rel="noopener">Solifity中文文档</a>、<a href="https://remix-ide.readthedocs.io/en/latest/index.html" target="_blank" rel="noopener">Solidity英文文档</a></strong></p>
<h3 id="3-1-Solidity源文件布局"><a href="#3-1-Solidity源文件布局" class="headerlink" title="3.1 Solidity源文件布局"></a>3.1 Solidity源文件布局</h3><p><strong>源文件可以被版本杂注pragma所注解，表明要求的编译器版本</strong></p>
<ul>
<li>例如：<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br></pre></td></tr></table></figure>
这样，源文件将既不允许低于 0.4.0 版本的编译器编译， 也不允许高于（包含） 0.5.0 版本的编译器编译（第二个条件因使用 ^ 被添加）。 这种做法的考虑是，编译器在 0.5.0 版本之前不会有重大变更，所以可确保源代码始终按预期被编译。 上面例子中不固定编译器的具体版本号，因此编译器的补丁版也可以使用。</li>
</ul>
<p><strong>import（导入其它源文件）</strong></p>
<ul>
<li>Solidity 所支持的导入语句import，语法同 JavaScript（从ES6 起）非常类似</li>
</ul>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">"filename"</span>;</span><br></pre></td></tr></table></figure>
<p>从“filename”中导入所有的全局符号到当前全局作用域中<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> * <span class="keyword">as</span> symbolName <span class="keyword">from</span> <span class="string">"filename"</span>;</span><br></pre></td></tr></table></figure><br>创建一个新的全局符号 symbolName，其成员均来自 “filename”中全局符号<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123;symbol1 <span class="keyword">as</span> alias, symbol2&#125; <span class="keyword">from</span> <span class="string">"filename"</span>;</span><br></pre></td></tr></table></figure><br>创建新的全局符号 alias 和 symbol2，分别从 “filename” 引用 symbol1 和 symbol2<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">"filename"</span> <span class="keyword">as</span> symbolName;</span><br></pre></td></tr></table></figure><br>这条语句等同于 import * as symbolName from “filename”;</p>
<p><strong>注释</strong></p>
<p>可以使用单行注释（//）和多行注释（/<em>…</em>/）</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 这是一个单行注释。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">这是一个</span></span><br><span class="line"><span class="comment">多行注释。</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>
<h3 id="3-2-数据类型与运算符"><a href="#3-2-数据类型与运算符" class="headerlink" title="3.2 数据类型与运算符"></a>3.2 数据类型与运算符</h3><h3 id="3-2-1-Solidity值类型介绍"><a href="#3-2-1-Solidity值类型介绍" class="headerlink" title="3.2.1 Solidity值类型介绍"></a>3.2.1 Solidity值类型介绍</h3><ul>
<li><strong>布尔（bool）</strong>：</li>
</ul>
<p>可能的取值为字符常量值 true 或 false</p>
<p>例子：<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br><span class="line"></span><br><span class="line">contract helloworld &#123;</span><br><span class="line">    bool boola=<span class="literal">true</span>; <span class="comment">//声明一个布尔类型的值，只用一个等号</span></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">booltesta</span>(<span class="params"></span>) <span class="title">public</span> <span class="title">view</span> <span class="title">returns</span>(<span class="params">bool</span>)</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> boola;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">booltestb</span>(<span class="params">int a,int b</span>) <span class="title">public</span> <span class="title">pure</span> <span class="title">returns</span>(<span class="params">bool</span>)</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> a==b;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-12.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 11</div>
</center>



<ul>
<li>整型（int/uint）**：</li>
</ul>
<p><code>int</code> / <code>uint</code> ：分别表示有符号和无符号的不同位数的整型变量。 支持关键字 <code>uint8</code> 到 <code>uint256</code> （无符号，从 8 位到 256 位）以及 <code>int8</code> 到 <code>int256</code>，以 8 位为步长递增。 <code>uint</code> 和 <code>int</code> 分别是 <code>uint256</code> 和 <code>int256</code> 的别名。</p>
<ul>
<li><strong>定长浮点型（fixed / ufixed）</strong>： </li>
</ul>
<p><code>fixed</code>/ <code>ufixed</code>：表示各种大小的有符号和无符号的定长浮点型。 在关键字 <code>ufixedMxN</code> 和 <code>fixedMxN</code> 中，<code>M</code> 表示该类型占用的位数，<code>N</code> 表示可用的小数位数。 <code>M</code>必须能整除 8，即 8 到 256 位。 <code>N</code>则可以是从 0 到 80 之间的任意数。 <code>ufixed</code> 和 <code>fixed</code> 分别是 <code>ufixed128x19</code> 和 <code>fixed128x19</code> 的别名。</p>
<ul>
<li><strong>地址（address 重点，后面细讲）</strong>：</li>
</ul>
<p>地址类型存储一个 20 字节的值（以太坊地址的大小）。 地址类型也有成员变量，并作为所有合约的基础。</p>
<p> <strong>地址类型成员变量</strong>:<code>balance</code> 和 <code>transfer</code></p>
<p> 可以使用 balance 属性来查询一个地址的余额， 也可以使用 transfer 函数向一个地址发送 以太币 （以 wei 为单位）：</p>
 <figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">address x = <span class="number">0x123</span>;</span><br><span class="line">address myAddress = <span class="keyword">this</span>;</span><br><span class="line"><span class="keyword">if</span> (x.balance &lt; <span class="number">10</span> &amp;&amp; myAddress.balance &gt;= <span class="number">10</span>) x.transfer(<span class="number">10</span>);</span><br></pre></td></tr></table></figure>
<p>注：如果 <code>x</code> 是一个合约地址，它的代码（更具体来说是它的 fallback 函数，如果有的话）会跟 <code>transfer</code> 函数调用一起执行（这是 EVM 的一个特性，无法阻止）。 如果在执行过程中用光了 gas 或者因为任何原因执行失败，以太币 交易会被打回，当前的合约也会在终止的同时抛出异常。</p>
<ul>
<li><strong>定长字节数组</strong>：</li>
</ul>
<p>关键字有 bytes1， bytes2， bytes3， …， bytes32<br><code>.length</code> 表示这个字节数组的长度（只读）.</p>
<p>注：可以将 <code>byte[]</code> 当作字节数组使用，但这种方式非常浪费存储空间，准确来说，是在传入调用时，每个元素会浪费 31 字节。 更好地做法是使用 <code>bytes</code>。</p>
<ul>
<li><strong>变长字节数组</strong></li>
</ul>
<p><code>bytes</code>:变长字节数组。它并不是值类型。</p>
<p><code>string</code>:变长 UTF-8 编码字符串类型。并不是值类型。 </p>
<ul>
<li><strong>地址字面常数（Address Literals）</strong></li>
</ul>
<p>比如像 <code>0xdCad3a6d3569DF655070DEd06cb7A1b2Ccd1D3AF</code> 这样的通过了地址校验和测试的十六进制字面常数属于 <code>address</code> 类型。 长度在 39 到 41 个数字的，没有通过校验和测试而产生了一个警告的十六进制字面常数视为正常的有理数字面常数。</p>
<ul>
<li><strong>有理数和整数字面常数</strong></li>
</ul>
<p>整数字面常数由范围在 0-9 的一串数字组成，表现成十进制。 例如，69 表示数字 69。 Solidity 中是没有八进制的，因此前置 0 是无效的。</p>
<p>十进制小数字面常数带有一个 .，至少在其一边会有一个数字。 比如：<code>1.，.1</code>，和 <code>1.3</code>。</p>
<p>科学符号也是支持的，尽管指数必须是整数，但底数可以是小数。 比如：<code>2e10， -2e10， 2e-10， 2.5e1</code>。</p>
<p>数值字面常数表达式本身支持任意精度，除非它们被转换成了非字面常数类型（也就是说，当它们出现在非字面常数表达式中时就会发生转换）。 这意味着在数值常量表达式中, 计算不会溢出而除法也不会截断。</p>
<p>例如， <code>(2**800 + 1) - 2**800</code> 的结果是字面常数 1 （属于 <code>uint8</code> 类型），尽管计算的中间结果已经超过了 以太坊虚拟机 的机器字长度。 此外， <code>.5 * 8</code> 的结果是整型 4 （尽管有非整型参与了计算）</p>
<ul>
<li><strong>字符串字面常数</strong></li>
</ul>
<p>字符串字面常数是指由双引号或单引号引起来的字符串（<code>&quot;foo&quot;</code>或者 <code>&#39;bar&#39;</code>）。 不像在 C 语言中那样带有结束符；<code>&quot;foo&quot;</code> 相当于 3 个字节而不是 4 个。 和整数字面常数一样，字符串字面常数的类型也可以发生改变，但它们可以隐式地转换成 <code>bytes1，……，bytes32</code>，如果合适的话，还可以转换成 <code>bytes</code> 以及 <code>string</code>。</p>
<ul>
<li><strong>十六进制字面常数</strong></li>
</ul>
<p>十六进制字面常数以关键字 <code>hex</code> 打头，后面紧跟着用单引号或双引号引起来的字符串（例如，<code>hex&quot;001122FF&quot;</code>）。 字符串的内容必须是一个十六进制的字符串，它们的值将使用二进制表示。</p>
<ul>
<li><strong>枚举（enum）</strong>：</li>
</ul>
<p>一种用户可以定义类型的方法，与C语言类似，默认从0开始递增，一般用来模拟合约的状态</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.16</span>;</span><br><span class="line"></span><br><span class="line">contract test &#123;</span><br><span class="line">    enum ActionChoices &#123; GoLeft, GoRight, GoStraight, SitStill &#125;；</span><br><span class="line">    ActionChoices choice;</span><br><span class="line">    ActionChoices constant defaultChoice = ActionChoices.GoStraight;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">setGoStraight</span>(<span class="params"></span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        choice = ActionChoices.GoStraight;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 由于枚举类型不属于 |ABI| 的一部分，因此对于所有来自 Solidity 外部的调用，</span></span><br><span class="line">    <span class="comment">// "getChoice" 的签名会自动被改成 "getChoice() returns (uint8)"。</span></span><br><span class="line">    <span class="comment">// 整数类型的大小已经足够存储所有枚举类型的值，随着值的个数增加，</span></span><br><span class="line">    <span class="comment">// 可以逐渐使用 `uint16` 或更大的整数类型。</span></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">getChoice</span>(<span class="params"></span>) <span class="title">public</span> <span class="title">view</span> <span class="title">returns</span> (<span class="params">ActionChoices</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> choice;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">getDefaultChoice</span>(<span class="params"></span>) <span class="title">public</span> <span class="title">pure</span> <span class="title">returns</span> (<span class="params">uint</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> uint(defaultChoice);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>函数（function）</strong>：</li>
</ul>
<p>函数类型是一种表示函数的类型。可以将一个函数赋值给另一个函数类型的变量，也可以将一个函数作为参数进行传递，还能在函数调用中返回函数类型变量。 函数类型有两类：- 内部（<code>internal</code>） 函数和 外部（<code>external</code>） 函数：</p>
<p>内部函数只能在当前合约内被调用（更具体来说，在当前代码块内，包括内部库函数和继承的函数中），因为它们不能在当前合约上下文的外部被执行。 调用一个内部函数是通过跳转到它的入口标签来实现的，就像在当前合约的内部调用一个函数。</p>
<p>外部函数由一个地址和一个函数签名组成，可以通过外部函数调用传递或者返回。</p>
<p>函数类型表示成如下的形式</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-11.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 12</div>
</center>



<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> (<span class="params">&lt;parameter types&gt;</span>) </span>&#123;internal|external&#125; [pure|constant|view|payable] [returns (<span class="xml"><span class="tag">&lt;<span class="name">return</span> <span class="attr">types</span>&gt;</span>)]</span></span><br></pre></td></tr></table></figure>
<p>与参数类型相反，返回类型不能为空 —— 如果函数类型不需要返回，则需要删除整个 <code>returns (&lt;return types&gt;)</code> 部分。</p>
<p>函数类型默认是内部函数，因此不需要声明 <code>internal</code> 关键字。 与此相反的是，合约中的函数本身默认是 <code>public</code>的，只有当它被当做类型名称时，默认才是内部函数。</p>
<p>有两种方法可以访问当前合约中的函数：一种是直接使用它的名字，<code>f</code> ，另一种是使用 <code>this.f</code> 。 前者适用于内部函数，后者适用于外部函数。</p>
<p>如果当函数类型的变量还没有初始化时就调用它的话会引发一个异常。 如果在一个函数被 <code>delete</code> 之后调用它也会发生相同的情况。</p>
<p>如果外部函数类型在 Solidity 的上下文环境以外的地方使用，它们会被视为 <code>function</code> 类型。 该类型将函数地址紧跟其函数标识一起编码为一个 <code>bytes24</code> 类型。</p>
<p>请注意，当前合约的 public 函数既可以被当作内部函数也可以被当作外部函数使用。 如果想将一个函数当作内部函数使用，就用 <code>f</code> 调用，如果想将其当作外部函数，使用 <code>this.f</code> 。</p>
<p><strong>Solidity函数可见性</strong></p>
<p>函数的可见性可以指定为 external，public ，internal 或者 private；对于状态变量，不能设置为 external ，默认是 internal。</p>
<ul>
<li>external ：外部函数作为合约接口的一部分，意味着我们可以从其他合约和交易中调用。 一个外部函数 f不能从内部调用（即 f 不起作用，但 this.f() 可以）。 当收到大量数据的时候，外部函数有时候会更有效率。</li>
<li>public ：public 函数是合约接口的一部分，可以在内部或通过消息调用。对于 public 状态变量， 会自动生成一个 getter 函数。</li>
<li>internal ：这些函数和状态变量只能是内部访问（即从当前合约内部或从它派生的合约访问），不使用 this 调用。</li>
<li>private ：private 函数和状态变量仅在当前定义它们的合约中使用，并且不能被派生合约使用。</li>
</ul>
<p><strong>Solidity函数状态可变性</strong></p>
<ul>
<li>pure：纯函数，不允许修改或访问状态</li>
<li>view：不允许修改状态</li>
<li>payable：允许从消息调用中接收以太币Ether 。</li>
<li>constant：与view相同，一般只修饰状态变量，不允许赋值（除初始化以外）</li>
</ul>
<p><strong>内部函数调用</strong></p>
<p>当前合约中的函数可以直接（“从内部”）调用，也可以递归调用，就像下边这个荒谬的例子一样<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.16</span>;</span><br><span class="line"></span><br><span class="line">contract C &#123;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">g</span>(<span class="params">uint a</span>) <span class="title">public</span> <span class="title">pure</span> <span class="title">returns</span> (<span class="params">uint ret</span>) </span>&#123; <span class="keyword">return</span> f(); &#125;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params"></span>) <span class="title">internal</span> <span class="title">pure</span> <span class="title">returns</span> (<span class="params">uint ret</span>) </span>&#123; <span class="keyword">return</span> g(<span class="number">7</span>) + f(); &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>这些函数调用在 EVM 中被解释为简单的跳转。这样做的效果就是当前内存不会被清除，也就是说，通过内部调用在函数之间传递内存引用是非常有效的。</p>
<p><strong>外部函数调用</strong></p>
<p>表达式 <code>this.g(8)</code>; 和 <code>c.g(2)</code>; （其中 c 是合约实例）也是有效的函数调用，但是这种情况下，函数将会通过一个消息调用来被“外部调用”，而不是直接的跳转。 请注意，不可以在构造函数中通过 this 来调用函数，因为此时真实的合约实例还没有被创建。</p>
<p>如果想要调用其他合约的函数，需要外部调用。对于一个外部调用，所有的函数参数都需要被复制到内存。</p>
<p>当调用其他合约的函数时，随函数调用发送的 Wei 和 gas 的数量可以分别由特定选项 <code>.value()</code> 和 <code>.gas()</code> 指定:</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br><span class="line"></span><br><span class="line">contract InfoFeed &#123;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">info</span>(<span class="params"></span>) <span class="title">public</span> <span class="title">payable</span> <span class="title">returns</span> (<span class="params">uint ret</span>) </span>&#123; <span class="keyword">return</span> <span class="number">42</span>; &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">contract Consumer &#123;</span><br><span class="line">    InfoFeed feed;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">setFeed</span>(<span class="params">address addr</span>) <span class="title">public</span> </span>&#123; feed = InfoFeed(addr); &#125;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">callFeed</span>(<span class="params"></span>) <span class="title">public</span> </span>&#123; feed.info.value(<span class="number">10</span>).gas(<span class="number">800</span>)(); &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>payable</code> 修饰符要用于修饰 <code>info</code>，否则，.<code>value()</code> 选项将不可用。</p>
<p>注意，表达式 <code>InfoFeed(addr)</code> 进行了一个的显式类型转换，说明”我们知道给定地址的合约类型是 <code>InfoFeed</code> “并且这不会执行构造函数。 显式类型转换需要谨慎处理。绝对不要在一个你不清楚类型的合约上执行函数调用。</p>
<p>我们也可以直接使用 <code>function setFeed(InfoFeed _feed) { feed = _feed; }</code> 。 注意一个事实，<code>feed.info.value(10).gas(800)</code> 只（局部地）设置了与函数调用一起发送的 Wei 值和 gas 的数量，只有最后的圆括号执行了真正的调用。</p>
<p>如果被调函数所在合约不存在（也就是账户中不包含代码）或者被调用合约本身抛出异常或者 gas 用完等，函数调用会抛出异常。</p>
<h3 id="3-2-2-引用类型介绍"><a href="#3-2-2-引用类型介绍" class="headerlink" title="3.2.2 引用类型介绍"></a>3.2.2 引用类型介绍</h3><p>比起之前讨论过的值类型，在处理复杂的类型（即占用的空间超过 256 位的类型）时，我们需要更加谨慎。 由于拷贝这些类型变量的开销相当大，我们不得不考虑它的存储位置，是将它们保存在 <strong>内存</strong> （并不是永久存储）中， 还是 <strong>存储</strong> （保存状态变量的地方）中。</p>
<ul>
<li><strong>数据位置</strong></li>
</ul>
<p>所有的复杂类型，即 <strong>数组</strong> 和 <strong>结构</strong> 类型，都有一个额外属性，“数据位置”，说明数据是保存在 <strong>内存</strong> 中还是 <strong>存储</strong> 中。 根据上下文不同，大多数时候数据有默认的位置，但也可以通过在类型名后增加关键字 <code>storage</code> 或 <code>memory</code> 进行修改。 函数参数（包括返回的参数）的数据位置默认是 <code>memory</code>， 局部变量的数据位置默认是 <code>storage</code>，状态变量的数据位置强制是 <code>storage</code>。</p>
<p>也存在第三种数据位置， <code>calldata</code> ，这是一块只读的，且不会永久存储的位置，用来存储函数参数。 外部函数的参数（非返回参数）的数据位置被强制指定为 <code>calldata</code>，效果跟 <code>memory</code> 差不多。</p>
<p>例子：<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br><span class="line"></span><br><span class="line">contract C &#123;</span><br><span class="line">    uint[] x; <span class="comment">// x 的数据存储位置是 storage</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// memoryArray 的数据存储位置是 memory</span></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params">uint[] memoryArray</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        x = memoryArray; <span class="comment">// 将整个数组拷贝到 storage 中，可行</span></span><br><span class="line">        <span class="keyword">var</span> y = x;  <span class="comment">// 分配一个指针（其中 y 的数据存储位置是 storage），可行</span></span><br><span class="line">        y[<span class="number">7</span>]; <span class="comment">// 返回第 8 个元素，可行</span></span><br><span class="line">        y.length = <span class="number">2</span>; <span class="comment">// 通过 y 修改 x，可行</span></span><br><span class="line">        <span class="keyword">delete</span> x; <span class="comment">// 清除数组，同时修改 y，可行</span></span><br><span class="line">        <span class="comment">// 下面的就不可行了；需要在 storage 中创建新的未命名的临时数组， /</span></span><br><span class="line">        <span class="comment">// 但 storage 是“静态”分配的：</span></span><br><span class="line">        <span class="comment">// y = memoryArray;</span></span><br><span class="line">        <span class="comment">// 下面这一行也不可行，因为这会“重置”指针，</span></span><br><span class="line">        <span class="comment">// 但并没有可以让它指向的合适的存储位置。</span></span><br><span class="line">        <span class="comment">// delete y;</span></span><br><span class="line"></span><br><span class="line">        g(x); <span class="comment">// 调用 g 函数，同时移交对 x 的引用</span></span><br><span class="line">        h(x); <span class="comment">// 调用 h 函数，同时在 memory 中创建一个独立的临时拷贝</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">g</span>(<span class="params">uint[] storage storageArray</span>) <span class="title">internal</span> </span>&#123;&#125;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">h</span>(<span class="params">uint[] memoryArray</span>) <span class="title">public</span> </span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>归纳：</p>
<p>强制指定的数据位置：</p>
<ol>
<li>外部函数的参数（不包括返回参数）： calldata</li>
<li>状态变量： storage</li>
</ol>
<p>默认数据位置：</p>
<ol>
<li>函数参数（包括返回参数）： memory</li>
<li>所有其它局部变量： storage</li>
</ol>
<ul>
<li><strong>数组</strong></li>
</ul>
<p>数组可以在声明时指定长度，也可以动态调整大小。 对于 <strong>存储</strong> 的数组来说，元素类型可以是任意的（即元素也可以是数组类型，映射类型或者结构体）。 对于 <strong>内存</strong> 的数组来说，元素类型不能是映射类型，如果作为 <code>public</code> 函数的参数，它只能是 <code>ABI</code> 类型。</p>
<p>一个元素类型为 <code>T</code>，固定长度为 <code>k</code> 的数组可以声明为 <code>T[k]</code>，而动态数组声明为 <code>T[]</code>。 </p>
<p>举个例子，一个长度为 5，元素类型为 <code>uint</code> 的动态数组的数组，应声明为 <code>uint[][5]</code> （注意这里跟其它语言比，数组长度的声明位置是反的）。 要访问第三个动态数组的第二个元素，你应该使用 <code>x[2][1]</code>（数组下标是从 0 开始的，且访问数组时的下标顺序与声明时相反，也就是说，<code>x[2]</code> 是从右边减少了一级）。。</p>
<p><code>bytes</code> 和 <code>string</code> 类型的变量是特殊的数组。 <code>bytes</code> 类似于 <code>byte[]</code>，但它在 <code>calldata</code> 中会被“紧打包”（译者注：将元素连续地存在一起，不会按每 32 字节一单元的方式来存放）。 <code>string</code> 与 <code>bytes</code> 相同，但（暂时）不允许用长度或索引来访问。</p>
<p>注：<br>如果想要访问以字节表示的字符串 s，请使用 <code>bytes(s)</code>.<code>length / bytes(s)[7] = &#39;x&#39;</code>;。 注意这时你访问的是 <code>UTF-8</code> 形式的低级<code>bytes</code> 类型，而不是单个的字符。</p>
<p><strong>成员</strong></p>
<p><code>length</code>:</p>
<p>数组有 length 成员变量表示当前数组的长度。 动态数组可以在 <strong>存储</strong> （而不是 <strong>内存</strong> ）中通过改变成员变量 .length 改变数组大小。 并不能通过访问超出当前数组长度的方式实现自动扩展数组的长度。 一经创建，<strong>内存</strong> 数组的大小就是固定的（但却是动态的，也就是说，它依赖于运行时的参数）。<br><code>push</code>:<br>    变长的 <strong>存储</strong> 数组以及 bytes 类型（而不是 string 类型）都有一个叫做 push 的成员函数，它用来附加新的元素到数组末尾。 这个函数将返回新的数组长度。 </p>
<p>例子：<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.16</span>;</span><br><span class="line"></span><br><span class="line">contract ArrayContract &#123;</span><br><span class="line">    uint[<span class="number">2</span>**<span class="number">20</span>] m_aLotOfIntegers;</span><br><span class="line">    <span class="comment">// 注意下面的代码并不是一对动态数组，</span></span><br><span class="line">    <span class="comment">// 而是一个数组元素为一对变量的动态数组（也就是数组元素为长度为 2 的定长数组的动态数组）。</span></span><br><span class="line">    bool[<span class="number">2</span>][] m_pairsOfFlags;</span><br><span class="line">    <span class="comment">// newPairs 存储在 memory 中 —— 函数参数默认的存储位置</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">setAllFlagPairs</span>(<span class="params">bool[<span class="number">2</span>][] newPairs</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 向一个 storage 的数组赋值会替代整个数组</span></span><br><span class="line">        m_pairsOfFlags = newPairs;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">setFlagPair</span>(<span class="params">uint index, bool flagA, bool flagB</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 访问一个不存在的数组下标会引发一个异常</span></span><br><span class="line">        m_pairsOfFlags[index][<span class="number">0</span>] = flagA;</span><br><span class="line">        m_pairsOfFlags[index][<span class="number">1</span>] = flagB;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">changeFlagArraySize</span>(<span class="params">uint newSize</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 如果 newSize 更小，那么超出的元素会被清除</span></span><br><span class="line">        m_pairsOfFlags.length = newSize;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">clear</span>(<span class="params"></span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 这些代码会将数组全部清空</span></span><br><span class="line">        <span class="keyword">delete</span> m_pairsOfFlags;</span><br><span class="line">        <span class="keyword">delete</span> m_aLotOfIntegers;</span><br><span class="line">        <span class="comment">// 这里也是实现同样的功能</span></span><br><span class="line">        m_pairsOfFlags.length = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    bytes m_byteData;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">byteArrays</span>(<span class="params">bytes data</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 字节的数组（语言意义中的 byte 的复数 ``bytes``）不一样，因为它们不是填充式存储的，</span></span><br><span class="line">        <span class="comment">// 但可以当作和 "uint8[]" 一样对待</span></span><br><span class="line">        m_byteData = data;</span><br><span class="line">        m_byteData.length += <span class="number">7</span>;</span><br><span class="line">        m_byteData[<span class="number">3</span>] = byte(<span class="number">8</span>);</span><br><span class="line">        <span class="keyword">delete</span> m_byteData[<span class="number">2</span>];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">addFlag</span>(<span class="params">bool[<span class="number">2</span>] flag</span>) <span class="title">public</span> <span class="title">returns</span> (<span class="params">uint</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> m_pairsOfFlags.push(flag);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">createMemoryArray</span>(<span class="params">uint size</span>) <span class="title">public</span> <span class="title">pure</span> <span class="title">returns</span> (<span class="params">bytes</span>) </span>&#123;</span><br><span class="line">        <span class="comment">// 使用 `new` 创建动态 memory 数组：</span></span><br><span class="line">        uint[<span class="number">2</span>][] memory arrayOfPairs = <span class="keyword">new</span> uint[<span class="number">2</span>][](size);</span><br><span class="line">        <span class="comment">// 创建一个动态字节数组：</span></span><br><span class="line">        bytes memory b = <span class="keyword">new</span> bytes(<span class="number">200</span>);</span><br><span class="line">        <span class="keyword">for</span> (uint i = <span class="number">0</span>; i &lt; b.length; i++)</span><br><span class="line">            b[i] = byte(i);</span><br><span class="line">        <span class="keyword">return</span> b;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<ul>
<li><strong>结构体</strong></li>
</ul>
<p>Solidity 支持通过构造结构体的形式定义新的类型，以下是一个结构体的示例：<br><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Funder</span> &#123;</span></span><br><span class="line">    address addr;</span><br><span class="line">    uint amount;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Campaign</span> &#123;</span></span><br><span class="line">    address beneficiary;</span><br><span class="line">    uint fundingGoal;</span><br><span class="line">    uint numFunders;</span><br><span class="line">    uint amount;</span><br><span class="line">    mapping (uint =&gt; Funder) funders;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<ul>
<li><strong>映射</strong><br>映射类型在声明时的形式为 <code>mapping(_KeyType =&gt; _ValueType)</code>。 其中 <code>_KeyType</code> 可以是除了映射、变长数组、合约、枚举以及结构体以外的几乎所有类型。 <code>_ValueType</code> 可以是包括映射类型在内的任何类型。</li>
</ul>
<p>映射可以视作 哈希表 <a href="https://en.wikipedia.org/wiki/Hash_table" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Hash_table</a>，它们在实际的初始化过程中创建每个可能的 key， 并将其映射到字节形式全是零的值：一个类型的 默认值。然而下面是映射与哈希表不同的地方： 在映射中，实际上并不存储 key，而是存储它的 <code>keccak256</code> 哈希值，从而便于查询实际的值。</p>
<p>正因为如此，映射是没有长度的，也没有 <code>key</code> 的集合或 <code>value</code> 的集合的概念。</p>
<p>只有状态变量（或者在 internal 函数中的对于存储变量的引用）可以使用映射类型。。</p>
<p>可以将映射声明为 <code>public</code>，然后来让 Solidity 创建一个 getter。<code>_KeyType</code> 将成为 getter 的必须参数，并且 getter 会返回 <code>_ValueType</code>。</p>
<p><code>_ValueType</code> 也可以是一个映射。这时在使用 getter 时将将需要递归地传入每个 <code>_KeyType</code>参数。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br><span class="line"></span><br><span class="line">contract MappingExample &#123;</span><br><span class="line">    mapping(<span class="function"><span class="params">address</span> =&gt;</span> uint) public balances;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">update</span>(<span class="params">uint newBalance</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        balances[msg.sender] = newBalance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">contract MappingUser &#123;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params"></span>) <span class="title">public</span> <span class="title">returns</span> (<span class="params">uint</span>) </span>&#123;</span><br><span class="line">        MappingExample m = <span class="keyword">new</span> MappingExample();</span><br><span class="line">        m.update(<span class="number">100</span>);</span><br><span class="line">        <span class="keyword">return</span> m.balances(<span class="keyword">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="3-2-3-涉及-LValues-的运算符"><a href="#3-2-3-涉及-LValues-的运算符" class="headerlink" title="3.2.3 涉及 LValues 的运算符"></a>3.2.3 涉及 LValues 的运算符</h4><ul>
<li><strong>删除</strong></li>
</ul>
<p><code>delete a</code> 的结果是将 <code>a</code> 的类型在初始化时的值赋值给 <code>a</code>。即对于整型变量来说，相当于 <code>a = 0</code>， 但 delete 也适用于数组，对于动态数组来说，是将数组的长度设为 0，而对于静态数组来说，是将数组中的所有元素重置。 如果对象是结构体，则将结构体中的所有属性重置。</p>
<p>delete 对整个映射是无效的（因为映射的键可以是任意的，通常也是未知的）。 因此在你删除一个结构体时，结果将重置所有的非映射属性，这个过程是递归进行的，除非它们是映射。 然而，单个的键及其映射的值是可以被删除的。</p>
<p>理解 <code>delete a</code>的效果就像是给 <code>a</code> 赋值很重要，换句话说，这相当于在 <code>a</code>中存储了一个新的对象。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br><span class="line"></span><br><span class="line">contract DeleteExample &#123;</span><br><span class="line">    uint data;</span><br><span class="line">    uint[] dataArray;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params"></span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        uint x = data;</span><br><span class="line">        <span class="keyword">delete</span> x; <span class="comment">// 将 x 设为 0，并不影响数据</span></span><br><span class="line">        <span class="keyword">delete</span> data; <span class="comment">// 将 data 设为 0，并不影响 x，因为它仍然有个副本</span></span><br><span class="line">        uint[] storage y = dataArray;</span><br><span class="line">        <span class="keyword">delete</span> dataArray;</span><br><span class="line">        <span class="comment">// 将 dataArray.length 设为 0，但由于 uint[] 是一个复杂的对象，y 也将受到影响，</span></span><br><span class="line">        <span class="comment">// 因为它是一个存储位置是 storage 的对象的别名。</span></span><br><span class="line">        <span class="comment">// 另一方面："delete y" 是非法的，引用了 storage 对象的局部变量只能由已有的 storage 对象赋值。</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-3-单位和全局变量"><a href="#3-3-单位和全局变量" class="headerlink" title="3.3 单位和全局变量"></a>3.3 单位和全局变量</h3><h3 id="3-3-1-以太币单位"><a href="#3-3-1-以太币单位" class="headerlink" title="3.3.1 以太币单位"></a>3.3.1 以太币单位</h3><p>以太币 单位之间的换算就是在数字后边加上 <code>wei</code>、 <code>finney</code>、 <code>szabo</code> 或 <code>ether</code> 来实现的，如果后面没有单位，缺省为 <code>Wei</code>。例如 <code>2 ether == 2000 finney</code> 的逻辑判断值为 <code>true</code>。</p>
<h3 id="3-3-2-时间单位"><a href="#3-3-2-时间单位" class="headerlink" title="3.3.2 时间单位"></a>3.3.2 时间单位</h3><p>秒是缺省时间单位，在时间单位之间，数字后面带有 <code>seconds</code>、 <code>minutes</code>、 <code>hours</code>、 <code>days</code>、 <code>weeks</code> 和 <code>years</code> 的可以进行换算，基本换算关系与现实生活相符。</p>
<h3 id="3-3-3-特殊变量和函数"><a href="#3-3-3-特殊变量和函数" class="headerlink" title="3.3.3 特殊变量和函数"></a>3.3.3 特殊变量和函数</h3><p>在全局命名空间中已经存在了（预设了）一些特殊的变量和函数，他们主要用来提供关于区块链的信息或一些通用的工具函数。</p>
<p><strong>区块和交易属性</strong></p>
<ul>
<li><code>block.blockhash(uint blockNumber) returns (bytes32)</code>：指定区块的区块哈希——仅可用于最新的 256 个区块且不包括当前区块；而 blocks 从 0.4.22 版本开始已经不推荐使用，由 <code>blockhash(uint blockNumber)</code> 代替</li>
<li><code>block.coinbase (address)</code>: 挖出当前区块的矿工地</li>
<li><code>block.difficulty (uint)</code>: 当前区块难度</li>
<li><code>block.gaslimit (uint)</code>: 当前区块 <code>gas</code> 限额</li>
<li><code>block.number (uint</code>): 当前区块号</li>
<li><code>block.timestamp (uint)</code>: 自 <code>unix epoch</code> 起始当前区块以秒计的时间戳</li>
<li><code>gasleft() returns (uint256)</code>：剩余的 <code>gas</code></li>
<li><code>msg.data (bytes)</code>: 完整的 <code>calldata</code></li>
<li><code>msg.gas (uint)</code>: 剩余 <code>gas</code> - 自 0.4.21 版本开始已经不推荐使用，由 gesleft() 代替</li>
<li><strong><code>msg.sender (address)</code>:</strong> 消息发送者（当前调用）</li>
<li><code>msg.sig (bytes4)</code>: calldata 的前 4 字节（也就是函数标识符）</li>
<li><code>msg.value (uint)</code>: 随消息发送的 wei 的数量</li>
<li><code>now (uint)</code>: 目前区块时间戳（<code>block.timestamp</code>）</li>
<li><code>tx.gasprice (uint)</code>: 交易的<code>gas</code> 价格</li>
<li><code>tx.origin (address)</code>: 交易发起者（完全的调用链）</li>
</ul>
<p><strong><a href="https://solidity-cn.readthedocs.io/zh/develop/abi-spec.html#abi" target="_blank" rel="noopener">ABI 编码函数</a></strong></p>
<ul>
<li><code>abi.encode(...) returns (bytes)</code>： ABI - 对给定参数进行编码</li>
<li><code>abi.encodePacked(...) returns (bytes)</code>：对给定参数执行 紧打包编码</li>
<li><code>abi.encodeWithSelector(bytes4 selector, ...) returns (bytes)：</code> ABI - 对给定参数进行编码，并以给定的函数选择器作为起始的 4 字节数据一起返回</li>
<li><code>abi.encodeWithSignature(string signature, ...) returns (bytes)</code>：等价于 <code>abi.encodeWithSelector(bytes4(keccak256(signature), ...)</code></li>
</ul>
<p><strong>错误处理</strong></p>
<ul>
<li><code>assert(bool condition)</code>:<br>  如果条件不满足，则使当前交易没有效果 — 用于检查内部错误。</li>
<li><code>require(bool condition)</code>:<br>  如果条件不满足则撤销状态更改 - 用于检查由输入或者外部组件引起的错误。</li>
<li><code>require(bool condition, string message)</code>:<br>  如果条件不满足则撤销状态更改 - 用于检查由输入或者外部组件引起的错误，可以同时提供一个错误消息。</li>
<li><code>revert()</code>:<br>  终止运行并撤销状态更改。</li>
<li><code>revert(string reason)</code>:<br>  终止运行并撤销状态更改，可以同时提供一个解释性的字符串。</li>
</ul>
<p><strong>地址相关</strong></p>
<ul>
<li><code>&lt;address&gt;.balance (uint256)</code>:<br>  以 Wei 为单位的 地址类型 的余额。</li>
<li><code>&lt;address&gt;.transfer(uint256 amount)</code>:<br>  向 地址类型 发送数量为 amount 的 Wei，失败时抛出异常，发送 2300 gas 的矿工费，不可调节。</li>
<li><code>&lt;address&gt;.send(uint256 amount) returns (bool)</code>:<br>  向 地址类型 发送数量为 amount 的 Wei，失败时返回 false，发送 2300 gas 的矿工费用，不可调节。</li>
<li><code>&lt;address&gt;.call(...) returns (bool)</code>:<br>  发出低级函数 CALL，失败时返回 false，发送所有可用 gas，可调节。</li>
<li><code>&lt;address&gt;.callcode(...) returns (bool)</code>：<br>  发出低级函数 CALLCODE，失败时返回 false，发送所有可用 gas，可调节。</li>
<li><code>&lt;address&gt;.delegatecall(...) returns (bool):</code><br>  发出低级函数 DELEGATECALL，失败时返回 false，发送所有可用 gas，可调节。 </li>
</ul>
<h3 id="3-4-表达式和控制结构"><a href="#3-4-表达式和控制结构" class="headerlink" title="3.4 表达式和控制结构(*)"></a>3.4 表达式和控制结构(*)</h3><h3 id="3-4-1-控制结构"><a href="#3-4-1-控制结构" class="headerlink" title="3.4.1 控制结构"></a>3.4.1 控制结构</h3><p>avaScript 中的大部分控制结构在 Solidity 中都是可用的，除了 <code>switch</code> 和 <code>goto</code>。 因此 Solidity 中有 <code>if，else，while，do，for，break，continue，return，? :</code>这些与在 C 或者 JavaScript 中表达相同语义的关键词。</p>
<p>用于表示条件的括号 <strong>不可以</strong> 被省略，单语句体两边的花括号可以被省略。</p>
<p>注意，与 C 和 JavaScript 不同， Solidity 中非布尔类型数值不能转换为布尔类型，因此 <code>if (1) { ... }</code> 的写法在 Solidity 中 无效 。</p>
<p>当一个函数有多个输出参数时， <code>return (v0, v1, ...,vn)</code> 写法可以返回多个值。不过元素的个数必须与输出参数的个数相同</p>
<h3 id="3-4-2-通过-new-创建合约"><a href="#3-4-2-通过-new-创建合约" class="headerlink" title="3.4.2 通过 new 创建合约"></a>3.4.2 通过 new 创建合约</h3><p>使用关键字 <code>new</code> 可以创建一个新合约。待创建合约的完整代码必须事先知道，因此递归的创建依赖是不可能的。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br><span class="line"></span><br><span class="line">contract D &#123;</span><br><span class="line">    uint x;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">D</span>(<span class="params">uint a</span>) <span class="title">public</span> <span class="title">payable</span> </span>&#123;</span><br><span class="line">        x = a;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">contract C &#123;</span><br><span class="line">    D d = <span class="keyword">new</span> D(<span class="number">4</span>); <span class="comment">// 将作为合约 C 构造函数的一部分执行</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">createD</span>(<span class="params">uint arg</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        D newD = <span class="keyword">new</span> D(arg);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">createAndEndowD</span>(<span class="params">uint arg, uint amount</span>) <span class="title">public</span> <span class="title">payable</span> </span>&#123;</span><br><span class="line">        <span class="comment">//随合约的创建发送 ether</span></span><br><span class="line">        D newD = (<span class="keyword">new</span> D).value(amount)(arg);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如示例中所示，使用 <code>.value（）</code> 选项创建 <code>D</code> 的实例时可以转发 <code>Ether</code>，但是不可能限制 <code>gas</code> 的数量。如果创建失败（可能因为栈溢出，或没有足够的余额或其他问题），会引发异常。</p>
<h3 id="3-4-3-错误处理：Assert-Require-Revert-and-Exceptions"><a href="#3-4-3-错误处理：Assert-Require-Revert-and-Exceptions" class="headerlink" title="3.4.3 错误处理：Assert, Require, Revert and Exceptions"></a>3.4.3 错误处理：Assert, Require, Revert and Exceptions</h3><p><code>Solidity</code> 使用状态恢复异常来处理错误。这种异常将撤消对当前调用（及其所有子调用）中的状态所做的所有更改，并且还向调用者标记错误。 便利函数 <code>assert</code> 和 <code>require</code> 可用于检查条件并在条件不满足时抛出异常。<code>assert</code> 函数只能用于测试内部错误，并检查非变量。</p>
<p> <code>require</code> 函数用于确认条件有效性，例如输入变量，或合约状态变量是否满足条件，或验证外部合约调用返回的值。 如果使用得当，分析工具可以评估你的合约，并标示出那些会使 <code>assert</code> 失败的条件和函数调用。 正常工作的代码不会导致一个 <code>assert</code>语句的失败；如果这发生了，那就说明出现了一个需要你修复的 bug。</p>
<p>还有另外两种触发异常的方法：<code>revert</code> 函数可以用来标记错误并恢复当前的调用。 <code>revert</code> 调用中包含有关错误的详细信息是可能的，这个消息会被返回给调用者。已经不推荐的关键字 <code>throw</code> 也可以用来替代 <code>revert()</code> （但无法返回错误消息）。</p>
<p>在下例中，你可以看到如何轻松使用<code>require</code>检查输入条件以及如何使用<code>assert</code>检查内部错误，注意，你可以给 require 提供一个消息字符串，而 assert 不行。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.22</span>;</span><br><span class="line"></span><br><span class="line">contract Sharer &#123;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">sendHalf</span>(<span class="params">address addr</span>) <span class="title">public</span> <span class="title">payable</span> <span class="title">returns</span> (<span class="params">uint balance</span>) </span>&#123;</span><br><span class="line">        <span class="built_in">require</span>(msg.value % <span class="number">2</span> == <span class="number">0</span>, <span class="string">"Even value required."</span>);</span><br><span class="line">        uint balanceBeforeTransfer = <span class="keyword">this</span>.balance;</span><br><span class="line">        addr.transfer(msg.value / <span class="number">2</span>);</span><br><span class="line">                    <span class="comment">//由于转移函数在失败时抛出异常并且不能在这里回调，因此我们应该没有办法仍然有一半的钱。</span></span><br><span class="line">        assert(<span class="keyword">this</span>.balance == balanceBeforeTransfer - msg.value / <span class="number">2</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.balance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-5-合约"><a href="#3-5-合约" class="headerlink" title="3.5 合约"></a>3.5 合约</h3><p>Solidity 合约类似于面向对象语言中的类。合约中有用于数据持久化的状态变量，和可以修改状态变量的函数。 调用另一个合约实例的函数时，会执行一个 EVM 函数调用，这个操作会切换执行时的上下文，这样，前一个合约的状态变量就不能访问了。</p>
<h3 id="3-5-1-创建合约"><a href="#3-5-1-创建合约" class="headerlink" title="3.5.1 创建合约"></a>3.5.1 创建合约</h3><p>可以通过以太坊交易“从外部”或从 Solidity 合约内部创建合约。<br>创建合约时，会执行一次构造函数（与合约同名的函数）。构造函数是可选的。只允许有一个构造函数，这意味着不支持重载。</p>
<p>在内部，构造函数参数在合约代码之后通过 <code>ABI</code> 编码 传递，但是如果你使用 <code>web3.js</code> 则不必关心这个问题。</p>
<p>如果一个合约想要创建另一个合约，那么创建者必须知晓被创建合约的源代码(和二进制代码)。 这意味着不可能循环创建依赖项。</p>
<h3 id="3-5-2-getter-函数"><a href="#3-5-2-getter-函数" class="headerlink" title="3.5.2 getter 函数"></a>3.5.2 getter 函数</h3><p>编译器自动为所有 <code>public</code> 状态变量创建 <code>getter</code> 函数。对于下面给出的合约，编译器会生成一个名为 <code>data</code> 的函数， 该函数不会接收任何参数并返回一个 <code>uint</code> ，即状态变量 <code>data</code> 的值。可以在声明时完成状态变量的初始化</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br><span class="line"></span><br><span class="line">contract C &#123;</span><br><span class="line">    uint public data = <span class="number">42</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">contract Caller &#123;</span><br><span class="line">    C c = <span class="keyword">new</span> C();</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params"></span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        uint local = c.data();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>getter 函数具有外部可见性。如果在内部访问 getter（即没有 this. ），它被认为一个状态变量。 如果它是外部访问的（即用 this. ），它被认为为一个函数。</p>
<h3 id="3-5-3-View-函数"><a href="#3-5-3-View-函数" class="headerlink" title="3.5.3 View 函数"></a>3.5.3 View 函数</h3><p>可以将函数声明为 view 类型，这种情况下要保证不修改状态。</p>
<p>下面的语句被认为是修改状态：</p>
<ol>
<li>修改状态变量。</li>
<li>产生事件。</li>
<li>创建其它合约。</li>
<li>使用 selfdestruct。</li>
<li>通过调用发送以太币。</li>
<li>调用任何没有标记为 view 或者 pure 的函数。</li>
<li>使用低级调用。</li>
<li>使用包含特定操作码的内联汇编。</li>
</ol>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.16</span>;</span><br><span class="line"></span><br><span class="line">contract C &#123;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params">uint a, uint b</span>) <span class="title">public</span> <span class="title">view</span> <span class="title">returns</span> (<span class="params">uint</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> a * (b + <span class="number">42</span>) + now;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-5-4-Pure-函数"><a href="#3-5-4-Pure-函数" class="headerlink" title="3.5.4 Pure 函数"></a>3.5.4 Pure 函数</h3><p>函数可以声明为 pure ，在这种情况下，承诺不读取或修改状态。</p>
<p>除了上面解释的状态修改语句列表之外，以下被认为是从状态中读取：</p>
<ol>
<li>读取状态变量。</li>
<li>访问 this.balance 或者 <address>.balance。</address></li>
<li>访问 block，tx， msg 中任意成员 （除 msg.sig 和 msg.data 之外）。</li>
<li>调用任何未标记为 pure 的函数。</li>
<li>使用包含某些操作码的内联汇编。</li>
</ol>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.16</span>;</span><br><span class="line"></span><br><span class="line">contract C &#123;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params">uint a, uint b</span>) <span class="title">public</span> <span class="title">pure</span> <span class="title">returns</span> (<span class="params">uint</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> a * (b + <span class="number">42</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="四、练习题"><a href="#四、练习题" class="headerlink" title="四、练习题"></a>四、练习题</h2><h3 id="4-1-将固定长度字节数组转化为string类型"><a href="#4-1-将固定长度字节数组转化为string类型" class="headerlink" title="4.1 将固定长度字节数组转化为string类型"></a>4.1 将固定长度字节数组转化为<code>string</code>类型</h3><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br><span class="line"></span><br><span class="line">contract bytes32tostring&#123;</span><br><span class="line">    </span><br><span class="line">    bytes10 testword=<span class="number">0x68656c6c6f776f726c64</span>; <span class="comment">//为helloworld</span></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">bytes32tostringF</span>(<span class="params"></span>) <span class="title">public</span> <span class="title">view</span> <span class="title">returns</span>(<span class="params">string</span>)</span>&#123;</span><br><span class="line">    </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="4-2-实现一个带有简单逻辑判断及多种数学运算的Solidity程序"><a href="#4-2-实现一个带有简单逻辑判断及多种数学运算的Solidity程序" class="headerlink" title="4.2 实现一个带有简单逻辑判断及多种数学运算的Solidity程序"></a>4.2 实现一个带有简单逻辑判断及多种数学运算的Solidity程序</h3><p><strong>参考自：</strong></p>
<ol>
<li><p>黄皮书：<a href="https://github.com/yuange1024/ethereum_yellowpaper/blob/master/ethereum_yellow_paper_cn.pdf" target="_blank" rel="noopener">https://github.com/yuange1024/ethereum_yellowpaper/blob/master/ethereum_yellow_paper_cn.pdf</a></p>
</li>
<li><p>白皮书：<a href="https://github.com/ethereum/wiki/wiki/White-Paper" target="_blank" rel="noopener">https://github.com/ethereum/wiki/wiki/White-Paper</a><br> <a href="https://blog.csdn.net/weixin_45067603" target="_blank" rel="noopener">INlinKC</a><br> <a href="https://ethfans.org/wikis/Home" target="_blank" rel="noopener">https://ethfans.org/wikis/Home</a></p>
</li>
<li>以太坊solidity学习记录: <a href="https://blog.csdn.net/weixin_45067603/article/details/105726491" target="_blank" rel="noopener">https://blog.csdn.net/weixin_45067603/article/details/105726491</a></li>
<li><a href="https://www.bilibili.com/video/BV1sJ411D72u" target="_blank" rel="noopener">尚硅谷区块链全套Go语言→GoWeb→以太坊→项目实战</a></li>
</ol>
]]></content>
      <categories>
        <category>Blockchain</category>
      </categories>
  </entry>
  <entry>
    <title>区块链入门（二）基础知识介绍</title>
    <url>/posts/fb46f828.html</url>
    <content><![CDATA[<font color="red"> 注：本教程为技术教程，不谈论且不涉及炒作任何数字货币 </font>

<p>本次组队学习重点在于以太坊基础知识、以太坊客户端以及以太坊solidity编程，因此本节教程重点在于以太坊核心知识点的掌握，区块链部分的基础知识可以作为补充，请学习者量力而行。另外若学习者觉得本节内容难度太高，可以先对基本知识点有一个概览，在第二节以及第三节实战内容学习完成之后再深入学习本节内容。</p>
<h1 id="一、区块链简介"><a href="#一、区块链简介" class="headerlink" title="一、区块链简介"></a>一、区块链简介</h1><h2 id="1-1、区块链与区块链技术"><a href="#1-1、区块链与区块链技术" class="headerlink" title="1.1、区块链与区块链技术"></a>1.1、区块链与区块链技术</h2><p>在阅读本教程之前，<a href="http://blog.codinglabs.org/articles/bitcoin-mechanism-make-easy.html" target="_blank" rel="noopener">大家对比特币原理不太了解同学可以先阅读下此博客~</a>,大家对比特币有简单了解后对于区块链会有更好的认识。</p>
<p><strong>区块链</strong>是将记录（区块）通过密码学串联并加密的链式数据结构。而<strong>区块链技术</strong>，是通过P2P网络和区块链来实现数据存储的<strong>去中心化</strong>、<strong>不可逆</strong>和<strong>不可篡改</strong>。比特币正是构建在区块链技术上的典型应用。通过区块链技术，我们可以将信息（数据、程序）保存在区块上并接入到区块链中，这样就实现了信息的去中心化存储、不可逆和不可篡改。<strong>区块链应用</strong>是指利用区块链技术开发的应用。</p>
<h2 id="1-2、区块链历史"><a href="#1-2、区块链历史" class="headerlink" title="1.2、区块链历史"></a>1.2、区块链历史</h2><p>2008年，一个网名叫中本聪（Satoshi Nakamoto）的人发表了一篇名为《比特币：一种点对点电子货币系统》的论文，论文中首次提到了“区块链”这一概念。2009年，中本聪创立了以区块链为底层技术的比特币网络，开发出了第一个区块，被称为“创世区块”。该阶段被称为“区块链1.0”。</p>
<p>由于比特币是一个电子货币系统，所以主要功能就是记账。但随后人们发现，区块链技术作为比特币的底层技术，功能可以远远不止于记账，许多关于“未知的信任”的问题，都可以通过区块链来解决，例如电子存证、信息记录等。于是在比特币的基础上，诞生了带有智能合约的区块链系统，即允许开发者通过编写智能合约来实现特定的逻辑，这一阶段被称为“区块链2.0”。这一阶段的主要代表是以太坊。</p>
<p>随后，人们想要提升区块链应用的性能，于是出现了EOS、ArcBlock等系统，其特点是高性能、大吞吐量，但由于引入了超级节点、云节点等特性，弱化了“去中心化”这一特点，因此受到较大的争议。这一阶段被称为“区块链3.0”。</p>
<p>由于比特币是一款电子货币，可扩展性较低，而所谓的“区块链3.0”目前受到较大争议，且部分项目的底层算法完全不同于典型的区块链，因此学习区块链2.0中的以太坊是目前学习区块链的最佳方式。</p>
<h2 id="1-3、区块链基础技术与算法"><a href="#1-3、区块链基础技术与算法" class="headerlink" title="1.3、区块链基础技术与算法"></a>1.3、区块链基础技术与算法</h2><p>区块链技术不是单独的一项技术，而是一系列技术组成的技术栈，其具有以下的特点：</p>
<ul>
<li>数据分布式存储</li>
<li>存储的数据不可逆、不可篡改、可回溯</li>
<li>数据的创建和维护由所有参与方共同参与</li>
</ul>
<p>为了实现这些特点、维护区块链应用的稳定运行，区块链技术中包含了分布式存储技术、密码学技术、共识机制以及区块链2.0提出的智能合约。</p>
<h3 id="1-3-1、区块"><a href="#1-3-1、区块" class="headerlink" title="1.3.1、区块"></a>1.3.1、区块</h3><p>区块链由一个个区块（block）组成。区块很像数据库的记录，每次写入数据，就是创建一个区块。</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\bg2017122703.png" width="300">
</center>
<center>中心化存储</center>

<p>每个区块包含两个部分。</p>
<blockquote>
<ul>
<li>区块头（Head）：记录当前区块的特征值</li>
<li>区块体（Body）：实际数据</li>
</ul>
</blockquote>
<p>区块头包含了当前区块的多项特征值。</p>
<blockquote>
<ul>
<li>生成时间</li>
<li>实际数据（即区块体）的哈希</li>
<li>上一个区块的哈希</li>
<li>…</li>
</ul>
</blockquote>
<h3 id="1-3-2、分布式存储技术"><a href="#1-3-2、分布式存储技术" class="headerlink" title="1.3.2、分布式存储技术"></a>1.3.2、分布式存储技术</h3><p>与传统的数据存储技术不同，在区块链技术中，数据并不是集中存放在某个数据中心上，也不是由某个权威机构或是大多数节点来存储，而是分散存储在区块链网络中的每一个节点上。</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image2.png" width="300">
</center>
<center>中心化存储</center>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image3.png" width="300">
</center>
<center>分布式存储</center>

<p><strong>节点和区块的关系是什么？</strong></p>
<p>可以用共享文档来简单描述：所有可以访问共享文档的账号就叫做节点，当然全节点需要同步共享文档，也就是拥有全部的区块数据区块就是共享文档。每个人更新了，所有人都可以查看最新的文档</p>
<h3 id="1-3-3、密码学技术"><a href="#1-3-3、密码学技术" class="headerlink" title="1.3.3、密码学技术"></a>1.3.3、密码学技术</h3><p>为了实现数据的不可逆、不可篡改和可回溯，区块链技术采用了一系列密码学算法和技术，包括哈希算法、Merkle 树、非对称加密算法。</p>
<h5 id="哈希算法"><a href="#哈希算法" class="headerlink" title="哈希算法"></a>哈希算法</h5><p>哈希算法是一个单向函数，可以将任意长度的输入数据转化为固定长度的输出数据（哈希值），哈希值就是这段输入数据唯一的数值表现。由于在计算上不可能找到哈希值相同而输入值不同的字符串，因此两段数据的哈希值相同，就可以认为这两段数据也是相同的，所以哈希算法常被用于对数据进行验证。</p>
<p>在区块链中，数据存储在区块里。每个区块都有一个区块头，区块头中存储了一个将该区块所有数据经过哈希算法得到的哈希值，同时，每个区块中还存储了前一个区块的哈希值，这样就形成了区块链。如果想要篡改某一个区块A中的数据，就会导致A的哈希值发生变化，后一个区块B就无法通过哈希值正确地指向A，这样篡改者又必须篡改B中的数据……也就是说，篡改者需要篡改被篡改的区块以及后面的所有区块，才能让所有的节点都接受篡改。</p>
<h5 id="Merkle树"><a href="#Merkle树" class="headerlink" title="Merkle树"></a>Merkle树</h5><p>Merkle树是一种树形结构，在区块链中，Merkle树的叶子节点是区块中数据的哈希值，非叶子节点是其子结点组合后的哈希值，这样由叶子节点开始逐层往上计算，最终形成一个Merkle根，记录在区块的头部，这样就可以保证每一笔交易都无法篡改。</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image4.png" width="500">
</center>
<center>Merkle 树</center>

<h5 id="非对称加密技术"><a href="#非对称加密技术" class="headerlink" title="非对称加密技术"></a>非对称加密技术</h5><p>非对称加密技术使用两个非对称密钥：公钥和私钥。公钥和私钥具有两个特点：</p>
<ol>
<li>通过其中一个密钥加密信息后，使用另一个密钥才能解开</li>
<li>公钥一般可以公开，私钥则保密</li>
</ol>
<p>在区块链中，非对称加密技术主要用于信息加密、数字签名和登录认证。在信息加密场景中，信息发送者A使用接收者B提供的公钥对信息进行加密，B收到加密的信息后再通过自己的私钥进行解密。再数字签名场景中，发送者A通过自己的私钥对信息进行加密，其他人通过A提供的公钥来对信息进行验证，证明信息确实是由A发出。在登录认证场景中，客户端使用私钥加密登录信息后进行发送，其他人通过客户端公钥来认证登录信息。</p>
<ul>
<li><p>RSA 算法</p>
<p>​        RSA加密算法是最常用的非对称加密算法，CFCA在证书服务中离不了它。但是有不少新来的同事对它不太了解，恰好看到一本书中作者用实例对它进行了简化而生动的描述，使得高深的数学理论能够被容易地理解。<br>​       RSA是第一个比较完善的公开密钥算法，它既能用于加密，也能用于数字签名。RSA以它的三个发明者Ron Rivest, Adi Shamir, Leonard Adleman的名字首字母命名，这个算法经受住了多年深入的密码分析，虽然密码分析者既不能证明也不能否定RSA的安全性，但这恰恰说明该算法有一定的可信性，目前它已经成为最流行的公开密钥算法。<br>　　RSA的安全基于大数分解的难度。其公钥和私钥是一对大素数（100到200位十进制数或更大）的函数。从一个公钥和密文恢复出明文的难度，等价于分解两个大素数之积（这是公认的数学难题）。 </p>
</li>
<li><p>ECC 椭圆曲线算法</p>
<p>具体可以参见此文章：<a href="https://zhuanlan.zhihu.com/p/36326221" target="_blank" rel="noopener">ECC椭圆曲线加密算法：介绍</a></p>
</li>
</ul>
<h3 id="1-3-4、共识机制"><a href="#1-3-4、共识机制" class="headerlink" title="1.3.4、共识机制"></a>1.3.4、共识机制</h3><p>区块链系统是一个分布式系统，分布式系统要解决都首要问题就是一致性问题，也就是如何使多个孤立的节点达成共识。在中心化系统中，由于有一个中心服务器这样的“领导”来统一各个节点，因此达成一致性几乎没有问题。但在去中心化场景下，由于各个节点是相互独立的，就可能会出现许多不一致的问题，例如由于网络状况等因素部分节点可能会有延迟、故障甚至宕机，造成节点之间通信的不可靠，因此一致性问题是分布式系统中一个很令人头疼的问题。</p>
<p>由 Eirc Brewer 提出，Lynch 等人证明的 CAP 定理为解决分布式系统中的一致性问题提供了思路。CAP 定理的描述如下：在分布式系统中，<strong>一致性</strong>、<strong>可用性</strong>和<strong>分区容错性</strong>三者不可兼得。这三个术语的解释如下：</p>
<ul>
<li>一致性（<strong>C</strong>onsistency）：所有节点在同一时刻拥有同样的值（等同于所有节点访问同一份最新的数据副本</li>
<li>可用性（<strong>A</strong>vailability）：每个请求都可以在有限时间内收到确定其是否成功的响应</li>
<li>分区容错性（<strong>P</strong>artition tolerance）：分区是指部分节点因为网络原因无法与其他节点达成一致。分区容错性是指由网络原因导致的系统分区不影响系统的正常运行。例如，由于网络原因系统被分为 A, B, C, D 四个区，A, B 中的节点无法正常工作，但 C, D 组成的分区仍能提供正常服务。</li>
</ul>
<p>在某些场景下，对一致性、可用性和分区容错性中的某一个特性要求不高时，就可以考虑弱化该特性，来保证整个系统的容错能力。区块链中常见的共识机制的基本思路正是来自 CAP 定理，部分区块链应用中用到的共识机制如下表：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>共识机制</th>
<th>应用</th>
</tr>
</thead>
<tbody>
<tr>
<td>PoW</td>
<td>比特币、莱特币、以太坊的前三个阶段</td>
</tr>
<tr>
<td>PoS</td>
<td>PeerCoin、NXT、以太坊的第四个阶段</td>
</tr>
<tr>
<td>PBFT</td>
<td>Hyperledger Fabric</td>
</tr>
</tbody>
</table>
</div>
<h5 id="PoW（Proof-of-Work，工作量证明）"><a href="#PoW（Proof-of-Work，工作量证明）" class="headerlink" title="PoW（Proof of Work，工作量证明）"></a>PoW（Proof of Work，工作量证明）</h5><p>PoW 机制的大致流程如下：</p>
<ol>
<li>向所有节点广播新交易和一个数学问题</li>
<li>最先解决了数学问题的节点将交易打包成区块，对全网广播</li>
<li>其他节点验证广播区块的节点是否解决了数学问题（完成了一定的工作量），验证通过则接受该区块，并将该区块的哈希值放入下一个区块中，表示承认该区块</li>
</ol>
<p>由于在 PoW 机制中，区块的产生需要解决一个数学问题，也就是所谓的<strong>挖矿</strong>，这往往要消耗较大的算力和电力，因此节点们倾向于在<strong>最长的链</strong>的基础上添加区块，因为如果节点想在自己的链上添加新的区块，那么就需要重新计算 1 个或 $n$ 个这样的数学问题（每添加一个区块就需要计算一个）。因此在比特币中最长的链被认为是合法的链，这样节点间就形成了一套“共识”。</p>
<p>PoW 机制的优点是完全去中心化，缺点是需要依赖数学运算，资源的消耗会比其他的共识机制高，可监管性弱，同时每次达成共识需要全网共同参与运算，性能较低。</p>
<h5 id="PoS（Proof-of-Stack，股权证明）"><a href="#PoS（Proof-of-Stack，股权证明）" class="headerlink" title="PoS（Proof of Stack，股权证明）"></a>PoS（Proof of Stack，股权证明）</h5><p>PoS 针对 PoW 的缺点做出了改进。PoS 要求参与者预先放置一些货币在区块链上用于换取“股权”，从而成为<strong>验证者（Validator）</strong>，验证者具有产生区块的权利。PoS 机制会按照存放货币的量和时间给验证者分配相应的利息，同时还引入了奖惩机制，打包错误区块的验证者将失去他的股权——即投入的货币以及产生区块的权利。PoS 机制的大致流程如下：</p>
<ol>
<li>加入 PoS 机制的都是持币人，称为验证者</li>
<li>PoS 算法根据验证者持币的多少在验证者中挑选出一个给予产生区块的权利</li>
<li>如果一定时间内没有产生区块，PoS 就挑选下一个验证者，给予产生区块的权利</li>
<li>如果某个验证者打包了一份欺诈性交易，PoS 将剥夺他的股权</li>
</ol>
<p>PoS 的优点在于：</p>
<ol>
<li>引入了利息，使得像比特币这样发币总数有限的通货紧缩系统在一定时间后不会“无币可发”</li>
<li>引入了奖惩机制使节点的运行更加可控，同时更好地防止攻击</li>
<li>与 PoW 相比，不需要为了生成新区块而消耗大量电力和算力</li>
<li>与 PoW 相比，缩短了达成共识所需的时间</li>
</ol>
<p>由于 PoS 机制需要用户已经持有一定数量的货币，没有提供在区块链应用创立初始阶段处理数字货币的方法，因此使用 PoS 机制的区块链应用会在发布时预先出售货币，或在初期采用 PoW，让矿工获得货币后再转换成 PoS，例如以太坊现阶段采用的是 PoW 机制，在第四阶段“宁静”（Serenity）中将过渡到 PoS。</p>
<h5 id="拜占庭将军问题（Byzantine-Generals-Problem）"><a href="#拜占庭将军问题（Byzantine-Generals-Problem）" class="headerlink" title="拜占庭将军问题（Byzantine Generals Problem）"></a>拜占庭将军问题（Byzantine Generals Problem）</h5><p>拜占庭将军问题是分布式网络中的通信容错问题，可以描述为：</p>
<blockquote>
<p>一组拜占庭将军各领一支队伍共同围困一座城市。各支军队的行动策略限定为进攻或撤离两种。因为部分军队进攻而部分军队撤离可能会造成灾难性的后果，因此各将军决定通过投标来达成一致策略，即“共进退”。因为各将军位于城市不同方向，他们只能通过信使互相联系。在投票过程中每位将军都将自己的选择（进攻或撤退）通过信使分别通知其他所有将军，这样一来每位将军根据自己的投票和其他所有将军送来的信息就可以知道共同投票的结果，进而做出行动。</p>
</blockquote>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image1.png" width="500">
</center>



<p>拜占庭将军的问题在于，将军中可能出现叛徒。假设3名将军中有1名叛徒，2名忠诚将军一人投进攻票，一人投撤退票，这时叛徒可能会故意给投进攻的将军投进攻票，而给投撤退的将军投撤退票。这就导致一名将军带队发起进攻，而另外一名将军带队撤退。</p>
<p>另外，由于将军之间通过信使进行通讯，即使所有将军都忠诚，也不能排除信使被敌人截杀，甚至信使叛变等情况。</p>
<p>假设存在叛变将军或信使出问题等情况，如果忠诚将军仍然能够通过投票来决定他们的战略，便称系统达到了<strong>拜占庭容错（Byzantine Fault Tolerance）</strong>。</p>
<p>拜占庭问题对应到区块链中，将军就是节点，信使就是网络等通信系统，要解决的是存在恶意节点、网络错误等情况下系统的一致性问题。</p>
<p><strong>PBFT（Practical Byzantine Fault Tolerance）</strong> 是第一个得到广泛应用且比较高效的拜占庭容错算法，能够在节点数量不小于 $n=3f+1$ 的情况下容忍 $f$ 个拜占庭节点（恶意节点）。</p>
<h1 id="二、以太坊介绍"><a href="#二、以太坊介绍" class="headerlink" title="二、以太坊介绍"></a>二、以太坊介绍</h1><p>首先我们要知道我们为什么要学习以太坊，主要有以下四个原因：</p>
<ul>
<li>以太坊是区块链2.0的代表，学习以太坊能了解到区块链技术的所有知识</li>
<li>引入了智能合约，拓宽了区块链的应用场景</li>
<li>对开发者友好、对用户友好，容易编写出简单的区块链应用，学习趣味性高</li>
<li>Solidity 语法与 Javascript、Go 等语言接近，易上手</li>
</ul>
<h2 id="2-1、以太坊简介"><a href="#2-1、以太坊简介" class="headerlink" title="2.1、以太坊简介"></a>2.1、以太坊简介</h2><p>区块链技术常常被认为是自互联网诞生以来最具颠覆性的技术，然而，自比特币诞生后一直没有很好的区块链应用开发平台。想要在比特币基础上开发区块链应用是非常复杂繁琐的，因为比特币仅仅是一个加密数字货币系统，无法用来实现更广阔的业务需求。以太坊是目前使用最广泛的支持完备应用开发的共有区块链系统。</p>
<p>和比特币不同，比特币只适合加密数字货币场景，不具备图灵完备性，也缺乏保存实时状态的账户概念，以及存在 PoW 机制带来的效率和资源浪费的问题，而以太坊作为区块链2.0的代表，目标是扩展智能合约和建立一个去中心化应用平台，具有图灵完备的特性、更高效的共识机制、支持智能合约等多种应用场景，使得开发者能够很方便地在以太坊上开发出基于区块链的应用。</p>
<h3 id="2-1-1、以太坊的发展"><a href="#2-1-1、以太坊的发展" class="headerlink" title="2.1.1、以太坊的发展"></a>2.1.1、以太坊的发展</h3><p>2014年， Vitalik Buterin 发表了文章《以太坊：一个下一代智能合约和去中心化应用平台》。同年，Buterin 在迈阿密比特币会议中宣布启动以太坊项目，并提出了多项创新性的区块链技术。2015年，以太坊CCO Stephan Tual 在官方博客上宣布以太坊系统诞生，主网上线。</p>
<p>以太坊发展至今经历了“前沿”（Frontier）、“家园”（Homestead）以及现在所处的“大都会”（Metropolis）三个阶段。第四阶段“宁静”（Serenity）将作为以太坊的最后一个阶段，目前尚未有计划发布日期。</p>
<h3 id="2-1-2、以太坊的特点"><a href="#2-1-2、以太坊的特点" class="headerlink" title="2.1.2、以太坊的特点"></a>2.1.2、以太坊的特点</h3><p>以太坊团队和外界对以太坊的描述都是“世界计算机”，这代表它是一个开源的、全球的去中心化计算架构。它执行称为智能合约的程序，并使用区块链来同步和存储系统状态，以及使用名为以太币的加密数字货币来计量和约束执行操作的资源成本。同时，以太坊提供了一系列的接口，使得开发者能够通过以太坊来开发去中心化 Web 应用DApps。</p>
<h3 id="2-1-3、智能合约"><a href="#2-1-3、智能合约" class="headerlink" title="2.1.3、智能合约"></a>2.1.3、智能合约</h3><p>相比比特币，以太坊最大的特点就是引入了<strong>智能合约</strong>。智能合约本质上就是一段编写好的程序，可以在特定的条件下被触发并执行特定的操作。由于区块链具有不可逆和不可篡改的特点，因此智能合约与区块链结合后，就成了一份“强制执行”的合约。</p>
<p>以太坊能够作为一个去中心化应用平台和”世界计算机”，其核心就是智能合约。智能合约的引入，使得开发者能够实现许多（理论上是任何）业务逻辑。如果说比特币是通过区块链技术开发的特定计算器，那么引入了智能合约的以太坊就是基于区块链技术的通用计算机。可以简单的理解成：比特币的交易系统就是一份写死的智能合约，而以太坊则将智能合约的开发权限交给开发者。</p>
<p>以太坊提供了对智能合约的全面支持，包括编写智能合约编程语言 <strong>Solidity</strong> 和运行智能合约的<strong>以太坊虚拟机（Ethereum Virtual Machine，EVM）</strong>。</p>
<h3 id="2-1-4、幽灵协议"><a href="#2-1-4、幽灵协议" class="headerlink" title="2.1.4、幽灵协议"></a>2.1.4、幽灵协议</h3><p>幽灵合约的英文是“Greedy Heaviest Observed Subtree” (GHOST) protocol，在介绍幽灵协议之前，先介绍以太坊中的叔区块、叔块奖励和叔块引用奖励这三个概念。</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image5.png" width="400">
</center>


<p>假设目前以太坊区块链中的区块高度（区块链上的区块个数）为6，现在产生了一笔新的交易，矿工A先将该笔交易打包成了区块 Block 7，在矿工A将 Block 7 广播到其他节点的这段时间里，矿工B和矿工C又分别产生了 Block 8 和 Block 9。Block 7、Block 8、Block 9 都指向 Block 6，即 Block 6 是他们的父区块。由于 Block 7 是最先产生的，因此 Block 7 被认为是有效区块，Block 8 和 Block 9 就是<strong>叔区块</strong>（作废区块）。</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image6.png" width="300">
</center>


<p>现在链上的区块高度为7，在这基础上又产生了新的交易，并被打包成了 Block 10。在以太坊中，Block 10 除了可以引用它的父区块 Block 7 外，还可以引用叔区块 Block 8 和 Block 9。并且，Block 8 和 Block 9 的矿工会因此获得一笔奖励，称为<strong>叔块奖励</strong>，Block 10 的矿工除了基础奖励之外，由于引用了叔区块，还会获得一笔额外的<strong>叔块引用奖励</strong>。</p>
<p><strong>幽灵协议</strong>是以太坊的一大创新。由于在比特币中的出块时间被设计为10分钟，而以太坊为了提高出块速度，将出块时间设计为12秒（实际14~15秒左右），这样的高速出块意味着高速确认，高速确认会带来区块的<strong>高作废率</strong>和<strong>低安全性</strong>。因为区块需要花一定的时间才能广播至全网，如果矿工 A 挖出了一个区块，而矿工 B 碰巧在 A 的区块扩散至 B 之前挖出了另一个区块，矿工 B 的区块就会作废并且没有对区块链的网络安全做出贡献。此外，这样的高速确认还会带来<strong>中心化</strong>的问题：如果 A 拥有全网 30% 的算力而 B 拥有 10% 的算力，那么 A 将会在 70% 的时间内都在产生作废区块，而 B 在 90% 的时间内都在产生作废区块，这样，B 永远追不上 A，后果是 A 通过其算力份额拥有对挖矿过程实际上的控制权，出现了算力垄断，弱化了去中心化。</p>
<p>幽灵协议正是为了解决上述问题而引入的，协议的主要内容如下：</p>
<ul>
<li>计算最长链时，不仅包括当前区块的父区块和祖区块，还包括祖先块的作废的后代区块（叔区块），将它们综合考虑来计算哪一个区块拥有支持其的最大工作量证明。这解决了网络安全性的问题</li>
<li>以太坊付给以“叔区块”身份为新块确认作出贡献的废区块87.5%的奖励（叔块奖励），把它们纳入计算的“侄子区块”将获得奖励的12.5%（叔块引用奖励）。这就使得即使产生作废区块的矿工也能够参与区块链网络贡献并获得奖励，解决了中心化倾向的问题</li>
<li>叔区块最深可以被其父母的第二代至第七代后辈区块引用。这样做是为了：<ul>
<li>降低引用叔区块的计算复杂性</li>
<li>过多的叔块引用奖励会剥夺矿工在主链上挖矿的激励，使得矿工有转向公开攻击者链上挖矿的倾向（即公开攻击者可能会恶意产生大量作废区块，无限引用将会诱使矿工转移到攻击者的链上，从而抛弃合法的主链）</li>
<li>计算表明带有激励的五层幽灵协议即使在出块时间为15s的情况下也实现了了95%以上的效率，而拥有25%算力的矿工从中心化得到的益处小于3%</li>
</ul>
</li>
</ul>
<h3 id="2-1-5、以太坊的组成部分"><a href="#2-1-5、以太坊的组成部分" class="headerlink" title="2.1.5、以太坊的组成部分"></a>2.1.5、以太坊的组成部分</h3><p>在以太坊中，包括了 P2P 网络、共识机制、交易、状态机、客户端这几个组成部分。</p>
<ul>
<li>P2P 网络：在以太坊主网上运行，可通过TCP端口30303访问，并运行称为 ÐΞVp2p 的协议。</li>
<li>共识机制：以太坊目前使用名为 Ethash 的 POW 算法，计划在将来会过渡到称为 Casper 的 POS 算法。</li>
<li>交易：以太坊中的交易本质上是网络消息，包括发送者、接收者、值和数据载荷（payload）。</li>
<li>状态机：以太坊的状态转移由以太坊虚拟机（Ethereum Virtual Machine，EVM）处理，EVM 能够将智能合约编译成机器码并执行。</li>
<li>客户端：用于用户和以太坊进行交互操作的软件实现，最突出的是 Go-Ethereum(Geth) 和 Parity。</li>
</ul>
<h3 id="2-1-6、以太坊中的概念"><a href="#2-1-6、以太坊中的概念" class="headerlink" title="2.1.6、以太坊中的概念"></a>2.1.6、以太坊中的概念</h3><ul>
<li>账户：以太坊中的账户类似于银行账户、应用账户，每个账户有一个20字节的地址。账户又分为<strong>普通账户</strong>（又叫外部账户，External Owned Account, EOA）和<strong>合约账户</strong>（Contract）。普通账户是由以太坊使用者创建的账户，包含地址、余额和随机数；合约账户是创建智能合约时建立的账户，包含存储空间和合约代码</li>
<li>状态：状态是由账户和两个账户之间价值的转移以及信息的状态转换构成的</li>
<li>地址：地址是一个账户 ECDSA 公钥的 Keccak 散列最右边的160位，通过地址可以在以太坊上接收或发送交易。在 Etherscan 上，可以通过地址来查询一个账户的信息</li>
<li>交易：以太坊中的交易不仅包括发送和接收以太币，还包括向合约账户发送交易来调用合约代码、向空用户发送交易来生成以交易信息为代码块的合约账户</li>
<li>Gas：Gas 是以太坊中的一种机制，用于执行智能合约或交易操作的虚拟燃料。由于以太坊是图灵完备的，为了避免开发者无意或恶意编写出死循环等浪费资源或滥用资源的情况，以太坊中的每一笔交易都需支付一定的 Gas （燃料费），即需支付一定的以太币作为 Gas。Gas 的金额通常是由交易的发起者指定并支付的</li>
<li>挖矿：和比特币类似，以太坊同样通过挖矿来产生区块。在以太坊目前的 PoW 机制下，每当一笔交易发出并广播，就会吸引矿工来将该交易打包成区块。每产生一个区块都会有一笔<strong>固定奖励</strong>给矿工，目前的固定奖励是3个以太。同时，区块中所有操作所需的 Gas 也会作为奖励给矿工。与比特币不同的是，以太坊中产生叔块的矿工可能会获得叔块奖励，引用叔块的矿工会获得叔块引用奖励</li>
<li>DApp（去中心化应用）：通过智能合约，开发者能够设计想要的逻辑，相当于是网站的后端。而 DApp 则相当于是一个完整的网站（前端+后端），因此 DApp = 智能合约 + Web 前端。以太坊提供了一个名为 web3.js 的 Javascript 库，通过 web3.js 可以实现 Web 与以太坊区块链的交互和与智能合约的交互，方便开发者创建 DApp</li>
</ul>
<h2 id="2-2、以太坊基础"><a href="#2-2、以太坊基础" class="headerlink" title="2.2、以太坊基础"></a>2.2、以太坊基础</h2><h3 id="2-2-1、以太坊中的货币"><a href="#2-2-1、以太坊中的货币" class="headerlink" title="2.2.1、以太坊中的货币"></a>2.2.1、以太坊中的货币</h3><p>以太坊中的货币称为 <strong>以太币</strong>，单位为<strong>以太（Ether）</strong>，也称 ETH 或符号 Ξ。以太可以被分割为更小的单位，最小的单位是 wei，1 以太 =  $10^18$  wei。以太币各单位的名称及之间的关系如下表：</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image-20210219000835894.png">
</center>





<h3 id="2-2-2、以太坊钱包"><a href="#2-2-2、以太坊钱包" class="headerlink" title="2.2.2、以太坊钱包"></a>2.2.2、以太坊钱包</h3><p>以太坊钱包是用于创建和广播交易的应用程序，常用的钱包有</p>
<ul>
<li>MetaMask，一款基于浏览器扩展的钱包，可以很方便地添加到 Chrome, FireFox 等支持扩展的浏览器中</li>
<li>Jaxx，一款跨平台、多币种的钱包</li>
<li>MyEtherWallet(MEW)，一款基于 Web 的钱包，可以在任何浏览器中运行</li>
<li>Emerald Wallet，一款被设计来用于以太坊经典区块链的钱包，但也与其他以太坊区块链兼容</li>
</ul>
<h4 id="MetaMask-基础"><a href="#MetaMask-基础" class="headerlink" title="MetaMask 基础"></a>MetaMask 基础</h4><p>以 Chrome 为例，访问 <a href="https://chrome.google.com/webstore/category/extensions" target="_blank" rel="noopener">Google 网上应用商店</a>，搜索 MetaMask 并添加至 Chrome</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image-20210219101124978.png">
</center>


<p>添加完成后 Chrome 会自动打开初始化页面</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image-20210219101226095.png">
</center>



<p>初次使用创建钱包</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image-20210219101300792.png">
</center>



<p>为钱包设置密码</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image-20210219101332089.png">
</center>




<p>创建密码后，MetaMask 会生成一串密语，密语是12个随机的英文单词，用于防止密码忘记。密语可以直接当成密码使用，因此需要妥善保管</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image-20210219102028033.png">
</center>



<p>注册完毕后就可以在 Chrome 地址栏右边的扩展程序栏点击 🦊 图标使用 MetaMask 了</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image-20210219102255927.png">
</center>

<center class="half">
    <img src="\Pic\Blockchain_Pic\image-20210219102322360.png">
</center>

<h4 id="获取测试以太"><a href="#获取测试以太" class="headerlink" title="获取测试以太"></a>获取测试以太</h4><p>除了以太坊主网以外，以太坊还提供了 Ropsten, Kovan, Rinkeby, Goerli 这几个公共测试网络，另外还支持局域网测试网络和自建测试网络。在这里我们切换到 Ropsten 测试网络</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image-20210219105616335.png">
</center>




<p>随后点击 <strong>Buy</strong> 按钮，点击<strong>测试水管</strong>下方的获取以太</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image-20210219105824087.png">
</center>




<p>在打开的页面中点击 request 1 ether from faucet 就可以得到1个测试以太，当然，可以多次点击。</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image-20210219105911910.png">
</center>


<center class="half">
    <img src="\Pic\Blockchain_Pic\2021-02-19_110327.png">
</center>


<p>测试以太仅供测试使用，除此之外没有任何价值，测试完毕后剩下的以太可以发送到水龙头账户捐赠给水龙头，以供他人测试使用。</p>
<h2 id="2-3、以太坊交易的数据结构"><a href="#2-3、以太坊交易的数据结构" class="headerlink" title="2.3、以太坊交易的数据结构"></a>2.3、以太坊交易的数据结构</h2><p>在以太坊网络中，交易执行属于一个事务。具有原子性、一致性、隔离性、持久性特点。</p>
<ul>
<li>原子性： 是不可分割的最小执行单位，要么做，要么不做。</li>
<li>一致性： 同一笔交易执行，必然是将以太坊账本从一个一致性状态变到另一个一致性状态。</li>
<li>隔离性： 交易执行途中不会受其他交易干扰。</li>
<li>持久性： 一旦交易提交，则对以太坊账本的改变是永久性的。后续的操作不会对其有任何影响。</li>
</ul>
<p>以太坊交易的本质是由外部拥有的账户发起的签名消息，由以太坊网络传输，并被序列化后记录在以太坊区块链上，<strong>交易是唯一可以触发状态更改或导致合约在EVM中执行的事物</strong></p>
<h3 id="2-3-1、交易的数据结构"><a href="#2-3-1、交易的数据结构" class="headerlink" title="2.3.1、交易的数据结构"></a>2.3.1、交易的数据结构</h3><p>以太坊的数据结构主要可以分为四部分：<code>nonce</code>、<code>gas</code>、交易目标和消息（主要部分）、交易签名</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\transaction-struct.png">
</center>



<p>开头是一个 uint64 类型的数字，称之为随机数。用于撤销交易、防止双花和修改以太坊账户的 Nonce 值。</p>
<p>第二部分是关于交易执行限制的设置，gas 为愿意供以太坊虚拟机运行的燃料上限。 <code>gasPrice</code> 是愿意支付的燃料单价。<code>gasPrcie * gas</code> 则为愿意为这笔交易支付的最高手续费。</p>
<p>第三部分是交易发送者输入以太坊虚拟机执行此交易的初始信息： 虚拟机操作对象（接收方 To）、从交易发送方转移到操作对象的资产（Value），以及虚拟机运行时入参(input)。其中 To 为空时，意味着虚拟机无可操作对象，<strong>此时虚拟机将利用 input 内容部署一个新合约</strong>。</p>
<p>第四部分是交易发送方对交易的签名结果，可以利用交易内容和签名结果反向推导出签名者，即交易发送方地址。以上总结如下：</p>
<ul>
<li><code>nonce</code>：由发起人EOA发出的序列号，用于防止交易消息重播。</li>
<li><code>gas price</code>：交易发起人愿意支付的gas单价（wei）。</li>
<li><code>start gas</code>：交易发起人愿意支付的最大gas量。</li>
<li><code>to</code>：目的以太坊地址。</li>
<li><code>value</code>：要发送到目的地的以太数量。</li>
<li><code>data</code>：可变长度二进制数据负载（payload）。</li>
<li><code>v,r,s</code>：发起人EOA的ECDSA签名的三个组成部分。</li>
<li>交易消息的结构使用递归长度前缀（RLP）编码方案进行序列化，该方案专为在以太坊中准确和字节完美的数据序列化而创建。</li>
</ul>
<h3 id="2-3-2、交易中的nonce"><a href="#2-3-2、交易中的nonce" class="headerlink" title="2.3.2、交易中的nonce"></a>2.3.2、交易中的<code>nonce</code></h3><p>按以太坊黄皮书的定义， <code>nonce</code>是一个标量值，它等于从这个地址发送的交易数，或者对于关联code的帐户来说，是这个帐户创建合约的数量。因此<code>nonce</code>便有以下特征：</p>
<ul>
<li><code>nonce</code>不会明确存储为区块链中帐户状态的一部分。相反，它是通过计算发送地址的已确认交易的数量来动态计算的。</li>
<li><code>nonce</code>值还用于防止错误计算账户余额。<code>nonce</code>强制来自任何地址的交易按顺序处理，没有间隔，无论节点接收它们的顺序如何。</li>
<li>使用<code>nonce</code>确保所有节点计算相同的余额和正确的序列交易，等同于用于防止比特币“双重支付”（“重放攻击”）的机制。但是，由于以太坊跟踪账户余额并且不单独跟踪 <code>UTXO</code> ，因此只有在错误地计算账户余额时才会发生“双重支付”。<code>nonce</code>机制可以防止这种情况发生。</li>
</ul>
<h3 id="2-3-3、并发和nonce"><a href="#2-3-3、并发和nonce" class="headerlink" title="2.3.3、并发和nonce"></a>2.3.3、并发和<code>nonce</code></h3><p>以太坊是一个允许操作（节点，客户端，DApps）并发的系统，但强制执行单例状态。例如，出块的时候只有一个系统状态。假如我们有多个独立的钱包应用或客户端，比如 MetaMask 和 Geth，它们可以使用相同的地址生成交易。如果我们希望它们都够同时发送交易，该怎么设置交易的<code>nonce</code>呢？一般有以下两种做法：</p>
<ul>
<li>用一台服务器为各个应用分配<code>nonce</code>，先来先服务——可能出现单点故障，并且失败的交易会将后续交易阻塞。</li>
<li>生成交易后不分配<code>nonce</code>，也不签名，而是把它放入一个队列等待。另起一个节点跟踪<code>nonce</code>并签名交易。同样会有单点故障的可能，而且跟踪<code>nonce</code>和签名的节点是无法实现真正并发的。</li>
</ul>
<h3 id="2-3-4、交易中的gas"><a href="#2-3-4、交易中的gas" class="headerlink" title="2.3.4、交易中的gas"></a>2.3.4、交易中的<code>gas</code></h3><p>Gas 中译是：瓦斯、汽油，代表一种可燃气体。 这形象地比喻以太坊的交易手续费计算模式，不同于比特币中<strong>直接</strong>支付比特币作为转账手续费， 以太坊视为一个去中心化的计算网络，当你发送Token、执行合约、转移以太币或者在此区块上干其他的时候，计算机在处理这笔交易时需要进行计算消耗网络资源，这样你必须支付燃油费购买燃料才能让计算机为你工作。最终燃料费作为手续费支付给矿工。</p>
<blockquote>
<p>注：可以在Etherscan上查询gas price与confirmation time的关系，如下图</p>
</blockquote>
<center class="half">
    <img src="\Pic\Blockchain_Pic\gas.jpg">
</center>


<p>因为手续费等于<code>gasPrice * gasUsed</code>，用户在转账，特别是执行智能合约时 gasUsed 无法提前预知。 这样存在一个风险，当用户的交易涉及一个恶意的智能合约，该合约执行将消耗无限的燃料， 这样会导致交易方的余额全部消耗（恶意的智能合约有可能是程序Bug，如合约执行陷入一个死循环）。</p>
<p>为了避免合约中的错误引起不可预计的燃料消耗，用户需要在发送交易时设定允许消耗的燃料上限，即 gasLimit。 这样不管合约是否良好，最坏情况也只是消耗 gasLimit 量的燃料。</p>
<p>然而，一笔交易所必须支付的燃料已经在区块中通过该交易已执行的计算量记录。 如果你不想支出太多燃料，而故意设置过低的 gasLimit 是没太多帮助的。 你必须支付足够燃料来支付本交易所必要的计算资源。如果交易尚未执行完成，而燃料已用完， 将出现一个 <code>Out of Gas</code> 的错误。特别注意的是，即使交易失败，你也必须为已占用的计算资源所支付手续费。 比如，你通过合约给 TFBOYS 投票，设置 gasPrice=2 gwei，gasLimit=40000（实现投票需要40001的燃料开销）， 最终你投票失败且仍然需要支付 40000*2 gwei= 80000 gwei= 0.00008 ETH。</p>
<p>另外，如果最终 gasUsed 低于 gasLimit，即燃料未用完。则剩余燃料(gasLimit - gasUsed )将在交易后退还给你。 比如你发送 1 Ether 到另一个账户B，设置 gas limit 为 400000，将有 400000 - 21000 返回给你。</p>
<blockquote>
<p>注意：21000 是标准转账交易的gasUsed。因此一笔标准的转账交易你可以设置 gasLimit 为21000</p>
</blockquote>
<h2 id="2-4、以太坊账户"><a href="#2-4、以太坊账户" class="headerlink" title="2.4、以太坊账户"></a>2.4、以太坊账户</h2><p>对比比特币的UTXO余额模型，以太坊使用“账户”余额模型。 以太坊丰富了账户内容，除余额外还能自定义存放任意多数据。 并利用账户数据的可维护性，构建智能合约账户。下面我们首先将比特币的UTXO余额模型与以太坊账户进行比较，说明其各自的优缺点以及适用性。</p>
<h3 id="2-4-1、比特币UTXO和以太坊账户结构比较"><a href="#2-4-1、比特币UTXO和以太坊账户结构比较" class="headerlink" title="2.4.1、比特币UTXO和以太坊账户结构比较"></a>2.4.1、比特币UTXO和以太坊账户结构比较</h3><p>在当前的区块链项目中，主要有两种记录保存方式，<strong>一种是账户/余额模型，一种是UTXO模型</strong>。比特币采用就是UTXO模型，以太坊、EOS等则采用的是账户/余额模型。</p>
<p><img src="\Pic/utxo_com.jpg" style="zoom:67%;"></p>
<h3 id="2-4-2、比特币UTXO"><a href="#2-4-2、比特币UTXO" class="headerlink" title="2.4.2、比特币UTXO"></a>2.4.2、比特币UTXO</h3><p>UTXO是 Unspent Transaction Output的缩写，意思是<strong>未花费的输出，</strong>可以简单理解为还没有用掉的收款。比如韩梅梅收到一笔比特币，她没有用掉，这笔比特币对她来说就是一个UTXO。关于UTXO的具体介绍大家可以查看<a href="https://zhuanlan.zhihu.com/p/74050135" target="_blank" rel="noopener">这篇文章</a>。</p>
<p><strong>UTXO 核心设计思路是：它记录交易事件，而不记录最终状态。</strong>要计算某个用户有多少比特币，就要对其钱包里所有的UTXO求和，得到结果就是他的持币数量。UTXO模型在转账交易时，是以UTXO为单位的，也就是说在支付时，调用的是整数倍UTXO，比如1个UTXO，3个UTXO，没有0.5个UTXO的说法。</p>
<ul>
<li>比特币在基于UTXO的结构中存储有关用户余额的数据，系统的整个状态就是一组UTXO的集合，每个UTXO都有一个所有者和一个面值（就像不同的硬币），而交易会花费若干个输入的UTXO，并根据规则创建若干个新的UTXO</li>
<li>每个引用的输入必须有效并且尚未花费，对于一个交易，必须包含有每个输入的所有者匹配的签名，总输入必须大于等于总输出值。所以系统中用户的余额是用户具有私钥的UTXO的总值</li>
</ul>
<h3 id="2-4-3、以太坊账户"><a href="#2-4-3、以太坊账户" class="headerlink" title="2.4.3、以太坊账户"></a>2.4.3、以太坊账户</h3><p>为什么以太坊不用UTXO呢？显然是因为麻烦，以太坊的做法更符合直觉，以太坊中的状态就是系统中所有账户的列表，每个账户都包含了一个余额和以太坊<strong>特殊定义的数据</strong>（代码和内部存储）。如果发送账户有足够多的余额来进行支付，则交易有效，在这种情况下发送账户先扣款，而收款账户将记入这笔收入。<strong>如果接受账户有相关代码，则代码会自动运行，并且它的内部存储也可能被更改，或者代码还可能向其他账户发送额外的消息，这就会导致进一步的借贷资金关系。</strong></p>
<h3 id="2-4-4、优缺点比较"><a href="#2-4-4、优缺点比较" class="headerlink" title="2.4.4、优缺点比较"></a>2.4.4、优缺点比较</h3><p><strong>比特币UTXO的优点</strong>：</p>
<ul>
<li>更高程度的隐私：如果用户为他们收到的每笔交易使用新地址，那么通常很难将账户互相链接。这很大程度上适用于货币，但不太适用于任何dapps，因为dapps通常涉及跟踪和用户绑定的复杂状态，可能不存在像货币那样简单的用户状态划分方案</li>
<li>潜在的可扩展性：UTXO在理论上更符合可扩展性要求，因为我们只需要依赖拥有UTXO的那些人去维护基于Merkle树的所有权证明就够了，即使包括所有者在内的每个人都决定忘记该数据，那么也只有所有者受到对应的UTXO的损失，不影响接下来的交易。而在账户模式中，如果每个人都丢失了与账户相对应的Merkle树的部分，那将会使得和该账户有关的消息完全无法处理，包括发币给它。</li>
</ul>
<p><strong>以太坊账户模式的优点</strong>：</p>
<ul>
<li>可以节省大量空间：不将UTXOs分开存储，而是合成一个账户；每个交易只需要一个输入、一个签名并产生一个输出</li>
<li>更好的可替代性：货币本质上都是同质化、可替代的；UTXO的设计使得货币从来源分成了“可花费”和“不可花费”两类，这在实际应用中很难有对应模型</li>
<li>更加简单：更容易编码和理解，特别是设计复杂脚本的时候，UTXO的脚本逻辑复杂时更令人费解</li>
<li>便于维护持久轻节点：只要沿着特定方向扫描状态树，轻节点 可以很容易地随时访问账户相关的所有数据。而UTXO地每个交易都会使得状态引用发生改变，这对应节点来说长时间运行Dapp会有很大压力</li>
</ul>
<h3 id="2-4-5、总结"><a href="#2-4-5、总结" class="headerlink" title="2.4.5、总结"></a>2.4.5、总结</h3><div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>BitCoin</th>
<th>Ethereum</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>设计定位</strong></td>
<td>现金系统</td>
<td>去中心化应用平台</td>
</tr>
<tr>
<td><strong>数据组成</strong></td>
<td>交易列表（账本）</td>
<td>交易和账户状态</td>
</tr>
<tr>
<td><strong>交易对象</strong></td>
<td>UTXO</td>
<td>Accounts</td>
</tr>
<tr>
<td><strong>代码控制</strong></td>
<td>脚本</td>
<td>智能合约</td>
</tr>
</tbody>
</table>
</div>
<h2 id="2-5、以太坊账户类型"><a href="#2-5、以太坊账户类型" class="headerlink" title="2.5、以太坊账户类型"></a>2.5、以太坊账户类型</h2><p>以太坊作为智能合约操作平台，将账户划分为两类：外部账户（EOAs）和合约账户（contract account），下面分别做简要介绍：</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\EOA_CA.png">
</center>



<h3 id="2-5-1、外部账户（EOA）"><a href="#2-5-1、外部账户（EOA）" class="headerlink" title="2.5.1、外部账户（EOA）"></a>2.5.1、外部账户（EOA）</h3><p>外部账户是由人来控制的，也就是常规理解的普通账户，外部账户包含以太币余额，主要作用就是发送交易（是广义的交易，包括转币和触发合约代码），是由用户私钥控制的，没有关联代码，所有在以太坊上交易的发起者都是外部账户。</p>
<p>外部账户特点总结：</p>
<ol>
<li>拥有以太余额。</li>
<li>能发送交易，包括转账和执行合约代码。</li>
<li>被私钥控制。</li>
<li>没有相关的可执行代码。</li>
</ol>
<h3 id="2-5-2、合约账户（CA）"><a href="#2-5-2、合约账户（CA）" class="headerlink" title="2.5.2、合约账户（CA）"></a>2.5.2、合约账户（CA）</h3><p>合约账户有时也叫内部账户，有对应的以太币余额和关联代码，它是由代码控制的，可以通过交易或来自其他合约的调用消息来触发代码执行，执行代码时可以操作自己的存储空间，也可以调用其他合约</p>
<p>合约账户特点总结：</p>
<ol>
<li>拥有以太余额。</li>
<li>有相关的可执行代码（合约代码）。</li>
<li>合约代码能够被交易或者其他合约消息调用。</li>
<li>合约代码被执行时可再调用其他合约代码。</li>
<li>合约代码被执行时可执行复杂运算，可永久地改变合约内部的数据存储。</li>
</ol>
<p>如果大家对概念还理解不深可以先尝试学习后面部分，本教程内容有限，推荐大家有精力阅读以下读物：</p>
<ul>
<li><a href="https://www.zhihu.com/question/61156867" target="_blank" rel="noopener">区块链学习的书籍</a></li>
<li><a href="https://www.ruanyifeng.com/blog/2017/12/blockchain-tutorial.html" target="_blank" rel="noopener">区块链入门教程</a></li>
<li><a href="https://developer.ibm.com/zh/technologies/blockchain/tutorials/" target="_blank" rel="noopener">IBM教程</a></li>
</ul>
<p><strong>参考自：</strong></p>
<ol>
<li>[比特币白皮书]<a href="https://www.8btc.com/wiki/bitcoin-a-peer-to-peer-electronic-cash-system" target="_blank" rel="noopener">https://www.8btc.com/wiki/bitcoin-a-peer-to-peer-electronic-cash-system</a>)</li>
<li><a href="https://ethfans.org/posts/ethereum-whitepaper" target="_blank" rel="noopener">以太坊白皮书</a></li>
<li><a href="https://www.chainnode.com/doc/399" target="_blank" rel="noopener">超级账本白皮书</a></li>
<li><a href="https://www.chainnode.com/doc/399" target="_blank" rel="noopener">闪电网络白皮书</a></li>
</ol>
]]></content>
      <categories>
        <category>Blockchain</category>
      </categories>
  </entry>
  <entry>
    <title>区块链入门（一）Linux基础</title>
    <url>/posts/cf0a3f0.html</url>
    <content><![CDATA[<h1 id="新手建议"><a href="#新手建议" class="headerlink" title="新手建议"></a>新手建议</h1><h2 id="学习Linux的注意事项"><a href="#学习Linux的注意事项" class="headerlink" title="学习Linux的注意事项"></a>学习Linux的注意事项</h2><ul>
<li><p>Linux严格区分大小写（命令全都是小写）—— 命令、文件名、选项等均区分大小写</p>
</li>
<li><p>Linux中<strong>所有内容</strong>以文件形式保存，包括硬件</p>
<ul>
<li>硬盘文件是/dev/sd[a-p]</li>
<li>光盘文件是/dev/sr0等</li>
</ul>
</li>
<li><p>Windows通过扩展名区分文件类型，还有图标可以区分；Linux不靠扩展名区分文件类型，靠文件权限区分，但也有一些约定俗成的扩展名：</p>
<ul>
<li>压缩包：”<em>.gz”, “</em>.bz2”, “<em>.tar.bz2”, “</em>.tgz”等</li>
<li>二进制软件包：”.rpm”</li>
<li>网页文件：”*.sh”</li>
<li>配置文件：”*.conf”</li>
</ul>
<p>注意：这些扩展名不是必要的，即时不加扩展名也没有影响，只是便于管理而已</p>
</li>
<li><p>Linux所有存储设备都必须挂在之后用户才能使用，包括硬盘、U盘、光盘（将设备与挂载点连接的过程就是挂载）</p>
</li>
<li><p>Windows下的程序不能直接在Linux中安装和运行</p>
</li>
</ul>
<h2 id="服务器管理和维护建议"><a href="#服务器管理和维护建议" class="headerlink" title="服务器管理和维护建议"></a>服务器管理和维护建议</h2><h3 id="服务器管理"><a href="#服务器管理" class="headerlink" title="服务器管理"></a>服务器管理</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">目录名</th>
<th style="text-align:center">目录作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">/bin/</td>
<td style="text-align:center">存放系统命令的目录，普通用户和超级用户都可以执行，不过放在/bin下的命令在单用户模式下也可以执行</td>
</tr>
<tr>
<td style="text-align:center">/sbin/</td>
<td style="text-align:center">保存和系统环境设置相关的命令，只有超级用户可以使用这些命令进行系统环境设置，但是有些命令可以允许普通用户查看</td>
</tr>
<tr>
<td style="text-align:center">/usr/bin/</td>
<td style="text-align:center">存放系统命令的目录，普通用户和超级用户都可以执行，这些命令和系统启动无关，在单用户模式下不能执行</td>
</tr>
<tr>
<td style="text-align:center">/usr/sbin/</td>
<td style="text-align:center">存放根文件系统不必要的系统管理命令，例如多数服务程序。只有超级用户可以使用</td>
</tr>
<tr>
<td style="text-align:center">/boot/</td>
<td style="text-align:center">系统启动目录，保存系统启动相关的文件，如内核文件和启动引导程序（grub）文件等</td>
</tr>
<tr>
<td style="text-align:center">/dev/</td>
<td style="text-align:center">设备文件保存位置，我们已经说过Linux中所有内容以文件形式保存，包括硬件，这个目录就是用来 保存所有硬件设备的</td>
</tr>
<tr>
<td style="text-align:center">/etc/</td>
<td style="text-align:center">配置文件保存位置，系统内所有采用默认安装方式（npm安装）的服务的配置文件全部保存在这个目录中，如用户账户和密码，服务的启动脚本，常用服务的配置文件等</td>
</tr>
<tr>
<td style="text-align:center">/home/</td>
<td style="text-align:center">每个用户的默认登陆位置，普通用户的home目录就是在/home下建立一个和用户名相同的目录</td>
</tr>
<tr>
<td style="text-align:center">/lib/</td>
<td style="text-align:center">系统调用的函数库保存位置</td>
</tr>
<tr>
<td style="text-align:center">/lost+found/</td>
<td style="text-align:center">当系统意外崩溃或机器意外关机时，产生的一些文件碎片放在这里，当系统启动的过程中fsck工具会对其进行检查，并修复已经损坏的文件系统。这个目录只在每个分区中出现，例如/lost+found就是根分区的备份恢复目录，/boot/lost+found就是/boot分区的备份恢复目录</td>
</tr>
<tr>
<td style="text-align:center">/media/</td>
<td style="text-align:center">挂载目录，系统建议是用来挂载媒体设备的，例如软盘和光盘</td>
</tr>
<tr>
<td style="text-align:center">/mnt/</td>
<td style="text-align:center">挂载目录，建议挂载额外设备，如U盘，移动硬盘和其他操作系统的分区</td>
</tr>
<tr>
<td style="text-align:center">/misc/</td>
<td style="text-align:center">挂载目录，系统建议用来挂载NFS服务的共享目录</td>
</tr>
<tr>
<td style="text-align:center">/opt/</td>
<td style="text-align:center">第三方安装的软件保存位置，但现在更多的是保存在/usr/local中</td>
</tr>
<tr>
<td style="text-align:center">/proc/</td>
<td style="text-align:center">虚拟文件系统，该目录的数据不保存到硬盘中，而是保存到内存中。主要保存系统的内核、进程、外部设备状态和网络状态灯，如/proc/cpuinfo是保存CPU信息的，/proc/devices是保存设备驱动的列表的，/proc/filesystems是保存 文件系统列表的，/proc/net/是保存网络协议信息的</td>
</tr>
<tr>
<td style="text-align:center">/sys/</td>
<td style="text-align:center">虚拟文件系统，主要保存内核相关信息</td>
</tr>
<tr>
<td style="text-align:center">/root/</td>
<td style="text-align:center">超级用户的家目录</td>
</tr>
<tr>
<td style="text-align:center">/srv/</td>
<td style="text-align:center">服务数据目录， 一些系统服务启动后可以在这个目录保存需要的数据</td>
</tr>
<tr>
<td style="text-align:center">/tmp/</td>
<td style="text-align:center">临时目录，系统存放临时文件的目录，该目录下所有用户都可以访问和写入，我们建议此目录不能保存重要数据，最好每次开机都把该目录清空</td>
</tr>
<tr>
<td style="text-align:center">/usr/</td>
<td style="text-align:center">系统软件资源目录，注意usr不是user的缩写，而是”Unix Software Resource”的缩写，所以不是存放用户数据，而是存放系统软件资源的目录。系统中安装的软件大多数都在这里</td>
</tr>
<tr>
<td style="text-align:center">/var/</td>
<td style="text-align:center">动态数据保存位置，主要保存缓存、日志以及软件运行所产生的文件</td>
</tr>
</tbody>
</table>
</div>
<h3 id="服务器注意事项"><a href="#服务器注意事项" class="headerlink" title="服务器注意事项"></a>服务器注意事项</h3><ol>
<li>远程服务器不允许关机，只能重启</li>
<li>重启时应该关闭服务</li>
<li>不要在服务器的访问高峰运行高负载命令</li>
<li>远程配置防火墙时不要把自己踢出服务器（可以设置每五分钟将防火墙规则重置一次，配置完之后再取消该设置）</li>
<li>指定合理的密码规范并定期更新</li>
<li>合理分配权限</li>
<li>定期备份重要数据和日志</li>
</ol>
<p>磁盘分区是用分区编辑器在磁盘上划分几个逻辑部分，碟片一旦划分成数个分区，不同类的目录和文件 可以存储进不同的分区。</p>
<h1 id="系统分区"><a href="#系统分区" class="headerlink" title="系统分区"></a>系统分区</h1><h2 id="分区类型"><a href="#分区类型" class="headerlink" title="分区类型"></a>分区类型</h2><ul>
<li>主分区：最多只能有4个</li>
<li>扩展分区：<ul>
<li>最多只能有1个</li>
<li>主分区加扩展分区最多有4个</li>
<li>不能写入数据，只能包含逻辑分区（这种限制是硬盘的限制）</li>
</ul>
</li>
<li>逻辑分区</li>
</ul>
<h2 id="格式化"><a href="#格式化" class="headerlink" title="格式化"></a>格式化</h2><p>硬盘经过正确分区后仍不能写入数据，我们的硬盘还必须经过格式化之后才能写入数据。格式化又称逻辑格式化，它是根据用户选定的文件系统（如FAT16、FAT32、NTFS、EXT 2、EXT3、EXT4等），在磁盘的特定区域写入特定数据，在分区中划分出一片用于存放文件分配表、目录表等用于文件管理的磁盘空间。格式化就是按照文件系统的规则将硬盘分成等大小的数据块，我们把数据块称为block。</p>
<blockquote>
<p>注：Windows可以识别的系统有FAT16、FAT32、NTFS；Linux可以识别的系统有EXT2、EXT3、EXT4</p>
</blockquote>
<h2 id="设备文件名"><a href="#设备文件名" class="headerlink" title="设备文件名"></a>设备文件名</h2><h4 id="硬盘设备文件名"><a href="#硬盘设备文件名" class="headerlink" title="硬盘设备文件名"></a>硬盘设备文件名</h4><p>Windows是直接分区——&gt;格式化——&gt;分配盘符即可使用，Linux需要分区——&gt;格式化——&gt;给分区建立设备文件名——&gt;分配盘符才能使用。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>硬件</th>
<th>设备文件名</th>
</tr>
</thead>
<tbody>
<tr>
<td>IDE硬盘</td>
<td>/dev/hd[a-d]</td>
</tr>
<tr>
<td>SCSI/SATA/USB硬盘</td>
<td>/dev/sd[a-p]</td>
</tr>
<tr>
<td>光驱</td>
<td>/dev/cdrom或dev/sr0</td>
</tr>
<tr>
<td>软盘</td>
<td>/dev/fd[0-1]</td>
</tr>
<tr>
<td>打印机（25针）</td>
<td>/dev/lp[0-2]</td>
</tr>
<tr>
<td>打印机（USB）</td>
<td>/dev/usb/lp[0-15]</td>
</tr>
<tr>
<td>鼠标</td>
<td>/dev/mouse</td>
</tr>
</tbody>
</table>
</div>
<h4 id="分区设备文件名"><a href="#分区设备文件名" class="headerlink" title="分区设备文件名"></a>分区设备文件名</h4><p>分区设备文件名直接<strong>在硬盘设备文件名后面加分区号</strong>即可，如</p>
<ul>
<li>IDE硬盘接口第一个分区：/dev/hda1（如今几乎看不到）</li>
<li>SCSI硬盘接口、SATA硬盘接口的第一个分区：/dev/sda1</li>
</ul>
<blockquote>
<p>IDE硬盘是最古老的硬盘，理论最高传输速度是133M/s</p>
<p>SCSI硬盘接口与IDE硬盘同时代，更加昂贵但速度更快，理论最高传输速度可达200M/s，但这种硬盘主要用在服务器上</p>
<p>但上两种硬盘接口如今已经基本淘汰，如今使用更多的是小口的SATA串口硬盘，SATA已发展到3代，其理论传输速度最高可达500M/s，目前不管是服务器还是个人机基本使用的都是SATA硬盘接口。</p>
</blockquote>
<p>需要留意的是，逻辑分区永远都是从5开始的</p>
<h2 id="挂载"><a href="#挂载" class="headerlink" title="挂载"></a>挂载</h2><p>挂载实际上就是Windows中分配盘符的过程，盘符则被相应地称为挂载点，必须分区的分区有以下两种：</p>
<ol>
<li>根分区：/</li>
<li>swap分区（交换分区）：可以理解为虚拟内存，当真正内存不够用时，可以使用这部分交换分区的硬盘空间来当内存，理论上来说交换分区应该是内存的两倍，但最大不超过2GB</li>
</ol>
<p>若无这两个分区，Linux不能正常使用，但我们还推荐把/boot单独分区，这是为了防止Linux系统启动不起来，一般200MB即可。</p>
<h1 id="远程登陆管理工具"><a href="#远程登陆管理工具" class="headerlink" title="远程登陆管理工具"></a>远程登陆管理工具</h1><h2 id="网络连接"><a href="#网络连接" class="headerlink" title="网络连接"></a>网络连接</h2><p>网络连接从虚拟机设置中可以看到，一共有三种：桥接、NAT和Host-only，下面讲解其区别：</p>
<ul>
<li>桥接：桥接意味着虚拟机如同一个单独的主机一样访问Wifi等，也可以和其他机器通信</li>
<li>NAT：虚拟机仅能和主机通信，但若主机可以访问互联网，虚拟机也可以访问互联网</li>
<li>Host-only：虚拟机仅能和主机本机通信，不能访问互联网</li>
</ul>
<h2 id="网络配置"><a href="#网络配置" class="headerlink" title="网络配置"></a>网络配置</h2><ol>
<li>首先调成Host-only模式，使得虚拟机仅与主机连接</li>
<li>在主机上找到VMware Network Adapter VMnet1的IP地址，我本地地址为192.168.19.1</li>
<li>在虚拟机上使用<code>ishw -c netwowrk</code>命令找到logical name，此即为虚拟机的网卡名称，我的虚拟网卡名称为ens33</li>
<li>使用命令ifconfig  [不等于IP地址]  logical name，例如我使用的是<code>ifconfig ens33 192.168.19.2</code></li>
<li>此时再ifconfig即可看到我们设置的已生效</li>
<li>我们可以在主机ping这个IP地址看到生效</li>
<li>使用secureCRT连接即可</li>
</ol>
<p>需要注意的是，以上方法配置IP地址时不是永久生效的，也就是重新启动电脑时就失效了，若想永久生效需要改变配置文件</p>
<p>若使用NAT模式，则步骤简单很多，只需要ifconfig获得IP地址之后直接用secureCRT连接即可</p>
<h2 id="WinSCP"><a href="#WinSCP" class="headerlink" title="WinSCP"></a>WinSCP</h2><p>另外推荐一个Windows主机与Linux虚拟机进行文件传输的工具——WinSCP，操作方法与上面类似，只需输入对应的IP地址即可连接。</p>
<h2 id="安装linux系统（以ubuntu为例）"><a href="#安装linux系统（以ubuntu为例）" class="headerlink" title="安装linux系统（以ubuntu为例）"></a>安装linux系统（以ubuntu为例）</h2><ul>
<li><p>使用vmware虚拟机安装</p>
<p><a href="https://zhuanlan.zhihu.com/p/38797088" target="_blank" rel="noopener">参考此博客：VMware安装Ubuntu18.04</a></p>
</li>
<li><p>使用win10子系统安装</p>
<p><a href="https://zhuanlan.zhihu.com/p/76032647" target="_blank" rel="noopener">参考此博客：在 win10 下使用 ubuntu 子系统</a></p>
</li>
</ul>
<h1 id="Linux常用命令"><a href="#Linux常用命令" class="headerlink" title="Linux常用命令"></a>Linux常用命令</h1><h2 id="一、最常用命令"><a href="#一、最常用命令" class="headerlink" title="一、最常用命令"></a>一、最常用命令</h2><p>这是我们<strong>使用得最多</strong>的命令了，<strong>Linux最基础的命令</strong>！</p>
<ul>
<li>可用 <code>pwd</code>命令查看用户的当前目录</li>
<li>可用 <code>cd</code> 命令来切换目录</li>
<li><code>.</code>表示当前目录</li>
<li><code>..</code> 表示当前目录的上一级目录（父目录）</li>
<li><code>-</code>表示用 cd 命令切换目录<strong>前</strong>所在的目录</li>
<li><code>~</code> 表示<strong>用户主目录</strong>的绝对路径名</li>
</ul>
<p><strong>绝对路径：</strong></p>
<ul>
<li>以斜线（/）开头 ，描述到文件位置的<strong>完整说明</strong> ，任何时候你想指定文件名的时候都可以使用</li>
</ul>
<p><strong>相对路径 ：</strong></p>
<ul>
<li>不以斜线（/）开头 ，指定<strong>相对于你的当前工作目录而言的位置</strong> ，可以被用作指定文件名的简捷方式</li>
</ul>
<h2 id="二、文件处理命令"><a href="#二、文件处理命令" class="headerlink" title="二、文件处理命令"></a>二、文件处理命令</h2><h3 id="1-命令格式与目录处理命令ls"><a href="#1-命令格式与目录处理命令ls" class="headerlink" title="1. 命令格式与目录处理命令ls"></a>1. 命令格式与目录处理命令<code>ls</code></h3><p><strong>命令格式</strong>：<code>命令[-选项][-参数]</code>，例：<code>ls -la /etc</code></p>
<p><strong>说明</strong>：</p>
<ol>
<li>个别命令使用不遵循此格式</li>
<li>当有多个选项时，可以写在一起</li>
<li>简化选项与完整选项：<code>-a</code> 等于 <code>--all</code></li>
</ol>
<p><code>ls</code>命令的语法：</p>
<ol>
<li><p><code>ls -a</code>可以显示所有文件，包括隐藏文件（以点.开头的文件是隐藏文件）</p>
</li>
<li><p>若希望查询的不是当前目录，可以使用<code>ls+其他目录</code>进行查询</p>
</li>
<li><p><code>ls -l</code>可以显示更多属性（long），属性阐述如下：</p>
</li>
<li><p>第一列分为三个部分，第一部分（如d告诉我们文件的类型是一个目录，-为二进制文件，1为软链接文件），drwx表示该文件支持读写和执行操作，r,w,x分别对应读、写、执行三个权限，三列分别对应所有者，所属组，其他人的权限</p>
</li>
<li><p>第二列的2、2、3等表示调用次数</p>
<ol>
<li>第三列表示所有者，也就是这个文件的总负责人（拥有文件的所有权，可转让）</li>
</ol>
</li>
<li>第四列表示所属组，也就是可以操作这个文件的人<ol>
<li>第五列表示文件大小，默认单位是字节（很反Windows）</li>
</ol>
</li>
<li><p>最后一个是文件的最后一次修改时间（Linux没有创建时间这个概念）</p>
</li>
<li><p><code>ls -lh</code>比原先的更人性化（humanitarian），它将对应的单位也显示了出来，<code>-h</code>实际上是一个通用选项，很多命令都可以加</p>
</li>
<li><p><code>-d</code>显示当前目录本身而不显示目录下的数据，一般与<code>-l</code>结合使用，如<code>ls -ld /etc</code></p>
</li>
<li><p><code>ls -id</code>可以查看当前目录对应的文件ID</p>
</li>
</ol>
<h3 id="2-目录处理命令"><a href="#2-目录处理命令" class="headerlink" title="2. 目录处理命令"></a>2. 目录处理命令</h3><h5 id="mkdir"><a href="#mkdir" class="headerlink" title="mkdir"></a><code>mkdir</code></h5><p><strong>语法</strong>：<code>mkdir -p [目录名]</code></p>
<p><strong>功能描述</strong>：创建新目录，<code>-p</code>递归创建（若一个目录本身不存在，可以在创建这个目录的同时创建子目录），也可以同时创建多个目录</p>
<h5 id="cd"><a href="#cd" class="headerlink" title="cd"></a><code>cd</code></h5><p><strong>语法</strong>：<code>cd directory</code></p>
<p><strong>功能描述</strong>：改变当前目录</p>
<h5 id="pwd"><a href="#pwd" class="headerlink" title="pwd"></a><code>pwd</code></h5><p><strong>语法</strong>：<code>pwd</code></p>
<p><strong>功能描述</strong>：显示当前目录（print working directory）</p>
<h5 id="rmdir"><a href="#rmdir" class="headerlink" title="rmdir"></a><code>rmdir</code></h5><p><strong>语法</strong>：<code>rmdir [目录名]</code></p>
<p><strong>功能描述</strong>：删除空目录（若目录非空则不能删除）</p>
<h5 id="cp"><a href="#cp" class="headerlink" title="cp"></a><code>cp</code></h5><p><strong>语法</strong>：<code>cp -rf [源文件或目录] [目标目录] -r 复制目录 -p 保留文件属性（文件创建时间等不发生变化）</code></p>
<p><strong>功能描述</strong>：复制文件或目录</p>
<h5 id="mv"><a href="#mv" class="headerlink" title="mv"></a><code>mv</code></h5><p><strong>语法</strong>：<code>mv [源文件或目录] [目标目录]</code></p>
<p><strong>功能描述</strong>：剪切文件、改名</p>
<h5 id="rm"><a href="#rm" class="headerlink" title="rm"></a><code>rm</code></h5><p><strong>语法</strong>：<code>rm -rf [文件或目录] -r 删除目录 -f 强制执行</code></p>
<p><strong>功能描述</strong>：删除文件</p>
<h3 id="3-文件处理命令"><a href="#3-文件处理命令" class="headerlink" title="3. 文件处理命令"></a>3. 文件处理命令</h3><h5 id="touch"><a href="#touch" class="headerlink" title="touch"></a><code>touch</code></h5><p><strong>语法</strong>：<code>touch [文件名]</code></p>
<p><strong>功能描述</strong>：创建空文件</p>
<h5 id="cat"><a href="#cat" class="headerlink" title="cat"></a><code>cat</code></h5><p><strong>语法</strong>：<code>cat [文件名]</code></p>
<p><strong>功能描述</strong>：显示文件内容  <code>-n</code>可显示行号</p>
<h5 id="tac"><a href="#tac" class="headerlink" title="tac"></a><code>tac</code></h5><p>与<code>cat</code>相反，可以倒着显示</p>
<h5 id="more"><a href="#more" class="headerlink" title="more"></a><code>more</code></h5><p><code>cat</code>命令显示的往往过多，若希望分页显示可以使用<code>more</code>，用法与<code>cat</code>相同，使用时按空格可以一页页往后翻，使用q或Q退出</p>
<h5 id="less"><a href="#less" class="headerlink" title="less"></a><code>less</code></h5><p>由于<code>more</code>无法向上翻，我们可以使用<code>less</code>命令，可以使用page up一页页往上翻，也可以使用上箭头一行行往上翻，其他操作与<code>more</code>相同。另外<code>less</code>还可以进行搜索，比如想要搜索关键词service，可以输入/service进行检索，页面会对这些关键词进行高亮，可以使用<code>n</code>找到其他关键词位置</p>
<h5 id="head"><a href="#head" class="headerlink" title="head"></a><code>head</code></h5><p>若只想要看文件的前几行，可以使用<code>head -n</code>加指定行数，若不加则默认显示前10行</p>
<h5 id="tail"><a href="#tail" class="headerlink" title="tail"></a><code>tail</code></h5><p>与<code>head</code>类似 ，但是显示后面几行。</p>
<p>常用搭配为：<code>tail -f</code>，该命令会动态显示文件末尾内容</p>
<h2 id="三、链接命令ln"><a href="#三、链接命令ln" class="headerlink" title="三、链接命令ln"></a>三、链接命令<code>ln</code></h2><p><strong>语法</strong>：<code>ln -s [原文件] [目标文件] -s 创建软链接</code></p>
<p><strong>功能描述</strong>：生成链接文件</p>
<p><strong>示例</strong>：</p>
<ul>
<li><code>ln -s /etc/issue issue.soft</code>：生成软链接</li>
<li><code>ln /etc/issue issue.hard</code>：生成硬链接</li>
</ul>
<p><strong>软链接和硬链接的区别</strong></p>
<p>我们使用<code>ls -l</code>查看这两个文件的信息：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-rw-r--r-- 2 root root 26 Jul 15  2020 issue.hard</span><br><span class="line">lrwxrwxrwx 1 root root 10 Jan 31 04:55 issue.soft -&gt; &#x2F;etc&#x2F;issue</span><br></pre></td></tr></table></figure>
<p>我们会发现这两个文件的信息相差的非常多，软链接文件开头的文件类型是<code>l(link)</code>，三个权限都是<code>rwx</code>，即可读可写可执行，软链接文件就类似于Windows的快捷方式，用处是便于做管理，我们可以看到最后有一个箭头指向<code>/etc/issue</code>。另外我们看到这个文件只有31个字节，因为它只是一个符号链接。我们可以总结得出软链接的三个特点：</p>
<ol>
<li>权限是<code>rwx</code></li>
<li>文件很小，只是符号链接</li>
<li>箭头指向源文件</li>
</ol>
<p>下面我们看硬链接的特点，我们首先分别查看 这两个文件的信息：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls -l issue.hard</span><br><span class="line">ls -l &#x2F;etc&#x2F;issue</span><br></pre></td></tr></table></figure>
<p>我们可以看到这两个文件的所有信息一模一样，包括文件的大小，这类似于拷贝，似乎相当于<code>cp -p</code>，而硬链接和<code>cp -p</code>的最大不同就是硬链接可以实现同步更新，我们可以做一个简单的实验，我们先查看硬链接文件，然后往源文件中写入文件，可以发现硬链接文件也被同时修改了，当然软链接也会同步修改。</p>
<p>但当我们将源文件复制到另一个位置并删除原位置文件之后，再试图打开软链接会提示“没有那个文件或目录”，而且再显示这个目录软链接会标红并一直闪，而硬链接可以正常访问，没有影响，这就是硬链接和软连接的不同之处。</p>
<p>实际上我们可以通过命令<code>ls -i</code>来识别其<code>i</code>节点以辨别出是硬链接还是软链接，硬链接和源文件的<code>i</code>节点相同，软链接则不同。</p>
<p>硬链接相当于一个同步文件，但可以做实时备份（一个文件删了不会影响另一个文件），硬链接有两个限制，这也是硬链接和软链接的区别：</p>
<ol>
<li>不能跨分区</li>
<li>不能针对目录使用</li>
</ol>
<h2 id="四、权限管理命令"><a href="#四、权限管理命令" class="headerlink" title="四、权限管理命令"></a>四、权限管理命令</h2><p>Linux用户一共分成三类，分别是所有者（U），所属组（G）和其他人（O），权限也分成三类，分别是<code>r</code>，<code>w</code>，<code>x</code>，对应读、写、执行，我们首先学习如何更改权限。</p>
<h4 id="chmod"><a href="#chmod" class="headerlink" title="chmod"></a><code>chmod</code></h4><p>更改文件的人只能是文件所有者或者管理员root用户，更改文件权限有两种方式，第一种方式如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod [&#123;ugoa&#125;&#123;+-&#x3D;&#125;&#123;rwx&#125;][文件或目录]</span><br></pre></td></tr></table></figure>
<p>其中第一个花括号里<code>u</code>，<code>g</code>，<code>o</code>，<code>a</code>分别表示所有者，所属组，其他人和所有人，第二个花括号<code>+</code>和<code>-</code>分别表示增加和减少权限，<code>=</code>表示成为后面的权限。第二种方式如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod [mod&#x3D;421][文件或目录] -R 递归修改</span><br></pre></td></tr></table></figure>
<p>数字的意思只是将三个权限位分别用数字来表示，比如<code>r</code>用4表示，<code>w</code>用2表示，<code>x</code>用1表示，则若要表示<code>rwxrw-r--</code>则记为<code>764</code></p>
<h4 id="chown"><a href="#chown" class="headerlink" title="chown"></a><code>chown</code></h4><p>命令英文原意是<code>change file ownership</code>，作用是改变文件或目录的所有者，改变文件file的所有者为user的具体用法为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chown user file</span><br></pre></td></tr></table></figure>
<p>要注意只有root和文件的所有者可以改变文件的权限</p>
<h4 id="chgrp"><a href="#chgrp" class="headerlink" title="chgrp"></a><code>chgrp</code></h4><p>命令英文原意是<code>change file  group ownership</code>，作用是改变文件或目录的所属组，若具体用法和前面<code>chown</code>相同。我们可以使用<code>groupadd</code>命令添加组（使用<code>useradd</code>命令添加用户）</p>
<h4 id="umask"><a href="#umask" class="headerlink" title="umask"></a><code>umask</code></h4><p>命令英文原意是<code>the user file-creation mask</code>，作用是显示、设置文件的缺省权限，语法是：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">umask [-S]</span><br></pre></td></tr></table></figure>
<p>其中<code>-S</code>的作用是显示新建文件的缺省权限，但需要注意的是缺省创建文件时不可以有可执行权限的，所以当<code>touch</code>创建文件时会发现所有权限都少了<code>x</code>。</p>
<p>当我们直接使用<code>umask</code>时，比如显示0022，第一个0是特殊权限，我们暂时不涉及，第二只第四位分别是所有者、所属组和其他人，我们的最终权限实际上是<code>777-022=755</code>，也就是<code>rwx r-x r-x</code>，当然这指的是目录，如果是文件由于没有可执行权限，文件权限应当是<code>rw- r-- r--</code>，当然缺省创建的权限可以更改，直接使用<code>umask 077</code>即可将文件缺省权限更改为<code>rwx --- ---</code>，但不推荐做这种更改</p>
]]></content>
      <categories>
        <category>Blockchain</category>
      </categories>
  </entry>
  <entry>
    <title>资金流入流出预测比赛（五）</title>
    <url>/posts/fe59ede.html</url>
    <content><![CDATA[<p>本文涉及内容为时间序列规则，参考链接为<a href="https://github.com/datawhalechina/team-learning-data-mining/tree/master/PurchaseAndRedemptionForecast" target="_blank" rel="noopener">Datawhale 资金流入流出学习内容</a></p>
<h1 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> sklearn <span class="keyword">as</span> skr</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> dateutil.relativedelta <span class="keyword">import</span> relativedelta</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPRegressor</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br><span class="line">np.random.seed(<span class="number">1024</span>)</span><br><span class="line"></span><br><span class="line">labels = [<span class="string">'total_purchase_amt'</span>, <span class="string">'total_redeem_amt'</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 分割数据集</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_data_underline</span><span class="params">(data: pd.DataFrame)</span>-&gt;pd.DataFrame:</span></span><br><span class="line">    trainset = data[(datetime.date(<span class="number">2014</span>,<span class="number">4</span>,<span class="number">1</span>) &lt;= data[<span class="string">'date'</span>]) &amp; (data[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>,<span class="number">8</span>,<span class="number">1</span>))]</span><br><span class="line">    testset = data[(datetime.date(<span class="number">2014</span>,<span class="number">8</span>,<span class="number">1</span>) &lt;= data[<span class="string">'date'</span>]) &amp; (data[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>,<span class="number">9</span>,<span class="number">1</span>))]</span><br><span class="line">    <span class="keyword">return</span> trainset, testset</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_data_online</span><span class="params">(data: pd.DataFrame)</span>-&gt;pd.DataFrame:</span></span><br><span class="line">    trainset = data[(datetime.date(<span class="number">2014</span>,<span class="number">4</span>,<span class="number">1</span>) &lt;= data[<span class="string">'date'</span>]) &amp; (data[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>,<span class="number">9</span>,<span class="number">1</span>))]</span><br><span class="line">    testset = data[(datetime.date(<span class="number">2014</span>,<span class="number">9</span>,<span class="number">1</span>) &lt;= data[<span class="string">'date'</span>]) &amp; (data[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>,<span class="number">10</span>,<span class="number">1</span>))]</span><br><span class="line">    <span class="keyword">return</span> trainset, testset</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义评价函数</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">AE</span><span class="params">(y: Iterable, yhat: Iterable)</span>-&gt;Iterable:</span></span><br><span class="line">    <span class="keyword">return</span> np.abs(y - yhat) / np.abs(y)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">total_AE</span><span class="params">(purchasehat: Iterable, redeemhat: Iterable, purchase: Iterable, redeem: Iterable, h: int = <span class="number">0.3</span>)</span>-&gt;Iterable:</span></span><br><span class="line">    <span class="keyword">return</span> sum(map(<span class="keyword">lambda</span> x : np.exp(-x/h)*<span class="number">10</span>, AE(purchase, purchasehat))) * <span class="number">0.45</span> + sum(map(<span class="keyword">lambda</span> x : np.exp(-x/h)*<span class="number">10</span>, AE(redeem, redeemhat))) * <span class="number">0.55</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在不同的时间段对模型进行验证</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">week_evalution_single</span><span class="params">(data: pd.DataFrame, model: object, types: str)</span>-&gt;pd.DataFrame:</span></span><br><span class="line">    results = []</span><br><span class="line">    a_month = relativedelta(months=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> [datetime.date(<span class="number">2014</span>, <span class="number">8</span>, <span class="number">1</span>), datetime.date(<span class="number">2014</span>, <span class="number">7</span>, <span class="number">25</span>), datetime.date(<span class="number">2014</span>, <span class="number">7</span>, <span class="number">18</span>), datetime.date(<span class="number">2014</span>, <span class="number">7</span>, <span class="number">11</span>), </span><br><span class="line">          datetime.date(<span class="number">2014</span>, <span class="number">7</span>, <span class="number">4</span>), datetime.date(<span class="number">2014</span>, <span class="number">6</span>, <span class="number">27</span>), datetime.date(<span class="number">2014</span>, <span class="number">6</span>,<span class="number">20</span>)]:</span><br><span class="line">        trainset = data[(i - <span class="number">4</span> * a_month &lt;= data[<span class="string">'date'</span>]) &amp; (data[<span class="string">'date'</span>] &lt; i)]</span><br><span class="line">        testset = data[(i &lt;= data[<span class="string">'date'</span>]) &amp; (data[<span class="string">'date'</span>] &lt; i + a_month)]</span><br><span class="line">        <span class="keyword">if</span> len(testset) == <span class="number">0</span> <span class="keyword">or</span> len(trainset) == <span class="number">0</span>:</span><br><span class="line">            i = datetime.date(<span class="number">2014</span>, <span class="number">4</span>, <span class="number">20</span>)</span><br><span class="line">            trainset = data[(i - <span class="number">4</span> * a_month &lt;= data[<span class="string">'date'</span>]) &amp; (data[<span class="string">'date'</span>] &lt; i)]</span><br><span class="line">            testset = data[(i &lt;= data[<span class="string">'date'</span>]) &amp; (data[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>, <span class="number">9</span>, <span class="number">1</span>))]</span><br><span class="line">        feature = [x <span class="keyword">for</span> x <span class="keyword">in</span> trainset.columns <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>,<span class="string">'date'</span>]]</span><br><span class="line">        </span><br><span class="line">        model.fit(X=trainset[feature], y=trainset[<span class="string">'total_'</span> + types + <span class="string">'_amt'</span>])</span><br><span class="line">        result_lr = model.predict(testset[feature])</span><br><span class="line">        </span><br><span class="line">        h = <span class="number">0.3</span></span><br><span class="line">        results.append(sum(AE(testset[<span class="string">'total_'</span> + types + <span class="string">'_amt'</span>], result_lr).apply(<span class="keyword">lambda</span> x : np.exp(-x/h))*<span class="number">10</span>))</span><br><span class="line">    <span class="keyword">return</span> pd.DataFrame(results)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 输出评级表格</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw_eva_table</span><span class="params">(df: pd.DataFrame)</span>-&gt;pd.DataFrame:</span></span><br><span class="line">    rest = df.copy()</span><br><span class="line">    rest[<span class="string">'interval'</span>] = [datetime.date(<span class="number">2014</span>, <span class="number">8</span>, <span class="number">1</span>), datetime.date(<span class="number">2014</span>, <span class="number">7</span>, <span class="number">25</span>), datetime.date(<span class="number">2014</span>, <span class="number">7</span>, <span class="number">18</span>), datetime.date(<span class="number">2014</span>, <span class="number">7</span>, <span class="number">11</span>), </span><br><span class="line">          datetime.date(<span class="number">2014</span>, <span class="number">7</span>, <span class="number">4</span>), datetime.date(<span class="number">2014</span>, <span class="number">6</span>, <span class="number">27</span>), datetime.date(<span class="number">2014</span>, <span class="number">6</span>,<span class="number">20</span>)]</span><br><span class="line">    <span class="keyword">return</span> rest</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对生成结果进行可视化</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">visual</span><span class="params">(result_purchase_lr: Iterable, result_redeem_lr: Iterable, testset: pd.DataFrame)</span>-&gt;<span class="keyword">None</span>:</span></span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">10</span>,<span class="number">4</span>))</span><br><span class="line">    plt.plot(testset[<span class="string">'date'</span>], result_purchase_lr, label=<span class="string">'predicted_purchase'</span>)</span><br><span class="line">    plt.plot(testset[<span class="string">'date'</span>], testset[<span class="string">'total_purchase_amt'</span>], label=<span class="string">'real_redeem'</span>)</span><br><span class="line"></span><br><span class="line">    plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">    plt.title(<span class="string">"The distribution of real and predict purchase"</span>)</span><br><span class="line">    plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">    plt.ylabel(<span class="string">"Amount"</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">10</span>,<span class="number">4</span>))</span><br><span class="line">    sns.barplot(testset[<span class="string">'date'</span>].dt.day ,result_purchase_lr - testset[<span class="string">'total_purchase_amt'</span>])</span><br><span class="line"></span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">10</span>,<span class="number">4</span>))</span><br><span class="line">    plt.plot(testset[<span class="string">'date'</span>], result_redeem_lr, label=<span class="string">'predicted_redeem'</span>)</span><br><span class="line">    plt.plot(testset[<span class="string">'date'</span>], testset[<span class="string">'total_redeem_amt'</span>], label=<span class="string">'real_redeem'</span>)</span><br><span class="line"></span><br><span class="line">    plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">    plt.title(<span class="string">"The distribution of real and predict redeem"</span>)</span><br><span class="line">    plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">    plt.ylabel(<span class="string">"Amount"</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">10</span>,<span class="number">4</span>))</span><br><span class="line">    sns.barplot(testset[<span class="string">'date'</span>].dt.day ,result_redeem_lr - testset[<span class="string">'total_redeem_amt'</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义提取线下最好效果特征的函数</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">feature_extract</span><span class="params">(data: pd.DataFrame, model: object, types: str)</span>-&gt;Tuple[List[str], List[float]]:</span></span><br><span class="line">    features = [x <span class="keyword">for</span> x <span class="keyword">in</span> data.columns <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> labels + [<span class="string">'date'</span>]]</span><br><span class="line">    random.shuffle(features)</span><br><span class="line">    results = []</span><br><span class="line">    score = <span class="number">-1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> features:</span><br><span class="line">        score_update = np.mean(week_evalution_single(data[results + [i] + labels + [<span class="string">'date'</span>]], model, types))</span><br><span class="line">        <span class="keyword">if</span> score_update &gt; score:</span><br><span class="line">            score = score_update</span><br><span class="line">            results.append(i)</span><br><span class="line">    <span class="keyword">return</span> results, score</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">robust_feature_extract</span><span class="params">(data: pd.DataFrame, model: object, types: str)</span>:</span></span><br><span class="line">    results = []</span><br><span class="line">    score = <span class="number">-1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        results_update, score_update = feature_extract(data, model, types)</span><br><span class="line">        <span class="keyword">if</span> score_update &gt; score:</span><br><span class="line">            score = score_update</span><br><span class="line">            results = results_update</span><br><span class="line">        print(results_update, score_update)</span><br><span class="line">    <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义AIC,BIC评价指标</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">AIC</span><span class="params">(L: Iterable, delta: float, n_features: int)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> L * np.log10(delta) + <span class="number">2</span> * (n_features + <span class="number">1</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">AIC</span><span class="params">(L: Iterable, delta: float, n_features: int)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> L * np.log10(delta) + (n_features + <span class="number">1</span>) * np.log10(L)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用AIC指标融合模型</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">feature_extract_AIC</span><span class="params">(data: pd.DataFrame, model: object, types: str)</span>-&gt;Tuple[List[str], float]:</span></span><br><span class="line">    features = [x <span class="keyword">for</span> x <span class="keyword">in</span> data.columns <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> labels + [<span class="string">'date'</span>]]</span><br><span class="line">    random.shuffle(features)</span><br><span class="line">    results = []</span><br><span class="line">    test_score = <span class="number">1e9</span></span><br><span class="line">    train_score = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> features:</span><br><span class="line">        test_score_update = np.mean(week_evalution_single(data[results + [i] + labels + [<span class="string">'date'</span>]], model, types)[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">if</span> test_score_update &lt; test_score:</span><br><span class="line">            test_score = test_score_update</span><br><span class="line">            results.append(i)</span><br><span class="line">            </span><br><span class="line">    trainset, testset = split_data_underline(data)</span><br><span class="line">    feature = results</span><br><span class="line">    model.fit(X=trainset[feature], y=trainset[<span class="string">'total_'</span> + types + <span class="string">'_amt'</span>])</span><br><span class="line">    train_result_lr = model.predict(trainset[feature])</span><br><span class="line">    delta = mean_squared_error(train_result_lr, trainset[<span class="string">'total_'</span> + types + <span class="string">'_amt'</span>])</span><br><span class="line">    <span class="comment">#delta = np.sum(AE(trainset['total_' + types + '_amt'], train_result_lr).apply(lambda x : np.exp(-x/0.1))*10)</span></span><br><span class="line">    <span class="keyword">return</span> results, AIC(len(trainset), delta, len(feature))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multi_model</span><span class="params">(data: pd.DataFrame, model: object, types: str)</span>-&gt;Tuple[List[List[str]], float]:</span></span><br><span class="line">    features = []</span><br><span class="line">    weights = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">        results_update, score_update = feature_extract_AIC(data, model, types)</span><br><span class="line">        features.append(results_update)</span><br><span class="line">        weights.append(score_update)</span><br><span class="line">    avg = np.mean(weights)</span><br><span class="line">    weights = [x - avg <span class="keyword">for</span> x <span class="keyword">in</span> weights]</span><br><span class="line">    weights = [np.power((<span class="number">-1</span> * x / <span class="number">2</span>), <span class="number">10</span>) <span class="keyword">for</span> x <span class="keyword">in</span> weights]</span><br><span class="line">    summ = np.sum(weights)</span><br><span class="line">    weights = [x / summ <span class="keyword">for</span> x <span class="keyword">in</span> weights]</span><br><span class="line">    <span class="keyword">return</span> features, weights</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生成线上结果</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_online_result</span><span class="params">(df: pd.DataFrame, feature: Iterable, model = LinearRegression<span class="params">()</span>, target:str = <span class="string">'total_purchase_amt'</span>)</span>-&gt;Iterable:</span></span><br><span class="line">    trainset, testset = split_data_online(df)</span><br><span class="line">    model.fit(X=trainset[feature], y=trainset[target])</span><br><span class="line">    result_purchase_lr = model.predict(testset[feature])</span><br><span class="line">    <span class="keyword">return</span> result_purchase_lr</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_under_result</span><span class="params">(df: pd.DataFrame, feature: Iterable, model = LinearRegression<span class="params">()</span>, target:str = <span class="string">'total_purchase_amt'</span>)</span>-&gt;Iterable:</span></span><br><span class="line">    trainset, testset = split_data_underline(df)</span><br><span class="line">    model.fit(X=trainset[feature], y=trainset[target])</span><br><span class="line">    result_purchase_lr = model.predict(testset[feature])</span><br><span class="line">    <span class="keyword">return</span> result_purchase_lr</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生成线上提交的格式</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize_upload_file</span><span class="params">(result_purchase_lr: Iterable, result_redeem_lr: Iterable, testset: pd.DataFrame)</span>-&gt;pd.DataFrame:</span></span><br><span class="line">    testset[<span class="string">'total_purchase_amt'</span>] = result_purchase_lr</span><br><span class="line">    testset[<span class="string">'total_redeem_amt'</span>] = result_redeem_lr</span><br><span class="line">    online_upload = testset[[<span class="string">'date'</span>,<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>]]</span><br><span class="line">    online_upload[<span class="string">'date'</span>] = online_upload[<span class="string">'date'</span>].astype(str)</span><br><span class="line">    online_upload[<span class="string">'date'</span>] = online_upload[<span class="string">'date'</span>].str.replace(<span class="string">'-'</span>,<span class="string">''</span>)</span><br><span class="line">    <span class="keyword">return</span> online_upload</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 线上结果可视化</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw_result</span><span class="params">(result_purchase_lr: Iterable, result_redeem_lr: Iterable, testset: pd.DataFrame)</span>:</span></span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">10</span>,<span class="number">4</span>))</span><br><span class="line">    plt.plot(testset[<span class="string">'date'</span>].dt.day, result_purchase_lr, label=<span class="string">'online_purchase'</span>)</span><br><span class="line">    plt.plot(testset[<span class="string">'date'</span>].dt.day, result_redeem_lr, label=<span class="string">'online_redeem'</span>)</span><br><span class="line"></span><br><span class="line">    plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">    plt.title(<span class="string">"The predict values"</span>)</span><br><span class="line">    plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">    plt.ylabel(<span class="string">"Amount"</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 重载DataFrame加法</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_two_df</span><span class="params">(df1, df2, features = None, left_a = <span class="number">0.45</span>, right_a = <span class="number">0.55</span>)</span>:</span></span><br><span class="line">    data = df1.copy()</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> features:</span><br><span class="line">        features = [x <span class="keyword">for</span> x <span class="keyword">in</span> data.columns <span class="keyword">if</span> x != <span class="string">'interval'</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> features:</span><br><span class="line">        data[i] = (data[i] * left_a + df2[i] * right_a)</span><br><span class="line">    <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 重载DataFrame乘法</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scale_df</span><span class="params">(df1, features = None, eta = <span class="number">1</span>)</span>:</span></span><br><span class="line">    data = df1.copy()</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> features:</span><br><span class="line">        features = [x <span class="keyword">for</span> x <span class="keyword">in</span> data.columns <span class="keyword">if</span> x != <span class="string">'interval'</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> features:</span><br><span class="line">        data[i] *= eta</span><br><span class="line">    <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure>
<h1 id="建模测试"><a href="#建模测试" class="headerlink" title="建模测试"></a>建模测试</h1><h2 id="一、仅使用IS特征"><a href="#一、仅使用IS特征" class="headerlink" title="一、仅使用IS特征"></a>一、仅使用IS特征</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">'Dataset/feature0522.csv'</span>)</span><br><span class="line">data[<span class="string">'date'</span>] = pd.to_datetime(data[<span class="string">'date'</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">trainset, testset = split_data_underline(data)</span><br><span class="line">result_purchase_lr = generate_under_result(data, [x <span class="keyword">for</span> x <span class="keyword">in</span> data.columns <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>,<span class="string">'date'</span>]], target=<span class="string">'total_purchase_amt'</span>)</span><br><span class="line">result_redeem_lr = generate_under_result(data, [x <span class="keyword">for</span> x <span class="keyword">in</span> data.columns <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>,<span class="string">'date'</span>]], target=<span class="string">'total_redeem_amt'</span>)</span><br></pre></td></tr></table></figure>
<h3 id="在八月份预测结果"><a href="#在八月份预测结果" class="headerlink" title="在八月份预测结果"></a>在八月份预测结果</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">total_AE(result_purchase_lr, result_redeem_lr, testset[<span class="string">'total_purchase_amt'</span>], testset[<span class="string">'total_redeem_amt'</span>])</span><br><span class="line"><span class="comment"># 189.31445991054966</span></span><br></pre></td></tr></table></figure>
<h3 id="滑窗测试结果"><a href="#滑窗测试结果" class="headerlink" title="滑窗测试结果"></a>滑窗测试结果</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">draw_eva_table(week_evalution_single(data, model=LinearRegression(), types = <span class="string">'purchase'</span>))</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>interval</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>197.277321</td>
      <td>2014-08-01</td>
    </tr>
    <tr>
      <th>1</th>
      <td>167.809363</td>
      <td>2014-07-25</td>
    </tr>
    <tr>
      <th>2</th>
      <td>162.569572</td>
      <td>2014-07-18</td>
    </tr>
    <tr>
      <th>3</th>
      <td>159.214733</td>
      <td>2014-07-11</td>
    </tr>
    <tr>
      <th>4</th>
      <td>144.062633</td>
      <td>2014-07-04</td>
    </tr>
    <tr>
      <th>5</th>
      <td>142.332339</td>
      <td>2014-06-27</td>
    </tr>
    <tr>
      <th>6</th>
      <td>126.240393</td>
      <td>2014-06-20</td>
    </tr>
  </tbody>
</table>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">draw_eva_table(week_evalution_single(data, LinearRegression(), <span class="string">'redeem'</span>))</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>interval</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>182.799392</td>
      <td>2014-08-01</td>
    </tr>
    <tr>
      <th>1</th>
      <td>172.093440</td>
      <td>2014-07-25</td>
    </tr>
    <tr>
      <th>2</th>
      <td>181.210211</td>
      <td>2014-07-18</td>
    </tr>
    <tr>
      <th>3</th>
      <td>168.488252</td>
      <td>2014-07-11</td>
    </tr>
    <tr>
      <th>4</th>
      <td>175.160622</td>
      <td>2014-07-04</td>
    </tr>
    <tr>
      <th>5</th>
      <td>174.465494</td>
      <td>2014-06-27</td>
    </tr>
    <tr>
      <th>6</th>
      <td>175.201245</td>
      <td>2014-06-20</td>
    </tr>
  </tbody>
</table>
### 八月份预测图与真实图


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">visual(result_purchase_lr, result_redeem_lr, testset)</span><br></pre></td></tr></table></figure>


![png](../Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B%EF%BC%88%E4%BA%94%EF%BC%89/output_26_0.png)

![png](../Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B%EF%BC%88%E4%BA%94%EF%BC%89/output_26_1.png)

![png](../Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B%EF%BC%88%E4%BA%94%EF%BC%89/output_26_2.png)

![png](../Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B%EF%BC%88%E4%BA%94%EF%BC%89/output_26_3.png)

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result_purchase_lr = generate_online_result(data, [x <span class="keyword">for</span> x <span class="keyword">in</span> trainset.columns <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>,<span class="string">'date'</span>]], LinearRegression(),<span class="string">'total_purchase_amt'</span>)</span><br><span class="line">result_redeem_lr = generate_online_result(data, [x <span class="keyword">for</span> x <span class="keyword">in</span> trainset.columns <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>,<span class="string">'date'</span>]], LinearRegression(),<span class="string">'total_redeem_amt'</span>)</span><br></pre></td></tr></table></figure>

### 九月份预测效果图(线性)


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">trainset, testset = split_data_online(data)</span><br><span class="line">draw_result(result_purchase_lr, result_redeem_lr, testset)</span><br></pre></td></tr></table></figure>


![png](../Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B%EF%BC%88%E4%BA%94%EF%BC%89/output_29_0.png)

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">normalize_upload_file(result_purchase_lr, result_redeem_lr, testset).to_csv(<span class="string">'20190612_only_is.csv'</span>,index=<span class="literal">False</span>,header=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

## 二、多模型对比


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multi_model_eva</span><span class="params">(data, types:str = <span class="string">'purchase'</span>)</span>:</span></span><br><span class="line">    results = pd.DataFrame()</span><br><span class="line">    <span class="keyword">for</span> model <span class="keyword">in</span> [LinearRegression(), DecisionTreeRegressor(), RandomForestRegressor(), GradientBoostingRegressor(), MLPRegressor(solver=<span class="string">'lbfgs'</span>), xgb.XGBRegressor(objective=<span class="string">'reg:squarederror'</span>)]:</span><br><span class="line">        <span class="keyword">if</span> results.empty:</span><br><span class="line">            results = draw_eva_table(week_evalution_single(data, model, types)).rename(columns=&#123;<span class="number">0</span>: repr(model).split(<span class="string">'('</span>)[<span class="number">0</span>]&#125;)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            results = pd.merge(results, \</span><br><span class="line">                               draw_eva_table(week_evalution_single(data, model, types)).rename(columns=&#123;<span class="number">0</span>: repr(model).split(<span class="string">'('</span>)[<span class="number">0</span>]&#125;), on=<span class="string">'interval'</span>)</span><br><span class="line">    results = results[[<span class="string">'interval'</span>] + [x <span class="keyword">for</span> x <span class="keyword">in</span> results.columns <span class="keyword">if</span> x != <span class="string">'interval'</span>]]</span><br><span class="line">    <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">add_two_df(multi_model_eva(data, <span class="string">'purchase'</span>), multi_model_eva(data, <span class="string">'redeem'</span>))</span><br></pre></td></tr></table></figure>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>interval</th>
      <th>LinearRegression</th>
      <th>DecisionTreeRegressor</th>
      <th>RandomForestRegressor</th>
      <th>GradientBoostingRegressor</th>
      <th>MLPRegressor</th>
      <th>XGBRegressor</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2014-08-01</td>
      <td>189.314460</td>
      <td>188.743896</td>
      <td>187.715746</td>
      <td>188.808471</td>
      <td>188.744889</td>
      <td>189.283918</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2014-07-25</td>
      <td>170.165605</td>
      <td>171.123954</td>
      <td>172.599158</td>
      <td>171.155189</td>
      <td>169.383859</td>
      <td>171.483486</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2014-07-18</td>
      <td>172.821924</td>
      <td>175.689847</td>
      <td>176.236757</td>
      <td>175.700583</td>
      <td>174.238004</td>
      <td>175.781053</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2014-07-11</td>
      <td>164.315168</td>
      <td>167.489060</td>
      <td>168.552495</td>
      <td>167.497959</td>
      <td>164.755084</td>
      <td>167.463230</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2014-07-04</td>
      <td>161.166527</td>
      <td>164.436476</td>
      <td>163.818487</td>
      <td>164.457772</td>
      <td>162.257028</td>
      <td>164.322969</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2014-06-27</td>
      <td>160.005574</td>
      <td>163.849417</td>
      <td>162.010456</td>
      <td>163.820346</td>
      <td>160.703909</td>
      <td>163.713086</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2014-06-20</td>
      <td>153.168861</td>
      <td>156.563393</td>
      <td>157.063395</td>
      <td>156.511847</td>
      <td>156.539468</td>
      <td>156.445360</td>
    </tr>
  </tbody>
</table>


<h2 id="三、劣汰后特征对比"><a href="#三、劣汰后特征对比" class="headerlink" title="三、劣汰后特征对比"></a>三、劣汰后特征对比</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_purchase = pd.read_csv(<span class="string">'Feature/purchase_feature_droped_0614.csv'</span>)</span><br><span class="line">data_purchase[<span class="string">'date'</span>] = pd.to_datetime(data_purchase[<span class="string">'date'</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_redeem = pd.read_csv(<span class="string">'Feature/redeem_feature_droped_0614.csv'</span>)</span><br><span class="line">data_redeem[<span class="string">'date'</span>] = pd.to_datetime(data_redeem[<span class="string">'date'</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">trainset_purchase, testset_purchase = split_data_underline(data_purchase)</span><br><span class="line">result_purchase_lr = generate_under_result(data_purchase, [x <span class="keyword">for</span> x <span class="keyword">in</span> data_purchase.columns</span><br><span class="line">                                                           <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>,<span class="string">'date'</span>]], </span><br><span class="line">                                           target=<span class="string">'total_purchase_amt'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">trainset_redeem, testset_redeem = split_data_underline(data_redeem)</span><br><span class="line">result_redeem_lr = generate_under_result(data_redeem, [x <span class="keyword">for</span> x <span class="keyword">in</span> data_redeem.columns</span><br><span class="line">                                                           <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>,<span class="string">'date'</span>]], </span><br><span class="line">                                           target=<span class="string">'total_redeem_amt'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">total_AE(result_purchase_lr, result_redeem_lr, testset_purchase[<span class="string">'total_purchase_amt'</span>], testset_redeem[<span class="string">'total_redeem_amt'</span>])</span><br><span class="line"><span class="comment"># 189.90232809854422</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">add_two_df(multi_model_eva(data_purchase, <span class="string">'purchase'</span>), multi_model_eva(data_redeem, <span class="string">'redeem'</span>))</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>interval</th>
      <th>LinearRegression</th>
      <th>DecisionTreeRegressor</th>
      <th>RandomForestRegressor</th>
      <th>GradientBoostingRegressor</th>
      <th>MLPRegressor</th>
      <th>XGBRegressor</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2014-08-01</td>
      <td>189.902328</td>
      <td>167.901814</td>
      <td>170.798802</td>
      <td>177.216664</td>
      <td>186.847975</td>
      <td>178.177163</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2014-07-25</td>
      <td>177.650078</td>
      <td>167.752839</td>
      <td>177.877918</td>
      <td>169.722728</td>
      <td>180.481298</td>
      <td>171.346027</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2014-07-18</td>
      <td>182.113181</td>
      <td>184.259270</td>
      <td>176.164814</td>
      <td>175.773043</td>
      <td>180.043535</td>
      <td>177.470257</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2014-07-11</td>
      <td>182.092305</td>
      <td>178.165773</td>
      <td>184.042765</td>
      <td>178.501400</td>
      <td>179.125274</td>
      <td>181.784144</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2014-07-04</td>
      <td>181.210428</td>
      <td>172.354412</td>
      <td>164.208141</td>
      <td>170.061840</td>
      <td>176.928324</td>
      <td>165.812636</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2014-06-27</td>
      <td>185.309340</td>
      <td>178.630136</td>
      <td>182.713216</td>
      <td>189.882640</td>
      <td>177.631714</td>
      <td>186.246480</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2014-06-20</td>
      <td>169.342125</td>
      <td>168.941842</td>
      <td>173.833505</td>
      <td>173.421845</td>
      <td>169.514554</td>
      <td>172.578523</td>
    </tr>
  </tbody>
</table>


<h3 id="八月份预测效果-线性"><a href="#八月份预测效果-线性" class="headerlink" title="八月份预测效果(线性)"></a>八月份预测效果(线性)</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">trainset, testset = split_data_underline(data)</span><br><span class="line">visual(result_purchase_lr, result_redeem_lr, testset)</span><br></pre></td></tr></table></figure>
<p><img src="/posts/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B%EF%BC%88%E4%BA%94%EF%BC%89/output_43_0.png" alt="png"></p>
<p><img src="/posts/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B%EF%BC%88%E4%BA%94%EF%BC%89/output_43_1.png" alt="png"></p>
<p><img src="/posts/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B%EF%BC%88%E4%BA%94%EF%BC%89/output_43_2.png" alt="png"></p>
<p><img src="/posts/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B%EF%BC%88%E4%BA%94%EF%BC%89/output_43_3.png" alt="output_43_3"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result_purchase_lr = generate_online_result(data_purchase, [x <span class="keyword">for</span> x <span class="keyword">in</span> data_purchase.columns <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>,<span class="string">'date'</span>]], LinearRegression(),<span class="string">'total_purchase_amt'</span>)</span><br><span class="line">result_redeem_lr = generate_online_result(data_redeem, [x <span class="keyword">for</span> x <span class="keyword">in</span> data_redeem.columns <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>,<span class="string">'date'</span>]], LinearRegression(),<span class="string">'total_redeem_amt'</span>)</span><br></pre></td></tr></table></figure>
<h3 id="生成线上效果（线性）"><a href="#生成线上效果（线性）" class="headerlink" title="生成线上效果（线性）"></a>生成线上效果（线性）</h3><p>可以看到28号很高（work in Sunday）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">trainset, testset = split_data_online(data)</span><br><span class="line">draw_result(result_purchase_lr, result_redeem_lr, testset)</span><br></pre></td></tr></table></figure>
<p><img src="/posts/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B%EF%BC%88%E4%BA%94%EF%BC%89/output_46_0.png" alt="png"></p>
<p>purchase feature</p>
<blockquote>
<p>‘dis_to_nowork’, ‘dis_to_work’, ‘dis_from_work’, ‘purchase_weekdayrate’,<br>       ‘redeem_dayrate’, ‘weekday_onehot_5’, ‘weekday_onehot_6’,<br>       ‘dis_from_nowork’, ‘is_holiday’, ‘weekday_onehot_1’, ‘weekday_onehot_2’,<br>       ‘weekday_onehot_0’, ‘dis_from_middleofweek’, ‘dis_from_holiendday’,<br>       ‘weekday_onehot_3’, ‘is_lastday_of_holiday’, ‘is_firstday_of_holiday’,<br>       ‘weekday_onehot_4’, ‘is_worked_yestday’, ‘is_second_week’,<br>       ‘is_third_week’, ‘dis_from_startofmonth’, ‘dis_from_holiday’,<br>       ‘dis_to_nowork%%%%dis_from_purchase_peak’, ‘total_purchase_amt’,<br>       ‘total_redeem_amt’, ‘date’</p>
</blockquote>
<p>Redeem feature</p>
<blockquote>
<p>‘is_work’, ‘dis_from_redeem_valley’, ‘purchase_weekdayrate’,<br>       ‘redeem_dayrate’, ‘weekday_onehot_5’, ‘is_gonna_work_tomorrow’,<br>       ‘is_holiday’, ‘dis_from_nowork’, ‘weekday_onehot_0’, ‘weekday_onehot_1’,<br>       ‘is_firstday_of_holiday’, ‘weekday_onehot_2’, ‘is_lastday_of_holiday’,<br>       ‘dis_from_holiday’, ‘is_work_on_sunday’, ‘is_firstday_of_work’,<br>       ‘is_secday_of_month’, ‘dis_from_holiendday’,<br>       ‘dis_from_redeem_valley%%%%dis_from_redeem_peak’, ‘total_purchase_amt’,<br>       ‘total_redeem_amt’, ‘date’</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">normalize_upload_file(result_purchase_lr, result_redeem_lr, testset).to_csv(<span class="string">'20190614_droped.csv'</span>,index=<span class="literal">False</span>,header=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<h3 id="生成线上效果（MLP）"><a href="#生成线上效果（MLP）" class="headerlink" title="生成线上效果（MLP）"></a>生成线上效果（MLP）</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result_purchase_lr = generate_online_result(data_purchase, [x <span class="keyword">for</span> x <span class="keyword">in</span> data_purchase.columns </span><br><span class="line">                                                            <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>,<span class="string">'date'</span>]], </span><br><span class="line">                                            MLPRegressor(solver=<span class="string">'lbfgs'</span>),<span class="string">'total_purchase_amt'</span>)</span><br><span class="line">result_redeem_lr = generate_online_result(data_redeem, [x <span class="keyword">for</span> x <span class="keyword">in</span> data_redeem.columns </span><br><span class="line">                                                        <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>,<span class="string">'date'</span>]], </span><br><span class="line">                                          MLPRegressor(solver=<span class="string">'lbfgs'</span>),<span class="string">'total_redeem_amt'</span>)</span><br><span class="line">trainset, testset = split_data_online(data)</span><br><span class="line">draw_result(result_purchase_lr, result_redeem_lr, testset)</span><br></pre></td></tr></table></figure>
<p><img src="/posts/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B%EF%BC%88%E4%BA%94%EF%BC%89/output_52_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">normalize_upload_file(result_purchase_lr, result_redeem_lr, testset).to_csv(<span class="string">'20190614_droped_MLP.csv'</span>,index=<span class="literal">False</span>,header=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<h3 id="生成线上效果（Xgboost）"><a href="#生成线上效果（Xgboost）" class="headerlink" title="生成线上效果（Xgboost）"></a>生成线上效果（Xgboost）</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result_purchase_lr = generate_online_result(data_purchase, [x <span class="keyword">for</span> x <span class="keyword">in</span> data_purchase.columns </span><br><span class="line">                                                            <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>,<span class="string">'date'</span>]], </span><br><span class="line">                                            xgb.XGBRegressor(objective=<span class="string">'reg:squarederror'</span>),<span class="string">'total_purchase_amt'</span>)</span><br><span class="line">result_redeem_lr = generate_online_result(data_redeem, [x <span class="keyword">for</span> x <span class="keyword">in</span> data_redeem.columns </span><br><span class="line">                                                        <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>,<span class="string">'date'</span>]], </span><br><span class="line">                                          xgb.XGBRegressor(objective=<span class="string">'reg:squarederror'</span>),<span class="string">'total_redeem_amt'</span>)</span><br><span class="line">trainset, testset = split_data_online(data)</span><br><span class="line">draw_result(result_purchase_lr, result_redeem_lr, testset)</span><br></pre></td></tr></table></figure>
<p><img src="/posts/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B%EF%BC%88%E4%BA%94%EF%BC%89/output_56_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">normalize_upload_file(result_purchase_lr, result_redeem_lr, testset).to_csv(<span class="string">'20190615_droped_XGB.csv'</span>,index=<span class="literal">False</span>,header=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<h2 id="四、AIC模型平均"><a href="#四、AIC模型平均" class="headerlink" title="四、AIC模型平均"></a>四、AIC模型平均</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">purchase_features, purchase_weight = multi_model(data_purchase, model=LinearRegression(), types = <span class="string">'purchase'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">redeem_features, redeem_weight = multi_model(data_redeem, model=LinearRegression(), types = <span class="string">'redeem'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">eva_for_aic</span><span class="params">(data_purchase, purchase_features, purchase_weight)</span>:</span></span><br><span class="line">    results = pd.DataFrame()</span><br><span class="line">    <span class="keyword">for</span> index, feature <span class="keyword">in</span> enumerate(purchase_features):</span><br><span class="line">        <span class="keyword">if</span> results.empty:</span><br><span class="line">            results = scale_df(multi_model_eva(data_purchase[[<span class="string">'date'</span>] + labels + feature], <span class="string">'purchase'</span>), </span><br><span class="line">                               eta = purchase_weight[index])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            results = add_two_df(results, multi_model_eva(data_purchase[[<span class="string">'date'</span>] + labels + feature], <span class="string">'purchase'</span>)</span><br><span class="line">                                 , left_a = <span class="number">1</span>,</span><br><span class="line">                                 right_a = purchase_weight[index])</span><br><span class="line">    <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">add_two_df(eva_for_aic(data_purchase, purchase_features, purchase_weight), </span><br><span class="line">           eva_for_aic(data_redeem, redeem_features, redeem_weight))</span><br></pre></td></tr></table></figure>
<p><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>interval</th>
      <th>LinearRegression</th>
      <th>DecisionTreeRegressor</th>
      <th>RandomForestRegressor</th>
      <th>GradientBoostingRegressor</th>
      <th>MLPRegressor</th>
      <th>XGBRegressor</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2014-08-01</td>
      <td>196.963095</td>
      <td>183.792030</td>
      <td>186.524287</td>
      <td>190.406781</td>
      <td>203.741264</td>
      <td>191.603561</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2014-07-25</td>
      <td>166.890259</td>
      <td>162.282961</td>
      <td>165.155036</td>
      <td>167.600603</td>
      <td>170.796653</td>
      <td>168.847170</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2014-07-18</td>
      <td>164.275651</td>
      <td>164.099009</td>
      <td>165.696601</td>
      <td>165.439729</td>
      <td>166.863106</td>
      <td>166.027208</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2014-07-11</td>
      <td>165.406218</td>
      <td>173.410333</td>
      <td>175.492379</td>
      <td>174.605650</td>
      <td>171.207335</td>
      <td>172.707320</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2014-07-04</td>
      <td>159.754349</td>
      <td>159.385969</td>
      <td>157.523226</td>
      <td>159.920750</td>
      <td>165.437567</td>
      <td>159.528064</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2014-06-27</td>
      <td>170.536885</td>
      <td>170.257129</td>
      <td>172.330545</td>
      <td>172.594357</td>
      <td>173.168680</td>
      <td>172.330513</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2014-06-20</td>
      <td>171.443469</td>
      <td>162.639913</td>
      <td>164.623205</td>
      <td>164.944005</td>
      <td>171.675562</td>
      <td>166.762065</td>
    </tr>
  </tbody>
</table></p>
<h2 id="五、针对残差建模"><a href="#五、针对残差建模" class="headerlink" title="五、针对残差建模"></a>五、针对残差建模</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_purchase = pd.read_csv(<span class="string">'Feature/residual_feature_purchase_0621.csv'</span>)</span><br><span class="line">data_purchase[<span class="string">'date'</span>] = pd.to_datetime(data_purchase[<span class="string">'date'</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_redeem = pd.read_csv(<span class="string">'Feature/residual_feature_redeem_0621.csv'</span>)</span><br><span class="line">data_redeem[<span class="string">'date'</span>] = pd.to_datetime(data_redeem[<span class="string">'date'</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">base = pd.read_csv(<span class="string">'Dataset/base.csv'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_residual_result</span><span class="params">(data, base, model=LinearRegression<span class="params">()</span>, types = <span class="string">'purchase'</span>, split_time = datetime.date<span class="params">(<span class="number">2014</span>,<span class="number">8</span>,<span class="number">1</span>)</span>)</span>:</span></span><br><span class="line">    a_month = relativedelta(months=<span class="number">1</span>)</span><br><span class="line">    trainset = data[(datetime.date(<span class="number">2014</span>,<span class="number">4</span>,<span class="number">1</span>) &lt;= data[<span class="string">'date'</span>]) &amp; (data[<span class="string">'date'</span>] &lt; split_time)]</span><br><span class="line">    testset = data[(split_time &lt;= data[<span class="string">'date'</span>]) &amp; (data[<span class="string">'date'</span>] &lt; split_time + a_month)]</span><br><span class="line">    feature = [x <span class="keyword">for</span> x <span class="keyword">in</span> data_purchase.columns </span><br><span class="line">               <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>,<span class="string">'date'</span>]]</span><br><span class="line">    model.fit(X=trainset[feature], y=trainset[<span class="string">'total_'</span> + types + <span class="string">'_amt'</span>])</span><br><span class="line">    result_purchase_rate = model.predict(testset[feature])</span><br><span class="line">    </span><br><span class="line">    base[<span class="string">'date'</span>] = pd.to_datetime(base[<span class="string">'date'</span>], format= <span class="string">"%Y%m%d"</span>)</span><br><span class="line">    result_purchase_cycle = np.array(base[(base[<span class="string">'date'</span>] &gt;= split_time)</span><br><span class="line">                                          &amp;(base[<span class="string">'date'</span>] &lt; split_time + a_month)][<span class="string">'total_'</span>+types+<span class="string">'_predicted_by_cycle'</span>])</span><br><span class="line">    result_purchase_residual =  result_purchase_rate * np.array(result_purchase_cycle)</span><br><span class="line">    <span class="keyword">return</span> result_purchase_residual</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_evaluate_for_residual</span><span class="params">(model=LinearRegression<span class="params">()</span>)</span>:</span></span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> [datetime.date(<span class="number">2014</span>, <span class="number">8</span>, <span class="number">1</span>), datetime.date(<span class="number">2014</span>, <span class="number">7</span>, <span class="number">25</span>), datetime.date(<span class="number">2014</span>, <span class="number">7</span>, <span class="number">18</span>), datetime.date(<span class="number">2014</span>, <span class="number">7</span>, <span class="number">11</span>), </span><br><span class="line">              datetime.date(<span class="number">2014</span>, <span class="number">7</span>, <span class="number">4</span>), datetime.date(<span class="number">2014</span>, <span class="number">6</span>, <span class="number">27</span>), datetime.date(<span class="number">2014</span>, <span class="number">6</span>,<span class="number">20</span>)]:</span><br><span class="line">        result_purchase_residual = generate_residual_result(data_purchase, base, model=model, types=<span class="string">'purchase'</span>, split_time = i)</span><br><span class="line">        result_redeem_residual = generate_residual_result(data_purchase, base, model=model, types=<span class="string">'redeem'</span>, split_time= i)</span><br><span class="line">        a_month = relativedelta(months=<span class="number">1</span>)</span><br><span class="line">        testset = data[(data[<span class="string">'date'</span>] &gt;= i) &amp; (data[<span class="string">'date'</span>] &lt; i + a_month)]</span><br><span class="line">        real_purchase = testset[<span class="string">'total_purchase_amt'</span>]</span><br><span class="line">        real_redeem = testset[<span class="string">'total_redeem_amt'</span>]</span><br><span class="line">        result.append(total_AE(result_purchase_residual, result_redeem_residual, real_purchase, real_redeem))</span><br><span class="line">    <span class="keyword">return</span> pd.DataFrame(result)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multi_model_eva_for_residual</span><span class="params">()</span>:</span></span><br><span class="line">    results = pd.DataFrame()</span><br><span class="line">    <span class="keyword">for</span> model <span class="keyword">in</span> [LinearRegression(), DecisionTreeRegressor(), RandomForestRegressor(), GradientBoostingRegressor(), MLPRegressor(solver=<span class="string">'lbfgs'</span>), xgb.XGBRegressor(objective=<span class="string">'reg:squarederror'</span>)]:</span><br><span class="line">        <span class="keyword">if</span> results.empty:</span><br><span class="line">            results = draw_eva_table(generate_evaluate_for_residual(model)).rename(columns=&#123;<span class="number">0</span>: repr(model).split(<span class="string">'('</span>)[<span class="number">0</span>]&#125;)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            results = pd.merge(results, \</span><br><span class="line">                               draw_eva_table(generate_evaluate_for_residual(model)).rename(columns=&#123;<span class="number">0</span>: repr(model).split(<span class="string">'('</span>)[<span class="number">0</span>]&#125;))</span><br><span class="line">    results = results[[<span class="string">'interval'</span>] + [x <span class="keyword">for</span> x <span class="keyword">in</span> results.columns <span class="keyword">if</span> x != <span class="string">'interval'</span>]]</span><br><span class="line">    <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_evaluate_for_cycle</span><span class="params">()</span>:</span></span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> [datetime.date(<span class="number">2014</span>, <span class="number">8</span>, <span class="number">1</span>), datetime.date(<span class="number">2014</span>, <span class="number">7</span>, <span class="number">25</span>), datetime.date(<span class="number">2014</span>, <span class="number">7</span>, <span class="number">18</span>), datetime.date(<span class="number">2014</span>, <span class="number">7</span>, <span class="number">11</span>), </span><br><span class="line">                  datetime.date(<span class="number">2014</span>, <span class="number">7</span>, <span class="number">4</span>), datetime.date(<span class="number">2014</span>, <span class="number">6</span>, <span class="number">27</span>), datetime.date(<span class="number">2014</span>, <span class="number">6</span>,<span class="number">20</span>)]:</span><br><span class="line">        a_month = relativedelta(months=<span class="number">1</span>)</span><br><span class="line">        testset = base[(base[<span class="string">'date'</span>] &gt;= i) &amp; (base[<span class="string">'date'</span>] &lt; i + a_month)].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">        result_purchase_residual = testset[<span class="string">'total_purchase_predicted_by_cycle'</span>]</span><br><span class="line">        result_redeem_residual = testset[<span class="string">'total_redeem_predicted_by_cycle'</span>]</span><br><span class="line">        testset = data[(data[<span class="string">'date'</span>] &gt;= i) &amp; (data[<span class="string">'date'</span>] &lt; i + a_month)].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">        real_purchase = testset[<span class="string">'total_purchase_amt'</span>]</span><br><span class="line">        real_redeem = testset[<span class="string">'total_redeem_amt'</span>]</span><br><span class="line">        result.append(total_AE(result_purchase_residual, result_redeem_residual, real_purchase, real_redeem))</span><br><span class="line">    <span class="keyword">return</span> pd.DataFrame(result).rename(columns=&#123;<span class="number">0</span>: <span class="string">'PureTimeSeries'</span>&#125;)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.merge(multi_model_eva_for_residual(), draw_eva_table(generate_evaluate_for_cycle()))</span><br></pre></td></tr></table></figure>
<p><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>interval</th>
      <th>LinearRegression</th>
      <th>DecisionTreeRegressor</th>
      <th>RandomForestRegressor</th>
      <th>GradientBoostingRegressor</th>
      <th>MLPRegressor</th>
      <th>XGBRegressor</th>
      <th>PureTimeSeries</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2014-08-01</td>
      <td>180.766534</td>
      <td>155.580904</td>
      <td>167.712675</td>
      <td>171.177173</td>
      <td>171.180097</td>
      <td>175.335191</td>
      <td>175.933714</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2014-07-25</td>
      <td>161.447048</td>
      <td>159.351623</td>
      <td>161.705225</td>
      <td>162.192265</td>
      <td>158.220680</td>
      <td>163.794727</td>
      <td>155.916275</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2014-07-18</td>
      <td>172.796145</td>
      <td>153.972984</td>
      <td>170.188452</td>
      <td>169.297901</td>
      <td>156.933699</td>
      <td>173.068241</td>
      <td>169.890622</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2014-07-11</td>
      <td>165.437181</td>
      <td>154.819818</td>
      <td>166.759593</td>
      <td>161.607800</td>
      <td>158.148139</td>
      <td>165.108007</td>
      <td>165.668307</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2014-07-04</td>
      <td>150.715908</td>
      <td>140.131046</td>
      <td>148.064148</td>
      <td>147.667609</td>
      <td>148.554344</td>
      <td>151.872781</td>
      <td>155.458113</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2014-06-27</td>
      <td>161.207466</td>
      <td>157.575158</td>
      <td>161.413391</td>
      <td>160.319942</td>
      <td>145.957128</td>
      <td>160.949321</td>
      <td>160.758547</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2014-06-20</td>
      <td>146.011833</td>
      <td>147.507212</td>
      <td>149.043333</td>
      <td>154.453050</td>
      <td>142.023337</td>
      <td>155.435619</td>
      <td>154.336379</td>
    </tr>
  </tbody>
</table></p>
<h3 id="1-只使用周期因子在8月份的预测效果"><a href="#1-只使用周期因子在8月份的预测效果" class="headerlink" title="(1) 只使用周期因子在8月份的预测效果"></a>(1) 只使用周期因子在8月份的预测效果</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">_, testset = split_data_underline(data)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">real_purchase = testset[<span class="string">'total_purchase_amt'</span>]</span><br><span class="line">real_redeem = testset[<span class="string">'total_redeem_amt'</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result_purchase_cycle = np.array(base[(base[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,<span class="number">8</span>,<span class="number">1</span>))&amp;(base[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>,<span class="number">9</span>,<span class="number">1</span>))][<span class="string">'total_purchase_predicted_by_cycle'</span>])</span><br><span class="line">result_redeem_cycle = np.array(base[(base[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,<span class="number">8</span>,<span class="number">1</span>))&amp;(base[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>,<span class="number">9</span>,<span class="number">1</span>))][<span class="string">'total_redeem_predicted_by_cycle'</span>])</span><br><span class="line">total_AE(result_purchase_cycle, result_redeem_cycle, real_purchase, real_redeem)</span><br><span class="line"><span class="comment"># 175.93371418259747</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">trainset, testset = split_data_underline(data)</span><br><span class="line">visual(result_purchase_cycle, result_redeem_cycle, testset)</span><br></pre></td></tr></table></figure>
<p><img src="/posts/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B%EF%BC%88%E4%BA%94%EF%BC%89/output_77_0.png" alt="png"></p>
<p><img src="/posts/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B%EF%BC%88%E4%BA%94%EF%BC%89/output_77_1.png" alt="png"></p>
<p><img src="/posts/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B%EF%BC%88%E4%BA%94%EF%BC%89/output_77_2.png" alt="png"></p>
<p><img src="/posts/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B%EF%BC%88%E4%BA%94%EF%BC%89/output_77_3.png" alt="png"></p>
<h3 id="2-只使用周期因子-预测残差在8月份的预测效果（比单纯用因子好）"><a href="#2-只使用周期因子-预测残差在8月份的预测效果（比单纯用因子好）" class="headerlink" title="(2) 只使用周期因子+预测残差在8月份的预测效果（比单纯用因子好）"></a>(2) 只使用周期因子+预测残差在8月份的预测效果（比单纯用因子好）</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">trainset_purchase, testset_purchase = split_data_underline(data_purchase)</span><br><span class="line">result_purchase_rate = generate_under_result(data_purchase, [x <span class="keyword">for</span> x <span class="keyword">in</span> data_purchase.columns</span><br><span class="line">                                                           <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>,<span class="string">'date'</span>]], </span><br><span class="line">                                           target=<span class="string">'total_purchase_amt'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">trainset_redeem, testset_redeem = split_data_underline(data_redeem)</span><br><span class="line">result_redeem_rate = generate_under_result(data_redeem, [x <span class="keyword">for</span> x <span class="keyword">in</span> data_redeem.columns</span><br><span class="line">                                                           <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>,<span class="string">'date'</span>]], </span><br><span class="line">                                           target=<span class="string">'total_redeem_amt'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">total_AE(result_purchase_rate * result_purchase_cycle, result_redeem_rate * result_redeem_cycle, real_purchase, real_redeem)</span><br><span class="line"><span class="comment"># 182.628220303351</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">trainset, testset = split_data_underline(data)</span><br><span class="line">visual(result_purchase_rate * result_purchase_cycle, result_redeem_rate * result_redeem_cycle, testset)</span><br></pre></td></tr></table></figure>
<p><img src="/posts/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B%EF%BC%88%E4%BA%94%EF%BC%89/output_82_0.png" alt="png"></p>
<p><img src="/posts/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B%EF%BC%88%E4%BA%94%EF%BC%89/output_82_1.png" alt="png"></p>
<p><img src="/posts/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B%EF%BC%88%E4%BA%94%EF%BC%89/output_82_2.png" alt="png"></p>
<p><img src="/posts/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B%EF%BC%88%E4%BA%94%EF%BC%89/output_82_3.png" alt="png"></p>
<h3 id="3-生成线上结果"><a href="#3-生成线上结果" class="headerlink" title="(3) 生成线上结果"></a>(3) 生成线上结果</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">trainset_purchase, testset_purchase = split_data_online(data_purchase)</span><br><span class="line">result_purchase_rate = generate_online_result(data_purchase, [x <span class="keyword">for</span> x <span class="keyword">in</span> data_purchase.columns</span><br><span class="line">                                                           <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>,<span class="string">'date'</span>]], </span><br><span class="line">                                           target=<span class="string">'total_purchase_amt'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">trainset_redeem, testset_redeem = split_data_online(data_redeem)</span><br><span class="line">result_redeem_rate = generate_online_result(data_redeem, [x <span class="keyword">for</span> x <span class="keyword">in</span> data_redeem.columns</span><br><span class="line">                                                           <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'total_purchase_amt'</span>,<span class="string">'total_redeem_amt'</span>,<span class="string">'date'</span>]], </span><br><span class="line">                                           target=<span class="string">'total_redeem_amt'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 修正一下预测结果试试</span></span><br><span class="line">result_purchase_rate = result_purchase_rate / np.mean(result_purchase_rate)</span><br><span class="line">result_redeem_rate = result_redeem_rate / np.mean(result_redeem_rate)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result_purchase_cycle = np.array(base[(base[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,<span class="number">9</span>,<span class="number">1</span>))&amp;(base[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>,<span class="number">10</span>,<span class="number">1</span>))][<span class="string">'total_purchase_predicted_by_cycle'</span>])</span><br><span class="line">result_redeem_cycle = np.array(base[(base[<span class="string">'date'</span>] &gt;= datetime.date(<span class="number">2014</span>,<span class="number">9</span>,<span class="number">1</span>))&amp;(base[<span class="string">'date'</span>] &lt; datetime.date(<span class="number">2014</span>,<span class="number">10</span>,<span class="number">1</span>))][<span class="string">'total_redeem_predicted_by_cycle'</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result_purchase_residual = result_purchase_rate * result_purchase_cycle</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result_redeem_residual = result_redeem_rate * result_redeem_cycle</span><br></pre></td></tr></table></figure>
<h4 id="月份周期因子线上结果（135）"><a href="#月份周期因子线上结果（135）" class="headerlink" title="月份周期因子线上结果（135）"></a>月份周期因子线上结果（135）</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">draw_result(result_purchase_cycle, result_redeem_cycle, testset_redeem)</span><br></pre></td></tr></table></figure>
<p><img src="/posts/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B%EF%BC%88%E4%BA%94%EF%BC%89/output_91_0.png" alt="png"></p>
<h4 id="残差处理后结果"><a href="#残差处理后结果" class="headerlink" title="残差处理后结果"></a>残差处理后结果</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">draw_result(result_purchase_residual, result_redeem_residual, testset_redeem)</span><br></pre></td></tr></table></figure>
<p><img src="/posts/Pic/%E8%B5%84%E9%87%91%E6%B5%81%E5%85%A5%E6%B5%81%E5%87%BA%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B%EF%BC%88%E4%BA%94%EF%BC%89/output_93_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">normalize_upload_file(result_purchase_residual, result_redeem_residual, testset_redeem).to_csv(<span class="string">'20190622_residual_liner.csv'</span>,index=<span class="literal">False</span>,header=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<h4 id="仅用与修正节假日的结果"><a href="#仅用与修正节假日的结果" class="headerlink" title="仅用与修正节假日的结果"></a>仅用与修正节假日的结果</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result_score135 = pd.read_csv(<span class="string">'Result/timeseries0606.csv'</span>,header=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result_residual = normalize_upload_file(result_purchase_residual, result_redeem_residual, testset_redeem).reset_index(drop=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result_residual[<span class="string">'date'</span>] = result_residual[<span class="string">'date'</span>].astype(int)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">days_need_to_change = [</span><br><span class="line">    <span class="number">20140906</span>,</span><br><span class="line">    <span class="number">20140907</span>,</span><br><span class="line">    <span class="number">20140908</span>,</span><br><span class="line">    <span class="number">20140928</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> index,row <span class="keyword">in</span> result_score135.iterrows():</span><br><span class="line">    <span class="keyword">if</span> row[<span class="number">0</span>] <span class="keyword">in</span> days_need_to_change:</span><br><span class="line">        result_score135.loc[index, <span class="number">1</span>] =  result_residual.loc[index, <span class="string">'total_purchase_amt'</span>]</span><br><span class="line">        result_score135.loc[index, <span class="number">2</span>] =   result_residual.loc[index, <span class="string">'total_redeem_amt'</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result_score135.to_csv(<span class="string">'result135_fixed_by_residual_0621.csv'</span>,index=<span class="literal">False</span>,header=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>宏观经济学（一）</title>
    <url>/posts/982364b6.html</url>
    <content><![CDATA[<h1 id="三部门经济"><a href="#三部门经济" class="headerlink" title="三部门经济"></a>三部门经济</h1><p>三部门经济是指包括家庭、企业和政府三个部门的经济。</p>
<p><img src="/posts/Pic/%E5%AE%8F%E8%A7%82%E7%BB%8F%E6%B5%8E%E5%AD%A6%EF%BC%88%E4%B8%80%EF%BC%89/wps1.png" alt="img" style="zoom:67%;"></p>
<h2 id="由家庭到厂商"><a href="#由家庭到厂商" class="headerlink" title="由家庭到厂商"></a>由家庭到厂商</h2><p>任何一个经济系统都包含家庭、企业和政府。经济学研究的是人，人是一种资源，从人口出发，满足其需求，参与就业获得收入不断循环就组成宏观经济学研究的内容。家庭是人、土地、矿产等资源的拥有者，但家庭若不与外界发生交换则无利可图（没有分工），因此家庭需要与厂商结合，以家庭为基础发展起过渡型的初级业态就产生了最初级的厂商。厂商从家庭产生之后从家庭中抽离出来得到了与家庭形成了新的循环。</p>
<p>劳动市场的要素就是资源，由资本市场人才市场土地市场等构成，家庭为要素市场提供生产要素，厂商组织资源，因此需要从要素市场购买生产要素，将生产出来的产品投入商品市场售卖，家庭则从商品市场购买厂商生产出的产品。家庭与厂商之间的供给需求关系不断互换。</p>
<h2 id="由厂商到政府"><a href="#由厂商到政府" class="headerlink" title="由厂商到政府"></a>由厂商到政府</h2><p>当原来的生产关系发展到一定程度后，政府随之出现，开始建立公共服务，政府的收入来源是家庭与厂商，家庭与厂商为政府提供税收，同时政府会对厂商投资，政府也会为家庭提供转移支付。</p>
<p>最合理的情况是，当厂商停产半停产，失业人口增加时，政府采取干预，使用财政政策与货币政策等调节通货膨胀、经济衰退、本币贬值、国际收支不平衡等问题。当厂商与家庭正常循环时政府不会出手干预。</p>
<p>政府在经济中的作用主要是通过政府的收入和支出体现的。政府税收主要包括两类，一类是直接税，这种税是对财产和收入征收的税，比如个人所得税、财产税、人头税等。另一种是间接税，这种税是对商品和劳务所征收的税，比如商品税、营业税、进口税等。政府支出包括政府对商品和劳务的购买与转移性支付。转移性支付属于政府福利支出，这种支出把一部分购买力无偿地转移给有困难的或合乎某种特殊规定的个人，比如，政府把钱支付给退伍军人、残疾人、困难户、失业者等都是转移支付。许多发展中国家政府支出中还包括投资。</p>
<p>三部门经济要正常循环，除保证商品市场、金融市场和要素市场均衡外还必须保证政府收支平衡，即政府收支大体相等。</p>
<h1 id="最终产品的去向"><a href="#最终产品的去向" class="headerlink" title="最终产品的去向"></a>最终产品的去向</h1><p>最终产品的去向根据不同需求者分为四类：</p>
<ul>
<li>普通消费者（家庭部门）所需的，称为消费品；</li>
<li>企业所需的，称为投资品；</li>
<li>政府所需的，称为政府购买品；</li>
<li>外国所需的，称为出口品</li>
</ul>
<p><strong>若厂商生产出来的产品没有成功出售，则视为厂商自己购买了自己的产品（存货），也被认为是投资品</strong>，因此投资品中有个负面的种类，即库存，当产品卖不出去，即库存增加，厂商就将面临停产，雇员即面临失业的风险。</p>
<p>上述四类被购的产品量乘上相应价格，被分别称为：</p>
<ul>
<li>消费，记作$C$；</li>
<li>投资，记作$I$；</li>
<li>政府购买，记作$G$；</li>
<li>出口，记作$X$</li>
</ul>
<p>下面重点对投资品进行介绍。</p>
<h2 id="投资品"><a href="#投资品" class="headerlink" title="投资品"></a>投资品</h2><p>计算公式为</p>
<blockquote>
<script type="math/tex; mode=display">I = \bar I + \Delta inv</script></blockquote>
<p>其中$\bar I$为资本物品，$\Delta inv$为存货物品，若不存在存货物品，则说明经济达到了最优（均衡）状态，这个最优不是从数量上来衡量，只是达到了某种最优的境界 。</p>
<h3 id="资本物品"><a href="#资本物品" class="headerlink" title="资本物品"></a>资本物品</h3><p>所谓资本物品，是指能长期使用的制造或建造的物体，它们可以用来生产其他物体，但不构成其他物体的一部分，如机器、设备、仪表、工具和厂房等。</p>
<ul>
<li>问：资本物品是否为“最终产品”？</li>
<li>答：这里的资本物品，显然为最终产品。因为企业是购买它们的最后使用者。</li>
</ul>
<p>这里所说的原材料和零部件是还未投入生产的部分，它们应属于这一年的最终产品，因为企业是作为这一年的最后使用者来购买它们的。</p>
<h3 id="存货物品"><a href="#存货物品" class="headerlink" title="存货物品"></a>存货物品</h3><p>所谓存货物品，是指企业购买的，但还未投入生产的原材料和零部件、在制品、半制品以及尚未销售出去的库存制成品。</p>
<h1 id="市场均衡等式"><a href="#市场均衡等式" class="headerlink" title="市场均衡等式"></a>市场均衡等式</h1><h2 id="国民生产总值"><a href="#国民生产总值" class="headerlink" title="国民生产总值"></a>国民生产总值</h2><p>这个等式是从“需求角度”，或支出法角度考虑的，“四类”最终产品中减去讲口品即为该国生产的最终产品的全部，一般被称为四驾马车。记进口为$M$，则有</p>
<script type="math/tex; mode=display">GNP = C + (\bar I+\Delta inv) + G + (X-M)</script><p>这是<strong>从需求方面</strong>研究产品市场均衡时的一个基本恒等式。其中投资$I$为总投资，即当年新投入的投资额</p>
<p><strong>说明两点</strong></p>
<ol>
<li><p>有一个习惯计法，即居民购买新建住宅并不包括在消费中，而是列入投资$I$中，尽管它们不是被企业购买。<br>理由是，房子是耐用品、不动产，更像厂房而不像食品、衣着和居民的其他消费项目。</p>
</li>
<li><p>是为了更方便简明，我们暂且不考虑有其他国家的存在，即只研究一个封闭的经济系统。<br>于是，$X=M=0$，从而GNP式成为：</p>
<script type="math/tex; mode=display">GNP = C + (\bar I+\Delta inv) + G</script></li>
</ol>
<h2 id="净投资"><a href="#净投资" class="headerlink" title="净投资"></a>净投资</h2><p>我们知道，在全年生产过程中，上年已有的投资品存量(比如一台机器)有一部分会被磨损消耗(即，需折旧)，因此产生了净投资的概念</p>
<blockquote>
<p>净投资：总投资$I-$折旧，记作$I_N$</p>
</blockquote>
<p>因此，国民生产净值为：</p>
<blockquote>
<script type="math/tex; mode=display">NNP=C+I_N+G</script></blockquote>
<h2 id="国民收入"><a href="#国民收入" class="headerlink" title="国民收入"></a>国民收入</h2><p>若我们将前面的按需求计改为按要素价格（供给）计，则有国民收入（即收入法）：</p>
<blockquote>
<p>$NI = \widetilde C+\widetilde{I_N}+\widetilde G$</p>
</blockquote>
<p>所以，国民收入有时也被称作<strong>要素收入</strong>，因为它正是以要素价格计的最终产品的净值。</p>
<p>根据$PI$（personal income）的定义，又可以把要素收入写成（与家庭部门及厂商部门联系）：</p>
<blockquote>
<script type="math/tex; mode=display">NI = PI + \text{(公司利润-红利)-(转移支付-被扣社会保险费+利息)}</script></blockquote>
<ul>
<li>公司利润$-$红利即为公司留利，可以看成是社会储蓄的一种(公司储蓄)，记作$S_F$；<ul>
<li>注意：从这一点开始，出现“储蓄”。</li>
</ul>
</li>
<li>被扣社会保险费可看成是政府转移支付中的一个负项，不妨把它纳入转移支付中；</li>
<li>利息也不妨记入转移支付中，因为这里所说的利息只是<strong>政府所付的（如国库券）利息</strong>，而不含通过银行或个人（包括企业）之间借贷所发生的利息。</li>
</ul>
<p>把这种广义的转移支付记成$TR$，于是有：</p>
<blockquote>
<script type="math/tex; mode=display">NI = PI+S_F-TR</script></blockquote>
<p>其中$PI$为家庭部门收入，$S_F$为厂商部门收入，$TR$为政府收入。其中$S_F$与$TR$均可能为0，做出如此断言时就成为经济学其中一个流派</p>
<h1 id="个人收入"><a href="#个人收入" class="headerlink" title="个人收入"></a>个人收入</h1><h2 id="三个去向"><a href="#三个去向" class="headerlink" title="三个去向"></a>三个去向</h2><p>个人收入，有且只有如下几方面（且它们之间没有交叉）：</p>
<ul>
<li>消费$C$；</li>
<li>个人储蓄$S_P$;</li>
<li>缴纳个人所得税$TA$</li>
</ul>
<p>故$PI = C+S_P+TA$，代入$NI$式中就有：</p>
<blockquote>
<script type="math/tex; mode=display">NI = C+S_P+S_F+TA-TR</script></blockquote>
<p>把$TA-TR$记为$T_1$，把$S_P+S_F$记作$S_N$，称为净储蓄，于是：</p>
<p>结合国民收入公式，我们有：</p>
<p>式子中，为净投资，为相应的净储蓄（即不把机器设备等损耗部分看作未被消费掉的储蓄）且包括公司留利。</p>
<p>$T_3$是真正的纯税收</p>
]]></content>
  </entry>
  <entry>
    <title>抽象代数/环的同态定理</title>
    <url>/posts/a55a5c8f.html</url>
    <content><![CDATA[<ul>
<li><p>定义：设$R_1, R_2$是两个环，$\phi$是$R_1$到$R_2$的映射，若满足：</p>
<script type="math/tex; mode=display">\phi(a+b) = \phi(a)+\phi(b)</script><script type="math/tex; mode=display">\phi(ab) = \phi(a)\phi(b)</script><p>则称$\phi$是$R_1$到$R_2$的同态，若$\phi$同时是满射与单射，则称环$R_!$与$R_2$同构。</p>
</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>Tensorflow/Tensorflow基础</title>
    <url>/posts/815f423b.html</url>
    <content><![CDATA[<h1 id="Tensorflow导入"><a href="#Tensorflow导入" class="headerlink" title="Tensorflow导入"></a>Tensorflow导入</h1><p>我们的代码主要是针对Tensorflow 1.x版本的环境，在Tensorflow 2.x下有部分代码无法正常运行，因此若是Tensorflow 1.x版本，只需简单使用<code>import tensorflow as tf</code>即可，而对于2.x版本的Tensorflow，我们可以将运行环境转换为1.x，并disable 2.x的特性：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow.compat.v1 <span class="keyword">as</span> tf</span><br><span class="line">tf.disable_v2_behavior</span><br></pre></td></tr></table></figure>
<p>也许有小伙伴不记得自己装过Tensorflow的版本，可以使用<code>tf.__version__</code>查看，下面我们都默认大家使用的是1.x的Tensorflow版本。</p>
<h1 id="Tensorflow三个核心概念"><a href="#Tensorflow三个核心概念" class="headerlink" title="Tensorflow三个核心概念"></a>Tensorflow三个核心概念</h1><h2 id="Graph"><a href="#Graph" class="headerlink" title="Graph"></a>Graph</h2><p>在Tensorflow中，计算图是一个有向图，用来描述计算节点一集计算节点之间的关系，所以在TensorFlow中我们存储一个值或者数组的时候，存的其实是这个值或者数组的计算图而不是其本身的数字</p>
<p><strong>关于计算图的操作</strong>：</p>
<ol>
<li>新建计算图：<code>g=tf.Graph()</code>，但是不同计算图上的张量是不能共享的，这个是存在于变量</li>
<li>指定计算图使用的device：<code>with g.device(&quot;/gpu:0&quot;)</code></li>
<li>设置默认计算图：<code>with g.as_default:</code></li>
<li>在会话中可以指定使用的计算图：<code>with tf.Session(graph=g1)</code></li>
</ol>
<p>下面是示例代码，大家可以自己运行一下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">g = tf.Graph()</span><br><span class="line">tf.compat.v1.disable_v2_behavior()</span><br><span class="line">tf.compat.v1.get_default_graph()</span><br><span class="line"><span class="keyword">with</span> g.device(<span class="number">0</span>):</span><br><span class="line">    a = tf.constant([<span class="number">10</span>, <span class="number">9</span>, <span class="number">8</span>, <span class="number">7</span>])</span><br><span class="line">    b = tf.constant([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">    c_1 = a + b</span><br><span class="line">    print(c_1.graph)</span><br><span class="line">    print(a.graph, b.graph)</span><br><span class="line">    </span><br><span class="line">    sess = tf.compat.v1.Session()</span><br><span class="line">    print(sess.run(c_1))</span><br></pre></td></tr></table></figure>
<p><code>a.graph</code>等的输出应类似<code>&lt;tensorflow.python.framework.ops.Graph object at 0x00000167399CEA90&gt;</code>，<code>sess.run</code>则是运行<code>a+b</code>这个计算</p>
<p>若没有使用GPU，也可以不指定device：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = tf.constant([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], name=<span class="string">"a"</span>)</span><br><span class="line">b = tf.constant([<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">6</span>], name=<span class="string">"b"</span>)</span><br><span class="line">c = a + b</span><br><span class="line">print(a.graph, b.graph, c.graph)</span><br><span class="line">sess = tf.compat.v1.Session()</span><br><span class="line">print(sess.run(c))</span><br></pre></td></tr></table></figure>
<p>下面定义多个图，会发现在后面<code>Session</code>运行时若指定<code>g1</code>将会报错，这是因为两次创建的图不一致：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">g1 = tf.Graph()</span><br><span class="line"><span class="keyword">with</span> g1.as_default():</span><br><span class="line">    a = tf.constant([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], name=<span class="string">"a"</span>)</span><br><span class="line">    b = tf.get_variable(<span class="string">"b"</span>, initializer=tf.constant_initializer()(shape=[<span class="number">1</span>]))</span><br><span class="line">    </span><br><span class="line">g2 = tf.Graph()</span><br><span class="line"><span class="keyword">with</span> g2.as_default():</span><br><span class="line">    a = tf.constant([<span class="number">2</span>, <span class="number">3</span>], name=<span class="string">"a"</span>)</span><br><span class="line">    b = tf.get_variable(<span class="string">"b"</span>, initializer=tf.constant_initializer()(shape=[<span class="number">3</span>]))</span><br><span class="line">    </span><br><span class="line"><span class="keyword">with</span> tf.Session(graph=g2) <span class="keyword">as</span> sess:</span><br><span class="line">    tf.global_variables_initializer().run()</span><br><span class="line">    c = a + <span class="number">1</span></span><br><span class="line">    print(<span class="string">"常量的情况下"</span>, sess.run(c))</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">""</span>, reuse=<span class="literal">True</span>):</span><br><span class="line">        print(<span class="string">"变量情况下"</span>, sess.run(tf.get_variable(<span class="string">"b"</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session(graph=g2) <span class="keyword">as</span> sess:</span><br><span class="line">    tf.global_variables_initializer().run()</span><br><span class="line">    c = a + <span class="number">1</span></span><br><span class="line">    print(<span class="string">"常量的情况下"</span>, sess.run(c))</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">""</span>, reuse=<span class="literal">True</span>):</span><br><span class="line">        print(<span class="string">"变量情况下"</span>, sess.run(tf.get_variable(<span class="string">"b"</span>)))</span><br></pre></td></tr></table></figure>
<h2 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h2><p>张量可以简单理解为多维数组，其中零阶张量表示标量，一阶张量为向量，第<code>n</code>阶张量可以理解为一个<code>n</code>维数组，但是张量在Tensorflow中的实现并不是直接采用数组的形式，它只是对Tensorflow中运算结果的引用，在张量中并没有真正保存数字，它保存的是如何得到这些数字的计算过程。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = tf.constant(<span class="number">2</span>, name=<span class="string">"a"</span>)</span><br><span class="line">b = tf.constant([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], name=<span class="string">"b"</span>)</span><br><span class="line">c = a * b</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(sess.run(c))</span><br></pre></td></tr></table></figure>
<h2 id="Session"><a href="#Session" class="headerlink" title="Session"></a>Session</h2><p>在Tensorflow中，计算图的计算过程都是在会话下进行的，同一个会话内的数据是可以共享的，会话结束计算的中间量就会消失，在Tensorflow中需要指定会话。<code>Session</code>有三种调用方式：</p>
<p>最常用的一种：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(result)</span><br></pre></td></tr></table></figure>
<p>另外不太常见的使用方式如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sess = tf.Session()</span><br><span class="line"><span class="keyword">with</span> sess.as_default():</span><br><span class="line">    print(result.eval())</span><br></pre></td></tr></table></figure>
<p>还有一种交互式的使用方式（保证安全性），此时会生成默认会话，不需指定：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sess = tf.InteractiveSession()</span><br></pre></td></tr></table></figure>
<h1 id="Tensorflow常用基础API"><a href="#Tensorflow常用基础API" class="headerlink" title="Tensorflow常用基础API"></a>Tensorflow常用基础API</h1><h2 id="简单API"><a href="#简单API" class="headerlink" title="简单API"></a>简单API</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tf.size()  <span class="comment"># This operation returns an integer representing the number of elements in input.</span></span><br><span class="line">tf.shape()  <span class="comment"># Returns the shape of a tensor.</span></span><br><span class="line"></span><br><span class="line">tf.reshape()  <span class="comment"># Reshapes a tensor.</span></span><br><span class="line">tf.squeeze()  <span class="comment"># Removes dimensions of size 1 from the shape of a tensor.</span></span><br><span class="line">tf.expand_dims()  <span class="comment"># Inserts a dimension of 1 into a tensor's shape.</span></span><br><span class="line"></span><br><span class="line">tf.concat()  <span class="comment"># Concatenates tensors along one dimension.</span></span><br><span class="line">tf.split()  <span class="comment"># Splits a tensor into sub tensors.</span></span><br><span class="line">tf.tile()  <span class="comment"># Constructs a tensor by tiling a given tensor.</span></span><br><span class="line"></span><br><span class="line">tf.slice()  <span class="comment"># Extracts a slice from a tensor.</span></span><br><span class="line">tf.stack()  <span class="comment"># Stacks a list of rank-R tensors into one rank-(R+1) tensor. v1.0之前为tf.pack()</span></span><br><span class="line">tf.gather()  <span class="comment"># Gather slices from params according to indices.</span></span><br><span class="line">tf.pad()  <span class="comment"># Pads a tensor.</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tf.reduce_sum()  <span class="comment"># Computes the sum of elements across dimensions of a tensor.</span></span><br><span class="line">tf.reduce_mean() <span class="comment"># Computes the mean of elements across dimensions of a tensor.</span></span><br><span class="line">tf.reduce_max()  <span class="comment"># Computes the maximum of elements across dimensions of a tensor.</span></span><br><span class="line"></span><br><span class="line">tf.argmax()  <span class="comment"># Returns the index with the largest value across axes of a tensor.</span></span><br><span class="line">tf.argmin()  <span class="comment"># Returns the index with the smallest value across axes of a tensor.</span></span><br><span class="line"></span><br><span class="line">tf.fill()  <span class="comment"># Creates a tensor filled with a scalar value.</span></span><br><span class="line"></span><br><span class="line">tf.random_shuffle()  <span class="comment"># Randomly shuffles a tensor along its first dimension.</span></span><br><span class="line">tf.truncated_normal()</span><br><span class="line">tf.random_normal()</span><br></pre></td></tr></table></figure>
<h2 id="tf-InteractiveSession"><a href="#tf-InteractiveSession" class="headerlink" title="tf.InteractiveSession()"></a><code>tf.InteractiveSession()</code></h2><p><code>tf.InteractiveSession()</code>是一种交互式的<code>session</code>方式，它让自己成为了默认的<code>session</code>，也就是说用户在不需要指明用哪个<code>session</code>运行的情况下，就可以运行起来，这就是默认的好处。这样的话就是<code>run()</code>和<code>eval()</code>函数可以不指明<code>session</code>啦。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a=tf.constant([[<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>],[<span class="number">4.</span>, <span class="number">5.</span>, <span class="number">6.</span>]])</span><br><span class="line">b=np.float32(np.random.<span class="built_in">randn</span>(<span class="number">3</span>,<span class="number">2</span>))</span><br><span class="line">c=tf.matmul(a,b)</span><br><span class="line">init=tf.global_variables_initializer()</span><br><span class="line">sess=tf.InteractiveSession()</span><br><span class="line">print (c.eval())</span><br></pre></td></tr></table></figure>
<p>若想使用<code>tf.Session()</code>，则必须加上<code>with sess.as_default():</code></p>
<h2 id="tf-nn模块"><a href="#tf-nn模块" class="headerlink" title="tf.nn模块"></a><code>tf.nn</code>模块</h2><h3 id="激活函数（Activation-Functions）"><a href="#激活函数（Activation-Functions）" class="headerlink" title="激活函数（Activation Functions）"></a>激活函数（Activation Functions）</h3><div class="table-container">
<table>
<thead>
<tr>
<th>操作</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>tf.nn.relu(features, name=None)</code></td>
<td>整流函数：<code>max(features, 0)</code></td>
</tr>
<tr>
<td><code>tf.nn.relu6(features, name=None)</code></td>
<td>以6为阈值的整流函数：<code>min(max(features, 0), 6)</code></td>
</tr>
<tr>
<td><code>tf.nn.elu(features, name=None)</code></td>
<td>elu函数，<code>exp(features) - 1 if &lt; 0</code>,否则featuresExponential Linear Units (ELUs)</td>
</tr>
<tr>
<td><code>tf.nn.softplus(features, name=None)</code></td>
<td>计算<code>softplus</code>：<code>log(exp(features) + 1)</code></td>
</tr>
<tr>
<td><code>tf.nn.dropout(x, keep_prob, noise_shape=None, seed=None, name=None)</code></td>
<td>计算<code>dropout</code>，<code>keep_prob</code>为keep概率, <code>noise_shape</code>为噪声的shape</td>
</tr>
<tr>
<td><code>tf.nn.bias_add(value, bias, data_format=None, name=None)</code></td>
<td>对<code>value</code>加一偏置量 此函数为<code>tf.add</code>的特殊情况，<code>bias</code>仅为一维， 函数通过广播机制进行与<code>value</code>和, 数据格式可以与<code>value</code>不同，返回为与<code>value</code>相同格式</td>
</tr>
<tr>
<td><code>tf.sigmoid(x, name=None)</code></td>
<td><code>y = 1 / (1 + exp(-x))</code></td>
</tr>
<tr>
<td><code>tf.tanh(x, name=None)</code></td>
<td><code>tf.tanh(x, name=None)</code></td>
</tr>
</tbody>
</table>
</div>
<h3 id="卷积函数（Convolution）"><a href="#卷积函数（Convolution）" class="headerlink" title="卷积函数（Convolution）"></a>卷积函数（Convolution）</h3><div class="table-container">
<table>
<thead>
<tr>
<th>操作</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None)</code></td>
<td>在给定的4D <code>input</code>与 <code>filter</code>下计算2D卷积输入shape为 <code>[batch, height, width, in_channels]</code></td>
</tr>
<tr>
<td><code>tf.nn.conv3d(input, filter, strides, padding, name=None)</code></td>
<td>在给定的5D <code>input</code>与 <code>filter</code>下计算3D卷积输入shape为<code>[batch, in_depth, in_height, in_width, in_channels]</code></td>
</tr>
<tr>
<td><code>tf.nn.depthwise_conv2d(input, filter, strides, padding, name=None)</code></td>
<td>卷积核能相互独立的在自己的通道上面进行卷积操作。</td>
</tr>
<tr>
<td><code>tf.nn.separable_conv2d(input, depthwise_filter, pointwise_filter, strides, padding, name=None)</code></td>
<td>在纵深卷积 <code>depthwise filter</code> 之后进行逐点卷积 <code>separable filter</code></td>
</tr>
</tbody>
</table>
</div>
<h3 id="池化函数（Pooling）"><a href="#池化函数（Pooling）" class="headerlink" title="池化函数（Pooling）"></a>池化函数（Pooling）</h3><div class="table-container">
<table>
<thead>
<tr>
<th>操作</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>tf.nn.avg_pool(value, ksize, strides, padding, data_format=’NHWC’, name=None)</code></td>
<td>平均方式池化</td>
</tr>
<tr>
<td><code>tf.nn.max_pool(value, ksize, strides, padding, data_format=’NHWC’, name=None)</code></td>
<td>最大值方法池化</td>
</tr>
<tr>
<td><code>tf.nn.max_pool_with_argmax(input, ksize, strides,padding, Targmax=None, name=None)</code></td>
<td>返回一个二维元组<code>(output,argmax)</code>,最大值<code>pooling</code>，返回最大值及其相应的索引</td>
</tr>
<tr>
<td><code>tf.nn.avg_pool3d(input, ksize, strides, padding, name=None)</code></td>
<td>3D平均值<code>pooling</code></td>
</tr>
<tr>
<td><code>tf.nn.max_pool3d(input, ksize, strides, padding, name=None)</code></td>
<td>3D最大值<code>pooling</code></td>
</tr>
</tbody>
</table>
</div>
<h3 id="数据标准化（Normalization）"><a href="#数据标准化（Normalization）" class="headerlink" title="数据标准化（Normalization）"></a>数据标准化（Normalization）</h3><div class="table-container">
<table>
<thead>
<tr>
<th>操作</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>tf.nn.l2_normalize(x, dim, epsilon=1e-12, name=None)</code></td>
<td>对维度<code>dim</code>进行L2范式标准化<code>output = x / sqrt(max(sum(x2), epsilon))</code></td>
</tr>
<tr>
<td><code>tf.nn.sufficient_statistics(x, axes, shift=None, keep_dims=False, name=None)</code></td>
<td>计算与均值和方差有关的完全统计量返回4维元组,元素个数，元素总和，元素的平方和，<code>shift</code>结果参见算法介绍</td>
</tr>
<tr>
<td><code>tf.nn.normalize_moments(counts, mean_ss, variance_ss, shift, name=None)</code></td>
<td>基于完全统计量计算均值和方差</td>
</tr>
<tr>
<td><code>tf.nn.moments(x, axes, shift=None, name=None, keep_dims=False)</code></td>
<td>直接计算均值与方差</td>
</tr>
<tr>
<td><code>tf.nn.local_response_normalization(input, depth_radius=None, bias=None, alpha=None, beta=None, name=None)</code></td>
<td>这个函数的作用是计算局部数据标准化。输入的数据 <code>input</code> 是一个四维的张量，但该张量被看做是一个一维的向量（ <code>input</code> 的最后一维作为向量），向量中的每一个元素都是一个三维的数组（对应 <code>input</code> 的前三维）。向量的每一个元素都是独立的被标准化的。</td>
</tr>
</tbody>
</table>
</div>
<h3 id="损失函数（Losses）"><a href="#损失函数（Losses）" class="headerlink" title="损失函数（Losses）"></a>损失函数（Losses）</h3><div class="table-container">
<table>
<thead>
<tr>
<th>操作</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>tf.nn.l2_loss(t, name=None)</code></td>
<td><code>output = sum(t ** 2) / 2</code></td>
</tr>
</tbody>
</table>
</div>
<h3 id="分类函数（Classification）"><a href="#分类函数（Classification）" class="headerlink" title="分类函数（Classification）"></a>分类函数（Classification）</h3><div class="table-container">
<table>
<thead>
<tr>
<th>操作</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>tf.nn.sigmoid_cross_entropy_with_logits(logits, targets, name=None)</code></td>
<td>计算输入<code>logits, targets</code>的交叉熵</td>
</tr>
<tr>
<td><code>tf.nn.softmax(logits, name=None)</code></td>
<td>计算<code>softmax softmax[i, j] = exp(logits[i, j]) / sum_j(exp(logits[i, j]))</code></td>
</tr>
<tr>
<td><code>tf.nn.log_softmax(logits, name=None)</code></td>
<td><code>logsoftmax[i, j] = logits[i, j] - log(sum(exp(logits[i])))</code></td>
</tr>
<tr>
<td><code>tf.nn.softmax_cross_entropy_with_logits(logits, labels, name=None)</code></td>
<td>计算<code>logits</code>和<code>labels</code>的<code>softmax</code>交叉熵<code>logits, labels</code>必须为相同的<code>shape</code>与数据类型</td>
</tr>
<tr>
<td><code>tf.nn.sparse_softmax_cross_entropy_with_logits(logits, labels, name=None)</code></td>
<td>计算<code>logits</code>和labels的<code>softmax</code>交叉熵</td>
</tr>
<tr>
<td><code>tf.nn.weighted_cross_entropy_with_logits(logits, targets, pos_weight, name=None)</code></td>
<td>与<code>sigmoid_cross_entropy_with_logits()</code>相似，但给正向样本损失加了权重<code>pos_weight</code></td>
</tr>
</tbody>
</table>
</div>
<p>这部分更多详细的介绍可以见<a href="https://blog.csdn.net/qq_36653505/article/details/81105894" target="_blank" rel="noopener">这篇博客</a></p>
]]></content>
  </entry>
  <entry>
    <title>Scipy/Scipy（1）</title>
    <url>/posts/c84b8b36.html</url>
    <content><![CDATA[<h1 id="一、SciPy概述"><a href="#一、SciPy概述" class="headerlink" title="一、SciPy概述"></a>一、SciPy概述</h1><p>NumPy替我们搞定了向量和矩阵的相关操作，基本上算是一个高级的科学计算器。SciPy基于NumPy提供了更为丰富和高级的功能扩展，在统计、优化、插值、数值积分、时频转换等方面提供了大量的可用函数，基本覆盖了基础科学计算相关的问题。</p>
<p>在量化分析中，运用最广泛的是统计和优化的相关技术，本篇重点介绍SciPy中的统计和优化模块，其他模块在随后系列文章中用到时再做详述。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> scipy.stats <span class="keyword">as</span> stats</span><br><span class="line"><span class="keyword">import</span> scipy.optimize <span class="keyword">as</span> opt</span><br></pre></td></tr></table></figure></p>
<h1 id="二、统计部分"><a href="#二、统计部分" class="headerlink" title="二、统计部分"></a>二、统计部分</h1><h3 id="生成随机数"><a href="#生成随机数" class="headerlink" title="生成随机数"></a>生成随机数</h3><p>我们从生成随机数开始，这样方便后面的介绍。生成$n$个随机数可用<code>rv_continuous.rvs(size=n)</code>或<code>rv_discrete.rvs(size=n)</code>，其中<code>rv_continuous</code>表示连续型的随机分布，如均匀分布（uniform）、正态分布（norm）、贝塔分布（beta）等；rv_discrete表示离散型的随机分布，如伯努利分布（bernoulli）、几何分布（geom）、泊松分布（poisson）等。我们生成10个$[0, 1]$区间上的随机数和10个服从参数$a=4，b=2$的贝塔分布随机数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rv_unif = stats.uniform.rvs(size=<span class="number">10</span>)</span><br><span class="line">print(rv_unif)</span><br><span class="line">rv_beta = stats.beta.rvs(size=<span class="number">10</span>, a=<span class="number">4</span>, b=<span class="number">2</span>)</span><br><span class="line">print(rv_beta)</span><br></pre></td></tr></table></figure><br>结果为：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[0.13343023 0.82528664 0.12357338 0.76093252 0.55256019 0.77734908</span><br><span class="line"> 0.02587088 0.23664022 0.23053925 0.35891198]</span><br><span class="line">[0.66993333 0.44235047 0.52443239 0.85816535 0.4013288  0.56135915</span><br><span class="line"> 0.73708043 0.67776086 0.72804616 0.92024739]</span><br></pre></td></tr></table></figure></p>
<p>在每个随机分布的生成函数里，都内置了默认的参数，如均匀分布的上下界默认是0和1。可是一旦需要修改这些参数，每次生成随机都要敲这么老长一串有点麻烦，能不能简单点？</p>
<p><code>SciPy</code>里头有一个<code>Freezing</code>的功能，可以提供简便版本的命令。<code>SciPy.stats</code>支持定义出某个具体的分布的对象，我们可以做如下的定义，让<code>beta</code>直接指代具体参数$a=4$和$b=2$的贝塔分布。为让结果具有可比性，这里指定了随机数的生成种子，由<code>NumPy</code>提供。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.random.seed(seed=<span class="number">2020</span>)</span><br><span class="line">rv_beta = stats.beta.rvs(size=<span class="number">10</span>, a=<span class="number">4</span>, b=<span class="number">2</span>)</span><br><span class="line">print(<span class="string">"method 1:"</span>)</span><br><span class="line">print(rv_beta)</span><br><span class="line"></span><br><span class="line">np.random.seed(seed=<span class="number">2020</span>)</span><br><span class="line">beta = stats.beta(a=<span class="number">4</span>, b=<span class="number">2</span>)</span><br><span class="line">print(<span class="string">"method 2:"</span>)</span><br><span class="line">print(beta.rvs(size=<span class="number">10</span>))</span><br></pre></td></tr></table></figure>
<p>结果为：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">method 1:</span><br><span class="line">[0.40765989 0.81432442 0.81389925 0.925416   0.77791256 0.71965217</span><br><span class="line"> 0.76665344 0.80133481 0.72746346 0.82444686]</span><br><span class="line">method 2:</span><br><span class="line">[0.40765989 0.81432442 0.81389925 0.925416   0.77791256 0.71965217</span><br><span class="line"> 0.76665344 0.80133481 0.72746346 0.82444686]</span><br></pre></td></tr></table></figure></p>
<h3 id="假设检验"><a href="#假设检验" class="headerlink" title="假设检验"></a>假设检验</h3><p>好了，现在我们生成一组数据，并查看相关的统计量（相关分布的参数可以在<a href="http://docs.scipy.org/doc/scipy/reference/stats.html" target="_blank" rel="noopener">这里</a>查到）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">norm_dist = stats.norm(loc=<span class="number">0.5</span>, scale=<span class="number">2</span>)</span><br><span class="line">n = <span class="number">200</span></span><br><span class="line">dat = norm_dist.rvs(size=n)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"mean of data is: "</span> + str(np.mean(dat)))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"median of data is: "</span> + str(np.median(dat)))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"standard deviation of data is: "</span> + str(np.std(dat)))</span><br></pre></td></tr></table></figure>
<p>结果为：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mean of data is: 0.3935187131823762</span><br><span class="line">median of data is: 0.29474903121906487</span><br><span class="line">standard deviation of data is: 1.9860982612048845</span><br></pre></td></tr></table></figure><br>假设这个数据是我们获取到的实际的某些数据，如股票日涨跌幅，我们对数据进行简单的分析。最简单的是<strong>检验这一组数据是否服从假设的分布</strong>，如正态分布。这个问题是典型的单样本假设检验问题，最为常见的解决方案是采用K-S检验（Kolmogorov-Smirnov test）。单样本K-S检验的原假设是给定的数据来自和原假设分布相同的分布，在<code>SciPy</code>中提供了<code>kstest</code>函数，参数分别是数据、拟检验的分布名称和对应的参数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mu = np.mean(dat)</span><br><span class="line">sigma = np.std(dat)</span><br><span class="line">stat_val, p_val = stats.kstest(dat, <span class="string">'norm'</span>, (mu, sigma))</span><br><span class="line">print(<span class="string">'KS-statistic D = %6.3f p-value = %6.4f'</span> % (stat_val, p_val))</span><br></pre></td></tr></table></figure><br>结果为：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">KS-statistic D &#x3D;  0.050 p-value &#x3D; 0.6757</span><br></pre></td></tr></table></figure><br>假设检验的<code>p-value</code>值很大（在原假设下，<code>p-value</code>是服从$[0, 1]$区间上的均匀分布的随机变量，可参考<a href="http://en.wikipedia.org/wiki/P-value" target="_blank" rel="noopener">该链接</a> ），因此我们接受原假设，即该数据通过了正态性的检验。在正态性的前提下，我们可进一步检验这组数据的均值是不是0。典型的方法是 $t$ 检验（t-test），其中单样本的t检验函数为<code>ttest_1samp</code>：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">stat_val, p_val = stats.ttest_1samp(dat, <span class="number">0</span>)</span><br><span class="line">print(<span class="string">'One-sample t-statistic D = %6.3f, p-value = %6.4f'</span> % (stat_val, p_val))</span><br><span class="line"><span class="comment"># One-sample t-statistic D =  2.795, p-value = 0.0057</span></span><br></pre></td></tr></table></figure><br>我们看到$p-value<0.05$，即给定显著性水平0.05的前提下，我们应拒绝原假设：数据的均值为0。我们再生成一组数据，尝试一下双样本的t检验（`ttest_ind`）： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">norm_dist2 = stats.norm(loc=<span class="number">-0.2</span>, scale=<span class="number">1.2</span>)</span><br><span class="line">dat2 = norm_dist2.rvs(size=<span class="number">100</span>)</span><br><span class="line">stat_val, p_val = stats.ttest_ind(dat, dat2, equal_var=<span class="literal">False</span>)</span><br><span class="line">print(<span class="string">'Two-sample t-statistic D = %6.3f, p-value = %6.4f'</span> % (stat_val, p_val))</span><br><span class="line"><span class="comment"># Two-sample t-statistic D =  3.544, p-value = 0.0005</span></span><br></pre></td></tr></table><br>注意，这里我们生成的第二组数据样本大小、方差和第一组均不相等，在运用t检验时需要使用<code>Welch&#39;s t-test</code>，即指定<code>ttest_ind</code>中的<code>equal_var=False</code>。我们同样得到了比较小的$p-value$，在显著性水平0.05的前提下拒绝原假设，即认为两组数据均值不等。</0.05$，即给定显著性水平0.05的前提下，我们应拒绝原假设：数据的均值为0。我们再生成一组数据，尝试一下双样本的t检验（`ttest_ind`）：></p>
<p><code>stats</code>还提供其他大量的假设检验函数，如<code>bartlett</code>和<code>levene</code>用于检验方差是否相等；<code>anderson_ksamp</code>用于进行<code>Anderson-Darling</code>的K-样本检验等。</p>
<h3 id="其他函数"><a href="#其他函数" class="headerlink" title="其他函数"></a>其他函数</h3><p>有时需要知道某数值在一个分布中的分位，或者给定了一个分布，求某分位上的数值。这可以通过<code>cdf</code>和<code>ppf</code>函数完成：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">g_dist = stats.gamma(a=<span class="number">2</span>)</span><br><span class="line">print(<span class="string">"quantiles of 2, 4 and 5:"</span>)</span><br><span class="line">print(g_dist.cdf([<span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>]))</span><br><span class="line">print(<span class="string">"Values of 25%, 50% and 90%:"</span>)</span><br><span class="line">print(g_dist.pdf([<span class="number">0.25</span>, <span class="number">0.5</span>, <span class="number">0.95</span>]))</span><br></pre></td></tr></table></figure><br>对于一个给定的分布，可以用<code>moment</code>很方便的查看分布的矩信息，例如我们查看$N(0,1)$的六阶原点矩：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">stats.norm.moment(<span class="number">6</span>, loc=<span class="number">0</span>, scale=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 15.000000000000004</span></span><br></pre></td></tr></table></figure><br><code>describe</code>函数提供对数据集的统计描述分析，包括数据样本大小，极值，均值，方差，偏度和峰度：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">norm_dist &#x3D; stats.norm(loc&#x3D;0, scale&#x3D;1.8)</span><br><span class="line">dat &#x3D; norm_dist.rvs(size&#x3D;100)</span><br><span class="line">info &#x3D; stats.describe(dat)</span><br><span class="line">print(&quot;Data size is: &quot; + str(info[0]))</span><br><span class="line">print(&quot;Minimum value is: &quot; + str(info[1][0]))</span><br><span class="line">print(&quot;Maximum value is: &quot; + str(info[1][1]))</span><br><span class="line">print(&quot;Arithmetic mean is: &quot; + str(info[2]))</span><br><span class="line">print(&quot;Unbiased variance is: &quot; + str(info[3]))</span><br><span class="line">print(&quot;Biased skewness is: &quot; + str(info[4]))</span><br><span class="line">print(&quot;Biased kurtosis is: &quot; + str(info[5]))</span><br></pre></td></tr></table></figure><br>结果为：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Data size is: 100</span><br><span class="line">Minimum value is: -3.656065377232337</span><br><span class="line">Maximum value is: 4.766443498849179</span><br><span class="line">Arithmetic mean is: 0.051618110504146594</span><br><span class="line">Unbiased variance is: 3.163608017164579</span><br><span class="line">Biased skewness is: 0.13490650793787465</span><br><span class="line">Biased kurtosis is: -0.47265469705343577</span><br></pre></td></tr></table></figure><br>当我们知道一组数据服从某些分布的时候，可以调用<code>fit</code>函数来得到对应分布参数的极大似然估计（MLE, maximum-likelihood estimation）。以下代码示例了假设数据服从正态分布，用极大似然估计分布参数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">norm_dist = stats.norm(loc=<span class="number">0</span>, scale=<span class="number">1.8</span>)</span><br><span class="line">dat = norm_dist.rvs(size=<span class="number">100</span>)</span><br><span class="line">mu, sigma = stats.norm.fit(dat)</span><br><span class="line">print(<span class="string">"MLE of data mean:"</span> + str(mu))</span><br><span class="line">print(<span class="string">"MLE of data standard deviation:"</span> + str(sigma))</span><br></pre></td></tr></table></figure><br>结果为：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">MLE of data mean:-0.09513087060141222</span><br><span class="line">MLE of data standard deviation:1.917831616655979</span><br></pre></td></tr></table></figure><br><code>pearsonr</code>和<code>spearmanr</code>可以计算Pearson和Spearman相关系数，这两个相关系数度量了两组数据的相互线性关联程度：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">norm_dist = stats.norm()</span><br><span class="line">dat1 = norm_dist.rvs(size=<span class="number">100</span>)</span><br><span class="line">exp_dist = stats.expon()</span><br><span class="line">dat2 = exp_dist.rvs(size=<span class="number">100</span>)</span><br><span class="line">cor, pval = stats.pearsonr(dat1, dat2)</span><br><span class="line">print(<span class="string">"Pearson correlation coefficient: "</span> + str(cor))</span><br><span class="line">cor, pval = stats.pearsonr(dat1, dat2)</span><br><span class="line">print(<span class="string">"Spearman's rank correlation coefficient: "</span> + str(cor))</span><br></pre></td></tr></table></figure><br>结果为：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Pearson correlation coefficient: -0.19532417034339547</span><br><span class="line">Spearman&#39;s rank correlation coefficient: -0.19532417034339547</span><br></pre></td></tr></table></figure><br>其中的<code>p-value</code>表示原假设（两组数据不相关）下，相关系数的显著性。</p>
<p>最后，在分析金融数据中使用频繁的线性回归在<code>SciPy</code>中也有提供，我们来看一个例子：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = stats.chi2.rvs(<span class="number">3</span>, size=<span class="number">50</span>)</span><br><span class="line">y = <span class="number">2.5</span> + <span class="number">1.2</span> * x + stats.norm.rvs(size=<span class="number">50</span>, loc=<span class="number">0</span>, scale=<span class="number">1.5</span>)</span><br><span class="line">slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Slope of fitted model is:"</span> , slope)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Intercept of fitted model is:"</span>, intercept)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"R-squared:"</span>, r_value**<span class="number">2</span>)</span><br></pre></td></tr></table></figure><br>结果为：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Slope of fitted model is: 1.1704239780738979</span><br><span class="line">Intercept of fitted model is: 2.550024706484493</span><br><span class="line">R-squared: 0.6908378963527287</span><br></pre></td></tr></table></figure><br>在前面的链接中，可以查到大部分<code>stat</code>中的函数，本节权作简单介绍，挖掘更多功能的最好方法还是直接读原始的文档。另外，<code>StatsModels</code>（ <a href="http://statsmodels.sourceforge.net" target="_blank" rel="noopener">http://statsmodels.sourceforge.net</a> ）模块提供了更为专业，更多的统计相关函数。若在<code>SciPy</code>没有满足需求，可以采用<code>StatsModels</code>。</p>
]]></content>
  </entry>
  <entry>
    <title>matlab/Matlab概率统计与曲线拟合</title>
    <url>/posts/7aa9eaaf.html</url>
    <content><![CDATA[<h1 id="一、二项分布"><a href="#一、二项分布" class="headerlink" title="一、二项分布"></a>一、二项分布</h1><ul>
<li>二项分布来源于伯努利试验 (事件发生概率 $\boldsymbol{p}$ ) :</li>
</ul>
<script type="math/tex; mode=display">
P\{x=k\}=\left(\begin{array}{c}
N \\
k
\end{array}\right) p^{k} q^{(N-k)}, k=0,1, \ldots, N</script><p>​    含义为独立重复N次试验后, 事件总共发生k次的概率</p>
<ul>
<li>分布函数 $F(X=k)=P\{X \leq k\},$ 二项分布记为 $B(n, p)$</li>
<li>$\mathrm{p_k}=$ <code>binopdf</code> $(\mathrm{k}, \mathrm{N}, \mathrm{p}) \quad$ 获得事件共发生$k$次的概率 $\boldsymbol{P}\{\boldsymbol{x}=\boldsymbol{k}\}$</li>
<li>$\mathrm{p_k}=$ <code>binocdf</code> $(\mathrm{k}, \mathrm{N}, \mathrm{p}) \quad$ 为事件最多发生$k$次的概率 $\boldsymbol{P}\{\boldsymbol{x} \leq \boldsymbol{k}\}$</li>
<li>$\mathrm{R}=$ <code>binornd</code> $(\mathrm{N}, \mathrm{p}, \mathrm{m}, \mathrm{n}) \quad$ 将生成一个服从二项分布 $B(N, \boldsymbol{p}),$<br>规模为 $m \times n$ 的随机矩阵</li>
<li>二项分布的数字特征 $E(k)=N p, D(k)=N p(1-p)$</li>
</ul>
<p><strong>例：画出$N=100,p=0.5$情况下的二项分布概率特性曲线</strong></p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">N = <span class="number">100</span>; p = <span class="number">0.5</span>;					<span class="comment">% 总试验次数和单次试验发生概率</span></span><br><span class="line">k = <span class="number">0</span>:N;							<span class="comment">% 所有可能的事件发生次数</span></span><br><span class="line">pdf = binopdf(k, N, p);				<span class="comment">% 绘制概率曲线</span></span><br><span class="line">cdf = binocdf(k, N, p);				<span class="comment">% 绘制分布曲线</span></span><br><span class="line">h = plotyy(k, pdf, k, cdf);			<span class="comment">% 左右两侧不同的纵轴刻度代表两个函数</span></span><br></pre></td></tr></table></figure>
<p>绘制结果为：</p>
<p><img src="/posts/Pic/Untitled/image-20201124102008010.png" alt="image-20201124102008010" style="zoom:67%;"></p>
<blockquote>
<p><strong>进阶绘图技巧：<code>set</code>函数的使用</strong></p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">set(get(h(<span class="number">1</span>),<span class="string">'Children'</span>),<span class="string">'Color'</span>,<span class="string">'b'</span>,<span class="string">'Marker'</span>, <span class="string">'.'</span>, <span class="string">'MarkerSize'</span>, <span class="number">13</span>)</span><br><span class="line"><span class="comment">% 句中 get(h(1),'children') 表示获取刚才第一条曲线绘制的所有子对象</span></span><br><span class="line"><span class="comment">% 然后将第一条曲线改为蓝色 并且在采样点加注实心点 不是只画点</span></span><br><span class="line"></span><br><span class="line">set(get(h(<span class="number">1</span>),<span class="string">'Ylabel'</span>), <span class="string">'String'</span>,<span class="string">'pdf'</span>)</span><br><span class="line"><span class="comment">% 句柄包含多个绘图时 需要 get 出来再操作 此行改变了左侧 Y 轴的标记名</span></span><br><span class="line"></span><br><span class="line">set(h(<span class="number">2</span>),<span class="string">'Ycolor'</span>,[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line"><span class="comment">% 第二条曲线纵坐标轴颜色改为纯红色</span></span><br><span class="line"></span><br><span class="line">set(get(h(<span class="number">2</span>),<span class="string">'Children'</span>),<span class="string">'Color'</span>,<span class="string">'r'</span>,<span class="string">'Marker'</span>,<span class="string">'+'</span>,<span class="string">'MarkerSize'</span>,<span class="number">4</span>)</span><br><span class="line"><span class="comment">% 第二条曲线改为红色并用来标注采样点</span></span><br><span class="line"></span><br><span class="line">set(get(h(<span class="number">2</span>), <span class="string">'Ylabel'</span>),<span class="string">'String'</span>, <span class="string">'cdf'</span>)</span><br><span class="line"><span class="comment">% 右侧Y轴的标记名</span></span><br><span class="line">xlabel(<span class="string">'k'</span>)</span><br><span class="line">grid on</span><br></pre></td></tr></table></figure>
</blockquote>
<p><strong>绘图结果为：</strong></p>
<p><img src="/posts/Pic/Untitled/image-20201124103134184.png" alt="image-20201124103134184" style="zoom:67%;"></p>
<h1 id="二、正态分布"><a href="#二、正态分布" class="headerlink" title="二、正态分布"></a>二、正态分布</h1><ul>
<li>正态分布 $N\left(\mu, \sigma^{2}\right)$ 为连续型随机分布，期望 $\mu,$ 标准差 $\sigma$ :</li>
</ul>
<script type="math/tex; mode=display">
f(x)=\frac{1}{\sigma \sqrt{2 \pi}} \mathrm{e}^{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}}, \quad x \in(-\infty,+\infty)</script><p>对应分布函数 $\Phi(x)=\int_{-\infty}^{x} f(t) \mathrm{d} t$</p>
<ul>
<li>$\mathrm{px}=$ <code>normpdf</code> $(\mathrm{x}, \mu,$ $\sigma$) $\quad$ 获得服从正态分布 $N(\mu, \sigma^2)$ 的随机变量概率密度函数在$x$的取值。 </li>
<li><p>$\mathrm{px}=$ <code>normcdf</code> $(\mathrm{x}, \mu,$ $\sigma$) $\quad$ 获得上述正态分布随机变量不超过$x$的总概率</p>
</li>
<li><p>$\mathrm{R}=$ <code>normrnd</code> $(\mu, $ $\sigma$ $, \mathrm{m}, \mathrm{n})$ 将生成一个服从上述正态分 布，规模为 $m \times n$ 的随机样本构成的矩阵</p>
</li>
<li><p>$\mathrm{R}=$ <code>randn</code> $(\mathrm{m}, \mathrm{n})$ 将生成一个服从标准正态分布 $N(\mathbf{0}, \mathbf{1}),$ 规模为 $m \times n$ 的随机样本构成的矩阵，事实上，我们可以利用这个矩阵可以构造任何正态分布随机矩阵。</p>
</li>
</ul>
<p><strong>例：正态分布几何表示</strong></p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">mu = <span class="number">3</span>; sigma = <span class="number">0.5</span>;</span><br><span class="line">x = mu + sigma*[<span class="number">-3</span>:<span class="number">-1</span>,<span class="number">1</span>:<span class="number">3</span>];         <span class="comment">% 设置六个不同的采样点</span></span><br><span class="line">yf = normcdf(x, mu, sigma);         <span class="comment">% 获得六个点的cdf值</span></span><br><span class="line">P = [yf(<span class="number">4</span>)-yf(<span class="number">3</span>), yf(<span class="number">5</span>)-yf(<span class="number">2</span>), yf(<span class="number">6</span>)-yf(<span class="number">1</span>)];    <span class="comment">% 计算cdf的差值（内部区域面积）</span></span><br><span class="line">xd = <span class="number">1</span>:<span class="number">0.1</span>:<span class="number">5</span>; yd = normpdf(xd, mu, sigma); clf</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k=<span class="number">1</span>:<span class="number">3</span></span><br><span class="line">   xx = x(<span class="number">4</span>-k):sigma/<span class="number">10</span>:x(<span class="number">3</span>+k);</span><br><span class="line">   yy = normpdf(xx, mu, sigma);</span><br><span class="line">   <span class="comment">% 对于三个不同的面积区间进行不同范围的采样,并获得 pdf 函数的值</span></span><br><span class="line">   subplot(<span class="number">3</span>, <span class="number">1</span>, k), <span class="built_in">plot</span>(xd, yd, <span class="string">'b'</span>);     <span class="comment">% 绘图位于3行1列第k个位置</span></span><br><span class="line">   <span class="built_in">hold</span> on, fill([x(<span class="number">4</span>-k), xx, x(<span class="number">3</span>+k)], [<span class="number">0</span>, yy, <span class="number">0</span>], <span class="string">'g'</span>); <span class="built_in">hold</span> off</span><br><span class="line">   <span class="keyword">if</span> k&lt;<span class="number">2</span></span><br><span class="line">       text(<span class="number">3.8</span>, <span class="number">0.6</span>, <span class="string">'[&#123;\mu&#125;-&#123;\sigma&#125;, &#123;\mu&#125;+&#123;\sigma&#125;]'</span>)</span><br><span class="line">   <span class="keyword">else</span></span><br><span class="line">       kk = int2str(k);</span><br><span class="line">       text(<span class="number">3.8</span>, <span class="number">0.6</span>, [<span class="string">'[&#123;\mu&#125;-'</span>, kk, <span class="string">'&#123;\sigma&#125;, &#123;\mu&#125;+'</span>, kk, <span class="string">'&#123;\sigma&#125;]'</span>])</span><br><span class="line">   <span class="keyword">end</span></span><br><span class="line">   text(<span class="number">2.8</span>, <span class="number">0.3</span>, num2str(P(k))); shg   <span class="comment">% 填充区域内显示面积</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">xlabel(<span class="string">'x'</span>); shg</span><br></pre></td></tr></table></figure>
<p>绘图结果为：</p>
<p><img src="/posts/Pic/Untitled/image-20201124105059445.png" alt="image-20201124105059445" style="zoom:67%;"></p>
<h1 id="三、统计分析命令"><a href="#三、统计分析命令" class="headerlink" title="三、统计分析命令"></a>三、统计分析命令</h1><ul>
<li>$\min (\mathrm{x}), \max (\mathrm{x})$ 分别计算矩阵各列的最大值或最小值,</li>
<li>若计算整个矩阵最大元素, 可用$\max (\max (\mathrm{x}))$ 或$\max (\mathrm{X}(:))$ </li>
<li>$\mathrm{mean} (\mathrm{x}),$ $\mathrm{median} (\mathrm{x})$ 分别计算矩阵各列的均值与中位值</li>
<li>$\mathrm{std}(\mathrm{x})$,$ \mathrm{var} $$(\mathrm{x})$ 分别计算矩阵各列的样本标准差与样本方差</li>
<li>$\mathrm{cov}$ $(\mathrm{x})$ 计算矩阵$x$各列所组成列向量计算出的协方差矩阵, 注意到对应的分丹仍然是$m-1$</li>
<li>$\mathrm{corrcoef} (\mathrm{x}) $计算矩阵x各列所组成列向量对应的相关系数</li>
</ul>
<p><strong>例：产生1000个服从$N(2, 0.5^2)$的随机数</strong></p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">mu = <span class="number">2</span>; s = <span class="number">0.5</span>;</span><br><span class="line">rng(<span class="number">22</span>, <span class="string">'v5normal'</span>)</span><br><span class="line">x = <span class="built_in">randn</span>(<span class="number">1000</span>, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">y = s*x+mu;</span><br><span class="line"></span><br><span class="line">subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>), histfit(x), axis([<span class="number">-5</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">100</span>]), ylabel(<span class="string">'x'</span>)</span><br><span class="line">subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>), histfit(y), axis([<span class="number">-5</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">100</span>]), ylabel(<span class="string">'y'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/posts/Pic/Untitled/4.jpg" alt="4" style="zoom:67%;"></p>
<h1 id="四、多项式拟合"><a href="#四、多项式拟合" class="headerlink" title="四、多项式拟合"></a>四、多项式拟合</h1><p>假设 $y=a_{1} x^{n}+a_{2} x^{n-1}+\cdots+a_{n} x+a_{n+1},$ 我们获取其函数曲线上的一组采样点 $\left\{x_{i}, y_{i} \mid i=1,2, \ldots, m\right\},$ 利用数学方法确定或估计系数 $a_{1}, a_{2}, \ldots, a_{n+1}$ 的问题称之为<strong>多项式拟合问题</strong></p>
<p>一般来讲，多项式拟合往往会与<strong>逼近或插值</strong>这两种知识相结合。在<strong>采样点准确，函数光滑</strong>的情况下，高阶的拟合（即假设更大的 $n$ ) 往往效果更佳，但如果采样信息有噪声误差, 过大的$n$可能会让结果失去拟合意义（一般设定 $n&lt;m$）</p>
<ul>
<li><code>p = ployfit(x, y, n)</code>将通过数组$x$和$y$的数据进行拟合，拟合的阶数或次数设定为自然数$n$,返回多项式系数$p$</li>
<li><code>yy=polyval (p, x)</code>可以将多项式系数回代，观察拟合值</li>
</ul>
<p>利用MATLAB函数计算采样$y$值向量与拟合值向量误差的$2-$范数, $1-$范数与$\infty-$范数，可以分析其<strong>平方残差</strong>、<strong>绝对值残差</strong>或<strong>一致逼近残差</strong>的情况。</p>
<p><strong>例：多项式拟合实例</strong></p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">x0 = <span class="number">0</span>:<span class="number">0.1</span>:<span class="number">1</span>;</span><br><span class="line">y0 = [<span class="number">-.447</span>, <span class="number">1.978</span>, <span class="number">3.11</span>, <span class="number">5.25</span>, <span class="number">5.02</span>, <span class="number">4.66</span>, <span class="number">4.01</span>, <span class="number">4.58</span>, <span class="number">3.45</span>, <span class="number">5.35</span>, <span class="number">9.22</span>];	<span class="comment">% 构造原始数据</span></span><br><span class="line">n = <span class="number">3</span>;P = polyfit(x0, y0, n)												<span class="comment">% 多项式拟合</span></span><br><span class="line">xx = <span class="number">0</span>:<span class="number">0.01</span>:<span class="number">1</span>; yy = polyval(P, xx);				<span class="comment">% 利用得到的多项式代回得到预测值</span></span><br><span class="line"><span class="built_in">plot</span>(xx, yy, <span class="string">'-b'</span>, x0, y0, <span class="string">'.r'</span>, <span class="string">'MarkerSize'</span>, <span class="number">20</span>);							<span class="comment">% 绘图</span></span><br><span class="line"><span class="built_in">legend</span>(<span class="string">'拟合曲线'</span>, <span class="string">'原始数据'</span>, <span class="string">'Location'</span>, <span class="string">'SouthEast'</span>)</span><br><span class="line">xlabel(<span class="string">'x'</span>)</span><br></pre></td></tr></table></figure>
<p>绘制结果为：</p>
<p><img src="/posts/Pic/Untitled/5.jpg" alt="5" style="zoom:67%;"></p>
<blockquote>
<p><strong>进阶制表</strong>：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">y1 = polyval(P, x0);</span><br><span class="line">T = <span class="built_in">table</span>(x0', y0', y1', y1'-y0', <span class="string">'VariableNames'</span>, &#123;<span class="string">'X'</span>, <span class="string">'Y'</span>, <span class="string">'Fit'</span>, <span class="string">'FitError'</span>&#125;)</span><br></pre></td></tr></table></figure>
</blockquote>
<p>表打印结果为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">T &#x3D;</span><br><span class="line"></span><br><span class="line">  11×4 table</span><br><span class="line"></span><br><span class="line">     X       Y         Fit       FitError </span><br><span class="line">    ___    ______    ________    _________</span><br><span class="line"></span><br><span class="line">      0    -0.447    -0.90431     -0.45731</span><br><span class="line">    0.1     1.978      2.2819       0.3039</span><br><span class="line">    0.2      3.11      4.0659      0.95592</span><br><span class="line">    0.3      5.25      4.7879     -0.46211</span><br><span class="line">    0.4      5.02       4.788     -0.23204</span><br><span class="line">    0.5      4.66      4.4063     -0.25372</span><br><span class="line">    0.6      4.01       3.983    -0.027002</span><br><span class="line">    0.7      4.58      3.8583     -0.72174</span><br><span class="line">    0.8      3.45      4.3722      0.92223</span><br><span class="line">    0.9      5.35       5.865      0.51503</span><br><span class="line">      1      9.22      8.6768     -0.54316</span><br></pre></td></tr></table></figure>
<h3 id="1-多项式拟合的最小二乘理解"><a href="#1-多项式拟合的最小二乘理解" class="headerlink" title="1. 多项式拟合的最小二乘理解"></a>1. 多项式拟合的最小二乘理解</h3><p><code>polyfit</code>函数的方法即解最小二乘问题 :</p>
<script type="math/tex; mode=display">
\min _{a_{1}, a_{2}, \ldots, a_{n+1}}\left\|y-\left(a_{1} x^{n}+\cdots+a_{n} x+a_{n+1}\right)\right\|_{2}</script><p>方法是构造 $y=\left[y_{1}, y_{2}, \ldots, y_{m}\right]^{\top}, a=\left[a_{1}, a_{2}, \ldots, a_{n+1}\right]^{\top}$$，X=\left[\begin{array}{cccc}x_{1}^{n} &amp; \cdots &amp; x_{1} &amp; 1 \\ x_{2}^{n} &amp; \cdots &amp; x_{2} &amp; 1 \\ \vdots &amp; \vdots &amp; \vdots &amp; \vdots \\ x_{m}^{n} &amp; \cdots &amp; x_{m} &amp; 1\end{array}\right],$</p>
<p>易得 $y=X a,$ 在 $m&gt;n+1$ 时, 方程超定 (可能无解) , 此时最小二乘解可以通过 $a=x\backslash y$ 获得</p>
<p><strong>例：用最小二乘法获得拟合结果</strong></p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">x0 = (<span class="number">0</span>:<span class="number">0.1</span>:<span class="number">1</span>)';</span><br><span class="line">y0 = [<span class="number">-.447</span>,<span class="number">1.978</span>,<span class="number">3.11</span>,<span class="number">5.25</span>,<span class="number">5.02</span>,<span class="number">4.66</span>,<span class="number">4.01</span>,<span class="number">4.58</span>,<span class="number">3.45</span>,<span class="number">5.35</span>,<span class="number">9.22</span>]';</span><br><span class="line"></span><br><span class="line">m = <span class="built_in">length</span>(x0);</span><br><span class="line">n = <span class="number">3</span>;</span><br><span class="line">X = <span class="built_in">zeros</span>(m,n+<span class="number">1</span>);                     <span class="comment">%m个采样点，n+1个未知系数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k=<span class="number">1</span>:n</span><br><span class="line">    X(:, n-k+<span class="number">1</span>) = (x0.^k);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">X(:, n+<span class="number">1</span>) = <span class="built_in">ones</span>(m, <span class="number">1</span>);</span><br><span class="line">aT = (X\y0)'</span><br></pre></td></tr></table></figure>
<p>输出结果应与调用多项式拟合函数得到的<code>P</code>相同</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">aT =</span><br><span class="line"></span><br><span class="line">   <span class="number">56.6915</span>  <span class="number">-87.1174</span>   <span class="number">40.0070</span>   <span class="number">-0.9043</span></span><br></pre></td></tr></table></figure>
<h3 id="2-适用于特定问题的拟合或回归方法"><a href="#2-适用于特定问题的拟合或回归方法" class="headerlink" title="2. 适用于特定问题的拟合或回归方法"></a>2. 适用于特定问题的拟合或回归方法</h3><ul>
<li><strong>岭回归模型</strong>：本质上仍可化归为最小二乘问题</li>
</ul>
<script type="math/tex; mode=display">
\min _{a_{1}, a_{2}, \ldots, a_{n+1}}\left\|y-\left(a_{1} x^{n}+\cdots+a_{n} x+a_{n+1}\right)\right\|_{2}^{2}+\lambda\|a\|_{2}^{2}</script><p>其中, $\boldsymbol{a}=\left[\begin{array}{llll}a_{1} &amp; a_{2} &amp; \cdots &amp; a_{n}\end{array}\right]^{\top}$ 表示拟合系数。</p>
<ul>
<li><strong>Lasso模型</strong>：对拟合系数具有稀疏正则的模型：</li>
</ul>
<script type="math/tex; mode=display">
\min _{a_{1}, a_{2}, \ldots, a_{n+1}} \frac{1}{2}\left\|y-\left(a_{1} x^{n}+\cdots+a_{n} x+a_{n+1}\right)\right\|_{2}^{2}+\lambda\|a\|_{1}</script><ul>
<li><strong>最小绝对残差 (LAR)模型</strong>：对离群值的处理有更好效果 :</li>
</ul>
<script type="math/tex; mode=display">
\min _{a_{1}, a_{2}, \ldots, a_{n+1}}\left\|y-\left(a_{1} x^{n}+\cdots+a_{n} x+a_{n+1}\right)\right\|_{1}</script><p>实际问题中，线性拟合所使用的基函数也未必一定是多项式, 根据实际问题可以设置为三角函数、指数函数、正态分布的概率密度函数，以及混合定义的基底函数。</p>
]]></content>
  </entry>
  <entry>
    <title>matlab/Matlab数字图像处理初步</title>
    <url>/posts/71d7d118.html</url>
    <content><![CDATA[<h1 id="灰度数字图像与矩阵"><a href="#灰度数字图像与矩阵" class="headerlink" title="灰度数字图像与矩阵"></a>灰度数字图像与矩阵</h1><ul>
<li><strong>灰度图像</strong>：一张灰度图像根据其竖直位置（行）与水平位置（列）可以对应于一个二维矩阵$𝒇(𝒙,𝒚),𝟏≤𝒙≤𝑴,𝟏≤𝒚≤𝑵$，其中$(𝑴,𝑵)$为图像的尺寸。而$𝒇(𝒙,𝒚)$表示的为图像的灰度，图像灰度值通常在数据文件中以<code>uint8</code>，即八位无符号整型$(0, 255)$的整数来表示灰度。0为黑色，255为白色。</li>
</ul>
<p><img src="/posts/Pic/Matlab%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%20%E5%88%9D%E6%AD%A5/image-20201215101026301.png" alt="image-20201215101026301"></p>
<ul>
<li><strong>彩色图像</strong>：彩色图像最为常用的存储模式为RGB存储模式，即彩色图像的红、绿、蓝三种颜色分别对应一种亮度（灰度）值。记为$𝒇(𝒙,𝒚,𝒛),𝟏≤𝒙≤𝑴,𝟏≤𝒚≤𝑵,𝒛∈{𝟏,𝟐,𝟑}$</li>
</ul>
<p><img src="/posts/Pic/Matlab%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%20%E5%88%9D%E6%AD%A5/image-20201215101132611.png" alt="image-20201215101132611" style="zoom:67%;"></p>
<p>​    <strong>注意：jpg文件为有损压缩，png文件为无损压缩</strong></p>
<h1 id="数字图像基础API"><a href="#数字图像基础API" class="headerlink" title="数字图像基础API"></a>数字图像基础API</h1><ul>
<li><p><strong>信息获取</strong>：函数<code>info=imfinfo(&#39;filename&#39;)</code>可获取灰度或彩色图像文件的基本信息，如假设文件名为<code>mcm1.png</code>，可见：</p>
<p>例如我展示一个图片的信息，结果为：</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">info &#x3D; </span><br><span class="line"></span><br><span class="line">  包含以下字段的 struct:</span><br><span class="line"></span><br><span class="line">           Filename: &#39;D:\matlab\AFile\temp\pic\songshu.jpg&#39;</span><br><span class="line">        FileModDate: &#39;26-Jul-2020 15:49:11&#39;</span><br><span class="line">           FileSize: 720467</span><br><span class="line">             Format: &#39;jpg&#39;</span><br><span class="line">      FormatVersion: &#39;&#39;</span><br><span class="line">              Width: 1920</span><br><span class="line">             Height: 1080</span><br><span class="line">           BitDepth: 24</span><br><span class="line">          ColorType: &#39;truecolor&#39;</span><br><span class="line">    FormatSignature: &#39;&#39;</span><br><span class="line">    NumberOfSamples: 3</span><br><span class="line">       CodingMethod: &#39;Huffman&#39;</span><br><span class="line">      CodingProcess: &#39;Progressive&#39;</span><br><span class="line">            Comment: &#123;&#125;</span><br><span class="line">        Orientation: 1</span><br><span class="line">        XResolution: 72</span><br><span class="line">        YResolution: 72</span><br><span class="line">     ResolutionUnit: &#39;Inch&#39;</span><br><span class="line">           Software: &#39;Adobe Photoshop CS Windows&#39;</span><br><span class="line">           DateTime: &#39;2017:02:26 10:40:49&#39;</span><br><span class="line">      DigitalCamera: [1×1 struct]</span><br><span class="line">      ExifThumbnail: [1×1 struct]</span><br></pre></td></tr></table></figure>
<ul>
<li><p><strong>读取图像</strong>：进入图像所在的文件夹，键入<code>A=imread(&#39;filename&#39;)</code>，即可获取灰度或彩色图像的信息，并且将其储存在矩阵A中</p>
</li>
<li><p><strong>展示图像</strong>：MATLAB函数<code>imshow(A)</code>可以弹出Figure并显示图像A</p>
</li>
</ul>
<p><strong>注意</strong>：</p>
<ol>
<li>数字图像的默认储存格式<code>uint8</code>并不适合进行数值计算。在进行数值计算时，矩阵往往被自动转化成双精度型。因此图示前往往将矩阵强制转换为<code>uint8</code>型。</li>
<li>对双精度型矩阵,直接使用<code>imshow</code>默认最小值为0,最大值为1。0~255双精度图像可标准化图示如<code>imshow(A/255)</code></li>
</ol>
<h1 id="彩色图像处理"><a href="#彩色图像处理" class="headerlink" title="彩色图像处理"></a>彩色图像处理</h1><h2 id="彩色图像的通道分离与图像存储"><a href="#彩色图像的通道分离与图像存储" class="headerlink" title="彩色图像的通道分离与图像存储"></a>彩色图像的通道分离与图像存储</h2><p>对于RGB格式的彩色图像矩阵A，<code>B=A(:,:,1)</code>即可提取彩色图像的红色通道值,其中B将以二维矩阵的形式存储表示</p>
<p><img src="/posts/Pic/Matlab%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%20%E5%88%9D%E6%AD%A5/image-20201215102333149.png" alt="image-20201215102333149"></p>
<p>相应API：</p>
<ul>
<li><p><code>imshow(B)</code>：将会得到对应红色通道的灰度图像</p>
</li>
<li><p><code>C=rgb2gray(A)</code>：可以根据彩色图像A的整体亮度均匀的转化为灰度图像C</p>
</li>
<li><p><code>imwrite(A,&#39;file_name&#39;)</code>可以将任何的灰度或彩色图像矩阵存入对应文件名。注意：<code>double</code>型矩阵存储时范围为0~1</p>
</li>
</ul>
<h2 id="彩色图像的颜色编码更换"><a href="#彩色图像的颜色编码更换" class="headerlink" title="彩色图像的颜色编码更换"></a>彩色图像的颜色编码更换</h2><p>RGB格式是大多数彩色图像的存储格式，按照红、绿、蓝三种颜色分别存储一张灰度图像。另一种非常流行的颜色模型为HSV模型，分为色调(Hue),饱和度(Saturation)以及明度(Value)三种信息</p>
<p><code>B = rgb2hsv(A)</code>，可以将RGB模型的矩阵A化为<code>hsv</code>型的矩阵B，而<code>C=hsv2rgb(B)</code>可以完成逆变换。若A为<code>uint8</code>型的数据，则会自动转为双精度型并除以255，再进行对应的色彩空间变换，<strong>HSV的指标范围均为0~1</strong></p>
<p><img src="/posts/Pic/Matlab%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%20%E5%88%9D%E6%AD%A5/image-20201215102736379.png" alt="image-20201215102736379"></p>
<h1 id="数字图像的简单处理"><a href="#数字图像的简单处理" class="headerlink" title="数字图像的简单处理"></a>数字图像的简单处理</h1><p><strong>数字图像的放大</strong></p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">RGB2 = imresize(RGB,[<span class="number">192</span>,<span class="number">256</span>]); 	<span class="comment">% 图像长宽减半</span></span><br></pre></td></tr></table></figure>
<p><strong>数字图像的放大</strong></p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">RGB3=imresize(RGB,[<span class="number">1000</span>,NaN]); 		<span class="comment">% 等比例放大</span></span><br></pre></td></tr></table></figure>
<p><em>Matlab默认使用双三次插值的方法获取更大的图像</em></p>
<p><strong>数字图像的裁剪</strong></p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">RGB4=RGB3(<span class="number">401</span>:<span class="number">600</span>,<span class="number">401</span>:<span class="number">600</span>,:);		<span class="comment">% 将前页放大图像的第401~600行，401~600列裁剪下来</span></span><br><span class="line">RGB5=RGB3(<span class="number">600</span>:<span class="number">-1</span>:<span class="number">401</span>,<span class="number">600</span>:<span class="number">-1</span>:<span class="number">401</span>,:); <span class="comment">% 与上述结果相比，进行了水平和垂直翻转</span></span><br><span class="line">RGB6=RGB3(<span class="number">1</span>:<span class="number">2</span>:<span class="keyword">end</span>,<span class="number">1</span>:<span class="number">2</span>:<span class="keyword">end</span>,:);		<span class="comment">% 本质上是一种“粗暴”的图像缩小算法</span></span><br></pre></td></tr></table></figure>
<p><strong>数字图像映射到曲面</strong></p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">[x,y,z] = sphere(<span class="number">100</span>);  <span class="comment">%生成101层高度的单位球面坐标，每层101X101个点坐标</span></span><br><span class="line">warp(x,y,z,RGB)			<span class="comment">%将彩椒图像映射到球面显示</span></span><br><span class="line">view(<span class="number">45</span>,<span class="number">-45</span>)			<span class="comment">%改变观察角度，也改变了图像相对位置</span></span><br></pre></td></tr></table></figure>
<h1 id="数字图像的亮度与对比度"><a href="#数字图像的亮度与对比度" class="headerlink" title="数字图像的亮度与对比度"></a>数字图像的亮度与对比度</h1><p><strong>亮度</strong>：设<code>uint8</code>型的灰度图像的二维矩阵为A，设置常整数<code>-255&lt;=c&lt;=255</code>，则<code>A+c</code>就表示亮度的调整。若<code>A+c</code>超过255则自动设置为255，反之若<code>A+c</code>小于0则自动设置为0</p>
<p><img src="/posts/Pic/Matlab%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%20%E5%88%9D%E6%AD%A5/image-20201215103533478.png" alt="image-20201215103533478" style="zoom:67%;"></p>
<p><strong>对比度</strong>：设<code>uint8</code>型的灰度图像的矩阵为A,设置正常数<code>c&gt;0</code>与<code>0~255</code>之间的整数<code>k</code>，则$c*(A-k)+k$则表示以<code>k</code>为灰度中心，将对比放大/缩小<code>c</code>倍。通常，因对比度常定义为最大最小灰度比值，故假设<code>k=0</code>，注意：结果仍会自动转化为<code>uint8</code>型的数据。</p>
<p><img src="/posts/Pic/Matlab%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%20%E5%88%9D%E6%AD%A5/image-20201215103730624.png" alt="image-20201215103730624" style="zoom:67%;"></p>
<h1 id="图像的直方图显示与均衡化"><a href="#图像的直方图显示与均衡化" class="headerlink" title="图像的直方图显示与均衡化"></a>图像的直方图显示与均衡化</h1><ul>
<li><code>imhist(A)</code>可绘制图像的灰度直方图，统计各灰度出现频率</li>
<li><code>B = histeq(A)</code>可将矩阵A进行灰度均衡化(一般增大对比度)</li>
</ul>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">I=imread(<span class="string">'peppers.png'</span>);   	<span class="comment">%读取图像并在左上角显示其灰度</span></span><br><span class="line">I=rgb2gray(I); </span><br><span class="line"><span class="built_in">figure</span>;subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>);</span><br><span class="line">imshow(I);</span><br><span class="line">title(<span class="string">'原始图像'</span>);</span><br><span class="line"></span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>);			<span class="comment">%绘制直方图</span></span><br><span class="line">imhist(I);</span><br><span class="line">title(<span class="string">'原始图像直方图'</span>);</span><br><span class="line"></span><br><span class="line">I1=histeq(I);     			<span class="comment">%图像均衡化后的效果</span></span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>);</span><br><span class="line">imshow(I1);title(<span class="string">'图像均衡化'</span>);</span><br><span class="line"></span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>);</span><br><span class="line">imhist(I1);</span><br><span class="line">title(<span class="string">'直方图均衡化'</span>);</span><br></pre></td></tr></table></figure>
<p><img src="/posts/Pic/Matlab%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%20%E5%88%9D%E6%AD%A5/image-20201215104123317.png" alt="image-20201215104123317" style="zoom:67%;"></p>
<h1 id="图像的背景提取与计算"><a href="#图像的背景提取与计算" class="headerlink" title="图像的背景提取与计算"></a>图像的背景提取与计算</h1><p>图像的背景提取可以基于图像的开运算算法(属于形态学图像基础，这里对原理不作要求)，对应的MATLAB函数为<code>imopen</code>，开运算的核心是对图像的腐蚀再膨胀的运算，主要效果除了对细节平滑化外，可以去掉前景亮色的边缘毛刺等，后面将专门介绍。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">clear all;coins=imread(<span class="string">'coins.png'</span>);	<span class="comment">%打开MATLAB內建的硬币图像</span></span><br><span class="line">background=imopen(coins,strel(<span class="string">'disk'</span>,<span class="number">15</span>));</span><br><span class="line"><span class="comment">%利用半径为15的圆盘做开运算</span></span><br><span class="line"></span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>),imshow(coins);title (<span class="string">'原始图像'</span>)</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>);imshow(background);title (<span class="string">'背景图像'</span>)</span><br><span class="line"><span class="comment">%可以发现，背景图像提取了每一个硬币的所在区域并进行了一定的光滑化</span></span><br><span class="line"></span><br><span class="line">coins1=imsubtract(coins,background);<span class="comment">%MATLAB提供的更专业的相减函数</span></span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>),imshow(coins1);  </span><br><span class="line">title (<span class="string">'imsubtract函数相减结果'</span>)</span><br><span class="line"></span><br><span class="line">K = imabsdiff(coins,background);<span class="comment">%前景值不论正负都可以保留</span></span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>);imshow(K,[])	<span class="comment">%按K的范围比例放缩输出（扩大对比度）</span></span><br><span class="line">title (<span class="string">'imabsdiff函数相减结果'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/posts/Pic/Matlab%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%20%E5%88%9D%E6%AD%A5/coin.png" style="zoom:75%;"></p>
<h1 id="图像的前景抠图与背景更换"><a href="#图像的前景抠图与背景更换" class="headerlink" title="图像的前景抠图与背景更换"></a>图像的前景抠图与背景更换</h1><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">ind = background&gt;=<span class="number">80</span>;		<span class="comment">%硬币区域背景值均大于等于80</span></span><br><span class="line"><span class="built_in">figure</span>;subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>);</span><br><span class="line">imshow(ind)</span><br><span class="line">title(<span class="string">'获取的前景位置'</span>)</span><br><span class="line"></span><br><span class="line">coins_f = immultiply(coins,ind);	</span><br><span class="line"><span class="comment">%两个uint8与logical矩阵做图像式乘法时，*或.*均会出现错误(非double)</span></span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>);imshow(coins_f)</span><br><span class="line">title(<span class="string">'抠取的前景图像'</span>)</span><br><span class="line"></span><br><span class="line">background_new = imread(<span class="string">'nbg.png'</span>);</span><br><span class="line"><span class="comment">%这个文件MATLAB没有,可自己尝试生成一个同型的灰度背景图像</span></span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>);imshow(background_new)</span><br><span class="line">title(<span class="string">'新背景图像'</span>)</span><br><span class="line"></span><br><span class="line">coins_new = coins_f + immultiply(background_new,~ind);</span><br><span class="line"><span class="comment">%逻辑型矩阵ind做非运算后，1变成0,0变成1。因此背景部分代替无硬币区域</span></span><br><span class="line"><span class="comment">%有硬币区域使用最初coins的图像灰度，进行整合</span></span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>);imshow(coins_new)</span><br><span class="line">title(<span class="string">'新合成图像'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/posts/Pic/Matlab%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%20%E5%88%9D%E6%AD%A5/image-20201215105836072.png" alt="image-20201215105836072" style="zoom:67%;"></p>
<h1 id="二维离散傅里叶变换"><a href="#二维离散傅里叶变换" class="headerlink" title="二维离散傅里叶变换"></a>二维离散傅里叶变换</h1><p>二维离散傅里叶变换可以理解为一维离散傅里叶变换的张量积，或理解按照两个方向分别作一次一维傅里叶变换。定义:</p>
<script type="math/tex; mode=display">
F(u, v)=\sum_{x=1}^{m} \sum_{y=1}^{n} f(x, y) \mathrm{e}^{\frac{(-2 \pi j)(x-1)(u-1)}{m}+\frac{(-2 \pi j)(y-1)(v-1)}{n}}</script><p>$1 \leq u \leq m, 1 \leq v \leq n,$ $j$为虚数单位。特别的当 $(u, v)=(1,1)$ 时, $F(1,1)=\sum_{x=1}^{m} \sum_{y=1}^{n} f(x, y)$ 称为离散傅里叶变换的低频系数。<br>余系数称为高频傅里叶系数。低频系数表达了函数的区域总和。 高频系数则在不同程度刻画函数的变化情况。 回函数<code>fft2 (X)</code>可计算出矩阵或图像X的二维离散傅里叶变换<br>离散傅里叶逆变换定义</p>
<script type="math/tex; mode=display">
f(x, y)=\frac{1}{m n} \sum_{u=1}^{m} \sum_{v=1}^{n} F(u, v) \mathrm{e}^{\frac{(2 \pi j)(x-1)(u-1)}{m}+\frac{(2 \pi j)(y-1)(v-1)}{n}}</script><p>$1 \leq x \leq m, 1 \leq y \leq n,$ MATLAB对应函数<code>ifft2 (Y)​</code></p>
<p>对Cameraman图像进行二维傅里叶变换，模的最大值必为低频值，除左上角外，大值多位于四个角落。因此可以使用MATLAB函数<code>fftshift</code>来平移傅里叶变换函数将大值置于中部</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">clear,close all;</span><br><span class="line">A = imread(<span class="string">'cameraman.tif'</span>);<span class="comment">%MATLAB自带的图像</span></span><br><span class="line">FA = fft2(A);</span><br><span class="line">subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>),imshow(<span class="built_in">abs</span>(FA),[<span class="number">0</span>,<span class="number">1e4</span>]),title(<span class="string">'原始傅里叶变换'</span>);</span><br><span class="line">FAS = fftshift(FA);	<span class="comment">%本身不改变FA的值，只是进行一个水平与竖直方向的平移</span></span><br><span class="line">subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>),imshow(<span class="built_in">abs</span>(FAS),[<span class="number">0</span>,<span class="number">1e4</span>]),title(<span class="string">'平移傅里叶变换'</span>);</span><br><span class="line"><span class="comment">%这里1e4并不是变换的最大模，只是为了能够尽量反映傅里叶系数模的对比度</span></span><br></pre></td></tr></table></figure>
<p>傅里叶变换对于自然图像往往不具有稀疏性。对于小块亮度函数，其频谱线会集中在坐标轴，并且保持旋转不变性。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">f=<span class="built_in">zeros</span>(<span class="number">900</span>,<span class="number">900</span>);</span><br><span class="line">f(<span class="number">351</span>:<span class="number">648</span>,<span class="number">476</span>:<span class="number">525</span>)=<span class="number">1</span>;</span><br><span class="line">subplot(<span class="number">221</span>);imshow(f,[]);title(<span class="string">'原始图像'</span>);</span><br><span class="line"></span><br><span class="line">F=fftshift(fft2(f));</span><br><span class="line">subplot(<span class="number">222</span>);imshow(<span class="built_in">log</span>(<span class="number">1</span>+<span class="built_in">abs</span>(F)),[])	</span><br><span class="line"><span class="comment">%log(1+abs(F))进行合理比例变化，保证图谱清晰</span></span><br><span class="line"></span><br><span class="line">title(<span class="string">'原始图像的频谱'</span>);</span><br><span class="line">f=imrotate(f,<span class="number">45</span>,<span class="string">'bilinear'</span>,<span class="string">'crop'</span>); 	</span><br><span class="line"><span class="comment">%对其进行旋转，双线性，如果出格则裁剪掉的算法</span></span><br><span class="line">subplot(<span class="number">223</span>),imshow(f,[])</span><br><span class="line">title(<span class="string">'图像正向旋转45度'</span>)</span><br><span class="line"></span><br><span class="line">Fc=fftshift(fft2(f));</span><br><span class="line">subplot(<span class="number">224</span>);</span><br><span class="line">imshow(<span class="built_in">log</span>(<span class="number">1</span>+<span class="built_in">abs</span>(Fc)),[])</span><br><span class="line">title(<span class="string">'旋转后图像的频谱'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/posts/Pic/Matlab%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%20%E5%88%9D%E6%AD%A5/image-20201215110825731.png" alt="image-20201215110825731" style="zoom:67%;"></p>
<h1 id="二维离散余弦变换"><a href="#二维离散余弦变换" class="headerlink" title="二维离散余弦变换"></a>二维离散余弦变换</h1><ul>
<li>二维离散余弦变换与二维离散傅里叶变换类似，但不同点为余弦变换是实变换，并且更贴近于真实图像的频谱分析需求（因为真实图像在二维空间往往并不具有周期性），定义:<br>$C(u, v)=a(u) b(v) \sum_{x=1}^{m} \sum_{y=1}^{n} f(x, y) \cos \frac{(2 x-1)(u-1) \pi}{2 m} \cos \frac{(2 y-1)(v-1) \pi}{2 n}$<br>$\mathbf{1} \leq u \leq m, \mathbf{1} \leq v \leq n_{\circ}$ 其中 $a(u)=\left\{\begin{array}{l}\sqrt{\frac{1}{m}}, u=1 \\ \sqrt{\frac{2}{m}}, u \neq 1\end{array}, b(v)=\left\{\begin{array}{l}\sqrt{\frac{1}{n}}, v=1 \\ \sqrt{\frac{2}{n}}, v \neq 1\end{array}\right.\right.$<br>特别的当 $(u, v)=(1,1)$ 时, $C(1,1)=\frac{1}{\sqrt{m n}} \sum_{x=1}^{m} \sum_{y=1}^{n} f(x, y)$ 称为<strong>离散余弦变换的低频系数</strong>。其余系数称为<strong>高频余弦系数</strong>。</li>
<li>函数<code>dct2 (X)</code>可计算出矩阵或图像X的二维离散余弦变换</li>
<li>离散余弦逆变换可以类似定义，其MATLAB对应函数<code>idct2 (Y)</code></li>
</ul>
<p>实际的自然图像，大都在整体区域上不满足恒为常值，也不满足具有周期纹理状的统一分布。但是往往<strong>在局部分片上满足相应形式</strong>，因此，分片傅里叶变换或分片余弦变换就有了很大的存在和利用价值。</p>
<h1 id="图像恢复问题"><a href="#图像恢复问题" class="headerlink" title="图像恢复问题"></a>图像恢复问题</h1><h2 id="图像去高斯噪声问题"><a href="#图像去高斯噪声问题" class="headerlink" title="图像去高斯噪声问题"></a>图像去高斯噪声问题</h2><p>与信号去噪问题相似，图像去噪问题即图像对应的目标函数受到了一些未知的退化变换，得到了一幅带有噪点的不准确图像。去噪问题即利用图像的内在性质与噪声分布的特点，完成目标清晰图像的估计与获取的过程。</p>
<p>函数<code>imnoise</code>可生成各种类型的带有各种噪声的图像</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">B = imnoise(A,<span class="string">'gaussian'</span>,<span class="number">0</span>,<span class="number">0.05</span>);</span><br><span class="line"><span class="comment">% 对图像A添加高斯噪声，均值0，方差0.05*(255^2),与个人生成随机矩阵计算相比，imnoise可以自动将结果化为uint8型</span></span><br></pre></td></tr></table></figure>
<p><img src="/posts/Pic/Matlab%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%20%E5%88%9D%E6%AD%A5/image-20201215111338848.png" alt="image-20201215111338848" style="zoom:67%;"></p>
<h2 id="均值滤波"><a href="#均值滤波" class="headerlink" title="均值滤波"></a>均值滤波</h2><p>最简单也最直接的二维图像高斯噪声的去噪方法即为均值滤波方法，对应的MATLAB函数为<code>imfilter</code>。用法形如：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">filt = <span class="number">1</span>/<span class="number">25</span> * <span class="built_in">ones</span>(<span class="number">5</span>)</span><br><span class="line">C = imfilter(B,filt,<span class="string">'symmetric'</span>,<span class="string">'same'</span>);</span><br></pre></td></tr></table></figure>
<p>解释：设立25点均值滤波的方法，即以每个像素为中心，周围$5X5$的范围的均值代替原有的含有噪声的图像函数值，这个和一元信号去噪使用<code>smooth</code>函数的原理基本相同。对称边界条件，滤波时不改变图像大小(对应<code>’same’</code>，否则为<code>’full’</code>)</p>
<p><img src="/posts/Pic/Matlab%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%20%E5%88%9D%E6%AD%A5/image-20201215111548575.png" alt="image-20201215111548575" style="zoom:67%;"></p>
<h2 id="恢复结果的衡量-峰值信噪比-PSNR"><a href="#恢复结果的衡量-峰值信噪比-PSNR" class="headerlink" title="恢复结果的衡量-峰值信噪比(PSNR)"></a>恢复结果的衡量-峰值信噪比(PSNR)</h2><p>除了直接通过肉眼观察图像质量外，基于图像函数误差定义的峰值信噪比，可以对图像的恢复质量进行数值上的分析。峰值信噪比的定义（8位无符号整型）为：</p>
<script type="math/tex; mode=display">10*\text{log}_{10}(\frac{255^2*\text{总点数}}{\sum[y-f(x)]^2})</script><p>可以注意到，峰值信噪比的值往往大于信噪比，仅取决于图像函数的绝对误差。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">psnr(B,A)			<span class="comment">% 真实图像在前后均可</span></span><br><span class="line"><span class="comment">% ans = 13.8864,带有噪声的图像PSNR值较低，单位分贝dB</span></span><br><span class="line">psnr(C,A)</span><br><span class="line"><span class="comment">% ans = 21.0560,均值滤波确实减小了误差，提高了PSNR</span></span><br></pre></td></tr></table></figure>
<h2 id="椒盐噪声与图像填充问题"><a href="#椒盐噪声与图像填充问题" class="headerlink" title="椒盐噪声与图像填充问题"></a>椒盐噪声与图像填充问题</h2><p>椒盐噪声，即随机选择图像中的若干像点，将他们的值变为0（黑椒点）或255（白盐点），使其与真实值无关。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">B = imnoise(A,<span class="string">'salt &amp; pepper'</span>,<span class="number">0.1</span>); <span class="comment">% 将10%随机的像点转化为非黑即白的椒盐噪声</span></span><br></pre></td></tr></table></figure>
<p>椒盐噪声所在位置的直接检测方法讲就是直接找出像素值 为0与255的点，用周围像素值填充。这些信息被认定为是无效的，需要通过其他位置的灰度值来恢复这些被破坏的灰度值。因此椒盐噪声去噪本质上是一种图像填充问题(估计完全未知元素)</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">ind = (B==<span class="number">0</span>) | (B==<span class="number">255</span>);</span><br></pre></td></tr></table></figure>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">sum(ind(:))/<span class="built_in">numel</span>(ind)</span><br><span class="line"><span class="comment">% ans = 0.1000 噪点比例检测</span></span><br></pre></td></tr></table></figure>
<h3 id="椒盐噪声的简单恢复方法-中值滤波"><a href="#椒盐噪声的简单恢复方法-中值滤波" class="headerlink" title="椒盐噪声的简单恢复方法-中值滤波"></a>椒盐噪声的简单恢复方法-中值滤波</h3><p>因为椒盐噪声噪点周围，我们认为绝大多数的信息是准确的，因此可以在噪点周围3X3或5X5的范围内取灰度值的中位数来估计噪点的灰度，可以削弱信息缺失的影响。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">C = medfilt2(B,[<span class="number">3</span> <span class="number">3</span>]); 	<span class="comment">% 3X3的中值滤波，即一个像点上下左右3X3区域内取中位数估计</span></span><br><span class="line">psnr(B,A)		       	<span class="comment">% ans = 15.0481 </span></span><br><span class="line">psnr(C,A)				<span class="comment">% ans 	= 25.8709</span></span><br><span class="line">C(~ind) = B(~ind);		<span class="comment">% 未填充区域应取消滤波效果</span></span><br><span class="line">psnr(C,A)				<span class="comment">% ans 	= 33.4267</span></span><br></pre></td></tr></table></figure>
<p><strong>图像区域填充问题与逐步填充的思想</strong></p>
<ul>
<li>图像有时候会整块的丢失或不再需要（如部分PS或美图软件中的擦除笔功能），此问题本质上也是一个图像填充问题，需要利用已知或未擦除区域对剩余区域进行估计。</li>
<li>反复进行中值滤波，真实值会渐渐渗透到填充区域内部，从而达到图像填充的理想效果。滤波半径尽量大一些</li>
</ul>
<h1 id="图像模糊"><a href="#图像模糊" class="headerlink" title="图像模糊"></a>图像模糊</h1><p><strong>卷积</strong></p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">A = imread(<span class="string">'XX.png'</span>);</span><br><span class="line">kernel = fspecial(<span class="string">'disk'</span>,<span class="number">10</span>);	   <span class="comment">%对焦不准模糊核，半径为10</span></span><br><span class="line">B = imfilter(A,kernel,<span class="string">'replicate'</span>); <span class="comment">%复制型边界条件,PSNR=21.05dB</span></span><br></pre></td></tr></table></figure>
<p><strong>移动模糊核</strong></p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">A = imread(<span class="string">'XX.png'</span>);</span><br><span class="line">kernel = fspecial(<span class="string">'motion'</span>,<span class="number">15</span>,<span class="number">90</span>);  <span class="comment">%向上平移15格的移动模糊</span></span><br><span class="line">B = imfilter(A,kernel,<span class="string">'replicate'</span>); <span class="comment">%复制型边界条件,PSNR=23.67dB</span></span><br></pre></td></tr></table></figure>
<p><strong>周期型边界条件</strong></p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">A = imread(<span class="string">'XX.png'</span>);</span><br><span class="line">kernel = fspecial(<span class="string">'disk'</span>,<span class="number">10</span>);		<span class="comment">%对焦不准模糊核，半径为10</span></span><br><span class="line">C = imfilter(A,kernel,<span class="string">'circular'</span>); 	<span class="comment">%周期型边界条件,PSNR=20.79dB</span></span><br></pre></td></tr></table></figure>
<p><strong>MATLAB的图像反卷积函数-<code>deconvreg</code></strong></p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">D = deconvreg(B,kernel);	<span class="comment">%复制型边界恢复效果很差,PSNR=7.79dB</span></span><br><span class="line">E = deconvreg(C,kernel);	<span class="comment">%周期型则几乎完全恢复,PSNR=28.94dB</span></span><br></pre></td></tr></table></figure>
<p><strong>MATLAB的盲反卷积函数-<code>deconvblind</code></strong></p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">F = deconvblind(B,kernel);		 </span><br><span class="line"><span class="comment">% 以kernel为初值，即使与真实的模糊核有差距，边界条件也有一些差距，仍可恢复到勉强的水平。PSNR=22.05dB</span></span><br></pre></td></tr></table></figure>
<p>可以将模糊化过程定义为函数句柄，再用<code>cgs,gmres</code>等反问题求解函数来获取较为准确的解。但由于整数化近似带来的误差所造成的的不可逆影响。结果仍然无法得到完全的清晰。<code>PSNR=27.44dB</code>，使用正则化将结果进行分片光滑的逼近可以进一步改善相应的结果。    </p>
]]></content>
  </entry>
  <entry>
    <title>matlab/Matlab数字信号与声音处理</title>
    <url>/posts/53add54c.html</url>
    <content><![CDATA[<h1 id="数字信号"><a href="#数字信号" class="headerlink" title="数字信号"></a>数字信号</h1><h2 id="函数信息与数字信号"><a href="#函数信息与数字信号" class="headerlink" title="函数信息与数字信号"></a>函数信息与数字信号</h2><p>数字信号区别与传统的函数信息的最大特点，就是其离散性，即数字信号的自变量与返回值都是离散定义的。例如，一个声音数字信号，一定有一个每秒若干次的采样，每一个时间段，声音的强度也将有一个固定精度的取值。</p>
<p>信号的数字化一般需要三个步骤：<strong>抽样、量化、编码</strong></p>
<blockquote>
<ul>
<li>一维的数字信号有时可能是<strong>波形信号</strong>，这样的信号通过拟合、插值，往往代表这一种具有光滑性与周期性的函数。</li>
<li>一维的数字信号也有可能是<strong>声音信号</strong>，这样的信号往往会具有多种频段的信息，对应的连续函数的傅里叶变换也将在部分区段或点位出现明显更大的系数。</li>
<li>一维的数字信号还有可能是<strong>分片光滑函数或分片常函数</strong>，也有可能是符合某种特定分布的随机函数。</li>
</ul>
</blockquote>
<h2 id="信噪比"><a href="#信噪比" class="headerlink" title="信噪比"></a>信噪比</h2><p>衡量误差大小的方法有很多，一种方式就是图示+观察，较 为直观可靠度也比较高。统计一致误差（最大误差）也是 一种衡量噪声强度的方法。</p>
<ul>
<li>相较来说，整体平方误差 $\Sigma[y-f(x)]^{2}$ (SE) 或平均平方误 差（MSE-mean square error ) 被更多采用。</li>
<li>另一种基于平方误差的噪声强度的定义为信噪比 (SNRsignal to noise ratio) $: 10 \cdot \log _{10}\left(\frac{\sum f^{2}(x)}{\sum[y-f(x)]^{2}}\right)_{\circ}$ 此值与真实信号的性质有关。在相同真实信号的情况下，信噪比越高，信号质量越高。MATLAB函数调用方法<code>snr (s, n)</code>, <code>s​</code> 为信号, <code>n</code>为误差。</li>
</ul>
<p>在已知噪声的分布类型与相应参数的情况下，直接以将这些噪声特性作为噪声强弱的度量，很多时候会更加可靠。 而信噪比可以作为一种衡量去噪或恢复质量的有效尺度。</p>
<p><strong>例：正弦函数加噪声计算信噪比：</strong></p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">x = <span class="number">0</span>:<span class="number">0.001</span>:<span class="number">2</span>*<span class="built_in">pi</span>;</span><br><span class="line">f = <span class="built_in">sin</span>(x);</span><br><span class="line">f_ = f + normrnd(<span class="number">0</span>, <span class="number">0.1</span>, <span class="number">1</span>, <span class="built_in">length</span>(x));</span><br><span class="line"><span class="built_in">plot</span>(x, f, x, f_);</span><br><span class="line">snr(f, f-f_)    <span class="comment">% 结果为16.6676</span></span><br></pre></td></tr></table></figure>
<p><img src="/posts/Pic/Matlab%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E4%B8%8E%E5%A3%B0%E9%9F%B3%E5%A4%84%E7%90%86/1-1606789967866.jpg" style="zoom:67%;"></p>
<h2 id="数字信号高斯噪声的均值滤波"><a href="#数字信号高斯噪声的均值滤波" class="headerlink" title="数字信号高斯噪声的均值滤波"></a>数字信号高斯噪声的均值滤波</h2><p>因为高斯噪声是0均值的，并且噪声的幅度明显小于信号本身的强度（SNR&gt;10即表明噪声强度不足信号强度的根号十分之一）。故采用简单的均值方法对带噪信号做光滑化处理（也称为<strong>均值滤波</strong>），就可以得到一个近似的恢复信号。</p>
<p><code>f1=smooth(y)</code> 是一种MATLAB自带的五点均值滤波方法，返回值<code>f1</code>为列向量，恢复效果如下图:<code>(SNR=22.3808)</code></p>
<p><img src="/posts/Pic/Matlab%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E4%B8%8E%E5%A3%B0%E9%9F%B3%E5%A4%84%E7%90%86/2.jpg" style="zoom:67%;"></p>
<p>代码为：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">f1 = smooth(f_); f2 = smooth(f1); f3 = smooth(f2);</span><br><span class="line"><span class="built_in">plot</span>(x, f1, x, f2, x, f3);</span><br><span class="line"><span class="built_in">legend</span>(<span class="string">'smooth函数的恢复结果'</span>, <span class="string">'2次smooth的恢复结果'</span>, <span class="string">'3次smooth的恢复结果'</span>)</span><br><span class="line"><span class="built_in">hold</span> off;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>f1=conv(y,ones(1,5)*1/5,&#39;same&#39;)</code> 进行<strong>五点均值滤波</strong>，除边界外与<code>smooth</code>函数效果相同：<code>(SNR=22.3660)</code></li>
<li><code>f2=conv(y,[1/16 1/4 3/8 1/4 1/16],&#39;same&#39;)</code>进行<strong>五点加权均值滤波</strong>，但本例效果一般：<code>(SNR=20.9296)</code></li>
<li><code>f3=conv(y,ones(1,9)*1/9,&#39;same&#39;)</code> 进行<strong>九点均值滤波</strong>，更大的滤波范围改进了恢复效果，但滤波范围过大会导致图像过度平滑、失去应有斜率而失真：<code>(SNR=24.3451)</code></li>
</ul>
<p>恢复效果为：</p>
<p><img src="/posts/Pic/Matlab%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E4%B8%8E%E5%A3%B0%E9%9F%B3%E5%A4%84%E7%90%86/3.jpg" style="zoom:67%;"></p>
<h2 id="傅里叶变换"><a href="#傅里叶变换" class="headerlink" title="傅里叶变换"></a>傅里叶变换</h2><h3 id="连续傅里叶变换"><a href="#连续傅里叶变换" class="headerlink" title="连续傅里叶变换"></a>连续傅里叶变换</h3><p><strong>傅里叶变换</strong>：是傅里叶级数的推广，可以从某种角度上理解成傅里叶级数的“周期”趋于无穷大的极限形式</p>
<ul>
<li><p>傅里叶变换定义为：$F(\omega)=\int_{-\infty}^{+\infty} f(t) \mathrm{e}^{-j \omega t} \mathrm{~d} t,$</p>
<p>其中$j$为虚数单位，另外注意到, $\mathbf{e}^{-j \omega t}=\cos \omega \boldsymbol{t}-\boldsymbol{j} \cdot \sin \omega \boldsymbol{t}$</p>
</li>
<li><p>傅里叶逆变换定义： $\mathrm{f}(\mathrm{t})=\frac{1}{2 \pi} \int_{-\infty}^{+\infty} F(\omega) \mathrm{e}^{j \omega t} \mathrm{~d} \omega$</p>
</li>
<li><p>帕萨瓦尔等式 $\int_{-\infty}^{+\infty}|f(t)|^{2} \mathrm{~d} t=\frac{1}{2 \pi} \int_{-\infty}^{+\infty}|F(\omega)|^{2} \mathrm{~d} \omega$</p>
</li>
</ul>
<p>与傅里叶级数类似，傅里叶变换的意义是进行时频分析, $\boldsymbol{t}$ 为时间, $\omega$ 为频率，傅里叶变换的取值往往决定了信号在什么频率上更强</p>
<p><strong>Matlab函数定义</strong>：</p>
<ul>
<li>函数<code>fourier(ft, t, w)</code> 时间域变量<code>t</code>，频率域变量<code>W</code></li>
<li>函数<code>ifourier (ft, w, t)</code>频率域变量<code>w</code>, 时间域变量<code>t</code></li>
</ul>
<h3 id="离散傅里叶变换"><a href="#离散傅里叶变换" class="headerlink" title="离散傅里叶变换"></a>离散傅里叶变换</h3><p>一维离散傅里叶变换定义为$Y(k) = \sum_{i=1}^n X(i)\text{e}^{\frac{(-2\pi j)(i-1)(k-1)}{n}}, 1\leq k \leq n,$ <code>j</code>为虚数单位。</p>
<p>特别的当 $k=1$ 时, $Y(\mathbf{1})=\sum_{i=1}^{n} X(i)$ 称为离散傅里早变换的<strong>低频系数</strong>，其余系数称为<strong>高频傅里叶系数</strong>。低频系数类似于连续傅里早变换的<code>F(0)</code>，表达了函数的总和。高频系数则在不同程度刻画函数的变化情况。</p>
<blockquote>
<p>注：函数<code>fft(x)</code> 可以利用上式计算出向量X的离散傅里叶变换</p>
</blockquote>
<ul>
<li>离散傅里叶变换是一种从有限长度的离散序列<code>X(i)</code> 到另一种有限长度离散序列<code>Y(k)</code> 的变换。变换的原理事实上是将序列<code>X(i)</code> 假想为了以<code>n</code>为周期的“无限长周期序列”，进而可以利用有限个特定的频率采样完成<code>X(i)</code>的频率表示。</li>
<li>离散傅里叶逆变换定义为$X(i) = \frac1n\sum_{k=1}^n Y(k)\text{e}^{\frac{(2\pi j)(i-1)(k-1)}{n}}, 1\leq i \leq n,$ 这一变换与傅里叶变换完全互逆。MATLAB函数<code>ifft(Y)</code> 可以实现对应的功能</li>
</ul>
<p>下图为前例正弦函数及含噪声的正弦函数的离散傅里叶变换：</p>
<p><img src="/posts/Pic/Matlab%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E4%B8%8E%E5%A3%B0%E9%9F%B3%E5%A4%84%E7%90%86/4.jpg" style="zoom:67%;"></p>
<p>代码为：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="built_in">plot</span>(x, <span class="built_in">abs</span>(fft(f_)), x, <span class="built_in">abs</span>(fft(f)));</span><br><span class="line">ylim([<span class="number">0</span> <span class="number">20</span>])</span><br><span class="line"><span class="built_in">legend</span>(<span class="string">'含噪声的离散傅里叶变换'</span>, <span class="string">'真实信号的离散傅里叶变换'</span>)</span><br></pre></td></tr></table></figure>
<h3 id="利用离散傅里叶变换完成高斯噪声去噪"><a href="#利用离散傅里叶变换完成高斯噪声去噪" class="headerlink" title="利用离散傅里叶变换完成高斯噪声去噪"></a>利用离散傅里叶变换完成高斯噪声去噪</h3><p>算法设计的原理即对含噪信号做离散傅里叶变换，然后仅<strong>保留大于5的系数</strong>，去除其他所有系数，再用离散傅里叶逆变换得到恢复后的数字信号，代码为：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">Ff = fft(f_);</span><br><span class="line">Ff(<span class="built_in">abs</span>(Ff)&lt;<span class="number">5</span>)=<span class="number">0.0</span>;         <span class="comment">%将绝对值小于5的傅里叶系数都设为0.0 </span></span><br><span class="line">f1 = ifft(Ff);</span><br><span class="line"><span class="built_in">plot</span>(x, f_, x, f1);</span><br><span class="line"><span class="built_in">legend</span>(<span class="string">'带噪声函数'</span>, <span class="string">'离散傅里叶变换结果'</span>);</span><br></pre></td></tr></table></figure>
<p><img src="/posts/Pic/Matlab%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E4%B8%8E%E5%A3%B0%E9%9F%B3%E5%A4%84%E7%90%86/5.jpg" style="zoom:67%;"></p>
<h3 id="离散傅里叶变换去噪的局限性"><a href="#离散傅里叶变换去噪的局限性" class="headerlink" title="离散傅里叶变换去噪的局限性"></a>离散傅里叶变换去噪的局限性</h3><p>然而，如果将三角函数进行阶梯函数叠加使其成为<strong>分片光滑函数</strong>，傅里叶变换结合硬阈值（去掉绝对值小于𝝀的系数）算法的效果，要么无法消除噪声，要么会破坏信号信息，导致恢复效果甚至明显不如五点均值的效果</p>
<blockquote>
<p>软阈值算和硬阈值的区别</p>
<ul>
<li><p>硬阈值算子 $T_{\lambda}(y)=\left\{\begin{array}{l}y,|y| \geq \lambda \\ 0,|y|&lt;\lambda\end{array},\right.$ 注意到其绝对值不小于$\lambda$的元素均末发生变化。对y的傅里早系数做硬阈值算子处理相当于求解问题$\operatorname{min}$ $_{x} \frac{1}{2}|x-y|_{2}^{2}+\frac{1}{2} \lambda^{2}|\widehat{x}|_{0},$ 其中, $\widehat{x}$ 表示 $x$ 的离散傅里叶变换, $|\boldsymbol{t}|_{0}$ 表示 $\boldsymbol{t}$ 的非零元素的个数。 </p>
</li>
<li><p>软阈值算子 $T_{\lambda}(y)=\operatorname{sign}(y) \cdot \max (|y|-\lambda, 0)$ ，对 $y$ 的傅里叶系数做软阈值算子处理相当于求解问题$\min _{x} \frac{1}{2}|x-y|_{2}^{2}+\lambda|\hat{x}|_{1}$</p>
</li>
</ul>
</blockquote>
<p><strong>软阈值算法完成高斯噪声去噪</strong></p>
<p>对于前例，软阈值算法可以获得比硬阈值算法更好的效果，但是仍然不如五点均值滤波，原因是<strong>函数并不具备全局光滑性或周期性</strong>，导致傅里叶系数的稀疏度不足。代码如下：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">clear,close all,rng default</span><br><span class="line">x=<span class="number">0</span>:<span class="built_in">pi</span>/<span class="number">50</span>:<span class="number">2</span>*<span class="built_in">pi</span>;f = <span class="built_in">sin</span>(x);</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:<span class="number">5</span>         <span class="comment">%强行设置若干处阶梯越阶，构造分片光滑函数 </span></span><br><span class="line">    f(<span class="built_in">i</span>*<span class="number">20</span><span class="number">-19</span>:<span class="built_in">i</span>*<span class="number">20</span>)=f(<span class="built_in">i</span>*<span class="number">20</span><span class="number">-19</span>:<span class="built_in">i</span>*<span class="number">20</span>)+(<span class="number">5</span>-<span class="built_in">i</span>);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">y = f + <span class="built_in">randn</span>(<span class="built_in">size</span>(x))*<span class="number">0.5</span>;</span><br><span class="line">Ff = fft(y);</span><br><span class="line">Ff = <span class="built_in">sign</span>(Ff).*<span class="built_in">max</span>(<span class="built_in">abs</span>(Ff)<span class="number">-5</span>,<span class="number">0</span>);</span><br><span class="line"><span class="comment">%将绝对值小于5的傅里叶系数都设为0.0，模大于5的系数幅角不变，模减5</span></span><br><span class="line"></span><br><span class="line">f1 = ifft(Ff);</span><br><span class="line">snr(f,f1-f)                <span class="comment">%结果的SNR=16.9631</span></span><br></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>数字信号处理的去噪问题往往种类繁多，最佳的去噪方法也往往不是唯一的，既与噪声类型和强度有关，也与目标函数（真实信号值）的函数特性有关。</p>
<ul>
<li><p>常见的噪声类型除高斯噪声外，还有<strong>冲击噪声</strong>（随机的部分采样值出现与真实信号值无关的错误函数值），通常可以使用中值滤波器进行噪点判别或直接调整。</p>
</li>
<li><p><strong>泊松噪声</strong>是信号处理较难解决的非加性噪声之一，在一个较大的假想最大值的基础上，在每点设$\lambda = k \cdot$ 真实值，$k&gt;0$为比例因子，然后基于参数（期望）为$\lambda$的泊松分布下获取一个整数值$Y$，带噪信号的该点对应信号值为$\frac Yk$。容易发现$k$越小时，泊松噪声造成的影响越大。</p>
</li>
<li><p><strong>傅里叶变换对于三角函数去噪效果极佳</strong>，因为三角函数在此变换系数满足完美稀疏，对于分片光滑函数效果则一般，根据目标函数特性选择<strong>合适变换及约束（正则化）</strong>方法很关键</p>
</li>
</ul>
<h1 id="声音信号处理"><a href="#声音信号处理" class="headerlink" title="声音信号处理"></a>声音信号处理</h1><ul>
<li>读取音乐的函数为<code>audioinfo</code>，返回值为<code>y</code>与<code>Fs</code>，其中<code>Fs</code>为一秒钟内信号读取次数，在这里（大多数音乐文件中）<code>Fs</code>为14400</li>
<li>播放音乐的函数为<code>sound</code>，<code>sound</code>函数中可带参数<code>Fs</code>，可以利用这个参数调节音乐的频率，如下例中将<code>Fs</code>除以$\sqrt{2}$后会发现音乐明显频率降低了。</li>
</ul>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">info = audioinfo(<span class="string">'Week14音乐识别文件库\Music1.mp3'</span>);</span><br><span class="line">[y, Fs]= audioread(<span class="string">'Week14音乐识别文件库\Music1.mp3'</span>);</span><br><span class="line">ys = y(<span class="number">1</span>:<span class="number">11</span>*Fs, <span class="number">1</span>);</span><br><span class="line">sound(ys, Fs);</span><br><span class="line">sound(ys, Fs/<span class="built_in">sqrt</span>(<span class="number">2</span>));</span><br><span class="line"><span class="built_in">plot</span>(<span class="built_in">abs</span>(fft(ys)));</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>matlab/Matlab多项式运算与数据可视化</title>
    <url>/posts/af683816.html</url>
    <content><![CDATA[<h1 id="Matlab多项式表示与运算"><a href="#Matlab多项式表示与运算" class="headerlink" title="Matlab多项式表示与运算"></a>Matlab多项式表示与运算</h1><p>MATLAB习惯将降幂排列的多项式 $\boldsymbol{a}(\boldsymbol{x})=\boldsymbol{a}_{1} \boldsymbol{x}^{\boldsymbol{n}}+\boldsymbol{a}_{2} \boldsymbol{x}^{\boldsymbol{n}-\mathbf{1}}+$$\cdots+a_{n} x+a_{n+1}$ 存储为系数行向量 $a=\left[a_{1}, a_{2}, \ldots, a_{n+1}\right]$</p>
<ul>
<li>多项式的乘法，基于MATLAB的多项式系数定义，有:</li>
</ul>
<script type="math/tex; mode=display">
\begin{array}{l}
\sum_{i=1}^{m+1} a_{i} x^{m+1-i} \cdot \sum_{j=1}^{n+1} b_{j} x^{n+1-j} \\
=\sum_{k=2}^{m+n+2}\left(\sum_{i=\max (1, k-n-1)}^{\min (m+1, k-1)} a_{i} b_{k-i}\right) x^{m+n+2-k}
\end{array}</script><p>注意：乘积多项式的系数恰为两个原始系数的卷积</p>
<h2 id="Matlab函数"><a href="#Matlab函数" class="headerlink" title="Matlab函数"></a>Matlab函数</h2><ul>
<li><code>c=conv (a,b)</code>：一种快速获取多项式相乘系数的方法 </li>
<li><code>[q,r]=deconv(b,a)</code> ：多项式带余除法, <code>q</code>为商，<code>r</code>为余式</li>
<li><p><code>[r,p,k]=residue(b,a)</code>：表示 $\frac{b(x)}{a(x)}=\sum_{i=1}^{n} \frac{r_{i}}{x-p_{i}}+\boldsymbol{k}(\boldsymbol{x})$<br>其中<code>r</code>为留数向量,<code>p</code>为极点向量，<code>k</code>为余式系数行向量</p>
</li>
<li><p><code>r=roots(a)</code>：求多项式<code>a(x)</code>的所有根（含重根和任意复根），注意到该函数返回的根用列向量存储。</p>
</li>
<li><p><code>a=poly(r)</code>：当<code>r</code>为一个行向量时，<code>a</code>为根等于<code>r</code>的多项式（即函数<code>roots</code>的逆运算）；而当<code>r</code>为方阵时，<code>poly</code>函数将获得<code>r</code>的特征多项式（用于计算特征值）</p>
</li>
<li><p><code>V=polyval(p,X)</code>：<code>p</code>为一个多项式的系数行向量，<code>X</code>可以是任意规模的矩阵，此函数将<code>X</code>每一个元素代入<code>p(x)</code>并获得代入后的数值矩阵<code>p(X)</code></p>
</li>
<li><p><code>V=polyvalm(p,X)</code>：其含义略有不同，此函数意味计算以矩阵<code>X</code>为整体的多项式代入的结果矩阵，即</p>
<script type="math/tex; mode=display">V = p_1X^n+p_2X^{n-1}+...+p_nX+p_{n+1}I</script></li>
<li><p><code>poly2str(a,&#39;s&#39;)</code>：以<code>a</code>向量元素为系数，<code>s</code>为自变量生成多项式字符串，按降幂顺序排列。</p>
</li>
</ul>
<h2 id="实例应用"><a href="#实例应用" class="headerlink" title="实例应用"></a>实例应用</h2><p><strong>例：多项式带余除法</strong></p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">format <span class="built_in">rat</span></span><br><span class="line">p1 = conv([<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>], conv([<span class="number">1</span>, <span class="number">4</span>], [<span class="number">1</span>, <span class="number">1</span>]));</span><br><span class="line">p2 = [<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>];</span><br><span class="line">[q, r] = deconv(p1, p2);</span><br><span class="line">cq=<span class="string">'商多项式为  '</span>; cr=<span class="string">'余多项式为  '</span>;</span><br><span class="line"><span class="built_in">disp</span>([cq,poly2str(q,<span class="string">'s'</span>)]),<span class="built_in">disp</span>([cr,poly2str(r,<span class="string">'s'</span>)])</span><br><span class="line">qp2=conv(q,p2);				<span class="comment">%回代pp1=商X分母+余式</span></span><br><span class="line">pp1=qp2+r; </span><br><span class="line">pp1==p1</span><br></pre></td></tr></table></figure>
<p><strong>例：矩阵的特征多项式与特征根</strong></p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">format short</span><br><span class="line">A=[<span class="number">11</span> <span class="number">12</span> <span class="number">13</span>;<span class="number">14</span> <span class="number">15</span> <span class="number">16</span>;<span class="number">17</span> <span class="number">18</span> <span class="number">19</span>];		</span><br><span class="line">PA=poly(A);  					</span><br><span class="line">PPA=poly2str(PA,<span class="string">'s'</span>);</span><br><span class="line">s = eig(A);</span><br><span class="line">r = roots(PA);</span><br><span class="line">n = <span class="built_in">length</span>(PA);</span><br><span class="line">AA = <span class="built_in">diag</span>(<span class="built_in">ones</span>(<span class="number">1</span>, n<span class="number">-2</span>, class(PA)), <span class="number">-1</span>);</span><br><span class="line">AA(<span class="number">1</span>,:) = -PA(<span class="number">2</span>:n) ./ PA(<span class="number">1</span>);			<span class="comment">%第一行减掉了特征多项式后三个系数</span></span><br><span class="line">sr = eig(AA);							<span class="comment">%该矩阵AA的特征多项式与PA相同，特征值也相同</span></span><br></pre></td></tr></table></figure>
<p>我们可以看到<code>PA</code>的结果为<code>1.0000  -45.0000  -18.0000   -0.0000</code>，这是该矩阵的特征多项式，即$\lambda^3-45\lambda^{2}-18\lambda = 0$，打印<code>PPA</code>显示特征多项式的字符串结果：<code>s^3 - 45 s^2 - 18 s - 9.8142e-15&#39;</code>，最后一项为机器误差可以忽略。由高等代数的知识我们知道该特征多项式的根即为<code>eig</code>的打印结果，因此我们可以发现<code>s</code>与<code>r</code>是相同的。</p>
<p><code>AA</code>为用长度为<code>n-2</code>的向量生成一个向下平移一行的<code>(n-1)×(n-1)</code>维矩阵，打印结果为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0   0   0</span><br><span class="line">1   0   0</span><br><span class="line">0   1   0</span><br></pre></td></tr></table></figure>
<p><strong>例：构造特征根的多项式</strong></p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">R=[<span class="number">-0.5</span>,<span class="number">-0.3</span>+<span class="number">0.4</span>*<span class="built_in">i</span>,<span class="number">-0.3</span><span class="number">-0.4</span>*<span class="built_in">i</span>];	<span class="comment">%三个特征根，复根需有共轭复数对</span></span><br><span class="line">P=poly(R)				<span class="comment">%生成对应的多项式</span></span><br><span class="line">PR=<span class="built_in">real</span>(P)</span><br><span class="line">PPR=poly2str(PR,<span class="string">'x'</span>)</span><br></pre></td></tr></table></figure>
<p><code>PPR</code>的打印结果为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PPR &#x3D;</span><br><span class="line">   x^3 + 1.1 x^2 + 0.55 x + 0.125</span><br></pre></td></tr></table></figure>
<p><strong>例：<code>polyval</code>与<code>polyvalm</code>函数</strong></p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">clear</span><br><span class="line">p=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>];				</span><br><span class="line">poly2str(p,<span class="string">'x'</span>)</span><br><span class="line">X=[<span class="number">1</span>,<span class="number">2</span>;<span class="number">3</span>,<span class="number">4</span>];</span><br><span class="line">va = X.^<span class="number">2</span>+<span class="number">2</span>*X+<span class="number">3</span>                 <span class="comment">%对应元素代入多项式p(x)</span></span><br><span class="line">Va = polyval(p,X)               <span class="comment">%等价的MATLAB函数polyval</span></span><br><span class="line"></span><br><span class="line">vm = X^<span class="number">2</span>+<span class="number">2</span>*X+<span class="number">3</span>*<span class="built_in">eye</span>(<span class="number">2</span>)           <span class="comment">%将矩阵整体代入p(x)</span></span><br><span class="line">Vm = polyvalm(p,X)              <span class="comment">%等价的MATLAB函数</span></span><br><span class="line"></span><br><span class="line">cp=poly(X);</span><br><span class="line">poly2str(cp,<span class="string">'x'</span>)				<span class="comment">%获取并显示X的特征多项式</span></span><br><span class="line">cpXa = polyval(cp,X)			<span class="comment">%代入X的元素，得到结果矩阵</span></span><br><span class="line">cpX = polyvalm(cp,X)			<span class="comment">%整体代入验证H-C定理</span></span><br></pre></td></tr></table></figure>
<h1 id="MATLAB有限长向量卷积函数conv"><a href="#MATLAB有限长向量卷积函数conv" class="headerlink" title="MATLAB有限长向量卷积函数conv"></a>MATLAB有限长向量卷积函数<code>conv</code></h1><p>已知 $a=\left[a_{1}, a_{2}, \ldots, a_{n}\right], b=\left[b_{1}, b_{2}, \ldots, b_{m}\right],$ 类似于前面多项式乘法的例子, $\operatorname{conv}(a, b)$ 函数将返回 $a * b$ 的向量, 即</p>
<script type="math/tex; mode=display">
(\boldsymbol{a} * \boldsymbol{b})_{\boldsymbol{k}}=\sum_{i=1}^{k-\mathbf{1}} \boldsymbol{a}_{i} \boldsymbol{b}_{\boldsymbol{k}-i}, 2 \leq \boldsymbol{k} \leq \boldsymbol{m}+\boldsymbol{n}</script><p>这里补充定义 $\forall i&gt;n, a_{i}=\mathbf{0}, \forall j&gt;m, b_{j}=0$</p>
<ul>
<li><code>conv(a,b,&#39;same&#39;)</code>将返回一个长度等于 $n$ 的卷积结果, 即截取上述卷积结果中间<code>n</code>个元素的结果, 常用于信号或图像处理问题。若3个选2个，则默认选择后两个。 </li>
<li><code>conv(a,b,&#39;valid&#39;)</code>将返回一个长度等于 $n-m+1$ 的卷积 结果, 即仅包含 $b$ 的全部元素参与卷积的中间项。</li>
<li><code>deconv</code>为反卷积函数。卷积运算之前对于边界条件的处理有时需要跟实际问题相结合。具体方法有0填充（默认），对称延拓，复制延拓，周期延拓等。</li>
</ul>
<p>例：</p>
<script type="math/tex; mode=display">\text { 有序列 } A(n)=\left\{\begin{array}{ll}
1 & n=3,4, \cdots, 12 \\
0 & \text { else }
\end{array} \quad \text { 和 } \quad B(n)=\left\{\begin{array}{ll}
1 & n=2,3, \cdots, 9 \\
0 & \text { else }
\end{array},\right.\right. \text { 求这两个序列的卷积。 }</script><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="comment">% 方法1：</span></span><br><span class="line">N1=<span class="number">3</span>;N2=<span class="number">12</span>;a=<span class="built_in">ones</span>(<span class="number">1</span>,N2+<span class="number">1</span>);a(<span class="number">1</span>:N1)=<span class="number">0</span>;<span class="comment">%相同的向量定义，用0填充左侧</span></span><br><span class="line">M1=<span class="number">2</span>;M2=<span class="number">9</span>;b=<span class="built_in">ones</span>(<span class="number">1</span>,M2+<span class="number">1</span>);b(<span class="number">1</span>:M1)=<span class="number">0</span>;	</span><br><span class="line">c=conv(a,b);				   <span class="comment">%直接conv函数计算</span></span><br><span class="line">kc=<span class="number">0</span>:(N2+M2);</span><br><span class="line"></span><br><span class="line"><span class="comment">% 方法2</span></span><br><span class="line">N1=<span class="number">3</span>;N2=<span class="number">12</span>;M1=<span class="number">2</span>;M2=<span class="number">9</span>;</span><br><span class="line">A=<span class="built_in">ones</span>(<span class="number">1</span>,(N2-N1+<span class="number">1</span>));	B=<span class="built_in">ones</span>(<span class="number">1</span>,(M2-M1+<span class="number">1</span>));	<span class="comment">%去掉左边的0，与前法类似</span></span><br><span class="line">C=conv(A,B);					</span><br><span class="line">Nc1=N1+M1;Nc2=N2+M2;				<span class="comment">%左右端点下标计算</span></span><br><span class="line">KC=Nc1:Nc2;</span><br><span class="line"></span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>),stem(kc,c), text(<span class="number">20</span>,<span class="number">6</span>,<span class="string">'0 起点法'</span>)   <span class="comment">%方法1直接绘图</span></span><br><span class="line">CC=[<span class="built_in">zeros</span>(<span class="number">1</span>,KC(<span class="number">1</span>)),C];	<span class="comment">%方法2的结果左侧填充5个0</span></span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>),stem(kc,CC),text(<span class="number">18</span>,<span class="number">6</span>,<span class="string">'非平凡区间法'</span>)</span><br><span class="line">xlabel(<span class="string">'n'</span>)  			<span class="comment">%注：计算单点的卷积值使用sum函数速度更快</span></span><br></pre></td></tr></table></figure>
<p><img src="/posts/Pic/Matlab%E5%A4%9A%E9%A1%B9%E5%BC%8F%E8%BF%90%E7%AE%97%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/1.png" style="zoom:75%;"></p>
]]></content>
  </entry>
  <entry>
    <title>Oracle（一）简单入门使用</title>
    <url>/posts/168a1497.html</url>
    <content><![CDATA[<p>有时候大家在登录sqlplus的时候会出现乱码的问题，一般可以使用<code>chcp 936</code>修改编码，如此即可正常显示</p>
<p>安装好Oracle后，我们该怎么登录呢？</p>
<ul>
<li>一种方式是在命令行使用<code>sqlplus /nolog</code>模式登入，继续输入<code>conn /as sysdba</code>，再输入<code>alter user [用户名] identified by 密码;</code>。修改成功后，会有上图“用户已更改”的提示，再次登录时用自己设定的密码即可。</li>
</ul>
<p>创建用户时如果直接使用<code>CREATE USER CHENK IDENTIFIED BY chenk;</code>会报错，在Oracle11g中我们应该加上<code>C##</code>才能创建用户，即：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> C<span class="comment">##CHENK IDENTIFIED BY chenk;</span></span><br></pre></td></tr></table></figure>
<p>同样，我们在授权时也需加上<code>C##</code>，即：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">GRANT</span> <span class="keyword">CONNECT</span>, <span class="keyword">RESOURCE</span>, DBA <span class="keyword">TO</span> C<span class="comment">##CHENK;</span></span><br></pre></td></tr></table></figure>
<p>我们若想登录该账号，只需使用<code>CONNECT</code>语句即可：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">CONNECT C<span class="comment">##CHENK @orcl</span></span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
</search>
