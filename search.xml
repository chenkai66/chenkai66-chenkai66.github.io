<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Python深度学习（二）深度学习用于计算机视觉</title>
    <url>/posts/1fc7d624.html</url>
    <content><![CDATA[<p>本节将介绍卷积神经网络，也叫<code>convnet</code>，它是计算机视觉应用几乎都在使用的一种深度学习模型。你将学到将卷积神经网络应用于图像分类问题，特别是那些训练数据集较小的问题。如果你工作的地方并非大型科技公司，这也将是你最常见的使用场景。</p>
<h1 id="一、卷积神经网络简介"><a href="#一、卷积神经网络简介" class="headerlink" title="一、卷积神经网络简介"></a>一、卷积神经网络简介</h1><p>我们将深入讲解卷积神经网络的原理，以及它在计算机视觉任务上为什么如此成功。但在此之前，我们先来看一个简单的卷积神经网络示例，即使用卷积神经网络对MNIST 数字进行分类，这个任务我们在第2 章用密集连接网络做过（当时的测试精度为97.8%）。虽然本例中的卷积神经网络很简单，但其精度肯定会超过前面的密集连接网络。</p>
<p>下列代码将会展示一个简单的卷积神经网络。它是Conv2D 层和MaxPooling2D 层的堆叠，很快你就会知道这些层的作用。</p>
<h2 id="1-实例化一个小型的卷积神经网络"><a href="#1-实例化一个小型的卷积神经网络" class="headerlink" title="1. 实例化一个小型的卷积神经网络"></a>1. 实例化一个小型的卷积神经网络</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>, input_shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br></pre></td></tr></table></figure>
<pre><code>Using TensorFlow backend.
</code></pre><p>重要的是，卷积神经网络接收形状为<code>(image_height, image_width, image_channels)</code>的输入张量（不包括批量维度）。本例中设置卷积神经网络处理大小为(28, 28, 1) 的输入张量，这正是MNIST 图像的格式。我们向第一层传入参数<code>input_shape=(28, 28, 1)</code> 来完成此设置。</p>
<p>我们来看一下目前卷积神经网络的架构。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_1&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     
=================================================================
Total params: 55,744
Trainable params: 55,744
Non-trainable params: 0
_________________________________________________________________
</code></pre><p>可以看到，每个Conv2D 层和MaxPooling2D 层的输出都是一个形状为(height, width,channels) 的3D 张量。宽度和高度两个维度的尺寸通常会随着网络加深而变小，通道数量由传<br>入Conv2D 层的第一个参数所控制（32 或64）。</p>
<p>下一步是将最后的输出张量［大小为(3, 3, 64)］输入到一个密集连接分类器网络中，即Dense 层的堆叠，你已经很熟悉了。这些分类器可以处理1D 向量，而当前的输出是3D 张量。首先，我们需要将3D 输出展平为1D，然后在上面添加几个Dense 层。</p>
<h2 id="2-在卷积神经网络上添加分类器"><a href="#2-在卷积神经网络上添加分类器" class="headerlink" title="2. 在卷积神经网络上添加分类器"></a>2. 在卷积神经网络上添加分类器</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>))</span><br></pre></td></tr></table></figure>
<p>我们将进行10 类别分类，最后一层使用带10 个输出的softmax 激活。现在网络的架构如下。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_1&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     
_________________________________________________________________
flatten_1 (Flatten)          (None, 576)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 64)                36928     
_________________________________________________________________
dense_2 (Dense)              (None, 10)                650       
=================================================================
Total params: 93,322
Trainable params: 93,322
Non-trainable params: 0
_________________________________________________________________
</code></pre><p>如你所见，在进入两个Dense层之前，形状(3, 3, 64) 的输出被展平为形状(576,) 的向量。</p>
<p>下面我们在MNIST数字图像上训练这个卷积神经网络。我们将复用MNIST示例中的很多代码。</p>
<h2 id="3-在MINST图像上训练卷积神经网络"><a href="#3-在MINST图像上训练卷积神经网络" class="headerlink" title="3. 在MINST图像上训练卷积神经网络"></a>3. 在MINST图像上训练卷积神经网络</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> to_categorical</span><br><span class="line">(train_images, train_labels), (test_images, test_labels) = mnist.load_data()</span><br><span class="line">train_images = train_images.reshape((<span class="number">60000</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))</span><br><span class="line">train_images = train_images.astype(<span class="string">'float32'</span>) / <span class="number">255</span></span><br><span class="line">test_images = test_images.reshape((<span class="number">10000</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))</span><br><span class="line">test_images = test_images.astype(<span class="string">'float32'</span>) / <span class="number">255</span></span><br><span class="line">train_labels = to_categorical(train_labels)</span><br><span class="line">test_labels = to_categorical(test_labels)</span><br><span class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>,</span><br><span class="line">            loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">            metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">model.fit(train_images, train_labels, epochs=<span class="number">5</span>, batch_size=<span class="number">64</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1/5
60000/60000 [==============================] - 25s 419us/step - loss: 0.1652 - accuracy: 0.9488
Epoch 2/5
60000/60000 [==============================] - 26s 429us/step - loss: 0.0458 - accuracy: 0.9864
Epoch 3/5
60000/60000 [==============================] - 24s 400us/step - loss: 0.0320 - accuracy: 0.9897
Epoch 4/5
60000/60000 [==============================] - 24s 396us/step - loss: 0.0247 - accuracy: 0.9924
Epoch 5/5
60000/60000 [==============================] - 24s 393us/step - loss: 0.0196 - accuracy: 0.9940
</code></pre><p>我们在测试数据上对模型进行评估。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">test_loss, test_acc = model.evaluate(test_images, test_labels)</span><br><span class="line">test_acc</span><br></pre></td></tr></table></figure>
<pre><code>10000/10000 [==============================] - 1s 112us/step


0.9923999905586243
</code></pre><p>密集连接网络的测试精度为97.8%，但这个简单卷积神经网络的测试精度达到了99.1%，我们将错误率降低了68%（相对比例）。相当不错！与密集连接模型相比，为什么这个简单卷积神经网络的效果这么好？要回答这个问题，我们来深入了解Conv2D 层和MaxPooling2D 层的作用。</p>
<h2 id="4-卷积神经网络"><a href="#4-卷积神经网络" class="headerlink" title="4. 卷积神经网络"></a>4. 卷积神经网络</h2><p>密集连接层和卷积层的根本区别在于，Dense 层从输入特征空间中学到的是全局模式（比如对于MNIST 数字，全局模式就是涉及所有像素的模式），而卷积层学到的是局部模式。对于图像来说，学到的就是在输入图像的二维小窗口中发现的模式。在上面的例子中，这些窗口的大小都是3×3。</p>
<center>
    <img src="\Pic\DeepLearning_Pic\conv_1.png" width="300" height="300" alt="图像可以被分解为局部模式，如边缘、纹理等" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图像可以被分解为局部模式，如边缘、纹理等</div>
</center>

<p>这个重要特性使卷积神经网络具有以下两个有趣的性质。</p>
<ul>
<li>卷积神经网络学到的模式具有平移不变性（translation invariant）。卷积神经网络在图像右下角学到某个模式之后，它可以在任何地方识别这个模式，比如左上角。对于密集连接网络来说，如果模式出现在新的位置，它只能重新学习这个模式。这使得卷积神经网络在处理图像时可以高效利用数据（因为视觉世界从根本上具有平移不变性），它只需要更少的训练样本就可以学到具有泛化能力的数据表示。</li>
<li>卷积神经网络可以学到模式的空间层次结构（spatial hierarchies of patterns）。第一个卷积层将学习较小的局部模式（比如边缘），第二个卷积层将学习由第一层特征组成的更大的模式，以此类推。这使得卷积神经网络可以有效地学习越来越复杂、越来越抽象的视觉概念（因为视觉世界从根本上具有空间层次结构）。</li>
</ul>
<p>对于包含两个空间轴（高度和宽度）和一个深度轴（也叫通道轴）的3D 张量，其卷积也叫特征图（feature map）。对于RGB 图像，深度轴的维度大小等于3，因为图像有3 个颜色通道：红色、绿色和蓝色。对于黑白图像（比如MNIST 数字图像），深度等于1（表示灰度等级）。卷积运算从输入特征图中提取图块，并对所有这些图块应用相同的变换，生成输出特征图（output feature map）。该输出特征图仍是一个3D 张量，具有宽度和高度，其深度可以任意取值，因为输出深度是层的参数，深度轴的不同通道不再像RGB 输入那样代表特定颜色，而是代表过滤器（filter）。过滤器对输入数据的某一方面进行编码，比如，单个过滤器可以从更高层次编码这样一个概念：“输入中包含一张脸。”</p>
<center>
    <img src="\Pic\DeepLearning_Pic\cat.png" width="300" height="300" alt="cat" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">视觉世界形成了视觉模块的空间层次结构：超局部的边缘组合成局部的对象，比如眼睛或耳朵，这些局部对象又组合成高级概念，比如“猫”</div>
</center>

<p>在MNIST示例中，第一个卷积层接收一个大小为<code>(28, 28, 1)</code>的特征图，并输出一个大小为<code>(26, 26, 32)</code>的特征图，即它在输入上计算32个过滤器。对于这32个输出通道，每个通道都包含一个26×26的数值网格，它是过滤器对输入的响应图（response map），表示这个过滤器模式在输入中不同位置的响应。这也是特征图这一术语的含义：深度轴的每个维度都是一个特征（或过滤器），而2D 张量<code>output[:, :, n]</code>是这个过滤器在输入上的响应的二维空间图（map）。</p>
<center>
    <img src="\Pic\DeepLearning_Pic\响应图.png" width="300" height="300" alt="响应图" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">响应图的概念：某个模式在输入中的不同位置是否存在的二维图</div>
</center>

<p>卷积由以下两个关键参数所定义：</p>
<ul>
<li>从输入中提取的图块尺寸：这些图块的大小通常是 3×3 或 5×5。本例中为 3×3，这是很常见的选择。</li>
<li>输出特征图的深度：卷积所计算的过滤器的数量。本例第一层的深度为32，最后一层的深度是64。</li>
</ul>
<p>对于Keras 的Conv2D 层，这些参数都是向层传入的前几个参数：<code>Conv2D(output_depth,(window_height, window_width))</code>。</p>
<p>卷积的工作原理：在3D 输入特征图上滑动（slide）这些3×3 或5×5 的窗口，在每个可能的位置停止并提取周围特征的3D图块［形状为<code>(window_height, window_width, input_depth)</code>］。然后每个3D 图块与学到的同一个权重矩阵［叫作卷积核（convolution kernel）］做张量积，转换成形状为<code>(output_depth,)</code> 的1D 向量。然后对所有这些向量进行空间重组，使其转换为形状为<code>(height, width, output_depth)</code>的3D 输出特征图。输出特征图中的每个空间位置都对应于输入特征图中的相同位置（比如输出的右下角包含了输入右下角的信息）。举个例子，利用3×3的窗口，向量<code>output[i, j, :]</code>来自3D 图块<code>input[i-1:i+1,j-1:j+1, :]</code>。整个过程详见下图：</p>
<center>
    <img src="\Pic\DeepLearning_Pic\卷积的工作原理.png" width="300" height="300" alt="卷积的工作原理" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">卷积的工作原理</div>
</center>

<p>注意，输出的宽度和高度可能与输入的宽度和高度不同，不同的原因可能有两点。</p>
<ul>
<li>边界效应，可以通过对输入特征图进行填充来抵消。</li>
<li>使用了步幅（stride），稍后会给出其定义。</li>
</ul>
<h2 id="5-最大池化运算"><a href="#5-最大池化运算" class="headerlink" title="5. 最大池化运算"></a>5. 最大池化运算</h2><p>在卷积神经网络示例中，你可能注意到，在每个MaxPooling2D层之后，特征图的尺寸都会减半。例如，在第一个MaxPooling2D层之前，特征图的尺寸是26×26，但最大池化运算将其减半为13×13。这就是最大池化的作用：<strong>对特征图进行下采样，与步进卷积类似。最大池化是从输入特征图中提取窗口，并输出每个通道的最大值。</strong>它的概念与卷积类似，但是最大池化使用硬编码的<code>max</code>张量运算对局部图块进行变换，而不是使用学到的线性变换（卷积核）。最大池化与卷积的最大不同之处在于，最大池化通常使用2×2的窗口和步幅2，其目的是将特征图下采样2倍。与此相对的是，卷积通常使用3×3 窗口和步幅1。为什么要用这种方式对特征图下采样？为什么不删除最大池化层，一直保留较大的特征图？我们来这么做试一下。这时模型的卷积基（convolutional base）如下所示。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model_no_max_pool = models.Sequential()</span><br><span class="line">model_no_max_pool.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>, input_shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)))</span><br><span class="line">model_no_max_pool.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model_no_max_pool.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model_no_max_pool.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_2&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 24, 24, 64)        18496     
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 22, 22, 64)        36928     
=================================================================
Total params: 55,744
Trainable params: 55,744
Non-trainable params: 0
_________________________________________________________________
</code></pre><p>这种架构有什么问题？有如下两点问题：</p>
<ul>
<li>这种架构不利于学习特征的空间层级结构。第三层的 3×3 窗口中只包含初始输入的 7×7 窗口中所包含的信息。卷积神经网络学到的高级模式相对于初始输入来说仍然很小，这可能不足以学会对数字进行分类（你可以试试仅通过7 像素×7 像素的窗口观察图像来识别其中的数字）。我们需要让最后一个卷积层的特征包含输入的整体信息。</li>
<li>最后一层的特征图对每个样本共有 22×22×64=30 976 个元素。这太多了。如果你将其展平并在上面添加一个大小为512 的Dense 层，那一层将会有1580 万个参数。这对于这样一个小模型来说太多了，会导致严重的过拟合。</li>
</ul>
<p>简而言之，使用下采样的原因，一是减少需要处理的特征图的元素个数，二是通过让连续卷积层的观察窗口越来越大（即窗口覆盖原始输入的比例越来越大），从而引入空间过滤器的层级结构。</p>
<p>注意，最大池化不是实现这种下采样的唯一方法。你已经知道，还可以在前一个卷积层中使用步幅来实现。此外，你还可以使用平均池化来代替最大池化，其方法是将每个局部输入图块变换为取该图块各通道的平均值，而不是最大值。但最大池化的效果往往比这些替代方法更好。</p>
<p>简而言之，原因在于特征中往往编码了某种模式或概念在特征图的不同位置是否存在（因此得名特征图），而观察不同特征的最大值而不是平均值能够给出更多的信息。因此，最合理的子采样策略是<strong>首先生成密集的特征图（通过无步进的卷积），然后观察特征每个小图块上的最大激活</strong>，而不是查看输入的稀疏窗口（通过步进卷积）或对输入图块取平均，因为后两种方法可能导致错过或淡化特征是否存在的信息。</p>
<p>现在你应该已经理解了卷积神经网络的基本概念，即特征图、卷积和最大池化，并且也知道如何构建一个小型卷积神经网络来解决简单问题，比如MNIST 数字分类。下面我们将介绍更加实用的应用。</p>
<h1 id="二、在小型数据集上从头开始训练一个卷积神经网络"><a href="#二、在小型数据集上从头开始训练一个卷积神经网络" class="headerlink" title="二、在小型数据集上从头开始训练一个卷积神经网络"></a>二、在小型数据集上从头开始训练一个卷积神经网络</h1><p>使用很少的数据来训练一个图像分类模型，这是很常见的情况，如果你要从事计算机视觉方面的职业，很可能会在实践中遇到这种情况。“很少的”样本可能是几百张图像，也可能是几万张图像。来看一个实例，我们将重点讨论猫狗图像分类，数据集中包含4000 张猫和狗的图像（2000 张猫的图像，2000 张狗的图像）。我们将2000 张图像用于训练，1000 张用于验证，1000张用于测试。</p>
<p>本节将介绍解决这一问题的基本策略，即使用已有的少量数据从头开始训练一个新模型。首先，在2000 个训练样本上训练一个简单的小型卷积神经网络，不做任何正则化，为模型目标设定一个基准。这会得到71% 的分类精度。此时主要的问题在于过拟合。然后，我们会介绍数据增强（data augmentation），它在计算机视觉领域是一种非常强大的降低过拟合的技术。使用数据增强之后，网络精度将提高到82%。随后我们会介绍将深度学习应用于小型数据集的另外两个重要技巧：用预训练的网络做特征提取（得到的精度范围在90%~96%），对预训练的网络进行微调（最终精度为97%）。总而言之，这三种策略——从头开始训练一个小型模型、使用预训练的网络做特征提取、对预训练的网络进行微调——构成了你的工具箱，未来可用于解决小型数据集的图像分类问题。</p>
<h2 id="1-深度学习与小数据问题的相关性"><a href="#1-深度学习与小数据问题的相关性" class="headerlink" title="1. 深度学习与小数据问题的相关性"></a>1. 深度学习与小数据问题的相关性</h2><p>有时你会听人说，仅在有大量数据可用时，深度学习才有效。这种说法部分正确：深度学习的一个基本特性就是能够独立地在训练数据中找到有趣的特征，无须人为的特征工程，而这只在拥有大量训练样本时才能实现。对于输入样本的维度非常高（比如图像）的问题尤其如此。</p>
<p>但对于初学者来说，所谓“大量”样本是相对的，即相对于你所要训练网络的大小和深度而言。只用几十个样本训练卷积神经网络就解决一个复杂问题是不可能的，但如果模型很小，并做了很好的正则化，同时任务非常简单，那么几百个样本可能就足够了。由于卷积神经网络学到的是局部的、平移不变的特征，它对于感知问题可以高效地利用数据。虽然数据相对较少，但在非常小的图像数据集上从头开始训练一个卷积神经网络，仍然可以得到不错的结果，而且无须任何自定义的特征工程。</p>
<p>此外，深度学习模型本质上具有高度的可复用性，比如，已有一个在大规模数据集上训练的图像分类模型或语音转文本模型，你只需做很小的修改就能将其复用于完全不同的问题。特别是在计算机视觉领域，许多预训练的模型（通常都是在ImageNet 数据集上训练得到的）现在都可以公开下载，并可以用于在数据很少的情况下构建强大的视觉模型。我们先来看一下数据。</p>
<h2 id="2-下载数据"><a href="#2-下载数据" class="headerlink" title="2. 下载数据"></a>2. 下载数据</h2><p>本节用到的猫狗分类数据集不包含在Keras 中。它由Kaggle 在2013 年末公开并作为一项计算视觉竞赛的一部分，当时卷积神经网络还不是主流算法。你可以从<a href="https://www.kaggle.com/c/dogs-vs-cats/data" target="_blank" rel="noopener">https://www.kaggle.com/c/dogs-vs-cats/data</a> 下载原始数据集。</p>
<p>这些图像都是中等分辨率的彩色JPEG 图像:</p>
<center>
    <img src="\Pic\DeepLearning_Pic\cat_dog_1.png" width="300" height="300" alt="猫狗分类数据集的一些样本。没有修改尺寸：样本在尺寸、外观等方面是不一样的" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">猫狗分类数据集的一些样本。没有修改尺寸：样本在尺寸、外观等方面是不一样的</div>
</center>

<p>不出所料，2013 年的猫狗分类Kaggle 竞赛的优胜者使用的是卷积神经网络。最佳结果达到了95% 的精度。本例中，虽然你只在不到参赛选手所用的10% 的数据上训练模型，但结果也和这个精度相当接近。</p>
<p>这个数据集包含25 000 张猫狗图像（每个类别都有12 500 张），大小为543MB（压缩后）。下载数据并解压之后，你需要创建一个新数据集，其中包含三个子集：每个类别各1000 个样本的训练集、每个类别各500 个样本的验证集和每个类别各500 个样本的测试集。创建新数据集的代码如下所示。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将图像复制到训练、验证和测试的目录</span></span><br><span class="line"><span class="keyword">import</span> os, shutil</span><br><span class="line">original_dataset_dir = <span class="string">'data/cat_dog/kaggle_original_data'</span></span><br><span class="line">base_dir = <span class="string">'data/cat_dog/cats_and_dogs_small'</span></span><br><span class="line">os.mkdir(base_dir)</span><br><span class="line">train_dir = os.path.join(base_dir, <span class="string">'train'</span>)</span><br><span class="line">os.mkdir(train_dir)</span><br><span class="line">validation_dir = os.path.join(base_dir, <span class="string">'validation'</span>)</span><br><span class="line">os.mkdir(validation_dir)</span><br><span class="line">test_dir = os.path.join(base_dir, <span class="string">'test'</span>)</span><br><span class="line">os.mkdir(test_dir)</span><br><span class="line">train_cats_dir = os.path.join(train_dir, <span class="string">'cats'</span>)</span><br><span class="line">os.mkdir(train_cats_dir)</span><br><span class="line">train_dogs_dir = os.path.join(train_dir, <span class="string">'dogs'</span>)</span><br><span class="line">os.mkdir(train_dogs_dir)</span><br><span class="line">validation_cats_dir = os.path.join(validation_dir, <span class="string">'cats'</span>)</span><br><span class="line">os.mkdir(validation_cats_dir)</span><br><span class="line">validation_dogs_dir = os.path.join(validation_dir, <span class="string">'dogs'</span>)</span><br><span class="line">os.mkdir(validation_dogs_dir)</span><br><span class="line">test_cats_dir = os.path.join(test_dir, <span class="string">'cats'</span>)</span><br><span class="line">os.mkdir(test_cats_dir)</span><br><span class="line">test_dogs_dir = os.path.join(test_dir, <span class="string">'dogs'</span>)</span><br><span class="line">os.mkdir(test_dogs_dir)</span><br><span class="line">fnames = [<span class="string">'cat.&#123;&#125;.jpg'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">dst = os.path.join(train_cats_dir, fname)</span><br><span class="line">shutil.copyfile(src, dst)</span><br><span class="line">fnames = [<span class="string">'cat.&#123;&#125;.jpg'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>, <span class="number">1500</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">dst = os.path.join(validation_cats_dir, fname)</span><br><span class="line">shutil.copyfile(src, dst)</span><br><span class="line">fnames = [<span class="string">'cat.&#123;&#125;.jpg'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1500</span>, <span class="number">2000</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">dst = os.path.join(test_cats_dir, fname)</span><br><span class="line">shutil.copyfile(src, dst)</span><br><span class="line">fnames = [<span class="string">'dog.&#123;&#125;.jpg'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">dst = os.path.join(train_dogs_dir, fname)</span><br><span class="line">shutil.copyfile(src, dst)</span><br><span class="line">fnames = [<span class="string">'dog.&#123;&#125;.jpg'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>, <span class="number">1500</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">dst = os.path.join(validation_dogs_dir, fname)</span><br><span class="line">shutil.copyfile(src, dst)</span><br><span class="line">fnames = [<span class="string">'dog.&#123;&#125;.jpg'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1500</span>, <span class="number">2000</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">dst = os.path.join(test_dogs_dir, fname)</span><br><span class="line">shutil.copyfile(src, dst)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os, shutil</span><br><span class="line">base_dir = <span class="string">'data/cat_dog/cats_and_dogs_small'</span></span><br><span class="line">train_dir = os.path.join(base_dir, <span class="string">'train'</span>)</span><br><span class="line">test_dir = os.path.join(base_dir, <span class="string">'test'</span>)</span><br><span class="line">validation_dir = os.path.join(base_dir, <span class="string">'validation'</span>)</span><br><span class="line">train_cats_dir = os.path.join(train_dir, <span class="string">'cats'</span>)</span><br><span class="line">test_cats_dir = os.path.join(test_dir, <span class="string">'cats'</span>)</span><br><span class="line">validation_cats_dir = os.path.join(validation_dir, <span class="string">'cats'</span>)</span><br><span class="line">train_dogs_dir = os.path.join(train_dir, <span class="string">'dogs'</span>)</span><br><span class="line">test_dogs_dir = os.path.join(test_dir, <span class="string">'dogs'</span>)</span><br><span class="line">validation_dogs_dir = os.path.join(validation_dir, <span class="string">'dogs'</span>)</span><br><span class="line">print(<span class="string">'total training cat images:'</span>, len(os.listdir(train_cats_dir)))</span><br><span class="line">print(<span class="string">'total training dog images:'</span>, len(os.listdir(train_dogs_dir)))</span><br><span class="line">print(<span class="string">'total validation cat images:'</span>, len(os.listdir(validation_cats_dir)))</span><br><span class="line">print(<span class="string">'total validation dog images:'</span>, len(os.listdir(validation_dogs_dir)))</span><br><span class="line">print(<span class="string">'total test cat images:'</span>, len(os.listdir(test_cats_dir)))</span><br><span class="line">print(<span class="string">'total test dog images:'</span>, len(os.listdir(test_dogs_dir)))</span><br></pre></td></tr></table></figure>
<pre><code>total training cat images: 1000
total training dog images: 1000
total validation cat images: 500
total validation dog images: 500
total test cat images: 500
total test dog images: 500
</code></pre><p>所以我们的确有2000 张训练图像、1000 张验证图像和1000 张测试图像。每个分组中两个类别的样本数相同，这是一个平衡的二分类问题，分类精度可作为衡量成功的指标。</p>
<h2 id="3-构建网络"><a href="#3-构建网络" class="headerlink" title="3. 构建网络"></a>3. 构建网络</h2><p>在前一个MNIST示例中，我们构建了一个小型卷积神经网络，所以你应该已经熟悉这种网络。我们将复用相同的总体结构，即卷积神经网络由<code>Conv2D</code>层（使用<code>relu</code>激活）和<code>MaxPooling2D</code>层交替堆叠构成。</p>
<p>但由于这里要处理的是更大的图像和更复杂的问题，你需要相应地增大网络，即再增加一个<code>Conv2D+MaxPooling2D</code>的组合。这既可以增大网络容量，也可以进一步减小特征图的尺寸，使其在连接<code>Flatten</code>层时尺寸不会太大。本例中初始输入的尺寸为150×150（有些随意的选择），所以最后在<code>Flatten</code>层之前的特征图大小为7×7。</p>
<p>你面对的是一个二分类问题，所以网络最后一层是使用<code>sigmoid</code>激活的单一单元（大小为 1 的<code>Dense</code>层）。这个单元将对某个类别的概率进行编码。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将猫狗分类的小型卷积神经网络实例化</span></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">"relu"</span>, input_shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>)))</span><br><span class="line">model.add(layers.MaxPooling2D(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">"relu"</span>))</span><br><span class="line">model.add(layers.MaxPooling2D(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dense(<span class="number">512</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_4&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_8 (Conv2D)            (None, 148, 148, 32)      896       
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 74, 74, 32)        0         
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 72, 72, 64)        18496     
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 36, 36, 64)        0         
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 34, 34, 128)       73856     
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 17, 17, 128)       0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 36992)             0         
_________________________________________________________________
dense_3 (Dense)              (None, 512)               18940416  
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 513       
=================================================================
Total params: 19,034,177
Trainable params: 19,034,177
Non-trainable params: 0
_________________________________________________________________
</code></pre><p>在编译这一步，和前面一样，我们将使用RMSprop 优化器。因为网络最后一层是单一sigmoid单元，所以我们将使用二元交叉熵作为损失函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 配置模型用于训练</span></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimizers</span><br><span class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>,optimizer=optimizers.RMSprop(lr=<span class="number">1e-4</span>),metrics=[<span class="string">'acc'</span>])</span><br></pre></td></tr></table></figure>
<h2 id="4-数据预处理"><a href="#4-数据预处理" class="headerlink" title="4. 数据预处理"></a>4. 数据预处理</h2><p>你现在已经知道，将数据输入神经网络之前，应该将数据格式化为经过预处理的浮点数张量。现在，数据以 JPEG 文件的形式保存在硬盘中，所以数据预处理步骤大致如下：</p>
<ol>
<li>读取图像文件</li>
<li>将JPEG文件解码为RGB像素网格</li>
<li>将这些像素网格转换为浮点数张量</li>
<li>将像素值（0~255 范围内）缩放到 <code>[0, 1]</code> 区间（正如你所知，神经网络喜欢处理较小的输<br>入值）</li>
</ol>
<p>这些步骤可能看起来有点吓人，但幸运的是，Keras 拥有自动完成这些步骤的工具。Keras有一个图像处理辅助工具的模块，位于<code>keras.preprocessing.image</code>。特别地，它包含<code>ImageDataGenerator</code>类，可以快速创建Python生成器，能够将硬盘上的图像文件自动转换为预处理好的张量批量。下面我们将用到这个类。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用ImageDataGenerator 从目录中读取图像</span></span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line">train_datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line">test_datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line">train_generator = train_datagen.flow_from_directory(</span><br><span class="line">        train_dir,</span><br><span class="line">        target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">        batch_size=<span class="number">20</span>,</span><br><span class="line">        class_mode=<span class="string">'binary'</span>)</span><br><span class="line">validation_generator = test_datagen.flow_from_directory(</span><br><span class="line">        validation_dir,</span><br><span class="line">        target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">        batch_size=<span class="number">20</span>,</span><br><span class="line">        class_mode=<span class="string">'binary'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Found 2000 images belonging to 2 classes.
Found 1000 images belonging to 2 classes.
</code></pre><p>我们来看一下其中一个生成器的输出：它生成了150×150 的RGB 图像［形状为(20,150, 150, 3)］与二进制标签［形状为(20,)］组成的批量。每个批量中包含20 个样本（批量大小）。注意，生成器会不停地生成这些批量，它会不断循环目标文件夹中的图像。因此，你需要在某个时刻终止（break）迭代循环。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> data_batch, labels_batch <span class="keyword">in</span> train_generator:</span><br><span class="line">    print(<span class="string">'data batch shape:'</span>, data_batch.shape)</span><br><span class="line">    print(<span class="string">'labels batch shape:'</span>, labels_batch.shape)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<pre><code>data batch shape: (20, 150, 150, 3)
labels batch shape: (20,)
</code></pre><p>利用生成器，我们让模型对数据进行拟合。我们将使用<code>fit_generator</code>方法来拟合，它在数据生成器上的效果和fit 相同。它的第一个参数应该是一个Python生成器，可以不停地生成输入和目标组成的批量，比如<code>train_generator</code>。因为数据是不断生成的，所以Keras模型要知道每一轮需要从生成器中抽取多少个样本。这是<code>steps_per_epoch</code>参数的作用：从生成器中抽取<code>steps_per_epoch</code>个批量后（即运行了<code>steps_per_epoch</code>次梯度下降），拟合过程将进入下一个轮次。本例中，每个批量包含20个样本，所以读取完所有2000 个样本需要100个批量。</p>
<p>使用<code>fit_generator</code>时，你可以传入一个<code>validation_data</code>参数，其作用和在<code>fit</code>方法中类似。值得注意的是，这个参数可以是一个数据生成器，但也可以是Numpy数组组成的元组。如果向<code>validation_data</code>传入一个生成器，那么这个生成器应该能够不停地生成验证数据批量，因此你还需要指定<code>validation_steps</code>参数，说明需要从验证生成器中抽取多少个批次用于评估。</p>
<h2 id="5-拟合模型"><a href="#5-拟合模型" class="headerlink" title="5. 拟合模型"></a>5. 拟合模型</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">history = model.fit_generator(</span><br><span class="line">    train_generator,</span><br><span class="line">    steps_per_epoch=<span class="number">100</span>,</span><br><span class="line">    epochs=<span class="number">30</span>,</span><br><span class="line">    validation_data=validation_generator,</span><br><span class="line">    validation_steps=<span class="number">50</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1/30
100/100 [==============================] - 71s 709ms/step - loss: 0.6845 - acc: 0.5520 - val_loss: 0.6738 - val_acc: 0.5850
Epoch 2/30
100/100 [==============================] - 65s 645ms/step - loss: 0.6184 - acc: 0.6405 - val_loss: 0.5264 - val_acc: 0.6730
Epoch 3/30
100/100 [==============================] - 83s 830ms/step - loss: 0.5660 - acc: 0.7160 - val_loss: 0.4590 - val_acc: 0.6360
Epoch 4/30
100/100 [==============================] - 74s 739ms/step - loss: 0.5222 - acc: 0.7400 - val_loss: 0.6281 - val_acc: 0.6680
Epoch 5/30
100/100 [==============================] - 70s 699ms/step - loss: 0.4870 - acc: 0.7635 - val_loss: 0.5049 - val_acc: 0.7010
Epoch 6/30
100/100 [==============================] - 70s 700ms/step - loss: 0.4575 - acc: 0.7800 - val_loss: 0.6481 - val_acc: 0.7110
Epoch 7/30
100/100 [==============================] - 70s 698ms/step - loss: 0.4273 - acc: 0.8025 - val_loss: 0.7052 - val_acc: 0.7060
Epoch 8/30
100/100 [==============================] - 70s 697ms/step - loss: 0.3928 - acc: 0.8265 - val_loss: 0.4466 - val_acc: 0.7050
Epoch 9/30
100/100 [==============================] - 70s 700ms/step - loss: 0.3731 - acc: 0.8485 - val_loss: 0.5841 - val_acc: 0.7180
Epoch 10/30
100/100 [==============================] - 71s 708ms/step - loss: 0.3347 - acc: 0.8575 - val_loss: 0.5448 - val_acc: 0.6970
Epoch 11/30
100/100 [==============================] - 71s 706ms/step - loss: 0.3212 - acc: 0.8655 - val_loss: 0.6970 - val_acc: 0.7150
Epoch 12/30
100/100 [==============================] - 70s 703ms/step - loss: 0.2870 - acc: 0.8830 - val_loss: 0.4558 - val_acc: 0.7210
Epoch 13/30
100/100 [==============================] - 70s 704ms/step - loss: 0.2593 - acc: 0.8990 - val_loss: 0.4447 - val_acc: 0.6940
Epoch 14/30
100/100 [==============================] - 70s 704ms/step - loss: 0.2326 - acc: 0.9165 - val_loss: 0.5825 - val_acc: 0.7220
Epoch 15/30
100/100 [==============================] - 71s 706ms/step - loss: 0.2018 - acc: 0.9325 - val_loss: 0.1710 - val_acc: 0.7170
Epoch 16/30
100/100 [==============================] - 71s 708ms/step - loss: 0.1785 - acc: 0.9390 - val_loss: 0.7726 - val_acc: 0.7160
Epoch 17/30
100/100 [==============================] - 71s 708ms/step - loss: 0.1579 - acc: 0.9480 - val_loss: 0.4888 - val_acc: 0.7150
Epoch 18/30
100/100 [==============================] - 71s 709ms/step - loss: 0.1399 - acc: 0.9545 - val_loss: 0.7219 - val_acc: 0.7130
Epoch 19/30
100/100 [==============================] - 71s 708ms/step - loss: 0.1229 - acc: 0.9580 - val_loss: 0.3776 - val_acc: 0.7180
Epoch 20/30
100/100 [==============================] - 71s 708ms/step - loss: 0.1002 - acc: 0.9735 - val_loss: 1.0687 - val_acc: 0.7240
Epoch 21/30
100/100 [==============================] - 71s 707ms/step - loss: 0.0841 - acc: 0.9785 - val_loss: 1.6117 - val_acc: 0.7270
Epoch 22/30
100/100 [==============================] - 71s 710ms/step - loss: 0.0753 - acc: 0.9840 - val_loss: 0.3944 - val_acc: 0.7240
Epoch 23/30
100/100 [==============================] - 71s 707ms/step - loss: 0.0649 - acc: 0.9825 - val_loss: 1.1620 - val_acc: 0.7240
Epoch 24/30
100/100 [==============================] - 71s 708ms/step - loss: 0.0503 - acc: 0.9905 - val_loss: 0.4844 - val_acc: 0.7260
Epoch 25/30
100/100 [==============================] - 71s 707ms/step - loss: 0.0464 - acc: 0.9875 - val_loss: 0.4670 - val_acc: 0.7080
Epoch 26/30
100/100 [==============================] - 71s 706ms/step - loss: 0.0362 - acc: 0.9945 - val_loss: 0.4580 - val_acc: 0.7140
Epoch 27/30
100/100 [==============================] - 71s 708ms/step - loss: 0.0324 - acc: 0.9920 - val_loss: 0.6673 - val_acc: 0.7240
Epoch 28/30
100/100 [==============================] - 71s 708ms/step - loss: 0.0211 - acc: 0.9970 - val_loss: 0.7170 - val_acc: 0.7260
Epoch 29/30
100/100 [==============================] - 71s 709ms/step - loss: 0.0195 - acc: 0.9965 - val_loss: 1.4715 - val_acc: 0.7250
Epoch 30/30
100/100 [==============================] - 71s 708ms/step - loss: 0.0137 - acc: 0.9965 - val_loss: 1.1098 - val_acc: 0.7010
</code></pre><p>始终在训练完成后保存模型，这是一种良好实践。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 保存模型</span></span><br><span class="line">model.save(<span class="string">'model/ComputerVersion/cats_and_dogs_small_1.h5'</span>)</span><br></pre></td></tr></table></figure>
<p>我们来分别绘制训练过程中模型在训练数据和验证数据上的损失和精度</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">acc = history.history[<span class="string">'acc'</span>]</span><br><span class="line">val_acc = history.history[<span class="string">'val_acc'</span>]</span><br><span class="line">loss = history.history[<span class="string">'loss'</span>]</span><br><span class="line">val_loss = history.history[<span class="string">'val_loss'</span>]</span><br><span class="line">epochs = range(<span class="number">1</span>, len(acc) + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, acc, <span class="string">'bo'</span>, label=<span class="string">'Training acc'</span>)</span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">'b'</span>, label=<span class="string">'Validation acc'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation accuracy'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.figure()</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, loss, <span class="string">'bo'</span>, label=<span class="string">'Training loss'</span>)</span><br><span class="line">plt.plot(epochs, val_loss, <span class="string">'b'</span>, label=<span class="string">'Validation loss'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_29_0.png" width="400" height="400" alt="训练损失和验证损失" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">训练损失和验证损失</div>
</center>


<center>
    <img src="\Pic\DeepLearning_Pic\output_29_1.png" width="400" height="400" alt="训练精度和验证精度" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">训练精度和验证精度</div>
</center>



<p>从这些图像中都能看出过拟合的特征。训练精度随着时间线性增加，直到接近100%，而验证精度则停留在70%~72%。验证损失仅在5 轮后就达到最小值，然后保持不变，而训练损失则一直线性下降，直到接近于0。</p>
<p>因为训练样本相对较少（2000 个），所以过拟合是你最关心的问题。前面已经介绍过几种降低过拟合的技巧，比如dropout 和权重衰减（L2 正则化）。现在我们将使用一种针对于计算机视觉领域的新方法，在用深度学习模型处理图像时几乎都会用到这种方法，它就是数据增强（data augmentation）。</p>
<h2 id="6-使用数据增强"><a href="#6-使用数据增强" class="headerlink" title="6. 使用数据增强"></a>6. 使用数据增强</h2><p>过拟合的原因是学习样本太少，导致无法训练出能够泛化到新数据的模型。如果拥有无限的数据，那么模型能够观察到数据分布的所有内容，这样就永远不会过拟合。数据增强是从现有的训练样本中生成更多的训练数据，其方法是利用多种能够生成可信图像的随机变换来增加（augment）样本。其目标是，模型在训练时不会两次查看完全相同的图像。这让模型能够观察到数据的更多内容，从而具有更好的泛化能力。</p>
<p>在Keras 中，这可以通过对<code>ImageDataGenerator</code>实例读取的图像执行多次随机变换来实现。我们先来看一个例子。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 利用ImageDataGenerator 来设置数据增强</span></span><br><span class="line">datagen = ImageDataGenerator(</span><br><span class="line">    rotation_range=<span class="number">40</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    shear_range=<span class="number">0.2</span>,</span><br><span class="line">    zoom_range=<span class="number">0.2</span>,</span><br><span class="line">    horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">    fill_mode=<span class="string">'nearest'</span>)</span><br></pre></td></tr></table></figure>
<p>这里只选择了几个参数（想了解更多参数，请查阅Keras 文档）。我们来快速介绍一下这些<br>参数的含义。</p>
<ul>
<li><code>rotation_range</code>是角度值（在 0~180 范围内），表示图像随机旋转的角度范围。</li>
<li><code>width_shift</code> 和 <code>height_shift</code> 是图像在水平或垂直方向上平移的范围（相对于总宽度或总高度的比例）。</li>
<li><code>shear_range</code>是随机错切变换的角度。</li>
<li><code>zoom_range</code>是图像随机缩放的范围。</li>
<li><code>horizontal_flip</code> 是随机将一半图像水平翻转。如果没有水平不对称的假设（比如真实世界的图像），这种做法是有意义的。</li>
<li><code>fill_mode</code>是用于填充新创建像素的方法，这些新像素可能来自于旋转或宽度/高度平移。</li>
</ul>
<p>我们来看一下增强后的图像</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 显示几个随机增强后的训练图像</span></span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line">fnames = [os.path.join(train_cats_dir, fname) <span class="keyword">for</span> fname <span class="keyword">in</span> os.listdir(train_cats_dir)]</span><br><span class="line">img_path = fnames[<span class="number">3</span>]</span><br><span class="line">img = image.load_img(img_path, target_size=(<span class="number">150</span>, <span class="number">150</span>))</span><br><span class="line">x = image.img_to_array(img)</span><br><span class="line">x = x.reshape((<span class="number">1</span>,) + x.shape)</span><br><span class="line">i = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> datagen.flow(x, batch_size=<span class="number">1</span>):</span><br><span class="line">    plt.figure(i)</span><br><span class="line">    imgplot = plt.imshow(image.array_to_img(batch[<span class="number">0</span>]))</span><br><span class="line">    i += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">4</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_33_0.png" width="400" height="400" alt="增强后的图像" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">增强后的图像（1）</div>
</center>

<center>
    <img src="\Pic\DeepLearning_Pic\output_33_1.png" width="400" height="400" alt="增强后的图像" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">增强后的图像（2）</div>
</center>

<center>
    <img src="\Pic\DeepLearning_Pic\output_33_2.png" width="400" height="400" alt="增强后的图像" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">增强后的图像（3）</div>
</center>

<center>
    <img src="\Pic\DeepLearning_Pic\output_33_3.png" width="400" height="400" alt="增强后的图像" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">增强后的图像（4）</div>
</center>




<p>如果你使用这种数据增强来训练一个新网络，那么网络将不会两次看到同样的输入。但网络看到的输入仍然是高度相关的，因为这些输入都来自于少量的原始图像。你无法生成新信息，而只能混合现有信息。因此，这种方法可能不足以完全消除过拟合。为了进一步降低过拟合，你还需要向模型中添加一个<code>Dropout</code>层，添加到密集连接分类器之前。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = models.Sequential()</span><br><span class="line"></span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>,input_shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>)))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">512</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"></span><br><span class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>,optimizer=optimizers.RMSprop(lr=<span class="number">1e-4</span>),metrics=[<span class="string">'acc'</span>])</span><br></pre></td></tr></table></figure>
<p>我们来训练这个使用了数据增强和dropout 的网络。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 利用数据增强生成器训练卷积神经网络</span></span><br><span class="line">train_datagen = ImageDataGenerator(</span><br><span class="line">    rescale=<span class="number">1.</span>/<span class="number">255</span>,</span><br><span class="line">    rotation_range=<span class="number">40</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    shear_range=<span class="number">0.2</span>,</span><br><span class="line">    zoom_range=<span class="number">0.2</span>,</span><br><span class="line">    horizontal_flip=<span class="literal">True</span>,)</span><br><span class="line"></span><br><span class="line">test_datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line"></span><br><span class="line">train_generator = train_datagen.flow_from_directory(</span><br><span class="line">    train_dir,</span><br><span class="line">    target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">    batch_size=<span class="number">32</span>,</span><br><span class="line">    class_mode=<span class="string">'binary'</span>)</span><br><span class="line"></span><br><span class="line">validation_generator = test_datagen.flow_from_directory(</span><br><span class="line">    validation_dir,</span><br><span class="line">    target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">    batch_size=<span class="number">32</span>,</span><br><span class="line">    class_mode=<span class="string">'binary'</span>)</span><br><span class="line"></span><br><span class="line">history = model.fit_generator(</span><br><span class="line">    train_generator,</span><br><span class="line">    steps_per_epoch=<span class="number">100</span>,</span><br><span class="line">    epochs=<span class="number">100</span>,</span><br><span class="line">    validation_data=validation_generator,</span><br><span class="line">    validation_steps=<span class="number">50</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Found 2000 images belonging to 2 classes.
Found 1000 images belonging to 2 classes.
Epoch 1/100
100/100 [==============================] - 76s 765ms/step - loss: 0.6914 - acc: 0.5183 - val_loss: 0.7206 - val_acc: 0.5032
Epoch 2/100
100/100 [==============================] - 72s 724ms/step - loss: 0.6739 - acc: 0.5729 - val_loss: 0.6612 - val_acc: 0.5921
Epoch 3/100
100/100 [==============================] - 72s 723ms/step - loss: 0.6692 - acc: 0.5701 - val_loss: 0.7034 - val_acc: 0.5374
Epoch 4/100
100/100 [==============================] - 72s 724ms/step - loss: 0.6496 - acc: 0.6080 - val_loss: 0.6402 - val_acc: 0.6269
Epoch 5/100
100/100 [==============================] - 75s 749ms/step - loss: 0.6313 - acc: 0.6408 - val_loss: 0.6454 - val_acc: 0.6650
Epoch 6/100
100/100 [==============================] - 77s 774ms/step - loss: 0.6112 - acc: 0.6555 - val_loss: 0.6192 - val_acc: 0.6823
Epoch 7/100
100/100 [==============================] - 76s 761ms/step - loss: 0.6064 - acc: 0.6585 - val_loss: 0.6323 - val_acc: 0.6853
Epoch 8/100
100/100 [==============================] - 77s 775ms/step - loss: 0.5988 - acc: 0.6724 - val_loss: 0.5059 - val_acc: 0.6804
Epoch 9/100
100/100 [==============================] - 75s 753ms/step - loss: 0.5842 - acc: 0.6926 - val_loss: 0.5870 - val_acc: 0.7139
Epoch 10/100
100/100 [==============================] - 77s 771ms/step - loss: 0.5765 - acc: 0.6954 - val_loss: 0.5300 - val_acc: 0.7157
Epoch 11/100
100/100 [==============================] - 77s 772ms/step - loss: 0.5766 - acc: 0.6869 - val_loss: 0.6192 - val_acc: 0.7004
Epoch 12/100
100/100 [==============================] - 74s 737ms/step - loss: 0.5625 - acc: 0.7048 - val_loss: 0.6041 - val_acc: 0.6916
Epoch 13/100
100/100 [==============================] - 73s 733ms/step - loss: 0.5667 - acc: 0.7014 - val_loss: 0.6984 - val_acc: 0.6849
Epoch 14/100
100/100 [==============================] - 80s 800ms/step - loss: 0.5551 - acc: 0.7142 - val_loss: 0.5477 - val_acc: 0.6859
Epoch 15/100
100/100 [==============================] - 74s 745ms/step - loss: 0.5481 - acc: 0.7263 - val_loss: 0.6152 - val_acc: 0.7139
Epoch 16/100
100/100 [==============================] - 75s 752ms/step - loss: 0.5450 - acc: 0.7155 - val_loss: 0.4643 - val_acc: 0.7088
Epoch 17/100
100/100 [==============================] - 75s 751ms/step - loss: 0.5368 - acc: 0.7225 - val_loss: 0.5045 - val_acc: 0.7259
Epoch 18/100
100/100 [==============================] - 77s 772ms/step - loss: 0.5334 - acc: 0.7305 - val_loss: 0.5234 - val_acc: 0.7384
Epoch 19/100
100/100 [==============================] - 73s 728ms/step - loss: 0.5276 - acc: 0.7446 - val_loss: 0.3467 - val_acc: 0.7284
Epoch 20/100
100/100 [==============================] - 72s 722ms/step - loss: 0.5252 - acc: 0.7346 - val_loss: 0.5238 - val_acc: 0.7506
Epoch 21/100
100/100 [==============================] - 73s 734ms/step - loss: 0.5319 - acc: 0.7304 - val_loss: 0.6062 - val_acc: 0.7189
Epoch 22/100
100/100 [==============================] - 74s 737ms/step - loss: 0.5140 - acc: 0.7434 - val_loss: 0.5258 - val_acc: 0.7500
Epoch 23/100
100/100 [==============================] - 76s 759ms/step - loss: 0.5001 - acc: 0.7538 - val_loss: 0.5850 - val_acc: 0.6681
Epoch 24/100
100/100 [==============================] - 75s 752ms/step - loss: 0.5181 - acc: 0.7345 - val_loss: 0.5819 - val_acc: 0.7429
Epoch 25/100
100/100 [==============================] - 73s 726ms/step - loss: 0.5130 - acc: 0.7421 - val_loss: 0.5566 - val_acc: 0.7519
Epoch 26/100
100/100 [==============================] - 74s 736ms/step - loss: 0.4970 - acc: 0.7513 - val_loss: 0.5302 - val_acc: 0.7468
Epoch 27/100
100/100 [==============================] - 75s 750ms/step - loss: 0.5017 - acc: 0.7617 - val_loss: 0.7022 - val_acc: 0.7597
Epoch 28/100
100/100 [==============================] - 74s 740ms/step - loss: 0.4944 - acc: 0.7601 - val_loss: 0.5136 - val_acc: 0.7602
Epoch 29/100
100/100 [==============================] - 76s 760ms/step - loss: 0.4971 - acc: 0.7575 - val_loss: 0.5346 - val_acc: 0.7539
Epoch 30/100
100/100 [==============================] - 73s 732ms/step - loss: 0.4934 - acc: 0.7582 - val_loss: 0.5304 - val_acc: 0.7253
Epoch 31/100
100/100 [==============================] - 75s 746ms/step - loss: 0.4920 - acc: 0.7557 - val_loss: 0.5527 - val_acc: 0.7410
Epoch 32/100
100/100 [==============================] - 74s 736ms/step - loss: 0.4881 - acc: 0.7676 - val_loss: 0.4412 - val_acc: 0.7622
Epoch 33/100
100/100 [==============================] - 74s 741ms/step - loss: 0.4879 - acc: 0.7594 - val_loss: 0.4859 - val_acc: 0.7773
Epoch 34/100
100/100 [==============================] - 73s 731ms/step - loss: 0.4791 - acc: 0.7775 - val_loss: 0.5089 - val_acc: 0.7809
Epoch 35/100
100/100 [==============================] - 76s 762ms/step - loss: 0.4783 - acc: 0.7718 - val_loss: 0.4133 - val_acc: 0.7862
Epoch 36/100
100/100 [==============================] - 75s 750ms/step - loss: 0.4723 - acc: 0.7754 - val_loss: 0.7177 - val_acc: 0.7371
Epoch 37/100
100/100 [==============================] - 72s 722ms/step - loss: 0.4684 - acc: 0.7705 - val_loss: 0.2175 - val_acc: 0.8014
Epoch 38/100
100/100 [==============================] - 74s 743ms/step - loss: 0.4617 - acc: 0.7784 - val_loss: 0.5956 - val_acc: 0.7655
Epoch 39/100
100/100 [==============================] - 74s 743ms/step - loss: 0.4610 - acc: 0.7811 - val_loss: 0.4567 - val_acc: 0.7970
Epoch 40/100
100/100 [==============================] - 76s 756ms/step - loss: 0.4573 - acc: 0.7828 - val_loss: 0.6099 - val_acc: 0.7816
Epoch 41/100
100/100 [==============================] - 73s 732ms/step - loss: 0.4521 - acc: 0.7883 - val_loss: 0.5290 - val_acc: 0.7809
Epoch 42/100
100/100 [==============================] - 72s 722ms/step - loss: 0.4563 - acc: 0.7854 - val_loss: 0.5905 - val_acc: 0.7938
Epoch 43/100
100/100 [==============================] - 75s 752ms/step - loss: 0.4538 - acc: 0.7822 - val_loss: 0.3387 - val_acc: 0.7919
Epoch 44/100
100/100 [==============================] - 76s 758ms/step - loss: 0.4508 - acc: 0.7893 - val_loss: 0.3386 - val_acc: 0.7766
Epoch 45/100
100/100 [==============================] - 76s 764ms/step - loss: 0.4392 - acc: 0.7981 - val_loss: 0.4522 - val_acc: 0.7539
Epoch 46/100
100/100 [==============================] - 75s 750ms/step - loss: 0.4415 - acc: 0.7904 - val_loss: 0.4479 - val_acc: 0.8039
Epoch 47/100
100/100 [==============================] - 75s 746ms/step - loss: 0.4431 - acc: 0.7996 - val_loss: 0.6296 - val_acc: 0.8015
Epoch 48/100
100/100 [==============================] - 74s 735ms/step - loss: 0.4337 - acc: 0.7842 - val_loss: 0.7442 - val_acc: 0.7899
Epoch 49/100
100/100 [==============================] - 73s 728ms/step - loss: 0.4492 - acc: 0.7895 - val_loss: 0.3889 - val_acc: 0.8090
Epoch 50/100
100/100 [==============================] - 73s 734ms/step - loss: 0.4369 - acc: 0.8011 - val_loss: 0.3906 - val_acc: 0.7719
Epoch 51/100
100/100 [==============================] - 73s 728ms/step - loss: 0.4203 - acc: 0.8106 - val_loss: 0.3646 - val_acc: 0.7303
Epoch 52/100
100/100 [==============================] - 75s 754ms/step - loss: 0.4243 - acc: 0.8056 - val_loss: 0.3277 - val_acc: 0.7957
Epoch 53/100
100/100 [==============================] - 74s 736ms/step - loss: 0.4288 - acc: 0.7986 - val_loss: 0.3046 - val_acc: 0.8096
Epoch 54/100
100/100 [==============================] - 73s 734ms/step - loss: 0.4203 - acc: 0.8046 - val_loss: 0.1641 - val_acc: 0.8189
Epoch 55/100
100/100 [==============================] - 73s 732ms/step - loss: 0.4296 - acc: 0.8065 - val_loss: 0.4410 - val_acc: 0.7963
Epoch 56/100
100/100 [==============================] - 74s 736ms/step - loss: 0.4264 - acc: 0.8112 - val_loss: 0.7351 - val_acc: 0.7751
Epoch 57/100
100/100 [==============================] - 74s 742ms/step - loss: 0.4208 - acc: 0.8081 - val_loss: 0.4422 - val_acc: 0.7899
Epoch 58/100
100/100 [==============================] - 73s 731ms/step - loss: 0.4186 - acc: 0.8059 - val_loss: 0.3010 - val_acc: 0.8230
Epoch 59/100
100/100 [==============================] - 72s 724ms/step - loss: 0.4123 - acc: 0.8078 - val_loss: 0.2892 - val_acc: 0.8061
Epoch 60/100
100/100 [==============================] - 74s 736ms/step - loss: 0.4048 - acc: 0.8211 - val_loss: 0.4229 - val_acc: 0.8039
Epoch 61/100
100/100 [==============================] - 72s 724ms/step - loss: 0.4085 - acc: 0.8147 - val_loss: 0.6638 - val_acc: 0.7932
Epoch 62/100
100/100 [==============================] - 74s 736ms/step - loss: 0.3915 - acc: 0.8229 - val_loss: 0.4043 - val_acc: 0.7824
Epoch 63/100
100/100 [==============================] - 73s 725ms/step - loss: 0.4047 - acc: 0.8112 - val_loss: 0.3251 - val_acc: 0.8035
Epoch 64/100
100/100 [==============================] - 72s 722ms/step - loss: 0.3958 - acc: 0.8185 - val_loss: 0.1415 - val_acc: 0.8125
Epoch 65/100
100/100 [==============================] - 73s 730ms/step - loss: 0.4035 - acc: 0.8021 - val_loss: 0.4303 - val_acc: 0.8103
Epoch 66/100
100/100 [==============================] - 72s 719ms/step - loss: 0.3885 - acc: 0.8141 - val_loss: 0.6505 - val_acc: 0.8054
Epoch 67/100
100/100 [==============================] - 73s 729ms/step - loss: 0.4019 - acc: 0.8169 - val_loss: 0.3303 - val_acc: 0.8122
Epoch 68/100
100/100 [==============================] - 72s 720ms/step - loss: 0.4013 - acc: 0.8147 - val_loss: 0.4759 - val_acc: 0.8247
Epoch 69/100
100/100 [==============================] - 74s 743ms/step - loss: 0.3903 - acc: 0.8178 - val_loss: 0.5856 - val_acc: 0.8128
Epoch 70/100
100/100 [==============================] - 72s 724ms/step - loss: 0.3819 - acc: 0.8292 - val_loss: 0.5976 - val_acc: 0.8086
Epoch 71/100
100/100 [==============================] - 72s 722ms/step - loss: 0.3844 - acc: 0.8229 - val_loss: 0.1998 - val_acc: 0.8185
Epoch 72/100
100/100 [==============================] - 75s 746ms/step - loss: 0.3849 - acc: 0.8251 - val_loss: 0.3054 - val_acc: 0.8325
Epoch 73/100
100/100 [==============================] - 73s 731ms/step - loss: 0.3930 - acc: 0.8207 - val_loss: 0.5404 - val_acc: 0.8138
Epoch 74/100
100/100 [==============================] - 74s 735ms/step - loss: 0.3792 - acc: 0.8314 - val_loss: 0.7166 - val_acc: 0.7919
Epoch 75/100
100/100 [==============================] - 73s 729ms/step - loss: 0.3747 - acc: 0.8273 - val_loss: 0.3519 - val_acc: 0.8099
Epoch 76/100
100/100 [==============================] - 72s 717ms/step - loss: 0.3782 - acc: 0.8323 - val_loss: 0.3318 - val_acc: 0.8109
Epoch 77/100
100/100 [==============================] - 74s 741ms/step - loss: 0.3732 - acc: 0.8336 - val_loss: 0.4652 - val_acc: 0.8247
Epoch 78/100
100/100 [==============================] - 72s 720ms/step - loss: 0.3614 - acc: 0.8386 - val_loss: 0.4755 - val_acc: 0.8325
Epoch 79/100
100/100 [==============================] - 75s 747ms/step - loss: 0.3750 - acc: 0.8330 - val_loss: 0.2174 - val_acc: 0.8086
Epoch 80/100
100/100 [==============================] - 73s 727ms/step - loss: 0.3593 - acc: 0.8386 - val_loss: 0.1871 - val_acc: 0.8286
Epoch 81/100
100/100 [==============================] - 75s 754ms/step - loss: 0.3712 - acc: 0.8365 - val_loss: 0.2686 - val_acc: 0.8128
Epoch 82/100
100/100 [==============================] - 75s 746ms/step - loss: 0.3682 - acc: 0.8387 - val_loss: 0.3900 - val_acc: 0.8138
Epoch 83/100
100/100 [==============================] - 74s 737ms/step - loss: 0.3644 - acc: 0.8403 - val_loss: 0.3761 - val_acc: 0.8306
Epoch 84/100
100/100 [==============================] - 77s 766ms/step - loss: 0.3391 - acc: 0.8488 - val_loss: 0.3467 - val_acc: 0.8318
Epoch 85/100
100/100 [==============================] - 75s 752ms/step - loss: 0.3486 - acc: 0.8482 - val_loss: 0.3446 - val_acc: 0.8261
Epoch 86/100
100/100 [==============================] - 76s 757ms/step - loss: 0.3519 - acc: 0.8483 - val_loss: 0.7064 - val_acc: 0.8293
Epoch 87/100
100/100 [==============================] - 76s 764ms/step - loss: 0.3520 - acc: 0.8381 - val_loss: 0.4178 - val_acc: 0.8242
Epoch 88/100
100/100 [==============================] - 73s 728ms/step - loss: 0.3543 - acc: 0.8453 - val_loss: 0.2981 - val_acc: 0.8267
Epoch 89/100
100/100 [==============================] - 75s 752ms/step - loss: 0.3465 - acc: 0.8527 - val_loss: 0.4845 - val_acc: 0.8363
Epoch 90/100
100/100 [==============================] - 73s 729ms/step - loss: 0.3451 - acc: 0.8387 - val_loss: 0.3519 - val_acc: 0.8319
Epoch 91/100
100/100 [==============================] - 74s 739ms/step - loss: 0.3562 - acc: 0.8401 - val_loss: 0.3915 - val_acc: 0.8299
Epoch 92/100
100/100 [==============================] - 77s 773ms/step - loss: 0.3336 - acc: 0.8516 - val_loss: 0.3190 - val_acc: 0.8344
Epoch 93/100
100/100 [==============================] - 81s 813ms/step - loss: 0.3436 - acc: 0.8427 - val_loss: 0.5416 - val_acc: 0.7938
Epoch 94/100
100/100 [==============================] - 80s 800ms/step - loss: 0.3318 - acc: 0.8535 - val_loss: 0.3949 - val_acc: 0.7912
Epoch 95/100
100/100 [==============================] - 78s 780ms/step - loss: 0.3330 - acc: 0.8589 - val_loss: 0.4805 - val_acc: 0.8222
Epoch 96/100
100/100 [==============================] - 83s 827ms/step - loss: 0.3341 - acc: 0.8533 - val_loss: 0.2260 - val_acc: 0.8273
Epoch 97/100
100/100 [==============================] - 78s 783ms/step - loss: 0.3212 - acc: 0.8621 - val_loss: 0.4926 - val_acc: 0.8338
Epoch 98/100
100/100 [==============================] - 83s 829ms/step - loss: 0.3245 - acc: 0.8526 - val_loss: 0.5733 - val_acc: 0.8177
Epoch 99/100
100/100 [==============================] - 87s 872ms/step - loss: 0.3156 - acc: 0.8628 - val_loss: 0.5779 - val_acc: 0.8204
Epoch 100/100
100/100 [==============================] - 84s 843ms/step - loss: 0.3205 - acc: 0.8589 - val_loss: 0.5135 - val_acc: 0.8479
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 保存模型</span></span><br><span class="line">model.save(<span class="string">'model/ComputerVersion/cats_and_dogs_small_2.h5'</span>)</span><br></pre></td></tr></table></figure>
<p>我们再次绘制结果，使用了数据增强和dropout 之后，模型不再过拟合：训练曲线紧紧跟随着验证曲线。现在的精度为82%，比未正则化的模型提高了15%（相对比例）。</p>
<p>通过进一步使用正则化方法以及调节网络参数（比如每个卷积层的过滤器个数或网络中的层数），你可以得到更高的精度，可以达到86%或87%。但只靠从头开始训练自己的卷积神经网络，再想提高精度就十分困难，因为可用的数据太少。想要在这个问题上进一步提高精度，下一步需要使用预训练的模型，这是接下来两节的重点。</p>
<h1 id="三、使用预训练的卷积神经网络"><a href="#三、使用预训练的卷积神经网络" class="headerlink" title="三、使用预训练的卷积神经网络"></a>三、使用预训练的卷积神经网络</h1><p>想要将深度学习应用于小型图像数据集，一种常用且非常高效的方法是使用预训练网络。预训练网络（pretrained network）是一个保存好的网络，之前已在大型数据集（通常是大规模图像分类任务）上训练好。如果这个原始数据集足够大且足够通用，那么预训练网络学到的特征的空间层次结构可以有效地作为视觉世界的通用模型，因此这些特征可用于各种不同的计算机视觉问题，即使这些新问题涉及的类别和原始任务完全不同。举个例子，你在ImageNet 上训练了一个网络（其类别主要是动物和日常用品），然后将这个训练好的网络应用于某个不相干的任务，比如在图像中识别家具。这种学到的特征在不同问题之间的可移植性，是深度学习与许多早期浅层学习方法相比的重要优势，它使得深度学习对小数据问题非常有效。</p>
<p>本例中，假设有一个在ImageNet 数据集（140 万张标记图像，1000 个不同的类别）上训练好的大型卷积神经网络。ImageNet 中包含许多动物类别，其中包括不同种类的猫和狗，因此可以认为它在猫狗分类问题上也能有良好的表现。我们将使用VGG16 架构，它由Karen Simonyan 和Andrew Zisserman 在2014 年开发a。对于ImageNet，它是一种简单而又广泛使用的卷积神经网络架构。虽然VGG16 是一个比较旧的模型，性能远比不了当前最先进的模型，而且还比许多新模型更为复杂，但我之所以选择它，是因为它的架构与你已经熟悉的架构很相似，因此无须引入新概念就可以很好地理解。这可能是你第一次遇到这种奇怪的模型名称——VGG、ResNet、Inception、Inception-ResNet、Xception 等。你会习惯这些名称的，因为如果你一直用深度学习做计算机视觉的话，它们会频繁出现。使用预训练网络有两种方法：<strong>特征提取</strong>（feature extraction）和<strong>微调模型</strong>（fine-tuning）。两种方法我们都会介绍。首先来看特征提取。</p>
<h2 id="1-特征提取"><a href="#1-特征提取" class="headerlink" title="1. 特征提取"></a>1. 特征提取</h2><p>特征提取是使用之前网络学到的表示来从新样本中提取出有趣的特征。然后将这些特征输入一个新的分类器，从头开始训练。</p>
<p>如前所述，用于图像分类的卷积神经网络包含两部分：首先是一系列池化层和卷积层，最后是一个密集连接分类器。第一部分叫作模型的卷积基（convolutional base）。对于卷积神经网络而言，特征提取就是取出之前训练好的网络的卷积基，在上面运行新数据，然后在输出上面训练一个新的分类器</p>
<center>
    <img src="\Pic\DeepLearning_Pic\预训练模型1.png" width="300" height="300" alt="保持卷积基不变，改变分类器" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">保持卷积基不变，改变分类器</div>
</center>

<p>为什么仅重复使用卷积基？我们能否也重复使用密集连接分类器？一般来说，应该避免这么做。原因在于卷积基学到的表示可能更加通用，因此更适合重复使用。卷积神经网络的特征图表示通用概念在图像中是否存在，无论面对什么样的计算机视觉问题，这种特征图都可能很有用。但是，分类器学到的表示必然是针对于模型训练的类别，其中仅包含某个类别出现在整张图像中的概率信息。此外，密集连接层的表示不再包含物体在输入图像中的位置信息。密集连接层舍弃了空间的概念，而物体位置信息仍然由卷积特征图所描述。如果物体位置对于问题很重要，那么密集连接层的特征在很大程度上是无用的。</p>
<p>注意，某个卷积层提取的表示的通用性（以及可复用性）取决于该层在模型中的深度。模型中更靠近底部的层提取的是局部的、高度通用的特征图（比如视觉边缘、颜色和纹理），而更靠近顶部的层提取的是更加抽象的概念（比如“猫耳朵”或“狗眼睛”）。因此，如果你的新数据集与原始模型训练的数据集有很大差异，那么最好只使用模型的前几层来做特征提取，而不是使用整个卷积基。</p>
<p>本例中，由于ImageNet的类别中包含多种狗和猫的类别，所以重复使用原始模型密集连接层中所包含的信息可能很有用。但我们选择不这么做，以便涵盖新问题的类别与原始模型的类别不一致的更一般情况。我们来实践一下，使用在ImageNet上训练的VGG16 网络的卷积基从猫狗图像中提取有趣的特征，然后在这些特征上训练一个猫狗分类器。VGG16 等模型内置于Keras 中。你可以从<code>keras.applications</code>模块中导入。下面是<code>keras.applications</code>中的一部分图像分类模型（都是在ImageNet数据集上预训练得到的）：</p>
<ul>
<li>Xception</li>
<li>Inception V3</li>
<li>ResNet50</li>
<li>VGG16</li>
<li>VGG19</li>
<li>MobileNet</li>
</ul>
<p>我们将<code>VGG16</code>模型实例化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将 VGG16 卷积基实例化</span></span><br><span class="line"><span class="keyword">from</span> keras.applications <span class="keyword">import</span> VGG16</span><br><span class="line">conv_base = VGG1616(weights=<span class="string">'imagenet'</span>, include_top=<span class="literal">False</span>, input_shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>))</span><br></pre></td></tr></table></figure>
<p>这里向构造函数中传入了三个参数。</p>
<ul>
<li>weights指定模型初始化的权重检查点。</li>
<li>include_top 指定模型最后是否包含密集连接分类器。默认情况下，这个密集连接分类器对应于ImageNet的1000个类别。因为我们打算使用自己的密集连接分类器（只有两个类别：cat和dog），所以不需要包含它。</li>
<li>input_shape是输入到网络中的图像张量的形状。这个参数完全是可选的，如果不传入这个参数，那么网络能够处理任意形状的输入。VGG16卷积基的详细架构如下所示。它和你已经熟悉的简单卷积神经网络很相似。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">conv_base.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;vgg16&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 150, 150, 3)       0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         
=================================================================
Total params: 14,714,688
Trainable params: 14,714,688
Non-trainable params: 0
_________________________________________________________________
</code></pre><p>最后的特征图形状为(4, 4, 512)。我们将在这个特征上添加一个密集连接分类器。接下来，下一步有两种方法可供选择：</p>
<ul>
<li>在你的数据集上运行卷积基，将输出保存成硬盘中的Numpy数组，然后用这个数据作为输入，输入到独立的密集连接分类器中。这种方法速度快，计算代价低，因为对于每个输入图像只需运行一次卷积基，而卷积基是目前流程中计算代价最高的。但出于同样的原因，这种方法不允许你使用数据增强。</li>
<li>在顶部添加<code>Dense</code>层来扩展已有模型（即<code>conv_base</code>），并在输入数据上端到端地运行整个模型。这样你可以使用数据增强，因为每个输入图像进入模型时都会经过卷积基。但出于同样的原因，这种方法的计算代价比第一种要高很多。</li>
</ul>
<h2 id="2-不使用数据增强的快速特征提取"><a href="#2-不使用数据增强的快速特征提取" class="headerlink" title="2. 不使用数据增强的快速特征提取"></a>2. 不使用数据增强的快速特征提取</h2><p>首先，运行<code>ImageDataGenerator</code>实例，将图像及其标签提取为<code>Numpy</code>数组。我们需要调用<code>conv_base</code>模型的<code>predict</code>方法来从这些图像中提取特征。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用预训练的卷积基提取特征</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line">base_dir = <span class="string">'data/cat_dog/cats_and_dogs_small'</span></span><br><span class="line">train_dir = os.path.join(base_dir, <span class="string">'train'</span>)</span><br><span class="line">validation_dir = os.path.join(base_dir, <span class="string">'validation'</span>)</span><br><span class="line">test_dir = os.path.join(base_dir, <span class="string">'test'</span>)</span><br><span class="line">datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line">batch_size = <span class="number">20</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_features</span><span class="params">(directory, sample_count)</span>:</span></span><br><span class="line">    features = np.zeros(shape=(sample_count, <span class="number">4</span>, <span class="number">4</span>, <span class="number">512</span>))</span><br><span class="line">    labels = np.zeros(shape=(sample_count))</span><br><span class="line">    generator = datagen.flow_from_directory(</span><br><span class="line">        directory,</span><br><span class="line">        target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">        batch_size=batch_size,</span><br><span class="line">        class_mode=<span class="string">'binary'</span>)</span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> inputs_batch, labels_batch <span class="keyword">in</span> generator:</span><br><span class="line">        features_batch = conv_base.predict(inputs_batch)</span><br><span class="line">        features[i * batch_size : (i + <span class="number">1</span>) * batch_size] = features_batch</span><br><span class="line">        labels[i * batch_size : (i + <span class="number">1</span>) * batch_size] = labels_batch</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> i * batch_size &gt;= sample_count:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> features, labels</span><br><span class="line"></span><br><span class="line">train_features, train_labels = extract_features(train_dir, <span class="number">2000</span>)</span><br><span class="line">validation_features, validation_labels = extract_features(validation_dir, <span class="number">1000</span>)</span><br><span class="line">test_features, test_labels = extract_features(test_dir, <span class="number">1000</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Found 2000 images belonging to 2 classes.
Found 1000 images belonging to 2 classes.
Found 1000 images belonging to 2 classes.
</code></pre><p>目前，提取的特征形状为<code>(samples, 4, 4, 512)</code>。我们要将其输入到密集连接分类器中，所以首先必须将其形状展平为<code>(samples, 8192)</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_features = np.reshape(train_features, (<span class="number">2000</span>, <span class="number">4</span> * <span class="number">4</span> * <span class="number">512</span>))</span><br><span class="line">validation_features = np.reshape(validation_features, (<span class="number">1000</span>, <span class="number">4</span> * <span class="number">4</span> * <span class="number">512</span>))</span><br><span class="line">test_features = np.reshape(test_features, (<span class="number">1000</span>, <span class="number">4</span> * <span class="number">4</span> * <span class="number">512</span>))</span><br></pre></td></tr></table></figure>
<p>现在你可以定义你的密集连接分类器（注意要使用<code>dropout</code>正则化），并在刚刚保存的数据和标签上训练这个分类器。</p>
<h3 id="定义并训练密集连接分类器"><a href="#定义并训练密集连接分类器" class="headerlink" title="定义并训练密集连接分类器"></a>定义并训练密集连接分类器</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimizers</span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">256</span>, activation=<span class="string">'relu'</span>, input_dim=<span class="number">4</span> * <span class="number">4</span> * <span class="number">512</span>))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line">model.compile(optimizer=optimizers.RMSprop(lr=<span class="number">2e-5</span>),</span><br><span class="line">    loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">    metrics=[<span class="string">'acc'</span>])</span><br><span class="line">history = model.fit(train_features, train_labels,</span><br><span class="line">    epochs=<span class="number">30</span>,</span><br><span class="line">    batch_size=<span class="number">20</span>,</span><br><span class="line">    validation_data=(validation_features, validation_labels))</span><br></pre></td></tr></table></figure>
<pre><code>Train on 2000 samples, validate on 1000 samples
Epoch 1/30
2000/2000 [==============================] - 4s 2ms/step - loss: 0.6064 - acc: 0.6600 - val_loss: 0.4430 - val_acc: 0.8350
Epoch 2/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.4158 - acc: 0.8210 - val_loss: 0.3588 - val_acc: 0.8610
Epoch 3/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.3449 - acc: 0.8585 - val_loss: 0.3250 - val_acc: 0.8770
Epoch 4/30
2000/2000 [==============================] - 4s 2ms/step - loss: 0.3145 - acc: 0.8645 - val_loss: 0.3024 - val_acc: 0.8840
Epoch 5/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.2900 - acc: 0.8800 - val_loss: 0.2865 - val_acc: 0.8910
Epoch 6/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.2563 - acc: 0.8995 - val_loss: 0.2808 - val_acc: 0.8860
Epoch 7/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.2441 - acc: 0.9035 - val_loss: 0.2654 - val_acc: 0.8950
Epoch 8/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.2302 - acc: 0.9185 - val_loss: 0.2627 - val_acc: 0.8950
Epoch 9/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.2226 - acc: 0.9095 - val_loss: 0.2599 - val_acc: 0.8930
Epoch 10/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1979 - acc: 0.9275 - val_loss: 0.2521 - val_acc: 0.9010
Epoch 11/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1949 - acc: 0.9305 - val_loss: 0.2537 - val_acc: 0.8940
Epoch 12/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1872 - acc: 0.9390 - val_loss: 0.2518 - val_acc: 0.8990
Epoch 13/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1781 - acc: 0.9275 - val_loss: 0.2451 - val_acc: 0.8980
Epoch 14/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1662 - acc: 0.9430 - val_loss: 0.2477 - val_acc: 0.9060
Epoch 15/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1632 - acc: 0.9450 - val_loss: 0.2449 - val_acc: 0.8980
Epoch 16/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1530 - acc: 0.9480 - val_loss: 0.2389 - val_acc: 0.9030
Epoch 17/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1477 - acc: 0.9465 - val_loss: 0.2454 - val_acc: 0.9010
Epoch 18/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1434 - acc: 0.9525 - val_loss: 0.2463 - val_acc: 0.8990
Epoch 19/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1346 - acc: 0.9550 - val_loss: 0.2390 - val_acc: 0.9020
Epoch 20/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1305 - acc: 0.9595 - val_loss: 0.2374 - val_acc: 0.9000
Epoch 21/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1216 - acc: 0.9630 - val_loss: 0.2430 - val_acc: 0.9000
Epoch 22/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1166 - acc: 0.9625 - val_loss: 0.2381 - val_acc: 0.9030
Epoch 23/30
2000/2000 [==============================] - 4s 2ms/step - loss: 0.1103 - acc: 0.9685 - val_loss: 0.2373 - val_acc: 0.9030
Epoch 24/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1112 - acc: 0.9635 - val_loss: 0.2460 - val_acc: 0.9020
Epoch 25/30
2000/2000 [==============================] - 4s 2ms/step - loss: 0.1067 - acc: 0.9675 - val_loss: 0.2380 - val_acc: 0.8990
Epoch 26/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.1004 - acc: 0.9695 - val_loss: 0.2378 - val_acc: 0.9000
Epoch 27/30
2000/2000 [==============================] - 4s 2ms/step - loss: 0.0994 - acc: 0.9680 - val_loss: 0.2450 - val_acc: 0.9030
Epoch 28/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.0947 - acc: 0.9710 - val_loss: 0.2396 - val_acc: 0.9010
Epoch 29/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.0870 - acc: 0.9770 - val_loss: 0.2416 - val_acc: 0.9020
Epoch 30/30
2000/2000 [==============================] - 3s 2ms/step - loss: 0.0870 - acc: 0.9730 - val_loss: 0.2473 - val_acc: 0.9010
</code></pre><p>训练速度非常快，因为你只需处理两个Dense 层。我们来看一下训练期间的损失曲线和精度曲线：</p>
<h3 id="绘制结果"><a href="#绘制结果" class="headerlink" title="绘制结果"></a>绘制结果</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">acc = history.history[<span class="string">'acc'</span>]</span><br><span class="line">val_acc = history.history[<span class="string">'val_acc'</span>]</span><br><span class="line">loss = history.history[<span class="string">'loss'</span>]</span><br><span class="line">val_loss = history.history[<span class="string">'val_loss'</span>]</span><br><span class="line"></span><br><span class="line">epochs = range(<span class="number">1</span>, len(acc) + <span class="number">1</span>)</span><br><span class="line">plt.plot(epochs, acc, <span class="string">'bo'</span>, label=<span class="string">'Training acc'</span>)</span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">'b'</span>, label=<span class="string">'Validation acc'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation accuracy'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(epochs, loss, <span class="string">'bo'</span>, label=<span class="string">'Training loss'</span>)</span><br><span class="line">plt.plot(epochs, val_loss, <span class="string">'b'</span>, label=<span class="string">'Validation loss'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_51_0.png" width="400" height="400" alt="训练损失和验证损失" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">训练损失和验证损失</div>
</center>


<center>
    <img src="\Pic\DeepLearning_Pic\output_51_1.png" width="400" height="400" alt="训练精度和验证精度" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">训练精度和验证精度</div>
</center>


<p>我们的验证精度达到了约90%，比上一节从头开始训练的小型模型效果要好得多。但从图中也可以看出，虽然<code>dropout</code>比率相当大，但模型几乎从一开始就过拟合。这是因为本方法没有使用数据增强，而数据增强对防止小型图像数据集的过拟合非常重要。</p>
<h2 id="3-使用数据增强的特征提取"><a href="#3-使用数据增强的特征提取" class="headerlink" title="3. 使用数据增强的特征提取"></a>3. 使用数据增强的特征提取</h2><p>下面我们来看一下特征提取的第二种方法，它的速度更慢，计算代价更高，但在训练期间可以使用数据增强。这种方法就是：扩展<code>conv_base</code>模型，然后在输入数据上端到端地运行模型。</p>
<blockquote>
<p>注意 本方法计算代价很高，只在有GPU的情况下才能尝试运行。它在CPU上是绝对难以运行的。如果你无法在GPU上运行代码，那么就采用第一种方法。</p>
</blockquote>
<p>模型的行为和层类似，所以你可以向<code>Sequential</code>模型中添加一个模型（比如<code>conv_base</code>），就像添加一个层一样。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在卷积基上添加一个密集连接分类器</span></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(conv_base)</span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dense(<span class="number">256</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br></pre></td></tr></table></figure>
<p>现在模型的架构如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_7&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
vgg16 (Model)                (None, 4, 4, 512)         14714688  
_________________________________________________________________
flatten_4 (Flatten)          (None, 8192)              0         
_________________________________________________________________
dense_9 (Dense)              (None, 256)               2097408   
_________________________________________________________________
dense_10 (Dense)             (None, 1)                 257       
=================================================================
Total params: 16,812,353
Trainable params: 16,812,353
Non-trainable params: 0
_________________________________________________________________
</code></pre><p>如你所见，<code>VGG16</code>的卷积基有14 714 688个参数，非常多。在其上添加的分类器有200万个参数。</p>
<p>在编译和训练模型之前，一定要“冻结”卷积基。冻结（<code>freeze</code>）一个或多个层是指在训练过程中保持其权重不变。如果不这么做，那么卷积基之前学到的表示将会在训练过程中被修改。因为其上添加的<code>Dense</code>层是随机初始化的，所以非常大的权重更新将会在网络中传播，对之前学到的表示造成很大破坏。</p>
<p>在<code>Keras</code>中，冻结网络的方法是将其<code>trainable</code>属性设为<code>False</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(<span class="string">'This is the number of trainable weights before freezing the conv base:'</span>, len(model.trainable_weights))</span><br><span class="line">conv_base.trainable = <span class="literal">False</span></span><br><span class="line">print(<span class="string">'This is the number of trainable weights after freezing the conv base:'</span>, len(model.trainable_weights))</span><br></pre></td></tr></table></figure>
<pre><code>This is the number of trainable weights before freezing the conv base: 30
This is the number of trainable weights after freezing the conv base: 4
</code></pre><p>如此设置之后，只有添加的两个Dense 层的权重才会被训练。总共有4 个权重张量，每层 2 个（主权重矩阵和偏置向量）。注意，为了让这些修改生效，你必须先编译模型。如果在编译之后修改了权重的<code>trainable</code>属性，那么应该重新编译模型，否则这些修改将被忽略。</p>
<p>现在你可以开始训练模型了，使用和前一个例子相同的数据增强设置。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 利用冻结的卷积基端到端地训练模型</span></span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimizers</span><br><span class="line"></span><br><span class="line">train_datagen = ImageDataGenerator(</span><br><span class="line">    rescale=<span class="number">1.</span>/<span class="number">255</span>,</span><br><span class="line">    rotation_range=<span class="number">40</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    shear_range=<span class="number">0.2</span>,</span><br><span class="line">    zoom_range=<span class="number">0.2</span>,</span><br><span class="line">    horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">    fill_mode=<span class="string">'nearest'</span>)</span><br><span class="line"></span><br><span class="line">test_datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line"></span><br><span class="line">train_generator = train_datagen.flow_from_directory(</span><br><span class="line">    train_dir,</span><br><span class="line">    target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">    batch_size=<span class="number">20</span>,</span><br><span class="line">    class_mode=<span class="string">'binary'</span>)</span><br><span class="line"></span><br><span class="line">validation_generator = test_datagen.flow_from_directory(</span><br><span class="line">    validation_dir,</span><br><span class="line">    target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">    batch_size=<span class="number">20</span>,</span><br><span class="line">    class_mode=<span class="string">'binary'</span>)</span><br><span class="line"></span><br><span class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">    optimizer=optimizers.RMSprop(lr=<span class="number">2e-5</span>),</span><br><span class="line">    metrics=[<span class="string">'acc'</span>])</span><br></pre></td></tr></table></figure>
<pre><code>Found 2000 images belonging to 2 classes.
Found 1000 images belonging to 2 classes.
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">history = model.fit_generator(</span><br><span class="line">    train_generator,</span><br><span class="line">    steps_per_epoch=<span class="number">100</span>,</span><br><span class="line">    epochs=<span class="number">30</span>,</span><br><span class="line">    validation_data=validation_generator,</span><br><span class="line">    validation_steps=<span class="number">50</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1/30
100/100 [==============================] - 154s 2s/step - loss: 0.3479 - acc: 0.8495 - val_loss: 0.1390 - val_acc: 0.8900
Epoch 2/30
100/100 [==============================] - 165s 2s/step - loss: 0.3448 - acc: 0.8560 - val_loss: 0.2075 - val_acc: 0.9010
Epoch 3/30
100/100 [==============================] - 178s 2s/step - loss: 0.3488 - acc: 0.8435 - val_loss: 0.2230 - val_acc: 0.9020
Epoch 4/30
100/100 [==============================] - 176s 2s/step - loss: 0.3232 - acc: 0.8555 - val_loss: 0.1981 - val_acc: 0.9030
Epoch 5/30
100/100 [==============================] - 166s 2s/step - loss: 0.3177 - acc: 0.8700 - val_loss: 0.3433 - val_acc: 0.8960
Epoch 6/30
100/100 [==============================] - 166s 2s/step - loss: 0.3232 - acc: 0.8630 - val_loss: 0.3095 - val_acc: 0.8990
Epoch 7/30
100/100 [==============================] - 170s 2s/step - loss: 0.3226 - acc: 0.8575 - val_loss: 0.1717 - val_acc: 0.9000
Epoch 8/30
100/100 [==============================] - 166s 2s/step - loss: 0.2967 - acc: 0.8735 - val_loss: 0.1980 - val_acc: 0.9020
Epoch 9/30
100/100 [==============================] - 165s 2s/step - loss: 0.3155 - acc: 0.8650 - val_loss: 0.5357 - val_acc: 0.8940
Epoch 10/30
100/100 [==============================] - 164s 2s/step - loss: 0.3109 - acc: 0.8570 - val_loss: 0.1268 - val_acc: 0.9020
Epoch 11/30
100/100 [==============================] - 164s 2s/step - loss: 0.3071 - acc: 0.8620 - val_loss: 0.4099 - val_acc: 0.8990
Epoch 12/30
100/100 [==============================] - 167s 2s/step - loss: 0.3166 - acc: 0.8585 - val_loss: 0.1766 - val_acc: 0.9000
Epoch 13/30
100/100 [==============================] - 163s 2s/step - loss: 0.2989 - acc: 0.8740 - val_loss: 0.1520 - val_acc: 0.9050
Epoch 14/30
100/100 [==============================] - 163s 2s/step - loss: 0.2943 - acc: 0.8730 - val_loss: 0.2935 - val_acc: 0.9010
Epoch 15/30
100/100 [==============================] - 163s 2s/step - loss: 0.2965 - acc: 0.8730 - val_loss: 0.5893 - val_acc: 0.9000
Epoch 16/30
100/100 [==============================] - 164s 2s/step - loss: 0.2848 - acc: 0.8775 - val_loss: 0.1792 - val_acc: 0.9070
Epoch 17/30
100/100 [==============================] - 166s 2s/step - loss: 0.2841 - acc: 0.8810 - val_loss: 0.2951 - val_acc: 0.9040
Epoch 18/30
100/100 [==============================] - 165s 2s/step - loss: 0.3002 - acc: 0.8650 - val_loss: 0.2552 - val_acc: 0.9030
Epoch 19/30
100/100 [==============================] - 165s 2s/step - loss: 0.3013 - acc: 0.8690 - val_loss: 0.4531 - val_acc: 0.8970
Epoch 20/30
100/100 [==============================] - 164s 2s/step - loss: 0.2898 - acc: 0.8750 - val_loss: 0.2342 - val_acc: 0.9070
Epoch 21/30
100/100 [==============================] - 165s 2s/step - loss: 0.2806 - acc: 0.8815 - val_loss: 0.2162 - val_acc: 0.9050
Epoch 22/30
100/100 [==============================] - 165s 2s/step - loss: 0.2854 - acc: 0.8750 - val_loss: 0.3686 - val_acc: 0.9040
Epoch 23/30
100/100 [==============================] - 165s 2s/step - loss: 0.2948 - acc: 0.8635 - val_loss: 0.2450 - val_acc: 0.9110
Epoch 24/30
100/100 [==============================] - 175s 2s/step - loss: 0.2738 - acc: 0.8790 - val_loss: 0.1684 - val_acc: 0.9100
Epoch 25/30
100/100 [==============================] - 170s 2s/step - loss: 0.2792 - acc: 0.8765 - val_loss: 0.1878 - val_acc: 0.9080
Epoch 26/30
100/100 [==============================] - 167s 2s/step - loss: 0.2687 - acc: 0.8855 - val_loss: 0.3175 - val_acc: 0.9080
Epoch 27/30
100/100 [==============================] - 172s 2s/step - loss: 0.2655 - acc: 0.8930 - val_loss: 0.1548 - val_acc: 0.9090
Epoch 28/30
100/100 [==============================] - 179s 2s/step - loss: 0.2628 - acc: 0.8910 - val_loss: 0.1822 - val_acc: 0.9020
Epoch 29/30
100/100 [==============================] - 177s 2s/step - loss: 0.2766 - acc: 0.8720 - val_loss: 0.2272 - val_acc: 0.9110
Epoch 30/30
100/100 [==============================] - 176s 2s/step - loss: 0.2676 - acc: 0.8815 - val_loss: 0.1242 - val_acc: 0.9120
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.save(<span class="string">'model/ComputerVersion/cats_and_dogs_small_dataEnforcementFeatureExtraction.h5'</span>)</span><br></pre></td></tr></table></figure>
<p>如你所见，这比从头开始训练的小型卷积神经网络要好得多。</p>
<h2 id="4-微调模型"><a href="#4-微调模型" class="headerlink" title="4. 微调模型"></a>4. 微调模型</h2><p>另一种广泛使用的模型复用方法是模型微调（fine-tuning），与特征提取互为补充。对于用于特征提取的冻结的模型基，微调是指将其顶部的几层“解冻”，并将这解冻的几层和新增加的部分（本例中是全连接分类器）联合训练。之所以叫作微调，是因为它只是略微调整了所复用模型中更加抽象的表示，以便让这些表示与手头的问题更加相关。</p>
<center>
    <img src="\Pic\DeepLearning_Pic\fine_tuning.png" width="200" height="200" alt="微调VGG16网络的最后一个卷积块" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">微调VGG16网络的最后一个卷积块</div>
</center>

<p>前面说过，冻结VGG16的卷积基是为了能够在上面训练一个随机初始化的分类器。同理，只有上面的分类器已经训练好了，才能微调卷积基的顶部几层。如果分类器没有训练好，那么训练期间通过网络传播的误差信号会特别大，微调的几层之前学到的表示都会被破坏。因此，微调网络的步骤如下。</p>
<ol>
<li>在已经训练好的基网络（base network）上添加自定义网络。</li>
<li>冻结基网络。</li>
<li>训练所添加的部分。</li>
<li>解冻基网络的一些层。</li>
<li>联合训练解冻的这些层和添加的部分。</li>
</ol>
<p>你在做特征提取时已经完成了前三个步骤。我们继续进行第四步：先解冻<code>conv_base</code>，然后冻结其中的部分层。提醒一下，卷积基的架构如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">conv_base.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;vgg16&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 150, 150, 3)       0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         
=================================================================
Total params: 14,714,688
Trainable params: 7,079,424
Non-trainable params: 7,635,264
_________________________________________________________________
</code></pre><p>我们将微调最后三个卷积层，也就是说，直到<code>block4_pool</code>的所有层都应该被冻结，而<code>block5_conv1</code>、<code>block5_conv2</code>和<code>block5_conv3</code>三层应该是可训练的。为什么不微调更多层？为什么不微调整个卷积基？你当然可以这么做，但需要考虑以下几点。</p>
<ul>
<li>卷积基中更靠底部的层编码的是更加通用的可复用特征，而更靠顶部的层编码的是更专业化的特征。微调这些更专业化的特征更加有用，因为它们需要在你的新问题上改变用途。微调更靠底部的层，得到的回报会更少。</li>
<li>训练的参数越多，过拟合的风险越大。卷积基有 1500 万个参数，所以在你的小型数据集上训练这么多参数是有风险的。</li>
</ul>
<p>因此，在这种情况下，一个好策略是仅微调卷积基最后的两三层。我们从上一个例子结束的地方开始，继续实现此方法。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 冻结直到某一层的所有层</span></span><br><span class="line">conv_base.trainable = <span class="literal">True</span></span><br><span class="line">set_trainable = <span class="literal">False</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> conv_base.layers:</span><br><span class="line">    <span class="keyword">if</span> layer.name == <span class="string">'block5_conv1'</span>:</span><br><span class="line">        set_trainable = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">if</span> set_trainable:</span><br><span class="line">        layer.trainable = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        layer.trainable = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>现在你可以开始微调网络。我们将使用学习率非常小的RMSProp优化器来实现。之所以让学习率很小，是因为对于微调的三层表示，我们希望其变化范围不要太大，太大的权重更新可能会破坏这些表示。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 微调模型</span></span><br><span class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">    optimizer=optimizers.RMSprop(lr=<span class="number">1e-5</span>),</span><br><span class="line">    metrics=[<span class="string">'acc'</span>])</span><br><span class="line">history = model.fit_generator(</span><br><span class="line">    train_generator,</span><br><span class="line">    steps_per_epoch=<span class="number">100</span>,</span><br><span class="line">    epochs=<span class="number">100</span>,</span><br><span class="line">    validation_data=validation_generator,</span><br><span class="line">    validation_steps=<span class="number">50</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.save(<span class="string">'model/ComputerVersion/cats_and_dogs_small_dataEnforcementFineTuning.h5'</span>)</span><br></pre></td></tr></table></figure>
<p>我们用和前面一样的绘图代码来绘制结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">acc = history.history[<span class="string">'acc'</span>]</span><br><span class="line">val_acc = history.history[<span class="string">'val_acc'</span>]</span><br><span class="line">loss = history.history[<span class="string">'loss'</span>]</span><br><span class="line">val_loss = history.history[<span class="string">'val_loss'</span>]</span><br><span class="line"></span><br><span class="line">epochs = range(<span class="number">1</span>, len(acc) + <span class="number">1</span>)</span><br><span class="line">plt.plot(epochs, acc, <span class="string">'bo'</span>, label=<span class="string">'Training acc'</span>)</span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">'b'</span>, label=<span class="string">'Validation acc'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation accuracy'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(epochs, loss, <span class="string">'bo'</span>, label=<span class="string">'Training loss'</span>)</span><br><span class="line">plt.plot(epochs, val_loss, <span class="string">'b'</span>, label=<span class="string">'Validation loss'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_70_0.png" width="400" height="400" alt="训练精度和验证精度" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">训练精度和验证精度</div>
</center>

<center>
    <img src="\Pic\DeepLearning_Pic\output_70_1.png" width="400" height="400" alt="训练损失和验证损失" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">训练损失和验证损失</div>
</center>




<p>这些曲线看起来包含噪声。为了让图像更具可读性，你可以将每个损失和精度都替换为指数移动平均值，从而让曲线变得平滑。下面用一个简单的实用函数来实现</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使曲线变得平滑</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">smooth_curve</span><span class="params">(points, factor=<span class="number">0.8</span>)</span>:</span></span><br><span class="line">    smoothed_points = []</span><br><span class="line">    <span class="keyword">for</span> point <span class="keyword">in</span> points:</span><br><span class="line">        <span class="keyword">if</span> smoothed_points:</span><br><span class="line">            previous = smoothed_points[<span class="number">-1</span>]</span><br><span class="line">            smoothed_points.append(previous * factor + point * (<span class="number">1</span> - factor))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            smoothed_points.append(point)</span><br><span class="line">    <span class="keyword">return</span> smoothed_points</span><br><span class="line"></span><br><span class="line">plt.plot(epochs,smooth_curve(acc), <span class="string">'bo'</span>, label=<span class="string">'Smoothed training acc'</span>)</span><br><span class="line">plt.plot(epochs,smooth_curve(val_acc), <span class="string">'b'</span>, label=<span class="string">'Smoothed validation acc'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation accuracy'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(epochs,smooth_curve(loss), <span class="string">'bo'</span>, label=<span class="string">'Smoothed training loss'</span>)</span><br><span class="line">plt.plot(epochs,smooth_curve(val_loss), <span class="string">'b'</span>, label=<span class="string">'Smoothed validation loss'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_72_0.png" width="400" height="400" alt="训练精度和验证精度" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">平滑后的训练精度和验证精度</div>
</center>

<center>
    <img src="\Pic\DeepLearning_Pic\output_72_1.png" width="400" height="400" alt="训练损失和验证损失" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">平滑后的训练损失和验证损失</div>
</center>


<p>注意，从损失曲线上看不出与之前相比有任何真正的提高（实际上还在变差）。你可能感到奇怪，如果损失没有降低，那么精度怎么能保持稳定或提高呢？答案很简单：图中展示的是逐点（pointwise）损失值的平均值，但影响精度的是损失值的分布，而不是平均值，因为精度是模型预测的类别概率的二进制阈值。即使从平均损失中无法看出，但模型也仍然可能在改进。现在，你可以在测试数据上最终评估这个模型。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">test_generator = test_datagen.flow_from_directory(</span><br><span class="line">    test_dir,</span><br><span class="line">    target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">    batch_size=<span class="number">20</span>,</span><br><span class="line">    class_mode=<span class="string">'binary'</span>)</span><br><span class="line">test_loss, test_acc = model.evaluate_generator(test_generator, steps=<span class="number">50</span>)</span><br><span class="line">print(<span class="string">'test acc:'</span>, test_acc)</span><br></pre></td></tr></table></figure>
<pre><code>Found 1000 images belonging to 2 classes.
test acc: 0.9399999976158142
</code></pre><h1 id="四、卷积神经网络的可视化"><a href="#四、卷积神经网络的可视化" class="headerlink" title="四、卷积神经网络的可视化"></a>四、卷积神经网络的可视化</h1><p>人们常说，深度学习模型是“黑盒”，即模型学到的表示很难用人类可以理解的方式来提取和呈现。虽然对于某些类型的深度学习模型来说，这种说法部分正确，但对卷积神经网络来说绝对不是这样。卷积神经网络学到的表示非常适合可视化，很大程度上是因为它们是视觉概念的表示。自2013 年以来，人们开发了多种技术来对这些表示进行可视化和解释。我们不会全部介绍，但会介绍三种最容易理解也最有用的方法。</p>
<ul>
<li>可视化卷积神经网络的中间输出（中间激活）：有助于理解卷积神经网络连续的层如何对输入进行变换，也有助于初步了解卷积神经网络每个过滤器的含义。</li>
<li>可视化卷积神经网络的过滤器：有助于精确理解卷积神经网络中每个过滤器容易接受的视觉模式或视觉概念。</li>
<li>可视化图像中类激活的热力图：有助于理解图像的哪个部分被识别为属于某个类别，从而可以定位图像中的物体。</li>
</ul>
<p>对于第一种方法（即激活的可视化），我们将使用猫狗分类问题上从头开始训练的小型卷积神经网络。对于另外两种可视化方法，我们将使用VGG16模型。</p>
<h2 id="1-可视化中间激活"><a href="#1-可视化中间激活" class="headerlink" title="1. 可视化中间激活"></a>1. 可视化中间激活</h2><p>可视化中间激活，是指对于给定输入，展示网络中各个卷积层和池化层输出的特征图（层的输出通常被称为该层的激活，即激活函数的输出）。这让我们可以看到输入如何被分解为网络学到的不同过滤器。我们希望在三个维度对特征图进行可视化：宽度、高度和深度（通道）。每个通道都对应相对独立的特征，所以将这些特征图可视化的正确方法是将每个通道的内容分别绘制成二维图像。我们首先来加载先前保存的模型。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line">model = load_model(<span class="string">'model/ComputerVersion/cats_and_dogs_small_2.h5'</span>)</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_5&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_11 (Conv2D)           (None, 148, 148, 32)      896       
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 74, 74, 32)        0         
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 72, 72, 64)        18496     
_________________________________________________________________
max_pooling2d_8 (MaxPooling2 (None, 36, 36, 64)        0         
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 34, 34, 128)       73856     
_________________________________________________________________
max_pooling2d_9 (MaxPooling2 (None, 17, 17, 128)       0         
_________________________________________________________________
conv2d_14 (Conv2D)           (None, 15, 15, 128)       147584    
_________________________________________________________________
max_pooling2d_10 (MaxPooling (None, 7, 7, 128)         0         
_________________________________________________________________
flatten_3 (Flatten)          (None, 6272)              0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 6272)              0         
_________________________________________________________________
dense_5 (Dense)              (None, 512)               3211776   
_________________________________________________________________
dense_6 (Dense)              (None, 1)                 513       
=================================================================
Total params: 3,453,121
Trainable params: 3,453,121
Non-trainable params: 0
_________________________________________________________________
</code></pre><p>接下来，我们需要一张输入图像，即一张猫的图像，它不属于网络的训练图像。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">img_path = <span class="string">"data/cat_dog/cats_and_dogs_small/test/cats/cat.1700.jpg"</span></span><br><span class="line">img = image.load_img(img_path, target_size=(<span class="number">150</span>, <span class="number">150</span>))</span><br><span class="line">img_tensor = image.img_to_array(img)</span><br><span class="line">img_tensor = np.expand_dims(img_tensor, axis=<span class="number">0</span>)</span><br><span class="line">img_tensor /= <span class="number">255.</span></span><br><span class="line">print(img_tensor.shape)</span><br></pre></td></tr></table></figure>
<pre><code>(1, 150, 150, 3)
</code></pre><p>我们来显示这张图像</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.imshow(img_tensor[<span class="number">0</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_80_0.png" width="400" height="400" alt="a" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<p>为了提取想要查看的特征图，我们需要创建一个<code>Keras</code>模型，以图像批量作为输入，并输出所有卷积层和池化层的激活。为此，我们需要使用<code>Keras</code>的<code>Model</code>类。模型实例化需要两个参数：一个输入张量（或输入张量的列表）和一个输出张量（或输出张量的列表）。得到的类是一个<code>Keras</code>模型，就像你熟悉的<code>Sequential</code>模型一样，将特定输入映射为特定输出。<code>Model</code>类允许模型有多个输出，这一点与<code>Sequential</code>模型不同。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 用一个输入张量和一个输出张量列表将模型实例化</span></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line">layer_outputs = [layer.output <span class="keyword">for</span> layer <span class="keyword">in</span> model.layers[:<span class="number">8</span>]]</span><br><span class="line">activation_model = models.Model(inputs=model.input, outputs=layer_outputs)</span><br></pre></td></tr></table></figure>
<p>输入一张图像，这个模型将返回原始模型前8 层的激活值。这是第一次遇到的多输出模型，之前的模型都是只有一个输入和一个输出。一般情况下，模型可以有任意个输入和输出。这个模型有一个输入和8 个输出，即每层激活对应一个输出。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 以预测模式运行模型</span></span><br><span class="line">activations = activation_model.predict(img_tensor)</span><br><span class="line"><span class="comment"># 例如，对于输入的猫图像，第一个卷积层的激活如下所示。</span></span><br><span class="line">first_layer_activation = activations[<span class="number">0</span>]</span><br><span class="line">print(first_layer_activation.shape)</span><br></pre></td></tr></table></figure>
<pre><code>(1, 148, 148, 32)
</code></pre><p>它是大小为148×148的特征图，有32个通道。我们来绘制原始模型第一层激活的第4个通道</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将第4个通道可视化</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.matshow(first_layer_activation[<span class="number">0</span>, :, :, <span class="number">4</span>], cmap=<span class="string">'viridis'</span>)</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_86_1.png" width="400" height="400" alt="通道激活" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">通道4激活</div>
</center>


<p>这个通道似乎是对角边缘检测器。我们再看一下第7个通道</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将第7个通道可视化</span></span><br><span class="line">plt.matshow(first_layer_activation[<span class="number">0</span>, :, :, <span class="number">7</span>], cmap=<span class="string">'viridis'</span>)</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_88_1.png" width="400" height="400" alt="通道激活" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">通道7激活</div>
</center>



<p>下面我们来绘制网络中所有激活的完整可视化。我们需要在8个特征图中的每一个中提取并绘制每一个通道，然后将结果叠加在一个大的图像张量中，按通道并排。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将每个中间激活的所有通道可视化</span></span><br><span class="line">layer_names = []</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> model.layers[:<span class="number">8</span>]:</span><br><span class="line">    layer_names.append(layer.name)</span><br><span class="line">images_per_row = <span class="number">16</span></span><br><span class="line"><span class="keyword">for</span> layer_name, layer_activation <span class="keyword">in</span> zip(layer_names, activations):</span><br><span class="line">    n_features = layer_activation.shape[<span class="number">-1</span>]</span><br><span class="line">    size = layer_activation.shape[<span class="number">1</span>]</span><br><span class="line">    n_cols = n_features // images_per_row</span><br><span class="line">    display_grid = np.zeros((size * n_cols, images_per_row * size))</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> range(n_cols):</span><br><span class="line">        <span class="keyword">for</span> row <span class="keyword">in</span> range(images_per_row):</span><br><span class="line">            channel_image = layer_activation[<span class="number">0</span>,:, :,col * images_per_row + row]</span><br><span class="line">            channel_image -= channel_image.mean()</span><br><span class="line">            channel_image /= channel_image.std()</span><br><span class="line">            channel_image *= <span class="number">64</span></span><br><span class="line">            channel_image += <span class="number">128</span></span><br><span class="line">            channel_image = np.clip(channel_image, <span class="number">0</span>, <span class="number">255</span>).astype(<span class="string">'uint8'</span>)</span><br><span class="line">            display_grid[col * size : (col + <span class="number">1</span>) * size,row * size : (row + <span class="number">1</span>) * size] = channel_image</span><br><span class="line">    scale = <span class="number">1.</span> / size</span><br><span class="line">    plt.figure(figsize=(scale * display_grid.shape[<span class="number">1</span>],</span><br><span class="line">    scale * display_grid.shape[<span class="number">0</span>]))</span><br><span class="line">    plt.title(layer_name)</span><br><span class="line">    plt.grid(<span class="literal">False</span>)</span><br><span class="line">    plt.imshow(display_grid, aspect=<span class="string">'auto'</span>, cmap=<span class="string">'viridis'</span>)</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_90_1.png" width="400" height="400" alt="通道激活" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>

<center>
    <img src="\Pic\DeepLearning_Pic\output_90_2.png" width="400" height="400" alt="通道激活" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<center>
    <img src="\Pic\DeepLearning_Pic\output_90_3.png" width="400" height="400" alt="通道激活" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<center>
    <img src="\Pic\DeepLearning_Pic\output_90_4.png" width="400" height="400" alt="通道激活" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<center>
    <img src="\Pic\DeepLearning_Pic\output_90_5.png" width="400" height="400" alt="通道激活" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>

<center>
    <img src="\Pic\DeepLearning_Pic\output_90_6.png" width="400" height="400" alt="通道激活" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>

<center>
    <img src="\Pic\DeepLearning_Pic\output_90_7.png" width="400" height="400" alt="通道激活" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>

<center>
    <img src="\Pic\DeepLearning_Pic\output_90_8.png" width="400" height="400" alt="通道激活" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>



<p>这里需要注意以下几点。</p>
<ul>
<li>第一层是各种边缘探测器的集合。在这一阶段，激活几乎保留了原始图像中的所有信息。</li>
<li>随着层数的加深，激活变得越来越抽象，并且越来越难以直观地理解。它们开始表示更高层次的概念，比如“猫耳朵”和“猫眼睛”。层数越深，其表示中关于图像视觉内容的信息就越少，而关于类别的信息就越多。</li>
<li>激活的稀疏度（sparsity）随着层数的加深而增大。在第一层里，所有过滤器都被输入图像激活，但在后面的层里，越来越多的过滤器是空白的。也就是说，输入图像中找不到这些过滤器所编码的模式。</li>
</ul>
<p>我们刚刚揭示了深度神经网络学到的表示的一个重要普遍特征：随着层数的加深，层所提取的特征变得越来越抽象。更高的层激活包含关于特定输入的信息越来越少，而关于目标的信息越来越多（本例中即图像的类别：猫或狗）。深度神经网络可以有效地作为信息蒸馏管道（information distillation pipeline），输入原始数据（本例中是RGB 图像），反复对其进行变换，将无关信息过滤掉（比如图像的具体外观），并放大和细化有用的信息（比如图像的类别）。</p>
<p>这与人类和动物感知世界的方式类似：人类观察一个场景几秒钟后，可以记住其中有哪些抽象物体（比如自行车、树），但记不住这些物体的具体外观。事实上，如果你试着凭记忆画一辆普通自行车，那么很可能完全画不出真实的样子，虽然你一生中见过上千辆自行车。你可以现在就试着画一下，这个说法绝对是真实的。你的大脑已经学会将视觉输入完全抽象化，即将其转换为更高层次的视觉概念，同时过滤掉不相关的视觉细节，这使得大脑很难记住周围事物的外观。</p>
<center>
    <img src="\Pic\DeepLearning_Pic\bike.png" width="200" height="200" alt="（左图）试着凭记忆画一辆自行车；（右图）自行车示意图" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">（左图）试着凭记忆画一辆自行车；（右图）自行车示意图</div>
</center>

<h2 id="2-可视化卷积神经网络的过滤器"><a href="#2-可视化卷积神经网络的过滤器" class="headerlink" title="2. 可视化卷积神经网络的过滤器"></a>2. 可视化卷积神经网络的过滤器</h2><p>想要观察卷积神经网络学到的过滤器，另一种简单的方法是显示每个过滤器所响应的视觉模式。这可以通过在输入空间中进行梯度上升来实现：从空白输入图像开始，将梯度下降应用于卷积神经网络输入图像的值，其目的是让某个过滤器的响应最大化。得到的输入图像是选定过滤器具有最大响应的图像。</p>
<p>这个过程很简单：我们需要构建一个损失函数，其目的是让某个卷积层的某个过滤器的值最大化；然后，我们要使用随机梯度下降来调节输入图像的值，以便让这个激活值最大化。例如，对于在<code>ImageNet</code>上预训练的<code>VGG16</code>网络，其<code>block3_conv1</code>层第0 个过滤器激活的损失如下所示。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 为过滤器的可视化定义损失张量</span></span><br><span class="line"><span class="keyword">from</span> keras.applications <span class="keyword">import</span> VGG16</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line">model = VGG16(weights=<span class="string">'imagenet'</span>,include_top=<span class="literal">False</span>)</span><br><span class="line">layer_name = <span class="string">'block3_conv1'</span></span><br><span class="line">filter_index = <span class="number">0</span></span><br><span class="line">layer_output = model.get_layer(layer_name).output</span><br><span class="line">loss = K.mean(layer_output[:, :, :, filter_index])</span><br></pre></td></tr></table></figure>
<p>为了实现梯度下降，我们需要得到损失相对于模型输入的梯度。为此，我们需要使用<code>Keras</code>的<code>backend</code>模块内置的<code>gradients</code>函数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 获取损失相对于输入的梯度</span></span><br><span class="line">grads = K.gradients(loss, model.input)[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p>为了让梯度下降过程顺利进行，一个非显而易见的技巧是将梯度张量除以其L2范数（张量中所有值的平方的平均值的平方根）来标准化。这就确保了输入图像的更新大小始终位于相同的范围。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 梯度标准化技巧</span></span><br><span class="line">grads /= (K.sqrt(K.mean(K.square(grads))) + <span class="number">1e-5</span>)</span><br></pre></td></tr></table></figure>
<p>现在你需要一种方法：给定输入图像，它能够计算损失张量和梯度张量的值。你可以定义一个Keras后端函数来实现此方法：<code>iterate</code>是一个函数，它将一个Numpy张量（表示为长度为1的张量列表）转换为两个Numpy张量组成的列表，这两个张量分别是损失值和梯度值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 给定Numpy输入值，得到Numpy输出值</span></span><br><span class="line">iterate = K.function([model.input], [loss, grads])</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">loss_value, grads_value = iterate([np.zeros((<span class="number">1</span>, <span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>))])</span><br></pre></td></tr></table></figure>
<p>现在你可以定义一个Python 循环来进行随机梯度下降。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 通过随机梯度下降让损失最大化</span></span><br><span class="line">input_img_data = np.random.random((<span class="number">1</span>, <span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>)) * <span class="number">20</span> + <span class="number">128.</span></span><br><span class="line">step = <span class="number">1.</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">40</span>):</span><br><span class="line">    loss_value, grads_value = iterate([input_img_data])</span><br><span class="line">    input_img_data += grads_value * step</span><br></pre></td></tr></table></figure>
<p>得到的图像张量是形状为<code>(1, 150, 150, 3)</code>的浮点数张量，其取值可能不是<code>[0, 255]</code>区间内的整数。因此，你需要对这个张量进行后处理，将其转换为可显示的图像。下面这个简单的实用函数可以做到这一点。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将张量转换为有效图像的实用函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">deprocess_image</span><span class="params">(x)</span>:</span></span><br><span class="line">    x -= x.mean()</span><br><span class="line">    x /= (x.std() + <span class="number">1e-5</span>)</span><br><span class="line">    x *= <span class="number">0.1</span></span><br><span class="line">    x += <span class="number">0.5</span></span><br><span class="line">    x = np.clip(x, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    x *= <span class="number">255</span></span><br><span class="line">    x = np.clip(x, <span class="number">0</span>, <span class="number">255</span>).astype(<span class="string">'uint8'</span>)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>接下来，我们将上述代码片段放到一个Python函数中，输入一个层的名称和一个过滤器索引，它将返回一个有效的图像张量，表示能够将特定过滤器的激活最大化的模式。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生成过滤器可视化的函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_pattern</span><span class="params">(layer_name, filter_index, size=<span class="number">150</span>)</span>:</span></span><br><span class="line">    layer_output = model.get_layer(layer_name).output</span><br><span class="line">    loss = K.mean(layer_output[:, :, :, filter_index])</span><br><span class="line">    grads = K.gradients(loss, model.input)[<span class="number">0</span>]</span><br><span class="line">    grads /= (K.sqrt(K.mean(K.square(grads))) + <span class="number">1e-5</span>)</span><br><span class="line">    iterate = K.function([model.input], [loss, grads])</span><br><span class="line">    input_img_data = np.random.random((<span class="number">1</span>, size, size, <span class="number">3</span>)) * <span class="number">20</span> + <span class="number">128.</span></span><br><span class="line">    step = <span class="number">1.</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">40</span>):</span><br><span class="line">        loss_value, grads_value = iterate([input_img_data])</span><br><span class="line">        input_img_data += grads_value * step</span><br><span class="line">    img = input_img_data[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> deprocess_image(img)</span><br></pre></td></tr></table></figure>
<p>我们来试用一下这个函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.imshow(generate_pattern(<span class="string">'block3_conv1'</span>, <span class="number">0</span>))</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_106_1.png" width="400" height="400" alt="通道激活" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>



<p>看起来，<code>block3_conv1</code>层第0个过滤器响应的是波尔卡点（polka-dot）图案。下面来看有趣的部分：我们可以将每一层的每个过滤器都可视化。为了简单起见，我们只查看每一层的前64 个过滤器，并只查看每个卷积块的第一层（即<code>block1_conv1</code>、<code>block2_conv1</code>、<code>block3_conv1</code>、<code>block4_ conv1</code>、<code>block5_conv1</code>）。我们将输出放在一个8×8的网格中，每个网格是一个64像素×64像素的过滤器模式，两个过滤器模式之间留有一些黑边</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生成某一层中所有过滤器响应模式组成的网格</span></span><br><span class="line">layer_name = <span class="string">'block1_conv1'</span></span><br><span class="line">size = <span class="number">64</span></span><br><span class="line">margin = <span class="number">5</span></span><br><span class="line">results = np.zeros((<span class="number">8</span> * size + <span class="number">7</span> * margin, <span class="number">8</span> * size + <span class="number">7</span> * margin, <span class="number">3</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">8</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">8</span>):</span><br><span class="line">        filter_img = generate_pattern(layer_name, i + (j * <span class="number">8</span>), size=size)</span><br><span class="line">        horizontal_start = i * size + i * margin</span><br><span class="line">        horizontal_end = horizontal_start + size</span><br><span class="line">        vertical_start = j * size + j * margin</span><br><span class="line">        vertical_end = vertical_start + size</span><br><span class="line">        results[horizontal_start: horizontal_end, vertical_start: vertical_end, :] = filter_img</span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">20</span>))</span><br><span class="line">plt.imshow(results)</span><br></pre></td></tr></table></figure>
<p>这些过滤器可视化包含卷积神经网络的层如何观察世界的很多信息：卷积神经网络中每一层都学习一组过滤器，以便将其输入表示为过滤器的组合。这类似于傅里叶变换将信号分解为一组余弦函数的过程。随着层数的加深，卷积神经网络中的过滤器变得越来越复杂，越来越精细。</p>
<ul>
<li>模型第一层（block1_conv1）的过滤器对应简单的方向边缘和颜色（还有一些是彩色边缘）。</li>
<li>block2_conv1层的过滤器对应边缘和颜色组合而成的简单纹理。</li>
<li>更高层的过滤器类似于自然图像中的纹理：羽毛、眼睛、树叶等。</li>
</ul>
<h2 id="3-可视化类激活的热力图"><a href="#3-可视化类激活的热力图" class="headerlink" title="3. 可视化类激活的热力图"></a>3. 可视化类激活的热力图</h2><p>我还要介绍另一种可视化方法，它有助于了解一张图像的哪一部分让卷积神经网络做出了最终的分类决策。这有助于对卷积神经网络的决策过程进行调试，特别是出现分类错误的情况下。这种方法还可以定位图像中的特定目标。</p>
<p>这种通用的技术叫作类激活图（CAM，class activation map）可视化，它是指对输入图像生成类激活的热力图。类激活热力图是与特定输出类别相关的二维分数网格，对任何输入图像的每个位置都要进行计算，它表示每个位置对该类别的重要程度。举例来说，对于输入到猫狗分类卷积神经网络的一张图像，CAM 可视化可以生成类别“猫”的热力图，表示图像的各个部分与“猫”的相似程度，CAM 可视化也会生成类别“狗”的热力图，表示图像的各个部分与“狗”的相似程度。</p>
<p>我们将使用的具体实现方式是“Grad-CAM: visual explanations from deep networks via gradientbasedlocalization”a 这篇论文中描述的方法。这种方法非常简单：给定一张输入图像，对于一个卷积层的输出特征图，用类别相对于通道的梯度对这个特征图中的每个通道进行加权。直观上来看，理解这个技巧的一种方法是，你是用“每个通道对类别的重要程度”对“输入图像对不同通道的激活强度”的空间图进行加权，从而得到了“输入图像对类别的激活强度”的空间图。</p>
<p>我们再次使用预训练的<code>VGG16</code>网络来演示此方法。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 加载带有预训练权重的VGG16网络</span></span><br><span class="line"><span class="keyword">from</span> keras.applications.vgg16 <span class="keyword">import</span> VGG16</span><br><span class="line">model = VGG16(weights=<span class="string">'imagenet'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5
553467904/553467096 [==============================] - 441s 1us/step
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 为VGG16模型预处理一张输入图像</span></span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"><span class="keyword">from</span> keras.applications.vgg16 <span class="keyword">import</span> preprocess_input, decode_predictions</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">img_path = <span class="string">'data/pic_input/elephant1.jpg'</span></span><br><span class="line">img = image.load_img(img_path, target_size=(<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">x = image.img_to_array(img)</span><br><span class="line">x = np.expand_dims(x, axis=<span class="number">0</span>)</span><br><span class="line">x = preprocess_input(x)</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\elephant1.jpg" width="200" height="200" alt="非洲象" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">非洲象</div>
</center>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">preds = model.predict(x)</span><br><span class="line">print(<span class="string">'Predicted:'</span>, decode_predictions(preds, top=<span class="number">3</span>)[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<pre><code>Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json
40960/35363 [==================================] - 0s 3us/step
Predicted: [(&#39;n02504458&#39;, &#39;African_elephant&#39;, 0.87728226), (&#39;n01871265&#39;, &#39;tusker&#39;, 0.11725453), (&#39;n02504013&#39;, &#39;Indian_elephant&#39;, 0.0054599163)]
</code></pre><p>对这张图像预测的前三个类别分别为：</p>
<ul>
<li>非洲象（African elephant，87.728226% 的概率）</li>
<li>长牙动物（tusker，11.725453% 的概率）</li>
<li>印度象（Indian elephant，0.54599163%的概率）</li>
</ul>
<p>网络识别出图像中包含数量不确定的非洲象。预测向量中被最大激活的元素是对应“非洲象”类别的元素，索引编号为386。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.argmax(preds[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<pre><code>386
</code></pre><p>为了展示图像中哪些部分最像非洲象，我们来使用<code>Grad-CAM</code>算法。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">african_elephant_output = model.output[:, <span class="number">386</span>]</span><br><span class="line">last_conv_layer = model.get_layer(<span class="string">'block5_conv3'</span>)</span><br><span class="line">grads = K.gradients(african_elephant_output, last_conv_layer.output)[<span class="number">0</span>]</span><br><span class="line">pooled_grads = K.mean(grads, axis=(<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">iterate = K.function([model.input],[pooled_grads, last_conv_layer.output[<span class="number">0</span>]])</span><br><span class="line">pooled_grads_value, conv_layer_output_value = iterate([x])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">512</span>):</span><br><span class="line">    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]</span><br><span class="line">heatmap = np.mean(conv_layer_output_value, axis=<span class="number">-1</span>)</span><br></pre></td></tr></table></figure>
<p>为了便于可视化，我们还需要将热力图标准化到<code>0~1</code>范围内。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">heatmap = np.maximum(heatmap, <span class="number">0</span>)</span><br><span class="line">heatmap /= np.max(heatmap)</span><br><span class="line">plt.matshow(heatmap)</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_120_1.png" width="400" height="400" alt="b" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>



<p>最后，我们可以用OpenCV 来生成一张图像，将原始图像叠加在刚刚得到的热力图上</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">img = cv2.imread(img_path)</span><br><span class="line">heatmap = cv2.resize(heatmap, (img.shape[<span class="number">1</span>], img.shape[<span class="number">0</span>]))</span><br><span class="line">heatmap = np.uint8(<span class="number">255</span> * heatmap)</span><br><span class="line">heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)</span><br><span class="line">superimposed_img = heatmap * <span class="number">0.4</span> + img</span><br><span class="line">cv2.imwrite(<span class="string">'data/pic_output/elephant_cam.jpg'</span>, superimposed_img)</span><br></pre></td></tr></table></figure>
<pre><code>True
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cv2.imshow(<span class="string">'合并后的图像'</span>, superimposed_img)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<pre><code>-1
</code></pre><h1 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h1><ul>
<li>卷积神经网络是解决视觉分类问题的最佳工具。</li>
<li>卷积神经网络通过学习模块化模式和概念的层次结构来表示视觉世界。</li>
<li>卷积神经网络学到的表示很容易可视化，卷积神经网络不是黑盒。</li>
<li>现在你能够从头开始训练自己的卷积神经网络来解决图像分类问题。</li>
<li>你知道了如何使用视觉数据增强来防止过拟合。</li>
<li>你知道了如何使用预训练的卷积神经网络进行特征提取与模型微调。</li>
<li>你可以将卷积神经网络学到的过滤器可视化，也可以将类激活热力图可视化。</li>
</ul>
]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
  </entry>
  <entry>
    <title>Python深度学习（一）神经网络入门</title>
    <url>/posts/d8ee3b71.html</url>
    <content><![CDATA[<h1 id="一、电影评论分类：二分类问题"><a href="#一、电影评论分类：二分类问题" class="headerlink" title="一、电影评论分类：二分类问题"></a>一、电影评论分类：二分类问题</h1><p>二分类问题可能是应用最广泛的机器学习问题。在这个例子中，你将学习根据电影评论的文字内容将其划分为正面或负面。</p>
<h2 id="1-IMDB-数据集"><a href="#1-IMDB-数据集" class="headerlink" title="1. IMDB 数据集"></a>1. IMDB 数据集</h2><p>本节使用IMDB 数据集，它包含来自互联网电影数据库（IMDB）的50 000条严重两极分化的评论。数据集被分为用于训练的25 000 条评论与用于测试的25 000 条评论，训练集和测试集都包含50% 的正面评论和50% 的负面评论。</p>
<p>为什么要将训练集和测试集分开？因为你不应该将训练机器学习模型的同一批数据再用于测试模型！模型在训练数据上的表现很好，并不意味着它在前所未见的数据上也会表现得很好，而且你真正关心的是模型在新数据上的性能（因为你已经知道了训练数据对应的标签，显然不再需要模型来进行预测）。例如，你的模型最终可能只是记住了训练样本和目标值之间的映射关系，但这对在前所未见的数据上进行预测毫无用处。后面将会更详细地讨论这一点。</p>
<p>与MNIST 数据集一样，IMDB 数据集也内置于Keras 库。它已经过预处理：评论（单词序列）已经被转换为整数序列，其中每个整数代表字典中的某个单词。</p>
<p>下列代码将会加载IMDB 数据集（第一次运行时会下载大约80MB 的数据）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> imdb</span><br><span class="line">(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=<span class="number">10000</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Using TensorFlow backend.
</code></pre><p>参数 <code>num_words=10000</code> 的意思是仅保留训练数据中前10 000个最常出现的单词。低频单词将被舍弃。这样得到的向量数据不会太大，便于处理。</p>
<p><code>train_data</code> 和 <code>test_data</code> 这两个变量都是评论组成的列表，每条评论又是单词索引组成的列表（表示一系列单词）。<code>train_labels</code> 和 <code>test_labels</code> 都是0 和1 组成的列表，其中0代表负面（negative），1 代表正面（positive）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(<span class="string">'train data'</span>, train_data[<span class="number">0</span>], <span class="string">'\ntrain label'</span>, train_labels[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<pre><code>train data [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32] 
train label 1
</code></pre><p>由于限定为前10 000 个最常见的单词，单词索引都不会超过10 000。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">max([max(sequence) <span class="keyword">for</span> sequence <span class="keyword">in</span> train_data])</span><br></pre></td></tr></table></figure>
<pre><code>9999
</code></pre><p>下面这段代码很有意思，你可以将某条评论迅速解码为英文单词。<br>注：</p>
<ol>
<li>索引减去了3，因为0、1、2是为“padding”（填充）、“start of sequence”（序列开始）、“unknown”（未知词）分别保留的索引</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">word_index = imdb.get_word_index()</span><br><span class="line">print(<span class="string">'word index of fawn: '</span>, word_index[<span class="string">'fawn'</span>])</span><br><span class="line">reverse_word_index = dict([(value, key) <span class="keyword">for</span> (key, value) <span class="keyword">in</span> word_index.items()])</span><br><span class="line">print(<span class="string">'the word with index 0, 1, 2 are: '</span>, reverse_word_index[<span class="number">1</span>], reverse_word_index[<span class="number">2</span>], reverse_word_index[<span class="number">3</span>])</span><br><span class="line">decoded_review = <span class="string">' '</span>.join(reverse_word_index.get(i<span class="number">-3</span>,<span class="string">'?'</span>) <span class="keyword">for</span> i <span class="keyword">in</span> train_data[<span class="number">0</span>])</span><br><span class="line">print(<span class="string">'decoded review of the first train data: '</span>, decoded_review)</span><br></pre></td></tr></table></figure>
<pre><code>word index of fawn:  34701
the word with index 0, 1, 2 are:  the and a
decoded review of the first train data:  ? this film was just brilliant casting location scenery story direction everyone&#39;s really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy&#39;s that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don&#39;t you think the whole story was so lovely because it was true and was someone&#39;s life after all that was shared with us all
</code></pre><h2 id="2-准备数据"><a href="#2-准备数据" class="headerlink" title="2. 准备数据"></a>2. 准备数据</h2><p>你不能将整数序列直接输入神经网络。你需要将列表转换为张量。转换方法有以下两种：</p>
<ul>
<li>填充列表，使其具有相同的长度，再将列表转换成形状为 (samples, word_indices)的整数张量，然后网络第一层使用能处理这种整数张量的层（即Embedding层）。</li>
<li>对列表进行 one-hot 编码，将其转换为 0 和 1 组成的向量。举个例子，序列[3, 5]将会被转换为10 000 维向量，只有索引为3 和5 的元素是1，其余元素都是0。然后网络第一层可以用Dense 层，它能够处理浮点数向量数据。</li>
</ul>
<p>下面我们采用后一种方法将数据向量化。为了加深理解，我们可以手动实现这一方法，如下所示。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将整数序列编码为二进制矩阵</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vectorize_sequences</span><span class="params">(sequences, dimension=<span class="number">10000</span>)</span>:</span></span><br><span class="line">    results = np.zeros((len(sequences), dimension))</span><br><span class="line">    <span class="keyword">for</span> i, sequence <span class="keyword">in</span> enumerate(sequences):</span><br><span class="line">        results[i, sequence] = <span class="number">1.</span></span><br><span class="line">    <span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line">x_train = vectorize_sequences(train_data)</span><br><span class="line">x_test = vectorize_sequences(test_data)</span><br></pre></td></tr></table></figure>
<p>样本现在变成了这样：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(x_train[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<pre><code>[0. 1. 1. ... 0. 0. 0.]
</code></pre><p>你还应该将标签向量化，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y_train = np.asarray(train_labels).astype(<span class="string">'float32'</span>)</span><br><span class="line">y_test = np.asarray(test_labels).astype(<span class="string">'float32'</span>)</span><br></pre></td></tr></table></figure>
<p>现在可以将数据输入到神经网络中。</p>
<h2 id="3-构建网络"><a href="#3-构建网络" class="headerlink" title="3. 构建网络"></a>3. 构建网络</h2><p>输入数据是向量，而标签是标量（1 和0），这是你会遇到的最简单的情况。有一类网络在这种问题上表现很好，就是带有<code>relu</code>激活的全连接层（Dense）的简单堆叠，比如<code>Dense(16, activation=&#39;relu&#39;)</code>。</p>
<p>传入<code>Dense</code>层的参数（16）是该层隐藏单元的个数。一个隐藏单元（hidden unit）是该层表示空间的一个维度。每个带有<code>relu</code>激活的<code>Dense</code>层都实现了下列张量运算：<code>output = relu(dot(W, input) + b)</code></p>
<p>16 个隐藏单元对应的权重矩阵<code>W</code>的形状为(input_dimension, 16)，与<code>W</code>做点积相当于将输入数据投影到16 维表示空间中（然后再加上偏置向量<code>b</code>并应用relu 运算）。你可以将表示空间的维度直观地理解为“网络学习内部表示时所拥有的自由度”。隐藏单元越多（即更高维的表示空间），网络越能够学到更加复杂的表示，但网络的计算代价也变得更大，而且可能会导致学到不好的模式（这种模式会提高训练数据上的性能，但不会提高测试数据上的性能）。</p>
<p>对于这种Dense 层的堆叠，你需要确定以下两个关键架构：</p>
<ul>
<li>网络有多少层；</li>
<li>每层有多少个隐藏单元。</li>
</ul>
<p>现在只需要选择下列架构：</p>
<ul>
<li>两个中间层，每层都有 16 个隐藏单元；</li>
<li>第三层输出一个标量，预测当前评论的情感。<br>中间层使用 relu 作为激活函数，最后一层使用 sigmoid 激活以输出一个0~1 范围内的概率值（表示样本的目标值等于1的可能性，即评论为正面的可能性）。 relu（rectified linear unit，整流线性单元）函数将所有负值归零，而sigmoid函数则将任意值“压缩”到<code>[0,1]</code>区间内，其输出值可以看作概率值。</li>
</ul>
<center>
    <img src="\Pic\DeepLearning_Pic\relu1.png" width="400" height="400" alt="整体线性流函数" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">整体线性流函数</div>
</center>

<center>
    <img src="\Pic\DeepLearning_Pic\sigmoid1.png" width="400" height="400" alt="sigmoid函数" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">sigmoid函数</div>
</center>

<p>下图显示了网络的结构：</p>
<center>
    <img src="\Pic\DeepLearning_Pic\structure_imdb_1.png" width="200" height="200" alt="structure_imdb_1" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">三层网络结构</div>
</center>

<h2 id="4-模型定义"><a href="#4-模型定义" class="headerlink" title="4. 模型定义"></a>4. 模型定义</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">"relu"</span>, input_shape=(<span class="number">10000</span>, )))</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">"relu"</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">"sigmoid"</span>))</span><br></pre></td></tr></table></figure>
<p>最后，你需要选择损失函数和优化器。由于你面对的是一个二分类问题，网络输出是一个概率值（网络最后一层使用<code>sigmoid</code>激活函数，仅包含一个单元），那么最好使用<code>binary_crossentropy</code>（二元交叉熵）损失。这并不是唯一可行的选择，比如你还可以使用<code>mean_squared_error</code>（均方误差）。但对于输出概率值的模型，交叉熵（crossentropy）往往是最好的选择。交叉熵是来自于信息论领域的概念，用于衡量概率分布之间的距离，在这个例子中就<br>是真实分布与预测值之间的距离。</p>
<p>下面的步骤是用<code>rmsprop</code>优化器和<code>binary_crossentropy</code>损失函数来配置模型。注意，我们还在训练过程中监控精度。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.compile(optimizer=<span class="string">"rmsprop"</span>, loss=<span class="string">"binary_crossentropy"</span>, metrics=[<span class="string">"accuracy"</span>])</span><br></pre></td></tr></table></figure>
<p>上述代码将优化器、损失函数和指标作为字符串传入，这是因为<code>rmsprop</code>、<code>binary_crossentropy</code>和<code>accuracy</code>都是Keras 内置的一部分。有时你可能希望配置自定义优化器的参数，或者传入自定义的损失函数或指标函数，前者可通过向<code>optimizer</code>参数传入一个优化器类实例来实现</p>
<h2 id="5-划分数据并训练模型"><a href="#5-划分数据并训练模型" class="headerlink" title="5. 划分数据并训练模型"></a>5. 划分数据并训练模型</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x_val = x_train[:<span class="number">10000</span>]</span><br><span class="line">partial_x_train = x_train[<span class="number">10000</span>:]</span><br><span class="line">y_val = y_train[:<span class="number">10000</span>]</span><br><span class="line">partial_y_train = y_train[<span class="number">10000</span>:]</span><br></pre></td></tr></table></figure>
<p>现在使用512 个样本组成的小批量，将模型训练20 个轮次（即对<code>x_train</code>和<code>y_train</code>两个张量中的所有样本进行20 次迭代）。与此同时，你还要监控在留出的10 000 个样本上的损失和精度。你可以通过将验证数据传入<code>validation_data</code>参数来完成。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">history = model.fit(partial_x_train,</span><br><span class="line">                    partial_y_train,</span><br><span class="line">                    epochs=<span class="number">20</span>,</span><br><span class="line">                    batch_size=<span class="number">512</span>,</span><br><span class="line">                    validation_data=(x_val, y_val))</span><br></pre></td></tr></table></figure>
<pre><code>Train on 15000 samples, validate on 10000 samples
Epoch 1/20
15000/15000 [==============================] - 10s 637us/step - loss: 0.5054 - accuracy: 0.7994 - val_loss: 0.3811 - val_accuracy: 0.8697
Epoch 2/20
15000/15000 [==============================] - 6s 402us/step - loss: 0.3009 - accuracy: 0.9039 - val_loss: 0.3074 - val_accuracy: 0.8841
Epoch 3/20
15000/15000 [==============================] - 2s 151us/step - loss: 0.2207 - accuracy: 0.9309 - val_loss: 0.2773 - val_accuracy: 0.8910
Epoch 4/20
15000/15000 [==============================] - 2s 137us/step - loss: 0.1777 - accuracy: 0.9433 - val_loss: 0.2731 - val_accuracy: 0.8912
Epoch 5/20
15000/15000 [==============================] - 2s 129us/step - loss: 0.1428 - accuracy: 0.9555 - val_loss: 0.2797 - val_accuracy: 0.8888
Epoch 6/20
15000/15000 [==============================] - 2s 137us/step - loss: 0.1201 - accuracy: 0.9629 - val_loss: 0.3101 - val_accuracy: 0.8818
Epoch 7/20
15000/15000 [==============================] - 2s 134us/step - loss: 0.1007 - accuracy: 0.9705 - val_loss: 0.3096 - val_accuracy: 0.8817
Epoch 8/20
15000/15000 [==============================] - 2s 129us/step - loss: 0.0845 - accuracy: 0.9768 - val_loss: 0.3309 - val_accuracy: 0.8826
Epoch 9/20
15000/15000 [==============================] - 2s 126us/step - loss: 0.0715 - accuracy: 0.9809 - val_loss: 0.3477 - val_accuracy: 0.8817
Epoch 10/20
15000/15000 [==============================] - 2s 127us/step - loss: 0.0604 - accuracy: 0.9848 - val_loss: 0.3675 - val_accuracy: 0.8788
Epoch 11/20
15000/15000 [==============================] - 2s 125us/step - loss: 0.0504 - accuracy: 0.9879 - val_loss: 0.4077 - val_accuracy: 0.8692
Epoch 12/20
15000/15000 [==============================] - 2s 125us/step - loss: 0.0410 - accuracy: 0.9908 - val_loss: 0.4214 - val_accuracy: 0.8725
Epoch 13/20
15000/15000 [==============================] - 2s 125us/step - loss: 0.0322 - accuracy: 0.9947 - val_loss: 0.4783 - val_accuracy: 0.8704
Epoch 14/20
15000/15000 [==============================] - 2s 125us/step - loss: 0.0291 - accuracy: 0.9939 - val_loss: 0.4782 - val_accuracy: 0.8741
Epoch 15/20
15000/15000 [==============================] - 2s 125us/step - loss: 0.0222 - accuracy: 0.9962 - val_loss: 0.5157 - val_accuracy: 0.8679
Epoch 16/20
15000/15000 [==============================] - 2s 126us/step - loss: 0.0188 - accuracy: 0.9966 - val_loss: 0.5413 - val_accuracy: 0.8714
Epoch 17/20
15000/15000 [==============================] - 2s 125us/step - loss: 0.0120 - accuracy: 0.9990 - val_loss: 0.5762 - val_accuracy: 0.8659
Epoch 18/20
15000/15000 [==============================] - 2s 129us/step - loss: 0.0129 - accuracy: 0.9979 - val_loss: 0.6005 - val_accuracy: 0.8674
Epoch 19/20
15000/15000 [==============================] - 2s 125us/step - loss: 0.0085 - accuracy: 0.9993 - val_loss: 0.6336 - val_accuracy: 0.8689
Epoch 20/20
15000/15000 [==============================] - 2s 124us/step - loss: 0.0070 - accuracy: 0.9993 - val_loss: 0.6647 - val_accuracy: 0.8675
</code></pre><p>在CPU 上运行，每轮的时间不到2秒，训练过程将在20 秒内结束。每轮结束时会有短暂的停顿，因为模型要计算在验证集的10 000 个样本上的损失和精度。</p>
<p>注意，调用<code>model.fit()</code>返回了一个<code>history</code>对象。这个对象有一个成员<code>history</code>，它是一个字典，包含训练过程中的所有数据，我们来看一下。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">history_dict = history.history</span><br><span class="line">history_dict.keys()</span><br></pre></td></tr></table></figure>
<pre><code>dict_keys([&#39;val_loss&#39;, &#39;val_accuracy&#39;, &#39;loss&#39;, &#39;accuracy&#39;])
</code></pre><h2 id="6-绘制训练损失和验证损失"><a href="#6-绘制训练损失和验证损失" class="headerlink" title="6. 绘制训练损失和验证损失"></a>6. 绘制训练损失和验证损失</h2><p>字典中包含4 个条目，对应训练过程和验证过程中监控的指标。我们将使用Matplotlib 在同一张图上绘制训练损失和验证损失，以及训练精度和验证精度。请注意，由于网络的随机初始化不同，你得到的结果可能会略有不同。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">history_dict = history.history</span><br><span class="line">loss_values = history_dict[<span class="string">'loss'</span>]</span><br><span class="line">val_loss_values = history_dict[<span class="string">'val_loss'</span>]</span><br><span class="line">epochs = range(<span class="number">1</span>, len(loss_values)+<span class="number">1</span>)</span><br><span class="line">plt.plot(epochs, loss_values, <span class="string">'bo'</span>, label=<span class="string">'Training loss'</span>)</span><br><span class="line">plt.plot(epochs, val_loss_values, <span class="string">'b'</span>, label=<span class="string">'Validation loss'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation loss'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Epochs'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_26_0.png" width="400" height="400" alt="训练损失和验证损失" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">训练损失和验证损失</div>
</center>


<h2 id="7-绘制训练精度和验证精度"><a href="#7-绘制训练精度和验证精度" class="headerlink" title="7. 绘制训练精度和验证精度"></a>7. 绘制训练精度和验证精度</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.clf()</span><br><span class="line">acc = history_dict[<span class="string">'accuracy'</span>]</span><br><span class="line">val_acc = history_dict[<span class="string">'val_accuracy'</span>]</span><br><span class="line">plt.plot(epochs, acc, <span class="string">'bo'</span>, label=<span class="string">'Training accuracy'</span>)</span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">'b'</span>, label=<span class="string">'Validation accuracy'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation accuracy'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Epochs'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Accuracy'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_28_0.png" width="400" height="400" alt="训练精度和验证精度" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">训练精度和验证精度</div>
</center>


<p>如你所见，训练损失每轮都在降低，训练精度每轮都在提升。这就是梯度下降优化的预期结果——你想要最小化的量随着每次迭代越来越小。但验证损失和验证精度并非如此：它们似乎在第四轮达到最佳值。这就是我们之前警告过的一种情况：模型在训练数据上的表现越来越好，但在前所未见的数据上不一定表现得越来越好。准确地说，你看到的是过拟合（overfit）：在第二轮之后，你对训练数据过度优化，最终学到的表示仅针对于训练数据，无法泛化到训练集之外的数据。</p>
<p>在这种情况下，为了防止过拟合，你可以在3 轮之后停止训练。通常来说，你可以使用许多方法来降低过拟合，我们将在后面详细介绍。</p>
<p>我们从头开始训练一个新的网络，训练4 轮，然后在测试数据上评估模型。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">'relu'</span>, input_shape=(<span class="number">10000</span>,)))</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>, loss=<span class="string">'binary_crossentropy'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">model.fit(x_train, y_train, epochs=<span class="number">4</span>, batch_size=<span class="number">512</span>)</span><br><span class="line">results = model.evaluate(x_test, y_test)</span><br><span class="line">print(results)</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1/4
25000/25000 [==============================] - 3s 100us/step - loss: 0.4556 - accuracy: 0.8245
Epoch 2/4
25000/25000 [==============================] - 2s 78us/step - loss: 0.2628 - accuracy: 0.9074
Epoch 3/4
25000/25000 [==============================] - 2s 81us/step - loss: 0.2002 - accuracy: 0.9290
Epoch 4/4
25000/25000 [==============================] - 2s 88us/step - loss: 0.1687 - accuracy: 0.9394
25000/25000 [==============================] - 7s 270us/step
[0.30153122137069704, 0.880840003490448]
</code></pre><p>这种相当简单的方法得到了88% 的精度。利用最先进的方法，你应该能够得到接近95% 的精度。</p>
<h2 id="8-使用训练好的网络在新数据上生成预测结果"><a href="#8-使用训练好的网络在新数据上生成预测结果" class="headerlink" title="8. 使用训练好的网络在新数据上生成预测结果"></a>8. 使用训练好的网络在新数据上生成预测结果</h2><p>训练好网络之后，你希望将其用于实践。你可以用<code>predict</code>方法来得到评论为正面的可能性大小。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.predict(x_test)</span><br></pre></td></tr></table></figure>
<pre><code>array([[0.17173755],
       [0.99980915],
       [0.77910084],
       ...,
       [0.08216667],
       [0.04566944],
       [0.51742095]], dtype=float32)
</code></pre><h1 id="二、新闻分类：多分类问题"><a href="#二、新闻分类：多分类问题" class="headerlink" title="二、新闻分类：多分类问题"></a>二、新闻分类：多分类问题</h1><p>下面你会构建一个网络，将路透社新闻划分为46 个互斥的主题。因为有多个类别，所以这是多分类（multiclass classification）问题的一个例子。因为每个数据点只能划分到一个类别，所以更具体地说，这是单标签、多分类（single-label, multiclass classification）问题的一个例子。如果每个数据点可以划分到多个类别（主题），那它就是一个多标签、多分类（multilabel,multiclass classification）问题。</p>
<h2 id="1-路透社数据集"><a href="#1-路透社数据集" class="headerlink" title="1. 路透社数据集"></a>1. 路透社数据集</h2><p>本节使用路透社数据集，它包含许多短新闻及其对应的主题，由路透社在1986 年发布。它是一个简单的、广泛使用的文本分类数据集。它包括46 个不同的主题：某些主题的样本更多，但训练集中每个主题都有至少10 个样本。与IMDB 和MNIST 类似，路透社数据集也内置为Keras 的一部分。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> reuters</span><br><span class="line">(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=<span class="number">10000</span>)</span><br><span class="line">print(<span class="string">'the length of train data: '</span>, len(train_data), <span class="string">'\nthe length of test data: '</span>, len(test_data))</span><br><span class="line">print(<span class="string">'train data 10: '</span>, train_data[<span class="number">10</span>], <span class="string">'\ntrain label 10: '</span>, train_labels[<span class="number">10</span>])</span><br></pre></td></tr></table></figure>
<pre><code>the length of train data:  8982 
the length of test data:  2246
train data 10:  [1, 245, 273, 207, 156, 53, 74, 160, 26, 14, 46, 296, 26, 39, 74, 2979, 3554, 14, 46, 4689, 4329, 86, 61, 3499, 4795, 14, 61, 451, 4329, 17, 12] 
train label 10:  3
</code></pre><p>如果好奇的话，你可以用下列代码将索引解码为单词。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">word_index = reuters.get_word_index()</span><br><span class="line">reverse_word_index = dict([(value, key) <span class="keyword">for</span> (key, value) <span class="keyword">in</span> word_index.items()])</span><br><span class="line">decoded_newswire = <span class="string">' '</span>.join([reverse_word_index.get(i - <span class="number">3</span>, <span class="string">'?'</span>) <span class="keyword">for</span> i <span class="keyword">in</span> train_data[<span class="number">0</span>]])</span><br><span class="line">print(decoded_newswire)</span><br></pre></td></tr></table></figure>
<pre><code>? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3
</code></pre><h2 id="2-准备数据-1"><a href="#2-准备数据-1" class="headerlink" title="2. 准备数据"></a>2. 准备数据</h2><p>你可以使用与上一个例子相同的代码将数据向量化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vectorize_sequences</span><span class="params">(sequences, dimension=<span class="number">10000</span>)</span>:</span></span><br><span class="line">    results = np.zeros((len(sequences), dimension))</span><br><span class="line">    <span class="keyword">for</span> i, sequence <span class="keyword">in</span> enumerate(sequences):</span><br><span class="line">        results[i, sequence] = <span class="number">1.</span></span><br><span class="line">    <span class="keyword">return</span> results</span><br><span class="line">x_train = vectorize_sequences(train_data)</span><br><span class="line">x_test = vectorize_sequences(test_data)</span><br></pre></td></tr></table></figure>
<p>将标签向量化有两种方法：你可以将标签列表转换为整数张量，或者使用one-hot 编码。</p>
<p>one-hot 编码是分类数据广泛使用的一种格式，也叫分类编码（categorical encoding）,在这个例子中，标签的one-hot 编码就是将每个标签表示为全零向量，只有标签索引对应的元素为1。其代码实现如下。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">to_one_hot</span><span class="params">(labels, dimension=<span class="number">46</span>)</span>:</span></span><br><span class="line">    results = np.zeros((len(labels), dimension))</span><br><span class="line">    <span class="keyword">for</span> i, label <span class="keyword">in</span> enumerate(labels):</span><br><span class="line">        results[i, label] = <span class="number">1.</span></span><br><span class="line">    <span class="keyword">return</span> results</span><br><span class="line">one_hot_train_labels = to_one_hot(train_labels)</span><br><span class="line">one_hot_test_labels = to_one_hot(test_labels)</span><br></pre></td></tr></table></figure>
<p>注意，Keras 内置方法可以实现这个操作：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.utils.np_utils <span class="keyword">import</span> to_categorical</span><br><span class="line">one_hot_train_labels = to_categorical(train_labels)</span><br><span class="line">one_hot_test_labels = to_categorical(test_labels)</span><br></pre></td></tr></table></figure>
<h2 id="3-构建网络-1"><a href="#3-构建网络-1" class="headerlink" title="3. 构建网络"></a>3. 构建网络</h2><p>这个主题分类问题与前面的电影评论分类问题类似，两个例子都是试图对简短的文本片段进行分类。但这个问题有一个新的约束条件：输出类别的数量从2 个变为46 个。输出空间的维度要大得多。</p>
<p>对于前面用过的Dense 层的堆叠，每层只能访问上一层输出的信息。如果某一层丢失了与分类问题相关的一些信息，那么这些信息无法被后面的层找回，也就是说，每一层都可能成为信息瓶颈。上一个例子使用了16 维的中间层，但对这个例子来说16 维空间可能太小了，无法学会区分46 个不同的类别。这种维度较小的层可能成为信息瓶颈，永久地丢失相关信息。</p>
<p>出于这个原因，下面将使用维度更大的层，包含64 个单元。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>, input_shape=(<span class="number">10000</span>,)))</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">46</span>, activation=<span class="string">'softmax'</span>))</span><br></pre></td></tr></table></figure>
<p>关于这个架构还应该注意另外两点：</p>
<ul>
<li>网络的最后一层是大小为 46 的 <code>Dense</code> 层。这意味着，对于每个输入样本，网络都会输出一个46 维向量。这个向量的每个元素（即每个维度）代表不同的输出类别。</li>
<li>最后一层使用了 <code>softmax</code> 激活。你在 MNIST 例子中见过这种用法。网络将输出在 46个不同输出类别上的概率分布——对于每一个输入样本，网络都会输出一个46 维向量，其中<code>output[i]</code>是样本属于第<code>i</code>个类别的概率。46 个概率的总和为1。</li>
</ul>
<p>对于这个例子，最好的损失函数是<code>categorical_crossentropy</code>（分类交叉熵）。它用于衡量两个概率分布之间的距离，这里两个概率分布分别是网络输出的概率分布和标签的真实分布。通过将这两个分布的距离最小化，训练网络可使输出结果尽可能接近真实标签。</p>
<h2 id="4-编译模型"><a href="#4-编译模型" class="headerlink" title="4. 编译模型"></a>4. 编译模型</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>,</span><br><span class="line">            loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">            metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure>
<h2 id="5-验证你的方法"><a href="#5-验证你的方法" class="headerlink" title="5. 验证你的方法"></a>5. 验证你的方法</h2><p>我们在训练数据中留出1000 个样本作为验证集。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x_val = x_train[:<span class="number">1000</span>]</span><br><span class="line">partial_x_train = x_train[<span class="number">1000</span>:]</span><br><span class="line">y_val = one_hot_train_labels[:<span class="number">1000</span>]</span><br><span class="line">partial_y_train = one_hot_train_labels[<span class="number">1000</span>:]</span><br></pre></td></tr></table></figure>
<p>现在开始训练网络，共20 个轮次。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">history = model.fit(partial_x_train,</span><br><span class="line">                    partial_y_train,</span><br><span class="line">                    epochs=<span class="number">20</span>,</span><br><span class="line">                    batch_size=<span class="number">512</span>,</span><br><span class="line">                    validation_data=(x_val, y_val))</span><br></pre></td></tr></table></figure>
<pre><code>Train on 7982 samples, validate on 1000 samples
Epoch 1/20
7982/7982 [==============================] - 2s 197us/step - loss: 2.7220 - accuracy: 0.5438 - val_loss: 1.7716 - val_accuracy: 0.6510
Epoch 2/20
7982/7982 [==============================] - 1s 90us/step - loss: 1.4464 - accuracy: 0.7068 - val_loss: 1.3297 - val_accuracy: 0.7160
Epoch 3/20
7982/7982 [==============================] - 1s 90us/step - loss: 1.0637 - accuracy: 0.7737 - val_loss: 1.1569 - val_accuracy: 0.7520
Epoch 4/20
7982/7982 [==============================] - 1s 92us/step - loss: 0.8311 - accuracy: 0.8247 - val_loss: 1.0649 - val_accuracy: 0.7690
Epoch 5/20
7982/7982 [==============================] - 1s 90us/step - loss: 0.6618 - accuracy: 0.8629 - val_loss: 0.9799 - val_accuracy: 0.7900
Epoch 6/20
7982/7982 [==============================] - 1s 90us/step - loss: 0.5263 - accuracy: 0.8905 - val_loss: 0.9437 - val_accuracy: 0.7910
Epoch 7/20
7982/7982 [==============================] - 1s 91us/step - loss: 0.4242 - accuracy: 0.9118 - val_loss: 0.9042 - val_accuracy: 0.8170
Epoch 8/20
7982/7982 [==============================] - 1s 92us/step - loss: 0.3445 - accuracy: 0.9295 - val_loss: 0.8994 - val_accuracy: 0.8200
Epoch 9/20
7982/7982 [==============================] - 1s 90us/step - loss: 0.2905 - accuracy: 0.9365 - val_loss: 0.9082 - val_accuracy: 0.8180
Epoch 10/20
7982/7982 [==============================] - 1s 89us/step - loss: 0.2414 - accuracy: 0.9437 - val_loss: 0.9217 - val_accuracy: 0.8090
Epoch 11/20
7982/7982 [==============================] - 1s 91us/step - loss: 0.2108 - accuracy: 0.9474 - val_loss: 0.9495 - val_accuracy: 0.8210
Epoch 12/20
7982/7982 [==============================] - 1s 91us/step - loss: 0.1879 - accuracy: 0.9530 - val_loss: 0.9722 - val_accuracy: 0.7960
Epoch 13/20
7982/7982 [==============================] - 1s 89us/step - loss: 0.1656 - accuracy: 0.9526 - val_loss: 1.0056 - val_accuracy: 0.7950
Epoch 14/20
7982/7982 [==============================] - 1s 91us/step - loss: 0.1504 - accuracy: 0.9545 - val_loss: 0.9687 - val_accuracy: 0.8090
Epoch 15/20
7982/7982 [==============================] - 1s 88us/step - loss: 0.1433 - accuracy: 0.9563 - val_loss: 1.0085 - val_accuracy: 0.8090
Epoch 16/20
7982/7982 [==============================] - 1s 90us/step - loss: 0.1312 - accuracy: 0.9551 - val_loss: 1.0123 - val_accuracy: 0.8040
Epoch 17/20
7982/7982 [==============================] - 1s 93us/step - loss: 0.1249 - accuracy: 0.9577 - val_loss: 1.0555 - val_accuracy: 0.8010
Epoch 18/20
7982/7982 [==============================] - 1s 90us/step - loss: 0.1226 - accuracy: 0.9554 - val_loss: 1.0423 - val_accuracy: 0.8000
Epoch 19/20
7982/7982 [==============================] - 1s 91us/step - loss: 0.1163 - accuracy: 0.9572 - val_loss: 1.0554 - val_accuracy: 0.8000
Epoch 20/20
7982/7982 [==============================] - 1s 113us/step - loss: 0.1086 - accuracy: 0.9588 - val_loss: 1.1368 - val_accuracy: 0.7790
</code></pre><h2 id="6-绘制图像"><a href="#6-绘制图像" class="headerlink" title="6. 绘制图像"></a>6. 绘制图像</h2><p>最后，我们来绘制损失曲线和精度曲线</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">loss = history.history[<span class="string">'loss'</span>]</span><br><span class="line">val_loss = history.history[<span class="string">'val_loss'</span>]</span><br><span class="line">epochs = range(<span class="number">1</span>, len(loss) + <span class="number">1</span>)</span><br><span class="line">plt.plot(epochs, loss, <span class="string">'bo'</span>, label=<span class="string">'Training loss'</span>)</span><br><span class="line">plt.plot(epochs, val_loss, <span class="string">'b'</span>, label=<span class="string">'Validation loss'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation loss'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Epochs'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_53_0.png" width="400" height="400" alt="训练损失和验证损失" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">训练损失和验证损失</div>
</center>



<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.clf()</span><br><span class="line">acc = history.history[<span class="string">'accuracy'</span>]</span><br><span class="line">val_acc = history.history[<span class="string">'val_accuracy'</span>]</span><br><span class="line">plt.plot(epochs, acc, <span class="string">'bo'</span>, label=<span class="string">'Training accuracy'</span>)</span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">'b'</span>, label=<span class="string">'Validation accuracy'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation accuracy'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Epochs'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Accuracy'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<center>
    <img src="\Pic\DeepLearning_Pic\output_54_0.png" width="400" height="400" alt="训练精度和验证精度" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">训练精度和验证精度</div>
</center>


<p>网络在训练9轮后开始过拟合。我们从头开始训练一个新网络，共9个轮次，然后在测试集上评估模型。</p>
<h2 id="7-从头开始重新训练一个模型"><a href="#7-从头开始重新训练一个模型" class="headerlink" title="7. 从头开始重新训练一个模型"></a>7. 从头开始重新训练一个模型</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>, input_shape=(<span class="number">10000</span>,)))</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">46</span>, activation=<span class="string">'softmax'</span>))</span><br><span class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>,</span><br><span class="line">            loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">            metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">model.fit(partial_x_train,</span><br><span class="line">        partial_y_train,</span><br><span class="line">        epochs=<span class="number">9</span>,</span><br><span class="line">        batch_size=<span class="number">512</span>,</span><br><span class="line">        validation_data=(x_val, y_val))</span><br><span class="line">results = model.evaluate(x_test, one_hot_test_labels)</span><br></pre></td></tr></table></figure>
<pre><code>Train on 7982 samples, validate on 1000 samples
Epoch 1/9
7982/7982 [==============================] - 1s 116us/step - loss: 2.7007 - accuracy: 0.5041 - val_loss: 1.7970 - val_accuracy: 0.6230
Epoch 2/9
7982/7982 [==============================] - 1s 103us/step - loss: 1.4223 - accuracy: 0.7050 - val_loss: 1.3018 - val_accuracy: 0.7210
Epoch 3/9
7982/7982 [==============================] - 1s 106us/step - loss: 1.0310 - accuracy: 0.7791 - val_loss: 1.1309 - val_accuracy: 0.7470
Epoch 4/9
7982/7982 [==============================] - 1s 106us/step - loss: 0.8089 - accuracy: 0.8242 - val_loss: 1.0300 - val_accuracy: 0.7800
Epoch 5/9
7982/7982 [==============================] - 1s 124us/step - loss: 0.6437 - accuracy: 0.8629 - val_loss: 0.9679 - val_accuracy: 0.7970
Epoch 6/9
7982/7982 [==============================] - 1s 116us/step - loss: 0.5177 - accuracy: 0.8931 - val_loss: 0.9502 - val_accuracy: 0.8040
Epoch 7/9
7982/7982 [==============================] - 1s 125us/step - loss: 0.4128 - accuracy: 0.9143 - val_loss: 0.9156 - val_accuracy: 0.8060
Epoch 8/9
7982/7982 [==============================] - 1s 123us/step - loss: 0.3394 - accuracy: 0.9267 - val_loss: 0.9121 - val_accuracy: 0.8110
Epoch 9/9
7982/7982 [==============================] - 1s 136us/step - loss: 0.2785 - accuracy: 0.9386 - val_loss: 0.8915 - val_accuracy: 0.8110
2246/2246 [==============================] - 0s 156us/step
</code></pre><p>这种方法可以得到约80% 的精度。对于平衡的二分类问题，完全随机的分类器能够得到50% 的精度。但在这个例子中，完全随机的精度约为19%，所以上述结果相当不错，至少和随机的基准比起来还不错。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> copy</span><br><span class="line">test_labels_copy = copy.copy(test_labels)</span><br><span class="line">np.random.shuffle(test_labels_copy)</span><br><span class="line">hits_array = np.array(test_labels) == np.array(test_labels_copy)</span><br><span class="line">float(np.sum(hits_array)) / len(test_labels)</span><br></pre></td></tr></table></figure>
<pre><code>0.18655387355298308
</code></pre><h2 id="8-在新数据上生成预测结果"><a href="#8-在新数据上生成预测结果" class="headerlink" title="8. 在新数据上生成预测结果"></a>8. 在新数据上生成预测结果</h2><p>你可以验证，模型实例的<code>predict</code>方法返回了在46 个主题上的概率分布。我们对所有测试数据生成主题预测。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">predictions = model.predict(x_test)</span><br></pre></td></tr></table></figure>
<p>predictions 中的每个元素都是长度为46 的向量</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">predictions[<span class="number">0</span>].shape</span><br></pre></td></tr></table></figure>
<pre><code>(46,)
</code></pre><p>最大的元素就是预测类别，即概率最大的类别。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.argmax(predictions[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<pre><code>3
</code></pre><h2 id="9-处理标签和损失的另一种方法"><a href="#9-处理标签和损失的另一种方法" class="headerlink" title="9. 处理标签和损失的另一种方法"></a>9. 处理标签和损失的另一种方法</h2><p>前面提到了另一种编码标签的方法，就是将其转换为整数张量，如下所示。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y_train = np.array(train_labels)</span><br><span class="line">y_test = np.array(test_labels)</span><br></pre></td></tr></table></figure><br>对于这种编码方法，唯一需要改变的是损失函数的选择。对于代码清单3-21 使用的损失函数<code>categorical_crossentropy</code>，标签应该遵循分类编码。对于整数标签，你应该使用<code>sparse_categorical_crossentropy</code>。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>,</span><br><span class="line">loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">metrics=[<span class="string">'acc'</span>])</span><br></pre></td></tr></table></figure><br>这个新的损失函数在数学上与<code>categorical_crossentropy</code>完全相同，二者只是接口不同</p>
<h1 id="三、预测房价：回归问题"><a href="#三、预测房价：回归问题" class="headerlink" title="三、预测房价：回归问题"></a>三、预测房价：回归问题</h1><p>前面两个例子都是分类问题，其目标是预测输入数据点所对应的单一离散的标签。另一种常见的机器学习问题是回归问题，它预测一个连续值而不是离散的标签，例如，根据气象数据预测明天的气温，或者根据软件说明书预测完成软件项目所需要的时间。</p>
<h2 id="1-波士顿房价数据集"><a href="#1-波士顿房价数据集" class="headerlink" title="1. 波士顿房价数据集"></a>1. 波士顿房价数据集</h2><p>下面将要预测20 世纪70 年代中期波士顿郊区房屋价格的中位数，已知当时郊区的一些数据点，比如犯罪率、当地房产税率等。</p>
<p>该数据集包含的数据点相对较少，只有506 个，分为404 个训练样本和102 个测试样本。输入数据的每个特征（比如犯罪率）都有不同的取值范围。例如，有些特性是比例，取值范围为0~1；有的取值范围为1~12；还有的取值范围为0~100，等等。</p>
<h2 id="2-加载波士顿房价数据"><a href="#2-加载波士顿房价数据" class="headerlink" title="2. 加载波士顿房价数据"></a>2. 加载波士顿房价数据</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> boston_housing</span><br><span class="line">(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()</span><br><span class="line">print(train_data.shape, test_data.shape)</span><br></pre></td></tr></table></figure>
<pre><code>(404, 13) (102, 13)
</code></pre><p>如你所见，我们有404 个训练样本和102 个测试样本，每个样本都有13 个数值特征，比如人均犯罪率、每个住宅的平均房间数、高速公路可达性等。</p>
<p>目标函数是房屋价格的中位数，单位是千美元。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_targets[:<span class="number">20</span>]</span><br></pre></td></tr></table></figure>
<pre><code>array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,
       17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5])
</code></pre><p>房价大都在10 000~50 000 美元。如果你觉得这很便宜，不要忘记当时是20 世纪70 年代中期，而且这些价格没有根据通货膨胀进行调整。</p>
<h2 id="3-准备数据"><a href="#3-准备数据" class="headerlink" title="3. 准备数据"></a>3. 准备数据</h2><p>将取值范围差异很大的数据输入到神经网络中，这是有问题的。网络可能会自动适应这种取值范围不同的数据，但学习肯定变得更加困难。对于这种数据，普遍采用的最佳实践是对每个特征做标准化，即对于输入数据的每个特征（输入数据矩阵中的列），减去特征平均值，再除以标准差，这样得到的特征平均值为0，标准差为1。用Numpy 可以很容易实现标准化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数据标准化</span></span><br><span class="line">mean = train_data.mean(axis=<span class="number">0</span>)</span><br><span class="line">train_data -= mean</span><br><span class="line">std = train_data.std(axis=<span class="number">0</span>)</span><br><span class="line">train_data /= std</span><br><span class="line">test_data -= mean</span><br><span class="line">test_data /= std</span><br></pre></td></tr></table></figure>
<p>注意，用于测试数据标准化的均值和标准差都是在训练数据上计算得到的。在工作流程中，你不能使用在测试数据上计算得到的任何结果，即使是像数据标准化这么简单的事情也不行。</p>
<h2 id="4-构建网络"><a href="#4-构建网络" class="headerlink" title="4. 构建网络"></a>4. 构建网络</h2><p>由于样本数量很少，我们将使用一个非常小的网络，其中包含两个隐藏层，每层有64 个单元。一般来说，训练数据越少，过拟合会越严重，而较小的网络可以降低过拟合。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 模型定义</span></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_model</span><span class="params">()</span>:</span></span><br><span class="line">    model = models.Sequential()</span><br><span class="line">    model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>, input_shape=(train_data.shape[<span class="number">1</span>],)))</span><br><span class="line">    model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">    model.add(layers.Dense(<span class="number">1</span>))</span><br><span class="line">    model.compile(optimizer=<span class="string">'rmsprop'</span>, loss=<span class="string">'mse'</span>, metrics=[<span class="string">'mae'</span>])</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<p>网络的最后一层只有一个单元，<strong>没有激活</strong>，是一个线性层。这是标量回归（标量回归是预测单一连续值的回归）的典型设置。添加激活函数将会限制输出范围。例如，如果向最后一层添加sigmoid 激活函数，网络只能学会预测0~1 范围内的值。这里最后一层是纯线性的，所以网络可以学会预测任意范围内的值。</p>
<p>注意，编译网络用的是<code>mse</code>损失函数，即均方误差（MSE，mean squared error），预测值与目标值之差的平方。这是回归问题常用的损失函数。</p>
<p>在训练过程中还监控一个新指标：平均绝对误差（MAE，mean absolute error）。它是预测值与目标值之差的绝对值。比如，如果这个问题的MAE 等于0.5，就表示你预测的房价与实际价格平均相差500 美元。</p>
<h2 id="5-利用K折验证来验证你的方法"><a href="#5-利用K折验证来验证你的方法" class="headerlink" title="5. 利用K折验证来验证你的方法"></a>5. 利用K折验证来验证你的方法</h2><p>为了在调节网络参数（比如训练的轮数）的同时对网络进行评估，你可以将数据划分为训练集和验证集，正如前面例子中所做的那样。但由于数据点很少，验证集会非常小（比如大约100 个样本）。因此，验证分数可能会有很大波动，这取决于你所选择的验证集和训练集。也就是说，验证集的划分方式可能会造成验证分数上有很大的方差，这样就无法对模型进行可靠的评估。</p>
<center>
    <img src="\Pic\DeepLearning_Pic\k-fold.png" width="400" height="400" alt="k-fold" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">k折验证</div>
</center>

<p>在这种情况下，最佳做法是使用<code>K</code>折交叉验证。这种方法将可用数据划分为<code>K</code>个分区（<code>K</code>通常取4 或5），实例化<code>K</code>个相同的模型，将每个模型在<code>K-1</code>个分区上训练，并在剩下的一个分区上进行评估。模型的验证分数等于<code>K</code>个验证分数的平均值。这种方法的代码实现很简单：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">k = <span class="number">4</span></span><br><span class="line">num_val_samples = len(train_data) // k</span><br><span class="line">num_epochs = <span class="number">100</span></span><br><span class="line">all_scores = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">    print(<span class="string">'processing fold #'</span>, i)</span><br><span class="line">    val_data = train_data[i * num_val_samples: (i + <span class="number">1</span>) * num_val_samples]</span><br><span class="line">    val_targets = train_targets[i * num_val_samples: (i + <span class="number">1</span>) * num_val_samples]</span><br><span class="line">    partial_train_data = np.concatenate([train_data[:i * num_val_samples],train_data[(i + <span class="number">1</span>) * num_val_samples:]],axis=<span class="number">0</span>)</span><br><span class="line">    partial_train_targets = np.concatenate([train_targets[:i * num_val_samples],train_targets[(i + <span class="number">1</span>) * num_val_samples:]],axis=<span class="number">0</span>)</span><br><span class="line">    model = build_model()</span><br><span class="line">    model.fit(partial_train_data, partial_train_targets,</span><br><span class="line">    epochs=num_epochs, batch_size=<span class="number">1</span>, verbose=<span class="number">0</span>)</span><br><span class="line">    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=<span class="number">0</span>)</span><br><span class="line">    all_scores.append(val_mae)</span><br></pre></td></tr></table></figure>
<pre><code>processing fold # 0
processing fold # 1
processing fold # 2
processing fold # 3
</code></pre><p>运行结果如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(<span class="string">'所有得分：'</span>, all_scores, <span class="string">'\n平均值为'</span>, np.mean(all_scores))</span><br></pre></td></tr></table></figure>
<pre><code>所有得分： [2.0891380310058594, 2.6256139278411865, 2.7675087451934814, 2.588402271270752] 
平均值为 2.51766574382782
</code></pre><p>每次运行模型得到的验证分数有很大差异，从2.6 到3.2 不等。平均分数（3.0）是比单一分数更可靠的指标——这就是K 折交叉验证的关键。在这个例子中，预测的房价与实际价格平均相差3000 美元，考虑到实际价格范围在10 000~50 000 美元，这一差别还是很大的。</p>
<p>我们可以让训练时间更长一点，达到500 个轮次。为了记录模型在每轮的表现，我们需要修改训练循环，以保存每轮的验证分数记录。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num_epochs = <span class="number">500</span></span><br><span class="line">all_mae_histories = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">    print(<span class="string">'processing fold #'</span>, i)</span><br><span class="line">    val_data = train_data[i * num_val_samples: (i + <span class="number">1</span>) * num_val_samples]</span><br><span class="line">    val_targets = train_targets[i * num_val_samples: (i + <span class="number">1</span>) * num_val_samples]</span><br><span class="line">    partial_train_data = np.concatenate([train_data[:i * num_val_samples],train_data[(i + <span class="number">1</span>) * num_val_samples:]],axis=<span class="number">0</span>)</span><br><span class="line">    partial_train_targets = np.concatenate([train_targets[:i * num_val_samples],train_targets[(i + <span class="number">1</span>) * num_val_samples:]],axis=<span class="number">0</span>)</span><br><span class="line">    model = build_model()</span><br><span class="line">    history = model.fit(partial_train_data, partial_train_targets,</span><br><span class="line">    validation_data=(val_data, val_targets),</span><br><span class="line">    epochs=num_epochs, batch_size=<span class="number">1</span>, verbose=<span class="number">0</span>)</span><br><span class="line">    mae_history = history.history[<span class="string">'val_mean_absolute_error'</span>]</span><br><span class="line">    all_mae_histories.append(mae_history)</span><br></pre></td></tr></table></figure><br>然后你可以计算每个轮次中所有折MAE 的平均值。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">average_mae_history = [np.mean([x[i] <span class="keyword">for</span> x <span class="keyword">in</span> all_mae_histories]) <span class="keyword">for</span> i <span class="keyword">in</span> range(num_epochs)]</span><br></pre></td></tr></table></figure><br>我们画图来看一下：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.plot(range(<span class="number">1</span>, len(average_mae_history) + <span class="number">1</span>), average_mae_history)</span><br><span class="line">plt.xlabel(<span class="string">'Epochs'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Validation MAE'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<center>
    <img src="\Pic\DeepLearning_Pic\MAE_1.png" width="400" height="400" alt="MAE_1" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">每轮的验证MAE</div>
</center>

<p>因为纵轴的范围较大，且数据方差相对较大，所以难以看清这张图的规律。我们来重新绘制一张图。</p>
<ul>
<li>删除前 10 个数据点，因为它们的取值范围与曲线上的其他点不同。</li>
<li>将每个数据点替换为前面数据点的指数移动平均值，以得到光滑的曲线。<br>代码如下所示：<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">smooth_curve</span><span class="params">(points, factor=<span class="number">0.9</span>)</span>:</span></span><br><span class="line">    smoothed_points = []</span><br><span class="line">    <span class="keyword">for</span> point <span class="keyword">in</span> points:</span><br><span class="line">        <span class="keyword">if</span> smoothed_points:</span><br><span class="line">            previous = smoothed_points[<span class="number">-1</span>]</span><br><span class="line">            smoothed_points.append(previous * factor + point * (<span class="number">1</span> - factor))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            smoothed_points.append(point)</span><br><span class="line">    <span class="keyword">return</span> smoothed_points</span><br><span class="line">smooth_mae_history = smooth_curve(average_mae_history[<span class="number">10</span>:])</span><br><span class="line">plt.plot(range(<span class="number">1</span>, len(smooth_mae_history) + <span class="number">1</span>), smooth_mae_history)</span><br><span class="line">plt.xlabel(<span class="string">'Epochs'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Validation MAE'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
从图中可以看出验证MAE 在80 轮后不再显著降低，之后就开始过拟合。</li>
</ul>
<center>
    <img src="\Pic\DeepLearning_Pic\MAE_2.png" width="400" height="400" alt="MAE_2" align="center">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">每轮的验证MAE（删除前十个数据点）</div>
</center>

<p>完成模型调参之后（除了轮数，还可以调节隐藏层大小），你可以使用最佳参数在所有训练数据上训练最终的生产模型，然后观察模型在测试集上的性能。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = build_model()</span><br><span class="line">model.fit(train_data, train_targets,</span><br><span class="line">epochs=<span class="number">80</span>, batch_size=<span class="number">16</span>, verbose=<span class="number">0</span>)</span><br><span class="line">test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)</span><br><span class="line">print(test_mae_score)</span><br></pre></td></tr></table></figure>
<pre><code>102/102 [==============================] - 0s 147us/step
2.905885696411133
</code></pre><p>你预测的房价还是和实际价格相差约2905 美元。</p>
]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
  </entry>
  <entry>
    <title>XGBoost（二）解决二分类和多分类问题</title>
    <url>/posts/8c5e1ebd.html</url>
    <content><![CDATA[<p>XGBoost由多棵决策树（CART）组成，每棵决策树预测真实值与之前所有决策树预测值之和的残差（残差=真实值-预测值），将所有决策树的预测值累加起来即为最终结果。</p>
<h1 id="一、二分类问题"><a href="#一、二分类问题" class="headerlink" title="一、二分类问题"></a>一、二分类问题</h1><p>XGBoost树模型由多棵回归树组成，并将多棵决策树的预测值累计相加作为最终结果。回归树产生的是连续的回归值，如何用它解决二分类问题呢？通过前面的学习知道，逻辑回归是在线性回归的基础上通过<code>sigmoid</code>函数将预测值映射到0～1的区间来代表二分类结果的概率。和逻辑回归一样，XGBoost也是采用<code>sigmoid</code>函数来解决二分类问题，即先通过回归树对样本进行预测，得到每棵树的预测结果，然后将其进行累加求和，最后通过<code>sigmoid</code>函数将其映射到0～1的区间代表二分类结果的概率。另外，对于二分类问题，XGBoost的目标函数采用的是类似逻辑回归的<code>logloss</code>，而非最小二乘。</p>
<p>XGBoost中关于二分类的常用参数有如下几个：</p>
<ul>
<li><code>Objective</code>: 该参数用来指定目标函数，XGBoost可以根据该参数判断进行何种学习任务，<code>binary:logistic</code>和<code>binary:logitraw</code>都表示学习任务类型为二分类。<code>binary:logistic</code>输出为概率，<code>binary:logitraw</code>输出为逻辑转换前的输出分数。</li>
<li><code>eval_metric</code>: 该参数用来指定模型的评估函数，和二分类相关的评估函数有：error、logloss和auc。error也称错误率，即预测错误的样本数占总样本数的比例，准确来说是预测错误样本的权重和占总样本权重和的比例，也可通过error@k的形式手工指定二分类的阈值。logloss通过惩罚分类来量化模型的准确性，最大限度减少logloss，等同于最大化模型的准确率。另外，AUC也是二分类中最常用的评估指标之一，计算方法可另外查询。</li>
</ul>
<p>下面仍然以该案例数据集进行说明。蘑菇数据集是一个非常著名的二分类数据集。该数据集一共包含23个特征，包括大小、表面、颜色等，每一种蘑菇都会被定义为可食用的或者有毒的，需要通过样本数据分析这些特征与蘑菇毒性的关系。以下是各个特征的详细说明：</p>
<ul>
<li>帽形（cap-shape）：钟形=b，圆锥形=c，凸形=x，平面=f，把手形=k，凹陷=S</li>
<li>帽面（cap-surface）：纤维状=f，凹槽状=g，鳞片状=y，光滑=s</li>
<li>帽颜色（cap-color）：棕色=n，浅黄色=b，肉桂色=c，灰色=g，绿色=r，粉红色=p，紫色=u，红色=e，白色=w，黄色=y</li>
<li>创伤（bruises）：创伤=t，no=f</li>
<li>气味（odor）：杏仁=a，茴香=l，石灰=c，腥味=y，臭味=f，霉味=m，无=n，刺鼻=p，辣=s</li>
<li>菌褶附属物（gill-attachment:）：附着=a，下降=d，自由=f，缺口=n</li>
<li>菌褶间距（gill-spacing）：紧密=c，拥挤=w，远隔=d</li>
<li>菌褶大小（gill-size）：宽=b，窄=n。</li>
<li>菌褶颜色（gill-color）：黑色=k，棕色=n，浅黄色=b，巧克力色=h，灰色=g，绿色=r，橙色=o，粉红色=p，紫色=u，红色=e，白色=w，黄色=y</li>
<li>茎形（stalk-shape）：扩大=e，锥形=t</li>
<li>茎根（stalk-root）：球根=b，棒状=c，杯状=u，均等的=e，根状菌索=z，扎根=r，缺省=？</li>
<li>环上茎面（stalk-surface-above-ring）：纤维状=f，鳞片状=y，丝状=k，光滑=s</li>
<li>环下茎面（stalk-surface-below-ring）：纤维状=f，鳞片状=y，丝状=k，光滑=s</li>
<li>环上茎颜色（stalk-color-above-ring）：棕色=n，浅黄色=b，黄棕色=c，灰色=g，橙色=o，粉红色=p，红色=e，白色=w，黄色=y</li>
<li>环下茎颜色（stalk-color-below-ring）：棕色=n，浅黄色=b，黄棕色=c，灰色=g，橙色=o，粉红色=p，红色=e，白色=w，黄色=y</li>
<li>菌幕类型（veil-type）：部分=p，普遍=u</li>
<li>菌幕颜色（veil-color）：棕色=n，橙色=o，白色=w，黄色=y</li>
<li>环数量（ring-number）：没有=n，一个=o，两个=t</li>
<li>环类型（ring-type）：蛛网状=c，消散状=e，喇叭形=f，大规模的=l，无=n，悬垂的=p，覆盖=s，环带=z</li>
<li>孢子显现颜色（spore-print-color）：黑色=k，棕色=n，蓝色=b，巧克力色=h，绿色=r，橙色=o，紫色=u，白色=w，黄色=y</li>
<li>种群（population）：丰富=a，聚集=c，众多=n，分散=s，个别=v，单独=y</li>
<li>栖息地（habitat）：草地=g，树叶=l，草甸=m，路上=p，城市=u，荒地=w，树林=d</li>
<li>class：label字段，有可食用（edible）和有毒性（poisonous）两个取值</li>
</ul>
<p>该数据集总共有8124个样本，其中类别为可食用的样本有4208个，类别为有毒性的样本有3916个。对于该二分类问题，XGBoost工程文件中提供了示例代码。示例以命令行的方式调用XGBoost，完成模型训练、预测等过程。示例位于<code>demo/CLI/binary_classification</code>文件夹下，其中包括下面几个文件：</p>
<ul>
<li><code>agaricus-lepiota.data</code>——蘑菇数据文件</li>
<li><code>agaricus-lepiota.fmap</code>——字段名称映射文件</li>
<li><code>agaricus-lepiota.names</code>——蘑菇数据集描述文件</li>
<li><code>mapfeat.py</code>——数据集特征值预处理</li>
<li><code>mknfold.py</code>——划分数据集</li>
<li><code>mushroom.conf</code>——模型配置文件</li>
<li><code>runexp.sh</code>——运行脚本</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_dir = <span class="string">"xgboost_source_code/demo/CLI/binary_classification/"</span></span><br></pre></td></tr></table></figure>
<p>读者可自行尝试执行<code>runexp.sh</code>脚本，学习命令行形式的调用过程。本节重点介绍如何通过Python调用XGBoost进行模型训练和预测，并对处理流程中的各个阶段进行详细解析。</p>
<p>首先需要对特征进行预处理。因为原始文件<code>agaricus-lepiota.data</code>中的数据并不能直接作为XGBoost的输入进行加载，需要进行预处理。这里将其中的字符数据转为数值型，并以LibSVM的格式输出。LibSVM是机器学习中经常采用的一种数据格式，如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;label&gt; &lt;index1&gt;:&lt;value1&gt;&lt;index2&gt;:&lt;value2&gt;...</span><br></pre></td></tr></table></figure>
<p><code>label</code>为训练数据集的目标值；<code>index</code>为特征索引，是一个以1为起始的整数；<code>value</code>是该特征的取值，如果某一特征的值缺省，则该特征可以空着不填，因此对于一个样本来讲，输出后的数据文件<code>index</code>可能并不连续，上述样本处理后的格式如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1 3:1 10:1 11:1 21:1 30:1 34:1 36:1 40:1 41:1 53:1 58:1 65:1 69:1 77:1 86:1 88:1 92:1 95:1 102:1 105:1 117:1 124:1</span><br><span class="line">0 3:1 10:1 20:1 21:1 23:1 34:1 36:1 39:1 41:1 53:1 56:1 65:1 69:1 77:1 86:1 88:1 92:1 95:1 102:1 106:1 116:1 120:1</span><br></pre></td></tr></table></figure>
<p>第一个样本中最开始的“1”便是该样本的label，在二分类问题中，一般1代表正样本，0代表负样本。之后的每个特征为一项，冒号前为该特征的索引，如3、10等，冒号后为该特征取值，如3、10两个特征的取值都是1。另外，观察处理后的数据可以发现，特征索引已经远远超过了22，如第一行样本中特征索引最大已经达到了124。</p>
<p>观察该数据集可以发现，其中大部分特征是离散型特征，连续型特征较少。在机器学习算法中，特征之间距离的计算是十分重要的，因此，直接把离散变量的取值转化为数值，并不能很好地代表特征间的距离，如菌幕颜色特征，其总共有棕色、橙色、白色、黄色4种颜色，假如将其映射为1、2、3、4，则棕色和橙色之间的距离是2-1=1，而棕色和白色之间的距离是3-1=2。这显然是不符合实际情况的，因为任意两个颜色之间的距离应该是相等的。因此，需要对特征进行独热编码（one-hot encoding）。</p>
<p>简单来讲，独热编码就是离散特征有多少取值，就用多少维来表示该特征。仍然以菌幕颜色特征为例，经过独热编码后，其将会转为4个特征，分别是菌幕颜色是否为棕色、菌幕颜色是否为橙色、菌幕颜色是否为白色和菌幕颜色是否为黄色，并且这4个特征取值只有0和1。经过独热编码之后，每两个颜色之间的距离都是一样的，比之前的处理更合理。离散特征经过独热编码之后，数据集的总特征数会变多，这就是上述示例中出现较大特征索引的原因。下面来看一下特征处理的代码实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadmap</span><span class="params">(fname)</span>:</span></span><br><span class="line">    fmap = &#123;&#125;</span><br><span class="line">    nmap = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> open(fname):</span><br><span class="line">        arr = l.split()</span><br><span class="line">        <span class="keyword">if</span> arr[<span class="number">0</span>].find(<span class="string">'.'</span>) != <span class="number">-1</span>:</span><br><span class="line">            idx = int(arr[<span class="number">0</span>].strip(<span class="string">'.'</span>))</span><br><span class="line">            <span class="keyword">assert</span> idx <span class="keyword">not</span> <span class="keyword">in</span> fmap</span><br><span class="line">            fmap[idx] = &#123;&#125;</span><br><span class="line">            ftype = arr[<span class="number">1</span>].strip(<span class="string">":"</span>)</span><br><span class="line">            content = arr[<span class="number">2</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            content = arr[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> it <span class="keyword">in</span> content.split(<span class="string">','</span>):</span><br><span class="line">            <span class="keyword">if</span> it.strip() == <span class="string">''</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            k, v = it.split(<span class="string">'='</span>)</span><br><span class="line">            fmap[idx][v] = len(nmap) + <span class="number">1</span></span><br><span class="line">            nmap[len(nmap)] = ftype + <span class="string">'='</span> + k</span><br><span class="line">    <span class="keyword">return</span> fmap, nmap</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_nmap</span><span class="params">(fo, nmap)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nmap)):</span><br><span class="line">        fo.write(<span class="string">'%d\t%s\ti\n'</span>%(i, nmap[i]))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fmap, nmap = loadmap(data_dir+<span class="string">'agaricus-lepiota.fmap'</span>)</span><br><span class="line">fo = open(<span class="string">'output/data/featmap.txt'</span>, <span class="string">'w'</span>)</span><br><span class="line">write_nmap(fo, nmap)</span><br><span class="line">fo.close()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fo = open(<span class="string">'output/data/agaricus.txt'</span>, <span class="string">'w'</span>)</span><br><span class="line"><span class="keyword">for</span> l <span class="keyword">in</span> open(data_dir+<span class="string">'agaricus-lepiota.data'</span>):</span><br><span class="line">    arr = l.split(<span class="string">','</span>)</span><br><span class="line">    <span class="keyword">if</span> arr[<span class="number">0</span>] == <span class="string">'p'</span>:</span><br><span class="line">        fo.write(<span class="string">'1'</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">assert</span> arr[<span class="number">0</span>] == <span class="string">'e'</span></span><br><span class="line">        fo.write(<span class="string">'0'</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len(arr)):</span><br><span class="line">        fo.write(<span class="string">' %d:1'</span> %fmap[i][arr[i].strip()])</span><br><span class="line">    fo.write(<span class="string">'\n'</span>)</span><br><span class="line">fo.close()</span><br></pre></td></tr></table></figure>
<p>首先程序会加载特征描述文件<code>agaricus-lepiota.fmap</code>，为每个特征的每个取值均分配一个唯一的索引标识，并为其重新命名，并将处理后的新特征索引和名称的映射保存为<code>featmap.txt</code>文件（该映射文件会在XGBoost中用到）。然后加载蘑菇数据集，通过新特征索引处理该数据集，生成转化后的新数据文件<code>featmap.txt</code>。特征处理完后即可通过mknfold.py划分数据集。在本示例中，划分数据集是通过代码实现的，当然读者也可以采用第3章介绍的scikit-learn中的<code>train_test_split</code>来划分数据集。下面看一下<code>mknfold.py</code>的代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> len(sys.argv) &lt; <span class="number">2</span>:</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">'Usage:&lt;filename&gt; &lt;k&gt; [nfold = 5]'</span>)</span><br><span class="line">    exit(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">random.seed( <span class="number">10</span> )</span><br><span class="line"></span><br><span class="line">k = int( sys.argv[<span class="number">2</span>] )</span><br><span class="line"><span class="keyword">if</span> len(sys.argv) &gt; <span class="number">3</span>:</span><br><span class="line">    nfold = int( sys.argv[<span class="number">3</span>] )</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    nfold = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">fi = open( sys.argv[<span class="number">1</span>], <span class="string">'r'</span> )</span><br><span class="line">ftr = open( sys.argv[<span class="number">1</span>]+<span class="string">'.train'</span>, <span class="string">'w'</span> )</span><br><span class="line">fte = open( sys.argv[<span class="number">1</span>]+<span class="string">'.test'</span>, <span class="string">'w'</span> )</span><br><span class="line"><span class="keyword">for</span> l <span class="keyword">in</span> fi:</span><br><span class="line">    <span class="keyword">if</span> random.randint( <span class="number">1</span> , nfold ) == k:</span><br><span class="line">        fte.write( l )</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        ftr.write( l )</span><br><span class="line"></span><br><span class="line">fi.close()</span><br><span class="line">ftr.close()</span><br><span class="line">fte.close()</span><br></pre></td></tr></table></figure>
<p>生成训练集和测试集后，便可通过XGBoost加载数据进行训练，下面通过Python实现XGBoost的调用。先加载训练集和测试集：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line">xgb_train = xgb.DMatrix(<span class="string">"xgboost_source_code/demo/data/agaricus.txt.train"</span>)</span><br><span class="line">xgb_test = xgb.DMatrix(<span class="string">"xgboost_source_code/demo/data/agaricus.txt.test"</span>)</span><br></pre></td></tr></table></figure>
<p>设定模型训练参数，开始模型训练：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">params = &#123;</span><br><span class="line">    <span class="string">"objective"</span> : <span class="string">"binary:logistic"</span>,</span><br><span class="line">    <span class="string">"booster"</span> : <span class="string">"gbtree"</span>, </span><br><span class="line">    <span class="string">"eta"</span> : <span class="number">1.0</span>,</span><br><span class="line">    <span class="string">"gamma"</span> : <span class="number">1.0</span>,</span><br><span class="line">    <span class="string">"min_child_weight"</span> : <span class="number">1</span>,</span><br><span class="line">    <span class="string">"max_depth"</span> : <span class="number">3</span></span><br><span class="line">&#125;</span><br><span class="line">num_round = <span class="number">2</span></span><br><span class="line">watchlist = [(xgb_train, <span class="string">"train"</span>), (xgb_test, <span class="string">"test"</span>)]</span><br><span class="line">model = xgb.train(params, xgb_train, num_round, watchlist)</span><br></pre></td></tr></table></figure>
<pre><code>[0]    train-error:0.01443    test-error:0.01614
[1]    train-error:0.00123    test-error:0.00000
</code></pre><p><code>params</code>中的<code>objective</code>和<code>booster</code>参数已经介绍过了，分别用于指定任务的学习目标和<code>booster</code>类型，其他参数说明如下：</p>
<ul>
<li><code>objective</code>设为<code>binary:logistic</code>，表示任务为二分类问题，最终输出为<code>sigmoid</code>变换后的概率。</li>
<li><code>booster</code>为<code>gbtree</code>表示采用XGBoost中的树模型。参数<code>eta</code>表示学习率，类似于梯度下降中法的$\alpha$，每次迭代完更新权重的步长。</li>
<li><code>gamma</code>表示节点分裂时损失函数减小的最小值，此处为1.0，表示损失函数至少下降1.0该节点才会进行分裂。</li>
<li><code>min_child_weight</code>表示叶子节点最小样本权重和，若节点分裂导致叶子节点的样本权重和小于该值，则节点不进行分裂。</li>
<li><code>max_depth</code>表示决策树分裂的最大深度。</li>
</ul>
<p>另外，该示例中指定了<code>num_round</code>为2，即模型会进行两轮<code>booster</code>训练，最终会生成两棵决策树。通过定义参数<code>watchlist</code>，模型在训练过程中会实时输出训练集和验证集的评估指标。</p>
<p>模型训练完成之后，可通过<code>save_model</code>方法将模型保存成模型文件，以供后续预测使用，如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.save_model(<span class="string">"output/model/02_agaricus.model"</span>)</span><br></pre></td></tr></table></figure>
<p>预测时，先加载保存的模型文件，然后再对数据集进行预测，如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">bst = xgb.Booster()</span><br><span class="line">bst.load_model(<span class="string">"output/model/02_agaricus.model"</span>)</span><br><span class="line">pred = bst.predict(xgb_test)</span><br><span class="line">print(pred)</span><br></pre></td></tr></table></figure>
<pre><code>[0.10828121 0.85500014 0.10828121 ... 0.95467216 0.04156424 0.95467216]
</code></pre><p>可以看到，输出结果是一个浮点数组成的数组，其中每个值代表对应样本的预测概率。预测完成后，输出文本格式的模型，这里仍然采用两种方式，如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 未作特征名转换</span></span><br><span class="line">dump_model_raw = bst.dump_model(<span class="string">"output/data/dump.raw.txt"</span>)</span><br><span class="line"><span class="comment"># 完成特征名转换</span></span><br><span class="line">dump_model_nice = bst.dump_model(<span class="string">"output/data/dump.nice.txt"</span>, <span class="string">"output/data/featmap.txt"</span>)</span><br></pre></td></tr></table></figure>
<p>下面主要以完成特征名称转换后的模型文件为例进行介绍。先来看一下索引和特征名称映射文件<code>featmap.txt</code>，格式如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;featureid&gt; &lt;featurename&gt; &lt;q or i or int&gt;\n</span><br></pre></td></tr></table></figure>
<p>其中：</p>
<ul>
<li><code>featureid</code>为特征索引</li>
<li><code>featurename</code>为特征名称</li>
<li><code>q or i or int</code>为特征的数据类型，其中<code>q</code>代表特征是一个连续值，如距离、价格等；<code>i</code>代表特征是一个二值特征（即特征只有两个取值），一般为0或1；<code>int</code>代表特征是整型值。可以看到，<code>featmap.txt</code>中的很多特征都是二值特征。这个也不难理解，因为该数据集中大部分是离散型的类别特征，因此经过独热编码处理后，新生成的特征基本都是二值特征。</li>
</ul>
<p>了解了特征映射文件后，下面来看一下文本格式的XGBoost树模型文件，以下截取了<code>dump.nice.txt</code>的前几行：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">booster[0]:</span><br><span class="line">0:[odor&#x3D;pungent] yes&#x3D;2,no&#x3D;1</span><br><span class="line">1:[stalk-root&#x3D;cup] yes&#x3D;4,no&#x3D;3</span><br><span class="line">3:[stalk-root&#x3D;missing] yes&#x3D;8,no&#x3D;7</span><br><span class="line">			7:leaf&#x3D;1.90174532</span><br><span class="line">			8:leaf&#x3D;-1.95061731</span><br><span class="line">4:[bruises?&#x3D;no] yes&#x3D;10,no&#x3D;9</span><br><span class="line">			9:leaf&#x3D;1.77777779</span><br><span class="line">			10:leaf&#x3D;-1.98104262</span><br><span class="line">2:[spore-print-color&#x3D;orange] yes&#x3D;6,no&#x3D;5</span><br><span class="line">5:[stalk-surface-below-ring&#x3D;silky] yes&#x3D;12,no&#x3D;11</span><br></pre></td></tr></table></figure>
<p>上面的一个booster代表一棵决策树，该模型一共有两棵决策树。在每棵决策树中，每一行代表一个节点，位于行首的数字代表该节点的索引，数字0表示该节点为根节点。若该行节点是非叶子节点，则索引后面是该节点的分裂条件，如第2行：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0:[odor&#x3D;pungent] yes&#x3D;2,no&#x3D;1</span><br></pre></td></tr></table></figure>
<p>该节点的索引为0，表示该节点是根节点，其分裂条件是odor=pungent，满足该条件的样本会被划分到节点2，不满足的则被划分到节点1。若该行节点是叶子节点，则索引后面是该叶子节点最终得到的权重。如第5行：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">7:leaf&#x3D;1.90174532</span><br></pre></td></tr></table></figure>
<p><code>leaf</code>表示该节点为叶子节点，最终得到的权重为1.90174532。由此，通过文本格式的模型文件，可以使用户了解样本在模型中是如何被划分的，使模型更具有可解释性，并且在实际的机器学习任务中，也有利于用户更好地分析和优化模型。</p>
<h1 id="二、多分类问题"><a href="#二、多分类问题" class="headerlink" title="二、多分类问题"></a>二、多分类问题</h1><p>与处理二分类问题类似，XGBoost在处理多分类问题时也是在树模型的基础上进行转换，不过不再是<code>sigmoid</code>函数，而是<code>softmax</code>函数。相信大家对<code>softmax</code>变换并不陌生，它可以将多分类的预测值映射到0到1之间，代表样本属于该类别的概率。XGBoost中解决多分类问题的主要参数如下：</p>
<ul>
<li><code>num_class</code>：说明在该分类任务的类别数量</li>
<li><code>objective</code>：该参数中的<code>multi:softmax</code>和<code>multi:softprob</code>均是指定学习任务为多分类。<code>multi:softmax</code>通过<code>softmax</code>函数解决多分类问题。<code>multi:softprob</code>和<code>multi:softmax</code>一样，主要区别在于其输出的是一个$ndata*nclass$向量，表示样本属于每个分类的预测概率</li>
<li><code>eval_metric</code>：与多分类相关的评估函数有<code>merror</code>和<code>mlogloss</code>。<code>merror</code>也称多分类错误率，通过判断样本所有分类预测值中预测值最大的分类和样本label是否一致来确定预测是否正确，其计算方式和<code>error</code>相似。<code>mlogloss</code>也是多分类问题中常用的评估指标。有关<code>merror</code>和<code>mlogloss</code>会在后面详细介绍。</li>
</ul>
<p>下面以识别小麦种子的类别作为示例，介绍如何通过XGBoost解决多分类问题。已知小麦种子数据集包含7个特征，分别为面积、周长、紧凑度、籽粒长度、籽粒宽度、不对称系数、籽粒腹沟长度，且均为连续型特征，以及小麦类别字段，共有3个类别，分别用1、2、3表示。加载该数据并进行特征处理，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">"input/seeds_dataset.txt"</span>, header=<span class="literal">None</span>, sep=<span class="string">'\s+'</span>, converters=&#123;<span class="number">7</span>: <span class="keyword">lambda</span> x:int(x)<span class="number">-1</span>&#125;)</span><br><span class="line">data.rename(columns=&#123;<span class="number">7</span>:<span class="string">'label'</span>&#125;, inplace=<span class="literal">True</span>)</span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>15.26</td>
      <td>14.84</td>
      <td>0.8710</td>
      <td>5.763</td>
      <td>3.312</td>
      <td>2.221</td>
      <td>5.220</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>14.88</td>
      <td>14.57</td>
      <td>0.8811</td>
      <td>5.554</td>
      <td>3.333</td>
      <td>1.018</td>
      <td>4.956</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>14.29</td>
      <td>14.09</td>
      <td>0.9050</td>
      <td>5.291</td>
      <td>3.337</td>
      <td>2.699</td>
      <td>4.825</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>13.84</td>
      <td>13.94</td>
      <td>0.8955</td>
      <td>5.324</td>
      <td>3.379</td>
      <td>2.259</td>
      <td>4.805</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>16.14</td>
      <td>14.99</td>
      <td>0.9034</td>
      <td>5.658</td>
      <td>3.562</td>
      <td>1.355</td>
      <td>5.175</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<p>为便于后续处理，将最后一个类别字段作为<code>label</code>字段，因为<code>label</code>的取值需在0到<code>num_class-1</code>范围内，因此需对类别字段进行处理（数据集中的3个类别取值分别为1～3），这里直接减1即可。</p>
<p>可以看到，数据集共包含8列，其中前7列为特征列，最后1列为<code>label</code>列，和数据集描述相符。除<code>label</code>列外，剩余特征没有指定列名，所以pandas自动以数字索引作为列名。下面对数据集进行划分（训练集和测试集的划分比例为4:1），并指定<code>label</code>字段生成XGBoost中的<code>DMatrix</code>数据结构，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mask = np.random.rand(len(data)) &lt; <span class="number">0.8</span></span><br><span class="line">train = data[mask]</span><br><span class="line">test = data[~mask]</span><br><span class="line">xgb_train = xgb.DMatrix(train.iloc[:,:<span class="number">6</span>], label=train.label)</span><br><span class="line">xgb_test = xgb.DMatrix(test.iloc[:,:<span class="number">6</span>], label=test.label)</span><br></pre></td></tr></table></figure>
<p>设置模型训练参数。设置参数<code>objective</code>为<code>multi:softmax</code>，表示采用<code>softmax</code>进行多分类，学习率参数<code>eta</code>和最大树深度<code>max_depth</code>在之前的示例中已有所介绍，不再赘述。参数<code>num_class</code>指定类别数量为3。相关代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">params = &#123;</span><br><span class="line">    <span class="string">'objective'</span>:<span class="string">'multi:softmax'</span>,</span><br><span class="line">    <span class="string">'eta'</span>:<span class="number">0.1</span>,</span><br><span class="line">    <span class="string">'max_depth'</span>:<span class="number">5</span>,</span><br><span class="line">    <span class="string">'num_class'</span>:<span class="number">3</span></span><br><span class="line">&#125;</span><br><span class="line">watchlist = [(xgb_train, <span class="string">"train"</span>), (xgb_test, <span class="string">"test"</span>)]</span><br><span class="line">num_round = <span class="number">10</span></span><br><span class="line">bst = xgb.train(params, xgb_train, num_round, watchlist)</span><br></pre></td></tr></table></figure>
<pre><code>[0]    train-merror:0.01219    test-merror:0.10870
[1]    train-merror:0.01219    test-merror:0.10870
[2]    train-merror:0.01219    test-merror:0.10870
[3]    train-merror:0.01219    test-merror:0.10870
[4]    train-merror:0.01219    test-merror:0.13043
[5]    train-merror:0.00610    test-merror:0.13043
[6]    train-merror:0.00610    test-merror:0.13043
[7]    train-merror:0.00610    test-merror:0.13043
[8]    train-merror:0.00610    test-merror:0.15217
[9]    train-merror:0.00610    test-merror:0.15217
</code></pre><p>在未指定评估函数的情况下，XGBoost默认采用<code>merror</code>作为多分类问题的评估指标。下面通过训练好的模型对测试集进行预测，并计算错误率，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pred = bst.predict(xgb_test)</span><br><span class="line">error_rate = np.sum(pred != test.label) / test.shape[<span class="number">0</span>]</span><br><span class="line">print(error_rate)</span><br></pre></td></tr></table></figure>
<pre><code>0.15217391304347827
</code></pre><p>为了方便对比学习，下面采用<code>multi:softprob</code>方法重新训练模型，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">params[<span class="string">"objective"</span>] = <span class="string">"multi:softprob"</span></span><br><span class="line">bst = xgb.train(params, xgb_train, num_round, watchlist)</span><br></pre></td></tr></table></figure>
<pre><code>[0]    train-merror:0.01219    test-merror:0.10870
[1]    train-merror:0.01219    test-merror:0.10870
[2]    train-merror:0.01219    test-merror:0.10870
[3]    train-merror:0.01219    test-merror:0.10870
[4]    train-merror:0.01219    test-merror:0.13043
[5]    train-merror:0.00610    test-merror:0.13043
[6]    train-merror:0.00610    test-merror:0.13043
[7]    train-merror:0.00610    test-merror:0.13043
[8]    train-merror:0.00610    test-merror:0.15217
[9]    train-merror:0.00610    test-merror:0.15217
</code></pre><p>对比两种函数变换方法的训练输出结果可以看出，不论采用<code>multi:softmax</code>还是<code>multi:softprob</code>作为<code>objective</code>训练模型，并不会影响到模型精度。</p>
<p>下面对测试集进行预测并计算错误率，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pred_prop = bst.predict(xgb_test)</span><br><span class="line">pred_label = np.argmax(pred_prop, axis=<span class="number">1</span>)</span><br><span class="line">error_rate = np.sum(pred_label != test.label) / test.shape[<span class="number">0</span>]</span><br><span class="line">print(<span class="string">'测试集错误率(softprob):&#123;&#125;'</span>.format(error_rate))</span><br></pre></td></tr></table></figure>
<pre><code>测试集错误率(softprob):0.15217391304347827
</code></pre><p>之后的处理则和采用<code>multi:softmax</code>时一样，统计预测错误的样本数，最终计算出分类错误率。采用<code>multi:softprob</code>得到的错误率和<code>multi:softmax</code>也是一样的</p>
]]></content>
      <categories>
        <category>XGBoost</category>
      </categories>
  </entry>
  <entry>
    <title>XGBoost（一）简单机器学习示例</title>
    <url>/posts/298496a6.html</url>
    <content><![CDATA[<h1 id="一、XGBoost简单应用"><a href="#一、XGBoost简单应用" class="headerlink" title="一、XGBoost简单应用"></a>一、XGBoost简单应用</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">xgb_train = xgb.DMatrix(<span class="string">"xgboost_source_code/demo/data/agaricus.txt.train"</span>)</span><br><span class="line">xgb_test = xgb.DMatrix(<span class="string">"xgboost_source_code/demo/data/agaricus.txt.test"</span>)</span><br><span class="line">param = &#123;<span class="string">'max_depth'</span>:<span class="number">2</span>, <span class="string">'eta'</span>:<span class="number">1</span>, <span class="string">'objective'</span>:<span class="string">'binary:logistic'</span>&#125;</span><br><span class="line">num_round = <span class="number">5</span></span><br><span class="line">watch_list = [(xgb_train, <span class="string">"train"</span>), (xgb_test, <span class="string">"test"</span>)]</span><br><span class="line">model = xgb.train(param, xgb_train, num_round, watch_list)</span><br></pre></td></tr></table></figure>
<pre><code>[0]    train-error:0.04652    test-error:0.04283
[1]    train-error:0.02226    test-error:0.02173
[2]    train-error:0.00706    test-error:0.00621
[3]    train-error:0.01520    test-error:0.01800
[4]    train-error:0.00706    test-error:0.00621
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">preds = model.predict(xgb_test)</span><br><span class="line">preds</span><br></pre></td></tr></table></figure>
<pre><code>array([0.08073306, 0.92217326, 0.08073306, ..., 0.98059034, 0.01182149,
       0.98059034], dtype=float32)
</code></pre><h1 id="二、机器学习算法基础"><a href="#二、机器学习算法基础" class="headerlink" title="二、机器学习算法基础"></a>二、机器学习算法基础</h1><p>我们首先介绍几个基础的机器学习算法的实现原理和应用，如KNN、线性回归、逻辑回归等，使读者对机器学习算法有一个基本认识的同时，了解如何在模型训练过程中进行优化，以及如何对模型结果进行评估。然后，对决策树模型做了详细介绍。决策树是XGBoost模型的重要组成部分，学习和掌握决策树的生成、剪枝等内容将会对后续的学习提供巨大帮助。排序问题是机器学习中的常见问题，神经网络和支持向量机也是经常采用的机器学习算法，最后将分别介绍两者的实现原理，结合详细的公式推导过程，使读者能够深入理解算法背后的数学原理。</p>
<h2 id="1-KNN做鸢尾花数据预测"><a href="#1-KNN做鸢尾花数据预测" class="headerlink" title="1. KNN做鸢尾花数据预测"></a>1. KNN做鸢尾花数据预测</h2><p>KNN的主要算法思想为：特征空间中的一个样本，如果与其最相似的k个样本中的大部分属于某个类别，则该样本也属于该类别。KNN既可以用于解决分类问题，也可以用于回归问题。</p>
<p>对于分类问题，离样本最近的k个邻居中占多数的类别作为该样本的类别，如果k=1，则选取最近邻居的类别作为该样本的类别。对于回归问题，样本的预测值是最近的k个邻居的平均值。</p>
<p>KNN的计算步骤如下。</p>
<ol>
<li>计算测试样本与训练集中所有（或大部分）样本的距离，该距离可以是欧氏距离、余弦距离等，较常用的是欧氏距离。</li>
<li>找到步骤1中距离最短的k个样本，作为预测样本的邻居。</li>
<li>对于分类问题，通过投票机制选出k个邻居中最多的类别作为预测样本的预测值。对于回归问题，则采用k个邻居的平均值。</li>
</ol>
<p>Iris也称鸢尾花卉数据集，是一类多重变量分析的数据集。数据集包含150个数据集，分为3类，每类50个数据，每个数据包含4个属性。可通过花萼长度，花萼宽度，花瓣长度，花瓣宽度4个属性预测鸢尾花卉属于（Setosa，Versicolour，Virginica）三个种类中的哪一类。</p>
<p><strong>数据描述</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>变量名</th>
<th>sepal_length</th>
<th>sepal_width</th>
<th>petal_length</th>
<th>petal_width</th>
<th>species</th>
</tr>
</thead>
<tbody>
<tr>
<td>变量解释</td>
<td>花萼长度（单位cm）</td>
<td>花萼宽度（单位cm）</td>
<td>花瓣长度（单位cm）</td>
<td>花瓣宽度（单位cm）</td>
<td>种类</td>
</tr>
<tr>
<td>数据类型</td>
<td>numeric</td>
<td>numeric</td>
<td>numeric</td>
<td>numeric</td>
<td>categorical</td>
</tr>
</tbody>
</table>
</div>
<h3 id="1-1-导入数据集并观察分布"><a href="#1-1-导入数据集并观察分布" class="headerlink" title="1.1 导入数据集并观察分布"></a>1.1 导入数据集并观察分布</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line">iris = load_iris()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.DataFrame(iris.data, columns=iris.feature_names).head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal length (cm)</th>
      <th>sepal width (cm)</th>
      <th>petal length (cm)</th>
      <th>petal width (cm)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
  </tbody>
</table>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">setosa_sepal_len = iris.data[:<span class="number">50</span>, <span class="number">0</span>]</span><br><span class="line">setosa_sepal_width = iris.data[:<span class="number">50</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">versi_sepal_len = iris.data[<span class="number">50</span>:<span class="number">100</span>, <span class="number">0</span>]</span><br><span class="line">versi_sepal_width = iris.data[<span class="number">50</span>:<span class="number">100</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">vergi_sepal_len = iris.data[<span class="number">100</span>:, <span class="number">0</span>]</span><br><span class="line">vergi_sepal_width = iris.data[<span class="number">100</span>:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">pyplot.scatter(setosa_sepal_len, setosa_sepal_width, marker = <span class="string">'o'</span>, c = <span class="string">'b'</span>,  s = <span class="number">30</span>, label = <span class="string">'Setosa'</span>)</span><br><span class="line">pyplot.scatter(versi_sepal_len, versi_sepal_width, marker = <span class="string">'o'</span>, c = <span class="string">'r'</span>,  s = <span class="number">50</span>, label = <span class="string">'Versicolour'</span>)</span><br><span class="line">pyplot.scatter(vergi_sepal_len, vergi_sepal_width, marker = <span class="string">'o'</span>, c = <span class="string">'y'</span>,  s = <span class="number">35</span>, label = <span class="string">'Virginica'</span>)</span><br><span class="line">pyplot.xlabel(<span class="string">"sepal length"</span>)</span><br><span class="line">pyplot.ylabel(<span class="string">"sepal width"</span>)</span><br><span class="line">pyplot.title(<span class="string">"sepal length and width scatter"</span>)</span><br><span class="line">pyplot.legend(loc = <span class="string">"upper right"</span>)</span><br></pre></td></tr></table></figure>
<p><img src="\Pic\XGBoost_Pic\output_7_1.png" alt="png"></p>
<h3 id="2-绘制各个品种各个特征平均值的直方图"><a href="#2-绘制各个品种各个特征平均值的直方图" class="headerlink" title="2. 绘制各个品种各个特征平均值的直方图"></a>2. 绘制各个品种各个特征平均值的直方图</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">iris_data = pd.DataFrame(iris.data, columns=iris.feature_names)</span><br><span class="line">iris_data[<span class="string">"class"</span>] = iris.target</span><br><span class="line">iris_data.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal length (cm)</th>
      <th>sepal width (cm)</th>
      <th>petal length (cm)</th>
      <th>petal width (cm)</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">grouped_data = iris_data.groupby(<span class="string">"class"</span>)</span><br><span class="line">group_mean = grouped_data.mean()</span><br><span class="line">group_mean.plot(kind=<span class="string">'bar'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">"center right"</span>, bbox_to_anchor=(<span class="number">1.4</span>, <span class="number">0.3</span>), ncol=<span class="number">1</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="\Pic\XGBoost_Pic\output_10_0.png" alt="png"></p>
<h3 id="3-划分数据集"><a href="#3-划分数据集" class="headerlink" title="3. 划分数据集"></a>3. 划分数据集</h3><p>因为我们至少需要一个训练集来训练模型（KNN则用于最终预测计算），一个测试集来检验模型对新样本的预测能力，而目前只有一个数据集，因此需要对数据集进行划分。划分数据集有很多方法，比如留出法（hold-out）、交叉验证法等，本示例采用较常用的留出法。留出法的实现原理是，按照一定比例将数据集划分为互不相交的两部分，分别作为训练集和测试集。此处选用的训练集、测试集的比例为4:1，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">msk = np.random.rand(len(iris_data)) &lt; <span class="number">0.8</span></span><br><span class="line">train_data_origin = iris_data[msk]</span><br><span class="line">test_data_origin = iris_data[~msk]</span><br><span class="line"></span><br><span class="line">train_data = train_data_origin.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">test_data = test_data_origin.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">train_label = train_data[<span class="string">"class"</span>]</span><br><span class="line">test_label = test_data[<span class="string">"class"</span>]</span><br><span class="line"></span><br><span class="line">train_fea = train_data.drop(<span class="string">"class"</span>, <span class="number">1</span>)</span><br><span class="line">test_fea = test_data.drop(<span class="string">"class"</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数据归一化</span></span><br><span class="line">train_norm = (train_fea - train_fea.min()) / (train_fea.max() - train_fea.min())</span><br><span class="line">test_norm = (test_fea - test_fea.min()) / (test_fea.max() - test_fea.min())</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> neighbors</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">knn = neighbors.KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line">knn.fit(train_norm, train_label)</span><br><span class="line">predict = knn.predict(test_norm)</span><br><span class="line">accuracy = accuracy_score(test_label, predict)</span><br><span class="line">accuracy</span><br></pre></td></tr></table></figure>
<pre><code>0.9166666666666666
</code></pre><p>KNN算法是机器学习中最简单、有效的算法。上面通过鸢尾花品种分类的示例详细介绍了KNN算法的实现原理和应用。KNN算法属于懒惰学习算法，当数据集的样本容量比较大时，计算量也会比较大，并且需要较大的存储空间。此外，它无法给出数据的任何基础结构信息，后面介绍的算法将会解决这个问题。</p>
<h2 id="2-线性回归预测波士顿房价"><a href="#2-线性回归预测波士顿房价" class="headerlink" title="2. 线性回归预测波士顿房价"></a>2. 线性回归预测波士顿房价</h2><p>下面通过一个示例来说明如何应用线性回归。以波士顿房屋价格数据集作为示例数据集，该数据集包含了波士顿房屋以及周边环境的一些详细信息，包括城镇人均犯罪率、一氧化碳浓度、住宅平均房屋数等。该数据集包含506个样本、13个特征字段、1个label字段</p>
<p><strong>数据描述</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>No</th>
<th>属性</th>
<th>数据类型</th>
<th>字段描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>CRIM</td>
<td>Float</td>
<td>城镇人均犯罪率</td>
</tr>
<tr>
<td>2</td>
<td>ZN</td>
<td>Float</td>
<td>占地面积超过2.5万平方英尺的住宅用地比例</td>
</tr>
<tr>
<td>3</td>
<td>INDUS</td>
<td>Float</td>
<td>城镇非零售业务地区的比例</td>
</tr>
<tr>
<td>4</td>
<td>CHAS</td>
<td>Integer</td>
<td>查尔斯河虚拟变量 (= 1 如果土地在河边；否则是0)</td>
</tr>
<tr>
<td>5</td>
<td>NOX</td>
<td>Float</td>
<td>一氧化氮浓度（每1000万份）</td>
</tr>
<tr>
<td>6</td>
<td>RM</td>
<td>Float</td>
<td>平均每居民房数</td>
</tr>
<tr>
<td>7</td>
<td>AGE</td>
<td>Float</td>
<td>在1940年之前建成的所有者占用单位的比例</td>
</tr>
<tr>
<td>8</td>
<td>DIS</td>
<td>Float</td>
<td>与五个波士顿就业中心的加权距离</td>
</tr>
<tr>
<td>9</td>
<td>RAD</td>
<td>Integer</td>
<td>辐射状公路的可达性指数</td>
</tr>
<tr>
<td>10</td>
<td>TAX</td>
<td>Float</td>
<td>每10,000美元的全额物业税率</td>
</tr>
<tr>
<td>11</td>
<td>PTRATIO</td>
<td>Float</td>
<td>城镇师生比例</td>
</tr>
<tr>
<td>12</td>
<td>B</td>
<td>Float</td>
<td>1000（Bk - 0.63）^ 2其中Bk是城镇黑人的比例</td>
</tr>
<tr>
<td>13</td>
<td>LSTAT</td>
<td>Float</td>
<td>人口中地位较低人群的百分数</td>
</tr>
<tr>
<td>14</td>
<td>MEDV</td>
<td>Float</td>
<td>（目标变量/类别属性）以1000美元计算的自有住房的中位数</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line">boston = load_boston()</span><br><span class="line">X = boston.data</span><br><span class="line">y = boston.target</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line">lr = LinearRegression()</span><br><span class="line">lr.fit(X_train, y_train)</span><br><span class="line">y_pred = lr.predict(X_test)</span><br><span class="line">mean_squared_error(y_test, y_pred)</span><br></pre></td></tr></table></figure>
<pre><code>23.380836480270315
</code></pre><p>另外XGBoost也提供了线性回归的API，其数据加载步骤与上述<code>scikit-learn</code>的方法相同，不再赘述。使用XGBoost，首先要把数据转化为其自定义的<code>DMatrix</code>格式，该格式为XGBoost特定的输入格式。然后定义模型参数，此处定义较为简单，只选用了2个参数，如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">params = &#123;<span class="string">"objective"</span>:<span class="string">"reg:linear"</span>, <span class="string">"booster"</span>:<span class="string">"gblinear"</span>&#125;</span><br></pre></td></tr></table></figure>
<p>其中，<code>objective</code>用于确定模型的目标函数，这里以<code>reg:squarederror</code>作为目标函数。参数<code>booster</code>用于确定采用什么样的模型，此处选择的是线性模型（gblinear），读者也可根据应用场景选择其他模型（gbtree、dart），因本节主要介绍线性回归，因此选用线性模型。定义好参数后即可训练模型，最后用该模型对测试集进行预测。代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_xgb = xgb.DMatrix(X_train, y_train)</span><br><span class="line">params = &#123;<span class="string">"objective"</span>:<span class="string">"reg:squarederror"</span>, <span class="string">"booster"</span>:<span class="string">"gblinear"</span>&#125;</span><br><span class="line">model = xgb.train(dtrain=train_xgb, params=params)</span><br><span class="line">y_pred = model.predict(xgb.DMatrix(X_test))</span><br></pre></td></tr></table></figure>
<p>综上，线性回归是一种解决回归问题的常见方法。在线性回归中，求解最优参数的方法是最小化其损失函数。最小化损失函数有两种方法：<strong>正规方程和梯度下降法</strong>。</p>
<p>正规方程通过矩阵运算求得最优参数，但其必须满足$X^TX$可逆，当样本数比特征数还少时，$X^TX$的逆是不能直接计算的。</p>
<p>梯度下降法是沿负梯度的方向一步步最小化损失函数，求解最优参数。梯度下降法需要指定步长并进行多次迭代，但相比于正规方程，梯度下降法可以应用于特征数较大的情况。最后，通过波士顿房价的示例展示了通过scikit-learn和XGBoost如何应用线性回归。</p>
<h2 id="3-逻辑回归预测良性-恶性乳腺肿瘤"><a href="#3-逻辑回归预测良性-恶性乳腺肿瘤" class="headerlink" title="3. 逻辑回归预测良性/恶性乳腺肿瘤"></a>3. 逻辑回归预测良性/恶性乳腺肿瘤</h2><p>下面将使用逻辑回归预测乳腺肿瘤是良性的还是恶性的。示例采用的数据集为威斯康星诊断乳腺癌数据集，它通过细胞核的相关特征来预测乳腺肿瘤为良性/恶性，这是一个非常著名的二分类数据集。该数据集包含569个样本，其中有212个恶性肿瘤样本，357个良性肿瘤样本。共有32个字段，字段1为ID，字段2为label，其他30个字段为细胞核的相关特征，例如：</p>
<ul>
<li>半径（从中心到周边点的平均距离）</li>
<li>纹理（灰度值的标准偏差）</li>
<li>周长</li>
<li>面积</li>
<li>光滑度（半径长度的局部变化）</li>
<li>紧凑性（周长的二次方/面积的负一次方）</li>
<li>凹度（轮廓的凹陷程度）</li>
<li>凹点（轮廓中凹部的数量）</li>
<li>对称</li>
<li>分形维数</li>
</ul>
<p>对于每张图像，分别计算以上10个特征的平均值、标准误差和最差/最大（最大的3个值的平均）值，由此生成30个特征。例如，字段3表示平均半径，字段13表示半径的标准误差，字段23表示最差半径。所有特征都保留4位有效数字。</p>
<p>scikit-learn已经集成了该数据集，并进行了相应的处理（如去掉了ID字段），使用时直接加载即可，如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_breast_cancer</span><br><span class="line">cancer = load_breast_cancer()</span><br><span class="line">X = cancer.data</span><br><span class="line">y = cancer.target</span><br></pre></td></tr></table></figure>
<p>其中，X为特征数据，包含上面介绍的30个特征，y为标签数据，标记乳腺肿瘤类型，1代表良性，0代表恶性。下面按4:1的比例将数据集划分为训练集和测试集：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lr.fit(X_train, y_train)</span><br><span class="line">y_pred = lr.predict(X_test)</span><br><span class="line">print(classification_report(y_test, y_pred, target_names=[<span class="string">"Benign"</span>, <span class="string">"Malignant"</span>]))</span><br></pre></td></tr></table></figure>
<pre><code>              precision    recall  f1-score   support

      Benign       0.95      0.90      0.93        42
   Malignant       0.95      0.97      0.96        72

    accuracy                           0.95       114
   macro avg       0.95      0.94      0.94       114
weighted avg       0.95      0.95      0.95       114
</code></pre><p>其中，列表的左边一列为分类的标签名，<code>avg/total</code>为各列的均值。<code>support</code>表示该类别样本出现的次数。</p>
<p>XGBoost提供了逻辑回归的API，读者可以通过XGBoost中的逻辑回归对数据集进行预测，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_xgb = xgb.DMatrix(X_train, y_train)</span><br><span class="line">params = &#123;<span class="string">"objective"</span>:<span class="string">"reg:logistic"</span>, <span class="string">"booster"</span>:<span class="string">"gblinear"</span>&#125;</span><br><span class="line">model = xgb.train(dtrain=train_xgb, params=params)</span><br><span class="line">y_pred = model.predict(xgb.DMatrix(X_test))</span><br></pre></td></tr></table></figure>
<p>XGBoost逻辑回归API的调用方式和线性回归类似，唯一不同的是目标函数<code>objective</code>改为<code>reg:logistic</code>，<code>booster</code>仍然选择线性模型。</p>
<p>注意，XGBoost在预测结果上和scikit-learn有些差别，XGBoost的预测结果是概率，而scikit-learn的预测结果是0或1的分类（scikit-learn也可通过<code>predict_proba</code>输出概率）。在XGBoost中，如果需要输出0或1的分类，需要用户自己对其进行转化，例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ypred_bst = np.array(y_pred)</span><br><span class="line">y_pred_bst = ypred_bst &gt; <span class="number">0.5</span></span><br><span class="line">y_pred_bst = y_pred_bst.astype(int)</span><br><span class="line">print(classification_report(y_test, y_pred_bst, target_names=[<span class="string">"Benign"</span>, <span class="string">"Malignant"</span>]))</span><br></pre></td></tr></table></figure>
<pre><code>              precision    recall  f1-score   support

      Benign       0.90      0.67      0.77        42
   Malignant       0.83      0.96      0.89        72

    accuracy                           0.85       114
   macro avg       0.87      0.81      0.83       114
weighted avg       0.86      0.85      0.84       114
</code></pre><h2 id="4-决策树解决肿瘤分类问题"><a href="#4-决策树解决肿瘤分类问题" class="headerlink" title="4. 决策树解决肿瘤分类问题"></a>4. 决策树解决肿瘤分类问题</h2><p>scikit-learn实现了决策树算法，它采用的是一种优化的CART版本，既可以解决分类问题，也可以解决回归问题。分类问题使用DecisionTreeClassifier类，回归问题使用DecisionTreeRegressor类。两个类的参数相似，只有部分有所区别，以下是对主要参数的说明。</p>
<ol>
<li><code>criterion</code>：特征选择采用的标准。DecisionTreeClassifier分类树默认采用<code>gini</code>（基尼系数）进行特征选择，也可以使用<code>entropy</code>（信息增益）。DecisionTreeRegressor默认采用MSE（均方误差），也可以使用MAE（平均绝对误差）。</li>
<li><code>splitter</code>：节点划分的策略。支持<code>best</code>和<code>random</code>两种方式，默认为<code>best</code>，即选取所有特征中最优的切分点作为节点的分裂点，<code>random</code>则随机选取部分切分点，从中选取局部最优的切分点作为节点的分裂点。</li>
<li><code>max_depth</code>：树的最大深度，默认为None，表示没有最大深度限制。节点停止分裂的条件是：样本均属于相同类别或所有叶子节点包含的样本数量小于$min_samples_split$。若将该参数设置为None以外的其他值，则决策树生成过程中达到该阈值深度时，节点停止分裂。</li>
<li><code>min_samples_split</code>：节点划分的最小样本数，默认为2。若节点包含的样本数小于该值，则该节点不再分裂。若该字段设置为浮点数，则表示最小样本百分比，划分的最小样本数为$ceil（min_samples_split*n_samples）$。</li>
<li><code>min_samples_leaf</code>：叶子节点包含的最小样本数，默认为1。此字段和<code>min_samples_split</code>类似，取值可以是整型，也可以是浮点型。整型表示一个叶子节点包含的最小样本数，浮点型则表示百分比。叶子节点包含的最小样本数为$ceil（min_samples_leaf*n_samples）$。</li>
<li><code>max_features</code> ：划分节点时备选的最大特征数，默认为None，表示选用所有特征。若该字段为整数，表示选用的最大特征数；若为浮点数，则表示选用特征的最大百分比。最大特征数为$int（max_features*n_features）$。</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_breast_cancer</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"></span><br><span class="line">cancer = load_breast_cancer()</span><br><span class="line">X = cancer.data</span><br><span class="line">y = cancer.target</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">clf = tree.DecisionTreeClassifier(max_depth=<span class="number">4</span>)</span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line">y_pred = clf.predict(X_test)</span><br><span class="line">print(classification_report(y_test, y_pred, target_names=[<span class="string">"Benign"</span>, <span class="string">"Malignant"</span>]))</span><br></pre></td></tr></table></figure>
<pre><code>              precision    recall  f1-score   support

      Benign       0.95      0.87      0.91        46
   Malignant       0.92      0.97      0.94        68

    accuracy                           0.93       114
   macro avg       0.93      0.92      0.93       114
weighted avg       0.93      0.93      0.93       114
</code></pre><p>为便于读者直观地理解树模型，可以使用Graphviz工具包将模型可视化。Graphviz是一个开源的图形可视化软件，可以将结构数据转化为形象的图形或网络，在软件工程、数据库、机器学习等领域的可视化界面中有应用。函数<code>export_graphviz</code>可以将<code>scikit-learn</code>中的决策树导出为Graphviz的格式，导出完成后即可对Graphviz格式的决策树进行图形渲染，如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> graphviz</span><br><span class="line">dot_data = tree.export_graphviz(clf, out_file=<span class="literal">None</span>,</span><br><span class="line">                               feature_names=cancer.feature_names,</span><br><span class="line">                               class_names=cancer.target_names,</span><br><span class="line">                               filled=<span class="literal">True</span>, rounded=<span class="literal">True</span>,</span><br><span class="line">                               special_characters=<span class="literal">True</span>)</span><br><span class="line">graph = graphviz.Source(dot_data)</span><br><span class="line"><span class="comment"># graph</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将dot_data写入到txt文件中</span></span><br><span class="line">f = open(<span class="string">'output/img/dot_data.txt'</span>, <span class="string">'w'</span>) </span><br><span class="line">f.write(dot_data) </span><br><span class="line">f.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解决中文乱码问题</span></span><br><span class="line"><span class="comment"># import re </span></span><br><span class="line"><span class="comment"># f_old = open('dot_data.txt', 'r') </span></span><br><span class="line"><span class="comment"># f_new = open('dot_data_new.txt', 'w', encoding='utf-8') </span></span><br><span class="line"><span class="comment"># for line in f_old: </span></span><br><span class="line"><span class="comment">#     if 'fontname' in line:</span></span><br><span class="line"><span class="comment">#         font_re = 'fontname=(.*?)]'</span></span><br><span class="line"><span class="comment">#     old_font = re.findall(font_re, line)[0]</span></span><br><span class="line"><span class="comment">#     line = line.replace(old_font, 'SimHei')</span></span><br><span class="line"><span class="comment">#     f_new.write(line)</span></span><br><span class="line"><span class="comment">#     f_old.close()</span></span><br><span class="line"><span class="comment">#     f_new.close()</span></span><br></pre></td></tr></table></figure>
<h2 id="5-神经网络识别手写体数字"><a href="#5-神经网络识别手写体数字" class="headerlink" title="5. 神经网络识别手写体数字"></a>5. 神经网络识别手写体数字</h2><p>手写体数字数据集（MNIST）是一个经典的多分类数据集，由不同的手写体数字图片以及0～9的数字标签样本构成。scikit-learn中的手写体数字数据集共有1797个样本，每个样本包含一个8×8像素的图像和0～9的数字标签。scikit-learn通过<code>MLPClassifier</code>类实现的多层感知器完成分类任务，通过<code>MLPRegressor</code>类完成回归任务。对于手写体数字数据集这样的多分类问题，显然要采用<code>MLPClassifier</code>。<code>MLPClassifier</code>的常用参数如下:</p>
<ul>
<li><code>hidden_layer_sizes</code>：用来指定隐藏层包含的节点数量，其类型为tuple，长度是<code>n_layers-2</code>，其中n_layers为网络总层数；</li>
<li><code>activation</code>：指定隐藏层的激活函数，默认为relu；</li>
<li><code>solver</code>：指定权重的更新方法，默认为sgd，即随机梯度下降法；</li>
<li><code>alpha</code>：指定L2正则的惩罚系数；</li>
<li><code>learning_rate</code>：指定训练过程中学习率更新方法，有constant、invscaling和adaptive这3种方法。其中，constant表示学习率在训练过程中为固定值；invscaling表示随着训练的进行，学习率指数降低；adaptive表示动态调整，当训练误差不断减少时（减少量超过一定阈值），学习率保持不变，若连续两次迭代训练损失未达到上述条件，则学习率缩小为原值的1/5。</li>
<li><code>max_iter</code>表示迭代的最大轮数，对于solver为sgd和adam的情况，<code>max_iter</code>相当于epoch的数量。</li>
</ul>
<p>了解了<code>MLPClassifier</code>类的常用参数后，下面介绍如何使用<code>MLPClassifier</code>来解决识别手写体数字的问题。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_digits</span><br><span class="line">digits = load_digits()</span><br><span class="line">X = digits.data</span><br><span class="line">y = digits.target</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">8</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line">mlp = MLPClassifier(hidden_layer_sizes=(<span class="number">128</span>, <span class="number">64</span>), max_iter=<span class="number">50</span>, alpha=<span class="number">1e-4</span>, solver=<span class="string">'sgd'</span>)</span><br><span class="line">mlp.fit(X_train, y_train)</span><br><span class="line">y_pred = mlp.predict(X_test)</span><br><span class="line">print(<span class="string">"Accuracy: "</span>, accuracy_score(y_test, y_pred))</span><br></pre></td></tr></table></figure>
<pre><code>Accuracy:  0.9555555555555556
</code></pre><h2 id="6-支持向量机识别手写体数字"><a href="#6-支持向量机识别手写体数字" class="headerlink" title="6. 支持向量机识别手写体数字"></a>6. 支持向量机识别手写体数字</h2><p>下面仍以手写体数字数据集（MNIST）为例，介绍如何使用SVM解决分类问题。SVM既可以解决二分类问题，也能解决多分类问题。SVM解决多分类问题的方法主要有两种：one-vs-one和one-vs-the-rest。</p>
<ul>
<li><code>one-vs-one</code>为每两类样本建立一个二分类器，则$k$个类别的样本需要建立$\frac{k(k-1)}{2}$个二分类器。</li>
<li><code>one-vs-the-rest</code>是为每个类别和其他剩余类别建立一个二分类器，从中选择预测概率最大的分类作为最终分类，k个类别的样本需建立k个二分类器。</li>
</ul>
<p>scikit-learn通过SVC类来解决分类问题，通过SVR类来解决回归问题（SVM也可以解决回归问题），下面采用SVC类解决手写体数字识别的多分类问题。</p>
<p>SVC可以通过参数kernel指定采用的核函数，支持的核函数有：<code>linear</code>（线性核函数）、<code>poly</code>（多项式）、<code>rbf</code>（高斯）、<code>sigmoid</code>、<code>precomputed</code>以及自定义形式<code>callable</code>。若不指定kernel，其默认采用<code>rbf</code>。SVC还有几个比较常用的参数：</p>
<ul>
<li>惩罚参数$C$，即前面松弛变量中介绍的不满足约束条件样本的惩罚系数；</li>
<li>参数<code>degree</code>是多项式核函数（kernel设置为<code>poly</code>）的阶数；</li>
<li>参数gamma表示高斯核和sigmoid核中的内核系数，在高斯核中对应的是高斯核函数公式中的$\frac{1}{2\sigma^2}$。</li>
</ul>
<p>数据集的加载和划分同神经网络中的示例，不再赘述。此处主要介绍模型拟合与评估。</p>
<p>先定义一个SVC模型，这里采用高斯核函数，惩罚系数C为1.0，gamma为0.001，当然也可以通过参数调优来确定参数。定义模型之后即可训练模型，然后对测试集进行预测，最后以准确率为指标评估预测结果。具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line">svc = svm.SVC(C=<span class="number">1.0</span>, kernel=<span class="string">"rbf"</span>, gamma=<span class="number">0.001</span>)</span><br><span class="line">svc.fit(X_train, y_train)</span><br><span class="line">y_pred = svc.predict(X_test)</span><br><span class="line">print(<span class="string">"Accuracy"</span>, accuracy_score(y_test, y_pred))</span><br></pre></td></tr></table></figure>
<pre><code>Accuracy 0.9861111111111112
</code></pre><p>也可以采用其他核函数，如多项式核函数，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">svc = svm.SVC(C=<span class="number">1.0</span>, kernel=<span class="string">"poly"</span>, degree=<span class="number">3</span>)</span><br><span class="line">svc.fit(X_train, y_train)</span><br><span class="line">y_pred = svc.predict(X_test)</span><br><span class="line">print(<span class="string">"Accuracy"</span>, accuracy_score(y_test, y_pred))</span><br></pre></td></tr></table></figure>
<pre><code>Accuracy 0.9861111111111112
</code></pre><p>可以看到，在本例中采用多项式核函数和高斯核函数的预测准确率是相同的。读者也可自行尝试其他参数，观察不同参数对模型预测的影响。</p>
]]></content>
      <categories>
        <category>XGBoost</category>
      </categories>
  </entry>
  <entry>
    <title>MySQL入门（六）分组查询</title>
    <url>/posts/ceaf7866.html</url>
    <content><![CDATA[<p>本文数据集下载链接：<a href="https://pan.baidu.com/s/1sVcSXfVZimc6ruyMr4Gr3g" target="_blank" rel="noopener">https://pan.baidu.com/s/1sVcSXfVZimc6ruyMr4Gr3g</a> ，提取码：7gfa </p>
<h1 id="一、分组函数简介"><a href="#一、分组函数简介" class="headerlink" title="一、分组函数简介"></a>一、分组函数简介</h1><p><code>GROUP BY</code> 语句根据一个或多个列对结果集进行分组，在分组的列上我们可以使用 <code>COUNT, SUM, AVG</code>等函数。</p>
<p><strong>功能</strong>：用于统计，又称为聚合函数或统计函数或组函数</p>
<p><strong>分类</strong>：<code>sum</code>求和，<code>avg</code>平均值，<code>max</code>最大值，<code>min</code>最小值，<code>count</code>计算个数</p>
<p><strong>特点</strong>：</p>
<ol>
<li><code>SUM, AVG</code>一般处理数值型， <code>MAX, MIN, COUNT</code>可以处理任何类型</li>
<li>是否忽略<code>NULL</code>值：所有分组函数都忽略<code>NULL</code>值</li>
<li>可以和<code>DISTINCT</code>搭配实现去重运算</li>
<li><code>COUNT</code>函数的专门介绍</li>
</ol>
<h2 id="1-简单使用"><a href="#1-简单使用" class="headerlink" title="1. 简单使用"></a>1. 简单使用</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT SUM(salary) FROM employees;</span><br><span class="line">SELECT AVG(salary) FROM employees;</span><br><span class="line">SELECT MIN(salary) FROM employees;</span><br><span class="line">SELECT MAX(salary) FROM employees;</span><br><span class="line">SELECT COUNT(salary) FROM employees; </span><br><span class="line">SELECT SUM(salary) 和, ROUND(AVG(salary), 2) 平均, MAX(salary) 最高, MIN(salary) 最低, COUNT(salary) FROM employees;</span><br></pre></td></tr></table></figure>
<h2 id="2-参数类型"><a href="#2-参数类型" class="headerlink" title="2. 参数类型"></a>2. 参数类型</h2><p>以下为无意义但不报错的使用方式：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT SUM(last_name), AVG(last_name) </span><br><span class="line">FROM employees;</span><br></pre></td></tr></table></figure>
<p>同理还有对日期求和等，也是无意义的。以下使用方式是合理的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT MAX(last_name), MIN(last_name) </span><br><span class="line">FROM employees;</span><br></pre></td></tr></table></figure>
<p>这是因为可以按照首字母排序，于是也有最大值和最小值，同理对日期求最大最小值也是可以的</p>
<p>也可以使用<code>COUNT</code>语句对其他类型求和：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT COUNT(commission_pct), COUNT(last_name) </span><br><span class="line">FROM employees;</span><br><span class="line"># 返回35和107</span><br></pre></td></tr></table></figure>
<p>两者不同是因为<code>COUNT</code>返回 不为NULL的个数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT SUM(DISTINCT salary), sum(salary) </span><br><span class="line">FROM employees;</span><br></pre></td></tr></table></figure>
<h2 id="3-COUNT函数详解"><a href="#3-COUNT函数详解" class="headerlink" title="3. COUNT函数详解"></a>3. <code>COUNT</code>函数详解</h2><p><strong>统计总行数</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT COUNT(*) </span><br><span class="line">FROM employees;</span><br></pre></td></tr></table></figure>
<p>每一行中只要有不为<code>NULL</code>的计数器就加一，同理也可以使用以下方式统计总行数：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT COUNT(1) </span><br><span class="line">FROM employees;</span><br></pre></td></tr></table></figure>
<p>事实上，<code>COUNT()</code>中的常量值可以取任何值获得同样的效果，但就效率而言</p>
<ul>
<li>在MYISAM存储引擎下，<code>COUNT(*)</code>的效率高</li>
<li>在INNODB存储引擎下，<code>COUNT(*)</code>的效率和<code>COUNT(1)</code>差不多，但比<code>COUNT(字段)</code>效率高</li>
</ul>
<p>因此一般使用<code>COUNT(*)</code>来统计行数</p>
<p><strong>注意：和分组函数一同查询的字段有限制(要求是group by后的字段)</strong></p>
<h1 id="二、分组查询"><a href="#二、分组查询" class="headerlink" title="二、分组查询"></a>二、分组查询</h1><ol>
<li><p>筛选条件可分为两类：分组前筛选和分组后筛选</p>
<p>|                | <strong>数据源</strong>     | <strong>位置</strong>             | <strong>关键字</strong> |<br>| ——————— | ——————— | —————————— | ————— |<br>| <strong>分组前筛选</strong> | 原始表         | <code>GROUP BY</code>子句的前面 | <code>WHERE</code>    |<br>| <strong>分组后筛选</strong> | 分组后的结果集 | <code>GROUP BY</code>子句的后面 | <code>HAVING</code>   |</p>
</li>
<li><p><code>GROUP BY</code>子句支持单个字段分组、多个字段分组（多个字段之间用逗号隔开，没有顺序要求）</p>
</li>
<li><p>也可以添加排序（放在整个分组查询最后）</p>
</li>
</ol>
<p>注：</p>
<ol>
<li>分组函数做条件肯定是放在HAVING子句中</li>
<li>能用分组前筛选的优先使用分组前筛选</li>
</ol>
<h2 id="1-GROUP-BY语法"><a href="#1-GROUP-BY语法" class="headerlink" title="1. GROUP BY语法"></a>1. <code>GROUP BY</code>语法</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT column_name, function(column_name)</span><br><span class="line">FROM table_name</span><br><span class="line">WHERE column_name operator value</span><br><span class="line">GROUP BY column_name;</span><br></pre></td></tr></table></figure>
<h2 id="2-具体示例"><a href="#2-具体示例" class="headerlink" title="2. 具体示例"></a>2. 具体示例</h2><p><strong>查询每个部门的平均工资</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT department_id, AVG(salary) </span><br><span class="line">FROM employees </span><br><span class="line">GROUP BY department_id;</span><br></pre></td></tr></table></figure>
<p><strong>查询每个工种有奖金的员工的最高工资</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT MAX(salary), job_id </span><br><span class="line">FROM employees </span><br><span class="line">WHERE commission_pct IS NOT NULL </span><br><span class="line">GROUP BY job_id;</span><br></pre></td></tr></table></figure>
<p><strong>根据上一题查询结果筛选最高工资&gt;12000</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT MAX(salary), job_id </span><br><span class="line">FROM employees </span><br><span class="line">WHERE commission_pct IS NOT NULL </span><br><span class="line">GROUP BY job_id </span><br><span class="line">HAVING MAX(salary)&gt;12000;</span><br></pre></td></tr></table></figure>
<p><strong>查询领导编号&gt;102的每个领导手下的最低工资&gt;5000的领导编号是哪个，以及其最低工资</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT MIN(salary), manager_id </span><br><span class="line">FROM employees </span><br><span class="line">WHERE manager_id&gt;102</span><br><span class="line">GROUP BY manager_id </span><br><span class="line">HAVING MIN(salary)&gt;5000</span><br></pre></td></tr></table></figure>
<p><strong>按表达式（函数）分组：按员工姓名的长度分组，查询每一组的员工个数，筛选员工个数&gt;5的有哪些</strong></p>
<p>① 查询每个长度的员工个数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT COUNT(*), LENGTH(last_name) len_name </span><br><span class="line">FROM employees </span><br><span class="line">GROUP BY LENGTH(last_name);</span><br></pre></td></tr></table></figure>
<p>② 添加筛选条件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT COUNT(*), LENGTH(last_name) len_name </span><br><span class="line">FROM employees </span><br><span class="line">GROUP BY LENGTH(last_name) </span><br><span class="line">HAVING COUNT(*) &gt; 5;</span><br></pre></td></tr></table></figure>
<p><strong>按多个字段分组</strong></p>
<p>案例：查询每个部门每个工种的员工的平均工资</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT AVG(salary), department_id, job_id </span><br><span class="line">FROM employees </span><br><span class="line">GROUP BY department_id, job_id;</span><br></pre></td></tr></table></figure>
<p><strong>添加排序</strong></p>
<p>案例：查询部门编号不为NULL的每个工种的员工的平均工资，并按工资高低显示</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT AVG(salary), department_id, job_id </span><br><span class="line">FROM employees </span><br><span class="line">WHERE department_id IS NOT NULL </span><br><span class="line">GROUP BY department_id, job_id </span><br><span class="line">ORDER BY AVG(salary) DESC;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>MySQL入门（五）函数</title>
    <url>/posts/a5e4959e.html</url>
    <content><![CDATA[<p>本文数据集下载链接：<a href="https://pan.baidu.com/s/1sVcSXfVZimc6ruyMr4Gr3g" target="_blank" rel="noopener">https://pan.baidu.com/s/1sVcSXfVZimc6ruyMr4Gr3g</a> ，提取码：7gfa </p>
<h1 id="一、常见函数"><a href="#一、常见函数" class="headerlink" title="一、常见函数"></a>一、常见函数</h1><p><strong>调用方法</strong>：<code>SELECT 函数名(实参列表) [FROM 表]</code></p>
<p><strong>优点</strong>：隐藏实现细节；提高代码的重用性</p>
<p><strong>分类</strong>：</p>
<ol>
<li>单行函数，如<code>concat</code>、<code>length</code>、<code>ifnull</code></li>
<li>分组函数，传递一组值进去，传出一个值（又称统计函数）</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT DATABASE();		# 查看当前DATABASE</span><br><span class="line">SELECT USER();</span><br><span class="line">SELECT VERSION();</span><br></pre></td></tr></table></figure>
<h1 id="二、单行函数"><a href="#二、单行函数" class="headerlink" title="二、单行函数"></a>二、单行函数</h1><h2 id="1-字符函数"><a href="#1-字符函数" class="headerlink" title="1. 字符函数"></a>1. 字符函数</h2><p><strong>函数1：<code>LENGTH</code></strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT LENGTH(&quot;MySQL&quot;);</span><br><span class="line">SELECT LENGTH(&quot;MySQL真简单&quot;);</span><br></pre></td></tr></table></figure>
<p>第一个显示为5，第二个显示为14（一个汉字占3个字节），由此我们知道<code>LENGTH</code>函数是用于获取参数值的字节个数的</p>
<p><strong>函数2：<code>CONCAT</code>拼接函数</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT CONCAT(last_name, &#39;_&#39;, first_name) 姓名 FROM employees;</span><br></pre></td></tr></table></figure>
<p><strong>函数3：<code>UPPER、LOWER</code></strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT UPPER(&#39;MySQL&#39;);</span><br><span class="line">SELECT LOWER(&#39;MySQL&#39;);</span><br></pre></td></tr></table></figure>
<p><strong>套娃1：将姓大写，名小写然后拼接</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT CONCAT(UPPER(last_name),LOWER(first_name)) FROM employees;</span><br></pre></td></tr></table></figure>
<p>由此可见函数可以嵌套调用</p>
<p><strong>函数4：<code>SUBSTR\SUBSTRING</code></strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT SUBSTR(&#39;我喜欢MySQL&#39;, 4) output;</span><br></pre></td></tr></table></figure>
<p>该函数返回<code>MySQL</code>，由此我们可见该函数的作用是返回索引及其之后的内容，同时我们可以发现MySQL中的<strong>索引是从0开始</strong>的</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT SUBSTR(&#39;我喜欢你&#39;, 2, 4) output;</span><br></pre></td></tr></table></figure>
<p>该函数返回<code>喜欢你</code>，这里是截取从指定索引处指定字符长度的字符</p>
<p><strong>套娃2：姓名中首字符大写，其他字符小写，并用_拼接显示出来</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT CONCAT(UPPER(SUBSTR(last_name, 1, 1)),&#39;_&#39;,LOWER(SUBSTR(last_name, 2))) output FROM employees;</span><br></pre></td></tr></table></figure>
<p><strong>函数5：<code>instr</code>返回起始索引</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT INSTR(&#39;我喜欢MySQL&#39;, &#39;MySQL&#39;) AS output;</span><br></pre></td></tr></table></figure>
<p>返回结果为4</p>
<p>注意：如果找不到对应索引，返回0</p>
<p><strong>函数6：<code>trim</code>去首尾空格</strong></p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">SELECT TRIM(<span class="string">'    MySQL   '</span>) AS output;</span><br></pre></td></tr></table></figure>
<p>实际上也可以去除前后某个指定的元素，比如我们要去除下例中首尾的<code>a</code>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT TRIM(&#39;a&#39; FROM &#39;aaaaaaaMySQLaaaa&#39;) AS output;</span><br></pre></td></tr></table></figure>
<p><strong>函数7：<code>lpad</code>用指定字符实现左填充指定长度</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT LPAD(&#39;MySQL&#39;, 10, &#39;*&#39;) AS output;</span><br></pre></td></tr></table></figure>
<p>返回结果为<code>*****MySQL</code>，若我们将长度指定为小于字段长的数字，例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT LPAD(&#39;MySQL&#39;, 3, &#39;*&#39;) AS output;</span><br></pre></td></tr></table></figure>
<p>返回值为<code>MyS</code></p>
<p><strong>函数8：<code>rpad</code>用指定字符右填充指定长度</strong></p>
<p>用法与左填充一样</p>
<p><strong>函数9：<code>replace</code>替换</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT REPLACE(&#39;我爱MySQL&#39;, &#39;爱&#39;, &#39;讨厌&#39;) AS output;</span><br></pre></td></tr></table></figure>
<p>结果很容易猜到，嘿嘿这里就不说啦。而且注意哦，这里的替换是全部替换，可以自己验证一下</p>
<h2 id="2-数学函数"><a href="#2-数学函数" class="headerlink" title="2. 数学函数"></a>2. 数学函数</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;*</span><br><span class="line">round: 四舍五入</span><br><span class="line">*&#x2F;</span><br><span class="line">SELECT ROUND(-1.55);		# 输出结果为-2</span><br><span class="line">SELECT ROUND(1.467,2);		# 输出结果为1.47</span><br><span class="line"></span><br><span class="line">&#x2F;*</span><br><span class="line">ceil: 向上取整(返回大于等于该数的最小整数)</span><br><span class="line">floor: 向下取整(返回小于等于该数的最大整数)</span><br><span class="line">*&#x2F;</span><br><span class="line">SELECT CEIL(1.01);			# 输出结果为2</span><br><span class="line">SELECT FLOOR(-9.99);		# 输出结果为-10</span><br><span class="line"></span><br><span class="line">&#x2F;*</span><br><span class="line">truncate: 截断</span><br><span class="line">*&#x2F;</span><br><span class="line">SELECT TRUNCATE(1.65, 1);	# 输出结果为1.6</span><br><span class="line"></span><br><span class="line">&#x2F;*</span><br><span class="line">mod: 取余</span><br><span class="line">*&#x2F;</span><br><span class="line">SELECT MOD(10, 3);			# 输出结果为1</span><br><span class="line"># 被除数如果是正则为正，如果是负则为负，因为运算方式为：MOD(a,b)&#x3D;a-a&#x2F;b*b</span><br></pre></td></tr></table></figure>
<h2 id="3-日期函数"><a href="#3-日期函数" class="headerlink" title="3. 日期函数"></a>3. 日期函数</h2><h3 id="3-1-获取日期的函数"><a href="#3-1-获取日期的函数" class="headerlink" title="3.1 获取日期的函数"></a>3.1 获取日期的函数</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># now: 返回当前系统日期+时间</span><br><span class="line">SELECT NOW();</span><br><span class="line"></span><br><span class="line"># curdate: 返回当前系统日期，不包含时间</span><br><span class="line">SELECT CURDATE();</span><br><span class="line"></span><br><span class="line"># curtime: 返回当前系统时间，不包含日期</span><br><span class="line">SELECT CURTIME();</span><br><span class="line"></span><br><span class="line"># 也可以自己定其他截取的时间特征:</span><br><span class="line">SELECT YEAR(NOW()); 		# 返回今年</span><br><span class="line"># 若希望返回英文：</span><br><span class="line">SELECT MONTHNAME(NOW());</span><br></pre></td></tr></table></figure>
<h3 id="3-2-转换日期的函数"><a href="#3-2-转换日期的函数" class="headerlink" title="3.2 转换日期的函数"></a>3.2 转换日期的函数</h3><p><strong><code>STR_TO_DATE</code></strong></p>
<p>该函数的作用是按日期格式的字符转换成指定格式的日期，示例如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT STR_TO_DATE(&#39;1999&#x2F;2&#x2F;18&#39;,&#39;%Y&#x2F;%m&#x2F;%d&#39;);</span><br></pre></td></tr></table></figure>
<p>返回<code>1999-02-18</code>，小伙伴可以自己尝试大小写的区别，并自行查阅其他格式符的含义和功能</p>
<p><strong><code>DATE_FORMAT</code></strong></p>
<p>该函数的作用是将日期转换成字符，恰好与<code>STR_TO_DATE</code>反过来，示例如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT DATE_FORMAT(NOW(),&#39;%Y年%m月%d日&#39;);</span><br></pre></td></tr></table></figure>
<p><strong>案例1：查询入职日期是1992年4月3号的员工信息</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * </span><br><span class="line">FROM employees </span><br><span class="line">WHERE hiredate &#x3D; STR_TO_DATE(&#39;1992年4月3日&#39;,&#39;%Y年%m月%d日&#39;);</span><br></pre></td></tr></table></figure>
<p><strong>案例2：查询有奖金的员工名及入职日期，要求格式为：xx月/xx日/xx年</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name, DATE_FORMAT(hiredate,&#39;%m月&#x2F;%d日 %y年&#39;) 入职日期 </span><br><span class="line">FROM employees </span><br><span class="line">WHERE commission_pct IS NOT NULL;</span><br></pre></td></tr></table></figure>
<h1 id="三、流程控制函数"><a href="#三、流程控制函数" class="headerlink" title="三、流程控制函数"></a>三、流程控制函数</h1><h2 id="1-IF函数"><a href="#1-IF函数" class="headerlink" title="1. IF函数"></a>1. <code>IF</code>函数</h2><p><code>IF</code>函数有三个参数，第一个表达式的结果若为 true，则返回表达式二的值，否则返回表达式三的值，如下将返回21</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT IF(10&gt;5, 21, 10);</span><br></pre></td></tr></table></figure>
<p><strong>示例：若员工有奖金则提示有，否则提示没有</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name, commission_pct, IF(commission_pct IS NULL, &#39;没奖金&#39;, &#39;有奖金&#39;) FROM employees;</span><br></pre></td></tr></table></figure>
<h2 id="2-case函数"><a href="#2-case函数" class="headerlink" title="2. case函数"></a>2. <code>case</code>函数</h2><p><strong>使用语法一</strong>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CASE 要判断的字段或表达式</span><br><span class="line">WHEN 常量1  THEN  要显示的值1或语句1</span><br><span class="line">WHEN 常量2  THEN  要显示的值2或语句2</span><br><span class="line">...</span><br><span class="line">ELSE 要显示的值n或语句n</span><br><span class="line">END</span><br></pre></td></tr></table></figure>
<p><strong>案例1：查询员工的工资，要求部门编号=30，则显示工资为1.1倍，部门编号=20，则显示工资为1.2倍，部门编号=30，则显示工资为1.3倍，其他部门显示的工资为原工资</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT salary 原始工资, department_id, </span><br><span class="line">CASE department_id </span><br><span class="line">WHEN 30 THEN salary*1.1</span><br><span class="line">WHEN 40 THEN salary*1.2</span><br><span class="line">WHEN 50 THEN salary*1.3</span><br><span class="line">ELSE salary;</span><br><span class="line">END AS 新工资</span><br><span class="line">FROM employees;</span><br></pre></td></tr></table></figure>
<p><strong>使用语法二：类似于多重<code>if</code></strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CASE</span><br><span class="line">WHEN 条件1 THEN 要显示的值1或语句1</span><br><span class="line">WHEN 条件2 THEN 要显示的值2或语句2</span><br><span class="line">...</span><br><span class="line">THEN 要显示的值n或语句n</span><br><span class="line">END</span><br></pre></td></tr></table></figure>
<p><strong>案例2:查询员工的工资情况：如果工资&gt;20000，显示级别A，若工资&gt;15000，显示级别B，若工资&gt;10000，显示级别C，否则显示级别D </strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT salary,</span><br><span class="line">CASE</span><br><span class="line">WHEN salary&gt;20000 THEN &#39;A&#39;</span><br><span class="line">WHEN salary&gt;15000 THEN &#39;B&#39;</span><br><span class="line">WHEN salary&gt;10000 THEN &#39;C&#39;</span><br><span class="line">ELSE &#39;D&#39;</span><br><span class="line">END AS &#39;工资级别&#39;</span><br><span class="line">FROM employees;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>MySQL入门（四）排序查询</title>
    <url>/posts/6b667049.html</url>
    <content><![CDATA[<p>本文数据集下载链接：<a href="https://pan.baidu.com/s/1sVcSXfVZimc6ruyMr4Gr3g" target="_blank" rel="noopener">https://pan.baidu.com/s/1sVcSXfVZimc6ruyMr4Gr3g</a> ，提取码：7gfa </p>
<h1 id="一、排序查询"><a href="#一、排序查询" class="headerlink" title="一、排序查询"></a>一、排序查询</h1><p>我们知道从 MySQL 表中使用 SQL SELECT 语句来读取数据，如果我们需要对读取的数据进行排序，我们就可以使用 MySQL 的 <strong>ORDER BY</strong> 子句来设定你想按哪个字段哪种方式来进行排序，再返回搜索结果。</p>
<h2 id="1-语法"><a href="#1-语法" class="headerlink" title="1. 语法"></a>1. 语法</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT 查询列表</span><br><span class="line">FROM 表</span><br><span class="line">[WHERE 筛选条件]</span><br><span class="line">ORDER BY 排序列表 【ASC】</span><br></pre></td></tr></table></figure>
<p>一般ORDER BY语句放在查询语句的最后【<code>LIMIT</code>子句除外】</p>
<ul>
<li>你可以使用任何字段来作为排序的条件，从而返回排序后的查询结果。</li>
<li>你可以设定多个字段来排序。</li>
<li>你可以使用 <code>ASC</code> 或 <code>DESC</code> 关键字来设置查询结果是按升序或降序排列。 默认情况下，它是按升序排列。</li>
<li>你可以添加 <code>WHERE...LIKE</code> 子句来设置条件。</li>
</ul>
<h2 id="2-案例"><a href="#2-案例" class="headerlink" title="2. 案例"></a>2. 案例</h2><p><strong>案例1</strong>：<strong>查询员工信息，要求工资从高到低排序</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * </span><br><span class="line">FROM employees </span><br><span class="line">ORDER BY salary DESC;</span><br></pre></td></tr></table></figure>
<p><strong>查询员工信息，要求工资从低到高排序</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * </span><br><span class="line">FROM employees </span><br><span class="line">ORDER BY salary ASC;</span><br></pre></td></tr></table></figure>
<p><strong>案例2：查询部门编号&gt;=90的员工信息，按入职时间的先后进行排序</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * </span><br><span class="line">FROM employees </span><br><span class="line">WHERE department_id &gt;&#x3D; 90 </span><br><span class="line">ORDER BY hiredate ASC;</span><br></pre></td></tr></table></figure>
<p><strong>案例3：按年薪高低显示员工的信息和年薪【按表达式排序】</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT *, salary*12*(1+IFNULL(commission_pct,0)) 年薪 </span><br><span class="line">FROM employees </span><br><span class="line">ORDER BY 年薪</span><br></pre></td></tr></table></figure>
<p><strong>案例4：按姓名长度显示员工的姓名和工资【按函数排序】</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT LENGTH(last_name) 字节长度,last_name,salary </span><br><span class="line">FROM employees </span><br><span class="line">ORDER BY 字节长度 DESC;</span><br></pre></td></tr></table></figure>
<p><strong>案例5：查询员工信息，要求先按工资排序，再按员工编号排序【按多个字段排序】</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * </span><br><span class="line">FROM employees </span><br><span class="line">ORDER BY salary ASC, employee_id DESC;</span><br></pre></td></tr></table></figure>
<h1 id="二、MySQL拼音排序"><a href="#二、MySQL拼音排序" class="headerlink" title="二、MySQL拼音排序"></a>二、MySQL拼音排序</h1><p>如果字符集采用的是 gbk(汉字编码字符集)，直接在查询语句后边添加 <code>ORDER BY</code>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * </span><br><span class="line">FROM runoob_tbl</span><br><span class="line">ORDER BY runoob_title;</span><br></pre></td></tr></table></figure>
<p>如果字符集采用的是 utf8(万国码)，需要先对字段进行转码然后排序：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * </span><br><span class="line">FROM runoob_tbl</span><br><span class="line">ORDER BY CONVERT(runoob_title using gbk);</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>MySQL入门（三）条件查询</title>
    <url>/posts/ca70db86.html</url>
    <content><![CDATA[<p>本文数据集下载链接：<a href="https://pan.baidu.com/s/1sVcSXfVZimc6ruyMr4Gr3g" target="_blank" rel="noopener">https://pan.baidu.com/s/1sVcSXfVZimc6ruyMr4Gr3g</a> ，提取码：7gfa </p>
<h1 id="一、条件查询基础"><a href="#一、条件查询基础" class="headerlink" title="一、条件查询基础"></a>一、条件查询基础</h1><p>我们知道从 MySQL 表中使用 SQL<code>SELECT</code> 语句来读取数据，如需有条件地从表中选取数据，可将 <code>WHERE</code> 子句添加到 <code>SELECT</code>语句中。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">操作符</th>
<th style="text-align:left">描述</th>
<th style="text-align:left">实例</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">=</td>
<td style="text-align:left">等号，检测两个值是否相等，如果相等返回true</td>
<td style="text-align:left">(A = B) 返回false。</td>
</tr>
<tr>
<td style="text-align:left">&lt;&gt;, !=</td>
<td style="text-align:left">不等于，检测两个值是否相等，如果不相等返回true</td>
<td style="text-align:left">(A != B) 返回 true。</td>
</tr>
<tr>
<td style="text-align:left">&gt;</td>
<td style="text-align:left">大于号，检测左边的值是否大于右边的值, 如果左边的值大于右边的值返回true</td>
<td style="text-align:left">(A &gt; B) 返回false。</td>
</tr>
<tr>
<td style="text-align:left">&lt;</td>
<td style="text-align:left">小于号，检测左边的值是否小于右边的值, 如果左边的值小于右边的值返回true</td>
<td style="text-align:left">(A &lt; B) 返回 true。</td>
</tr>
<tr>
<td style="text-align:left">&gt;=</td>
<td style="text-align:left">大于等于号，检测左边的值是否大于或等于右边的值, 如果左边的值大于或等于右边的值返回true</td>
<td style="text-align:left">(A &gt;= B) 返回false。</td>
</tr>
<tr>
<td style="text-align:left">&lt;=</td>
<td style="text-align:left">小于等于号，检测左边的值是否小于或等于右边的值, 如果左边的值小于或等于右边的值返回true</td>
<td style="text-align:left">(A &lt;= B) 返回 true。</td>
</tr>
</tbody>
</table>
</div>
<p><strong>语法</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT </span><br><span class="line">				查询列表 </span><br><span class="line">	FROM </span><br><span class="line">				表名 </span><br><span class="line">	WHERE </span><br><span class="line">				筛选条件</span><br></pre></td></tr></table></figure>
<p><strong>分类</strong></p>
<ol>
<li>按条件表达式筛选：&gt; &lt; = != &lt;&gt; &gt;+ &lt;=</li>
<li>按逻辑表达式筛选：&amp;&amp;  ||  !（and or not）</li>
<li>模糊查询：LIKE,  BETWEEN AND, IN, IS NULL</li>
</ol>
<h1 id="二、三种查询方式介绍"><a href="#二、三种查询方式介绍" class="headerlink" title="二、三种查询方式介绍"></a>二、三种查询方式介绍</h1><h2 id="1-按条件表达式筛选"><a href="#1-按条件表达式筛选" class="headerlink" title="1. 按条件表达式筛选"></a>1. 按条件表达式筛选</h2><p><strong>案例一：查询工资&gt;12000的员工信息</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * </span><br><span class="line">FROM employees </span><br><span class="line">WHERE salary&gt;12000;</span><br></pre></td></tr></table></figure>
<p><strong>案例二：查询部门编号不等于90号的员工名和部门编号</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name, department_id </span><br><span class="line">FROM employees </span><br><span class="line">WHERE department_id&lt;&gt;90;</span><br></pre></td></tr></table></figure>
<h2 id="2-按逻辑表达式筛选"><a href="#2-按逻辑表达式筛选" class="headerlink" title="2. 按逻辑表达式筛选"></a>2. 按逻辑表达式筛选</h2><p><strong>案例一：查询工资在10000到20000之间的员工名、工资及奖金</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name, salary, commission_pct </span><br><span class="line">FROM employees </span><br><span class="line">WHERE salary&gt;&#x3D;10000 AND salary&lt;&#x3D;20000;</span><br></pre></td></tr></table></figure>
<p><strong>案例二：查询部门编号不是在90到110之间的，或者工资高于15000的员工信息</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * </span><br><span class="line">FROM employees </span><br><span class="line">WHERE department_id&lt;90 </span><br><span class="line">OR department_id&gt;110 </span><br><span class="line">OR salary&gt;15000;</span><br></pre></td></tr></table></figure>
<p>更为简洁的写法是（使用逻辑表达式）：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * </span><br><span class="line">FROM employees </span><br><span class="line">WHERE NOT(department_id&gt;&#x3D;90 AND department_id&lt;&#x3D;110) OR salary&gt;15000;</span><br></pre></td></tr></table></figure>
<h2 id="3-模糊查询"><a href="#3-模糊查询" class="headerlink" title="3. 模糊查询"></a>3. 模糊查询</h2><h3 id="3-1-LIKE"><a href="#3-1-LIKE" class="headerlink" title="3.1 LIKE"></a>3.1 LIKE</h3><ul>
<li>一般和通配符搭配使用</li>
<li>通配符：<ul>
<li>$\%$ 百分号：任意多个字符，包含0个字符</li>
<li>$_$ 下划线：任意单个字符</li>
</ul>
</li>
</ul>
<p><strong>案例一：查询员工名中包含字符a的员工信息</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * </span><br><span class="line">FROM employees </span><br><span class="line">WHERE last_name LIKE &#39;%a%&#39;;</span><br></pre></td></tr></table></figure>
<p><strong>案例二：查询员工名中第三个字符为n，第五个字符为l的员工名和工资</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name, salary </span><br><span class="line">FROM employees </span><br><span class="line">WHERE last_name LIKE &#39;__n_l%&#39;;</span><br></pre></td></tr></table></figure>
<p><strong>案例三：查询员工名中第二个字符为下划线（_）的员工名，第二种方法为手动指定转义字符</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name </span><br><span class="line">FROM employees </span><br><span class="line">WHERE last_name </span><br><span class="line">LIKE &#39;_\_%&#39;;</span><br></pre></td></tr></table></figure>
<p>第二种方法代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name </span><br><span class="line">FROM employees </span><br><span class="line">WHERE last_name LIKE &#39;_$_%&#39; ESCAPE &#39;$&#39;;</span><br></pre></td></tr></table></figure>
<h3 id="3-2-BETWEEN-AND"><a href="#3-2-BETWEEN-AND" class="headerlink" title="3.2 BETWEEN AND"></a>3.2 BETWEEN AND</h3><ol>
<li><p>使用BETWEEN AND可以提高语句的简洁度</p>
<ol>
<li>包含临界值</li>
<li>两个值不能颠倒顺序</li>
</ol>
</li>
</ol>
<p><strong>案例：查询员工编号在100到120之间的员工信息，第一种做法较繁琐，第二种用BETWEEN AND</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * </span><br><span class="line">FROM employees </span><br><span class="line">WHERE employee_id&gt;&#x3D;100 </span><br><span class="line">AND employee_id&lt;&#x3D;120;</span><br></pre></td></tr></table></figure>
<p>或者更简洁的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * </span><br><span class="line">FROM employees </span><br><span class="line">WHERE employee_id BETWEEN 100 AND 120;</span><br></pre></td></tr></table></figure>
<h3 id="3-3-IN"><a href="#3-3-IN" class="headerlink" title="3.3 IN"></a>3.3 IN</h3><ol>
<li>使用IN提高语句简洁度</li>
<li>IN列表的值类型必须一致或兼容</li>
<li>不支持下划线或通配符</li>
</ol>
<p><strong>案例：查询员工的工种编号是 IT_PROG、AD_VP、AD_PRES中的一个员工名和工种编号</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name, job_id </span><br><span class="line">FROM employees </span><br><span class="line">WHERE job_id&#x3D;&#39;IT_PROG&#39; </span><br><span class="line">OR job_id&#x3D;&#39;AD_VP&#39; OR job_id&#x3D;&#39;AD_PRES&#39;;</span><br></pre></td></tr></table></figure>
<p>或者更简洁的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name, job_id </span><br><span class="line">FROM employees </span><br><span class="line">WHERE job_id IN (&#39;IT_PROG&#39;, &#39;AD_VP&#39;, &#39;AD_PRES&#39;);</span><br></pre></td></tr></table></figure>
<h3 id="3-4-IS-NULL"><a href="#3-4-IS-NULL" class="headerlink" title="3.4 IS NULL"></a>3.4 IS NULL</h3><ul>
<li>=或&lt;&gt;不能用于判断null值</li>
<li>is null或is not null可以判断null值</li>
</ul>
<p><strong>案例：查询没有奖金的员工名和奖金率</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name, commission_pct </span><br><span class="line">FROM employees </span><br><span class="line">WHERE commission_pct IS NULL;</span><br></pre></td></tr></table></figure>
<p><strong>变式：查询有奖金的员工名和奖金率</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name, commission_pct </span><br><span class="line">FROM employees </span><br><span class="line">WHERE commission_pct IS NOT NULL;</span><br></pre></td></tr></table></figure>
<p><strong>注意：以下为错误：</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * FROM employees</span><br><span class="line">WHERE salary IS 12000;</span><br></pre></td></tr></table></figure>
<h2 id="4-安全等与-lt-gt"><a href="#4-安全等与-lt-gt" class="headerlink" title="4. 安全等与 &lt;=&gt;"></a>4. 安全等与 &lt;=&gt;</h2><ol>
<li>优点：既可以判断NULL值又可以判断普通数值</li>
<li>缺点：可读性较低</li>
</ol>
<p><strong>案例1：查询没有奖金的员工名和奖金率</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name, commission_pct </span><br><span class="line">FROM employees </span><br><span class="line">WHERE commission_pct &lt;&#x3D;&gt; NULL;</span><br></pre></td></tr></table></figure>
<p><strong>案例2：查询工资为12000的员工信息</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name, commission_pct </span><br><span class="line">FROM employees </span><br><span class="line">WHERE salary &lt;&#x3D;&gt; 12000;</span><br></pre></td></tr></table></figure>
<h1 id="三、易混辨析"><a href="#三、易混辨析" class="headerlink" title="三、易混辨析"></a>三、易混辨析</h1><p><strong>where：</strong>数据库中常用的是where关键字，用于在初始表中筛选查询。它是一个约束声明，用于约束数据，在返回结果集之前起作用。</p>
<p><strong>group by:</strong>对select查询出来的结果集按照某个字段或者表达式进行分组，获得一组组的集合，然后从每组中取出一个指定字段或者表达式的值。</p>
<p><strong>having：</strong>用于对where和group by查询出来的分组经行过滤，查出满足条件的分组结果。它是一个过滤声明，是在查询返回结果集以后对查询结果进行的过滤操作。</p>
<p><strong>执行顺序</strong></p>
<p><code>select –&gt;where –&gt; group by–&gt; having–&gt;order by</code></p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>MySQL入门（二）基础查询</title>
    <url>/posts/8bec0637.html</url>
    <content><![CDATA[<p>本文数据集下载链接：<a href="https://pan.baidu.com/s/1sVcSXfVZimc6ruyMr4Gr3g" target="_blank" rel="noopener">https://pan.baidu.com/s/1sVcSXfVZimc6ruyMr4Gr3g</a> ，提取码：7gfa </p>
<p><strong>DQL指的是Data Query Language，即数据查询语言，是MySQL语言中的一个子集</strong></p>
<h1 id="基础查询"><a href="#基础查询" class="headerlink" title="基础查询"></a>基础查询</h1><p>MySQL 数据库使用SQL SELECT语句来查询数据。你可以通过 mysql&gt; 命令提示窗口中在数据库中查询数据，或者通过PHP脚本来查询数据。</p>
<ul>
<li>查询语句中你可以使用一个或者多个表，表之间使用逗号(,)分割，并使用WHERE语句来设定查询条件。</li>
<li>SELECT 命令可以读取一条或者多条记录。</li>
<li>你可以使用星号（*）来代替其他字段，SELECT语句会返回表的所有字段数据</li>
<li>你可以使用 WHERE 语句来包含任何条件。</li>
<li>你可以使用 LIMIT 属性来设定返回的记录数。</li>
<li>你可以通过OFFSET指定SELECT语句开始查询的数据偏移量。默认情况下偏移量为0。</li>
</ul>
<h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><ol>
<li><code>select</code> 查询列表 <code>from</code> 表名;</li>
<li>可以使用 <code>字段</code>区分关键字</li>
</ol>
<h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><pre><code> 1. 查询列表可以是：表中的字段、常量、表达式、函数
 2. 查询的结果是一个虚拟的表格
</code></pre><h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><p><strong>查询表中的单个字段</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name FROM employees;</span><br></pre></td></tr></table></figure>
<p><strong>查询表中的多个字段</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name, salary, email FROM employees;</span><br></pre></td></tr></table></figure>
<p><strong>查询表中的所有字段（可以通过全选复制字段名快速复制）</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT employee_id,	first_name,	last_name	email,	phone_number,	job_id,	salary,	commission_pct,	manager_id,	department_id,	hiredate FROM employees;</span><br></pre></td></tr></table></figure>
<p><strong>等同于下面语句（但*使得顺序与原来一样）</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * FROM employees;</span><br></pre></td></tr></table></figure>
<p><strong>查询常量值</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT 100；</span><br><span class="line">SELECT &#39;john&#39;;</span><br></pre></td></tr></table></figure>
<p><strong>查询表达式</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT 100%98;</span><br></pre></td></tr></table></figure>
<p><strong>查询函数</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT VERSION();</span><br></pre></td></tr></table></figure>
<h1 id="为字段取别名"><a href="#为字段取别名" class="headerlink" title="为字段取别名"></a>为字段取别名</h1><pre><code> 1. 便于理解
 2. 如果要查询的字段有重名的情况，使用别名可以区分开
</code></pre><p><strong>方式一：使用As</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT 100%98 AS 结果;</span><br><span class="line"></span><br><span class="line">SELECT last_name AS 姓, first_name As 名 </span><br><span class="line">FROM employees;</span><br></pre></td></tr></table></figure>
<p><strong>方式二：使用空格</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT last_name 姓, first_name 名 </span><br><span class="line">FROM employees;</span><br></pre></td></tr></table></figure>
<p><strong>案例：查询salary，显示结果为out put</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT salary AS &#39;out put&#39; </span><br><span class="line">FROM employees;</span><br></pre></td></tr></table></figure>
<h1 id="去重"><a href="#去重" class="headerlink" title="去重"></a>去重</h1><p>去重的关键字是<code>DISTINCT</code>，注意：不可以同时对多个字段去重</p>
<p><strong>案例：查询员工表中涉及到的所有的部门编号(DISTINCT关键字)</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT DISTINCT department_id </span><br><span class="line">FROM employees;</span><br></pre></td></tr></table></figure>
<h1 id="加号和CONCAT的作用"><a href="#加号和CONCAT的作用" class="headerlink" title="加号和CONCAT的作用"></a>加号和CONCAT的作用</h1><p>JAVA中的加号有两个功能：</p>
<pre><code>1. 运算符，两个操作数都是数值型
2. 连接符，只要有一个操作数为字符串
</code></pre><p>MySQL中的加号只有一个功能：运算符</p>
<pre><code>1. 若两个操作数都为数值型，则做加法运算： select 100 + 90;
2. 若其中一方为字符型，试图将字符型数值转换成数值型：select &#39;123&#39;+90;
3. 若转换失败，则将字符型数值转换成0：select &#39;john&#39;+90;
4. 只要有其中一方为null，则结果必为null
</code></pre><p><strong>案例：查询员工名和姓连接成一个字段，并显示为姓名</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT CONCAT(last_name,&#39; &#39;,first_name) AS 姓名 </span><br><span class="line">FROM employees;</span><br></pre></td></tr></table></figure>
<p><strong>案例：显示出表employees的全部列，各个列之间用逗号连接，列头显示成OUT_PUT</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT </span><br><span class="line">		CONCAT(employee_id, &#39;,&#39;,	first_name, &#39;,&#39;,	last_name, &#39;,&#39;,	email, &#39;,&#39;,	phone_number, &#39;,&#39;,	job_id, &#39;,&#39;,	salary, &#39;,&#39;,	IFNULL(commission_pct,0), &#39;,&#39;,	manager_id, &#39;,&#39;,	department_id, &#39;,&#39;,	hiredate)</span><br><span class="line">AS </span><br><span class="line">		out_put </span><br><span class="line">FROM </span><br><span class="line">		employees;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>MySQL入门（一）数据库基础概念</title>
    <url>/posts/e89e7d68.html</url>
    <content><![CDATA[<h1 id="一、数据库基本概念"><a href="#一、数据库基本概念" class="headerlink" title="一、数据库基本概念"></a>一、数据库基本概念</h1><p>数据库（Database）是按照数据结构来组织、存储和管理数据的仓库。每个数据库都有一个或多个不同的 API 用于创建，访问，管理，搜索和复制所保存的数据。我们也可以将数据存储在文件中，但是在文件中读写数据速度相对较慢。</p>
<p>所以，现在我们使用关系型数据库管理系统（RDBMS）来存储和管理大数据量。所谓的关系型数据库，是建立在关系模型基础上的数据库，借助于集合代数等数学概念和方法来处理数据库中的数据。<strong>数据库的好处</strong>是可以持久化数据到本地，同时可以实现结构化查询，方便管理<strong>数据库相关概念</strong>如下：</p>
<ol>
<li>DB：数据库，保存一组有组织的数据的容器</li>
<li>DBMS：数据库管理系统，又称为数据库软件（产品），用于管理数据库中的数据</li>
<li>SQL：结构化查询语言，用于和DBMS通信的语言</li>
</ol>
<h2 id="1-RDBMS-术语"><a href="#1-RDBMS-术语" class="headerlink" title="1. RDBMS 术语"></a>1. RDBMS 术语</h2><p>在我们开始学习MySQL 数据库前，让我们先了解下RDBMS的一些术语：</p>
<ul>
<li><strong>数据库:</strong> 数据库是一些关联表的集合。</li>
<li><strong>数据表:</strong> 表是数据的矩阵。在一个数据库中的表看起来像一个简单的电子表格。</li>
<li><strong>列:</strong> 一列(数据元素) 包含了相同类型的数据, 例如邮政编码的数据。</li>
<li><strong>行：</strong>一行（=元组，或记录）是一组相关的数据，例如一条用户订阅的数据。</li>
<li><strong>冗余</strong>：存储两倍数据，冗余降低了性能，但提高了数据的安全性。</li>
<li><strong>主键</strong>：主键是唯一的。一个数据表中只能包含一个主键。你可以使用主键来查询数据。</li>
<li><strong>外键：</strong>外键用于关联两个表。</li>
<li><strong>复合键</strong>：复合键（组合键）将多个列作为一个索引键，一般用于复合索引。</li>
<li><strong>索引：</strong>使用索引可快速访问数据库表中的特定信息。索引是对数据库表中一列或多列的值进行排序的一种结构。类似于书籍的目录。</li>
<li><strong>参照完整性:</strong> 参照的完整性要求关系中不允许引用不存在的实体。与实体完整性是关系模型必须满足的完整性约束条件，目的是保证数据的一致性。</li>
</ul>
<h2 id="2-MySQL数据库基本概况"><a href="#2-MySQL数据库基本概况" class="headerlink" title="2. MySQL数据库基本概况"></a>2. MySQL数据库基本概况</h2><p>MySQL 是一个关系型数据库管理系统，由瑞典 MySQL AB 公司开发，目前属于 Oracle 公司。MySQL 是一种关联数据库管理系统，关联数据库将数据保存在不同的表中，而不是将所有数据放在一个大仓库内，这样就增加了速度并提高了灵活性。</p>
<ul>
<li>MySQL 是开源的，目前隶属于 Oracle 旗下产品。</li>
<li>MySQL 支持大型的数据库。可以处理拥有上千万条记录的大型数据库。</li>
<li>MySQL 使用标准的 SQL 数据语言形式。</li>
<li>MySQL 可以运行于多个系统上，并且支持多种语言。这些编程语言包括 C、C++、Python、Java、Perl、PHP、Eiffel、Ruby 和 Tcl 等。</li>
<li>MySQL 对PHP有很好的支持，PHP 是目前最流行的 Web 开发语言。</li>
<li>MySQL 支持大型数据库，支持 5000 万条记录的数据仓库，32 位系统表文件最大可支持 4GB，64 位系统支持最大的表文件为8TB。</li>
<li>MySQL 是可以定制的，采用了 GPL 协议，你可以修改源码来开发自己的 MySQL 系统。</li>
</ul>
<h2 id="4-数据库存储数据的特点"><a href="#4-数据库存储数据的特点" class="headerlink" title="4. 数据库存储数据的特点"></a>4. 数据库存储数据的特点</h2><ol>
<li>将数据放到表中，表再放到库中</li>
<li>一个数据库中可以有多个表，每个表都有一个名字用来标识自己，表名具有唯一性</li>
<li>表具有一些特性，这些特性定义了数据在表中如何存储，类似java中的“类”的设计</li>
<li>表由列组成，我们也称之为字段。所有表都是由一个或多个列组成的，每一列类似java中的”属性“</li>
<li>表中的数据是按行存储的，每一行类似java中的“对象”</li>
</ol>
<h1 id="二、MySQL基本操作"><a href="#二、MySQL基本操作" class="headerlink" title="二、MySQL基本操作"></a>二、MySQL基本操作</h1><p><strong>MySQL服务的启动和终止</strong></p>
<p>假设已经 安装好了MySQL，我们可以通过Windows中的服务手动 启动或关闭MySQL服务，也可以通过管理员模式打开命令行，使用<code>net stop mysql</code>与<code>net start mysql</code>分别关闭和启动MySQL，</p>
<p><strong>MySQL服务端的登陆和退出</strong></p>
<p>MySQL服务端可以直接通过MySQL Shell进入，但这种方式<strong>只能容许root用户进入</strong>，我们推荐使用命令行进入，在命令行下输入：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql -h localhost -P 3307 -u root -p</span><br></pre></td></tr></table></figure>
<p>其中3307为本机设定的端口号，每个人可能不一样，-p之后将会要去输入密码，此时输入之前预设的密码即可，也可以直接在后面接，但注意-p若后面直接接密码，<strong>不加空格</strong>。若是直接本机进入，可以省略<code>-h localhost -P 3307</code>。</p>
<p>退出时直接使用<code>exit</code>或<code>Ctrl+C</code>即可</p>
<h1 id="三、MySQL常用命令"><a href="#三、MySQL常用命令" class="headerlink" title="三、MySQL常用命令"></a>三、MySQL常用命令</h1><p>以下命令结尾都需要加分号；</p>
<ul>
<li><p><code>show databases;</code>可以显示所有数据库</p>
</li>
<li><p><code>use+库名</code>：打开某个数据库</p>
</li>
<li><p><code>show tables</code>：显示库中的某个表内容</p>
</li>
<li><p><code>show tables from+库名（比如MySQL）</code>：从某个库显示表</p>
</li>
<li><p><code>select database()</code>：显示所在的库</p>
</li>
<li><p>创建表名为stuinfo：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create table stuinfo(                                                                                   -&gt; id int,                                                                                              -&gt; name varchar(20));</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>select * from stuinfo</code>：由于为空表，故返回Empty Set</p>
</li>
<li><p><code>desc stuinfo</code>：显示stuinfo表</p>
</li>
<li><p><code>insert info stuinfo(id,name) values(1, &#39;rose&#39;)</code>：插入表</p>
<p>此时再显示，如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select * from stuinfo;                                                                                 +------+------+                                                                                         | id   | name |                                                                                         +------+------+                                                                                         |    1 | rose |                                                                                         |    2 | john |                                                                                          +------+------+</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>update stuinfo set name=&#39;lilei&#39; where id=1;</code>将rose的名字修改为lilei</p>
</li>
<li><code>delete from stuinfo where id=1</code>：将lilei删除</li>
<li><code>select version()</code>：显示版本号（也可以退出之后<code>mysql --version</code>查看）</li>
</ul>
<h1 id="四、MySQL的语法规范"><a href="#四、MySQL的语法规范" class="headerlink" title="四、MySQL的语法规范"></a>四、MySQL的语法规范</h1><ol>
<li>不区分大小写，但建议关键字大写，表名、列名小写</li>
<li>每条命令最好分号结尾</li>
<li>每条命令根据需要，可以进行缩进或换行</li>
<li>注释：<ul>
<li>单行注释：#注释文字</li>
<li>单行注释：— 注释文字（需要加空格）</li>
<li>多行注释：/<em> 注释文字 </em>/</li>
</ul>
</li>
</ol>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>区块链入门（五）合约编写实例补充</title>
    <url>/posts/a4c5a08d.html</url>
    <content><![CDATA[<font color="red"> 注：本教程为技术教程，不谈论且不涉及炒作任何数字货币 </font>

<h1 id="合约编写实战实例"><a href="#合约编写实战实例" class="headerlink" title="合约编写实战实例"></a>合约编写实战实例</h1><h2 id="一、简单代币合约"><a href="#一、简单代币合约" class="headerlink" title="一、简单代币合约"></a>一、简单代币合约</h2><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity &gt; <span class="number">0.4</span><span class="number">.22</span>;</span><br><span class="line"></span><br><span class="line">contract Coin&#123;</span><br><span class="line">    <span class="comment">//这里我们定义了一个address 作为key, uint做为value的hashTable balances; 我们还定义了一个address的变量minter;</span></span><br><span class="line">    address public minter;</span><br><span class="line">    mapping(<span class="function"><span class="params">address</span>=&gt;</span>uint) balances;</span><br><span class="line">    event Sent(address <span class="keyword">from</span>, address to, uint amount);</span><br><span class="line">    <span class="keyword">constructor</span>()&#123;</span><br><span class="line">        <span class="comment">//代表创建这个合约的账户地址，被赋值给变量minter.</span></span><br><span class="line">        minter = msg.sender;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//添加一个挖矿合约 </span></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">mint</span>(<span class="params">address receiver, uint amount</span>) <span class="title">public</span></span>&#123;</span><br><span class="line">        <span class="built_in">require</span>(msg.sender == minter);</span><br><span class="line">        balances[receiver] += amount;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">send</span>(<span class="params">address receiver, uint amount</span>) <span class="title">public</span></span>&#123;</span><br><span class="line">        <span class="built_in">require</span>(balances[msg.sender] &gt;= amount);</span><br><span class="line">        balances[msg.sender] -= amount;</span><br><span class="line">        balances[receiver] += amount;</span><br><span class="line">        emit Sent(msg.sender,receiver,amount);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>解析：<br>上面实现一个简单的加密货币，币在这里可以无中生有，但只有创建合约的人才能做到，且任何人都可以给他人转币，无需注册名和密码。</p>
<p><code>address</code>类型是一个160位的值，不允许任何算数操作，这种类型适合存储合约地址或外部人员。</p>
<p><code>mappings</code>可看作是一个哈希表，它会执行虚拟初始化，以使得所有可能存在的键都映射到一个字节表示为全零的值。</p>
<p><code>event Sent(address from, address to, uint amount)</code>;声明了一个所谓的事件，它在send函数最后一行被发出。用户界面可以监听区块链上正在发送的事件，且不会花费太多成本，一旦它被发出，监听该事件的listener都将收到通知，而所有的事件都包含了<code>from</code>,<code>t</code>o和<code>amoun</code>t三个参数，可方便追踪事务。</p>
<p><code>msg.sender</code>始终是当前函数或者外部函数调用的来源地址。</p>
<p>最后真正被用户和其他合约所调用的，用于完成本合约功能的方法是<code>mint</code>和<code>send</code>。若<code>mint</code>被合约创建者外的其他调用则说明都不会发生。</p>
<p><code>send</code>函数可被任何人用于向其他人发送代币，前提是发送者拥有这些代币，若使用合约发送代币给一个地址，当在区块链浏览器上查到该地址时时看不到任何相关信息的，因为，实际上发送币和更改余额的信息仅仅存在特定合约的数据存储器中。通过使用事件，可非常简单地为新币创建一个区块链浏览器来追踪交易和余额。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-15.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>



<h2 id="二、水龙头合约"><a href="#二、水龙头合约" class="headerlink" title="二、水龙头合约"></a>二、水龙头合约</h2><p>在前面我们通过 Ropsten 测试网络的水龙头（Faucet）获取了一些以太币，并提到可以向水龙头账户发送以太币来捐赠以太币。实际上，水龙头账户是一个合约账户，水龙头就是一份合约，而整个网站就是合约+前端组成的DApp。下面我们通过 Remix 来编写一个简单的水龙头合约，借此了解如何创建、部署合约以及一些 Solidity 的基本语法。</p>
<p>首先打开 Remix，并新建一个名为 faucet.sol 的文件，该文件就是 Solidity 的源文件</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-16.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>

<p>打开 faucet.sol，并写入如下代码</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.7</span><span class="number">.0</span>;</span><br><span class="line"></span><br><span class="line">contract faucet &#123;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">withdraw</span> (<span class="params">uint amount</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        <span class="built_in">require</span> (amount &lt;= <span class="number">1e18</span>);</span><br><span class="line">        msg.sender.transfer (amount);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    receive () external payable &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过这几行代码我们就实现了一个非常简单的水龙头合约。首行代码 <code>pragma solidity ^0.7.0</code>是一个<strong>杂注</strong>，指定了我们的源文件使用的编译器版本不能低于 0.7.0，也不能高于 0.8.0。</p>
<p><code>contract faucet{...}</code> 声明了一个合约对象，合约对象类似面向对象语言中的类，对象名必须跟文件名相同。</p>
<p>接下来通过  <code>function withdraw (uint amount) public {...}</code> 创建了一个名为  withdraw 的函数，该函数接收一个无符号整数（uint）作为参数，并且被声明为 public 函数，意为可以被其他合约调用。</p>
<p>withdraw 函数体中的 <code>require</code> 是 Solidity 的内置函数，用来检测括号中的条件是否满足。条件满足则继续执行合约，条件不满足则合约停止执行，回撤所有执行过的操作，并抛出异常。在这里我们通过 <code>require (amount &lt;= 1e18)</code> 来检测输入的以太币值是否小于等于1个以太。</p>
<p>接下来的这一行 <code>msg.sender.transfer (amount)</code> 就是实际的提款操作了。<code>msg</code> 是 Solidity 中内置的对象，所有合约都可以访问，它代表触发此合约的交易。也就是说当我们调用 <code>withdraw</code> 函数的时候实际上触发了一笔交易，并用 <code>msg</code> 来表示它。<code>sender</code> 是交易 <code>msg</code> 的属性，表示了交易的发件人地址。函数 <code>transfer</code> 是一个内置函数，它接收一个参数作为以太币的数量，并将该数量的以太币从合约账户发送到调用合约的用户的地址中。</p>
<p>最后一行是一个特殊的函数 <code>receive</code> ，这是所谓的 <code>fallback</code> 或 <code>default</code> 函数。当合约中的其他函数无法处理发送到合约中的交易信息时，就会执行该函数。在这里，我们将该函数声明为 <code>external</code> 和 <code>payable</code> ，<code>external</code> 意味着该函数可以接收来自外部账户的调用，<code>payable</code> 意味着该函数可以接收来自外部账户发送的以太币。</p>
<p>这样，当我们调用合约中的 <code>withdraw</code> 并提供一个参数时，我们可以从这份合约中提出以太币；当我们向合约发送以太币时，就会调用 <code>receive</code> 函数往合约中捐赠以太币。</p>
<p>代码编写完毕后，在 Remix 左侧的功能栏中选择第二项，并点击 <em>Compile faucet.sol</em> 来编译我们的 sol 文件。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-17.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<p>编译完成后会出现一个 Warning，提示我们添加 SPDX license，可以忽略。</p>
<p>随后选择 Remix 左侧工具栏的第三项，进入合约部署界面</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-18.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<p>首先将 ENVIRONMENT 选择为 Injected Web3，这样才能通过 MetaMask 钱包来发送交易。</p>
<p>随后点击 Deploy 部署合约，MetaMask 会弹出部署合约的交易界面</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-19.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<p>因为该笔交易是合约创建交易，因此我们支付的以太币为0，但仍需支付一定的 Gas 费用，可以自己设定 Gas 的价格。</p>
<p>合约部署成功后会收到 Chrome 的消息提示，并在 Remix 的 Deployed Contracts 中也会有显示</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-20.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<p>这样我们就完成了这个水龙头合约的部署。</p>
<h4 id="水龙头测试"><a href="#水龙头测试" class="headerlink" title="水龙头测试"></a>水龙头测试</h4><p>我们刚刚创建的水龙头中还没有以太坊，因此我们可以通过 MetaMask 向水龙头合约的地址中发送一些以太坊。水龙头合约的地址会显示在 Remix 中的，见上图 FAUCET AT 0X7A4…34219，可以直接复制。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-21.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<p>交易被确认后，我们的水龙头中就有了0.999726个以太币，现在我们可以通过 Remix 中合约一栏的 withdraw 按钮来提取以太币了。需要注意，这里输入的以太币个数是以 wei 为单位的。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-22.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<p>点击 withdraw 后，会弹出警告框</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-23.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<p>这是因为目前我们还没有设置这笔交易的 Gas，不用担心，点击 Send Transaction 后，在弹出的 MetaMask 中设置即可。</p>
<p>交易被确认后，我们得到了刚刚提取的0.999726个以太币</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-15.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"></div>
</center>


<p>若大家没有执行成功可以重新做一次、查找其他资料或者<a href="https://www.bilibili.com/video/BV1sJ411D72u?p=465" target="_blank" rel="noopener">观看此视频</a></p>
<h2 id="三、投票合约的实现"><a href="#三、投票合约的实现" class="headerlink" title="三、投票合约的实现"></a>三、投票合约的实现</h2><p><img src="\Pic\Blockchain_Pic\rating.png" style="zoom:67%;"></p>
<p>本次教程将以一个较复杂的投票合约作为结束，我们希望实现的功能是为每个（投票）建议建立一份合约,然后作为合约的创造者-主席，主席将赋予每个成员(地址)投票权，而成员的投票权可以选择委托给其他人也可以自己投票，结束时将返回投票最多的提案。听起来很简单一个功能实现起来却较为复杂，下面我们拆分开进行讲解</p>
<p>注：</p>
<ol>
<li>代码可直接在Remix编辑器的已有solidity文件中找到,在contract/_Ballot.sol文件里</li>
<li>若学习者前面部分掌握较牢固，不妨尝试直接自行阅读代码，无需阅读本节内容</li>
</ol>
<p>首先我们定义成员类型，我们为每个投票者定义权重、是否已投票、</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">struct Voter &#123;</span><br><span class="line">    uint weight; <span class="comment">// weight is accumulated by delegation</span></span><br><span class="line">    bool voted;  <span class="comment">// if true, that person already voted</span></span><br><span class="line">    address delegate; <span class="comment">// person delegated to</span></span><br><span class="line">    uint vote;   <span class="comment">// index of the voted proposal</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后我们定义提案类型，包含提案名和投票总数：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">struct Proposal &#123;</span><br><span class="line">    bytes32 name;   <span class="comment">// short name (up to 32 bytes)</span></span><br><span class="line">    uint voteCount; <span class="comment">// number of accumulated votes</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>定义三个变量，主席是一个公开的地址，建立投票者与地址的映射，然后定义提案动态数组：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">address public chairperson;</span><br><span class="line">mapping(<span class="function"><span class="params">address</span> =&gt;</span> Voter) public voters;</span><br><span class="line">Proposal[] public proposals;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>address public chairperson</code>：投票发起人，类型为 address。</li>
<li><code>mapping(address =&gt; Voter) public voters</code>：所有投票人，类型为 <code>address</code> 到 <code>Voter</code> 的映射。</li>
<li><code>Proposal[] public proposals</code>：所有提案，类型为动态大小的 <code>Proposal</code> 数组。</li>
</ul>
<p>3 个状态变量都使用了 <code>public</code> 关键字，使得变量可以被外部访问（即通过消息调用）。事实上，编译器会自动为 <code>public</code>的变量创建同名的 <code>getter</code> 函数，供外部直接读取。</p>
<p>我们还需要为每个投票赋予初始权值，并将主席的权重设置为1。我们一般使用<code>constructor</code>赋初值，这与C++等语言类似：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">constructor</span>(bytes32[] memory proposalNames) &#123;</span><br><span class="line">    chairperson = msg.sender;</span><br><span class="line">    voters[chairperson].weight = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (uint i = <span class="number">0</span>; i &lt; proposalNames.length; i++) &#123;</span><br><span class="line">        proposals.push(Proposal(&#123;</span><br><span class="line">            name: proposalNames[i],</span><br><span class="line">            voteCount: <span class="number">0</span></span><br><span class="line">        &#125;));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>所有提案的名称通过参数 <code>bytes32[] proposalNames</code> 传入，逐个记录到状态变量 <code>proposals</code> 中。同时用 <code>msg.sender</code> 获取当前调用消息的发送者的地址，记录为投票发起人 <code>chairperson</code>，该发起人投票权重设为 1。</p>
<p>接下来我们需要给每个投票者赋予权重：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">giveRightToVote</span>(<span class="params">address voter</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">    <span class="built_in">require</span>(</span><br><span class="line">        msg.sender == chairperson,</span><br><span class="line">        <span class="string">"Only chairperson can give right to vote."</span></span><br><span class="line">    );</span><br><span class="line">    <span class="built_in">require</span>(</span><br><span class="line">        !voters[voter].voted,</span><br><span class="line">        <span class="string">"The voter already voted."</span></span><br><span class="line">    );</span><br><span class="line">    <span class="built_in">require</span>(voters[voter].weight == <span class="number">0</span>);</span><br><span class="line">    voters[voter].weight = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该函数给 <code>address voter</code> 赋予投票权，即将 <code>voter</code> 的投票权重设为 1，存入 <code>voters</code> 状态变量。</p>
<p>上面这个函数只有投票发起人 <code>chairperson</code> 可以调用。这里用到了 <code>require((msg.sender == chairperson) &amp;&amp; !voters[voter].voted)</code> 函数。如果<code>require</code> 中表达式结果为 <code>false</code>，这次调用会中止，且回滚所有状态和以太币余额的改变到调用前。但已消耗的 <code>Gas</code> 不会返还。</p>
<p>下面一段是整段代码的重点，其作用是委托其他人代理投票，基本思路是：</p>
<ol>
<li>使用<code>require</code>判断委托人是否已投票（若投过票再委托则重复投票），并判断被委托对象是否是自己</li>
<li>当判断被委托人不是0地址（主席）时，被委托人代理委托人的票，【绕口警告】由于被委托人也可能委托了别人，因此这里需要一直循环直到找到最后没有委托别人的被委托人为止！</li>
<li>委托人找到对应的被委托人，委托人已投票（避免重复投票）</li>
<li>判断被委托人是否已投票，若投了票则将被委托人投的提案票数加上委托人的权重，若未投票则令被委托人的权重加上委托人的权重（以后投票自然相当于投两票）</li>
</ol>
<p>注：该函数使用了 <code>while</code> 循环，这里合约编写者需要十分谨慎，防止调用者消耗过多 <code>Gas</code>，甚至出现死循环。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">delegate</span>(<span class="params">address to</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">    Voter storage sender = voters[msg.sender];</span><br><span class="line">    <span class="built_in">require</span>(!sender.voted, <span class="string">"You already voted."</span>);</span><br><span class="line">    <span class="built_in">require</span>(to != msg.sender, <span class="string">"Self-delegation is disallowed."</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (voters[to].delegate != address(<span class="number">0</span>)) &#123;</span><br><span class="line">    	to = voters[to].delegate;</span><br><span class="line">    	<span class="built_in">require</span>(to != msg.sender, <span class="string">"Found loop in delegation."</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    sender.voted = <span class="literal">true</span>;</span><br><span class="line">    sender.delegate = to;</span><br><span class="line">    Voter storage delegate_ = voters[to];</span><br><span class="line">    <span class="keyword">if</span> (delegate_.voted) &#123;</span><br><span class="line">    	proposals[delegate_.vote].voteCount += sender.weight;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    	delegate_.weight += sender.weight;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>投票部分仅是几个简单的条件判断：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">vote</span>(<span class="params">uint proposal</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        Voter storage sender = voters[msg.sender];</span><br><span class="line">        <span class="built_in">require</span>(sender.weight != <span class="number">0</span>, <span class="string">"Has no right to vote"</span>);</span><br><span class="line">        <span class="built_in">require</span>(!sender.voted, <span class="string">"Already voted."</span>);</span><br><span class="line">        sender.voted = <span class="literal">true</span>;</span><br><span class="line">        sender.vote = proposal;</span><br><span class="line">        proposals[proposal].voteCount += sender.weight;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>用 <code>voters[msg.sender]</code> 获取投票人，即此次调用的发起人。接下来检查是否是重复投票，如果不是，进行投票后相关状态变量的更新。</p>
<p>接下来是计算获胜提案:</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">winningProposal</span>(<span class="params"></span>) <span class="title">public</span> <span class="title">view</span></span></span><br><span class="line"><span class="function">        <span class="title">returns</span> (<span class="params">uint winningProposal_</span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    uint winningVoteCount = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (uint p = <span class="number">0</span>; p &lt; proposals.length; p++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (proposals[p].voteCount &gt; winningVoteCount) &#123;</span><br><span class="line">            winningVoteCount = proposals[p].voteCount;</span><br><span class="line">            winningProposal_ = p;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>returns (uint winningProposal)</code> 指定了函数的返回值类型，<code>constant</code> 表示该函数不会改变合约状态变量的值。</p>
<p>最后是查询获胜者名称：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">winnerName</span>(<span class="params"></span>) <span class="title">public</span> <span class="title">view</span></span></span><br><span class="line"><span class="function">        <span class="title">returns</span> (<span class="params">bytes32 winnerName_</span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    winnerName_ = proposals[winningProposal()].name;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里采用内部调用 <code>winningProposal()</code> 函数的方式获得获胜提案。如果需要采用外部调用，则需要写为 <code>this.winningProposal()</code>。</p>
<p><strong>参考自：</strong></p>
<p><a href="https://www.bilibili.com/video/BV1sJ411D72u" target="_blank" rel="noopener">尚硅谷区块链全套Go语言→GoWeb→以太坊→项目实战</a><br><a href="http://cw.hubwiz.com/card/c/web3.js-1.0/" target="_blank" rel="noopener">web3.js 1.0中文手册</a></p>
]]></content>
      <categories>
        <category>Blockchain</category>
      </categories>
  </entry>
  <entry>
    <title>区块链入门（四）web3js</title>
    <url>/posts/5521455b.html</url>
    <content><![CDATA[<font color="red">注：本教程为技术教程，不谈论且不涉及炒作任何数字货币 </font>

<h2 id="一、以太坊客户端"><a href="#一、以太坊客户端" class="headerlink" title="一、以太坊客户端"></a>一、以太坊客户端</h2><h3 id="1-1、什么是以太坊客户端"><a href="#1-1、什么是以太坊客户端" class="headerlink" title="1.1、什么是以太坊客户端"></a>1.1、什么是以太坊客户端</h3><ul>
<li>以太坊客户端是一个软件应用程序，它实现以太坊规范并通过p2p网络与其他以太坊客户端进行通信。如果不同的以太坊客户端符合参考规范和标准化通信协议，则可以进行相互操作。</li>
<li>以太坊是一个开源项目，由“黄皮书”正式规范定义。除了各种以太坊改进提案之外，此正式规范还定义了以太坊客户端的标准行为。</li>
<li>因为以太坊有明确的正式规范，以太网客户端有了许多独立开发的软件实现，它们之间又可以彼此交互。</li>
</ul>
<h3 id="1-2、基于以太坊规范的网络"><a href="#1-2、基于以太坊规范的网络" class="headerlink" title="1.2、基于以太坊规范的网络"></a>1.2、基于以太坊规范的网络</h3><ul>
<li>存在各种基于以太坊规范的网络，这些网络基本符合以太坊“黄皮书”中定义的形式规范，但它们之间可能相互也可能不相互操作。</li>
<li>这些基于以太坊的网络中有：以太坊，以太坊经典，Ella，Expanse，Ubiq，Musicoin等等。</li>
<li>虽然大多数在协议级别兼容，但这些网络通常具有特殊要求，以太坊客户端软件的维护人员、需要进行微小更改、以支持每个网络的功能或属性</li>
</ul>
<h3 id="1-3、太坊的多种客户端"><a href="#1-3、太坊的多种客户端" class="headerlink" title="1.3、太坊的多种客户端"></a>1.3、太坊的多种客户端</h3><ul>
<li><a href="https://github.com/ethereum/go-ethereum" target="_blank" rel="noopener">go-ethereum ( Go )</a><br>官方推荐，开发使用最多</li>
<li>parity ( Rust )<br>最轻便客户端，在历次以太坊网络攻击中表现卓越</li>
<li><p>cpp-ethereum (C++)</p>
</li>
<li><p>pyethapp (python)</p>
</li>
<li><p>ethereumjs-lib ( javascript )</p>
</li>
<li><p>EthereumJ / Harmony ( Java )</p>
</li>
</ul>
<h3 id="1-4、以太坊全节点"><a href="#1-4、以太坊全节点" class="headerlink" title="1.4、以太坊全节点"></a>1.4、以太坊全节点</h3><ul>
<li>全节点是整个主链的一个副本，存储并维护链上的所有数据，并随时验证新区块的合法性。</li>
<li>区块链的健康和扩展弹性，取决于具有许多独立操作和地理上分散的全节点。每个全节点都可以帮助其他新节点获取区块数据，并提供所有交易和合约的独立验证。</li>
<li>运行全节点将耗费巨大的成本，包括硬件资源和带宽。</li>
<li>以太坊开发不需要在实时网络（主网）上运行的全节点。我们可以使用测试网络的节点来代替，也可以用本地私链，或者使用服务商提供的基于云的以太坊客户端；这些几乎都可以执行所有操作。</li>
</ul>
<h3 id="1-5、远程客户端和轻节点"><a href="#1-5、远程客户端和轻节点" class="headerlink" title="1.5、远程客户端和轻节点"></a>1.5、远程客户端和轻节点</h3><ul>
<li><p>远程客户端</p>
<p>不存储区块链的本地副本或验证块和交易。这些客户端一般只提供钱包的功能，可以创建和广播交易。远程客户端可用于连接到现有网络，MetaMask 就是一个这样的客户端。</p>
</li>
<li><p>轻节点</p>
<p>  不保存链上的区块历史数据，只保存区块链当前的状态。轻节点可以对块和交易进行验证。</p>
</li>
</ul>
<ul>
<li><p>全节点的优缺点</p>
<ul>
<li>优点<ul>
<li>为以太坊网络的灵活性和抗审查性提供有力支持</li>
<li>权威地验证所有交易</li>
<li>可以直接与公众区块链上的任何合约交互</li>
<li>可以离线查询区块链状态（账户、合约等）</li>
<li>可以直接把自己的合约部署到公共区块链中</li>
</ul>
</li>
<li>缺点<ul>
<li>需要巨大的硬件和带宽资源，而且会不断增长</li>
<li>第一次下载往往需要几天才能完全同步</li>
<li>必须及时维护、升级并保持在线状态以同步区块</li>
</ul>
</li>
</ul>
<h5 id="公共测试网络节点的优缺点"><a href="#公共测试网络节点的优缺点" class="headerlink" title="公共测试网络节点的优缺点"></a>公共测试网络节点的优缺点</h5><ul>
<li>优点<ul>
<li>一个testnet节点需要同步和存储更少的数据，大约10GB，具体取决于不同的网络</li>
<li>一个testnet节点一般可以在几个小时内完成同步</li>
<li>部署合约或进行交易只需要发送测试以太，可以从”水龙头“免费获得</li>
<li>测试网络是公共区块链，有许多其他用户和合约运行（区别于私链）</li>
</ul>
</li>
<li>缺点<ul>
<li>测试网络上使用测试以太没有价值。因此无法测试交易对手的安全性，因为没有任何利害关系</li>
<li>测试网络上的测试无法涵盖所有真实主网特性。例如：交易费用虽然是发送交易所必需的，但由于gas免费，因此 testnet上往往不会考虑。而且一般来说，测试网络不会像主网一样经常拥堵</li>
</ul>
</li>
</ul>
<h5 id="本地私链的优缺点"><a href="#本地私链的优缺点" class="headerlink" title="本地私链的优缺点"></a>本地私链的优缺点</h5><ul>
<li>优点<ul>
<li>磁盘上几乎没有数据，也不同步别的数据，是一个完全干净的环境</li>
<li>无需获取测试以太，可以分配任意以太，也可以随时自己挖矿获得</li>
<li>没有其他用户与合约，无外部干扰</li>
</ul>
</li>
<li>缺点<ul>
<li>没有其他用户意味与公链的行为不同，发送的交易并不存在空间或交易顺序的竞争</li>
<li>除自己之外没有矿工意味着挖矿更容易预测，因此无法测试公链上发生的某些情况</li>
<li>没有其他合约意味着必须部署要测试的所有内容，包括所有的依赖项和合约库</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>我们的教程主要基于本地私链的搭建，以后的交易等也主要基于我们的私链，因此以太坊客户端及私链的搭建在我们本次学习中至关重要。</p>
<p><strong>JSON-RPC</strong></p>
<ul>
<li>以太坊客户端提供了API 和一组远程调用（RPC）命令，这些命令被编码为 JSON。这被称为 JSON-RPC API。本质上，JSON-RPCAPI 就是一个接口，允许我们编写的程序使用以太坊客户端作为网关，访问以太坊网络和链上数据。</li>
<li>通常，RPC 接口作为一个 HTTP 服务，端口设定为 8545。出于安全原因，默认情况下，它仅限于接受来自localhost 的连接。</li>
<li>要访问JSON-RPC API，我们可以使用编程语言编写的专用库，例如JavaScript的 web3.js。</li>
<li>或者也可以手动构建HTTP请求并发送/接收JSON编码的请求，如：</li>
</ul>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">curl -X POST -H <span class="string">"Content-Type:application/json"</span> --data <span class="string">'&#123;"jsonrpc":"2.0","method":"web3_clientVersion","params":[],"id":1&#125;'</span> http:<span class="comment">//127.0.0.1:8545</span></span><br></pre></td></tr></table></figure>
<h2 id="二、用-Geth-搭建以太坊私链"><a href="#二、用-Geth-搭建以太坊私链" class="headerlink" title="二、用 Geth 搭建以太坊私链"></a>二、用 Geth 搭建以太坊私链</h2><h3 id="2-1安装-go"><a href="#2-1安装-go" class="headerlink" title="2.1安装 go"></a>2.1安装 go</h3><p>大家首先输入<code>go version</code>查看自己是否配置成功go环境，若不成功参考下面博客：</p>
<p><a href="https://blog.csdn.net/qq_44702847/article/details/108597386" target="_blank" rel="noopener">go ： GoLand安装及环境配置</a></p>
<p>若成功则如下图所示</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part3-1.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 1</div>
</center>



<h3 id="2-2-安装-Geth"><a href="#2-2-安装-Geth" class="headerlink" title="2.2 安装 Geth"></a>2.2 安装 Geth</h3><p>安装 Geth 有很多种方式，这里主要就 Linux 环境给出两种方法：系统包管理器（apt-get）安装和源码安装。更加推荐大家用源码安装，在整个过程中可以看到 Geth 各组件的构建步骤。</p>
<p>其他OS安装方法见<a href="https://geth.ethereum.org/docs/install-and-build/installing-geth" target="_blank" rel="noopener">本教程</a></p>
<p><strong>方法一、apt-get</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">sudo apt-<span class="keyword">get</span> install software-properties-common</span><br><span class="line">sudo add-apt-repository -y ppa:ethereum/ethereum</span><br><span class="line">sudo apt-<span class="keyword">get</span> update</span><br><span class="line">sudo apt-<span class="keyword">get</span> install ethereum</span><br></pre></td></tr></table></figure>
<p><strong>方法二、源码安装</strong></p>
<ol>
<li>克隆 github 仓库我们的第一步是克隆 git 仓库，以获取源代码的副本。</li>
</ol>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">git clone https:<span class="comment">//github.com/ethereum/go-ethereum.git</span></span><br></pre></td></tr></table></figure>
<ol>
<li>从源码构建 Geth要构建 Geth，切换到下载源代码的目录并使用 make 命令：</li>
</ol>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">cd go-ethereum</span><br><span class="line">make geth</span><br></pre></td></tr></table></figure>
<p>如果一切顺利，我们将看到 Go 编译器构建每个组件，直到它生成 geth 可执行文件：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">build/env.sh go run build/ci.go install ./cmd/geth</span><br><span class="line">&gt;&gt;&gt; <span class="regexp">/usr/</span>local/go/bin/go install -ldflags -X</span><br><span class="line">main.gitCommit=<span class="number">58</span>a1e13e6dd7f52a1d5e67bee47d23fd6cfdee5c -v ./cmd/geth</span><br><span class="line">github.com/ethereum/go-ethereum/common/hexutil</span><br><span class="line">github.com/ethereum/go-ethereum/common/math</span><br><span class="line">github.com/ethereum/go-ethereum/crypto/sha3 github.com/ethereum/go-ethereum/rlp</span><br><span class="line">github.com/ethereum/go-ethereum/crypto/secp256k1</span><br><span class="line">github.com/ethereum/go-ethereum/common [...]</span><br><span class="line">github.com/ethereum/go-ethereum/cmd/utils</span><br><span class="line">github.com/ethereum/go-ethereum/cmd/geth Done building. Run <span class="string">"build/bin/geth"</span> to</span><br><span class="line">launch geth.</span><br></pre></td></tr></table></figure>
<p> 查看 geth version，确保在真正运行之前安装正常：</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part3-2.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 2</div>
</center>



<h3 id="启动节点同步"><a href="#启动节点同步" class="headerlink" title="启动节点同步"></a>启动节点同步</h3><p>安装好了 Geth，现在我们可以尝试运行一下它。执行下面的命令，geth 就会开始同步区块，并存储在当前目录下。</p>
<p>这里的 —syncmode fast 参数表示我们会以“快速”模式同步区块。在这种模式下，我们只会下载每个区块头和区块体，但不会执行验证所有的交易，直到所有区块同步完毕再去获取一个系统当前的状态。这样就节省了很多交易验证的时间。</p>
 <figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">geth –datadir . --syncmode fast</span><br></pre></td></tr></table></figure>
<p>—datadir：后面的参数是区块数据及秘钥存放目录</p>
<p>通常，在同步以太坊区块链时，客户端会一开始就下载并验证每个块和每个交易，也就是说从创世区块开始。 毫无疑问，如果我们不加 —syncmode fast 参数，同步将花费很长时间并且具有很高的资源要求（它将需要更多的 RAM，如果你没有快速存储，则需要很长时间）。有些文章会把这个参数写成 —fast，这是以前快速同步模式的参数写法，现在已经被 –syncmode fast取代。如果我们想同步测试网络的区块，可以用下面的命令：</p>
 <figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">geth --testnet --datadir . --syncmode fast</span><br></pre></td></tr></table></figure>
<p>—testnet 这个参数会告诉 geth 启动并连接到最新的测试网络，也就是 Ropsten。测试网络的区块和交易数量会明显少于主网，所以会更快一点。但即使是用快速模式同步测试网络，也会需要几个小时的时间</p>
<h3 id="2-3-搭建自己的私有链"><a href="#2-3-搭建自己的私有链" class="headerlink" title="2.3 搭建自己的私有链"></a>2.3 搭建自己的私有链</h3><p>因为公共网络的区块数量太多，同步耗时太长，我们为了方便快速了解 Geth，可以试着用它来搭一个只属于自己的私链。首先，我们需要创建网络的“创世”（genesis）状态，这写在一个小小的 JSON 文件里（例如，我们将其命名为 genesis.json，保存到当前目录下）：</p>
 <figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="string">"config"</span>: &#123;</span><br><span class="line">    <span class="string">"chainId"</span>: <span class="number">15</span></span><br><span class="line">    &#125;,</span><br><span class="line"><span class="string">"difficulty"</span>: <span class="string">"2000"</span>,</span><br><span class="line"><span class="string">"gasLimit"</span>: <span class="string">"2100000"</span>,</span><br><span class="line"><span class="string">"alloc"</span>: &#123;</span><br><span class="line">    <span class="string">"7df9a875a174b3bc565e6424a0050ebc1b2d1d82"</span>: &#123;   <span class="string">"balance"</span>: <span class="string">"300000"</span> &#125;,</span><br><span class="line">    <span class="string">"f41c74c9ae680c1aa78f42e5647a62f353b7bdde"</span>: &#123; <span class="string">"balance"</span>: <span class="string">"400000"</span> &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>genesis.json介绍</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part3-3.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 3</div>
</center>



<p>要创建一条以它作为创世块的区块链，我们可以使用下面的命令：</p>
 <figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">geth --datadir . init genesis.json</span><br></pre></td></tr></table></figure>
<p>初始化完成后目录下多了geth和keystore两个文件夹：</p>
<ul>
<li>geth：保存该链上的区块数据</li>
<li>keystore：保存该链上的账户信息</li>
</ul>
<p><strong>可能遇到问题</strong>：</p>
<ul>
<li><p>Fatal: invalid genesis file: missing 0x prefix for hex data：这个错误信息意思很明白，就是你的json文件中，对于16进制数据，需要加上0x前缀</p>
</li>
<li><p>Fatal: invalid genesis file: hex string has odd length: 从Geth 1.6版本开始，设置的十六进制数值，不能是奇数位， 比如不能是0x0，而应该是0x00。</p>
</li>
<li><p>Fatal: failed to write genesis block: genesis has no chain configuration ：这个错误信息，就是说，你的配置文件中，缺少config部分。</p>
</li>
<li><p>Error: invalid sender: 这个错误虽然不会导致私有链初始化时出现失败的情况，但是会在以后的转账（web3.eth.sendTransaction），或者部署智能合约的时候产生。解决方法就是chainId 不能设置为0。 如果你完全按照Geth官方文档上给出的配置文件进行配置，就会产生这个错误。</p>
</li>
</ul>
<p>在当前目录下运行 geth，就会启动这条私链，注意要将 networked 设置为与创世块配置里的chainId 一致。</p>
 <figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 简单开启</span></span><br><span class="line">(base) haobo@haobo:~<span class="regexp">/home/m</span>nt/bitcoin/test$ geth --datadir . --networkid <span class="number">150</span> --nodiscover <span class="built_in">console</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 更一般的形式</span></span><br><span class="line">(base) haobo@haobo:~<span class="regexp">/home/m</span>nt/bitcoin/test$ geth --networkid <span class="number">150</span> --datadir <span class="string">"."</span> --identity <span class="string">"kexin"</span> --rpc --rpcport <span class="string">"8545"</span> --rpcaddr <span class="string">"localhost"</span> --port <span class="string">"30303"</span> --nodiscover --allow-insecure-unlock --rpcapi <span class="string">"eth,net,web3,personal,admin,shh,txpool,debug,miner"</span> <span class="built_in">console</span></span><br></pre></td></tr></table></figure>
<p>参数含义：</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part3-4.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 4</div>
</center>



<p>我们可以看到节点正常启动：</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part3-5.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 5</div>
</center>


<p>启动完之后，就可以通过<code>admin.nodeInfo.protocols.eth</code>来获取到刚启动的节点的一些信息（如下），比较上文初始化的配置，相关内容是一致的。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part3-6.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 6</div>
</center>


<p>恭喜！我们已经成功启动了一条自己的私链。</p>
<h2 id="3、Geth-控制台命令"><a href="#3、Geth-控制台命令" class="headerlink" title="3、Geth 控制台命令"></a>3、Geth 控制台命令</h2><p><code>Geth Console</code> 是一个交互式的 JavaScript 执行环境，其中 &gt; 是命令提示符,里面内置了一些用来操作以太坊的 JavaScript对象，我们可以直接调用这些对象来获取区块链上的相关信息。</p>
<p><strong>这些对象主要包括：</strong></p>
<ul>
<li>eth：主要包含对区块链进行访问和交互相关的方法；</li>
<li>net：主要包含查看 p2p 网络状态的方法；</li>
<li>admin：主要包含与管理节点相关的方法；</li>
<li>miner：主要包含挖矿相关的一些方法；</li>
<li>personal：包含账户管理的方法；</li>
<li>txpool：包含查看交易内存池的方法；</li>
<li>web3：包含以上所有对象，还包含一些通用方法。</li>
</ul>
<p><strong>常用命令有：</strong></p>
<ul>
<li>personal.newAccount()：创建账户；</li>
<li>personal.unlockAccount()：解锁账户；</li>
<li>eth.accounts：枚举系统中的账户；</li>
<li>eth.getBalance()：查看账户余额，返回值的单位是 Wei（Wei 是以太坊中最小货币面额单位，类似比特币中的聪，1 ether = 10^18 Wei）；</li>
<li>eth.blockNumber：列出区块总数；</li>
<li>eth.getTransaction()：获取交易；</li>
<li>eth.getBlock()：获取区块；</li>
<li>miner.start()：开始挖矿；</li>
<li>miner.stop()：停止挖矿；</li>
<li>web3.fromWei()：Wei 换算成以太币；</li>
<li>web3.toWei()：以太币换算成 Wei；</li>
<li>txpool.status：交易池中的状态；</li>
<li>admin.addPeer()：连接到其他节点</li>
</ul>
<h3 id="3-1-操作测试"><a href="#3-1-操作测试" class="headerlink" title="3.1 操作测试"></a>3.1 操作测试</h3><p><strong>3.1.1 创建账户</strong></p>
<p>进入控制台后，可以通过使用命令来与私有链进行交互。创建一个新的账户：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; personal.newAccount()</span><br><span class="line">Passphrase:</span><br><span class="line">Repeat passphrase:</span><br><span class="line"><span class="string">"0xc8248c7ecbfd7c4104923275b99fafb308bbff92"</span></span><br></pre></td></tr></table></figure>
<p>输入两遍密码后，生成账户地址。以同样的方式，可创建多个账户，查看账户：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; eth.accounts</span><br></pre></td></tr></table></figure>
<p>查看账户余额</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; eth.getBalance(eth.accounts[<span class="number">0</span>])</span><br><span class="line"><span class="number">0</span></span><br></pre></td></tr></table></figure>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part3-7.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 7</div>
</center>


<p><strong>3.1.2 挖矿</strong></p>
<p>启动挖矿：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; miner.start(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>其中 <code>start</code> 的参数表示挖矿使用的线程数。第一次启动挖矿会先生成挖矿所需的 <code>DAG</code>文件，这个过程有点慢，等进度达到 100% 后，就会开始挖矿，此时屏幕会被挖矿信息刷屏。</p>
<p>停止挖矿，在 控制台 中输入：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; miner.stop()</span><br></pre></td></tr></table></figure>
<p>挖到一个区块会奖励以太币，挖矿所得的奖励会进入矿工的账户，这个账户叫做 coinbase，默认情况下 coinbase 是本地账户中的第一个账户，可以通过 miner.setEtherbase() 将其他账户设置成 coinbase。</p>
<p>可以使用以下命令，当新区块挖出后，挖矿即可结束。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; miner.start(<span class="number">1</span>);admin.sleepBlocks(<span class="number">1</span>);miner.stop();</span><br></pre></td></tr></table></figure>
<p><strong>3.1.3 交易</strong></p>
<p>目前，账户 0 已经挖到了 3 个块的奖励，账户 1 的余额还是0：<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; eth.getBalance(eth.accounts[<span class="number">0</span>])</span><br><span class="line"><span class="number">15000000000000000000</span></span><br><span class="line">&gt; eth.getBalance(eth.accounts[<span class="number">1</span>])</span><br><span class="line"><span class="number">0</span></span><br></pre></td></tr></table></figure></p>
<p>我们要从账户 0 向账户 1 转账，先解锁账户 0，才能发起交易：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; personal.unlockAccount(eth.accounts[<span class="number">0</span>])</span><br><span class="line">Unlock account <span class="number">0x3443ffb2a5ce3f4b80080791e0fde16a3fac2802</span></span><br><span class="line">Passphrase: </span><br><span class="line"><span class="literal">true</span></span><br></pre></td></tr></table></figure>
<p>发送交易，账户 0 -&gt; 账户 1：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; amount = web3.toWei(<span class="number">5</span>,<span class="string">'ether'</span>)</span><br><span class="line"><span class="string">"5000000000000000000"</span></span><br><span class="line">&gt; eth.sendTransaction(&#123;<span class="attr">from</span>:eth.accounts[<span class="number">0</span>],<span class="attr">to</span>:eth.accounts[<span class="number">1</span>],<span class="attr">value</span>:amount&#125;)</span><br><span class="line">INFO [<span class="number">09</span><span class="number">-12</span>|<span class="number">07</span>:<span class="number">38</span>:<span class="number">12</span>] Submitted transaction                    fullhash=<span class="number">0x9f5e61f3d686f793e2df6378d1633d7a9d1df8ec8c597441e1355112d102a6ce</span> recipient=<span class="number">0x02bee2a1582bbf58c42bbdfe7b8db4685d4d4c62</span></span><br><span class="line"><span class="string">"0x9f5e61f3d686f793e2df6378d1633d7a9d1df8ec8c597441e1355112d102a6ce"</span></span><br></pre></td></tr></table></figure>
<p>此时如果没有挖矿，用 <code>txpool.status</code> 命令可以看到本地交易池中有一个待确认的交易，可以使用 <code>eth.getBlock(&quot;pending&quot;, true).transactions</code>查看当前待确认交易。使用下面命令开始挖矿。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt;miner.start(<span class="number">1</span>);admin.sleepBlocks(<span class="number">1</span>);miner.stop();</span><br></pre></td></tr></table></figure>
<p>新区块挖出后，挖矿结束，查看账户 1 的余额，已经收到了账户 0 的以太币：<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; web3.fromWei(eth.getBalance(eth.accounts[<span class="number">1</span>]),<span class="string">'ether'</span>)</span><br><span class="line"><span class="number">5</span></span><br></pre></td></tr></table></figure></p>
<p><strong>3.1.3 查看交易和区块</strong></p>
<p>查看当前区块总数：<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; eth.blockNumber</span><br><span class="line"><span class="number">4</span></span><br></pre></td></tr></table></figure></p>
<p>通过区块号查看区块：<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; eth.getBlock(<span class="number">4</span>)</span><br></pre></td></tr></table></figure></p>
<p>通过交易 Hash 查看交易（Hash 值包含在上面交易返回值中）：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt;  eth.getTransaction(<span class="string">"0x9f5e61f3d686f793e2df6378d1633d7a9d1df8ec8c597441e1355112d102a6ce"</span>)</span><br></pre></td></tr></table></figure>
<p><strong>3.1.3 其他节点加入</strong></p>
<p>此时，私有链已经通过该节点创建好了，如果其他节点想加入，需要通过以太坊客户端连接到该私有区块网络，并连接该网络的节点来同步区块信息。在其他主机上安装以太坊客户端Geth，通过Geth命令进入该私有区块链，注意要指定相同的网络号。</p>
<p>假设有两个节点：节点一和节点二，NetWorkID 都是 6666，通过下面的步骤就可以从节点一连接到节点二。</p>
<p>首先要知道节点二的 enode 信息，在节点二的 Geth Console 中执行下面的命令查看 enode 信息：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; admin.nodeInfo.enode</span><br><span class="line"><span class="string">"enode://d465bcbd5c34da7f4b8e00cbf9dd18e7e2c38fbd6642b7435f340c7d5168947ff2b822146e1dc1b07e02f7c15d5ca09249a92f1d0caa34587c9b2743172259ee@[::]:30303"</span></span><br></pre></td></tr></table></figure>
<p>然后在节点一的 Geth Console 中执行 <code>admin.addPeer()</code>，就可以连接到节点二：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; admin.addPeer(<span class="string">"enode://d465bcbd5c34da7f4b8e00cbf9dd18e7e2c38fbd6642b7435f340c7d5168947ff2b822146e1dc1b07e02f7c15d5ca09249a92f1d0caa34587c9b2743172259ee@[::]:30303"</span>)</span><br></pre></td></tr></table></figure>
<p><code>addPeer()</code> 的参数就是节点二的 enode 信息，注意要把 enode 中的 <code>[::]</code> 替换成节点二的 IP 地址。连接成功后，节点二就会开始同步节点一的区块，同步完成后，任意一个节点开始挖矿，另一个节点会自动同步区块，向任意一个节点发送交易，另一个节点也会收到该笔交易。</p>
<p>通过 <code>admin.peers</code>可以查看连接到的其他节点信息，通过 <code>net.peerCount</code>可以查看已连接到的节点数量。</p>
<p>除了上面的方法，也可以在启动节点的时候指定<code>--bootnodes</code>选项连接到其他节点。</p>
<blockquote>
<p>如果只是自己测试开发使用，建议使用dev环境，在需要在启动时增加<code>–dev</code>参数即可，在dev模式下会监听交易，一旦有交易发送就会打包然后挖矿确认，且默认的<code>account[0]</code>开发者账户初始有一大堆以太币。</p>
</blockquote>
<h2 id="3、智能合约操作"><a href="#3、智能合约操作" class="headerlink" title="3、智能合约操作"></a>3、智能合约操作</h2><h3 id="3-1、创建和编译智能合约"><a href="#3-1、创建和编译智能合约" class="headerlink" title="3.1、创建和编译智能合约"></a>3.1、创建和编译智能合约</h3><p>经过part2的学习大家已经基本上掌握了Solidity，接下来我们编写一个智能合约：</p>
<p>该合约包含一个方法 multiply()，将输入的两个数相乘后输出：<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br><span class="line">contract TestContract</span><br><span class="line">&#123;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">multiply</span>(<span class="params">uint a, uint b</span>) <span class="title">returns</span> (<span class="params">uint</span>)</span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> a * b;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>将上面的代码复制到Remix编辑器里，程序将自动完成编译。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part3-8.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 8</div>
</center>


<p>点击 run 在Environment中设选择JavaScript VM, Value可设置为1，点击Deploy，则可创建该部署智能合约的交易。</p>
<p>因为我们要将该智能合约部署到私有链上，需要得到智能合约编译后的EVM二进制码和JSON ABI（Application Binary Interface）。将生成的交易保存到scenario.json文件，点击箭头所指按钮</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part3-9.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 9</div>
</center>



<p>其中38-65行为该智能合约的ABI（注意前面还有一个[符号），ABI指定了合约接口，包括可调用的合约方法、变量、事件等。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part3-10.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 10</div>
</center>


<p>input`字段为合约EVM二进制码，可点击直接复制。</p>
<p>在Linux下可以直接使用安装好的编译器进行编译，把合约代码保存到文件名为testContract.sol 里,通过下面两个命令分别得到EVM二进制码和JSON ABI。</p>
<p>如果没有安装solc先执行</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">sudo snap install solc</span><br></pre></td></tr></table></figure>
<p>接下来执行<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">$solc --bin testContract.sol</span><br><span class="line">$solc --abi testContract.sol</span><br></pre></td></tr></table></figure></p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part3-11.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 11</div>
</center>


<h3 id="3-2、部署智能合约"><a href="#3-2、部署智能合约" class="headerlink" title="3.2、部署智能合约"></a>3.2、部署智能合约</h3><p>回到 Geth 的控制台，用变量 code 和 abi 记录上面两个值：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; code = <span class="string">"608060405234801561001057600080fd5b5060b88061001f6000396000f3fe6080604052348015600f57600080fd5b506004361060285760003560e01c8063165c4a1614602d575b600080fd5b606060048036036040811015604157600080fd5b8101908080359060200190929190803590602001909291905050506076565b6040518082815260200191505060405180910390f35b600081830290509291505056fea265627a7a7231582049ecffb2740a6e31f7c8fbf4a928b88d3a95f417b985dc23cd1ad4c06a9b043864736f6c63430005100032"</span></span><br><span class="line">&gt; abi = [&#123;</span><br><span class="line">    <span class="string">"0xd1ef8ab8f12bde83ebaee1be4183c75f45ab5835643812016a7751173bfb9dc0"</span>: [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="string">"constant"</span>: <span class="literal">true</span>,</span><br><span class="line">        <span class="string">"inputs"</span>: [</span><br><span class="line">          &#123;</span><br><span class="line">            <span class="string">"name"</span>: <span class="string">"a"</span>,</span><br><span class="line">            <span class="string">"type"</span>: <span class="string">"uint256"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          &#123;</span><br><span class="line">            <span class="string">"name"</span>: <span class="string">"b"</span>,</span><br><span class="line">            <span class="string">"type"</span>: <span class="string">"uint256"</span></span><br><span class="line">          &#125;</span><br><span class="line">        ],</span><br><span class="line">        <span class="string">"name"</span>: <span class="string">"multiply"</span>,</span><br><span class="line">        <span class="string">"outputs"</span>: [</span><br><span class="line">          &#123;</span><br><span class="line">            <span class="string">"name"</span>: <span class="string">""</span>,</span><br><span class="line">            <span class="string">"type"</span>: <span class="string">"uint256"</span></span><br><span class="line">          &#125;</span><br><span class="line">        ],</span><br><span class="line">        <span class="string">"payable"</span>: <span class="literal">false</span>,</span><br><span class="line">        <span class="string">"stateMutability"</span>: <span class="string">"view"</span>,</span><br><span class="line">        <span class="string">"type"</span>: <span class="string">"function"</span></span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;]</span><br></pre></td></tr></table></figure>
<p>使用账户 0 来部署合约，首先解锁账户：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; personal.unlockAccount(eth.accounts[<span class="number">0</span>])</span><br><span class="line">Unlock account <span class="number">0xb51654f60dee35265558a1d2e61468fe00f12888</span></span><br><span class="line">Passphrase:</span><br><span class="line"><span class="literal">true</span></span><br></pre></td></tr></table></figure>
<p>创建合约实例，发送部署合约的交易：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt; myContract = eth.contract(abi)   </span><br><span class="line">...</span><br><span class="line">&gt; contract = myContract.new(&#123;<span class="attr">from</span>:eth.accounts[<span class="number">0</span>],<span class="attr">data</span>:code,<span class="attr">gas</span>:<span class="number">1000000</span>&#125;)</span><br></pre></td></tr></table></figure>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part3-12.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 12</div>
</center>

<p>此时如果没有挖矿，用 <code>txpool.status</code> 命令可以看到本地交易池中有一个待确认的交易。使用 <code>miner.start()</code> 命令开始挖矿，一段时间后交易会被确认。通过查询该交易可得到合约地址，使用命令：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt;eth.getTransactionReceipt(<span class="string">"0x085b66b2591ee31c3ad58a66ca485bd19bea6c1fc8ca7550a896853ab52855a6"</span>)</span><br><span class="line">contractAddress: <span class="string">"0xd92845cc4bffc1d6a4b6a389933b88880d5ded24"</span></span><br></pre></td></tr></table></figure>
<h3 id="3-3、调用智能合约"><a href="#3-3、调用智能合约" class="headerlink" title="3.3、调用智能合约"></a>3.3、调用智能合约</h3><p>使用以下命令通过发送交易来调用合约，sendTransaction 方法的前几个参数应该与合约中 multiply 方法的输入参数对应。这种情况下，交易会通过挖矿记录到区块链中：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt;contract.multiply.sendTransaction(<span class="number">2</span>, <span class="number">4</span>, &#123;<span class="attr">from</span>:eth.accounts[<span class="number">0</span>]&#125;)</span><br></pre></td></tr></table></figure>
<p>在本地运行该方法可直接查看返回结果，不会记录到区块链中，命令如下：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt;contract.multiply.call(<span class="number">2</span>，<span class="number">4</span>)</span><br><span class="line"><span class="number">8</span></span><br></pre></td></tr></table></figure>
<p>如果其他节点要调用这个已经部署好的合约，需要知道该合约的地址以及ABI。可以通过发送交易调用，也可以本地调用。我们以本地调用为例。<br>创建合约实例：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt;abi = [&#123;</span><br><span class="line">    <span class="string">"0xd1ef8ab8f12bde83ebaee1be4183c75f45ab5835643812016a7751173bfb9dc0"</span>: [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="string">"constant"</span>: <span class="literal">true</span>,</span><br><span class="line">        <span class="string">"inputs"</span>: [</span><br><span class="line">          &#123;</span><br><span class="line">            <span class="string">"name"</span>: <span class="string">"a"</span>,</span><br><span class="line">            <span class="string">"type"</span>: <span class="string">"uint256"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          &#123;</span><br><span class="line">            <span class="string">"name"</span>: <span class="string">"b"</span>,</span><br><span class="line">            <span class="string">"type"</span>: <span class="string">"uint256"</span></span><br><span class="line">          &#125;</span><br><span class="line">        ],</span><br><span class="line">        <span class="string">"name"</span>: <span class="string">"multiply"</span>,</span><br><span class="line">        <span class="string">"outputs"</span>: [</span><br><span class="line">          &#123;</span><br><span class="line">            <span class="string">"name"</span>: <span class="string">""</span>,</span><br><span class="line">            <span class="string">"type"</span>: <span class="string">"uint256"</span></span><br><span class="line">          &#125;</span><br><span class="line">        ],</span><br><span class="line">        <span class="string">"payable"</span>: <span class="literal">false</span>,</span><br><span class="line">        <span class="string">"stateMutability"</span>: <span class="string">"view"</span>,</span><br><span class="line">        <span class="string">"type"</span>: <span class="string">"function"</span></span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;]</span><br><span class="line">&gt;sample=eth.contract(abi)</span><br><span class="line">&gt;samplecontract=sample.at(<span class="string">"0xd92845cc4bffc1d6a4b6a389933b88880d5ded24"</span>)</span><br></pre></td></tr></table></figure>
<p>调用合约</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&gt;samplecontract.multiply.call(<span class="number">2</span>，<span class="number">4</span>)</span><br><span class="line"><span class="number">8</span></span><br></pre></td></tr></table></figure>
<h2 id="4、web3-js-简介"><a href="#4、web3-js-简介" class="headerlink" title="4、web3.js 简介"></a>4、web3.js 简介</h2><p>我们除了通过Geth的JavaScript Console进行交互以外，还有许多第三方库可以使用，方便开发基于以太坊区块链的应用：</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part3-13.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 13</div>
</center>


<p>本文使用web3.js与Geth客户端交互，首先搭建开发环境。</p>
<h3 id="4-1-环境搭建"><a href="#4-1-环境搭建" class="headerlink" title="4.1 环境搭建"></a>4.1 环境搭建</h3><p><strong>4.1.1 node.js安装</strong></p>
<p>更新源<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">sudo apt-<span class="keyword">get</span> update</span><br><span class="line">sudo apt-<span class="keyword">get</span> install -y python-software-properties software-properties-common</span><br><span class="line">sudo add-apt-repository ppa:chris-lea/node.js</span><br><span class="line">sudo apt-<span class="keyword">get</span> update</span><br></pre></td></tr></table></figure></p>
<p>node.js、npm安装<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">sudo apt-<span class="keyword">get</span> install nodejs</span><br><span class="line">sudo apt install nodejs-legacy</span><br><span class="line">sudo apt install npm</span><br></pre></td></tr></table></figure><br>安装完后，可以通过 <code>node --version npm --version</code> 查看是否安装成功及版本号。npm 包管理工具随 node 一起安装，如果版本太低，建议升到新版本。</p>
<p><strong>4.1.2 web3.js模块安装</strong><br>使用npm可完成本地安装、全局安装模块。<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">npm install -global &lt;package name&gt; <span class="comment">//全局安装</span></span><br><span class="line">npm install &lt;package name&gt; <span class="comment">//本地安装</span></span><br></pre></td></tr></table></figure></p>
<p>我这里选择使用本地安装模块，这样方便开发的应用移植、上线等。创建一个工程文件夹etherjs。在该文件夹下初始化一个新的 package.json 文件，使用下面命令自动生成。<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">npm init -y</span><br></pre></td></tr></table></figure></p>
<p>本地安装并添加模块名到 package.json<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">npm install &lt;package name&gt; --save</span><br><span class="line">或者npm install &lt;package name&gt; --save-dev</span><br></pre></td></tr></table></figure></p>
<p>区别在于—save-dev 是你开发时候依赖的东西，—save 是你发布之后还依赖的东西。一般使用—save。<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">npm install web3 --save</span><br></pre></td></tr></table></figure></p>
<p>如果这样安装不成功，使用下面命令安装指定版本：<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">npm install web3@^<span class="number">0.20</span><span class="number">.1</span> --save</span><br></pre></td></tr></table></figure></p>
<p><strong>4.1.3 solc.js模块安装</strong><br>solc是用来编译智能合约的模块<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">npm install solc --save</span><br></pre></td></tr></table></figure></p>
<p><strong>4.1.4 编译器——Visual Studio Code</strong></p>
<p>这里选择Visual Studio Code，适合node.js开发，集成的终端可以很方便运行程序。</p>
<p>安装Ubuntu Make<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">sudo add-apt-repository ppa:ubuntu-desktop/ubuntu-make</span><br><span class="line">sudo apt-<span class="keyword">get</span> update</span><br><span class="line">sudo apt-<span class="keyword">get</span> install ubuntu-make</span><br></pre></td></tr></table></figure><br>安装visual-studio-code<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">umake web visual-studio-code</span><br></pre></td></tr></table></figure><br>安装完成后，直接搜索Visual Studio Code应用，把图标拖拽到Unity启动器上，就可以方便使用了。</p>
<h3 id="4-2-web3-js-介绍"><a href="#4-2-web3-js-介绍" class="headerlink" title="4.2 web3.js 介绍"></a>4.2 web3.js 介绍</h3><p>web3js 的全称是Web3 JavaScript app API，它是一个JavaScript API库。要使DApper在以太坊上运行，我们可以使用web3.js库提供的web3对象。web3.js通过RPC调用与本地节点通信，它可以用于任何暴露了RPC层的以太坊节点，web3包含了eth对象 - web3.eth（专门与以太坊区块链交互）和 shh对象 - web3.shh（用于与 Whisper交互）[Whisper是以太坊生态系统的一部分，主要用来做消息传递]</p>
<p>如果我们想要在以太坊上开发合约，目前来说最方便的方法就是调用Web3.js库，它会给我们一个Web3对象。我们进入geth控制台，直接键入web3就可以看到所有的方法。下面主要介绍如何通过web3js创建合约并调用</p>
<p><strong>4.2.1异步回调（callback）</strong></p>
<ul>
<li>web3js API 设计的最初目的，主要是为了和本地 RPC 节点共同使用，所以默认情况下发送的是同步 HTTP 请求</li>
<li>如果要发送异步请求，可以在函数的最后一个参数位置上，传入一个回调函数。回调函数是可选（optioanl）的</li>
<li><p>我们一般采用的回调风格是所谓的“错误优先”，例如：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">web3.eth.getBlock(<span class="number">48</span>, <span class="function"><span class="keyword">function</span>(<span class="params">error, result</span>)</span>&#123;</span><br><span class="line"><span class="keyword">if</span>(!error)</span><br><span class="line">　　<span class="built_in">console</span>.log(<span class="built_in">JSON</span>.stringify(result));</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">　　<span class="built_in">console</span>.error(error);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>4.2.2 回调 Promise 事件（v1.0.0）</strong></p>
<ul>
<li>为了帮助 web3 集成到不同标准的所有类型项目中，1.0.0 版本提供了多种方式来处理异步函数。大多数的 web3 对象允许将一个回调函数作为最后一个函数参数传入，同时会返回一个promise 用于链式函数调用。</li>
<li>以太坊作为一个区块链系统，一次请求具有不同的结束阶段。为了满足这样的要求，1.0.0 版本将这类函数调用的返回值包成一个“承诺事件”（promiEvent），这是一个 promise 和EventEmitter 的结合体。</li>
<li>PromiEvent 的用法就像 promise 一样，另外还加入了.on，.once 和.off方法</li>
</ul>
 <figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">web3.eth.sendTransaction(&#123;<span class="attr">from</span>: <span class="string">'0x123...'</span>, <span class="attr">data</span>: <span class="string">'0x432...'</span>&#125;)</span><br><span class="line">.once(<span class="string">'transactionHash'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">hash</span>)</span>&#123; ... &#125;)</span><br><span class="line">.once(<span class="string">'receipt'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">receipt</span>)</span>&#123; ... &#125;)</span><br><span class="line">.on(<span class="string">'confirmation'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">confNumber, receipt</span>)</span>&#123; ... &#125;)</span><br><span class="line">.on(<span class="string">'error'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">error</span>)</span>&#123; ... &#125;)</span><br><span class="line">.then(<span class="function"><span class="keyword">function</span>(<span class="params">receipt</span>)</span>&#123; <span class="comment">// will be fired once the receipt is mined &#125;);</span></span><br></pre></td></tr></table></figure>
<p><strong>4.2.3 应用二进制接口（ABI）</strong></p>
<ul>
<li>web3.js 通过以太坊智能合约的 json 接口（Application Binary Interface，ABI）创建一个 JavaScript 对象，用来在 js代码中描述\</li>
<li>函数（functions）</li>
<li>type：函数类型，默认“function”，也可能是“constructor”</li>
<li>constant, payable, stateMutability：函数的状态可变性</li>
<li>inputs, outputs: 函数输入、输出参数描述列表</li>
<li>事件（events）</li>
<li>type：类型，总是“event”</li>
<li>inputs：输入对象列表，包括 name、type、indexed</li>
</ul>
<p><strong>4.2.4 批处理请求（batch requests）</strong></p>
<ul>
<li>批处理请求允许我们将请求排序，然后一起处理它们。</li>
<li>注意：批量请求不会更快。实际上，在某些情况下，一次性地发出许多请求会更快，因为请求是异步处理的。</li>
<li>批处理请求主要用于确保请求的顺序，并串行处理。</li>
</ul>
 <figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> batch = web3.createBatch();</span><br><span class="line">batch.add(web3.eth.getBalance.request(<span class="string">'0x0000000000000000</span></span><br><span class="line"><span class="string">000000000000000000000000'</span>, <span class="string">'latest'</span>, callback));</span><br><span class="line">batch.add(web3.eth.contract(abi).at(address).balance.request(a</span><br><span class="line">ddress, callback2));</span><br><span class="line">batch.execute();</span><br></pre></td></tr></table></figure>
<p><strong>4.2.5 大数处理（big numbers）</strong></p>
<ul>
<li>JavaScript 中默认的数字精度较小，所以web3.js 会自动添加一个依赖库 BigNumber，专门用于大数处理</li>
<li><p>对于数值，我们应该习惯把它转换成 BigNumber 对象来处理</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> balance = <span class="keyword">new</span></span><br><span class="line">BigNumber(<span class="string">'131242344353464564564574574567456'</span>);</span><br><span class="line"><span class="comment">// or var balance = web3.eth.getBalance(someAddress);</span></span><br><span class="line">balance.plus(<span class="number">21</span>).toString(<span class="number">10</span>);</span><br><span class="line"><span class="comment">//"131242344353464564564574574567477"</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>BigNumber.toString(10) 对小数只保留20位浮点精度。所以推荐的做法是，我们内部总是用 wei 来表示余额（大整数），只有在需要显示给用户看的时候才转换为ether或其它单位</p>
</li>
</ul>
<h3 id="4-3-常用-API-——-基本信息查询"><a href="#4-3-常用-API-——-基本信息查询" class="headerlink" title="4.3 常用 API —— 基本信息查询"></a>4.3 常用 API —— 基本信息查询</h3><p><strong>4.3.1 查看 web3 版本</strong></p>
<ul>
<li>v0.2x.x：web3.version.api</li>
<li>v1.0.0：web3.version</li>
</ul>
<p>查看 web3 连接到的节点版本（ clientVersion ）</p>
<ul>
<li>同步：web3.version.node</li>
<li>异步：web3.version.getNode((error,result)=&gt;{console.log(result)})</li>
<li>v1.0.0：web3.eth.getNodeInfo().then(console.log)</li>
</ul>
<p><strong>4.3.2 基本信息查询</strong></p>
<p>获取 network id</p>
<ul>
<li>同步：web3.version.network</li>
<li>异步：web3.version.getNetwork((err, res)=&gt;{console.log(res)})</li>
<li>v1.0.0：web3.eth.net.getId().then(console.log)</li>
</ul>
<p>获取节点的以太坊协议版本</p>
<ul>
<li>同步：web3.version.ethereum</li>
<li>异步：web3.version.getEthereum((err, res)=&gt;{console.log(res)}</li>
<li>v1.0.0：web3.eth.getProtocolVersion().then(console.log)</li>
</ul>
<p><strong>4.3.3 网络状态查询</strong></p>
<p>是否有节点连接 / 监听，返回 true/false</p>
<ul>
<li>同步：web3.isConnect() 或者 web3.net.listening</li>
<li>异步：web3.net.getListening((err,res)=&gt;console.log(res))</li>
<li>v1.0.0：web3.eth.net.isListening().then(console.log)</li>
</ul>
<p>查看当前连接的 peer 节点</p>
<ul>
<li>同步：web3.net.peerCount</li>
<li>异步：web3.net.getPeerCount((err,res)=&gt;console.log(res))</li>
<li>v1.0.0：web3.eth.net.getPeerCount().then(console.log)</li>
</ul>
<p><strong>4.3.4 Provider</strong></p>
<p>查看当前设置的 web3 provider</p>
<ul>
<li>web3.currentProvider</li>
</ul>
<p>查看浏览器环境设置的 web3 provider （ v1.0.0 ）</p>
<ul>
<li>web3.givenProvider</li>
</ul>
<p>设置 provider</p>
<ul>
<li>web3.setProvider(provider)</li>
<li>web3.setProvider(new web3.providers.HttpProvider(‘<a href="http://localhost:8545" target="_blank" rel="noopener">http://localhost:8545</a>‘))</li>
</ul>
<h3 id="4-4-web3-通用工具方法"><a href="#4-4-web3-通用工具方法" class="headerlink" title="4.4 web3 通用工具方法"></a>4.4 web3 通用工具方法</h3><p>以太单位转换</p>
<ul>
<li>web3.fromWei web3.toWei数据类型转换</li>
<li>web3.toString web3.toDecimal web3.toBigNumber字符编码转换</li>
<li>web3.toHex web3.toAscii web3.toUtf8 web3.fromUtf8地址相关</li>
<li>web3.isAddress web3.toChecksumAddress</li>
</ul>
<h3 id="4-5-web3-eth"><a href="#4-5-web3-eth" class="headerlink" title="4.5 web3.eth"></a>4.5 web3.eth</h3><p><strong>4.5.1 账户相关</strong></p>
<p>coinbase 查询</p>
<ul>
<li>同步：web3.eth.coinbase</li>
<li>异步：web3.eth.getCoinbase( (err, res)=&gt;console.log(res) )</li>
<li>v1.0.0：web3.eth.getCoinbase().then(console.log)</li>
</ul>
<p>账户查询</p>
<ul>
<li>同步：web3.eth.accounts</li>
<li>异步：web3.eth.getAccounts( (err, res)=&gt;console.log(res) )</li>
<li>v1.0.0：web3.eth.getAccounts().then(console.log)</li>
</ul>
<p><strong>4.5.2 区块相关</strong></p>
<p>区块高度查询</p>
<ul>
<li>同步：web3.eth. blockNumber</li>
<li>异步：web3.eth.getBlockNumber( callback )</li>
</ul>
<p>gasPrice 查询</p>
<ul>
<li>同步：web3.eth.gasPrice</li>
<li>异步：web3.eth.getGasPrice( callback )</li>
</ul>
<p>区块查询</p>
<ul>
<li>同步：web3.eth.getBlockNumber( hashStringOrBlockNumber[ ,returnTransactionObjects] )</li>
<li>异步：web3.eth.getBlockNumber( hashStringOrBlockNumber, callback )</li>
</ul>
<p>块中交易数量查询</p>
<ul>
<li>同步：web3.eth.getBlockTransactionCount( hashStringOrBlockNumber )</li>
<li>异步：web3.eth.getBlockTransactionCount( hashStringOrBlockNumber, callback )</li>
</ul>
<p><strong>4.5.3 交易相关</strong></p>
<p>余额查询</p>
<ul>
<li>同步：web3.eth.getBalance(addressHexString [, defaultBlock])</li>
<li>异步：web3.eth.getBalance(addressHexString [, defaultBlock][, callback])</li>
</ul>
<p>交易查询</p>
<ul>
<li>同步：web3.eth.getTransaction(transactionHash)</li>
<li>异步：web3.eth.getTransaction(transactionHash [, callback])</li>
</ul>
<p>交易执行相关</p>
<ul>
<li>交易收据查询（已进块）</li>
<li>同步：web3.eth.getTransactionReceipt(hashString)</li>
<li>异步：web3.eth.getTransactionReceipt(hashString [,callback])</li>
<li>估计 gas 消耗量</li>
<li>同步：web3.eth.estimateGas(callObject)</li>
<li>异步：web3.eth.estimateGas(callObject [, callback])</li>
</ul>
<p><strong>4.5.4 发送交易</strong></p>
<ul>
<li>web3.eth.sendTransaction(transactionObject [, callback])</li>
<li>交易对象：</li>
<li>from：发送地址</li>
<li>to：接收地址，如果是创建合约交易，可不填</li>
<li>value：交易金额，以wei为单位，可选</li>
<li>gas：交易消耗 gas 上限，可选</li>
<li>gasPrice：交易 gas 单价，可选</li>
<li>data：交易携带的字串数据，可选</li>
<li>nonce：整数 nonce 值，可选</li>
</ul>
<p><strong>4.5.5 消息调用</strong></p>
<ul>
<li>web3.eth.call(callObject [, defaultBlock] [, callback])</li>
<li>参数：<ul>
<li>调用对象：与交易对象相同，只是from也是可选的</li>
<li>默认区块：默认“latest”，可以传入指定的区块高度</li>
<li>回调函数，如果没有则为同步调用</li>
</ul>
</li>
</ul>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> result = web3.eth.call(&#123; <span class="attr">to</span>:<span class="string">"0xc4abd0339eb8d57087278718986382264244252f"</span>,</span><br><span class="line">data:<span class="string">"0xc6888fa1000000000000000000000000000000000000000000000000000 0000000000003"</span> &#125;);</span><br><span class="line"><span class="built_in">console</span>.log(result);</span><br></pre></td></tr></table></figure>
<p><strong>4.5.6 日志过滤（事件监听）</strong><br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">web3.eth.filter( filterOptions [ , callback ] )</span><br><span class="line"><span class="comment">// filterString 可以是 'latest' or 'pending'</span></span><br><span class="line"><span class="keyword">var</span> filter = web3.eth.filter(filterString);</span><br><span class="line"><span class="comment">// 或者可以填入一个日志过滤 options</span></span><br><span class="line"><span class="keyword">var</span> filter = web3.eth.filter(options);</span><br><span class="line"><span class="comment">// 监听日志变化</span></span><br><span class="line">filter.watch(<span class="function"><span class="keyword">function</span>(<span class="params">error, result</span>)</span>&#123; <span class="keyword">if</span> (!error) <span class="built_in">console</span>.log(result); &#125;);</span><br><span class="line"><span class="comment">// 还可以用传入回调函数的方法，立刻开始监听日志</span></span><br><span class="line">web3.eth.filter(options, <span class="function"><span class="keyword">function</span>(<span class="params">error, result</span>)</span>&#123;</span><br><span class="line"><span class="keyword">if</span> (!error) <span class="built_in">console</span>.log(result);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p>
<p><strong>4.5.7 合约相关 —— 创建合约</strong></p>
<p>web3.eth.contract</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> MyContract = web3.eth.contract(abiArray);</span><br><span class="line"><span class="comment">// 通过地址初始化合约实例</span></span><br><span class="line"><span class="keyword">var</span> contractInstance = MyContract.at(address);</span><br><span class="line"><span class="comment">// 或者部署一个新合约</span></span><br><span class="line"><span class="keyword">var</span> contractInstance = MyContract.new([constructorParam1][, constructorParam2], &#123;<span class="attr">data</span>: <span class="string">'0x12345...'</span>, <span class="attr">from</span>:myAccount, <span class="attr">gas</span>: <span class="number">1000000</span>&#125;);</span><br></pre></td></tr></table></figure>
<p><strong>4.5.8 调用合约函数</strong></p>
<p>可以通过已创建的合约实例，直接调用合约函数</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 直接调用，自动按函数类型决定用 sendTransaction 还是 call</span></span><br><span class="line">myContractInstance.myMethod(param1 [, param2, ...] [,transactionObject] [, defaultBlock] [, callback]);</span><br><span class="line"><span class="comment">// 显式以消息调用形式 call 该函数</span></span><br><span class="line">myContractInstance.myMethod.call(param1 [, param2, ...] [,transactionObject] [, defaultBlock] [, callback]);</span><br><span class="line"><span class="comment">// 显式以发送交易形式调用该函数</span></span><br><span class="line">myContractInstance.myMethod.sendTransaction(param1 [,param2, ...] [, transactionObject] [, callback]);</span><br></pre></td></tr></table></figure>
<p><strong>4.5.9 监听合约事件</strong></p>
<p>合约的 event 类似于 filter，可以设置过滤选项来监听</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> event = myContractInstance.MyEvent(&#123;<span class="attr">valueA</span>: <span class="number">23</span>&#125;[, additionalFilterObject])</span><br><span class="line"><span class="comment">// 监听事件</span></span><br><span class="line">event.watch(<span class="function"><span class="keyword">function</span>(<span class="params">error, result</span>)</span>&#123; </span><br><span class="line"><span class="keyword">if</span> (!error) </span><br><span class="line">　　<span class="built_in">console</span>.log(result); </span><br><span class="line">&#125;);</span><br><span class="line"><span class="comment">// 还可以用传入回调函数的方法，立刻开始监听事件</span></span><br><span class="line"><span class="keyword">var</span> event = myContractInstance.MyEvent([&#123;<span class="attr">valueA</span>: <span class="number">23</span>&#125;][, additionalFilterObject] , <span class="function"><span class="keyword">function</span>(<span class="params">error, result</span>)</span>&#123;</span><br><span class="line">　　<span class="keyword">if</span> (!error) <span class="built_in">console</span>.log(result);</span><br><span class="line">&#125;</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<h2 id="5、交互实现——部署智能合约"><a href="#5、交互实现——部署智能合约" class="headerlink" title="5、交互实现——部署智能合约"></a>5、交互实现——部署智能合约</h2><p>通过编写一个depoly.js程序实现自动化的部署智能合约。首先要保持Geth客户端正常运行，并开启rpc。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">geth --identity <span class="string">"TestNode"</span> --rpc --rpcport <span class="string">"8545"</span> --datadir data0 --port <span class="string">"30303"</span> --nodiscover --networkid <span class="number">6666</span> --rpcapi admin,eth,miner,personal,txpool,eth,web3,net <span class="built_in">console</span></span><br></pre></td></tr></table></figure>
<p>合约应该在智能合约编译器（如remix）调试好，然后将其写到test.sol文件里。<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br><span class="line">contract TestContract</span><br><span class="line">&#123;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">multiply</span>(<span class="params">uint a, uint b</span>) <span class="title">returns</span> (<span class="params">uint</span>)</span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> a * b;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>使用solc模块生成合约的code和abi，我将该过程自定义为一个模块test.js，方便depoly.js调用。<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> fs = <span class="built_in">require</span>(<span class="string">'fs'</span>);</span><br><span class="line"><span class="keyword">var</span> solc = <span class="built_in">require</span>(<span class="string">'solc'</span>);</span><br><span class="line"><span class="comment">//compile smart contract to get bytecode and abi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> source = fs.readFileSync(<span class="string">"./test.sol"</span>,<span class="string">'utf8'</span>);  <span class="comment">//读取代码</span></span><br><span class="line">    <span class="comment">//console.log("compiling contract...");</span></span><br><span class="line"><span class="keyword">var</span> compiledcontract = solc.compile(source); <span class="comment">//编译</span></span><br><span class="line">    <span class="comment">//console.log('done');</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">var</span> contractName <span class="keyword">in</span> compiledcontract.contracts)&#123;</span><br><span class="line">    <span class="keyword">var</span> bytecode = compiledcontract.contracts[contractName].bytecode;</span><br><span class="line">    <span class="keyword">var</span> abi = <span class="built_in">JSON</span>.parse(compiledcontract.contracts[contractName].interface);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//console.log(JSON.stringify(abi, undefined, 2));</span></span><br><span class="line"><span class="comment">//console.log(bytecode);</span></span><br><span class="line"><span class="comment">//console.log(abi);</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">bytecode</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(bytecode);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">abi</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(abi);</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">module</span>.exports = &#123;<span class="attr">bytecode</span>:bytecode,<span class="attr">abi</span>:abi&#125;;</span><br></pre></td></tr></table></figure><br>depoly.js通过与Geth交互部署智能合约。当合约被区块链确认后，会直接返回合约地址。<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> Web3 = <span class="built_in">require</span>(<span class="string">'web3'</span>);</span><br><span class="line"><span class="keyword">var</span> contract = <span class="built_in">require</span>(<span class="string">'./test'</span>);</span><br><span class="line"><span class="keyword">var</span> web;</span><br><span class="line"></span><br><span class="line"><span class="comment">//connect to node</span></span><br><span class="line"><span class="keyword">var</span> ethereumUri = <span class="string">'http://localhost:8545'</span>;</span><br><span class="line"><span class="keyword">if</span> (<span class="keyword">typeof</span> web3 !== <span class="string">'undefined'</span>) &#123;</span><br><span class="line">    web3 = <span class="keyword">new</span> Web3(web3.currentProvider);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// set the provider you want from Web3.providers</span></span><br><span class="line">    web3 = <span class="keyword">new</span> Web3(<span class="keyword">new</span> Web3.providers.HttpProvider(ethereumUri));</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//查询区块链中基本的账户信息</span></span><br><span class="line"><span class="keyword">if</span>(!web3.isConnected())&#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="built_in">Error</span>(<span class="string">'unable to connect to ethereum node at '</span>+ ethereumUri);</span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">'connected to etherum node at '</span>+ ethereumUri);</span><br><span class="line">    <span class="keyword">var</span> coinbase = web3.eth.accounts[<span class="number">0</span>];</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">'coinbase:'</span> + coinbase);</span><br><span class="line">    <span class="keyword">var</span> balance = web3.eth.getBalance(coinbase);</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">'balance:'</span> + web3.fromWei(balance, <span class="string">'ether'</span>) + <span class="string">" ETH"</span>);</span><br><span class="line">    <span class="keyword">var</span> accounts = web3.eth.accounts;</span><br><span class="line">    <span class="built_in">console</span>.log(accounts);    </span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//通过coinbase部署智能合约</span></span><br><span class="line"><span class="keyword">var</span> abi = contract.abi;</span><br><span class="line"><span class="keyword">var</span> bytecode = contract.bytecode;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (web3.personal.unlockAccount(coinbase, <span class="string">'123'</span>)) &#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">`<span class="subst">$&#123;coinbase&#125;</span> is unlocaked`</span>);</span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">`unlock failed, <span class="subst">$&#123;coinbase&#125;</span>`</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> gasEstimate = web3.eth.estimateGas(&#123;<span class="attr">data</span>: <span class="string">'0x'</span> + bytecode&#125;); <span class="comment">//gas估计</span></span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'gasEstimate = '</span> + gasEstimate);</span><br><span class="line"><span class="keyword">var</span> MyContract = web3.eth.contract(abi);</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'deploying contract...'</span>);</span><br><span class="line"><span class="keyword">var</span> myContractReturned = MyContract.new(&#123;</span><br><span class="line">    <span class="keyword">from</span>: coinbase,</span><br><span class="line">    data: <span class="string">'0x'</span>+ bytecode,</span><br><span class="line">    gas: gasEstimate + <span class="number">50000</span></span><br><span class="line">&#125;, <span class="function"><span class="keyword">function</span> (<span class="params">err, myContract</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!err) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!myContract.address) &#123;</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">`myContract.transactionHash = <span class="subst">$&#123;myContract.transactionHash&#125;</span>`</span>); <span class="comment">// The hash of the transaction, which deploys the contract</span></span><br><span class="line">        <span class="comment">// check address on the second call (contract deployed)</span></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">`myContract.address = <span class="subst">$&#123;myContract.address&#125;</span>`</span>); <span class="comment">// the contract address</span></span><br><span class="line">            global.contractAddress = myContract.address;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">console</span>.log(err);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p>
<p><strong>参考自：</strong></p>
<p><a href="https://geth.ethereum.org/docs/install-and-build/installing-geth" target="_blank" rel="noopener">Go Ethereum</a></p>
<p><a href="https://www.jianshu.com/p/9fa31e4cdf4d" target="_blank" rel="noopener">以太坊私有链Geth控制台操作教程</a></p>
<p><a href="https://www.bilibili.com/video/BV1sJ411D72u" target="_blank" rel="noopener">尚硅谷区块链全套Go语言→GoWeb→以太坊→项目实战</a><br><a href="http://cw.hubwiz.com/card/c/web3.js-1.0/" target="_blank" rel="noopener">web3.js 1.0中文手册</a></p>
]]></content>
      <categories>
        <category>Blockchain</category>
      </categories>
  </entry>
  <entry>
    <title>区块链入门（三）Solidity基础</title>
    <url>/posts/f6ff6959.html</url>
    <content><![CDATA[<font color="red"> 注：本教程为技术教程，不谈论且不涉及炒作任何数字货币 </font>

<h1 id="Solidity-入门教学"><a href="#Solidity-入门教学" class="headerlink" title="Solidity 入门教学"></a>Solidity 入门教学</h1><h2 id="1、-简介"><a href="#1、-简介" class="headerlink" title="1、 简介"></a>1、 简介</h2><h3 id="1-1-Solidity是什么"><a href="#1-1-Solidity是什么" class="headerlink" title="1.1 Solidity是什么"></a>1.1 Solidity是什么</h3><ul>
<li>Solidity 是一门面向合约的、为实现智能合约而创建的高级编程语言。这门语言受到了 C++，Python 和 Javascript 语言的影响，设计的目的是能在以太坊虚拟机（EVM）上运行。</li>
<li>Solidity 是静态类型语言，支持继承、库和复杂的用户定义类型等特性。</li>
<li>内含的类型除了常见编程语言中的标准类型，还包括 <code>address</code>等以太坊独有的类型，Solidity 源码文件通常以 .sol 作为扩展名</li>
<li>目前尝试 Solidity 编程的推荐方式是使用 Remix。Remix是一个基于 Web 浏览器的 IDE，它可以让你编写 Solidity 智能合约，然后部署并运行该智能合约。</li>
</ul>
<h3 id="1-2-Solidity语言特性"><a href="#1-2-Solidity语言特性" class="headerlink" title="1.2 Solidity语言特性"></a>1.2 Solidity语言特性</h3><p>Solidity的语法接近于JavaScript，是一种面向对象的语言。但作为一种真正意义上运行在网络上的去中心合约，它又有很多的不同：</p>
<ul>
<li>以太坊底层基于帐户，而不是 <a href="https://cloud.tencent.com/developer/article/1367743" target="_blank" rel="noopener">UTXO</a>，所以增加了一个特殊的address 的数据类型用于定位用户和合约账户。</li>
<li>语言内嵌框架支持支付。提供了 <code>payable</code> 等关键字，可以在语言层面直接支持支付。</li>
<li>使用区块链进行数据存储。数据的每一个状态都可以永久存储，所以在使用时需要确定变量使用内存，还是区块链存储。</li>
<li>运行环境是在去中心化的网络上，所以需要强调合约或函数执行的调用的方式。</li>
<li>不同的异常机制。一旦出现异常，所有的执行都将会被回撤，这主要是为了保证合约执行的原子性，以避免中间状态出现的数据不一致。</li>
</ul>
<h3 id="1-3-Solidity源码和智能合约"><a href="#1-3-Solidity源码和智能合约" class="headerlink" title="1.3 Solidity源码和智能合约"></a>1.3 Solidity源码和智能合约</h3><p>Solidity 源代码要成为可以运行在以太坊上的智能合约需要经历如下的</p>
<p><strong>步骤：</strong></p>
<ol>
<li>用 Solidity 编写的智能合约源代码需要先使用编译器编译为字节码（Bytecode），编译过程中会同时产生智能合约的二进制接口规范（Application Binary Interface，简称为ABI）；</li>
<li>通过交易（Transaction）的方式将字节码部署到以太坊网络，每次成功部署都会产生一个新的智能合约账户；</li>
<li>使用 Javascript 编写的 DApp 通常通过 web3.js + ABI去调用智能合约中的函数来实现数据的读取和修改。</li>
</ol>
<h3 id="1-4-合约结构"><a href="#1-4-合约结构" class="headerlink" title="1.4 合约结构"></a>1.4 合约结构</h3><ul>
<li>状态变量（State Variables）作为合约状态的一部分，值会永久保存在存储空间内。</li>
<li>函数（Functions）合约中可执行的代码块。</li>
<li>函数修饰器（Function Modifiers）在函数声明中，用来补充修饰函数的语义。</li>
<li>事件（Events）非常方便的 EVM 日志工具接口。</li>
</ul>
<h2 id="2、-Solidity编译器安装以及简单使用"><a href="#2、-Solidity编译器安装以及简单使用" class="headerlink" title="2、 Solidity编译器安装以及简单使用"></a>2、 Solidity编译器安装以及简单使用</h2><p>Remix 是一个开源的 IDE,是一个浏览器在线编辑器。作为 Solidity 智能合约开发环境，Solidity IDE  Remix(在线浏览器编辑器)提供基本的编译、部署至本地或测试网络、执行合约等功能。</p>
<h3 id="2-1-remix安装以及使用"><a href="#2-1-remix安装以及使用" class="headerlink" title="2.1 remix安装以及使用"></a>2.1 remix安装以及使用</h3><ol>
<li><strong>浏览器端配置</strong></li>
</ol>
<p>在浏览器端有俩个选择，分别为英文版与中文版（有些许差别）</p>
<ul>
<li><p>Remix中文版地址：<a href="http://remix.hubwiz.com" target="_blank" rel="noopener">http://remix.hubwiz.com</a></p>
</li>
<li><p>Remix英文版地址（<strong>推荐</strong>）：<a href="https://remix.ethereum.org/" target="_blank" rel="noopener">https://remix.ethereum.org/</a></p>
</li>
</ul>
<p><strong>PS.可能需要科学上网</strong></p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-1.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 1</div>
</center>



<p>下面都以<code>英文版</code>为例子介绍</p>
<p>1、<strong>浏览器输入 <a href="https://remix.ethereum.org/" target="_blank" rel="noopener">https://remix.ethereum.org/</a></strong></p>
<p>如果出现加载慢，加载不完全的情况，刷新几次即可</p>
<p>2、左侧可以看到我们所有的文件，下面是我们的remix控制台</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-2.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 2</div>
</center>



<p>上图小图标从左到右依次为：</p>
<ul>
<li>创建新文件</li>
<li>创建新文件夹</li>
<li>Github代码片段分享</li>
<li>表示打开一个本地文件</li>
</ul>
<p>控制台图片如下：</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-3.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 3</div>
</center>



<ul>
<li>1 从左至右表示隐藏控制台、清除控制台输出、pending的交易数量</li>
<li>2 表示监听所有交易</li>
<li>3 表示搜索框</li>
<li>4 表示输出区域</li>
<li>5 表示使用JavaScript与以太坊交互的区域，可以使用Web3对象</li>
</ul>
<p>3、点击文件样式图标输入我们的文件名即可(以.sol为后缀)</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-4.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 4</div>
</center>


<p>4、安装必要的插件</p>
<p>点击插件管理器，页面中为这个图标</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-5.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 5</div>
</center>




<ul>
<li><p>安装compiler</p>
<p>  搜索关键字compiler</p>
<center>
  <img style="border-radius: 0.3125em;
  box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-6.png">
  <br>
  <div style="color:orange; border-bottom: 1px solid #d9d9d9;
  display: inline-block;
  color: #999;
  padding: 2px;">图 6</div>
</center>



</li>
</ul>
<p>5、写一个简单的样例</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br><span class="line"></span><br><span class="line">contract SimpleStorage &#123;</span><br><span class="line">    uint storedData;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">set</span>(<span class="params">uint x</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        storedData = x;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">get</span>(<span class="params"></span>) <span class="title">public</span> <span class="title">view</span> <span class="title">returns</span> (<span class="params">uint</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> storedData;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>第一行就是告诉大家源代码使用Solidity版本0.4.0写的，并且使用0.4.0以上版本运行也没问题（最高到0.5.0，但是不包含0.5.0）。这是为了确保合约不会在新的编译器版本中突然行为异常。关键字 <code>pragma</code> 的含义是，一般来说，pragmas（编译指令）是告知编译器如何处理源代码的指令的。</p>
<p>Solidity中合约的含义就是一组代码（它的 函数 )和数据（它的 状态 ），它们位于以太坊区块链的一个特定地址上。 代码行 <code>uint storedData</code>; 声明一个类型为 <code>uint</code> (256位无符号整数）的状态变量，叫做 <code>storedData</code> 。 你可以认为它是数据库里的一个位置，可以通过调用管理数据库代码的函数进行查询和变更。对于以太坊来说，上述的合约就是拥有合约（owning contract）。在这种情况下，函数 <code>set</code> 和 <code>get</code> 可以用来变更或取出变量的值。</p>
<p>要访问一个状态变量，并不需要像 <code>this.</code> 这样的前缀，虽然这是其他语言常见的做法。</p>
<p>该合约能完成的事情并不多（由于以太坊构建的基础架构的原因）：它能允许任何人在合约中存储一个单独的数字，并且这个数字可以被世界上任何人访问，且没有可行的办法阻止你发布这个数字。当然，任何人都可以再次调用 <code>set</code> ，传入不同的值，覆盖你的数字，但是这个数字仍会被存储在区块链的历史记录中。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-7.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 7</div>
</center>



<p>点击<code>compile test.sol</code>，可以看到编译按钮，建议将<code>Auto compile</code>打钩（自动编译）,之后会在编译图标上看到一个以绿色为背景的对勾。</p>
<p>编译组件说明：</p>
<ul>
<li><code>Compiler</code>可以选择Solidity的编译器版本</li>
<li><code>Language</code>可以选择编程语言</li>
<li><code>EVM Version</code>可以选择EVM虚拟机版本</li>
<li><code>Auto compile</code>可以设置自动编译，修改完代码后自动执行编译操作</li>
<li><code>Enable optimization</code>可以设置对编译进行优化</li>
<li><code>Hide warnings</code>可以设置隐藏警告信息。</li>
<li><code>Contract</code>选择需要编译的合约</li>
<li><code>Publish on Swarm</code>和<code>Publish on Ipfs</code>分别将合约上传到Swarm和Ipfs这两个分布式文件系统上去</li>
<li><code>Compilation Details</code>很重要，可以查看编译的信息，包括ABI、字节码、函数Hash等</li>
<li><code>ABI</code>和<code>Bytecode</code>分别复制ABI和字节码。</li>
<li>再下面的部分空白用来显示编译的Warnings和Errors。</li>
</ul>
<p>我们点击<code>Compilation Details</code>就能看到编译之后的一些信息，如下图所示（部分）</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-8.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 8</div>
</center>


<ul>
<li><code>NAME</code>：合约名</li>
<li><code>METADATA</code>：一些编译相关的信息，比如版本、所用的语言、设置等</li>
<li><code>BYTECODE</code>：写入区块的字节码</li>
<li><code>ABI</code>：此智能合约对应的 ABI ，也就是我们合约里面定义的一些接口</li>
<li><code>WEB3DEPLOY</code>：智能合约编译之后的发布命令，这个就是比较重要的，之后的web3就是调用这段命令来部署合约的</li>
<li><code>METADATAHASH</code>：数据的一个哈希值</li>
<li><code>SWARMLOCATION</code>：Swarm网络的一个地址</li>
<li><code>FUNCTIONHASHES</code>：合约定义的方法的hash，其实我们执行合约的时候就是通过这个hash去找到对应的方法进行执行的</li>
<li><code>GASESTIMATES</code>：关于矿工费的一个预算，在ETH上进行合约的部署，执行等都是需要矿工费的。一般合约代码越多矿工费越高。</li>
</ul>
<p>点击下面的run图标，可以看到部署，以及账户信息，环境等等</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-9.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 9</div>
</center>



<p>点击deploy之后天可以看到自己的合约已经部署完成，打开之后可以看见我们写的函数<code>set</code>,<code>get</code>了，给<code>set</code>函数输入一个值，点击<code>get</code>会得到相应的值</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-10.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 10</div>
</center>



<ul>
<li><code>Environment</code> 表示合约部署的环境。<code>Javascript VM</code>是虚拟了一个节点，而<code>Injected Web3</code>和<code>Web3 Provider</code>则真正连接一个节点。</li>
<li><code>Account</code>代表不同的虚拟账户，每个虚拟账户每个有 100 ETH</li>
<li><code>Deploy</code>表示合约部署按钮</li>
<li><code>Deployed Contracts</code>表示已经部署的合约</li>
</ul>
<p>中文版界面与英文版界面有些许不一致，但都大同小异，想了解同学可以查看本博客(界面与中文版大致相同）：<br><a href="https://cloud.tencent.com/developer/article/1182404" target="_blank" rel="noopener">Solidity语言编辑器REMIX指导大全</a></p>
<ol>
<li><strong>本地配置：</strong><ul>
<li><a href="https://cloud.tencent.com/developer/article/1374376" target="_blank" rel="noopener">win下</a></li>
<li><a href="https://blog.csdn.net/qq_41944960/article/details/100134020" target="_blank" rel="noopener">ubuntu下</a></li>
</ul>
</li>
</ol>
<ol>
<li><strong>Docker</strong></li>
</ol>
<p>我们为编译器提供了最新的docker构建。 stable 仓库里的是已发布的版本，nightly 仓库则是在开发分支中的带有不稳定变更的版本。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run ethereum&#x2F;solc:stable solc --version</span><br></pre></td></tr></table></figure>
<p>目前，docker 镜像只含有 solc 的可执行程序，因此你需要额外的工作去把源代码和输出目录连接起来。</p>
<h2 id="3、Solidity基础操作"><a href="#3、Solidity基础操作" class="headerlink" title="3、Solidity基础操作"></a>3、Solidity基础操作</h2><p><strong>由于篇幅有限，以下只会讲解一些较基础、重要的概念(足够后面使用)，有些可能会一带而过或者“忽略”，如果大家途中有没太明白地方建议先百度、Google，或者查看此教程<a href="https://solidity-cn.readthedocs.io/zh/develop/index.html" target="_blank" rel="noopener">Solifity中文文档</a>、<a href="https://remix-ide.readthedocs.io/en/latest/index.html" target="_blank" rel="noopener">Solidity英文文档</a></strong></p>
<h3 id="3-1-Solidity源文件布局"><a href="#3-1-Solidity源文件布局" class="headerlink" title="3.1 Solidity源文件布局"></a>3.1 Solidity源文件布局</h3><p><strong>源文件可以被版本杂注pragma所注解，表明要求的编译器版本</strong></p>
<ul>
<li>例如：<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br></pre></td></tr></table></figure>
这样，源文件将既不允许低于 0.4.0 版本的编译器编译， 也不允许高于（包含） 0.5.0 版本的编译器编译（第二个条件因使用 ^ 被添加）。 这种做法的考虑是，编译器在 0.5.0 版本之前不会有重大变更，所以可确保源代码始终按预期被编译。 上面例子中不固定编译器的具体版本号，因此编译器的补丁版也可以使用。</li>
</ul>
<p><strong>import（导入其它源文件）</strong></p>
<ul>
<li>Solidity 所支持的导入语句import，语法同 JavaScript（从ES6 起）非常类似</li>
</ul>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">"filename"</span>;</span><br></pre></td></tr></table></figure>
<p>从“filename”中导入所有的全局符号到当前全局作用域中<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> * <span class="keyword">as</span> symbolName <span class="keyword">from</span> <span class="string">"filename"</span>;</span><br></pre></td></tr></table></figure><br>创建一个新的全局符号 symbolName，其成员均来自 “filename”中全局符号<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123;symbol1 <span class="keyword">as</span> alias, symbol2&#125; <span class="keyword">from</span> <span class="string">"filename"</span>;</span><br></pre></td></tr></table></figure><br>创建新的全局符号 alias 和 symbol2，分别从 “filename” 引用 symbol1 和 symbol2<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">"filename"</span> <span class="keyword">as</span> symbolName;</span><br></pre></td></tr></table></figure><br>这条语句等同于 import * as symbolName from “filename”;</p>
<p><strong>注释</strong></p>
<p>可以使用单行注释（//）和多行注释（/<em>…</em>/）</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 这是一个单行注释。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">这是一个</span></span><br><span class="line"><span class="comment">多行注释。</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>
<h3 id="3-2-数据类型与运算符"><a href="#3-2-数据类型与运算符" class="headerlink" title="3.2 数据类型与运算符"></a>3.2 数据类型与运算符</h3><h3 id="3-2-1-Solidity值类型介绍"><a href="#3-2-1-Solidity值类型介绍" class="headerlink" title="3.2.1 Solidity值类型介绍"></a>3.2.1 Solidity值类型介绍</h3><ul>
<li><strong>布尔（bool）</strong>：</li>
</ul>
<p>可能的取值为字符常量值 true 或 false</p>
<p>例子：<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br><span class="line"></span><br><span class="line">contract helloworld &#123;</span><br><span class="line">    bool boola=<span class="literal">true</span>; <span class="comment">//声明一个布尔类型的值，只用一个等号</span></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">booltesta</span>(<span class="params"></span>) <span class="title">public</span> <span class="title">view</span> <span class="title">returns</span>(<span class="params">bool</span>)</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> boola;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">booltestb</span>(<span class="params">int a,int b</span>) <span class="title">public</span> <span class="title">pure</span> <span class="title">returns</span>(<span class="params">bool</span>)</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> a==b;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-12.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 11</div>
</center>



<ul>
<li>整型（int/uint）**：</li>
</ul>
<p><code>int</code> / <code>uint</code> ：分别表示有符号和无符号的不同位数的整型变量。 支持关键字 <code>uint8</code> 到 <code>uint256</code> （无符号，从 8 位到 256 位）以及 <code>int8</code> 到 <code>int256</code>，以 8 位为步长递增。 <code>uint</code> 和 <code>int</code> 分别是 <code>uint256</code> 和 <code>int256</code> 的别名。</p>
<ul>
<li><strong>定长浮点型（fixed / ufixed）</strong>： </li>
</ul>
<p><code>fixed</code>/ <code>ufixed</code>：表示各种大小的有符号和无符号的定长浮点型。 在关键字 <code>ufixedMxN</code> 和 <code>fixedMxN</code> 中，<code>M</code> 表示该类型占用的位数，<code>N</code> 表示可用的小数位数。 <code>M</code>必须能整除 8，即 8 到 256 位。 <code>N</code>则可以是从 0 到 80 之间的任意数。 <code>ufixed</code> 和 <code>fixed</code> 分别是 <code>ufixed128x19</code> 和 <code>fixed128x19</code> 的别名。</p>
<ul>
<li><strong>地址（address 重点，后面细讲）</strong>：</li>
</ul>
<p>地址类型存储一个 20 字节的值（以太坊地址的大小）。 地址类型也有成员变量，并作为所有合约的基础。</p>
<p> <strong>地址类型成员变量</strong>:<code>balance</code> 和 <code>transfer</code></p>
<p> 可以使用 balance 属性来查询一个地址的余额， 也可以使用 transfer 函数向一个地址发送 以太币 （以 wei 为单位）：</p>
 <figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">address x = <span class="number">0x123</span>;</span><br><span class="line">address myAddress = <span class="keyword">this</span>;</span><br><span class="line"><span class="keyword">if</span> (x.balance &lt; <span class="number">10</span> &amp;&amp; myAddress.balance &gt;= <span class="number">10</span>) x.transfer(<span class="number">10</span>);</span><br></pre></td></tr></table></figure>
<p>注：如果 <code>x</code> 是一个合约地址，它的代码（更具体来说是它的 fallback 函数，如果有的话）会跟 <code>transfer</code> 函数调用一起执行（这是 EVM 的一个特性，无法阻止）。 如果在执行过程中用光了 gas 或者因为任何原因执行失败，以太币 交易会被打回，当前的合约也会在终止的同时抛出异常。</p>
<ul>
<li><strong>定长字节数组</strong>：</li>
</ul>
<p>关键字有 bytes1， bytes2， bytes3， …， bytes32<br><code>.length</code> 表示这个字节数组的长度（只读）.</p>
<p>注：可以将 <code>byte[]</code> 当作字节数组使用，但这种方式非常浪费存储空间，准确来说，是在传入调用时，每个元素会浪费 31 字节。 更好地做法是使用 <code>bytes</code>。</p>
<ul>
<li><strong>变长字节数组</strong></li>
</ul>
<p><code>bytes</code>:变长字节数组。它并不是值类型。</p>
<p><code>string</code>:变长 UTF-8 编码字符串类型。并不是值类型。 </p>
<ul>
<li><strong>地址字面常数（Address Literals）</strong></li>
</ul>
<p>比如像 <code>0xdCad3a6d3569DF655070DEd06cb7A1b2Ccd1D3AF</code> 这样的通过了地址校验和测试的十六进制字面常数属于 <code>address</code> 类型。 长度在 39 到 41 个数字的，没有通过校验和测试而产生了一个警告的十六进制字面常数视为正常的有理数字面常数。</p>
<ul>
<li><strong>有理数和整数字面常数</strong></li>
</ul>
<p>整数字面常数由范围在 0-9 的一串数字组成，表现成十进制。 例如，69 表示数字 69。 Solidity 中是没有八进制的，因此前置 0 是无效的。</p>
<p>十进制小数字面常数带有一个 .，至少在其一边会有一个数字。 比如：<code>1.，.1</code>，和 <code>1.3</code>。</p>
<p>科学符号也是支持的，尽管指数必须是整数，但底数可以是小数。 比如：<code>2e10， -2e10， 2e-10， 2.5e1</code>。</p>
<p>数值字面常数表达式本身支持任意精度，除非它们被转换成了非字面常数类型（也就是说，当它们出现在非字面常数表达式中时就会发生转换）。 这意味着在数值常量表达式中, 计算不会溢出而除法也不会截断。</p>
<p>例如， <code>(2**800 + 1) - 2**800</code> 的结果是字面常数 1 （属于 <code>uint8</code> 类型），尽管计算的中间结果已经超过了 以太坊虚拟机 的机器字长度。 此外， <code>.5 * 8</code> 的结果是整型 4 （尽管有非整型参与了计算）</p>
<ul>
<li><strong>字符串字面常数</strong></li>
</ul>
<p>字符串字面常数是指由双引号或单引号引起来的字符串（<code>&quot;foo&quot;</code>或者 <code>&#39;bar&#39;</code>）。 不像在 C 语言中那样带有结束符；<code>&quot;foo&quot;</code> 相当于 3 个字节而不是 4 个。 和整数字面常数一样，字符串字面常数的类型也可以发生改变，但它们可以隐式地转换成 <code>bytes1，……，bytes32</code>，如果合适的话，还可以转换成 <code>bytes</code> 以及 <code>string</code>。</p>
<ul>
<li><strong>十六进制字面常数</strong></li>
</ul>
<p>十六进制字面常数以关键字 <code>hex</code> 打头，后面紧跟着用单引号或双引号引起来的字符串（例如，<code>hex&quot;001122FF&quot;</code>）。 字符串的内容必须是一个十六进制的字符串，它们的值将使用二进制表示。</p>
<ul>
<li><strong>枚举（enum）</strong>：</li>
</ul>
<p>一种用户可以定义类型的方法，与C语言类似，默认从0开始递增，一般用来模拟合约的状态</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.16</span>;</span><br><span class="line"></span><br><span class="line">contract test &#123;</span><br><span class="line">    enum ActionChoices &#123; GoLeft, GoRight, GoStraight, SitStill &#125;；</span><br><span class="line">    ActionChoices choice;</span><br><span class="line">    ActionChoices constant defaultChoice = ActionChoices.GoStraight;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">setGoStraight</span>(<span class="params"></span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        choice = ActionChoices.GoStraight;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 由于枚举类型不属于 |ABI| 的一部分，因此对于所有来自 Solidity 外部的调用，</span></span><br><span class="line">    <span class="comment">// "getChoice" 的签名会自动被改成 "getChoice() returns (uint8)"。</span></span><br><span class="line">    <span class="comment">// 整数类型的大小已经足够存储所有枚举类型的值，随着值的个数增加，</span></span><br><span class="line">    <span class="comment">// 可以逐渐使用 `uint16` 或更大的整数类型。</span></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">getChoice</span>(<span class="params"></span>) <span class="title">public</span> <span class="title">view</span> <span class="title">returns</span> (<span class="params">ActionChoices</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> choice;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">getDefaultChoice</span>(<span class="params"></span>) <span class="title">public</span> <span class="title">pure</span> <span class="title">returns</span> (<span class="params">uint</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> uint(defaultChoice);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>函数（function）</strong>：</li>
</ul>
<p>函数类型是一种表示函数的类型。可以将一个函数赋值给另一个函数类型的变量，也可以将一个函数作为参数进行传递，还能在函数调用中返回函数类型变量。 函数类型有两类：- 内部（<code>internal</code>） 函数和 外部（<code>external</code>） 函数：</p>
<p>内部函数只能在当前合约内被调用（更具体来说，在当前代码块内，包括内部库函数和继承的函数中），因为它们不能在当前合约上下文的外部被执行。 调用一个内部函数是通过跳转到它的入口标签来实现的，就像在当前合约的内部调用一个函数。</p>
<p>外部函数由一个地址和一个函数签名组成，可以通过外部函数调用传递或者返回。</p>
<p>函数类型表示成如下的形式</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="\Pic\Blockchain_Pic\part2-11.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 12</div>
</center>



<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> (<span class="params">&lt;parameter types&gt;</span>) </span>&#123;internal|external&#125; [pure|constant|view|payable] [returns (<span class="xml"><span class="tag">&lt;<span class="name">return</span> <span class="attr">types</span>&gt;</span>)]</span></span><br></pre></td></tr></table></figure>
<p>与参数类型相反，返回类型不能为空 —— 如果函数类型不需要返回，则需要删除整个 <code>returns (&lt;return types&gt;)</code> 部分。</p>
<p>函数类型默认是内部函数，因此不需要声明 <code>internal</code> 关键字。 与此相反的是，合约中的函数本身默认是 <code>public</code>的，只有当它被当做类型名称时，默认才是内部函数。</p>
<p>有两种方法可以访问当前合约中的函数：一种是直接使用它的名字，<code>f</code> ，另一种是使用 <code>this.f</code> 。 前者适用于内部函数，后者适用于外部函数。</p>
<p>如果当函数类型的变量还没有初始化时就调用它的话会引发一个异常。 如果在一个函数被 <code>delete</code> 之后调用它也会发生相同的情况。</p>
<p>如果外部函数类型在 Solidity 的上下文环境以外的地方使用，它们会被视为 <code>function</code> 类型。 该类型将函数地址紧跟其函数标识一起编码为一个 <code>bytes24</code> 类型。</p>
<p>请注意，当前合约的 public 函数既可以被当作内部函数也可以被当作外部函数使用。 如果想将一个函数当作内部函数使用，就用 <code>f</code> 调用，如果想将其当作外部函数，使用 <code>this.f</code> 。</p>
<p><strong>Solidity函数可见性</strong></p>
<p>函数的可见性可以指定为 external，public ，internal 或者 private；对于状态变量，不能设置为 external ，默认是 internal。</p>
<ul>
<li>external ：外部函数作为合约接口的一部分，意味着我们可以从其他合约和交易中调用。 一个外部函数 f不能从内部调用（即 f 不起作用，但 this.f() 可以）。 当收到大量数据的时候，外部函数有时候会更有效率。</li>
<li>public ：public 函数是合约接口的一部分，可以在内部或通过消息调用。对于 public 状态变量， 会自动生成一个 getter 函数。</li>
<li>internal ：这些函数和状态变量只能是内部访问（即从当前合约内部或从它派生的合约访问），不使用 this 调用。</li>
<li>private ：private 函数和状态变量仅在当前定义它们的合约中使用，并且不能被派生合约使用。</li>
</ul>
<p><strong>Solidity函数状态可变性</strong></p>
<ul>
<li>pure：纯函数，不允许修改或访问状态</li>
<li>view：不允许修改状态</li>
<li>payable：允许从消息调用中接收以太币Ether 。</li>
<li>constant：与view相同，一般只修饰状态变量，不允许赋值（除初始化以外）</li>
</ul>
<p><strong>内部函数调用</strong></p>
<p>当前合约中的函数可以直接（“从内部”）调用，也可以递归调用，就像下边这个荒谬的例子一样<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.16</span>;</span><br><span class="line"></span><br><span class="line">contract C &#123;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">g</span>(<span class="params">uint a</span>) <span class="title">public</span> <span class="title">pure</span> <span class="title">returns</span> (<span class="params">uint ret</span>) </span>&#123; <span class="keyword">return</span> f(); &#125;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params"></span>) <span class="title">internal</span> <span class="title">pure</span> <span class="title">returns</span> (<span class="params">uint ret</span>) </span>&#123; <span class="keyword">return</span> g(<span class="number">7</span>) + f(); &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>这些函数调用在 EVM 中被解释为简单的跳转。这样做的效果就是当前内存不会被清除，也就是说，通过内部调用在函数之间传递内存引用是非常有效的。</p>
<p><strong>外部函数调用</strong></p>
<p>表达式 <code>this.g(8)</code>; 和 <code>c.g(2)</code>; （其中 c 是合约实例）也是有效的函数调用，但是这种情况下，函数将会通过一个消息调用来被“外部调用”，而不是直接的跳转。 请注意，不可以在构造函数中通过 this 来调用函数，因为此时真实的合约实例还没有被创建。</p>
<p>如果想要调用其他合约的函数，需要外部调用。对于一个外部调用，所有的函数参数都需要被复制到内存。</p>
<p>当调用其他合约的函数时，随函数调用发送的 Wei 和 gas 的数量可以分别由特定选项 <code>.value()</code> 和 <code>.gas()</code> 指定:</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br><span class="line"></span><br><span class="line">contract InfoFeed &#123;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">info</span>(<span class="params"></span>) <span class="title">public</span> <span class="title">payable</span> <span class="title">returns</span> (<span class="params">uint ret</span>) </span>&#123; <span class="keyword">return</span> <span class="number">42</span>; &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">contract Consumer &#123;</span><br><span class="line">    InfoFeed feed;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">setFeed</span>(<span class="params">address addr</span>) <span class="title">public</span> </span>&#123; feed = InfoFeed(addr); &#125;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">callFeed</span>(<span class="params"></span>) <span class="title">public</span> </span>&#123; feed.info.value(<span class="number">10</span>).gas(<span class="number">800</span>)(); &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>payable</code> 修饰符要用于修饰 <code>info</code>，否则，.<code>value()</code> 选项将不可用。</p>
<p>注意，表达式 <code>InfoFeed(addr)</code> 进行了一个的显式类型转换，说明”我们知道给定地址的合约类型是 <code>InfoFeed</code> “并且这不会执行构造函数。 显式类型转换需要谨慎处理。绝对不要在一个你不清楚类型的合约上执行函数调用。</p>
<p>我们也可以直接使用 <code>function setFeed(InfoFeed _feed) { feed = _feed; }</code> 。 注意一个事实，<code>feed.info.value(10).gas(800)</code> 只（局部地）设置了与函数调用一起发送的 Wei 值和 gas 的数量，只有最后的圆括号执行了真正的调用。</p>
<p>如果被调函数所在合约不存在（也就是账户中不包含代码）或者被调用合约本身抛出异常或者 gas 用完等，函数调用会抛出异常。</p>
<h3 id="3-2-2-引用类型介绍"><a href="#3-2-2-引用类型介绍" class="headerlink" title="3.2.2 引用类型介绍"></a>3.2.2 引用类型介绍</h3><p>比起之前讨论过的值类型，在处理复杂的类型（即占用的空间超过 256 位的类型）时，我们需要更加谨慎。 由于拷贝这些类型变量的开销相当大，我们不得不考虑它的存储位置，是将它们保存在 <strong>内存</strong> （并不是永久存储）中， 还是 <strong>存储</strong> （保存状态变量的地方）中。</p>
<ul>
<li><strong>数据位置</strong></li>
</ul>
<p>所有的复杂类型，即 <strong>数组</strong> 和 <strong>结构</strong> 类型，都有一个额外属性，“数据位置”，说明数据是保存在 <strong>内存</strong> 中还是 <strong>存储</strong> 中。 根据上下文不同，大多数时候数据有默认的位置，但也可以通过在类型名后增加关键字 <code>storage</code> 或 <code>memory</code> 进行修改。 函数参数（包括返回的参数）的数据位置默认是 <code>memory</code>， 局部变量的数据位置默认是 <code>storage</code>，状态变量的数据位置强制是 <code>storage</code>。</p>
<p>也存在第三种数据位置， <code>calldata</code> ，这是一块只读的，且不会永久存储的位置，用来存储函数参数。 外部函数的参数（非返回参数）的数据位置被强制指定为 <code>calldata</code>，效果跟 <code>memory</code> 差不多。</p>
<p>例子：<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br><span class="line"></span><br><span class="line">contract C &#123;</span><br><span class="line">    uint[] x; <span class="comment">// x 的数据存储位置是 storage</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// memoryArray 的数据存储位置是 memory</span></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params">uint[] memoryArray</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        x = memoryArray; <span class="comment">// 将整个数组拷贝到 storage 中，可行</span></span><br><span class="line">        <span class="keyword">var</span> y = x;  <span class="comment">// 分配一个指针（其中 y 的数据存储位置是 storage），可行</span></span><br><span class="line">        y[<span class="number">7</span>]; <span class="comment">// 返回第 8 个元素，可行</span></span><br><span class="line">        y.length = <span class="number">2</span>; <span class="comment">// 通过 y 修改 x，可行</span></span><br><span class="line">        <span class="keyword">delete</span> x; <span class="comment">// 清除数组，同时修改 y，可行</span></span><br><span class="line">        <span class="comment">// 下面的就不可行了；需要在 storage 中创建新的未命名的临时数组， /</span></span><br><span class="line">        <span class="comment">// 但 storage 是“静态”分配的：</span></span><br><span class="line">        <span class="comment">// y = memoryArray;</span></span><br><span class="line">        <span class="comment">// 下面这一行也不可行，因为这会“重置”指针，</span></span><br><span class="line">        <span class="comment">// 但并没有可以让它指向的合适的存储位置。</span></span><br><span class="line">        <span class="comment">// delete y;</span></span><br><span class="line"></span><br><span class="line">        g(x); <span class="comment">// 调用 g 函数，同时移交对 x 的引用</span></span><br><span class="line">        h(x); <span class="comment">// 调用 h 函数，同时在 memory 中创建一个独立的临时拷贝</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">g</span>(<span class="params">uint[] storage storageArray</span>) <span class="title">internal</span> </span>&#123;&#125;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">h</span>(<span class="params">uint[] memoryArray</span>) <span class="title">public</span> </span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>归纳：</p>
<p>强制指定的数据位置：</p>
<ol>
<li>外部函数的参数（不包括返回参数）： calldata</li>
<li>状态变量： storage</li>
</ol>
<p>默认数据位置：</p>
<ol>
<li>函数参数（包括返回参数）： memory</li>
<li>所有其它局部变量： storage</li>
</ol>
<ul>
<li><strong>数组</strong></li>
</ul>
<p>数组可以在声明时指定长度，也可以动态调整大小。 对于 <strong>存储</strong> 的数组来说，元素类型可以是任意的（即元素也可以是数组类型，映射类型或者结构体）。 对于 <strong>内存</strong> 的数组来说，元素类型不能是映射类型，如果作为 <code>public</code> 函数的参数，它只能是 <code>ABI</code> 类型。</p>
<p>一个元素类型为 <code>T</code>，固定长度为 <code>k</code> 的数组可以声明为 <code>T[k]</code>，而动态数组声明为 <code>T[]</code>。 </p>
<p>举个例子，一个长度为 5，元素类型为 <code>uint</code> 的动态数组的数组，应声明为 <code>uint[][5]</code> （注意这里跟其它语言比，数组长度的声明位置是反的）。 要访问第三个动态数组的第二个元素，你应该使用 <code>x[2][1]</code>（数组下标是从 0 开始的，且访问数组时的下标顺序与声明时相反，也就是说，<code>x[2]</code> 是从右边减少了一级）。。</p>
<p><code>bytes</code> 和 <code>string</code> 类型的变量是特殊的数组。 <code>bytes</code> 类似于 <code>byte[]</code>，但它在 <code>calldata</code> 中会被“紧打包”（译者注：将元素连续地存在一起，不会按每 32 字节一单元的方式来存放）。 <code>string</code> 与 <code>bytes</code> 相同，但（暂时）不允许用长度或索引来访问。</p>
<p>注：<br>如果想要访问以字节表示的字符串 s，请使用 <code>bytes(s)</code>.<code>length / bytes(s)[7] = &#39;x&#39;</code>;。 注意这时你访问的是 <code>UTF-8</code> 形式的低级<code>bytes</code> 类型，而不是单个的字符。</p>
<p><strong>成员</strong></p>
<p><code>length</code>:</p>
<p>数组有 length 成员变量表示当前数组的长度。 动态数组可以在 <strong>存储</strong> （而不是 <strong>内存</strong> ）中通过改变成员变量 .length 改变数组大小。 并不能通过访问超出当前数组长度的方式实现自动扩展数组的长度。 一经创建，<strong>内存</strong> 数组的大小就是固定的（但却是动态的，也就是说，它依赖于运行时的参数）。<br><code>push</code>:<br>    变长的 <strong>存储</strong> 数组以及 bytes 类型（而不是 string 类型）都有一个叫做 push 的成员函数，它用来附加新的元素到数组末尾。 这个函数将返回新的数组长度。 </p>
<p>例子：<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.16</span>;</span><br><span class="line"></span><br><span class="line">contract ArrayContract &#123;</span><br><span class="line">    uint[<span class="number">2</span>**<span class="number">20</span>] m_aLotOfIntegers;</span><br><span class="line">    <span class="comment">// 注意下面的代码并不是一对动态数组，</span></span><br><span class="line">    <span class="comment">// 而是一个数组元素为一对变量的动态数组（也就是数组元素为长度为 2 的定长数组的动态数组）。</span></span><br><span class="line">    bool[<span class="number">2</span>][] m_pairsOfFlags;</span><br><span class="line">    <span class="comment">// newPairs 存储在 memory 中 —— 函数参数默认的存储位置</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">setAllFlagPairs</span>(<span class="params">bool[<span class="number">2</span>][] newPairs</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 向一个 storage 的数组赋值会替代整个数组</span></span><br><span class="line">        m_pairsOfFlags = newPairs;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">setFlagPair</span>(<span class="params">uint index, bool flagA, bool flagB</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 访问一个不存在的数组下标会引发一个异常</span></span><br><span class="line">        m_pairsOfFlags[index][<span class="number">0</span>] = flagA;</span><br><span class="line">        m_pairsOfFlags[index][<span class="number">1</span>] = flagB;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">changeFlagArraySize</span>(<span class="params">uint newSize</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 如果 newSize 更小，那么超出的元素会被清除</span></span><br><span class="line">        m_pairsOfFlags.length = newSize;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">clear</span>(<span class="params"></span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 这些代码会将数组全部清空</span></span><br><span class="line">        <span class="keyword">delete</span> m_pairsOfFlags;</span><br><span class="line">        <span class="keyword">delete</span> m_aLotOfIntegers;</span><br><span class="line">        <span class="comment">// 这里也是实现同样的功能</span></span><br><span class="line">        m_pairsOfFlags.length = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    bytes m_byteData;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">byteArrays</span>(<span class="params">bytes data</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 字节的数组（语言意义中的 byte 的复数 ``bytes``）不一样，因为它们不是填充式存储的，</span></span><br><span class="line">        <span class="comment">// 但可以当作和 "uint8[]" 一样对待</span></span><br><span class="line">        m_byteData = data;</span><br><span class="line">        m_byteData.length += <span class="number">7</span>;</span><br><span class="line">        m_byteData[<span class="number">3</span>] = byte(<span class="number">8</span>);</span><br><span class="line">        <span class="keyword">delete</span> m_byteData[<span class="number">2</span>];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">addFlag</span>(<span class="params">bool[<span class="number">2</span>] flag</span>) <span class="title">public</span> <span class="title">returns</span> (<span class="params">uint</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> m_pairsOfFlags.push(flag);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">createMemoryArray</span>(<span class="params">uint size</span>) <span class="title">public</span> <span class="title">pure</span> <span class="title">returns</span> (<span class="params">bytes</span>) </span>&#123;</span><br><span class="line">        <span class="comment">// 使用 `new` 创建动态 memory 数组：</span></span><br><span class="line">        uint[<span class="number">2</span>][] memory arrayOfPairs = <span class="keyword">new</span> uint[<span class="number">2</span>][](size);</span><br><span class="line">        <span class="comment">// 创建一个动态字节数组：</span></span><br><span class="line">        bytes memory b = <span class="keyword">new</span> bytes(<span class="number">200</span>);</span><br><span class="line">        <span class="keyword">for</span> (uint i = <span class="number">0</span>; i &lt; b.length; i++)</span><br><span class="line">            b[i] = byte(i);</span><br><span class="line">        <span class="keyword">return</span> b;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<ul>
<li><strong>结构体</strong></li>
</ul>
<p>Solidity 支持通过构造结构体的形式定义新的类型，以下是一个结构体的示例：<br><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Funder</span> &#123;</span></span><br><span class="line">    address addr;</span><br><span class="line">    uint amount;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Campaign</span> &#123;</span></span><br><span class="line">    address beneficiary;</span><br><span class="line">    uint fundingGoal;</span><br><span class="line">    uint numFunders;</span><br><span class="line">    uint amount;</span><br><span class="line">    mapping (uint =&gt; Funder) funders;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<ul>
<li><strong>映射</strong><br>映射类型在声明时的形式为 <code>mapping(_KeyType =&gt; _ValueType)</code>。 其中 <code>_KeyType</code> 可以是除了映射、变长数组、合约、枚举以及结构体以外的几乎所有类型。 <code>_ValueType</code> 可以是包括映射类型在内的任何类型。</li>
</ul>
<p>映射可以视作 哈希表 <a href="https://en.wikipedia.org/wiki/Hash_table" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Hash_table</a>，它们在实际的初始化过程中创建每个可能的 key， 并将其映射到字节形式全是零的值：一个类型的 默认值。然而下面是映射与哈希表不同的地方： 在映射中，实际上并不存储 key，而是存储它的 <code>keccak256</code> 哈希值，从而便于查询实际的值。</p>
<p>正因为如此，映射是没有长度的，也没有 <code>key</code> 的集合或 <code>value</code> 的集合的概念。</p>
<p>只有状态变量（或者在 internal 函数中的对于存储变量的引用）可以使用映射类型。。</p>
<p>可以将映射声明为 <code>public</code>，然后来让 Solidity 创建一个 getter。<code>_KeyType</code> 将成为 getter 的必须参数，并且 getter 会返回 <code>_ValueType</code>。</p>
<p><code>_ValueType</code> 也可以是一个映射。这时在使用 getter 时将将需要递归地传入每个 <code>_KeyType</code>参数。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br><span class="line"></span><br><span class="line">contract MappingExample &#123;</span><br><span class="line">    mapping(<span class="function"><span class="params">address</span> =&gt;</span> uint) public balances;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">update</span>(<span class="params">uint newBalance</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        balances[msg.sender] = newBalance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">contract MappingUser &#123;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params"></span>) <span class="title">public</span> <span class="title">returns</span> (<span class="params">uint</span>) </span>&#123;</span><br><span class="line">        MappingExample m = <span class="keyword">new</span> MappingExample();</span><br><span class="line">        m.update(<span class="number">100</span>);</span><br><span class="line">        <span class="keyword">return</span> m.balances(<span class="keyword">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="3-2-3-涉及-LValues-的运算符"><a href="#3-2-3-涉及-LValues-的运算符" class="headerlink" title="3.2.3 涉及 LValues 的运算符"></a>3.2.3 涉及 LValues 的运算符</h4><ul>
<li><strong>删除</strong></li>
</ul>
<p><code>delete a</code> 的结果是将 <code>a</code> 的类型在初始化时的值赋值给 <code>a</code>。即对于整型变量来说，相当于 <code>a = 0</code>， 但 delete 也适用于数组，对于动态数组来说，是将数组的长度设为 0，而对于静态数组来说，是将数组中的所有元素重置。 如果对象是结构体，则将结构体中的所有属性重置。</p>
<p>delete 对整个映射是无效的（因为映射的键可以是任意的，通常也是未知的）。 因此在你删除一个结构体时，结果将重置所有的非映射属性，这个过程是递归进行的，除非它们是映射。 然而，单个的键及其映射的值是可以被删除的。</p>
<p>理解 <code>delete a</code>的效果就像是给 <code>a</code> 赋值很重要，换句话说，这相当于在 <code>a</code>中存储了一个新的对象。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br><span class="line"></span><br><span class="line">contract DeleteExample &#123;</span><br><span class="line">    uint data;</span><br><span class="line">    uint[] dataArray;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params"></span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        uint x = data;</span><br><span class="line">        <span class="keyword">delete</span> x; <span class="comment">// 将 x 设为 0，并不影响数据</span></span><br><span class="line">        <span class="keyword">delete</span> data; <span class="comment">// 将 data 设为 0，并不影响 x，因为它仍然有个副本</span></span><br><span class="line">        uint[] storage y = dataArray;</span><br><span class="line">        <span class="keyword">delete</span> dataArray;</span><br><span class="line">        <span class="comment">// 将 dataArray.length 设为 0，但由于 uint[] 是一个复杂的对象，y 也将受到影响，</span></span><br><span class="line">        <span class="comment">// 因为它是一个存储位置是 storage 的对象的别名。</span></span><br><span class="line">        <span class="comment">// 另一方面："delete y" 是非法的，引用了 storage 对象的局部变量只能由已有的 storage 对象赋值。</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-3-单位和全局变量"><a href="#3-3-单位和全局变量" class="headerlink" title="3.3 单位和全局变量"></a>3.3 单位和全局变量</h3><h3 id="3-3-1-以太币单位"><a href="#3-3-1-以太币单位" class="headerlink" title="3.3.1 以太币单位"></a>3.3.1 以太币单位</h3><p>以太币 单位之间的换算就是在数字后边加上 <code>wei</code>、 <code>finney</code>、 <code>szabo</code> 或 <code>ether</code> 来实现的，如果后面没有单位，缺省为 <code>Wei</code>。例如 <code>2 ether == 2000 finney</code> 的逻辑判断值为 <code>true</code>。</p>
<h3 id="3-3-2-时间单位"><a href="#3-3-2-时间单位" class="headerlink" title="3.3.2 时间单位"></a>3.3.2 时间单位</h3><p>秒是缺省时间单位，在时间单位之间，数字后面带有 <code>seconds</code>、 <code>minutes</code>、 <code>hours</code>、 <code>days</code>、 <code>weeks</code> 和 <code>years</code> 的可以进行换算，基本换算关系与现实生活相符。</p>
<h3 id="3-3-3-特殊变量和函数"><a href="#3-3-3-特殊变量和函数" class="headerlink" title="3.3.3 特殊变量和函数"></a>3.3.3 特殊变量和函数</h3><p>在全局命名空间中已经存在了（预设了）一些特殊的变量和函数，他们主要用来提供关于区块链的信息或一些通用的工具函数。</p>
<p><strong>区块和交易属性</strong></p>
<ul>
<li><code>block.blockhash(uint blockNumber) returns (bytes32)</code>：指定区块的区块哈希——仅可用于最新的 256 个区块且不包括当前区块；而 blocks 从 0.4.22 版本开始已经不推荐使用，由 <code>blockhash(uint blockNumber)</code> 代替</li>
<li><code>block.coinbase (address)</code>: 挖出当前区块的矿工地</li>
<li><code>block.difficulty (uint)</code>: 当前区块难度</li>
<li><code>block.gaslimit (uint)</code>: 当前区块 <code>gas</code> 限额</li>
<li><code>block.number (uint</code>): 当前区块号</li>
<li><code>block.timestamp (uint)</code>: 自 <code>unix epoch</code> 起始当前区块以秒计的时间戳</li>
<li><code>gasleft() returns (uint256)</code>：剩余的 <code>gas</code></li>
<li><code>msg.data (bytes)</code>: 完整的 <code>calldata</code></li>
<li><code>msg.gas (uint)</code>: 剩余 <code>gas</code> - 自 0.4.21 版本开始已经不推荐使用，由 gesleft() 代替</li>
<li><strong><code>msg.sender (address)</code>:</strong> 消息发送者（当前调用）</li>
<li><code>msg.sig (bytes4)</code>: calldata 的前 4 字节（也就是函数标识符）</li>
<li><code>msg.value (uint)</code>: 随消息发送的 wei 的数量</li>
<li><code>now (uint)</code>: 目前区块时间戳（<code>block.timestamp</code>）</li>
<li><code>tx.gasprice (uint)</code>: 交易的<code>gas</code> 价格</li>
<li><code>tx.origin (address)</code>: 交易发起者（完全的调用链）</li>
</ul>
<p><strong><a href="https://solidity-cn.readthedocs.io/zh/develop/abi-spec.html#abi" target="_blank" rel="noopener">ABI 编码函数</a></strong></p>
<ul>
<li><code>abi.encode(...) returns (bytes)</code>： ABI - 对给定参数进行编码</li>
<li><code>abi.encodePacked(...) returns (bytes)</code>：对给定参数执行 紧打包编码</li>
<li><code>abi.encodeWithSelector(bytes4 selector, ...) returns (bytes)：</code> ABI - 对给定参数进行编码，并以给定的函数选择器作为起始的 4 字节数据一起返回</li>
<li><code>abi.encodeWithSignature(string signature, ...) returns (bytes)</code>：等价于 <code>abi.encodeWithSelector(bytes4(keccak256(signature), ...)</code></li>
</ul>
<p><strong>错误处理</strong></p>
<ul>
<li><code>assert(bool condition)</code>:<br>  如果条件不满足，则使当前交易没有效果 — 用于检查内部错误。</li>
<li><code>require(bool condition)</code>:<br>  如果条件不满足则撤销状态更改 - 用于检查由输入或者外部组件引起的错误。</li>
<li><code>require(bool condition, string message)</code>:<br>  如果条件不满足则撤销状态更改 - 用于检查由输入或者外部组件引起的错误，可以同时提供一个错误消息。</li>
<li><code>revert()</code>:<br>  终止运行并撤销状态更改。</li>
<li><code>revert(string reason)</code>:<br>  终止运行并撤销状态更改，可以同时提供一个解释性的字符串。</li>
</ul>
<p><strong>地址相关</strong></p>
<ul>
<li><code>&lt;address&gt;.balance (uint256)</code>:<br>  以 Wei 为单位的 地址类型 的余额。</li>
<li><code>&lt;address&gt;.transfer(uint256 amount)</code>:<br>  向 地址类型 发送数量为 amount 的 Wei，失败时抛出异常，发送 2300 gas 的矿工费，不可调节。</li>
<li><code>&lt;address&gt;.send(uint256 amount) returns (bool)</code>:<br>  向 地址类型 发送数量为 amount 的 Wei，失败时返回 false，发送 2300 gas 的矿工费用，不可调节。</li>
<li><code>&lt;address&gt;.call(...) returns (bool)</code>:<br>  发出低级函数 CALL，失败时返回 false，发送所有可用 gas，可调节。</li>
<li><code>&lt;address&gt;.callcode(...) returns (bool)</code>：<br>  发出低级函数 CALLCODE，失败时返回 false，发送所有可用 gas，可调节。</li>
<li><code>&lt;address&gt;.delegatecall(...) returns (bool):</code><br>  发出低级函数 DELEGATECALL，失败时返回 false，发送所有可用 gas，可调节。 </li>
</ul>
<h3 id="3-4-表达式和控制结构"><a href="#3-4-表达式和控制结构" class="headerlink" title="3.4 表达式和控制结构(*)"></a>3.4 表达式和控制结构(*)</h3><h3 id="3-4-1-控制结构"><a href="#3-4-1-控制结构" class="headerlink" title="3.4.1 控制结构"></a>3.4.1 控制结构</h3><p>avaScript 中的大部分控制结构在 Solidity 中都是可用的，除了 <code>switch</code> 和 <code>goto</code>。 因此 Solidity 中有 <code>if，else，while，do，for，break，continue，return，? :</code>这些与在 C 或者 JavaScript 中表达相同语义的关键词。</p>
<p>用于表示条件的括号 <strong>不可以</strong> 被省略，单语句体两边的花括号可以被省略。</p>
<p>注意，与 C 和 JavaScript 不同， Solidity 中非布尔类型数值不能转换为布尔类型，因此 <code>if (1) { ... }</code> 的写法在 Solidity 中 无效 。</p>
<p>当一个函数有多个输出参数时， <code>return (v0, v1, ...,vn)</code> 写法可以返回多个值。不过元素的个数必须与输出参数的个数相同</p>
<h3 id="3-4-2-通过-new-创建合约"><a href="#3-4-2-通过-new-创建合约" class="headerlink" title="3.4.2 通过 new 创建合约"></a>3.4.2 通过 new 创建合约</h3><p>使用关键字 <code>new</code> 可以创建一个新合约。待创建合约的完整代码必须事先知道，因此递归的创建依赖是不可能的。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br><span class="line"></span><br><span class="line">contract D &#123;</span><br><span class="line">    uint x;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">D</span>(<span class="params">uint a</span>) <span class="title">public</span> <span class="title">payable</span> </span>&#123;</span><br><span class="line">        x = a;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">contract C &#123;</span><br><span class="line">    D d = <span class="keyword">new</span> D(<span class="number">4</span>); <span class="comment">// 将作为合约 C 构造函数的一部分执行</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">createD</span>(<span class="params">uint arg</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        D newD = <span class="keyword">new</span> D(arg);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">createAndEndowD</span>(<span class="params">uint arg, uint amount</span>) <span class="title">public</span> <span class="title">payable</span> </span>&#123;</span><br><span class="line">        <span class="comment">//随合约的创建发送 ether</span></span><br><span class="line">        D newD = (<span class="keyword">new</span> D).value(amount)(arg);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如示例中所示，使用 <code>.value（）</code> 选项创建 <code>D</code> 的实例时可以转发 <code>Ether</code>，但是不可能限制 <code>gas</code> 的数量。如果创建失败（可能因为栈溢出，或没有足够的余额或其他问题），会引发异常。</p>
<h3 id="3-4-3-错误处理：Assert-Require-Revert-and-Exceptions"><a href="#3-4-3-错误处理：Assert-Require-Revert-and-Exceptions" class="headerlink" title="3.4.3 错误处理：Assert, Require, Revert and Exceptions"></a>3.4.3 错误处理：Assert, Require, Revert and Exceptions</h3><p><code>Solidity</code> 使用状态恢复异常来处理错误。这种异常将撤消对当前调用（及其所有子调用）中的状态所做的所有更改，并且还向调用者标记错误。 便利函数 <code>assert</code> 和 <code>require</code> 可用于检查条件并在条件不满足时抛出异常。<code>assert</code> 函数只能用于测试内部错误，并检查非变量。</p>
<p> <code>require</code> 函数用于确认条件有效性，例如输入变量，或合约状态变量是否满足条件，或验证外部合约调用返回的值。 如果使用得当，分析工具可以评估你的合约，并标示出那些会使 <code>assert</code> 失败的条件和函数调用。 正常工作的代码不会导致一个 <code>assert</code>语句的失败；如果这发生了，那就说明出现了一个需要你修复的 bug。</p>
<p>还有另外两种触发异常的方法：<code>revert</code> 函数可以用来标记错误并恢复当前的调用。 <code>revert</code> 调用中包含有关错误的详细信息是可能的，这个消息会被返回给调用者。已经不推荐的关键字 <code>throw</code> 也可以用来替代 <code>revert()</code> （但无法返回错误消息）。</p>
<p>在下例中，你可以看到如何轻松使用<code>require</code>检查输入条件以及如何使用<code>assert</code>检查内部错误，注意，你可以给 require 提供一个消息字符串，而 assert 不行。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.22</span>;</span><br><span class="line"></span><br><span class="line">contract Sharer &#123;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">sendHalf</span>(<span class="params">address addr</span>) <span class="title">public</span> <span class="title">payable</span> <span class="title">returns</span> (<span class="params">uint balance</span>) </span>&#123;</span><br><span class="line">        <span class="built_in">require</span>(msg.value % <span class="number">2</span> == <span class="number">0</span>, <span class="string">"Even value required."</span>);</span><br><span class="line">        uint balanceBeforeTransfer = <span class="keyword">this</span>.balance;</span><br><span class="line">        addr.transfer(msg.value / <span class="number">2</span>);</span><br><span class="line">                    <span class="comment">//由于转移函数在失败时抛出异常并且不能在这里回调，因此我们应该没有办法仍然有一半的钱。</span></span><br><span class="line">        assert(<span class="keyword">this</span>.balance == balanceBeforeTransfer - msg.value / <span class="number">2</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.balance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-5-合约"><a href="#3-5-合约" class="headerlink" title="3.5 合约"></a>3.5 合约</h3><p>Solidity 合约类似于面向对象语言中的类。合约中有用于数据持久化的状态变量，和可以修改状态变量的函数。 调用另一个合约实例的函数时，会执行一个 EVM 函数调用，这个操作会切换执行时的上下文，这样，前一个合约的状态变量就不能访问了。</p>
<h3 id="3-5-1-创建合约"><a href="#3-5-1-创建合约" class="headerlink" title="3.5.1 创建合约"></a>3.5.1 创建合约</h3><p>可以通过以太坊交易“从外部”或从 Solidity 合约内部创建合约。<br>创建合约时，会执行一次构造函数（与合约同名的函数）。构造函数是可选的。只允许有一个构造函数，这意味着不支持重载。</p>
<p>在内部，构造函数参数在合约代码之后通过 <code>ABI</code> 编码 传递，但是如果你使用 <code>web3.js</code> 则不必关心这个问题。</p>
<p>如果一个合约想要创建另一个合约，那么创建者必须知晓被创建合约的源代码(和二进制代码)。 这意味着不可能循环创建依赖项。</p>
<h3 id="3-5-2-getter-函数"><a href="#3-5-2-getter-函数" class="headerlink" title="3.5.2 getter 函数"></a>3.5.2 getter 函数</h3><p>编译器自动为所有 <code>public</code> 状态变量创建 <code>getter</code> 函数。对于下面给出的合约，编译器会生成一个名为 <code>data</code> 的函数， 该函数不会接收任何参数并返回一个 <code>uint</code> ，即状态变量 <code>data</code> 的值。可以在声明时完成状态变量的初始化</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br><span class="line"></span><br><span class="line">contract C &#123;</span><br><span class="line">    uint public data = <span class="number">42</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">contract Caller &#123;</span><br><span class="line">    C c = <span class="keyword">new</span> C();</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params"></span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        uint local = c.data();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>getter 函数具有外部可见性。如果在内部访问 getter（即没有 this. ），它被认为一个状态变量。 如果它是外部访问的（即用 this. ），它被认为为一个函数。</p>
<h3 id="3-5-3-View-函数"><a href="#3-5-3-View-函数" class="headerlink" title="3.5.3 View 函数"></a>3.5.3 View 函数</h3><p>可以将函数声明为 view 类型，这种情况下要保证不修改状态。</p>
<p>下面的语句被认为是修改状态：</p>
<ol>
<li>修改状态变量。</li>
<li>产生事件。</li>
<li>创建其它合约。</li>
<li>使用 selfdestruct。</li>
<li>通过调用发送以太币。</li>
<li>调用任何没有标记为 view 或者 pure 的函数。</li>
<li>使用低级调用。</li>
<li>使用包含特定操作码的内联汇编。</li>
</ol>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.16</span>;</span><br><span class="line"></span><br><span class="line">contract C &#123;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params">uint a, uint b</span>) <span class="title">public</span> <span class="title">view</span> <span class="title">returns</span> (<span class="params">uint</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> a * (b + <span class="number">42</span>) + now;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-5-4-Pure-函数"><a href="#3-5-4-Pure-函数" class="headerlink" title="3.5.4 Pure 函数"></a>3.5.4 Pure 函数</h3><p>函数可以声明为 pure ，在这种情况下，承诺不读取或修改状态。</p>
<p>除了上面解释的状态修改语句列表之外，以下被认为是从状态中读取：</p>
<ol>
<li>读取状态变量。</li>
<li>访问 this.balance 或者 <address>.balance。</address></li>
<li>访问 block，tx， msg 中任意成员 （除 msg.sig 和 msg.data 之外）。</li>
<li>调用任何未标记为 pure 的函数。</li>
<li>使用包含某些操作码的内联汇编。</li>
</ol>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.16</span>;</span><br><span class="line"></span><br><span class="line">contract C &#123;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params">uint a, uint b</span>) <span class="title">public</span> <span class="title">pure</span> <span class="title">returns</span> (<span class="params">uint</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> a * (b + <span class="number">42</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="四、练习题"><a href="#四、练习题" class="headerlink" title="四、练习题"></a>四、练习题</h2><h3 id="4-1-将固定长度字节数组转化为string类型"><a href="#4-1-将固定长度字节数组转化为string类型" class="headerlink" title="4.1 将固定长度字节数组转化为string类型"></a>4.1 将固定长度字节数组转化为<code>string</code>类型</h3><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.0</span>;</span><br><span class="line"></span><br><span class="line">contract bytes32tostring&#123;</span><br><span class="line">    </span><br><span class="line">    bytes10 testword=<span class="number">0x68656c6c6f776f726c64</span>; <span class="comment">//为helloworld</span></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">bytes32tostringF</span>(<span class="params"></span>) <span class="title">public</span> <span class="title">view</span> <span class="title">returns</span>(<span class="params">string</span>)</span>&#123;</span><br><span class="line">    </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="4-2-实现一个带有简单逻辑判断及多种数学运算的Solidity程序"><a href="#4-2-实现一个带有简单逻辑判断及多种数学运算的Solidity程序" class="headerlink" title="4.2 实现一个带有简单逻辑判断及多种数学运算的Solidity程序"></a>4.2 实现一个带有简单逻辑判断及多种数学运算的Solidity程序</h3><p><strong>参考自：</strong></p>
<ol>
<li><p>黄皮书：<a href="https://github.com/yuange1024/ethereum_yellowpaper/blob/master/ethereum_yellow_paper_cn.pdf" target="_blank" rel="noopener">https://github.com/yuange1024/ethereum_yellowpaper/blob/master/ethereum_yellow_paper_cn.pdf</a></p>
</li>
<li><p>白皮书：<a href="https://github.com/ethereum/wiki/wiki/White-Paper" target="_blank" rel="noopener">https://github.com/ethereum/wiki/wiki/White-Paper</a><br> <a href="https://blog.csdn.net/weixin_45067603" target="_blank" rel="noopener">INlinKC</a><br> <a href="https://ethfans.org/wikis/Home" target="_blank" rel="noopener">https://ethfans.org/wikis/Home</a></p>
</li>
<li>以太坊solidity学习记录: <a href="https://blog.csdn.net/weixin_45067603/article/details/105726491" target="_blank" rel="noopener">https://blog.csdn.net/weixin_45067603/article/details/105726491</a></li>
<li><a href="https://www.bilibili.com/video/BV1sJ411D72u" target="_blank" rel="noopener">尚硅谷区块链全套Go语言→GoWeb→以太坊→项目实战</a></li>
</ol>
]]></content>
      <categories>
        <category>Blockchain</category>
      </categories>
  </entry>
  <entry>
    <title>区块链入门（二）基础知识介绍</title>
    <url>/posts/fb46f828.html</url>
    <content><![CDATA[<font color="red"> 注：本教程为技术教程，不谈论且不涉及炒作任何数字货币 </font>

<p>本次组队学习重点在于以太坊基础知识、以太坊客户端以及以太坊solidity编程，因此本节教程重点在于以太坊核心知识点的掌握，区块链部分的基础知识可以作为补充，请学习者量力而行。另外若学习者觉得本节内容难度太高，可以先对基本知识点有一个概览，在第二节以及第三节实战内容学习完成之后再深入学习本节内容。</p>
<h1 id="一、区块链简介"><a href="#一、区块链简介" class="headerlink" title="一、区块链简介"></a>一、区块链简介</h1><h2 id="1-1、区块链与区块链技术"><a href="#1-1、区块链与区块链技术" class="headerlink" title="1.1、区块链与区块链技术"></a>1.1、区块链与区块链技术</h2><p>在阅读本教程之前，<a href="http://blog.codinglabs.org/articles/bitcoin-mechanism-make-easy.html" target="_blank" rel="noopener">大家对比特币原理不太了解同学可以先阅读下此博客~</a>,大家对比特币有简单了解后对于区块链会有更好的认识。</p>
<p><strong>区块链</strong>是将记录（区块）通过密码学串联并加密的链式数据结构。而<strong>区块链技术</strong>，是通过P2P网络和区块链来实现数据存储的<strong>去中心化</strong>、<strong>不可逆</strong>和<strong>不可篡改</strong>。比特币正是构建在区块链技术上的典型应用。通过区块链技术，我们可以将信息（数据、程序）保存在区块上并接入到区块链中，这样就实现了信息的去中心化存储、不可逆和不可篡改。<strong>区块链应用</strong>是指利用区块链技术开发的应用。</p>
<h2 id="1-2、区块链历史"><a href="#1-2、区块链历史" class="headerlink" title="1.2、区块链历史"></a>1.2、区块链历史</h2><p>2008年，一个网名叫中本聪（Satoshi Nakamoto）的人发表了一篇名为《比特币：一种点对点电子货币系统》的论文，论文中首次提到了“区块链”这一概念。2009年，中本聪创立了以区块链为底层技术的比特币网络，开发出了第一个区块，被称为“创世区块”。该阶段被称为“区块链1.0”。</p>
<p>由于比特币是一个电子货币系统，所以主要功能就是记账。但随后人们发现，区块链技术作为比特币的底层技术，功能可以远远不止于记账，许多关于“未知的信任”的问题，都可以通过区块链来解决，例如电子存证、信息记录等。于是在比特币的基础上，诞生了带有智能合约的区块链系统，即允许开发者通过编写智能合约来实现特定的逻辑，这一阶段被称为“区块链2.0”。这一阶段的主要代表是以太坊。</p>
<p>随后，人们想要提升区块链应用的性能，于是出现了EOS、ArcBlock等系统，其特点是高性能、大吞吐量，但由于引入了超级节点、云节点等特性，弱化了“去中心化”这一特点，因此受到较大的争议。这一阶段被称为“区块链3.0”。</p>
<p>由于比特币是一款电子货币，可扩展性较低，而所谓的“区块链3.0”目前受到较大争议，且部分项目的底层算法完全不同于典型的区块链，因此学习区块链2.0中的以太坊是目前学习区块链的最佳方式。</p>
<h2 id="1-3、区块链基础技术与算法"><a href="#1-3、区块链基础技术与算法" class="headerlink" title="1.3、区块链基础技术与算法"></a>1.3、区块链基础技术与算法</h2><p>区块链技术不是单独的一项技术，而是一系列技术组成的技术栈，其具有以下的特点：</p>
<ul>
<li>数据分布式存储</li>
<li>存储的数据不可逆、不可篡改、可回溯</li>
<li>数据的创建和维护由所有参与方共同参与</li>
</ul>
<p>为了实现这些特点、维护区块链应用的稳定运行，区块链技术中包含了分布式存储技术、密码学技术、共识机制以及区块链2.0提出的智能合约。</p>
<h3 id="1-3-1、区块"><a href="#1-3-1、区块" class="headerlink" title="1.3.1、区块"></a>1.3.1、区块</h3><p>区块链由一个个区块（block）组成。区块很像数据库的记录，每次写入数据，就是创建一个区块。</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\bg2017122703.png" width="300">
</center>
<center>中心化存储</center>

<p>每个区块包含两个部分。</p>
<blockquote>
<ul>
<li>区块头（Head）：记录当前区块的特征值</li>
<li>区块体（Body）：实际数据</li>
</ul>
</blockquote>
<p>区块头包含了当前区块的多项特征值。</p>
<blockquote>
<ul>
<li>生成时间</li>
<li>实际数据（即区块体）的哈希</li>
<li>上一个区块的哈希</li>
<li>…</li>
</ul>
</blockquote>
<h3 id="1-3-2、分布式存储技术"><a href="#1-3-2、分布式存储技术" class="headerlink" title="1.3.2、分布式存储技术"></a>1.3.2、分布式存储技术</h3><p>与传统的数据存储技术不同，在区块链技术中，数据并不是集中存放在某个数据中心上，也不是由某个权威机构或是大多数节点来存储，而是分散存储在区块链网络中的每一个节点上。</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image2.png" width="300">
</center>
<center>中心化存储</center>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image3.png" width="300">
</center>
<center>分布式存储</center>

<p><strong>节点和区块的关系是什么？</strong></p>
<p>可以用共享文档来简单描述：所有可以访问共享文档的账号就叫做节点，当然全节点需要同步共享文档，也就是拥有全部的区块数据区块就是共享文档。每个人更新了，所有人都可以查看最新的文档</p>
<h3 id="1-3-3、密码学技术"><a href="#1-3-3、密码学技术" class="headerlink" title="1.3.3、密码学技术"></a>1.3.3、密码学技术</h3><p>为了实现数据的不可逆、不可篡改和可回溯，区块链技术采用了一系列密码学算法和技术，包括哈希算法、Merkle 树、非对称加密算法。</p>
<h5 id="哈希算法"><a href="#哈希算法" class="headerlink" title="哈希算法"></a>哈希算法</h5><p>哈希算法是一个单向函数，可以将任意长度的输入数据转化为固定长度的输出数据（哈希值），哈希值就是这段输入数据唯一的数值表现。由于在计算上不可能找到哈希值相同而输入值不同的字符串，因此两段数据的哈希值相同，就可以认为这两段数据也是相同的，所以哈希算法常被用于对数据进行验证。</p>
<p>在区块链中，数据存储在区块里。每个区块都有一个区块头，区块头中存储了一个将该区块所有数据经过哈希算法得到的哈希值，同时，每个区块中还存储了前一个区块的哈希值，这样就形成了区块链。如果想要篡改某一个区块A中的数据，就会导致A的哈希值发生变化，后一个区块B就无法通过哈希值正确地指向A，这样篡改者又必须篡改B中的数据……也就是说，篡改者需要篡改被篡改的区块以及后面的所有区块，才能让所有的节点都接受篡改。</p>
<h5 id="Merkle树"><a href="#Merkle树" class="headerlink" title="Merkle树"></a>Merkle树</h5><p>Merkle树是一种树形结构，在区块链中，Merkle树的叶子节点是区块中数据的哈希值，非叶子节点是其子结点组合后的哈希值，这样由叶子节点开始逐层往上计算，最终形成一个Merkle根，记录在区块的头部，这样就可以保证每一笔交易都无法篡改。</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image4.png" width="500">
</center>
<center>Merkle 树</center>

<h5 id="非对称加密技术"><a href="#非对称加密技术" class="headerlink" title="非对称加密技术"></a>非对称加密技术</h5><p>非对称加密技术使用两个非对称密钥：公钥和私钥。公钥和私钥具有两个特点：</p>
<ol>
<li>通过其中一个密钥加密信息后，使用另一个密钥才能解开</li>
<li>公钥一般可以公开，私钥则保密</li>
</ol>
<p>在区块链中，非对称加密技术主要用于信息加密、数字签名和登录认证。在信息加密场景中，信息发送者A使用接收者B提供的公钥对信息进行加密，B收到加密的信息后再通过自己的私钥进行解密。再数字签名场景中，发送者A通过自己的私钥对信息进行加密，其他人通过A提供的公钥来对信息进行验证，证明信息确实是由A发出。在登录认证场景中，客户端使用私钥加密登录信息后进行发送，其他人通过客户端公钥来认证登录信息。</p>
<ul>
<li><p>RSA 算法</p>
<p>​        RSA加密算法是最常用的非对称加密算法，CFCA在证书服务中离不了它。但是有不少新来的同事对它不太了解，恰好看到一本书中作者用实例对它进行了简化而生动的描述，使得高深的数学理论能够被容易地理解。<br>​       RSA是第一个比较完善的公开密钥算法，它既能用于加密，也能用于数字签名。RSA以它的三个发明者Ron Rivest, Adi Shamir, Leonard Adleman的名字首字母命名，这个算法经受住了多年深入的密码分析，虽然密码分析者既不能证明也不能否定RSA的安全性，但这恰恰说明该算法有一定的可信性，目前它已经成为最流行的公开密钥算法。<br>　　RSA的安全基于大数分解的难度。其公钥和私钥是一对大素数（100到200位十进制数或更大）的函数。从一个公钥和密文恢复出明文的难度，等价于分解两个大素数之积（这是公认的数学难题）。 </p>
</li>
<li><p>ECC 椭圆曲线算法</p>
<p>具体可以参见此文章：<a href="https://zhuanlan.zhihu.com/p/36326221" target="_blank" rel="noopener">ECC椭圆曲线加密算法：介绍</a></p>
</li>
</ul>
<h3 id="1-3-4、共识机制"><a href="#1-3-4、共识机制" class="headerlink" title="1.3.4、共识机制"></a>1.3.4、共识机制</h3><p>区块链系统是一个分布式系统，分布式系统要解决都首要问题就是一致性问题，也就是如何使多个孤立的节点达成共识。在中心化系统中，由于有一个中心服务器这样的“领导”来统一各个节点，因此达成一致性几乎没有问题。但在去中心化场景下，由于各个节点是相互独立的，就可能会出现许多不一致的问题，例如由于网络状况等因素部分节点可能会有延迟、故障甚至宕机，造成节点之间通信的不可靠，因此一致性问题是分布式系统中一个很令人头疼的问题。</p>
<p>由 Eirc Brewer 提出，Lynch 等人证明的 CAP 定理为解决分布式系统中的一致性问题提供了思路。CAP 定理的描述如下：在分布式系统中，<strong>一致性</strong>、<strong>可用性</strong>和<strong>分区容错性</strong>三者不可兼得。这三个术语的解释如下：</p>
<ul>
<li>一致性（<strong>C</strong>onsistency）：所有节点在同一时刻拥有同样的值（等同于所有节点访问同一份最新的数据副本</li>
<li>可用性（<strong>A</strong>vailability）：每个请求都可以在有限时间内收到确定其是否成功的响应</li>
<li>分区容错性（<strong>P</strong>artition tolerance）：分区是指部分节点因为网络原因无法与其他节点达成一致。分区容错性是指由网络原因导致的系统分区不影响系统的正常运行。例如，由于网络原因系统被分为 A, B, C, D 四个区，A, B 中的节点无法正常工作，但 C, D 组成的分区仍能提供正常服务。</li>
</ul>
<p>在某些场景下，对一致性、可用性和分区容错性中的某一个特性要求不高时，就可以考虑弱化该特性，来保证整个系统的容错能力。区块链中常见的共识机制的基本思路正是来自 CAP 定理，部分区块链应用中用到的共识机制如下表：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>共识机制</th>
<th>应用</th>
</tr>
</thead>
<tbody>
<tr>
<td>PoW</td>
<td>比特币、莱特币、以太坊的前三个阶段</td>
</tr>
<tr>
<td>PoS</td>
<td>PeerCoin、NXT、以太坊的第四个阶段</td>
</tr>
<tr>
<td>PBFT</td>
<td>Hyperledger Fabric</td>
</tr>
</tbody>
</table>
</div>
<h5 id="PoW（Proof-of-Work，工作量证明）"><a href="#PoW（Proof-of-Work，工作量证明）" class="headerlink" title="PoW（Proof of Work，工作量证明）"></a>PoW（Proof of Work，工作量证明）</h5><p>PoW 机制的大致流程如下：</p>
<ol>
<li>向所有节点广播新交易和一个数学问题</li>
<li>最先解决了数学问题的节点将交易打包成区块，对全网广播</li>
<li>其他节点验证广播区块的节点是否解决了数学问题（完成了一定的工作量），验证通过则接受该区块，并将该区块的哈希值放入下一个区块中，表示承认该区块</li>
</ol>
<p>由于在 PoW 机制中，区块的产生需要解决一个数学问题，也就是所谓的<strong>挖矿</strong>，这往往要消耗较大的算力和电力，因此节点们倾向于在<strong>最长的链</strong>的基础上添加区块，因为如果节点想在自己的链上添加新的区块，那么就需要重新计算 1 个或 $n$ 个这样的数学问题（每添加一个区块就需要计算一个）。因此在比特币中最长的链被认为是合法的链，这样节点间就形成了一套“共识”。</p>
<p>PoW 机制的优点是完全去中心化，缺点是需要依赖数学运算，资源的消耗会比其他的共识机制高，可监管性弱，同时每次达成共识需要全网共同参与运算，性能较低。</p>
<h5 id="PoS（Proof-of-Stack，股权证明）"><a href="#PoS（Proof-of-Stack，股权证明）" class="headerlink" title="PoS（Proof of Stack，股权证明）"></a>PoS（Proof of Stack，股权证明）</h5><p>PoS 针对 PoW 的缺点做出了改进。PoS 要求参与者预先放置一些货币在区块链上用于换取“股权”，从而成为<strong>验证者（Validator）</strong>，验证者具有产生区块的权利。PoS 机制会按照存放货币的量和时间给验证者分配相应的利息，同时还引入了奖惩机制，打包错误区块的验证者将失去他的股权——即投入的货币以及产生区块的权利。PoS 机制的大致流程如下：</p>
<ol>
<li>加入 PoS 机制的都是持币人，称为验证者</li>
<li>PoS 算法根据验证者持币的多少在验证者中挑选出一个给予产生区块的权利</li>
<li>如果一定时间内没有产生区块，PoS 就挑选下一个验证者，给予产生区块的权利</li>
<li>如果某个验证者打包了一份欺诈性交易，PoS 将剥夺他的股权</li>
</ol>
<p>PoS 的优点在于：</p>
<ol>
<li>引入了利息，使得像比特币这样发币总数有限的通货紧缩系统在一定时间后不会“无币可发”</li>
<li>引入了奖惩机制使节点的运行更加可控，同时更好地防止攻击</li>
<li>与 PoW 相比，不需要为了生成新区块而消耗大量电力和算力</li>
<li>与 PoW 相比，缩短了达成共识所需的时间</li>
</ol>
<p>由于 PoS 机制需要用户已经持有一定数量的货币，没有提供在区块链应用创立初始阶段处理数字货币的方法，因此使用 PoS 机制的区块链应用会在发布时预先出售货币，或在初期采用 PoW，让矿工获得货币后再转换成 PoS，例如以太坊现阶段采用的是 PoW 机制，在第四阶段“宁静”（Serenity）中将过渡到 PoS。</p>
<h5 id="拜占庭将军问题（Byzantine-Generals-Problem）"><a href="#拜占庭将军问题（Byzantine-Generals-Problem）" class="headerlink" title="拜占庭将军问题（Byzantine Generals Problem）"></a>拜占庭将军问题（Byzantine Generals Problem）</h5><p>拜占庭将军问题是分布式网络中的通信容错问题，可以描述为：</p>
<blockquote>
<p>一组拜占庭将军各领一支队伍共同围困一座城市。各支军队的行动策略限定为进攻或撤离两种。因为部分军队进攻而部分军队撤离可能会造成灾难性的后果，因此各将军决定通过投标来达成一致策略，即“共进退”。因为各将军位于城市不同方向，他们只能通过信使互相联系。在投票过程中每位将军都将自己的选择（进攻或撤退）通过信使分别通知其他所有将军，这样一来每位将军根据自己的投票和其他所有将军送来的信息就可以知道共同投票的结果，进而做出行动。</p>
</blockquote>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image1.png" width="500">
</center>



<p>拜占庭将军的问题在于，将军中可能出现叛徒。假设3名将军中有1名叛徒，2名忠诚将军一人投进攻票，一人投撤退票，这时叛徒可能会故意给投进攻的将军投进攻票，而给投撤退的将军投撤退票。这就导致一名将军带队发起进攻，而另外一名将军带队撤退。</p>
<p>另外，由于将军之间通过信使进行通讯，即使所有将军都忠诚，也不能排除信使被敌人截杀，甚至信使叛变等情况。</p>
<p>假设存在叛变将军或信使出问题等情况，如果忠诚将军仍然能够通过投票来决定他们的战略，便称系统达到了<strong>拜占庭容错（Byzantine Fault Tolerance）</strong>。</p>
<p>拜占庭问题对应到区块链中，将军就是节点，信使就是网络等通信系统，要解决的是存在恶意节点、网络错误等情况下系统的一致性问题。</p>
<p><strong>PBFT（Practical Byzantine Fault Tolerance）</strong> 是第一个得到广泛应用且比较高效的拜占庭容错算法，能够在节点数量不小于 $n=3f+1$ 的情况下容忍 $f$ 个拜占庭节点（恶意节点）。</p>
<h1 id="二、以太坊介绍"><a href="#二、以太坊介绍" class="headerlink" title="二、以太坊介绍"></a>二、以太坊介绍</h1><p>首先我们要知道我们为什么要学习以太坊，主要有以下四个原因：</p>
<ul>
<li>以太坊是区块链2.0的代表，学习以太坊能了解到区块链技术的所有知识</li>
<li>引入了智能合约，拓宽了区块链的应用场景</li>
<li>对开发者友好、对用户友好，容易编写出简单的区块链应用，学习趣味性高</li>
<li>Solidity 语法与 Javascript、Go 等语言接近，易上手</li>
</ul>
<h2 id="2-1、以太坊简介"><a href="#2-1、以太坊简介" class="headerlink" title="2.1、以太坊简介"></a>2.1、以太坊简介</h2><p>区块链技术常常被认为是自互联网诞生以来最具颠覆性的技术，然而，自比特币诞生后一直没有很好的区块链应用开发平台。想要在比特币基础上开发区块链应用是非常复杂繁琐的，因为比特币仅仅是一个加密数字货币系统，无法用来实现更广阔的业务需求。以太坊是目前使用最广泛的支持完备应用开发的共有区块链系统。</p>
<p>和比特币不同，比特币只适合加密数字货币场景，不具备图灵完备性，也缺乏保存实时状态的账户概念，以及存在 PoW 机制带来的效率和资源浪费的问题，而以太坊作为区块链2.0的代表，目标是扩展智能合约和建立一个去中心化应用平台，具有图灵完备的特性、更高效的共识机制、支持智能合约等多种应用场景，使得开发者能够很方便地在以太坊上开发出基于区块链的应用。</p>
<h3 id="2-1-1、以太坊的发展"><a href="#2-1-1、以太坊的发展" class="headerlink" title="2.1.1、以太坊的发展"></a>2.1.1、以太坊的发展</h3><p>2014年， Vitalik Buterin 发表了文章《以太坊：一个下一代智能合约和去中心化应用平台》。同年，Buterin 在迈阿密比特币会议中宣布启动以太坊项目，并提出了多项创新性的区块链技术。2015年，以太坊CCO Stephan Tual 在官方博客上宣布以太坊系统诞生，主网上线。</p>
<p>以太坊发展至今经历了“前沿”（Frontier）、“家园”（Homestead）以及现在所处的“大都会”（Metropolis）三个阶段。第四阶段“宁静”（Serenity）将作为以太坊的最后一个阶段，目前尚未有计划发布日期。</p>
<h3 id="2-1-2、以太坊的特点"><a href="#2-1-2、以太坊的特点" class="headerlink" title="2.1.2、以太坊的特点"></a>2.1.2、以太坊的特点</h3><p>以太坊团队和外界对以太坊的描述都是“世界计算机”，这代表它是一个开源的、全球的去中心化计算架构。它执行称为智能合约的程序，并使用区块链来同步和存储系统状态，以及使用名为以太币的加密数字货币来计量和约束执行操作的资源成本。同时，以太坊提供了一系列的接口，使得开发者能够通过以太坊来开发去中心化 Web 应用DApps。</p>
<h3 id="2-1-3、智能合约"><a href="#2-1-3、智能合约" class="headerlink" title="2.1.3、智能合约"></a>2.1.3、智能合约</h3><p>相比比特币，以太坊最大的特点就是引入了<strong>智能合约</strong>。智能合约本质上就是一段编写好的程序，可以在特定的条件下被触发并执行特定的操作。由于区块链具有不可逆和不可篡改的特点，因此智能合约与区块链结合后，就成了一份“强制执行”的合约。</p>
<p>以太坊能够作为一个去中心化应用平台和”世界计算机”，其核心就是智能合约。智能合约的引入，使得开发者能够实现许多（理论上是任何）业务逻辑。如果说比特币是通过区块链技术开发的特定计算器，那么引入了智能合约的以太坊就是基于区块链技术的通用计算机。可以简单的理解成：比特币的交易系统就是一份写死的智能合约，而以太坊则将智能合约的开发权限交给开发者。</p>
<p>以太坊提供了对智能合约的全面支持，包括编写智能合约编程语言 <strong>Solidity</strong> 和运行智能合约的<strong>以太坊虚拟机（Ethereum Virtual Machine，EVM）</strong>。</p>
<h3 id="2-1-4、幽灵协议"><a href="#2-1-4、幽灵协议" class="headerlink" title="2.1.4、幽灵协议"></a>2.1.4、幽灵协议</h3><p>幽灵合约的英文是“Greedy Heaviest Observed Subtree” (GHOST) protocol，在介绍幽灵协议之前，先介绍以太坊中的叔区块、叔块奖励和叔块引用奖励这三个概念。</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image5.png" width="400">
</center>


<p>假设目前以太坊区块链中的区块高度（区块链上的区块个数）为6，现在产生了一笔新的交易，矿工A先将该笔交易打包成了区块 Block 7，在矿工A将 Block 7 广播到其他节点的这段时间里，矿工B和矿工C又分别产生了 Block 8 和 Block 9。Block 7、Block 8、Block 9 都指向 Block 6，即 Block 6 是他们的父区块。由于 Block 7 是最先产生的，因此 Block 7 被认为是有效区块，Block 8 和 Block 9 就是<strong>叔区块</strong>（作废区块）。</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image6.png" width="300">
</center>


<p>现在链上的区块高度为7，在这基础上又产生了新的交易，并被打包成了 Block 10。在以太坊中，Block 10 除了可以引用它的父区块 Block 7 外，还可以引用叔区块 Block 8 和 Block 9。并且，Block 8 和 Block 9 的矿工会因此获得一笔奖励，称为<strong>叔块奖励</strong>，Block 10 的矿工除了基础奖励之外，由于引用了叔区块，还会获得一笔额外的<strong>叔块引用奖励</strong>。</p>
<p><strong>幽灵协议</strong>是以太坊的一大创新。由于在比特币中的出块时间被设计为10分钟，而以太坊为了提高出块速度，将出块时间设计为12秒（实际14~15秒左右），这样的高速出块意味着高速确认，高速确认会带来区块的<strong>高作废率</strong>和<strong>低安全性</strong>。因为区块需要花一定的时间才能广播至全网，如果矿工 A 挖出了一个区块，而矿工 B 碰巧在 A 的区块扩散至 B 之前挖出了另一个区块，矿工 B 的区块就会作废并且没有对区块链的网络安全做出贡献。此外，这样的高速确认还会带来<strong>中心化</strong>的问题：如果 A 拥有全网 30% 的算力而 B 拥有 10% 的算力，那么 A 将会在 70% 的时间内都在产生作废区块，而 B 在 90% 的时间内都在产生作废区块，这样，B 永远追不上 A，后果是 A 通过其算力份额拥有对挖矿过程实际上的控制权，出现了算力垄断，弱化了去中心化。</p>
<p>幽灵协议正是为了解决上述问题而引入的，协议的主要内容如下：</p>
<ul>
<li>计算最长链时，不仅包括当前区块的父区块和祖区块，还包括祖先块的作废的后代区块（叔区块），将它们综合考虑来计算哪一个区块拥有支持其的最大工作量证明。这解决了网络安全性的问题</li>
<li>以太坊付给以“叔区块”身份为新块确认作出贡献的废区块87.5%的奖励（叔块奖励），把它们纳入计算的“侄子区块”将获得奖励的12.5%（叔块引用奖励）。这就使得即使产生作废区块的矿工也能够参与区块链网络贡献并获得奖励，解决了中心化倾向的问题</li>
<li>叔区块最深可以被其父母的第二代至第七代后辈区块引用。这样做是为了：<ul>
<li>降低引用叔区块的计算复杂性</li>
<li>过多的叔块引用奖励会剥夺矿工在主链上挖矿的激励，使得矿工有转向公开攻击者链上挖矿的倾向（即公开攻击者可能会恶意产生大量作废区块，无限引用将会诱使矿工转移到攻击者的链上，从而抛弃合法的主链）</li>
<li>计算表明带有激励的五层幽灵协议即使在出块时间为15s的情况下也实现了了95%以上的效率，而拥有25%算力的矿工从中心化得到的益处小于3%</li>
</ul>
</li>
</ul>
<h3 id="2-1-5、以太坊的组成部分"><a href="#2-1-5、以太坊的组成部分" class="headerlink" title="2.1.5、以太坊的组成部分"></a>2.1.5、以太坊的组成部分</h3><p>在以太坊中，包括了 P2P 网络、共识机制、交易、状态机、客户端这几个组成部分。</p>
<ul>
<li>P2P 网络：在以太坊主网上运行，可通过TCP端口30303访问，并运行称为 ÐΞVp2p 的协议。</li>
<li>共识机制：以太坊目前使用名为 Ethash 的 POW 算法，计划在将来会过渡到称为 Casper 的 POS 算法。</li>
<li>交易：以太坊中的交易本质上是网络消息，包括发送者、接收者、值和数据载荷（payload）。</li>
<li>状态机：以太坊的状态转移由以太坊虚拟机（Ethereum Virtual Machine，EVM）处理，EVM 能够将智能合约编译成机器码并执行。</li>
<li>客户端：用于用户和以太坊进行交互操作的软件实现，最突出的是 Go-Ethereum(Geth) 和 Parity。</li>
</ul>
<h3 id="2-1-6、以太坊中的概念"><a href="#2-1-6、以太坊中的概念" class="headerlink" title="2.1.6、以太坊中的概念"></a>2.1.6、以太坊中的概念</h3><ul>
<li>账户：以太坊中的账户类似于银行账户、应用账户，每个账户有一个20字节的地址。账户又分为<strong>普通账户</strong>（又叫外部账户，External Owned Account, EOA）和<strong>合约账户</strong>（Contract）。普通账户是由以太坊使用者创建的账户，包含地址、余额和随机数；合约账户是创建智能合约时建立的账户，包含存储空间和合约代码</li>
<li>状态：状态是由账户和两个账户之间价值的转移以及信息的状态转换构成的</li>
<li>地址：地址是一个账户 ECDSA 公钥的 Keccak 散列最右边的160位，通过地址可以在以太坊上接收或发送交易。在 Etherscan 上，可以通过地址来查询一个账户的信息</li>
<li>交易：以太坊中的交易不仅包括发送和接收以太币，还包括向合约账户发送交易来调用合约代码、向空用户发送交易来生成以交易信息为代码块的合约账户</li>
<li>Gas：Gas 是以太坊中的一种机制，用于执行智能合约或交易操作的虚拟燃料。由于以太坊是图灵完备的，为了避免开发者无意或恶意编写出死循环等浪费资源或滥用资源的情况，以太坊中的每一笔交易都需支付一定的 Gas （燃料费），即需支付一定的以太币作为 Gas。Gas 的金额通常是由交易的发起者指定并支付的</li>
<li>挖矿：和比特币类似，以太坊同样通过挖矿来产生区块。在以太坊目前的 PoW 机制下，每当一笔交易发出并广播，就会吸引矿工来将该交易打包成区块。每产生一个区块都会有一笔<strong>固定奖励</strong>给矿工，目前的固定奖励是3个以太。同时，区块中所有操作所需的 Gas 也会作为奖励给矿工。与比特币不同的是，以太坊中产生叔块的矿工可能会获得叔块奖励，引用叔块的矿工会获得叔块引用奖励</li>
<li>DApp（去中心化应用）：通过智能合约，开发者能够设计想要的逻辑，相当于是网站的后端。而 DApp 则相当于是一个完整的网站（前端+后端），因此 DApp = 智能合约 + Web 前端。以太坊提供了一个名为 web3.js 的 Javascript 库，通过 web3.js 可以实现 Web 与以太坊区块链的交互和与智能合约的交互，方便开发者创建 DApp</li>
</ul>
<h2 id="2-2、以太坊基础"><a href="#2-2、以太坊基础" class="headerlink" title="2.2、以太坊基础"></a>2.2、以太坊基础</h2><h3 id="2-2-1、以太坊中的货币"><a href="#2-2-1、以太坊中的货币" class="headerlink" title="2.2.1、以太坊中的货币"></a>2.2.1、以太坊中的货币</h3><p>以太坊中的货币称为 <strong>以太币</strong>，单位为<strong>以太（Ether）</strong>，也称 ETH 或符号 Ξ。以太可以被分割为更小的单位，最小的单位是 wei，1 以太 =  $10^18$  wei。以太币各单位的名称及之间的关系如下表：</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image-20210219000835894.png">
</center>





<h3 id="2-2-2、以太坊钱包"><a href="#2-2-2、以太坊钱包" class="headerlink" title="2.2.2、以太坊钱包"></a>2.2.2、以太坊钱包</h3><p>以太坊钱包是用于创建和广播交易的应用程序，常用的钱包有</p>
<ul>
<li>MetaMask，一款基于浏览器扩展的钱包，可以很方便地添加到 Chrome, FireFox 等支持扩展的浏览器中</li>
<li>Jaxx，一款跨平台、多币种的钱包</li>
<li>MyEtherWallet(MEW)，一款基于 Web 的钱包，可以在任何浏览器中运行</li>
<li>Emerald Wallet，一款被设计来用于以太坊经典区块链的钱包，但也与其他以太坊区块链兼容</li>
</ul>
<h4 id="MetaMask-基础"><a href="#MetaMask-基础" class="headerlink" title="MetaMask 基础"></a>MetaMask 基础</h4><p>以 Chrome 为例，访问 <a href="https://chrome.google.com/webstore/category/extensions" target="_blank" rel="noopener">Google 网上应用商店</a>，搜索 MetaMask 并添加至 Chrome</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image-20210219101124978.png">
</center>


<p>添加完成后 Chrome 会自动打开初始化页面</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image-20210219101226095.png">
</center>



<p>初次使用创建钱包</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image-20210219101300792.png">
</center>



<p>为钱包设置密码</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image-20210219101332089.png">
</center>




<p>创建密码后，MetaMask 会生成一串密语，密语是12个随机的英文单词，用于防止密码忘记。密语可以直接当成密码使用，因此需要妥善保管</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image-20210219102028033.png">
</center>



<p>注册完毕后就可以在 Chrome 地址栏右边的扩展程序栏点击 🦊 图标使用 MetaMask 了</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image-20210219102255927.png">
</center>

<center class="half">
    <img src="\Pic\Blockchain_Pic\image-20210219102322360.png">
</center>

<h4 id="获取测试以太"><a href="#获取测试以太" class="headerlink" title="获取测试以太"></a>获取测试以太</h4><p>除了以太坊主网以外，以太坊还提供了 Ropsten, Kovan, Rinkeby, Goerli 这几个公共测试网络，另外还支持局域网测试网络和自建测试网络。在这里我们切换到 Ropsten 测试网络</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image-20210219105616335.png">
</center>




<p>随后点击 <strong>Buy</strong> 按钮，点击<strong>测试水管</strong>下方的获取以太</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image-20210219105824087.png">
</center>




<p>在打开的页面中点击 request 1 ether from faucet 就可以得到1个测试以太，当然，可以多次点击。</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\image-20210219105911910.png">
</center>


<center class="half">
    <img src="\Pic\Blockchain_Pic\2021-02-19_110327.png">
</center>


<p>测试以太仅供测试使用，除此之外没有任何价值，测试完毕后剩下的以太可以发送到水龙头账户捐赠给水龙头，以供他人测试使用。</p>
<h2 id="2-3、以太坊交易的数据结构"><a href="#2-3、以太坊交易的数据结构" class="headerlink" title="2.3、以太坊交易的数据结构"></a>2.3、以太坊交易的数据结构</h2><p>在以太坊网络中，交易执行属于一个事务。具有原子性、一致性、隔离性、持久性特点。</p>
<ul>
<li>原子性： 是不可分割的最小执行单位，要么做，要么不做。</li>
<li>一致性： 同一笔交易执行，必然是将以太坊账本从一个一致性状态变到另一个一致性状态。</li>
<li>隔离性： 交易执行途中不会受其他交易干扰。</li>
<li>持久性： 一旦交易提交，则对以太坊账本的改变是永久性的。后续的操作不会对其有任何影响。</li>
</ul>
<p>以太坊交易的本质是由外部拥有的账户发起的签名消息，由以太坊网络传输，并被序列化后记录在以太坊区块链上，<strong>交易是唯一可以触发状态更改或导致合约在EVM中执行的事物</strong></p>
<h3 id="2-3-1、交易的数据结构"><a href="#2-3-1、交易的数据结构" class="headerlink" title="2.3.1、交易的数据结构"></a>2.3.1、交易的数据结构</h3><p>以太坊的数据结构主要可以分为四部分：<code>nonce</code>、<code>gas</code>、交易目标和消息（主要部分）、交易签名</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\transaction-struct.png">
</center>



<p>开头是一个 uint64 类型的数字，称之为随机数。用于撤销交易、防止双花和修改以太坊账户的 Nonce 值。</p>
<p>第二部分是关于交易执行限制的设置，gas 为愿意供以太坊虚拟机运行的燃料上限。 <code>gasPrice</code> 是愿意支付的燃料单价。<code>gasPrcie * gas</code> 则为愿意为这笔交易支付的最高手续费。</p>
<p>第三部分是交易发送者输入以太坊虚拟机执行此交易的初始信息： 虚拟机操作对象（接收方 To）、从交易发送方转移到操作对象的资产（Value），以及虚拟机运行时入参(input)。其中 To 为空时，意味着虚拟机无可操作对象，<strong>此时虚拟机将利用 input 内容部署一个新合约</strong>。</p>
<p>第四部分是交易发送方对交易的签名结果，可以利用交易内容和签名结果反向推导出签名者，即交易发送方地址。以上总结如下：</p>
<ul>
<li><code>nonce</code>：由发起人EOA发出的序列号，用于防止交易消息重播。</li>
<li><code>gas price</code>：交易发起人愿意支付的gas单价（wei）。</li>
<li><code>start gas</code>：交易发起人愿意支付的最大gas量。</li>
<li><code>to</code>：目的以太坊地址。</li>
<li><code>value</code>：要发送到目的地的以太数量。</li>
<li><code>data</code>：可变长度二进制数据负载（payload）。</li>
<li><code>v,r,s</code>：发起人EOA的ECDSA签名的三个组成部分。</li>
<li>交易消息的结构使用递归长度前缀（RLP）编码方案进行序列化，该方案专为在以太坊中准确和字节完美的数据序列化而创建。</li>
</ul>
<h3 id="2-3-2、交易中的nonce"><a href="#2-3-2、交易中的nonce" class="headerlink" title="2.3.2、交易中的nonce"></a>2.3.2、交易中的<code>nonce</code></h3><p>按以太坊黄皮书的定义， <code>nonce</code>是一个标量值，它等于从这个地址发送的交易数，或者对于关联code的帐户来说，是这个帐户创建合约的数量。因此<code>nonce</code>便有以下特征：</p>
<ul>
<li><code>nonce</code>不会明确存储为区块链中帐户状态的一部分。相反，它是通过计算发送地址的已确认交易的数量来动态计算的。</li>
<li><code>nonce</code>值还用于防止错误计算账户余额。<code>nonce</code>强制来自任何地址的交易按顺序处理，没有间隔，无论节点接收它们的顺序如何。</li>
<li>使用<code>nonce</code>确保所有节点计算相同的余额和正确的序列交易，等同于用于防止比特币“双重支付”（“重放攻击”）的机制。但是，由于以太坊跟踪账户余额并且不单独跟踪 <code>UTXO</code> ，因此只有在错误地计算账户余额时才会发生“双重支付”。<code>nonce</code>机制可以防止这种情况发生。</li>
</ul>
<h3 id="2-3-3、并发和nonce"><a href="#2-3-3、并发和nonce" class="headerlink" title="2.3.3、并发和nonce"></a>2.3.3、并发和<code>nonce</code></h3><p>以太坊是一个允许操作（节点，客户端，DApps）并发的系统，但强制执行单例状态。例如，出块的时候只有一个系统状态。假如我们有多个独立的钱包应用或客户端，比如 MetaMask 和 Geth，它们可以使用相同的地址生成交易。如果我们希望它们都够同时发送交易，该怎么设置交易的<code>nonce</code>呢？一般有以下两种做法：</p>
<ul>
<li>用一台服务器为各个应用分配<code>nonce</code>，先来先服务——可能出现单点故障，并且失败的交易会将后续交易阻塞。</li>
<li>生成交易后不分配<code>nonce</code>，也不签名，而是把它放入一个队列等待。另起一个节点跟踪<code>nonce</code>并签名交易。同样会有单点故障的可能，而且跟踪<code>nonce</code>和签名的节点是无法实现真正并发的。</li>
</ul>
<h3 id="2-3-4、交易中的gas"><a href="#2-3-4、交易中的gas" class="headerlink" title="2.3.4、交易中的gas"></a>2.3.4、交易中的<code>gas</code></h3><p>Gas 中译是：瓦斯、汽油，代表一种可燃气体。 这形象地比喻以太坊的交易手续费计算模式，不同于比特币中<strong>直接</strong>支付比特币作为转账手续费， 以太坊视为一个去中心化的计算网络，当你发送Token、执行合约、转移以太币或者在此区块上干其他的时候，计算机在处理这笔交易时需要进行计算消耗网络资源，这样你必须支付燃油费购买燃料才能让计算机为你工作。最终燃料费作为手续费支付给矿工。</p>
<blockquote>
<p>注：可以在Etherscan上查询gas price与confirmation time的关系，如下图</p>
</blockquote>
<center class="half">
    <img src="\Pic\Blockchain_Pic\gas.jpg">
</center>


<p>因为手续费等于<code>gasPrice * gasUsed</code>，用户在转账，特别是执行智能合约时 gasUsed 无法提前预知。 这样存在一个风险，当用户的交易涉及一个恶意的智能合约，该合约执行将消耗无限的燃料， 这样会导致交易方的余额全部消耗（恶意的智能合约有可能是程序Bug，如合约执行陷入一个死循环）。</p>
<p>为了避免合约中的错误引起不可预计的燃料消耗，用户需要在发送交易时设定允许消耗的燃料上限，即 gasLimit。 这样不管合约是否良好，最坏情况也只是消耗 gasLimit 量的燃料。</p>
<p>然而，一笔交易所必须支付的燃料已经在区块中通过该交易已执行的计算量记录。 如果你不想支出太多燃料，而故意设置过低的 gasLimit 是没太多帮助的。 你必须支付足够燃料来支付本交易所必要的计算资源。如果交易尚未执行完成，而燃料已用完， 将出现一个 <code>Out of Gas</code> 的错误。特别注意的是，即使交易失败，你也必须为已占用的计算资源所支付手续费。 比如，你通过合约给 TFBOYS 投票，设置 gasPrice=2 gwei，gasLimit=40000（实现投票需要40001的燃料开销）， 最终你投票失败且仍然需要支付 40000*2 gwei= 80000 gwei= 0.00008 ETH。</p>
<p>另外，如果最终 gasUsed 低于 gasLimit，即燃料未用完。则剩余燃料(gasLimit - gasUsed )将在交易后退还给你。 比如你发送 1 Ether 到另一个账户B，设置 gas limit 为 400000，将有 400000 - 21000 返回给你。</p>
<blockquote>
<p>注意：21000 是标准转账交易的gasUsed。因此一笔标准的转账交易你可以设置 gasLimit 为21000</p>
</blockquote>
<h2 id="2-4、以太坊账户"><a href="#2-4、以太坊账户" class="headerlink" title="2.4、以太坊账户"></a>2.4、以太坊账户</h2><p>对比比特币的UTXO余额模型，以太坊使用“账户”余额模型。 以太坊丰富了账户内容，除余额外还能自定义存放任意多数据。 并利用账户数据的可维护性，构建智能合约账户。下面我们首先将比特币的UTXO余额模型与以太坊账户进行比较，说明其各自的优缺点以及适用性。</p>
<h3 id="2-4-1、比特币UTXO和以太坊账户结构比较"><a href="#2-4-1、比特币UTXO和以太坊账户结构比较" class="headerlink" title="2.4.1、比特币UTXO和以太坊账户结构比较"></a>2.4.1、比特币UTXO和以太坊账户结构比较</h3><p>在当前的区块链项目中，主要有两种记录保存方式，<strong>一种是账户/余额模型，一种是UTXO模型</strong>。比特币采用就是UTXO模型，以太坊、EOS等则采用的是账户/余额模型。</p>
<p><img src="\Pic/utxo_com.jpg" style="zoom:67%;"></p>
<h3 id="2-4-2、比特币UTXO"><a href="#2-4-2、比特币UTXO" class="headerlink" title="2.4.2、比特币UTXO"></a>2.4.2、比特币UTXO</h3><p>UTXO是 Unspent Transaction Output的缩写，意思是<strong>未花费的输出，</strong>可以简单理解为还没有用掉的收款。比如韩梅梅收到一笔比特币，她没有用掉，这笔比特币对她来说就是一个UTXO。关于UTXO的具体介绍大家可以查看<a href="https://zhuanlan.zhihu.com/p/74050135" target="_blank" rel="noopener">这篇文章</a>。</p>
<p><strong>UTXO 核心设计思路是：它记录交易事件，而不记录最终状态。</strong>要计算某个用户有多少比特币，就要对其钱包里所有的UTXO求和，得到结果就是他的持币数量。UTXO模型在转账交易时，是以UTXO为单位的，也就是说在支付时，调用的是整数倍UTXO，比如1个UTXO，3个UTXO，没有0.5个UTXO的说法。</p>
<ul>
<li>比特币在基于UTXO的结构中存储有关用户余额的数据，系统的整个状态就是一组UTXO的集合，每个UTXO都有一个所有者和一个面值（就像不同的硬币），而交易会花费若干个输入的UTXO，并根据规则创建若干个新的UTXO</li>
<li>每个引用的输入必须有效并且尚未花费，对于一个交易，必须包含有每个输入的所有者匹配的签名，总输入必须大于等于总输出值。所以系统中用户的余额是用户具有私钥的UTXO的总值</li>
</ul>
<h3 id="2-4-3、以太坊账户"><a href="#2-4-3、以太坊账户" class="headerlink" title="2.4.3、以太坊账户"></a>2.4.3、以太坊账户</h3><p>为什么以太坊不用UTXO呢？显然是因为麻烦，以太坊的做法更符合直觉，以太坊中的状态就是系统中所有账户的列表，每个账户都包含了一个余额和以太坊<strong>特殊定义的数据</strong>（代码和内部存储）。如果发送账户有足够多的余额来进行支付，则交易有效，在这种情况下发送账户先扣款，而收款账户将记入这笔收入。<strong>如果接受账户有相关代码，则代码会自动运行，并且它的内部存储也可能被更改，或者代码还可能向其他账户发送额外的消息，这就会导致进一步的借贷资金关系。</strong></p>
<h3 id="2-4-4、优缺点比较"><a href="#2-4-4、优缺点比较" class="headerlink" title="2.4.4、优缺点比较"></a>2.4.4、优缺点比较</h3><p><strong>比特币UTXO的优点</strong>：</p>
<ul>
<li>更高程度的隐私：如果用户为他们收到的每笔交易使用新地址，那么通常很难将账户互相链接。这很大程度上适用于货币，但不太适用于任何dapps，因为dapps通常涉及跟踪和用户绑定的复杂状态，可能不存在像货币那样简单的用户状态划分方案</li>
<li>潜在的可扩展性：UTXO在理论上更符合可扩展性要求，因为我们只需要依赖拥有UTXO的那些人去维护基于Merkle树的所有权证明就够了，即使包括所有者在内的每个人都决定忘记该数据，那么也只有所有者受到对应的UTXO的损失，不影响接下来的交易。而在账户模式中，如果每个人都丢失了与账户相对应的Merkle树的部分，那将会使得和该账户有关的消息完全无法处理，包括发币给它。</li>
</ul>
<p><strong>以太坊账户模式的优点</strong>：</p>
<ul>
<li>可以节省大量空间：不将UTXOs分开存储，而是合成一个账户；每个交易只需要一个输入、一个签名并产生一个输出</li>
<li>更好的可替代性：货币本质上都是同质化、可替代的；UTXO的设计使得货币从来源分成了“可花费”和“不可花费”两类，这在实际应用中很难有对应模型</li>
<li>更加简单：更容易编码和理解，特别是设计复杂脚本的时候，UTXO的脚本逻辑复杂时更令人费解</li>
<li>便于维护持久轻节点：只要沿着特定方向扫描状态树，轻节点 可以很容易地随时访问账户相关的所有数据。而UTXO地每个交易都会使得状态引用发生改变，这对应节点来说长时间运行Dapp会有很大压力</li>
</ul>
<h3 id="2-4-5、总结"><a href="#2-4-5、总结" class="headerlink" title="2.4.5、总结"></a>2.4.5、总结</h3><div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>BitCoin</th>
<th>Ethereum</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>设计定位</strong></td>
<td>现金系统</td>
<td>去中心化应用平台</td>
</tr>
<tr>
<td><strong>数据组成</strong></td>
<td>交易列表（账本）</td>
<td>交易和账户状态</td>
</tr>
<tr>
<td><strong>交易对象</strong></td>
<td>UTXO</td>
<td>Accounts</td>
</tr>
<tr>
<td><strong>代码控制</strong></td>
<td>脚本</td>
<td>智能合约</td>
</tr>
</tbody>
</table>
</div>
<h2 id="2-5、以太坊账户类型"><a href="#2-5、以太坊账户类型" class="headerlink" title="2.5、以太坊账户类型"></a>2.5、以太坊账户类型</h2><p>以太坊作为智能合约操作平台，将账户划分为两类：外部账户（EOAs）和合约账户（contract account），下面分别做简要介绍：</p>
<center class="half">
    <img src="\Pic\Blockchain_Pic\EOA_CA.png">
</center>



<h3 id="2-5-1、外部账户（EOA）"><a href="#2-5-1、外部账户（EOA）" class="headerlink" title="2.5.1、外部账户（EOA）"></a>2.5.1、外部账户（EOA）</h3><p>外部账户是由人来控制的，也就是常规理解的普通账户，外部账户包含以太币余额，主要作用就是发送交易（是广义的交易，包括转币和触发合约代码），是由用户私钥控制的，没有关联代码，所有在以太坊上交易的发起者都是外部账户。</p>
<p>外部账户特点总结：</p>
<ol>
<li>拥有以太余额。</li>
<li>能发送交易，包括转账和执行合约代码。</li>
<li>被私钥控制。</li>
<li>没有相关的可执行代码。</li>
</ol>
<h3 id="2-5-2、合约账户（CA）"><a href="#2-5-2、合约账户（CA）" class="headerlink" title="2.5.2、合约账户（CA）"></a>2.5.2、合约账户（CA）</h3><p>合约账户有时也叫内部账户，有对应的以太币余额和关联代码，它是由代码控制的，可以通过交易或来自其他合约的调用消息来触发代码执行，执行代码时可以操作自己的存储空间，也可以调用其他合约</p>
<p>合约账户特点总结：</p>
<ol>
<li>拥有以太余额。</li>
<li>有相关的可执行代码（合约代码）。</li>
<li>合约代码能够被交易或者其他合约消息调用。</li>
<li>合约代码被执行时可再调用其他合约代码。</li>
<li>合约代码被执行时可执行复杂运算，可永久地改变合约内部的数据存储。</li>
</ol>
<p>如果大家对概念还理解不深可以先尝试学习后面部分，本教程内容有限，推荐大家有精力阅读以下读物：</p>
<ul>
<li><a href="https://www.zhihu.com/question/61156867" target="_blank" rel="noopener">区块链学习的书籍</a></li>
<li><a href="https://www.ruanyifeng.com/blog/2017/12/blockchain-tutorial.html" target="_blank" rel="noopener">区块链入门教程</a></li>
<li><a href="https://developer.ibm.com/zh/technologies/blockchain/tutorials/" target="_blank" rel="noopener">IBM教程</a></li>
</ul>
<p><strong>参考自：</strong></p>
<ol>
<li>[比特币白皮书]<a href="https://www.8btc.com/wiki/bitcoin-a-peer-to-peer-electronic-cash-system" target="_blank" rel="noopener">https://www.8btc.com/wiki/bitcoin-a-peer-to-peer-electronic-cash-system</a>)</li>
<li><a href="https://ethfans.org/posts/ethereum-whitepaper" target="_blank" rel="noopener">以太坊白皮书</a></li>
<li><a href="https://www.chainnode.com/doc/399" target="_blank" rel="noopener">超级账本白皮书</a></li>
<li><a href="https://www.chainnode.com/doc/399" target="_blank" rel="noopener">闪电网络白皮书</a></li>
</ol>
]]></content>
      <categories>
        <category>Blockchain</category>
      </categories>
  </entry>
  <entry>
    <title>区块链入门（一）Linux基础</title>
    <url>/posts/cf0a3f0.html</url>
    <content><![CDATA[<h1 id="新手建议"><a href="#新手建议" class="headerlink" title="新手建议"></a>新手建议</h1><h2 id="学习Linux的注意事项"><a href="#学习Linux的注意事项" class="headerlink" title="学习Linux的注意事项"></a>学习Linux的注意事项</h2><ul>
<li><p>Linux严格区分大小写（命令全都是小写）—— 命令、文件名、选项等均区分大小写</p>
</li>
<li><p>Linux中<strong>所有内容</strong>以文件形式保存，包括硬件</p>
<ul>
<li>硬盘文件是/dev/sd[a-p]</li>
<li>光盘文件是/dev/sr0等</li>
</ul>
</li>
<li><p>Windows通过扩展名区分文件类型，还有图标可以区分；Linux不靠扩展名区分文件类型，靠文件权限区分，但也有一些约定俗成的扩展名：</p>
<ul>
<li>压缩包：”<em>.gz”, “</em>.bz2”, “<em>.tar.bz2”, “</em>.tgz”等</li>
<li>二进制软件包：”.rpm”</li>
<li>网页文件：”*.sh”</li>
<li>配置文件：”*.conf”</li>
</ul>
<p>注意：这些扩展名不是必要的，即时不加扩展名也没有影响，只是便于管理而已</p>
</li>
<li><p>Linux所有存储设备都必须挂在之后用户才能使用，包括硬盘、U盘、光盘（将设备与挂载点连接的过程就是挂载）</p>
</li>
<li><p>Windows下的程序不能直接在Linux中安装和运行</p>
</li>
</ul>
<h2 id="服务器管理和维护建议"><a href="#服务器管理和维护建议" class="headerlink" title="服务器管理和维护建议"></a>服务器管理和维护建议</h2><h3 id="服务器管理"><a href="#服务器管理" class="headerlink" title="服务器管理"></a>服务器管理</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">目录名</th>
<th style="text-align:center">目录作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">/bin/</td>
<td style="text-align:center">存放系统命令的目录，普通用户和超级用户都可以执行，不过放在/bin下的命令在单用户模式下也可以执行</td>
</tr>
<tr>
<td style="text-align:center">/sbin/</td>
<td style="text-align:center">保存和系统环境设置相关的命令，只有超级用户可以使用这些命令进行系统环境设置，但是有些命令可以允许普通用户查看</td>
</tr>
<tr>
<td style="text-align:center">/usr/bin/</td>
<td style="text-align:center">存放系统命令的目录，普通用户和超级用户都可以执行，这些命令和系统启动无关，在单用户模式下不能执行</td>
</tr>
<tr>
<td style="text-align:center">/usr/sbin/</td>
<td style="text-align:center">存放根文件系统不必要的系统管理命令，例如多数服务程序。只有超级用户可以使用</td>
</tr>
<tr>
<td style="text-align:center">/boot/</td>
<td style="text-align:center">系统启动目录，保存系统启动相关的文件，如内核文件和启动引导程序（grub）文件等</td>
</tr>
<tr>
<td style="text-align:center">/dev/</td>
<td style="text-align:center">设备文件保存位置，我们已经说过Linux中所有内容以文件形式保存，包括硬件，这个目录就是用来 保存所有硬件设备的</td>
</tr>
<tr>
<td style="text-align:center">/etc/</td>
<td style="text-align:center">配置文件保存位置，系统内所有采用默认安装方式（npm安装）的服务的配置文件全部保存在这个目录中，如用户账户和密码，服务的启动脚本，常用服务的配置文件等</td>
</tr>
<tr>
<td style="text-align:center">/home/</td>
<td style="text-align:center">每个用户的默认登陆位置，普通用户的home目录就是在/home下建立一个和用户名相同的目录</td>
</tr>
<tr>
<td style="text-align:center">/lib/</td>
<td style="text-align:center">系统调用的函数库保存位置</td>
</tr>
<tr>
<td style="text-align:center">/lost+found/</td>
<td style="text-align:center">当系统意外崩溃或机器意外关机时，产生的一些文件碎片放在这里，当系统启动的过程中fsck工具会对其进行检查，并修复已经损坏的文件系统。这个目录只在每个分区中出现，例如/lost+found就是根分区的备份恢复目录，/boot/lost+found就是/boot分区的备份恢复目录</td>
</tr>
<tr>
<td style="text-align:center">/media/</td>
<td style="text-align:center">挂载目录，系统建议是用来挂载媒体设备的，例如软盘和光盘</td>
</tr>
<tr>
<td style="text-align:center">/mnt/</td>
<td style="text-align:center">挂载目录，建议挂载额外设备，如U盘，移动硬盘和其他操作系统的分区</td>
</tr>
<tr>
<td style="text-align:center">/misc/</td>
<td style="text-align:center">挂载目录，系统建议用来挂载NFS服务的共享目录</td>
</tr>
<tr>
<td style="text-align:center">/opt/</td>
<td style="text-align:center">第三方安装的软件保存位置，但现在更多的是保存在/usr/local中</td>
</tr>
<tr>
<td style="text-align:center">/proc/</td>
<td style="text-align:center">虚拟文件系统，该目录的数据不保存到硬盘中，而是保存到内存中。主要保存系统的内核、进程、外部设备状态和网络状态灯，如/proc/cpuinfo是保存CPU信息的，/proc/devices是保存设备驱动的列表的，/proc/filesystems是保存 文件系统列表的，/proc/net/是保存网络协议信息的</td>
</tr>
<tr>
<td style="text-align:center">/sys/</td>
<td style="text-align:center">虚拟文件系统，主要保存内核相关信息</td>
</tr>
<tr>
<td style="text-align:center">/root/</td>
<td style="text-align:center">超级用户的家目录</td>
</tr>
<tr>
<td style="text-align:center">/srv/</td>
<td style="text-align:center">服务数据目录， 一些系统服务启动后可以在这个目录保存需要的数据</td>
</tr>
<tr>
<td style="text-align:center">/tmp/</td>
<td style="text-align:center">临时目录，系统存放临时文件的目录，该目录下所有用户都可以访问和写入，我们建议此目录不能保存重要数据，最好每次开机都把该目录清空</td>
</tr>
<tr>
<td style="text-align:center">/usr/</td>
<td style="text-align:center">系统软件资源目录，注意usr不是user的缩写，而是”Unix Software Resource”的缩写，所以不是存放用户数据，而是存放系统软件资源的目录。系统中安装的软件大多数都在这里</td>
</tr>
<tr>
<td style="text-align:center">/var/</td>
<td style="text-align:center">动态数据保存位置，主要保存缓存、日志以及软件运行所产生的文件</td>
</tr>
</tbody>
</table>
</div>
<h3 id="服务器注意事项"><a href="#服务器注意事项" class="headerlink" title="服务器注意事项"></a>服务器注意事项</h3><ol>
<li>远程服务器不允许关机，只能重启</li>
<li>重启时应该关闭服务</li>
<li>不要在服务器的访问高峰运行高负载命令</li>
<li>远程配置防火墙时不要把自己踢出服务器（可以设置每五分钟将防火墙规则重置一次，配置完之后再取消该设置）</li>
<li>指定合理的密码规范并定期更新</li>
<li>合理分配权限</li>
<li>定期备份重要数据和日志</li>
</ol>
<p>磁盘分区是用分区编辑器在磁盘上划分几个逻辑部分，碟片一旦划分成数个分区，不同类的目录和文件 可以存储进不同的分区。</p>
<h1 id="系统分区"><a href="#系统分区" class="headerlink" title="系统分区"></a>系统分区</h1><h2 id="分区类型"><a href="#分区类型" class="headerlink" title="分区类型"></a>分区类型</h2><ul>
<li>主分区：最多只能有4个</li>
<li>扩展分区：<ul>
<li>最多只能有1个</li>
<li>主分区加扩展分区最多有4个</li>
<li>不能写入数据，只能包含逻辑分区（这种限制是硬盘的限制）</li>
</ul>
</li>
<li>逻辑分区</li>
</ul>
<h2 id="格式化"><a href="#格式化" class="headerlink" title="格式化"></a>格式化</h2><p>硬盘经过正确分区后仍不能写入数据，我们的硬盘还必须经过格式化之后才能写入数据。格式化又称逻辑格式化，它是根据用户选定的文件系统（如FAT16、FAT32、NTFS、EXT 2、EXT3、EXT4等），在磁盘的特定区域写入特定数据，在分区中划分出一片用于存放文件分配表、目录表等用于文件管理的磁盘空间。格式化就是按照文件系统的规则将硬盘分成等大小的数据块，我们把数据块称为block。</p>
<blockquote>
<p>注：Windows可以识别的系统有FAT16、FAT32、NTFS；Linux可以识别的系统有EXT2、EXT3、EXT4</p>
</blockquote>
<h2 id="设备文件名"><a href="#设备文件名" class="headerlink" title="设备文件名"></a>设备文件名</h2><h4 id="硬盘设备文件名"><a href="#硬盘设备文件名" class="headerlink" title="硬盘设备文件名"></a>硬盘设备文件名</h4><p>Windows是直接分区——&gt;格式化——&gt;分配盘符即可使用，Linux需要分区——&gt;格式化——&gt;给分区建立设备文件名——&gt;分配盘符才能使用。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>硬件</th>
<th>设备文件名</th>
</tr>
</thead>
<tbody>
<tr>
<td>IDE硬盘</td>
<td>/dev/hd[a-d]</td>
</tr>
<tr>
<td>SCSI/SATA/USB硬盘</td>
<td>/dev/sd[a-p]</td>
</tr>
<tr>
<td>光驱</td>
<td>/dev/cdrom或dev/sr0</td>
</tr>
<tr>
<td>软盘</td>
<td>/dev/fd[0-1]</td>
</tr>
<tr>
<td>打印机（25针）</td>
<td>/dev/lp[0-2]</td>
</tr>
<tr>
<td>打印机（USB）</td>
<td>/dev/usb/lp[0-15]</td>
</tr>
<tr>
<td>鼠标</td>
<td>/dev/mouse</td>
</tr>
</tbody>
</table>
</div>
<h4 id="分区设备文件名"><a href="#分区设备文件名" class="headerlink" title="分区设备文件名"></a>分区设备文件名</h4><p>分区设备文件名直接<strong>在硬盘设备文件名后面加分区号</strong>即可，如</p>
<ul>
<li>IDE硬盘接口第一个分区：/dev/hda1（如今几乎看不到）</li>
<li>SCSI硬盘接口、SATA硬盘接口的第一个分区：/dev/sda1</li>
</ul>
<blockquote>
<p>IDE硬盘是最古老的硬盘，理论最高传输速度是133M/s</p>
<p>SCSI硬盘接口与IDE硬盘同时代，更加昂贵但速度更快，理论最高传输速度可达200M/s，但这种硬盘主要用在服务器上</p>
<p>但上两种硬盘接口如今已经基本淘汰，如今使用更多的是小口的SATA串口硬盘，SATA已发展到3代，其理论传输速度最高可达500M/s，目前不管是服务器还是个人机基本使用的都是SATA硬盘接口。</p>
</blockquote>
<p>需要留意的是，逻辑分区永远都是从5开始的</p>
<h2 id="挂载"><a href="#挂载" class="headerlink" title="挂载"></a>挂载</h2><p>挂载实际上就是Windows中分配盘符的过程，盘符则被相应地称为挂载点，必须分区的分区有以下两种：</p>
<ol>
<li>根分区：/</li>
<li>swap分区（交换分区）：可以理解为虚拟内存，当真正内存不够用时，可以使用这部分交换分区的硬盘空间来当内存，理论上来说交换分区应该是内存的两倍，但最大不超过2GB</li>
</ol>
<p>若无这两个分区，Linux不能正常使用，但我们还推荐把/boot单独分区，这是为了防止Linux系统启动不起来，一般200MB即可。</p>
<h1 id="远程登陆管理工具"><a href="#远程登陆管理工具" class="headerlink" title="远程登陆管理工具"></a>远程登陆管理工具</h1><h2 id="网络连接"><a href="#网络连接" class="headerlink" title="网络连接"></a>网络连接</h2><p>网络连接从虚拟机设置中可以看到，一共有三种：桥接、NAT和Host-only，下面讲解其区别：</p>
<ul>
<li>桥接：桥接意味着虚拟机如同一个单独的主机一样访问Wifi等，也可以和其他机器通信</li>
<li>NAT：虚拟机仅能和主机通信，但若主机可以访问互联网，虚拟机也可以访问互联网</li>
<li>Host-only：虚拟机仅能和主机本机通信，不能访问互联网</li>
</ul>
<h2 id="网络配置"><a href="#网络配置" class="headerlink" title="网络配置"></a>网络配置</h2><ol>
<li>首先调成Host-only模式，使得虚拟机仅与主机连接</li>
<li>在主机上找到VMware Network Adapter VMnet1的IP地址，我本地地址为192.168.19.1</li>
<li>在虚拟机上使用<code>ishw -c netwowrk</code>命令找到logical name，此即为虚拟机的网卡名称，我的虚拟网卡名称为ens33</li>
<li>使用命令ifconfig  [不等于IP地址]  logical name，例如我使用的是<code>ifconfig ens33 192.168.19.2</code></li>
<li>此时再ifconfig即可看到我们设置的已生效</li>
<li>我们可以在主机ping这个IP地址看到生效</li>
<li>使用secureCRT连接即可</li>
</ol>
<p>需要注意的是，以上方法配置IP地址时不是永久生效的，也就是重新启动电脑时就失效了，若想永久生效需要改变配置文件</p>
<p>若使用NAT模式，则步骤简单很多，只需要ifconfig获得IP地址之后直接用secureCRT连接即可</p>
<h2 id="WinSCP"><a href="#WinSCP" class="headerlink" title="WinSCP"></a>WinSCP</h2><p>另外推荐一个Windows主机与Linux虚拟机进行文件传输的工具——WinSCP，操作方法与上面类似，只需输入对应的IP地址即可连接。</p>
<h2 id="安装linux系统（以ubuntu为例）"><a href="#安装linux系统（以ubuntu为例）" class="headerlink" title="安装linux系统（以ubuntu为例）"></a>安装linux系统（以ubuntu为例）</h2><ul>
<li><p>使用vmware虚拟机安装</p>
<p><a href="https://zhuanlan.zhihu.com/p/38797088" target="_blank" rel="noopener">参考此博客：VMware安装Ubuntu18.04</a></p>
</li>
<li><p>使用win10子系统安装</p>
<p><a href="https://zhuanlan.zhihu.com/p/76032647" target="_blank" rel="noopener">参考此博客：在 win10 下使用 ubuntu 子系统</a></p>
</li>
</ul>
<h1 id="Linux常用命令"><a href="#Linux常用命令" class="headerlink" title="Linux常用命令"></a>Linux常用命令</h1><h2 id="一、最常用命令"><a href="#一、最常用命令" class="headerlink" title="一、最常用命令"></a>一、最常用命令</h2><p>这是我们<strong>使用得最多</strong>的命令了，<strong>Linux最基础的命令</strong>！</p>
<ul>
<li>可用 <code>pwd</code>命令查看用户的当前目录</li>
<li>可用 <code>cd</code> 命令来切换目录</li>
<li><code>.</code>表示当前目录</li>
<li><code>..</code> 表示当前目录的上一级目录（父目录）</li>
<li><code>-</code>表示用 cd 命令切换目录<strong>前</strong>所在的目录</li>
<li><code>~</code> 表示<strong>用户主目录</strong>的绝对路径名</li>
</ul>
<p><strong>绝对路径：</strong></p>
<ul>
<li>以斜线（/）开头 ，描述到文件位置的<strong>完整说明</strong> ，任何时候你想指定文件名的时候都可以使用</li>
</ul>
<p><strong>相对路径 ：</strong></p>
<ul>
<li>不以斜线（/）开头 ，指定<strong>相对于你的当前工作目录而言的位置</strong> ，可以被用作指定文件名的简捷方式</li>
</ul>
<h2 id="二、文件处理命令"><a href="#二、文件处理命令" class="headerlink" title="二、文件处理命令"></a>二、文件处理命令</h2><h3 id="1-命令格式与目录处理命令ls"><a href="#1-命令格式与目录处理命令ls" class="headerlink" title="1. 命令格式与目录处理命令ls"></a>1. 命令格式与目录处理命令<code>ls</code></h3><p><strong>命令格式</strong>：<code>命令[-选项][-参数]</code>，例：<code>ls -la /etc</code></p>
<p><strong>说明</strong>：</p>
<ol>
<li>个别命令使用不遵循此格式</li>
<li>当有多个选项时，可以写在一起</li>
<li>简化选项与完整选项：<code>-a</code> 等于 <code>--all</code></li>
</ol>
<p><code>ls</code>命令的语法：</p>
<ol>
<li><p><code>ls -a</code>可以显示所有文件，包括隐藏文件（以点.开头的文件是隐藏文件）</p>
</li>
<li><p>若希望查询的不是当前目录，可以使用<code>ls+其他目录</code>进行查询</p>
</li>
<li><p><code>ls -l</code>可以显示更多属性（long），属性阐述如下：</p>
</li>
<li><p>第一列分为三个部分，第一部分（如d告诉我们文件的类型是一个目录，-为二进制文件，1为软链接文件），drwx表示该文件支持读写和执行操作，r,w,x分别对应读、写、执行三个权限，三列分别对应所有者，所属组，其他人的权限</p>
</li>
<li><p>第二列的2、2、3等表示调用次数</p>
<ol>
<li>第三列表示所有者，也就是这个文件的总负责人（拥有文件的所有权，可转让）</li>
</ol>
</li>
<li>第四列表示所属组，也就是可以操作这个文件的人<ol>
<li>第五列表示文件大小，默认单位是字节（很反Windows）</li>
</ol>
</li>
<li><p>最后一个是文件的最后一次修改时间（Linux没有创建时间这个概念）</p>
</li>
<li><p><code>ls -lh</code>比原先的更人性化（humanitarian），它将对应的单位也显示了出来，<code>-h</code>实际上是一个通用选项，很多命令都可以加</p>
</li>
<li><p><code>-d</code>显示当前目录本身而不显示目录下的数据，一般与<code>-l</code>结合使用，如<code>ls -ld /etc</code></p>
</li>
<li><p><code>ls -id</code>可以查看当前目录对应的文件ID</p>
</li>
</ol>
<h3 id="2-目录处理命令"><a href="#2-目录处理命令" class="headerlink" title="2. 目录处理命令"></a>2. 目录处理命令</h3><h5 id="mkdir"><a href="#mkdir" class="headerlink" title="mkdir"></a><code>mkdir</code></h5><p><strong>语法</strong>：<code>mkdir -p [目录名]</code></p>
<p><strong>功能描述</strong>：创建新目录，<code>-p</code>递归创建（若一个目录本身不存在，可以在创建这个目录的同时创建子目录），也可以同时创建多个目录</p>
<h5 id="cd"><a href="#cd" class="headerlink" title="cd"></a><code>cd</code></h5><p><strong>语法</strong>：<code>cd directory</code></p>
<p><strong>功能描述</strong>：改变当前目录</p>
<h5 id="pwd"><a href="#pwd" class="headerlink" title="pwd"></a><code>pwd</code></h5><p><strong>语法</strong>：<code>pwd</code></p>
<p><strong>功能描述</strong>：显示当前目录（print working directory）</p>
<h5 id="rmdir"><a href="#rmdir" class="headerlink" title="rmdir"></a><code>rmdir</code></h5><p><strong>语法</strong>：<code>rmdir [目录名]</code></p>
<p><strong>功能描述</strong>：删除空目录（若目录非空则不能删除）</p>
<h5 id="cp"><a href="#cp" class="headerlink" title="cp"></a><code>cp</code></h5><p><strong>语法</strong>：<code>cp -rf [源文件或目录] [目标目录] -r 复制目录 -p 保留文件属性（文件创建时间等不发生变化）</code></p>
<p><strong>功能描述</strong>：复制文件或目录</p>
<h5 id="mv"><a href="#mv" class="headerlink" title="mv"></a><code>mv</code></h5><p><strong>语法</strong>：<code>mv [源文件或目录] [目标目录]</code></p>
<p><strong>功能描述</strong>：剪切文件、改名</p>
<h5 id="rm"><a href="#rm" class="headerlink" title="rm"></a><code>rm</code></h5><p><strong>语法</strong>：<code>rm -rf [文件或目录] -r 删除目录 -f 强制执行</code></p>
<p><strong>功能描述</strong>：删除文件</p>
<h3 id="3-文件处理命令"><a href="#3-文件处理命令" class="headerlink" title="3. 文件处理命令"></a>3. 文件处理命令</h3><h5 id="touch"><a href="#touch" class="headerlink" title="touch"></a><code>touch</code></h5><p><strong>语法</strong>：<code>touch [文件名]</code></p>
<p><strong>功能描述</strong>：创建空文件</p>
<h5 id="cat"><a href="#cat" class="headerlink" title="cat"></a><code>cat</code></h5><p><strong>语法</strong>：<code>cat [文件名]</code></p>
<p><strong>功能描述</strong>：显示文件内容  <code>-n</code>可显示行号</p>
<h5 id="tac"><a href="#tac" class="headerlink" title="tac"></a><code>tac</code></h5><p>与<code>cat</code>相反，可以倒着显示</p>
<h5 id="more"><a href="#more" class="headerlink" title="more"></a><code>more</code></h5><p><code>cat</code>命令显示的往往过多，若希望分页显示可以使用<code>more</code>，用法与<code>cat</code>相同，使用时按空格可以一页页往后翻，使用q或Q退出</p>
<h5 id="less"><a href="#less" class="headerlink" title="less"></a><code>less</code></h5><p>由于<code>more</code>无法向上翻，我们可以使用<code>less</code>命令，可以使用page up一页页往上翻，也可以使用上箭头一行行往上翻，其他操作与<code>more</code>相同。另外<code>less</code>还可以进行搜索，比如想要搜索关键词service，可以输入/service进行检索，页面会对这些关键词进行高亮，可以使用<code>n</code>找到其他关键词位置</p>
<h5 id="head"><a href="#head" class="headerlink" title="head"></a><code>head</code></h5><p>若只想要看文件的前几行，可以使用<code>head -n</code>加指定行数，若不加则默认显示前10行</p>
<h5 id="tail"><a href="#tail" class="headerlink" title="tail"></a><code>tail</code></h5><p>与<code>head</code>类似 ，但是显示后面几行。</p>
<p>常用搭配为：<code>tail -f</code>，该命令会动态显示文件末尾内容</p>
<h2 id="三、链接命令ln"><a href="#三、链接命令ln" class="headerlink" title="三、链接命令ln"></a>三、链接命令<code>ln</code></h2><p><strong>语法</strong>：<code>ln -s [原文件] [目标文件] -s 创建软链接</code></p>
<p><strong>功能描述</strong>：生成链接文件</p>
<p><strong>示例</strong>：</p>
<ul>
<li><code>ln -s /etc/issue issue.soft</code>：生成软链接</li>
<li><code>ln /etc/issue issue.hard</code>：生成硬链接</li>
</ul>
<p><strong>软链接和硬链接的区别</strong></p>
<p>我们使用<code>ls -l</code>查看这两个文件的信息：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-rw-r--r-- 2 root root 26 Jul 15  2020 issue.hard</span><br><span class="line">lrwxrwxrwx 1 root root 10 Jan 31 04:55 issue.soft -&gt; &#x2F;etc&#x2F;issue</span><br></pre></td></tr></table></figure>
<p>我们会发现这两个文件的信息相差的非常多，软链接文件开头的文件类型是<code>l(link)</code>，三个权限都是<code>rwx</code>，即可读可写可执行，软链接文件就类似于Windows的快捷方式，用处是便于做管理，我们可以看到最后有一个箭头指向<code>/etc/issue</code>。另外我们看到这个文件只有31个字节，因为它只是一个符号链接。我们可以总结得出软链接的三个特点：</p>
<ol>
<li>权限是<code>rwx</code></li>
<li>文件很小，只是符号链接</li>
<li>箭头指向源文件</li>
</ol>
<p>下面我们看硬链接的特点，我们首先分别查看 这两个文件的信息：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls -l issue.hard</span><br><span class="line">ls -l &#x2F;etc&#x2F;issue</span><br></pre></td></tr></table></figure>
<p>我们可以看到这两个文件的所有信息一模一样，包括文件的大小，这类似于拷贝，似乎相当于<code>cp -p</code>，而硬链接和<code>cp -p</code>的最大不同就是硬链接可以实现同步更新，我们可以做一个简单的实验，我们先查看硬链接文件，然后往源文件中写入文件，可以发现硬链接文件也被同时修改了，当然软链接也会同步修改。</p>
<p>但当我们将源文件复制到另一个位置并删除原位置文件之后，再试图打开软链接会提示“没有那个文件或目录”，而且再显示这个目录软链接会标红并一直闪，而硬链接可以正常访问，没有影响，这就是硬链接和软连接的不同之处。</p>
<p>实际上我们可以通过命令<code>ls -i</code>来识别其<code>i</code>节点以辨别出是硬链接还是软链接，硬链接和源文件的<code>i</code>节点相同，软链接则不同。</p>
<p>硬链接相当于一个同步文件，但可以做实时备份（一个文件删了不会影响另一个文件），硬链接有两个限制，这也是硬链接和软链接的区别：</p>
<ol>
<li>不能跨分区</li>
<li>不能针对目录使用</li>
</ol>
<h2 id="四、权限管理命令"><a href="#四、权限管理命令" class="headerlink" title="四、权限管理命令"></a>四、权限管理命令</h2><p>Linux用户一共分成三类，分别是所有者（U），所属组（G）和其他人（O），权限也分成三类，分别是<code>r</code>，<code>w</code>，<code>x</code>，对应读、写、执行，我们首先学习如何更改权限。</p>
<h4 id="chmod"><a href="#chmod" class="headerlink" title="chmod"></a><code>chmod</code></h4><p>更改文件的人只能是文件所有者或者管理员root用户，更改文件权限有两种方式，第一种方式如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod [&#123;ugoa&#125;&#123;+-&#x3D;&#125;&#123;rwx&#125;][文件或目录]</span><br></pre></td></tr></table></figure>
<p>其中第一个花括号里<code>u</code>，<code>g</code>，<code>o</code>，<code>a</code>分别表示所有者，所属组，其他人和所有人，第二个花括号<code>+</code>和<code>-</code>分别表示增加和减少权限，<code>=</code>表示成为后面的权限。第二种方式如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod [mod&#x3D;421][文件或目录] -R 递归修改</span><br></pre></td></tr></table></figure>
<p>数字的意思只是将三个权限位分别用数字来表示，比如<code>r</code>用4表示，<code>w</code>用2表示，<code>x</code>用1表示，则若要表示<code>rwxrw-r--</code>则记为<code>764</code></p>
<h4 id="chown"><a href="#chown" class="headerlink" title="chown"></a><code>chown</code></h4><p>命令英文原意是<code>change file ownership</code>，作用是改变文件或目录的所有者，改变文件file的所有者为user的具体用法为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chown user file</span><br></pre></td></tr></table></figure>
<p>要注意只有root和文件的所有者可以改变文件的权限</p>
<h4 id="chgrp"><a href="#chgrp" class="headerlink" title="chgrp"></a><code>chgrp</code></h4><p>命令英文原意是<code>change file  group ownership</code>，作用是改变文件或目录的所属组，若具体用法和前面<code>chown</code>相同。我们可以使用<code>groupadd</code>命令添加组（使用<code>useradd</code>命令添加用户）</p>
<h4 id="umask"><a href="#umask" class="headerlink" title="umask"></a><code>umask</code></h4><p>命令英文原意是<code>the user file-creation mask</code>，作用是显示、设置文件的缺省权限，语法是：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">umask [-S]</span><br></pre></td></tr></table></figure>
<p>其中<code>-S</code>的作用是显示新建文件的缺省权限，但需要注意的是缺省创建文件时不可以有可执行权限的，所以当<code>touch</code>创建文件时会发现所有权限都少了<code>x</code>。</p>
<p>当我们直接使用<code>umask</code>时，比如显示0022，第一个0是特殊权限，我们暂时不涉及，第二只第四位分别是所有者、所属组和其他人，我们的最终权限实际上是<code>777-022=755</code>，也就是<code>rwx r-x r-x</code>，当然这指的是目录，如果是文件由于没有可执行权限，文件权限应当是<code>rw- r-- r--</code>，当然缺省创建的权限可以更改，直接使用<code>umask 077</code>即可将文件缺省权限更改为<code>rwx --- ---</code>，但不推荐做这种更改</p>
]]></content>
      <categories>
        <category>Blockchain</category>
      </categories>
  </entry>
</search>
